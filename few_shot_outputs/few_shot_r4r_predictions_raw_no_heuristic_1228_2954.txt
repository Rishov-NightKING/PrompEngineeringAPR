private void updateBitmap(byte[] byteBuffer, int length) { Preconditions.checkArgument(bitmap.size() >= length, "Bitmap size must be greater than or equal to length"); long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp = tmp + h2; } }
private void updateBitmap(byte[] byteBuffer, int length) { long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp += h2; } }
```java import com.google.common.hash.Hashing; import org.apache.kudu.annotations.InterfaceAudience; import org.apache.kudu.annotations.InterfaceStability; import java.nio.charset.StandardCharsets; import java.util.BitSet; @InterfaceAudience.LimitedPrivate("Test") public class BloomFilter { private final int nBits; private final int nHashes; private final BitSet bitmap; public BloomFilter(int nBits, int nHashes) { this.nBits = nBits; this.nHashes = nHashes; this.bitmap = new BitSet(nBits); } private void bitmapSet(BitSet bitmap, long bitPos) { bitmap.set((int) bitPos); } private long pickBit(long hash, int nBits) { return hash % nBits; } private long hash(byte[] data) { return Hashing.murmur3_128().hashBytes(data).asLong(); } private boolean checkIfContains(byte[] data) { long h = hash(data); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp = tmp + h2; } return true; } public boolean mayContain(String data) { byte[] byteBuffer = data.getBytes(StandardCharsets.UTF_8); return checkIfContains(byteBuffer); } public boolean mayContain(boolean data) { byte[] byteBuffer = new byte[1]; byteBuffer[0] = (byte) (data ? 1 : 0); return checkIfContains(byteBuffer); } public boolean mayContain(byte data) { byte[] byteBuffer = new byte[1]; byteBuffer[0] = data; return checkIfContains(byteBuffer); } } ```
private boolean checkIfContains(byte[] bytes) { long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; int remHashes = nHashes; while (remHashes != 0) { long bitPos = pickBit(tmp, nBits); if (!bitmapTest(bitmap, bitPos)) { return false; } tmp = tmp + h2; remHashes--; } return true; }
private boolean checkIfContains(byte[] bytes) { long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; int remHashes = nHashes; while (remHashes != 0) { long bitpos = pickBit(tmp, nBits); if (!bitmapTest(bitmap, bitpos)) { return false; } tmp += h2; remHashes--; } return true; }
private static long computeCrc32(@NonNull byte[] type, @Nullable byte[] data) { CRC32 checksum = new CRC32(); checksum.update(type); if (data != null) { checksum.update(data); } return checksum.getValue(); } import static org.mockito.Matchers.anyString; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.when; import com.android.annotations.NonNull; import com.android.sdklib.mock.MockLog; import com.google.common.base.Optional; import junit.framework.TestCase; import org.mockito.Mock; import org.mockito.MockitoAnnotations; import org.xml.sax.SAXException; import java.io.IOException; import javax.xml.parsers.ParserConfigurationException; public class PlaceholderHandlerTest extends TestCase { @Mock ActionRecorder.Builder mActionRecorder; @Mock MergingReport.Builder mBuilder; MockLog mMockLog = new MockLog(); @Override protected void setUp() throws Exception { super.setUp(); MockitoAnnotations.initMocks(this); when(mBuilder.getLogger()).thenReturn(mMockLog); when(mBuilder.getActionRecorder()).thenReturn(mActionRecorder); } public void testPlaceholders() throws ParserConfigurationException, SAXException, IOException { String xml = "" + "<manifest\n" // rest of the code } myWizardState.put(ATTR_RES_DIR, resPath); myWizardState.put(ATTR_RES_OUT, FileUtil.toSystemIndependentName(resDir.getPath())); File manifestDir = findManifestDirectory(sourceProvider); if (manifestDir != null) { String manifestPath = FileUtil.getRelativePath(ioModuleDir, manifestDir); myWizardState.put(ATTR_MANIFEST_DIR, manifestPath); myWizardState.put(ATTR_MANIFEST_OUT, FileUtil.toSystemIndependentName(manifestDir.getPath())); } String applicationPackageName = gradleProject.computePackageName(); String packageName = null; if (myTargetFolder != null && IdeaSourceProvider.containsFile(sourceProvider, VfsUtilCore.virtualToIoFile(myTargetFolder))) { packageName = getPackageFromDirectory(VfsUtilCore.virtualToIoFile(myTargetFolder), sourceProvider, myModule, myWizardState); if (packageName != null && !packageName.equals(applicationPackageName)) { myWizardState.put(ATTR_APPLICATION_PACKAGE, applicationPackageName); } } long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (
private static int computeOptimalHashCount(int nBits, int elems) { int nHashes = (int)(nBits * kNaturalLog2 / elems); if (nHashes < 1) { nHashes = 1; } return nHashes; }
// software distributed under the License is distributed on an // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.client; import static org.junit.Assert.assertTrue; import java.util.Random; import org.apache.kudu.util.BloomFilter; import org.junit.Test; public class TestBloomFilter { private int nBytes = 32 * 1024; private int kRandomSeed = (int) System.currentTimeMillis(); private int nKeys = 2000; private double fpRate = 0.01; @Test public void testIntGenBFBySizeAndFPRate() { final BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); // Put integers into bloomfilter by random Random rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { bf.put(rand.nextInt()); } // Reset the rand and check existence of the keys. rand = new Random(kRandomSeed); // ... rest of the test code } }
public void testFloat() { final BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); Random rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { bf.put(rand.nextFloat()); } rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { assertTrue(bf.mayContain(rand.nextFloat())); } }
import java.util.List; import org.apache.impala.authorization.PrivilegeRequestBuilder; import org.apache.impala.common.AnalysisException; import org.apache.impala.common.InternalException; import org.apache.impala.common.Pair; import org.apache.impala.thrift.TAdminRequest; import org.apache.impala.thrift.TAdminRequestType; import org.apache.impala.thrift.TNetworkAddress; import org.apache.impala.thrift.TShutdownParams; import com.google.common.base.Joiner; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; public class AdminFnStmt extends StatementBase { private final String fnName_; private final List<Expr> params_; public AdminFnStmt(String fnName, List<Expr> params) { this.fnName_ = Preconditions.checkNotNull(fnName); this.params_ = Preconditions.checkNotNull(params); } public String getFnName() { return fnName_; } public List<Expr> getParams() { return params_; } }
/** * This class is not used since it accesses multiple catalog entities in order to compute a snapshot * of catalog metadata. * * Operations that CREATE/DROP catalog objects such as tables and databases employ the * following locking protocol: * 1. Acquire the metastoreDdlLock_ * 2. Update the Hive Metastore * 3. Increment and get a new catalog version * 4. Update the catalog * 5. Make Sentry cache changes if ownership is enabled. * 5. Release the metastoreDdlLock_ * * It is imperative that other operations that need to hold both the catalog lock and * table locks at the same time follow the same locking protocol and acquire these * locks in that particular order. Also, operations that modify table metadata * (e.g. alter table statements) should not acquire the metastoreDdlLock_. * * TODO: Refactor the CatalogOpExecutor and CatalogServiceCatalog classes and consolidate * the locking protocol into a single class. * * TODO: Improve catalog's consistency guarantees by using a hierarchical locking scheme. */
public Description getDescription(ChangeResource rsrc) { boolean isProjectOwner; try { isProjectOwner = projectControlFactory.controlFor(rsrc.getProject(), rsrc.getUser()).isOwner(); } catch (IOException | NoSuchProjectException e) { isProjectOwner = false; log.error("Cannot retrieve project owner ACL", e); } return new Description() .setLabel("Start Review") .setTitle("Set Ready For Review") .setVisible( and( rsrc.getChange().getStatus() == Status.NEW && rsrc.getChange().isWorkInProgress(), or( rsrc.isUserOwner(), or( isProjectOwner, permissionBackend.user(self).testCond(GlobalPermission.ADMINISTRATE_SERVER) ) ) ) ); } public Description getDescription(ChangeResource rsrc) { boolean isProjectOwner; try { isProjectOwner = projectControlFactory.controlFor(rsrc.getProject(), rsrc.getUser()).isOwner(); } catch (IOException | NoSuchProjectException e) { isProjectOwner = false; log.error("Cannot retrieve project owner ACL", e); } return new Description() .setLabel("WIP") .setTitle("Set Work In Progress") .setVisible( and( rsrc.getChange().getStatus() == Status.NEW && !rsrc.getChange().isWorkInProgress(), or( rsrc.isUserOwner(), or( isProjectOwner, permissionBackend.user(self).testCond(GlobalPermission.ADMINISTRATE_SERVER) ) ) ) ); } /** * application to retain this object for long periods of time. */ public static class PathInfo { public final FileMode fileMode; public final String path; public final ObjectId objectId; protected PathInfo(TreeWalk tw) { fileMode = tw.getFileMode(0); path = tw.getPathString(); objectId = tw.getObjectId(0); } } /** * The revision at which the data was loaded. Is null for data yet to be created. */ @Nullable protected RevCommit revision; protected RevWalk rw; protected ObjectReader reader; protected ObjectInserter inserter; protected DirCache newTree; /** * @return name of the reference storing this configuration. */ protected abstract String getRefName(); /** * Set up the metadata, parsing any state from the loaded revision. */ protected abstract void onLoad()
package org.apache.kudu.util; import javax.annotation.concurrent.NotThreadSafe; import java.nio.charset.StandardCharsets; import java.util.BitSet; import com.sangupta.murmur.Murmur2; import org.apache.yetus.audience.InterfaceAudience; import org.apache.yetus.audience.InterfaceStability; /** * A space-efficient filter which offers an approximate containment check. * * It can be used to filter all the records which are wanted, but doesn't guarantee to filter out * all the records which are not wanted. * * Please check this <a href="https://en.wikipedia.org/wiki/Bloom_filter">wiki</a> for more details. * * The BloomFilter here is a scanning filter and used to shrink the amount of records */ @NotThreadSafe @InterfaceAudience.Public @InterfaceStability.Evolving public class BloomFilter { // implementation code goes here }
/** * A space-efficient filter and offers an approximate containment check. * * <p>It can be used to filter all the records which are wanted, but doesn't guarantee to filter out * all the records which are <i>not</i> wanted. * * <p>Please check this <a href="https://en.wikipedia.org/wiki/Bloom_filter">wiki</a> for more details. * * <p>The {@code BloomFilter} here is a scanning filter and used to shrink the amount of records * returned from TServer. It provides different types of {@code put} methods. When you {@code put} a * record into {@code BloomFilter}, it means you are expecting TServer to return records have * the same value in a scan. * * <p>Here is an example for use: * <pre> * {@code * BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); * bf.put(1); * bf.put(3); * bf.put(4); * } * </pre> */ public class BloomFilter { // implementation details... }
Buggy Code: ```java * the same value in a scan. * * <p>Here is an example for use: * <pre> * {@code * BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); * bf.put(1); * bf.put(3); * bf.put(4); * byte[] bitSet = bf.getBitSet(); * byte[] nHashes = bf.getNHashes(); * String hashFunctionName = bf.getHashFunctionName(); * // TODO: implemnt the interface for serializaing and sending * // (bitSet, nHashes, hashFunctionName) to TServer. * } * </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { if (bitSet.size() < 8) { ``` Review: "implement" and "serializing" Fixed Code: ```java * the same value in a scan. * * <p>Here is an example for use: * <pre> * {@code * BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); * bf.put(1); * bf.put(3); * bf.put(4); * byte[] bitSet = bf.getBitSet(); * byte[] nHashes = bf.getNHashes(); * String hashFunctionName = bf.getHashFunctionName(); * // TODO: implement the interface for serializing and sending * // (bitSet, nHashes, hashFunctionName) to TServer. * } * </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { if (bitSet.size() < 8) { ```
public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { Preconditions.checkArgument(bitSet.size() >= 8, "Number of bits in bitset should be at least 8, but found " + bitSet.length()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } }
@InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { if (bitSet.size() < 8) { throw new IllegalArgumentException("Number of bits in bitset should be at least 8, but found " + bitSet.length()); } this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } }
if (bitSet.size() < 8) { throw new IllegalArgumentException("Number of bits in bitset should be at least 8, but found " + bitSet.length()); } this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate, HashFunction hashFunction) { int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, optimalExpectedCount(nBytes, fpRate)); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); }
public static BloomFilter bySizeAndFPRate(int nBytes, double fpRate, HashFunction hashFunction) { int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, optimalExpectedCount(nBytes, fpRate)); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); } public static BloomFilter byCountAndFPRate(int expectedCount, double fpRate) { return byCountAndFPRate(expectedCount, fpRate, HashFunctions.MURMUR2); } public static BloomFilter byCountAndFPRate(int expectedCount, double fpRate, HashFunction hashFunction) { int nBytes = optimalNumOfBytes(expectedCount, fpRate); int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, expectedCount); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); }
import org.eclipse.emf.compare.rcp.ui.internal.structuremergeviewer.filters.StructureMergeViewerFilter; import org.eclipse.emf.edit.provider.IItemColorProvider; import org.eclipse.emf.edit.provider.IItemFontProvider; import org.eclipse.emf.edit.tree.provider.TreeItemProviderAdapterFactory; /** * A specific implementation of {@link org.eclipse.emf.edit.tree.provider.TreeItemProviderAdapterFactory}. * * @author <a href="mailto:mikael.barbero@obeo.fr">Mikael Barbero</a> * @since 4.0 */ public class TreeItemProviderAdapterFactorySpec extends TreeItemProviderAdapterFactory { /** An instance of {@code StructureMergeViewerFilter}. */ private final StructureMergeViewerFilter filter; /** * Constructor. */ public TreeItemProviderAdapterFactorySpec(StructureMergeViewerFilter filter) { super(); this.filter = filter; supportedTypes.add(IItemFontProvider.class); supportedTypes.add(IItemColorProvider.class); supportedTypes.add(IItemStyledLabelProvider.class); supportedTypes.add(IItemDescriptionProvider.class); supportedTypes.add(ISemanticObjectLabelProvider.class); } /** * {@inheritDoc} * * @see org.eclipse.emf.edit.tree.provider.TreeItemProviderAdapterFactory#createTreeNodeAdapter() */ @Override public Adapter createTreeNodeAdapter() { return new TreeNodeItemProviderSpec(this); } }
private ExternalIdsUpdate(GitRepositoryManager repoManager, AllUsersName allUsersName, ExternalIdCache externalIdCache, PersonIdent committerIdent, PersonIdent authorIdent) { this.repoManager = repoManager; this.allUsersName = allUsersName; this.externalIdCache = externalIdCache; this.committerIdent = committerIdent; this.authorIdent = authorIdent; } public void insert(@NotNull AllocationInfo alloc) { StackTraceElement[] trace = alloc.getStackTrace(); String[] packages; if (trace.length > 0) { int match = 0; for (int i = 0; i < trace.length; i++) { if (myFilter.matcher(trace[i].getClassName()).matches()) { match = i; break; } } // TODO don't use the last trace, but use a user defined filter. String name = trace[match].getClassName(); int ix = name.indexOf("$"); name = ix >= 0 ? name.substring(0, ix) : name; packages = name.split("\\."); } else { packages = new String[] { "< Unknown >" }; } insert(packages, alloc, 0); } public void setValues(@NotNull Color primaryColor, @NotNull Color primaryDarkColor, @NotNull Color accentColor) { myColorPalette = new ColorPalette(primaryColor, primaryDarkColor, accentColor); } updateBitset(byteBuffer, 8); public void put(float data) { put(Float.floatToIntBits(data)); } public void put(double data) { put(Double.doubleToLongBits(data)); } public void put(String data) { put(data.getBytes(StandardCharsets.UTF_8)); } public byte[] getBitSet() { return bitSet.toByteArray(); } public int getNHashes() { return nHashes; } private String getHashFunctionName() { return hashFunction.toString(); } // Mark it `private` and user can only use the `HashFunction` specified in the // enumeration below. Thus user cannot send TServer a self defined `HashFunction`, // which might not be identified by TServer. private interface HashFunction { long hash(byte[] data, int length, long seed); } public enum HashFunctions implements HashFunction { // Currently only Murmur2 is provided as an option for hashing.
// Currently only Murmur2 is provided as an option for hashing. // We can consider to provide some other options like Murmur3, CityHash in the future. MURMUR2() { @Override public long hash(byte[] data, int length, long seed) { return Murmur2.hash(data, length, seed); } @Override public String toString() { return "Murmur2"; } } private void updateBitset(byte[] byteBuffer, int length) { Preconditions.checkArgument(byteBuffer.length >= length); long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = tmp % nBits; bitSet.set((int)bitPos); tmp += h2; } } @InterfaceAudience.LimitedPrivate("Test") public boolean mayContain(byte[] data) { return checkIfContains(data); }
TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onDatabase("functional", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onTable("functional", "alltypes", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes")) .error(accessError(true, "functional.alltypes"), onServer(true, allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onDatabase(true, "functional", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onTable(true, "functional", "alltypes", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))); } finally { authzCatalog_.removeRole("foo_owner"); } // Alter table rename. authorize("alter table functional.alltypes rename to functional_parquet.new_table") .ok(onServer(TPrivilegeLevel.ALL)) .ok(onServer(TPrivilegeLevel.OWNER)) .ok(onDatabase("functional", TPrivilegeLevel.ALL), onDatabase("functional_parquet", TPrivilegeLevel.CREATE))
import java.util.regex.Matcher; import java.util.regex.Pattern; import org.eclipse.osee.framework.core.enums.BranchType; import org.eclipse.osee.framework.jdk.core.type.IResourceRegistry; import org.eclipse.osee.framework.jdk.core.type.ResourceToken; import org.eclipse.osee.orcs.data.BranchReadable; import org.eclipse.osee.orcs.search.BranchQuery; import org.eclipse.osee.template.engine.CompositeRule; import org.eclipse.osee.template.engine.IdentifiableOptionsRule; import org.eclipse.osee.template.engine.PageCreator; import org.eclipse.osee.template.engine.PageFactory; public class OseeAppletPage { //example input for pattern: <input id="selected_branch" type="text" list="baselineBranches" required/><br /> private static final Pattern listAttributePattern = Pattern.compile("<input[^>]+?list=\"([^\"]+)"); private final BranchQuery query; public OseeAppletPage(BranchQuery query) { this.query = query; } public String realizeApplet(IResourceRegistry registry, ResourceToken valuesResource) { PageCreator page = PageFactory.newPageCreator(registry); return realizeApplet(valuesResource, page); } }
private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; if (ownerType == PrincipalType.USER) { Reference<Boolean> existingUser = new Reference<>(); owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); if (!existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } else { owner = catalog_.addRoleIfNotExists(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } response.result.addToRemoved_catalog_objects(cPrivilege.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } finally { catalog_.getLock().writeLock().unlock(); } }
@InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private static final double DEFAULT_FP_RATE = 0.01; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { Preconditions.checkArgument(bitSet.size() >= 8, "Number of bits in bitset should be at least 8, but found %s.", bitSet.size()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySize(int nBytes) { return BySizeAndFPRate(nBytes, DEFAULT_FP_RATE); } }
"bitset should be at least 8, but found %s.", bitSet.size()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter bySize(int nBytes) { return bySizeAndFPRate(nBytes, DEFAULT_FP_RATE); } public static BloomFilter bySizeAndFPRate(int nBytes, double fpRate) { return bySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); }
/** * Generate bloom filter, default hashing is {@code Murmur2}. * * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been {@code put} into the {@code BloomFilter}. */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } /** * Generate bloom filter. * * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been {@code put} into the {@code BloomFilter}. * @param hashFunction hashing used when updating or checking containment, user should pick * the hashing function from {@code HashFunctions} */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate, HashFunction hashFunction) { // implementation } /** * Generate bloom filter, default hashing is {@code Murmur2}. * * @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize(int nBytes) { return BySizeAndFPRate(nBytes, DEFAULT_FP_RATE); }
TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onDatabase("functional", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onTable("functional", "alltypes", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes")) .error(accessError(true, "functional.alltypes"), onServer(true, allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onDatabase(true, "functional", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onTable(true, "functional", "alltypes", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))); } finally { authzCatalog_.removeRole("foo_owner"); } boolean exceptionThrown = false; try { parseAndAnalyze("alter table functional.alltypes set owner role foo_owner", analysisContext_, frontend_); } catch (AnalysisException e) { exceptionThrown = true; assertEquals("Role 'foo_owner' does not exist.", e.getLocalizedMessage()); }
private final long MISSING_TBL_LOAD_WAIT_TIMEOUT_MS = 2 * 60 * 1000; private final long MAX_CATALOG_UPDATE_WAIT_TIME_MS = 2 * 1000; //TODO: Make the reload interval configurable. private static final int AUTHORIZATION_POLICY_RELOAD_INTERVAL_SECS = 5 * 60; private ImpaladCatalog impaladCatalog_; private final AuthorizationConfig authzConfig_; private final AtomicReference<AuthorizationChecker> authzChecker_; private final ScheduledExecutorService policyReader_ = Executors.newScheduledThreadPool(1); private final String defaultKuduMasterHosts_; public Frontend(AuthorizationConfig authorizationConfig, String defaultKuduMasterHosts) { this(authorizationConfig, new ImpaladCatalog(defaultKuduMasterHosts)); } /** * C'tor used by tests to pass in a custom ImpaladCatalog. */ public Frontend(AuthorizationConfig authorizationConfig, ImpaladCatalog catalog) { authzConfig_ = authorizationConfig; impaladCatalog_ = catalog; defaultKuduMasterHosts_ = catalog.getDefaultKuduMasterHosts(); authzChecker_ = new AtomicReference<AuthorizationChecker>(new AuthorizationChecker(authzConfig_, impaladCatalog_.getAuthPolicy())); }
public String getHostname() { return hostPort.getHostString(); }
public void killTabletServerOnPort(int port) throws InterruptedException { Process ts = tserverProcesses.remove(port); if (ts == null) { return; } LOG.info("Killing server at port " + port); destroyAndWaitForProcess(ts); } public void killAllTabletServers() throws InterruptedException { for (Process tserver : tserverProcesses.values()) { destroyAndWaitForProcess(tserver); } tserverProcesses.clear(); } public void restartDeadTabletServers() throws Exception { for (int port : tserverPorts) { if (tserverProcesses.containsKey(port)) { continue; } restartDeadTabletServerOnPort(port); } }
private static String findBinaryDir() { String kuduHomeProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduHomeProp != null) { LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduHomeProp); return kuduHomeProp; } String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { // kudu is available on the path BufferedReader reader = new BufferedReader(new InputStreamReader(process.getInputStream())); String kuduPath = reader.readLine(); LOG.info("Using Kudu binary directory found on the path: {}", kuduPath); return new File(kuduPath).getParent(); } } catch (IOException | InterruptedException e) { LOG.warn("Failed to determine Kudu binary directory: {}", e.getMessage()); } LOG.warn("Unable to find Kudu binary directory. Defaulting to current working directory."); return System.getProperty("user.dir"); }
String kuduHomeProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduHomeProp != null) { LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduHomeProp); return kuduHomeProp; } String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); // ... } } } catch (IOException | InterruptedException e) { LOG.warn("Failed to determine Kudu binary directory", e); } // Default to using the kudu that is available on the path return "kudu";
import java.io.File; import java.io.IOException; import java.io.InputStreamReader; import java.io.Reader; import java.nio.charset.StandardCharsets; import com.google.common.io.CharStreams; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KuduHomeLocator { private static final Logger LOG = LoggerFactory.getLogger(KuduHomeLocator.class); private static final String KUDU_HOME_VAR = "KUDU_HOME"; private static final String UTF_8 = StandardCharsets.UTF_8.name(); public static String locateKuduHome() { // First, check the system property. String kuduHomeProp = System.getProperty("kudu.home"); if (kuduHomeProp != null) { LOG.info("Using Kudu home directory specified by system property 'kudu.home': {}", kuduHomeProp); String kuduBinDir = new File(kuduHomeProp, "bin").getPath(); return kuduBinDir; } // Next, check the environment variable. String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } // Last, use the kudu that is available on the path. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) { LOG.error("Failed to locate Kudu home directory", ex); } return null; } }
String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; // Last, use the kudu that is available on the path. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) { throw new RuntimeException("Error while locating kudu binary", ex); } throw new RuntimeException("Could not locate the kudu binary directory. " + "Set the system variable " + KUDU_BIN_DIR_PROP + ", environment variable " + KUDU_HOME_VAR);
public class AlterViewStmt extends CreateOrAlterViewStmtBase { public AlterViewStmt(TableName tableName, List<ColumnDef> columnDefs, QueryStmt viewDefStmt) { super(false, tableName, columnDefs, null, viewDefStmt); } @Override public void analyze(Analyzer analyzer) throws AnalysisException { // Enforce Hive column labels for view compatibility. analyzer.setUseHiveColLabels(true); viewDefStmt_.analyze(analyzer); Preconditions.checkState(tableName_ != null && !tableName_.isEmpty()); dbName_ = analyzer.getTargetDbName(tableName_); try { owner_ = analyzer.getUser().getShortName(); } catch (InternalException e) { throw new AnalysisException("Error calling getShortName() for user: " + analyzer.getUser().getName(), e); } serverName_ = analyzer.getServerName(); FeTable table = analyzer.getTable(tableName_, Privilege.ALTER); Preconditions.checkNotNull(table); if (!(table instanceof FeView)) { throw new AnalysisException("Table " + tableName_ + " is not a view"); } } }
try { miniCluster.waitFor(); } catch (InterruptedException e) { LOG.warn("Minicluster process did not exit, destroying"); miniCluster.destroy(); } } /** * Returns a master server identified by an address. * * @param hostAndPort unique address identifying the server * @return the DaemonInfo of the server * @throws RuntimeException if the server is not found */ private DaemonInfo getMasterServer(HostAndPort hostAndPort) throws RuntimeException { DaemonInfo d = masterServers.get(hostAndPort); if (d == null) { throw new RuntimeException(String.format("Master server %s not found", hostAndPort)); } return d; } /** * Returns a tablet server identified by an address. * * @param hostAndPort unique address identifying the server * @return the DaemonInfo of the server * @throws RuntimeException if the server is not found */ private DaemonInfo getTabletServer(HostAndPort hostAndPort) throws RuntimeException { DaemonInfo d = tabletServers.get(hostAndPort); if (d == null) { throw new RuntimeException(String.format("Tablet server %s not found", hostAndPort)); } return d; }
import static org.junit.Assert.assertArrayEquals; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; import java.net.InetAddress; import java.net.InetSocketAddress; import java.util.Arrays; import java.util.List; import org.apache.kudu.client.HostAndPort; import org.junit.Test; public class TestNetUtil { @Test public void testParseString() { String aStringWithPort = "1.2.3.4:1234"; HostAndPort hostAndPortForAStringWithPort = NetUtil.parseString(aStringWithPort, 0); assertEquals(hostAndPortForAStringWithPort.getHost(), "1.2.3.4"); assertEquals(hostAndPortForAStringWithPort.getPort(), 1234); String aStringWithoutPort = "1.2.3.4"; HostAndPort hostAndPortForAStringWithoutPort = NetUtil.parseString(aStringWithoutPort, 12345); assertEquals(hostAndPortForAStringWithoutPort.getHost(), "1.2.3.4"); assertEquals(hostAndPortForAStringWithoutPort.getPort(), 12345); } }
private static String findBinaryDir() { String kuduBinDirProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduBinDirProp != null) { LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduBinDirProp); return kuduBinDirProp; } try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) { // Handle exception } // Default behavior if no binary directory is found return null; }
private PrivilegedExecutor privilegedExecutor; public KuduSink() { this(null); } @InterfaceAudience.LimitedPrivate("Test") @InterfaceAudience.Private public KuduSink(KuduClient kuduClient) { this.client = kuduClient; } @Override public synchronized void start() { Preconditions.checkState(table == null && session == null, "Please call stop before calling start on an old instance."); if (client == null) { client = privilegedExecutor.execute(new PrivilegedAction<KuduClient>() { @Override public KuduClient run() { return new KuduClient.KuduClientBuilder(masterAddresses).build(); } }); } session = client.newSession(); session.setFlushMode(SessionConfiguration.FlushMode.MANUAL_FLUSH); session.setTimeoutMillis(timeoutMillis); session.setIgnoreAllDuplicateRows(ignoreDuplicateRows); session.setMutationBufferSpace(batchSize); try { table = client.openTable(tableName); } catch (Exception ex) { sinkCounter.incrementConnectionFailedCount(); // Handle exception } }
TABLE_NAME); batchSize = context.getInteger(BATCH_SIZE, DEFAULT_BATCH_SIZE); timeoutMillis = context.getLong(TIMEOUT_MILLIS, DEFAULT_TIMEOUT_MILLIS); ignoreDuplicateRows = context.getBoolean(IGNORE_DUPLICATE_ROWS, DEFAULT_IGNORE_DUPLICATE_ROWS); String operationProducerType = context.getString(PRODUCER); String kerberosPrincipal = context.getString(KERBEROS_PRINCIPAL); String kerberosKeytab = context.getString(KERBEROS_KEYTAB); String proxyUser = context.getString(PROXY_USER); privilegedExecutor = FlumeAuthenticationUtil.getAuthenticator(kerberosPrincipal, kerberosKeytab).proxyAs(proxyUser); // Check for operations producer, if null set default operations producer type. if (operationProducerType == null || operationProducerType.isEmpty()) { operationProducerType = DEFAULT_KUDU_OPERATION_PRODUCER; logger.warn("No Kudu operations producer provided, using default"); } Context producerContext = new Context(); producerContext.putAll(context.getSubProperties(KuduSinkConfigurationConstants.PRODUCER_PREFIX)); try { Class<? extends KuduOperationsProducer> clazz = (Class<? extends KuduOperationsProducer>) Class.forName(operationProducerType); operationsProducer = clazz.getDeclaredConstructor().newInstance();
.nullable(true).build()); columns.add(new ColumnSchema.ColumnSchemaBuilder("stringField", Type.STRING).build()); columns.add(new ColumnSchema.ColumnSchemaBuilder("decimalField", Type.DECIMAL) .typeAttributes(DecimalUtil.typeAttributes(9, 1)).build()); CreateTableOptions createOptions = new CreateTableOptions() .setRangePartitionColumns(ImmutableList.of("key")) .setNumReplicas(1); return createTable(tableName, new Schema(columns), createOptions); } private List<Event> generateEvents(int eventCount, SchemaLocation schemaLocation) throws Exception { List<Event> events = new ArrayList<>(); for (int i = 0; i < eventCount; i++) { AvroKuduOperationsProducerTestRecord record = new AvroKuduOperationsProducerTestRecord(); record.setKey(10 * i); record.setLongField(2L * i); record.setDoubleField(2.71828 * i); record.setNullableField(i % 2 == 0 ? null : "taco"); record.setStringField(String.format("hello %d", i)); record.setDecimalField(BigDecimal.valueOf(i, 1)); events.add(record); } return events; }
```java return sink; } static KuduSink createSecureSink(String tableName, String masterAddresses, String clusterRoot) { Context context = new Context(); context.put(KERBEROS_KEYTAB, clusterRoot + "/krb5kdc/test-user.keytab"); context.put(KERBEROS_PRINCIPAL, "test-user@KRBTEST.COM"); return createSink(tableName, null, context, masterAddresses); } static void processEventsCreatingSink(KuduClient syncClient, Context context, String tableName, List<Event> events) throws EventDeliveryException { KuduSink sink = createSink(syncClient, tableName, context); sink.start(); processEvents(sink, events); } static void processEvents(KuduSink sink, List<Event> events) throws EventDeliveryException { Channel channel = sink.getChannel(); Transaction tx = channel.getTransaction(); tx.begin(); for (Event e : events) { channel.put(e); } tx.commit(); tx.close(); Status status = sink.process(); if (events.isEmpty()) { assertSame("incorrect status for empty channel", status, Status.BACKOFF); } else { assertSame("incorrect status for non-empty channel", status, Status.READY); } } ```
import org.slf4j.LoggerFactory; import org.apache.kudu.ColumnSchema; import org.apache.kudu.Schema; import org.apache.kudu.Type; import org.apache.kudu.client.BaseKuduTest; import org.apache.kudu.client.CreateTableOptions; import org.apache.kudu.client.KuduTable; import org.apache.kudu.client.MiniKuduCluster.MiniKuduClusterBuilder; public class SecureKuduSinkTest extends BaseKuduTest { private static final Logger LOG = LoggerFactory.getLogger(SecureKuduSinkTest.class); private static final int TICKET_LIFETIME_SECONDS = 10; private static final int RENEWABLE_LIFETIME_SECONDS = 30; @Before public void clearTicketCacheProperty() { // Let Flume authenticate System.clearProperty(KUDU_TICKETCACHE_PROPERTY); } @Override protected MiniKuduClusterBuilder getMiniClusterBuilder() { return super.getMiniClusterBuilder() .kdcTicketLifetime(TICKET_LIFETIME_SECONDS + "s") .kdcRenewLifetime(RENEWABLE_LIFETIME_SECONDS + "s") .enableKerberos(); } @Test public void testEventsWithShortTickets() throws Exception { LOG.info("Creating new table..."); ArrayList<ColumnSchema> columns = new ArrayList<>(1); // Rest of the code... } }
Fixed Code: StatsSetupConst.TRUE); msClient.alter_table(msTable_.getDbName(), msTable_.getTableName(), msTable_); } catch (TException e) { throw new TableLoadingException(e.getMessage()); } } /** * Loads the schema from the Kudu table including column definitions and primary key * columns. Throws an ImpalaRuntimeException if Kudu column data types cannot be * mapped to Impala data types. */ private void loadSchema(org.apache.kudu.client.KuduTable kuduTable) throws ImpalaRuntimeException { Preconditions.checkNotNull(kuduTable); clearColumns(); primaryKeyColumnNames_.clear(); List<FieldSchema> cols = msTable_.getSd().getCols(); cols.clear(); int pos = 0; kuduSchema_ = kuduTable.getSchema(); for (ColumnSchema colSchema: kuduSchema_.getColumns()) { KuduColumn kuduCol = KuduColumn.fromColumnSchema(colSchema, pos); Preconditions.checkNotNull(kuduCol); // Add the HMS column } } public CacheMetrics(MetricMaker metrics, final DynamicMap<Cache<?, ?>> cacheMap) { final CallbackMetric1<String, Long> memEnt = metrics.newCallbackMetric("caches/memory_cached", Long.class, new Description("Memory entries").setGauge().setUnit("entries"), F_NAME); final CallbackMetric1<String, Double> memHit = metrics.newCallbackMetric("caches/memory_hit_ratio", Double.class, new Description("Memory hit ratio").setGauge().setUnit("percent"), fName); final CallbackMetric1<String, Long> memEvict = metrics.newCallbackMetric("caches/memory_eviction_count", Long.class, new Description("Memory eviction count").setGauge() .setUnit("evicted entries"), fName); final CallbackMetric1<String, Long> perDiskEnt = metrics.newCallbackMetric("caches/disk_cached", Long.class, new Description("Disk entries used by persistent cache").setGauge() .setUnit("entries"), fName); final CallbackMetric1<String, Double> perDiskHit = private static long interval(Config rc, String section) { long interval = -1; try { interval = ConfigUtil.getTimeUnit(rc
public PartitionRefImpl(TPartialPartitionInfo p) { this.info_ = p; }
private void computeScanRangeLocations(Analyzer analyzer) { TNetworkAddress networkAddress = addressToTNetworkAddress("localhost:12345"); Integer hostIndex = analyzer.getHostIndex().getIndex(networkAddress); scanRanges_ = Lists.newArrayList( new TScanRangeLocations( new TScanRange(), Lists.newArrayList(new TScanRangeLocation(hostIndex)) ) ); } private boolean tryConvertKuduPredicate(Analyzer analyzer, org.apache.kudu.client.KuduTable table, Expr expr) { if (!(expr instanceof BinaryPredicate)) { return false; } BinaryPredicate predicate = (BinaryPredicate) expr; predicate = normalizeSlotRefComparison(predicate, analyzer); if (predicate == null) { return false; } ComparisonOp op = getKuduOperator(predicate.getOp()); if (op == null) { return false; } SlotRef ref = (SlotRef) predicate.getChild(0); LiteralExpr literal = (LiteralExpr) predicate.getChild(1); if (literal instanceof NullLiteral) { return false; } String colName = ref.getDesc().getColumn().getName(); ColumnSchema column = table.getSchema().getColumn(colName); KuduPredicate kuduPredicate = null; switch (literal.getType().getPrimitiveType()) { case BOOLEAN: { kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((BoolLiteral)literal).getValue()); break; } case TINYINT: // other cases... } // rest of the code... }
if (!(expr instanceof BinaryPredicate)) return false; BinaryPredicate predicate = (BinaryPredicate) expr; predicate = normalizeSlotRefComparison(predicate, analyzer); if (predicate == null) return false; ComparisonOp op = getKuduOperator(predicate.getOp()); if (op == null) return false; SlotRef ref = (SlotRef) predicate.getChild(0); LiteralExpr literal = (LiteralExpr) predicate.getChild(1); if (literal instanceof NullLiteral) return false; String colName = ref.getDesc().getColumn().getName(); ColumnSchema column = table.getSchema().getColumn(colName); KuduPredicate kuduPredicate = null; switch (literal.getType().getPrimitiveType()) { case BOOLEAN: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((BoolLiteral)literal).getValue()); break; case TINYINT: case SMALLINT: case INT: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((NumericLiteral)literal).getLongValue()); break; case BIGINT: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((NumericLiteral)literal).getLongValue()); break; case FLOAT: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((NumericLiteral)literal).getDoubleValue()); break; case DOUBLE: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((NumericLiteral)literal).getDoubleValue()); break; case STRING: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((StringLiteral)literal).getValue()); break; case TIMESTAMP: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((TimestampLiteral)literal).getValue()); break; default: return false; } return kuduPredicate != null;
// Compute the per-instance number of concurrent partitions, taking the number // of nodes and the data partition of the fragment executing this sink into account. long numConcurrentPartitionsPerInstance; if (inputIsClustered_) { numConcurrentPartitionsPerInstance = 1; } else { numConcurrentPartitionsPerInstance = fragment_.getPerInstanceNdv(queryOptions.getMt_dop(), partitionKeyExprs_); if (numConcurrentPartitionsPerInstance == -1) { numConcurrentPartitionsPerInstance = DEFAULT_NUM_PARTITIONS; } } FeFsTable table = (FeFsTable) targetTable_; // TODO: Estimate the memory requirements more accurately by partition type. Set<HdfsFileFormat> formats = table.getFileFormats(); long perPartitionMemReq = getPerPartitionMemReq(formats); long perInstanceMemEstimate; // The estimate is based purely on the per-partition mem req if the input cardinality_ // or the avg row size is unknown. if (inputNode.getCardinality() == -1 || inputNode.getAvgRowSize() == -1) { perInstanceMemEstimate = numConcurrentPartitionsPerInstance * perPartitionMemReq; }
FunctionCallExpr mergeAggInputFn) { super(); fnName_ = fnName; params_ = params; mergeAggInputFn_ = mergeAggInputFn == null ? null : (FunctionCallExpr) mergeAggInputFn.clone(); if (params.exprs() != null) { children_ = Lists.newArrayList(params_.exprs()); } } public static Expr createExpr(FunctionName fnName, FunctionParams params) { FunctionCallExpr functionCallExpr = new FunctionCallExpr(fnName, params); if (fnName.getFnNamePath().size() == 1 && fnName.getFnNamePath().get(0).equalsIgnoreCase("decode") || fnName.getFnNamePath().size() == 2 && fnName.getFnNamePath().get(0).equalsIgnoreCase(Catalog.BUILTINS_DB) && fnName.getFnNamePath().get(1).equalsIgnoreCase("decode")) { return new CaseExpr(functionCallExpr); } return functionCallExpr; }
public static FunctionCallExpr createMergeAggCall(FunctionCallExpr agg, List<Expr> params) { Preconditions.checkState(agg.isAnalyzed()); Preconditions.checkState(agg.isAggregateFunction()); FunctionCallExpr result = new FunctionCallExpr(agg.fnName_, new FunctionParams(false, params), agg); result.fn_ = agg.fn_; result.type_ = agg.type_; if (agg.isMergeAggFn()) { result.label_ = agg.label_; } else { result.label_ = agg.toSql().replaceFirst(agg.fnName_.toString(), agg.fnName_.toString() + ":merge"); } Preconditions.checkState(!result.type_.isWildcardDecimal()); return result; }
public static FunctionCallExpr createMergeAggCall(FunctionCallExpr agg, List<Expr> params) { Preconditions.checkState(agg.isAnalyzed()); Preconditions.checkState(agg.isAggregateFunction()); FunctionCallExpr result = new FunctionCallExpr(agg.fnName_, new FunctionParams(false, params), agg); result.fn_ = agg.fn_; result.type_ = agg.type_; if (agg.isMergeAggFn()) { result.label_ = agg.label_; } else { result.label_ = agg.toSql().replaceFirst(agg.fnName_.toString(), agg.fnName_.toString() + ":merge"); } Preconditions.checkState(!result.type_.isWildcardDecimal()); return result; }
// For CTAS the overall TExecRequest statement type is DDL, but the // query_exec_request should be DML result.stmt_type = analysisResult.isCreateTableAsSelectStmt() ? TStmtType.DDL : TStmtType.DML; result.query_exec_request.stmt_type = TStmtType.DML; // create finalization params of insert stmt InsertStmt insertStmt = analysisResult.getInsertStmt(); if (insertStmt.getTargetTable() instanceof HdfsTable) { TFinalizeParams finalizeParams = new TFinalizeParams(); finalizeParams.setIs_overwrite(insertStmt.isOverwrite()); finalizeParams.setTable_name(insertStmt.getTargetTableName().getTbl()); finalizeParams.setTable_id(insertStmt.getTargetTable().getId()); String db = insertStmt.getTargetTableName().getDb(); finalizeParams.setTable_db(db == null ? queryCtx.session.database : db); HdfsTable hdfsTable = (HdfsTable) insertStmt.getTargetTable(); finalizeParams.setHdfs_base_dir(hdfsTable.getHdfsBaseDir()); finalizeParams.setStaging_dir(hdfsTable.getHdfsBaseDir() + "/_impala_insert_staging"); queryExecRequest.setFinalize_params(finalizeParams); }
import org.slf4j.LoggerFactory; import com.google.common.base.Objects; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** * Encapsulates all the information needed to compute a list of aggregate functions with * compatible grouping including their distributed execution. * * Each SELECT block containing aggregates will have a single MultiAggregateInfo which * will contain one AggregateInfo per unique list of DISTINCT expressions. If there is * only a single DISTINCT class, a single AggregateInfo will be created which will * represent that class and any non-DISTINCT aggregates. If there is more than one * DISTINCT class, the non-DISTINCT aggregates will be grouped together in their own * AggregateInfo. * * Execution is modeled as a tree of AggregateInfo objects which express the local and * merging aggregate computations. The tree structure looks as follows: * - for non-distinct aggregation: * - aggInfo: contains the original aggregation functions and grouping exprs * - aggInfo.mergeAggInfo: contains the merging aggregation functions (grouping */
private long warnThresholdMs_; private static final long WARN_THRESHOLD_MS = 10000; private long infoThresholdMs_; private static final long INFO_THRESHOLD_MS = 1000; private Thread monitorThread_; private volatile boolean shouldRun = true; private static JvmPauseMonitor INSTANCE = new JvmPauseMonitor(); public static void initPauseMonitor() { if (INSTANCE.isStarted()) return; INSTANCE.init(); } private JvmPauseMonitor() { this(INFO_THRESHOLD_MS, WARN_THRESHOLD_MS); } private JvmPauseMonitor(long infoThresholdMs, long warnThresholdMs) { this.infoThresholdMs_ = infoThresholdMs; this.warnThresholdMs_ = warnThresholdMs; } protected void init() { monitorThread_ = new Thread(new Monitor(), "JVM pause monitor"); monitorThread_.setDaemon(true); monitorThread_.start(); }
switch (catalogObject.getType()) { case DATABASE: return "DATABASE:" + catalogObject.getDb().getDb_name().toLowerCase(); case TABLE: case VIEW: TTable tbl = catalogObject.getTable(); return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; case ROLE: return "ROLE:" + catalogObject.getRole().getRole_name().toLowerCase(); case PRIVILEGE: return "PRIVILEGE:" + catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default: return ""; }
public void testBasicsWithStats() { // Return all rows. Cardinality is row count runTest("SELECT id FROM functional.alltypes", 7300); // Return all rows. Cardinality is row count, // should not be influenced by limited NDV of selected // column. runTest("SELECT bool_col FROM functional.alltypes", 7300); // Result cardinality reduced by limited NDV. // Boolean column has cardinality 3 (true, false, null). // Since we have metadata, and know the column is non-null, // NDV is 2. We select one of them. runTest("SELECT id FROM functional.alltypes WHERE bool_col = TRUE", 7300/2); // Result cardinality reduced by NDV. // NDV should be 10 (from metadata). runTest("SELECT id FROM functional.alltypes WHERE int_col = 1", 7300/10); // Assume classic 0.1 selectivity for other operators // IMPALA-7560 says this should be revised. runTest("SELECT id FROM functional.alltypes WHERE int_col != 1", 730); }
protected void expectCardinality(String query, long expected) { List<PlanFragment> plan = getPlan(query); PlanNode planRoot = plan.get(0).getPlanRoot(); assertEquals(expected, planRoot.getCardinality()); }
protected void runTest(String query, long expected) { List<PlanFragment> plan = getPlan(query); PlanNode planRoot = plan.get(0).getPlanRoot(); assertEquals("Unexpected cardinality for query: " + query, expected, planRoot.getCardinality()); }
private List<PlanFragment> getPlan(String query) { TQueryCtx queryCtx = TestUtils.createQueryContext("default", System.getProperty("user.name")); queryCtx.client_request.setStmt(query); TQueryOptions queryOptions = queryCtx.client_request.getQuery_options(); queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.capturePlan(); try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString(queryOptions, TExplainLevel.EXTENDED)); } return plan; }
// Set up the query context. Note that we need to deep copy it before planning each // time since planning modifies it. TQueryCtx queryCtx = TestUtils.createQueryContext("default", System.getProperty("user.name")); queryCtx.client_request.setStmt(query); TQueryOptions queryOptions = queryCtx.client_request.getQuery_options(); queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.capturePlan(); // Discard the actual execution plan. Return the cached // internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString(queryOptions, TExplainLevel.EXTENDED)); } return plan;
queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.capturePlan(); try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString(queryOptions, TExplainLevel.EXTENDED)); } return plan;
private void computeNdv() { if (desc_.getStats().hasStats()) { numDistinctValues_ = desc_.getStats().getNumDistinctValues(); if (desc_.isNullable() && !desc_.getType().isBoolean()) { long nullCount = desc_.getStats().getNumNulls(); if (nullCount > 0 || nullCount == -1) { numDistinctValues_ = Math.min(numDistinctValues_, MAX_NDV_WITH_NULLS); } } } }
// computeNdv(); FeTable rootTable = resolvedPath.getRootTable(); if (rootTable != null && rootTable.getNumRows() > 0) { numDistinctValues_ = Math.min(numDistinctValues_, rootTable.getNumRows()); } // computePreliminaryNdv(); FeTable rootTable = resolvedPath.getRootTable(); if (rootTable != null && rootTable.getNumRows() > 0) { numDistinctValues_ = computePreliminaryNdv(); } @Override protected float computeEvalCost() { return SLOT_REF_COST; } @Override protected boolean isConstantImpl() { return false; } public SlotDescriptor getDesc() { Preconditions.checkState(isAnalyzed()); Preconditions.checkNotNull(desc_); return desc_; } public SlotId getSlotId() { Preconditions.checkState(isAnalyzed()); Preconditions.checkNotNull(desc_); return desc_.getId(); } public Path getResolvedPath() { Preconditions.checkState(isAnalyzed()); return desc_.getPath(); } @Override
for (String groupName: groupNames) { roles.addAll(fe.getCatalog().getAuthPolicy().getGrantedRoles(groupName)); } for (Role role: roles) { Principal rolePrincipal = getRole(role.getName()); if (rolePrincipal != null) { createShowUserPrivilegesResultRows(result, rolePrincipal.getPrivileges(), filter, rolePrincipal.getName(), TPrincipalType.ROLE); } } return result; } /** * This method adds the rows to the output for the SHOW GRANT USER statement for user * and associated roles. */ private void createShowUserPrivilegesResultRows(TResultSet result, List<PrincipalPrivilege> privileges, TPrivilege filter, String name, TPrincipalType type) { for (PrincipalPrivilege p : privileges) { TPrivilege privilege = p.toThrift(); if (filter != null && isPrivilegeFiltered(filter, privilege)) { continue; } TResultRowBuilder rowBuilder = new TResultRowBuilder(); rowBuilder.add(Strings.nullToEmpty(type.name().toUpperCase())); rowBuilder.add(Strings.nullToEmpty(name)); // add more columns to the rowBuilder as needed result.addToRows(rowBuilder.get()); } }
public synchronized TResultSet getRolePrivileges(String roleName, TPrivilege filter) { TResultSet result = new TResultSet(); result.setSchema(new TResultSetMetadata()); addColumnOutputColumns(result.getSchema()); result.setRows(Lists.<TResultRow>newArrayList()); Role role = getRole(roleName); if (role != null) { for (RolePrivilege p : role.getPrivileges()) { TPrivilege privilege = p.toThrift(); if (filter != null && isPrivilegeFiltered(filter, privilege)) { continue; } TResultRowBuilder rowBuilder = new TResultRowBuilder(); result.addToRows(addShowPrincipalOutputResults(privilege, rowBuilder).get()); } } return result; } private boolean isPrivilegeFiltered(TPrivilege filter, TPrivilege privilege) { filter.setPrivilege_level(privilege.getPrivilege_level()); String privName = RolePrivilege.buildPrivilegeName(filter); // Check if the filter matches the privilege // ... }
Type.STRING.toThrift())); addColumnOutputColumns(result.getSchema()); result.setRows(Lists.<TResultRow>newArrayList()); // A user should be considered to not exist if they do not have any groups. Set<String> groupNames = fe.getAuthzChecker().getUserGroups( new org.apache.impala.authorization.User(principalName)); if (groupNames.isEmpty()) { throw new AnalysisException(String.format("User '%s' does not exist.", principalName)); } Principal user = getUser(principalName); if (user != null) { for (PrincipalPrivilege p : user.getPrivileges()) { TPrivilege privilege = p.toThrift(); if (filter != null) { if (isPrivilegeFiltered(filter, privilege)) continue; } TResultRowBuilder rowBuilder = new TResultRowBuilder(); rowBuilder.add(Strings.nullToEmpty(TPrincipalType.USER.name().toUpperCase())); rowBuilder.add(Strings.nullToEmpty(principalName)); result.addToRows(addShowPrincipalOutputResults(privilege, rowBuilder).get()); } }
import org.apache.sentry.provider.common.GroupMappingService; import java.util.Map; import java.util.Set; public class CustomClusterGroupMapper implements GroupMappingService { private final Map<String, Set<String>> groupsMap_ = Maps.newHashMap(); public CustomClusterGroupMapper() { String devUser = System.getProperty("user.name"); groupsMap_.put(devUser, Sets.newHashSet(devUser)); groupsMap_.put("user_1group", Sets.newHashSet("group_1")); groupsMap_.put("user_2group", Sets.newHashSet("group_2a", "group_2b")); groupsMap_.put("user1_shared", Sets.newHashSet("group_3")); } }
public CustomClusterResourceAuthorizationProvider(String resource, PolicyEngine policy, Model model) { super(policy, new CustomClusterGroupMapper(), model); }
public CustomClusterResourceAuthorizationProvider(Configuration conf, String resource, PolicyEngine policy, Model model) { super(policy, new CustomClusterGroupMapper(), model); }
import org.apache.impala.catalog.Type; import org.apache.impala.common.AnalysisException; import org.apache.impala.thrift.TExprNode; import org.apache.impala.thrift.TExprNodeType; import org.apache.impala.thrift.TSlotRef; import com.google.common.base.Joiner; import com.google.common.base.Objects; import com.google.common.base.Preconditions; public class SlotRef extends Expr { private static final int NULL_ADJUST_THRESHOLD = 1; private final List<String> rawPath_; private final String label_; private SlotDescriptor desc_; public SlotRef(ArrayList<String> rawPath) { super(); rawPath_ = rawPath; label_ = ToSqlUtils.getPathSql(rawPath_); } }
import static org.junit.Assert.fail; import java.util.List; import org.apache.impala.common.ImpalaException; import org.apache.impala.service.Frontend.PlanCtx; import org.apache.impala.testutil.TestUtils; import org.apache.impala.thrift.TExplainLevel; import org.apache.impala.thrift.TQueryCtx; import org.apache.impala.thrift.TQueryOptions; import org.junit.Test; /** * Test the inference of tuple cardinality from NDV and * selectivity. */ public class CardinalityTest extends PlannerTestBase { private static final boolean DEBUG_MODE = false; /** * Test the happy path: table with stats, no all-null cols. */ @Test public void testBasicsWithStats() { // Return all rows. Cardinality is row count; verifyCardinality("SELECT id FROM functional.alltypes", 7300); // Return all rows. Cardinality is row count, // should not be influenced by limited NDV of selected // column. verifyCardinality("SELECT bool_col FROM functional.alltypes", 7300); // Result cardinality reduced by limited NDV. // Boolean column has cardinality 3 (true, false, null). verifyCardinality("SELECT DISTINCT bool_col FROM functional.alltypes", 3); } }
queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.requestPlanCapture(); // Discard the actual execution plan. Return the cached internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { logger.debug(plan.get(0).getExplainString(queryOptions, TExplainLevel.EXTENDED)); } return plan;
public void testJoinWithoutStats() { expectCardinality("SELECT d FROM functional.alltypes, functional.nullrows", 7300 * 26); String baseStmt = "SELECT COUNT(*) " + "FROM functional.alltypes, functional.nullrows " + "GROUP BY "; expectCardinality(baseStmt + "id", 7300); expectCardinality(baseStmt + "a", 26); expectCardinality(baseStmt + "b", 2); expectCardinality(baseStmt + "f", 6); expectCardinality(baseStmt + "c", 1); expectCardinality(baseStmt + "a, c", 26); expectCardinality(baseStmt + "a, f", 156); }
public void testJoins() { // Cartesian product String joinClause = " FROM functional.alltypes t1, functional.alltypes t2 "; expectCardinality("SELECT t1.id" + joinClause, 7300 * 7300); // Cartesian product, reduced by NDV of group key expectCardinality("SELECT COUNT(*)" + joinClause + "GROUP BY t1.id", 7300); expectCardinality("SELECT COUNT(*)" + joinClause + "GROUP BY t1.id, t1.int_col", 7300 * 10); }
import org.apache.hadoop.util.GenericOptionsParser; import org.apache.kudu.test.KuduRule; import org.junit.After; import org.junit.Rule; import org.junit.Test; import org.apache.kudu.mapreduce.CommandLineParser; import org.apache.kudu.mapreduce.HadoopTestingUtility; public class ITExportCsv { private static final String TABLE_NAME = ITExportCsv.class.getName() + "-" + System.currentTimeMillis(); private static final HadoopTestingUtility HADOOP_UTIL = new HadoopTestingUtility(); @Rule public KuduRule harness = new KuduRule(); @After public void tearDown() throws Exception { HADOOP_UTIL.cleanup(); } @Test public void test() throws Exception { Configuration conf = new Configuration(); String testHome = HADOOP_UTIL.setupAndGetTestDir(ITExportCsv.class.getName(), conf).getAbsolutePath(); createFourTabletsTableWithNineRows(harness.getAsyncClient(), TABLE_NAME, DEFAULT_SLEEP); String[] args = new String[] { // test arguments }; CommandLineParser parser = new CommandLineParser(args); GenericOptionsParser gop = new GenericOptionsParser(conf, parser.getRemainingArgs()); ExportCsvJob job = new ExportCsvJob(); job.setConf(conf); int res = job.run(gop.getRemainingArgs()); assertEquals(0, res); } }
package org.apache.kudu.client; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertNotNull; import static org.junit.Assert.assertNotSame; import static org.junit.Assert.assertTrue; import com.stumbleupon.async.Deferred; import org.junit.Test; import org.apache.kudu.util.NetUtil; public class TestConnectionCache { @Test(timeout = 50000) public void test() throws Exception { MiniKuduCluster cluster = null; try { cluster = new MiniKuduCluster.MiniKuduClusterBuilder().numMasterServers(3).build(); final AsyncKuduClient client = new AsyncKuduClient.AsyncKuduClientBuilder(cluster.getMasterAddressesAsString()).build(); // Below we ping the masters directly using RpcProxy, so if they aren't ready to process // RPCs we'll get an error. Here by listing the tables we make sure this won't happen since // the masters are ready to process RPCs when they return from the constructor. client.listTables().join(); // Test connection cache ConnectionCache cache = new ConnectionCache(client, 10); assertNotNull(cache); // Get connection from cache Connection connection1 = cache.getConnection(); assertNotNull(connection1); // Get connection again, should be the same instance Connection connection2 = cache.getConnection(); assertSame(connection1, connection2); // Release connection cache.releaseConnection(connection1); // Get connection again, should be the same instance Connection connection3 = cache.getConnection(); assertSame(connection1, connection3); // Close connection cache.closeConnection(connection1); // Get connection again, should be a different instance Connection connection4 = cache.getConnection(); assertNotSame(connection1, connection4); // Close cache cache.close(); } finally { if (cluster != null) { cluster.shutdown(); } } } }
private MiniKuduClusterBuilder clusterBuilder; private MiniKuduCluster miniCluster; public AsyncKuduClient asyncClient; public KuduClient client; public KuduRule(final MiniKuduClusterBuilder clusterBuilder) { this.clusterBuilder = clusterBuilder; } public KuduRule() { this.clusterBuilder = getBaseClusterBuilder(); } public static MiniKuduClusterBuilder getBaseClusterBuilder() { return new MiniKuduClusterBuilder() .numMasterServers(NUM_MASTER_SERVERS) .numTabletServers(NUM_TABLET_SERVERS); } @Override public Statement apply(Statement base, Description description) { MasterServerConfig masterServerConfig = description.getAnnotation(MasterServerConfig.class); if (masterServerConfig != null) { for(String flag : masterServerConfig.flags()) { clusterBuilder.addMasterServerFlag(flag); } } // Rest of the code }
// Set any master server flags defined in the method level annotation. MasterServerConfig masterServerConfig = description.getAnnotation(MasterServerConfig.class); if (masterServerConfig != null) { for (String flag : masterServerConfig.flags()) { clusterBuilder.addMasterServerFlag(flag); } } // Set any tablet server flags defined in the method level annotation. TabletServerConfig tabletServerConfig = description.getAnnotation(TabletServerConfig.class); if (tabletServerConfig != null) { for (String flag : tabletServerConfig.flags()) { clusterBuilder.addTabletServerFlag(flag); } } // Generate the ExternalResource Statement. Statement statement = super.apply(base, description); // Wrap in the RetryRule to rerun flaky tests. // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. return new RetryRule().apply(statement, description);
// Set any tablet server flags defined in the method level annotation. TabletServerConfig tabletServerConfig = description.getAnnotation(TabletServerConfig.class); if (tabletServerConfig != null) { for(String flag : tabletServerConfig.flags()) { clusterBuilder.addTabletServerFlag(flag); } } // Generate the ExternalResource Statement. Statement statement = super.apply(base, description); // Wrap in the RetryRule to rerun flaky tests. // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. return new RetryRule().apply(statement, description);
// Wrap in the RetryRule to rerun flaky tests. // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. return new RetryRule().apply(statement, description); @Override public void before() throws Exception { FakeDNS.getInstance().install(); LOG.info("Creating a new MiniKuduCluster..."); miniCluster = clusterBuilder.build(); LOG.info("Creating a new Kudu client..."); asyncClient = new AsyncKuduClient.AsyncKuduClientBuilder(miniCluster.getMasterAddressesAsString()) .defaultAdminOperationTimeoutMs(DEFAULT_SLEEP) .build(); client = asyncClient.syncClient(); } @Override public void after() { try { if (asyncClient != null) { client.shutdown(); // No need to explicitly shutdown the async client, // shutting down the sync client effectively does that. } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } }
public void after() { try { if (asyncClient != null) { client.shutdown(); } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } }
public KuduTable createTable(String tableName, Schema schema, CreateTableOptions builder) throws KuduException { LOG.info("Creating table: {}", tableName); return asyncClient.syncClient().createTable(tableName, schema, builder); }
// shutting down the sync client effectively does that. } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } } public KuduClient getClient() { return client; } public AsyncKuduClient getAsyncClient() { return asyncClient; } public KuduTable createTable(String tableName, Schema schema, CreateTableOptions builder) throws KuduException { LOG.info("Creating table: {}", tableName); return asyncClient.syncClient().createTable(tableName, schema, builder); } /** * Helper method to open a table. It sets the default sleep time when joining on the Deferred. * @param name Name of the table * @return A KuduTable * @throws Exception MasterErrorException if the table doesn't exist */ public KuduTable openTable(String name) throws Exception { Deferred<KuduTable> d = asyncClient.openTable(name); return d.join(DEFAULT_SLEEP); }
public void kinit(String username) throws IOException { miniCluster.kinit(username); } public void resetClients() throws IOException { client.shutdown(); asyncClient = new AsyncKuduClient.AsyncKuduClientBuilder(miniCluster.getMasterAddressesAsString()) .defaultAdminOperationTimeoutMs(DEFAULT_SLEEP) .build(); client = asyncClient.syncClient(); } @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD}) public @interface MasterServerConfig { String[] flags(); }
public void analyzePlanHints(Analyzer analyzer) { for (PlanHint hint : planHints_) { if (hint.is("straight_join")) { analyzer.setIsStraightJoin(); } else { analyzer.addWarning("PLAN hint not recognized: " + hint); } } }
public void analyzePlanHints(Analyzer analyzer) { for (PlanHint hint : planHints_) { if (!hint.is("straight_join")) { analyzer.addWarning("PLAN hint not recognized: " + hint); } else { analyzer.setIsStraightJoin(); } } }
// be moved from this location, the user needs to have all permission. sourceDataPath_.analyze(analyzer, Privilege.ALL); // Catch all exceptions thrown by accessing files, and rethrow as AnalysisExceptions. try { Path source = sourceDataPath_.getPath(); FileSystem fs = source.getFileSystem(FileSystemUtil.getConfiguration()); if (!(fs instanceof DistributedFileSystem) && !(fs instanceof S3AFileSystem) && !(fs instanceof AzureBlobFileSystem) && !(fs instanceof SecureAzureBlobFileSystem) && !(fs instanceof AdlFileSystem)) { throw new AnalysisException(String.format("INPATH location '%s' " + "must point to an HDFS, S3A, ADL or ABFS filesystem.", sourceDataPath_)); } if (!fs.exists(source)) { throw new AnalysisException(String.format( "INPATH location '%s' does not exist.", sourceDataPath_)); } // If the source file is a directory, we must be able to read from and write to ... } catch (IOException e) { throw new AnalysisException("Error accessing files: " + e.getMessage()); }
private static final int COMPRESSION_LEVEL = Deflater.BEST_SPEED; public static byte[] deflateCompress(byte[] input) { if (input == null) { return null; } ByteArrayOutputStream bos = new ByteArrayOutputStream(input.length); DeflaterOutputStream stream = new DeflaterOutputStream(bos, new Deflater(COMPRESSION_LEVEL)); try { stream.write(input); stream.close(); } catch (IOException e) { LOG.error("Error compressing input bytes.", e); return null; } return bos.toByteArray(); }
// so it's necessary to use the HMS APIs directly. HiveMetastoreConfig hmsConfig = client.getHiveMetastoreConfig(); HiveConf hiveConf = new HiveConf(); hiveConf.setVar(HiveConf.ConfVars.METASTOREURIS, hmsConfig.getHiveMetastoreUris()); hiveConf.setBoolVar(HiveConf.ConfVars.METASTORE_USE_THRIFT_SASL, hmsConfig.getHiveMetastoreSaslEnabled()); // Check that the owner of the table in the HMS matches. IMetaStoreClient hmsClient = new HiveMetaStoreClient(hiveConf, null, false); assertEquals(owner, hmsClient.getTable("default", "testOverrideTableOwner").getOwner()); // Altering the table should not result in a change of ownership. client.alterTable(tableName, new AlterTableOptions().renameTable("default.testOverrideTableOwner_renamed")); assertEquals(owner, hmsClient.getTable("default", "testOverrideTableOwner_renamed").getOwner()); }
PrivilegeRequest request = new PrivilegeRequestBuilder() .any().onAnyTable(db.getName()).toRequest(); return authzChecker_.get().hasAccess(user, request); public List<DataSource> getDataSrcs(String pattern) { return impaladCatalog_.getDataSources(PatternMatcher.createHivePatternMatcher(pattern)); } public TResultSet getColumnStats(String dbName, String tableName) throws ImpalaException { Table table = impaladCatalog_.getTable(dbName, tableName); TResultSet result = new TResultSet(); TResultSetMetadata resultSchema = new TResultSetMetadata(); result.setSchema(resultSchema); resultSchema.addToColumns(new TColumn("Column", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("Type", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("#Distinct Values", Type.BIGINT.toThrift())); // Generate result set and schema for a SHOW COLUMN STATS command. return result; }
return authzChecker_.get().hasAccess(user, request); } public List<DataSource> getDataSrcs(String pattern) { return impaladCatalog_.getDataSources(PatternMatcher.createHivePatternMatcher(pattern)); } public TResultSet getColumnStats(String dbName, String tableName) throws ImpalaException { Table table = impaladCatalog_.getTable(dbName, tableName); TResultSet result = new TResultSet(); TResultSetMetadata resultSchema = new TResultSetMetadata(); result.setSchema(resultSchema); resultSchema.addToColumns(new TColumn("Column", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("Type", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("#Distinct Values", Type.BIGINT.toThrift())); resultSchema.addToColumns(new TColumn("#Nulls", Type.BIGINT.toThrift())); }
} else { root.setLimit(stmt.getLimit()); root.computeStats(analyzer); } return root; } private PlanNode addUnassignedConjuncts(Analyzer analyzer, List<TupleId> tupleIds, PlanNode root) throws ImpalaException { if (root instanceof EmptySetNode) return root; Preconditions.checkNotNull(root); List<Expr> conjuncts = analyzer.getUnassignedConjuncts(root); for (TupleId tid: tupleIds) { analyzer.createEquivConjuncts(tid, conjuncts); } if (conjuncts.isEmpty()) return root;
// KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { void analyze(Analyzer analyzer) throws AnalysisException; String toSql(); String toSql(ToSqlOptions options); }
List<Expr> tupleIsNullPreds = Lists.newArrayList(); for (Expr rhsExpr: inputSmap.getRhs()) { // Ignore substitutions that are irrelevant at this plan node and its ancestors. if (!rhsExpr.isBoundByTupleIds(input.getTupleIds())) continue; rhsExpr.collect(TupleIsNullPredicate.class, tupleIsNullPreds); } Expr.removeDuplicates(tupleIsNullPreds); sortInfo.addMaterializedExprs(tupleIsNullPreds, analyzer_); } sortInfo.getSortTupleDescriptor().materializeSlots(); return sortInfo; } private PlanNode createSortGroupPlan(PlanNode root, SortGroup sortGroup, List<Expr> partitionExprs) throws ImpalaException { List<Expr> partitionByExprs = sortGroup.partitionByExprs; List<OrderByElement> orderByElements = sortGroup.orderByElements;
public void computeResourceProfile(TQueryOptions queryOptions) { Preconditions.checkState(hasValidStats()); if (type_ == TSortType.TOPN) { long perInstanceMemEstimate = (long) Math.ceil((cardinality_ + offset_) * avgRowSize_); resourceProfile_ = new ResourceProfile(perInstanceMemEstimate, 0); return; } double fullInputSize = getChild(0).cardinality_ * avgRowSize_; boolean hasVarLenSlots = false; for (SlotDescriptor slotDesc : info_.getSortTupleDescriptor().getSlots()) { if (slotDesc.isMaterialized() && !slotDesc.getType().isFixedLengthType()) { hasVarLenSlots = true; break; } } if (hasVarLenSlots) { // Compute memory required for a 2-phase sort double memoryCost = Math.sqrt(fullInputSize); resourceProfile_ = new ResourceProfile((long) memoryCost, 0); } else { // Compute memory required for an in-memory sort long perInstanceMemEstimate = (long) Math.ceil(fullInputSize); resourceProfile_ = new ResourceProfile(perInstanceMemEstimate, 0); } }
private Expr simplifyCompoundPredicate(CompoundPredicate expr) { Expr leftChild = expr.getChild(0); if (!(leftChild instanceof BoolLiteral)) return expr; if (expr.getOp() == CompoundPredicate.Operator.AND) { if (((BoolLiteral) leftChild).getValue()) { return expr.getChild(1); } else { return leftChild; } } else { if (((BoolLiteral) leftChild).getValue()) { return leftChild; } else { return expr.getChild(1); } } }
private boolean isBroadcastExchange() { Preconditions.checkState(!children_.isEmpty()); DataSink sink = getChild(0).getFragment().getSink(); if (sink == null) return false; Preconditions.checkState(sink instanceof DataStreamSink); DataStreamSink streamSink = (DataStreamSink) sink; return !streamSink.getOutputPartition().isPartitioned() && fragment_.isPartitioned(); }
byte[] partitionStats, boolean hasIncrementalStats) { table_ = Preconditions.checkNotNull(table); spec_ = Preconditions.checkNotNull(spec); msPartition_ = Preconditions.checkNotNull(msPartition); fileDescriptors_ = fileDescriptors; partitionStats_ = partitionStats; hasIncrementalStats_ = hasIncrementalStats; Preconditions.checkState(msPartition_.getSd().getCols() == null); }
private class RewriteConditionalFnsRule implements ExprRewriteRule { public static final RewriteConditionalFnsRule INSTANCE = new RewriteConditionalFnsRule(); private RewriteConditionalFnsRule() { } @Override public Expr apply(Expr expr, Analyzer analyzer) throws AnalysisException { if (!expr.isAnalyzed()) { return expr; } if (expr instanceof FunctionCallExpr) { FunctionCallExpr functionCallExpr = (FunctionCallExpr) expr; String functionName = functionCallExpr.getFnName().getFunction(); List<Expr> children = functionCallExpr.getChildren(); if (functionName.equalsIgnoreCase("nullif")) { return rewriteNullIfFunction(children, analyzer); } else if (functionName.equalsIgnoreCase("nvl")) { return rewriteNvlFunction(children, analyzer); } } return expr; } private Expr rewriteNullIfFunction(List<Expr> children, Analyzer analyzer) throws AnalysisException { if (children.size() != 2) { throw new AnalysisException("Invalid number of arguments for nullif function"); } Expr expr1 = children.get(0); Expr expr2 = children.get(1); CaseExpr caseExpr = new CaseExpr(); caseExpr.setCaseExpr(expr1); caseExpr.addWhenClause(new CaseWhenClause(expr1, new NullLiteral())); caseExpr.setElseExpr(expr1); return caseExpr; } private Expr rewriteNvlFunction(List<Expr> children, Analyzer analyzer) throws AnalysisException { if (children.size() != 2) { throw new AnalysisException("Invalid number of arguments for nvl function"); } Expr expr1 = children.get(0); Expr expr2 = children.get(1); CaseExpr caseExpr = new CaseExpr(); caseExpr.setCaseExpr(expr1); caseExpr.addWhenClause(new CaseWhenClause(new IsNullPredicate(expr1), expr2)); caseExpr.setElseExpr(expr1); return caseExpr; } }
Lists.newArrayList( new CaseWhenClause(expr.getChild(0), expr.getChild(1))), expr.getChild(2) ); // ELSE elseExpr END /** * Rewrites IFNULL(a, x), which is an alias * for ISNULL(a, x) and NVL(a, x). * * IFNULL(NULL, x) --> x * IFNULL(a, x) --> a, if a is a non-null literal * IFNULL(a, x) --> * CASE WHEN a IS NULL THEN x ELSE a END */ private Expr rewriteIfNullFn(FunctionCallExpr expr) { Preconditions.checkState(expr.getChildren().size() == 2); Expr child0 = expr.getChild(0); return new CaseExpr( null, // CASE Lists.newArrayList( new CaseWhenClause( new IsNullPredicate(child0, false), expr.getChild(1) ) ), // THEN x child0.clone() // ELSE a ); }
} /** * Test some basic simplifications that are assumed in the * subsequent tests. These uncovered subtle errors and are here * to prevent regressions. */ @Test public void sanityTest() throws ImpalaException { verifySelectRewrite("null + 1", "NULL"); verifySelectRewrite("null is null", "TRUE"); verifySelectRewrite("id + (2 + 3)", "id + 5"); verifySelectRewrite("1 + 2 + id", "3 + id"); // TODO: IMPALA-7766 // verifySelectRewrite("id + 1 + 2", "id + 3"); // TODO: IMPALA-7769 // verifySelectRewrite("cast(null as INT) IS NULL", "TRUE"); // verifySelectRewrite("(null + 1) is null", "TRUE"); // verifySelectRewrite("(1 + 1) is null", "FALSE"); // verifySelectRewrite("CASE WHEN null + 1 THEN 10 ELSE 20 END", "20"); } @Test public void testIf() throws ImpalaException { // Simplifications provided by CASE rewriting
// TODO: IMPALA-7766 // verifySelectRewrite("id + 1 + 2", "id + 3"); // TODO: IMPALA-7769 // verifySelectRewrite("cast(null as INT) IS NULL", "TRUE"); // verifySelectRewrite("(null + 1) is null", "TRUE"); // verifySelectRewrite("(1 + 1) is null", "FALSE"); // verifySelectRewrite("CASE WHEN null + 1 THEN 10 ELSE 20 END", "20"); @Test public void testIf() throws ImpalaException { // Simplifications provided by CASE rewriting verifySelectRewrite("if(true, id, id+1)", "id"); verifySelectRewrite("if(false, id, id+1)", "id + 1"); verifySelectRewrite("if(null, id, id+1)", "id + 1"); // Nothing to simplify verifySelectRewrite("if(id = 0, true, false)", "CASE WHEN id = 0 THEN TRUE ELSE FALSE END"); // Don't simplify if drops last aggregate verifySelectRewrite("if(true, 0, sum(id))", "if(true, 0, sum(id))"); }
SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; } public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr);
public Expr RewritesOk(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOk(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOk(String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rules, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName; ... }
public Expr RewritesOk(String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rules, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName; SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = origExpr; for (ExprRewriteRule rule : rules) { rewrittenExpr = rule.apply(rewrittenExpr, analyzer_); } String rewrittenExprStr = rewrittenExpr.toSql(); Assert.assertEquals(expectedExprStr, rewrittenExprStr); return rewrittenExpr; }
String stmtStr = "select " + exprStr + " from " + tableName; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException {
public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getWhereClause(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; }
public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getWhereClause(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; }
// specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { /** * Perform semantic analysis of node and all of its children. * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node and its descendants. * @param options controls the form of the SQL that is returned. * @see ToSqlOptions */ String toSql(ToSqlOptions options); /** * Returns the SQL string corresponding to this node and its descendants. * This should return the same result as calling toSql(ToSqlOptions.DEFAULT). */ String toSql(); }
package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { void analyze(Analyzer analyzer) throws AnalysisException; String toSql(ToSqlOptions options); String toSql(); }
@Override default LSMComponentType getType() { return LSMComponentType.DISK; } @Override DiskComponentMetadata getMetadata(); long getComponentSize(); int getFileReferenceCount(); void destroy() throws HyracksDataException; default ILSMDiskComponentID getComponentID() throws HyracksDataException; public void acronym(String text, String definition) { assertOpenBlock(); characters(text); characters("("); characters(definition); characters(")"); } for (String line : lines) { int c = line.indexOf(": "); if (c < 0) { rec = new SubmitRecord(); submitRecords.add(rec); int s = line.indexOf(' '); String statusStr = s >= 0 ? line.substring(0, s) : line; Optional<SubmitRecord.Status> status = Enums.getIfPresent(SubmitRecord.Status.class, statusStr); checkFooter(status.isPresent(), FOOTER_SUBMITTED_WITH, line); rec.status = status.get(); if (s >= 0) { rec.errorMessage = line.substring(s); } } else { for (Change change : ReviewDbUtil.unwrapDb(db).changes().all()) { ChangeNotes notes = createFromChangeOnlyWhenNoteDbDisabled(change); if (predicate.apply(notes)) { m.put(change.getProject(), notes); } rec.labels.add(label); Optional<SubmitRecord.Label.Status> status = Enums.getIfPresent(SubmitRecord.Label.Status.class, line.substring(0, c)); checkFooter(status.isPresent(), FOOTER_SUBMITTED_WITH, line); } } } void analyze(Analyzer analyzer) throws AnalysisException; String toSql(ToSqlOptions options); default String toSql() { return toSql(ToSqlOptions.DEFAULT); }
package org.apache.impala.analysis; public enum ToSqlOptions { DEFAULT(false, false), REWRITTEN(true, false), SHOW_IMPLICIT_CASTS(true, true); private boolean rewritten_; private ToSqlOptions(boolean rewritten) { this.rewritten_ = rewritten; } public boolean isRewritten() { return rewritten_; } }
public static String wrapString(String s, int wrapLength) { StringBuilder ret = new StringBuilder(s.length() + 32); String[] split = s.split("\n"); for (int i = 0; i < split.length; i++) { String line = split[i]; String wrappedLine = WordUtils.wrap(line, wrapLength, null, true); ret.append(wrappedLine); if (i < split.length - 1) ret.append("\n"); } return ret.toString(); }
public static String wrapString(String s, int wrapLength) { StringBuilder ret = new StringBuilder(s.length() + 32); String[] split = s.split("\n"); for (int i = 0; i < split.length; i++) { String line = split[i]; String wrappedLine = WordUtils.wrap(line, wrapLength, null, true); ret.append(wrappedLine); if (i < split.length - 1) { ret.append("\n"); } } return ret.toString(); }
public void checkNumericLiteralCasts(AnalysisContext ctx, String columnName, String data, String castColumn) { String query = "insert into table functional.alltypesnopart (" + columnName + ") " + "values(" + data + ")"; String expectedToSql = "INSERT INTO TABLE " + "functional.alltypesnopart(" + columnName + ") " + "SELECT CAST(" + data + " AS " + castColumn + ")"; }
private void assertToSqlWithImplicitCasts(AnalysisContext ctx, String query, String expectedToSqlWithImplicitCasts) { StatementBase stmt = (StatementBase) AnalyzesOk(query, ctx); String actual = stmt.toSql(SHOW_IMPLICIT_CASTS); Assert.assertEquals("Bad sql with implicit casts from original query:\n" + query, expectedToSqlWithImplicitCasts, actual); }
import org.apache.hyracks.algebricks.core.algebra.operators.logical.IndexInsertDeleteUpsertOperator; import org.apache.hyracks.algebricks.core.algebra.operators.logical.InsertDeleteUpsertOperator; import org.apache.hyracks.algebricks.core.algebra.operators.logical.InsertDeleteUpsertOperator.Kind; import org.apache.hyracks.algebricks.core.algebra.operators.logical.SinkOperator; import org.apache.hyracks.algebricks.core.rewriter.base.IAlgebraicRewriteRule; public class ReplaceSinkOpWithCommitOpRule implements IAlgebraicRewriteRule { @Override public boolean rewritePre(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException { return false; } @Override public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException { AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue(); if (op.getOperatorTag() != LogicalOperatorTag.SINK) { return false; } SinkOperator sinkOperator = (SinkOperator) op; List<Mutable<ILogicalExpression>> primaryKeyExprs = null; int datasetId = 0; AbstractLogicalOperator descendantOp = (AbstractLogicalOperator) sinkOperator.getInputs().get(0).getValue(); LogicalVariable upsertVar = null; // TODO Auto-generated method stub return false; } }
public String toString() { return "ProGuard File"; } public Commons.Protocol protocol; @ZoomField(name = "description") public String description; @JsonProperty("admin_state_up") @ZoomField(name = "admin_state_up") public Boolean adminStateUp; @JsonProperty("default_tls_container_ref") @ZoomField(name = "default_tls_container_ref") public String defaultTlsContainerRef; @JsonProperty("sni_container_refs") @ZoomField(name = "sni_container_refs") public List<String> sniContainerRefs; @ZoomField(name = "loadbalancers") public List<UUID> loadBalancers; @JsonProperty("default_pool_id") @ZoomField(name = "default_pool_id") public UUID defaultPoolId; @ZoomField(name = "name") public String name; @Override public String toString() { return MoreObjects.toStringHelper(this) .omitNullValues() .add("id", id) .add("tenantId", tenantId) .add("projectId", projectId) .add("name", name) .add("description", description) .add("connectionLimit", connectionLimit) .add("defaultTlsContainerRef", defaultTlsContainerRef) .toString(); } // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.fixes; import static com.google.common.base.Preconditions.checkNotNull; /** * A modifier of a string. It allows to replace multiple parts of a string by indicating those parts * with indices based on the unmodified string. There is one limitation though: Replacements which * affect lower indices of the string must be specified before replacements for higher indices. */ class StringModifier { private final StringBuilder stringBuilder; private int characterShift = 0; private int previousEndOffset = Integer.MIN_VALUE; StringModifier(String string) { checkNotNull(string, "string must not be null"); stringBuilder = new StringBuilder(string); } /** * Replaces part of the string with another content. When called multiple times, the calls must be * in ascending order of the start offset. * * @param startOffset the start offset of the part to replace * @param endOffset the end offset of the part to
// Negative values always get bytes as unit. // TODO: fix this behaviour if needed. assertEquals("-10B", PrintUtils.printBytesRoundedToMb(-10L)); assertEquals("-123456789B", PrintUtils.printBytesRoundedToMb(-123456789L)); /** * wrap length for testWrapText() - less than 80 to make test layout nicer */ private static final int WRAP_LENGTH = 60; /** * Test for PrintUtils.wrapString(). */ @Test public void testWrapText() { // Simple query wrapping. assertWrap( "Analyzed query: SELECT * FROM functional_kudu.alltypestiny WHERE CAST(bigint_col" + " AS DOUBLE) < CAST(10 AS DOUBLE)", "Analyzed query: SELECT * FROM functional_kudu.alltypestiny\n" + "WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)" ); // Simple query with a hint retains newlines surrounding hint. assertWrap( "SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n", "SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n" ); }
assertWrap("insert into foo values (' " + " " + " ')", "insert into foo values (' \n" + "')"); // test that long words are broken up for clarity assertWrap("select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx", "select\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxx"); private void assertWrap(String input, String expected) { String actual = PrintUtils.wrapString(input, WRAP_LENGTH); assertEquals(expected, actual); assertNoBlankLines(actual); assertNoTerminatingNewline(actual); assertNoLongLines(actual); } private void assertNoLongLines(String s) { for (String line : s.split("\n")) { assertTrue(line.length() <= 80); } }
public static void openDrawer(int drawerLayoutId, int gravity) { onView(withId(drawerLayoutId)).perform(open(gravity)); } + " " + " ')", "insert into foo values (' \n" + "')"); // test that long words are broken up for clarity assertWrap("select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx", "select\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxx"); private void assertWrap(String input, String expected) { String actual = PrintUtils.wrapString(input, WRAP_LENGTH); assertEquals(expected, actual); assertNoBlankLines(actual); assertNoTerminatingNewline(actual); assertNoLongLines(actual); } private void assertNoLongLines(String s) { for (String line : s.split("\n")) { if (line.length() > MAX_LINE_LENGTH) { fail("Line exceeds maximum length: " + line); } } }
import java.util.List; import org.apache.impala.analysis.Analyzer; import org.apache.impala.analysis.CaseExpr; import org.apache.impala.analysis.CaseWhenClause; import org.apache.impala.analysis.Expr; import org.apache.impala.analysis.FunctionCallExpr; import org.apache.impala.analysis.IsNullPredicate; import org.apache.impala.analysis.NullLiteral; import org.apache.impala.common.AnalysisException; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** * Rewrites conditional functions to use a CASE statement. * The conditional functions vanish from the plan after this rewrite: there is no back-end implementation for these functions. * * coalesce(v1, v2, ...) * if(condition, ifTrue, ifFalseOrNull) * ifnull(a, ifNull) * isnull(a, ifNull) * nullif(expr1, expr2) * nvl(a, ifNull) * * Since every function is rewritten to a CASE statement, the planner runs the rule to simplify CASE after this rule. * Where that other rule can perform simplifications, those simplifications are omitted here. However, the CASE */ public class ConditionalFunctionRewriter { public void rewriteConditionalFunctions(Analyzer analyzer, Expr expr) throws AnalysisException { Preconditions.checkNotNull(analyzer); Preconditions.checkNotNull(expr); List<Expr> children = expr.getChildren(); List<Expr> newChildren = Lists.newArrayList(); for (Expr child : children) { if (child instanceof FunctionCallExpr) { FunctionCallExpr functionCall = (FunctionCallExpr) child; String functionName = functionCall.getFnName().getFunction(); switch (functionName) { case "coalesce": rewriteCoalesceFunction(analyzer, functionCall, newChildren); break; case "if": rewriteIfFunction(analyzer, functionCall, newChildren); break; case "ifnull": case "isnull": case "nvl": rewriteNullFunction(analyzer, functionCall, newChildren); break; case "nullif": rewriteNullIfFunction(analyzer, functionCall, newChildren); break; default: newChildren.add(child); break; } } else { newChildren.add(child); } } expr.setChildren(newChildren); } private void rewriteCoalesceFunction(Analyzer analyzer, FunctionCallExpr
switch (expr.getFnName().getFunction()) { case "if": return rewriteIfFn(expr); case "coalesce": return rewriteCoalesceFn(expr); case "isnull": case "nvl": case "ifnull": return rewriteIfNullFn(expr); default: return expr; } private Expr rewriteIfFn(FunctionCallExpr expr) { Preconditions.checkState(expr.getChildren().size() == 3); return new CaseExpr( null, Lists.newArrayList( new CaseWhenClause(expr.getChild(0), expr.getChild(1)) ), expr.getChild(2) ); }
private Expr rewriteCoalesceFn(FunctionCallExpr expr) { List<Expr> revised = new ArrayList<>(); for (Expr childExpr : expr.getChildren()) { if (childExpr.isNullLiteral()) { continue; } revised.add(childExpr); } return new CaseExpr(revised); }
// Negative values always get bytes as unit. // TODO: fix this behaviour if needed. assertEquals("-10B", PrintUtils.printBytesRoundedToMb(-10L)); assertEquals("-123456789B", PrintUtils.printBytesRoundedToMb(-123456789L)); } /** * Wrap length for testWrapText() - less than 80 to make test layout nicer. */ private static final int WRAP_LENGTH = 60; /** * Test for PrintUtils.wrapString(). */ @Test public void testWrapText() { // Simple query wrapping. assertWrap( "Analyzed query: SELECT * FROM functional_kudu.alltypestiny WHERE CAST(bigint_col" + " AS DOUBLE) < CAST(10 AS DOUBLE)", "Analyzed query: SELECT * FROM functional_kudu.alltypestiny\n" + "WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)" ); // Simple query with a hint retains newlines surrounding hint. assertWrap( "SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n" + "tpch_parquet.lineitem ON orders.orderkey = lineitem.orderkey", "SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n" + "tpch_parquet.lineitem ON orders.orderkey = lineitem.orderkey" ); }
"Expr '%s' in select list returns a complex type '%s'.\n" + "Only scalar types are allowed in the select list.", expr.toSql(), expr.getType().toSql())); if (!expr.getType().isSupported() || expr.getType().isInvalid()) { throw new AnalysisException("Unsupported type '" + expr.getType().toSql() + "' in '" + expr.toSql() + "'."); } } if (TreeNode.contains(resultExprs_, AnalyticExpr.class)) { if (fromClause_.isEmpty()) { throw new AnalysisException("Analytic expressions require FROM clause."); } // do this here, not after analyzeAggregation(), otherwise the AnalyticExprs // will get substituted away if (selectList_.isDistinct()) { throw new AnalysisException("cannot combine SELECT DISTINCT with analytic functions"); } } if (whereClause_ != null) { whereClause_.analyze(analyzer); if (whereClause_.contains(Expr.isAggregatePredicate())) {
public static ExprRewriteRule INSTANCE = new FoldConstantsRule(); @Override public Expr apply(Expr expr, Analyzer analyzer) throws AnalysisException { for (Expr child : expr.getChildren()) { if (!child.isLiteral()) { return expr; } } if (expr.isLiteral() || !expr.isConstant()) { return expr; } if (expr instanceof CastExpr) { CastExpr castExpr = (CastExpr) expr; if (castExpr.getChild(0) instanceof NullLiteral) { return expr; } } if (!expr.isAnalyzed()) { expr.analyze(analyzer); } return expr; }
public static String getPartitionKeyValueString(LiteralExpr literalValue, String nullPartitionKeyValue) { Preconditions.checkNotNull(literalValue); if (Expr.IS_NULL_LITERAL.apply(literalValue) || literalValue.getStringValue().isEmpty()) { return nullPartitionKeyValue; } return literalValue.getStringValue(); }
public void testUpdateCatalog() { withAllPrincipalTypes(ctx -> { String principalName = String.format("%s_update", PRINCIPAL_NAME_PREFIX); addCatalogPrincipalPrivileges(ctx.type_, ctx.catalog_, principalName, "functional"); addSentryPrincipalPrivileges(ctx.type_, ctx.sentryService_, principalName, "functional", "functional_kudu"); SentryProxy.refreshSentryAuthorization(ctx.catalog_, ctx.sentryService_, USER, false); checkCatalogPrincipalPrivileges(ctx.type_, ctx.catalog_, principalName, "server=server1->db=functional->grantoption=false", "server=server1->db=functional_kudu->grantoption=false"); }); }
switch (catalogObject.getType()) { case DATABASE: return "DATABASE:" + catalogObject.getDb().getDb_name().toLowerCase(); case TABLE: case VIEW: TTable tbl = catalogObject.getTable(); return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; case ROLE: return "ROLE:" + catalogObject.getRole().getRole_name().toLowerCase(); case PRIVILEGE: return "PRIVILEGE:" + catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default: String principalName = catalogObject.getPrincipal().getPrincipal_name(); if (catalogObject.getPrincipal().getPrincipal_type() == TPrincipalType.ROLE) { principalName = principalName.toLowerCase(); } return "PRINCIPAL:" + principalName; }
return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; case ROLE: return "ROLE:" + catalogObject.getRole().getRole_name().toLowerCase(); case PRIVILEGE: return "PRIVILEGE:" + catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default: throw new IllegalStateException("Unsupported catalog object type: " + catalogObject.getType());
for (SlotDescriptor d: slotsBySize.get(slotSize)) { Preconditions.checkState(d.isMaterialized()); d.setByteSize(slotSize); d.setByteOffset(slotOffset); d.setSlotIdx(slotIdx++); slotOffset += slotSize; // assign null indicator if (d.getIsNullable()) { d.setNullIndicatorByte(nullIndicatorByte); d.setNullIndicatorBit(nullIndicatorBit); nullIndicatorBit = (nullIndicatorBit + 1) % 8; if (nullIndicatorBit == 0) { ++nullIndicatorByte; } } else { // non-nullable slots will have 0 for the byte offset and -1 for the bit mask d.setNullIndicatorBit(-1); d.setNullIndicatorByte(0); } } Preconditions.checkState(slotOffset == totalSlotSize); byteSize_ = totalSlotSize + numNullBytes_;
// specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { void analyze(Analyzer analyzer) throws AnalysisException; String toSql(ToSqlOptions options); }
public List<NodeType> getChildren() { return children_; } public <C extends TreeNode<NodeType>> List<C> getNodesPreOrder() { List<TreeNode<NodeType>> result = new ArrayList<>(); getNodesPreOrderAux(result); return (List<C>) result; } protected void getNodesPreOrderAux(List<TreeNode<NodeType>> result) { result.add(this); for (NodeType child : children_) { child.getNodesPreOrderAux(result); } } public List<TreeNode<NodeType>> getNodesPostOrder() { List<TreeNode<NodeType>> result = new ArrayList<>(); getNodesPostOrderAux(result); return result; } protected void getNodesPostOrderAux(List<TreeNode<NodeType>> result) { for (NodeType child : children_) { child.getNodesPostOrderAux(result); } result.add(this); }
} for (NodeType child: children_) child.collect(predicate, matches); } /** * Add all nodes in the tree that are of class 'cl' to the list 'matches'. * This node is checked first, followed by its children in order. If the node * itself is of class 'cl', the children are skipped. */ @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>, D extends C> void collect(Class<?> cl, Collection<D> matches) { if (cl.equals(getClass())) { matches.add((D) this); return; } for (NodeType child: children_) child.collect(cl, matches); } /** * Add all nodes in the tree that satisfy 'predicate' to the list 'matches' * This node is checked first, followed by its children in order. All nodes * that match in the subtree are added. */ @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>, D extends C> void collectAll(
public static <C extends TreeNode<C>, D extends C> void collect(Collection<C> nodeList, Predicate<? super C> predicate, Collection<D> matches) { for (C node : nodeList) { node.collect(predicate, matches); } } public static <C extends TreeNode<C>, D extends C> void collect(Collection<C> nodeList, Class<C> cl, Collection<D> matches) { for (C node : nodeList) { node.collect(cl, matches); } } @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>> boolean contains(Predicate<? super C> predicate) { if (predicate.apply((C) this)) { return true; } for (NodeType child : children_) { if (child.contains(predicate)) { return true; } } return false; }
public boolean contains(Class<?> cl) { if (cl.equals(getClass())) return true; for (NodeType child : children_) { if (child.contains(cl)) return true; } return false; }
public static <C extends TreeNode<C>> boolean contains(List<C> nodeList, Class<C> cl) { for (C node : nodeList) { if (node.contains(cl)) { return true; } } return false; }
import org.apache.parquet.schema.Type; import org.apache.parquet.schema.GroupType; import org.apache.parquet.schema.LogicalTypeAnnotation; import org.apache.parquet.schema.ListLogicalTypeAnnotation; import org.apache.parquet.schema.MapLogicalTypeAnnotation; import org.apache.parquet.schema.MapKeyValueTypeAnnotation; import org.apache.parquet.schema.PrimitiveType; import org.apache.parquet.schema.Type.Repetition; import org.apache.parquet.schema.Types; import java.util.ArrayList; import java.util.List; public class ParquetTypeConverter { public static Type convertParquetType(org.apache.parquet.schema.Type parquetType) throws AnalysisException { if (parquetType.isPrimitive()) { return convertPrimitive(parquetType.asPrimitiveType()); } else if (parquetType.isGroup()) { return convertGroup(parquetType.asGroupType()); } else { throw new AnalysisException("Unsupported Parquet type: " + parquetType); } } private static Type convertPrimitive(PrimitiveType primitiveType) { return Types.optional(primitiveType.getPrimitiveTypeName()); } private static Type convertGroup(GroupType groupType) throws AnalysisException { List<Type> fields = new ArrayList<>(); for (org.apache.parquet.schema.Type fieldType : groupType.getFields()) { fields.add(convertParquetType(fieldType)); } return Types.buildGroup(Repetition.OPTIONAL).addFields(fields); } private static Type convertArray(GroupType innerGroup) throws AnalysisException { return Types.optionalList().element(convertParquetType(innerGroup.getType(0))); } private static Type convertLogicalParquetType(org.apache.parquet.schema.Type parquetType) throws AnalysisException { LogicalTypeAnnotation logicalType = parquetType.getLogicalTypeAnnotation(); if (logicalType instanceof ListLogicalTypeAnnotation) { return convertArray(parquetType.asGroupType()); } if (logicalType instanceof MapLogicalTypeAnnotation || logicalType instanceof MapKeyValueTypeAnnotation) { throw new AnalysisException("Unsupported Parquet logical type: " + logicalType); } return convertParquetType(parquetType); } }
import org.apache.thrift.TDataSink; import org.apache.thrift.TDataSinkType; import org.apache.thrift.TExecStats; protected final TDataSink toThrift() { TDataSink tsink = new TDataSink(getSinkType()); tsink.setLabel(fragment_.getId() + ":" + getLabel()); TExecStats estimatedStats = new TExecStats(); estimatedStats.setMemory_used(resourceProfile_.getMemEstimateBytes()); tsink.setEstimated_stats(estimatedStats); toThriftInternal(tsink); return tsink; } abstract protected void toThriftInternal(TDataSink tsink); abstract protected TDataSinkType getSinkType(); public void setFragment(PlanFragment fragment) { fragment_ = fragment; } public PlanFragment getFragment() { return fragment_; } public ResourceProfile getResourceProfile() { return resourceProfile_; } public abstract void computeResourceProfile(TQueryOptions queryOptions);
public void testScalarFunctionSql() { // Can't generate SQL for an unresolved function List<Type> args = new ArrayList<>(); Function fn = Function.createFunction("mydb", "fn1", args, Type.INT, false, TFunctionBinaryType.JAVA); try { ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); } catch (UnsupportedOperationException e) { // Expected } // Java function, leave off location and symbol List<Type> args = new ArrayList<>(); Function fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); // Java function, with location and symbol List<Type> args = new ArrayList<>(); Function fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation("/path/to/function"); fn.setSymbol("symbol"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1 LOCATION '/path/to/function' SYMBOL 'symbol'\n"; assertEquals(expected, sql); }
Function fn = Function.createFunction("mydb", "fn1", args, Type.INT, false, TFunctionBinaryType.JAVA); try { ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); } catch (UnsupportedOperationException e) { // Expected } { // Java function, leave off location and symbol List<Type> args = new ArrayList<>(); Function fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = new ArrayList<>(); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); }
fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn.setSymbolName("MyClass"); sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN);
String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn.setSymbolName("MyClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql);
String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); List<Type> args = new ArrayList<>(); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setSymbolName("myClass"); sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); expected = "CREATE FUNCTION mydb.fn1()\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql);
String expected = "CREATE FUNCTION mydb.fn1()\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql); { // C++ function, with location and symbol List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1(VARCHAR(*), BOOLEAN)\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql); }
public void testAggFnSql() { List<Type> args = Lists.newArrayList(Type.INT, Type.BOOLEAN); AggregateFunction fn = new AggregateFunction(new FunctionName("mydb", "fn1"), args, Type.BIGINT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setUpdateFnSymbol("Update"); fn.setInitFnSymbol("Init"); fn.setMergeFnSymbol("Merge"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE AGGREGATE FUNCTION mydb.fn1(INT, BOOLEAN)\n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " UPDATE_FN='Update'\n" + " INIT_FN='Init'\n" + " MERGE_FN='Merge'\n"; assertEquals(expected, sql); }
String sql = "CREATE AGGREGATE FUNCTION mydb.fn1(INT, BOOLEAN)\n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " UPDATE_FN='Update'\n" + " INIT_FN='Init'\n" + " MERGE_FN='Merge'\n"; assertEquals(expected, sql); List<Type> args = Lists.newArrayList(Type.INT, Type.BOOLEAN); AggregateFunction fn = new AggregateFunction(new FunctionName("mydb", "fn1"), args, Type.BIGINT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setUpdateFnSymbol("Update"); fn.setInitFnSymbol("Init"); fn.setMergeFnSymbol("Merge"); fn.setFinalizeFnSymbol("Finalize"); fn.setSerializeFnSymbol("Serialize"); fn.setIntermediateType(Type.INT); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE AGGREGATE FUNCTION mydb.fn1(INT, BOOLEAN)\n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " UPDATE_FN='Update'\n" + " INIT_FN='Init'\n" + " MERGE_FN='Merge'\n";
public void testCreateFunctionSql() { ScalarFunction fn1 = new ScalarFunction(new FunctionName("mydb", "fn1"), new ArrayList<>(), Type.INT, false); fn1.setBinaryType(TFunctionBinaryType.JAVA); fn1.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn1.setSymbolName("MyClass"); List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn2 = new ScalarFunction(new FunctionName("mydb", "fn2"), args, Type.INT, false); fn2.setBinaryType(TFunctionBinaryType.NATIVE); fn2.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn2.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn1, fn2)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass';\n" + "CREATE FUNCTION mydb.fn2\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass';\n"; assertEquals(expected, sql); }
ScalarFunction fn1 = new ScalarFunction(new FunctionName("mydb", "fn1"), new ArrayList<>(), Type.INT, false); fn1.setBinaryType(TFunctionBinaryType.JAVA); fn1.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn1.setSymbolName("MyClass"); List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn2 = new ScalarFunction(new FunctionName("mydb", "fn2"), args, Type.INT, false); fn2.setBinaryType(TFunctionBinaryType.NATIVE); fn2.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn2.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn1, fn2)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass';\n" + "CREATE FUNCTION mydb.fn2(VARCHAR(*), BOOLEAN)\n" + " RETURNS INT\n" +
public RetryRule() { this(Integer.getInteger("rerunFailingTestsCount", 0)); }
protected static boolean compareBitmaps(Bitmap img1, Bitmap img2) { if (img1.getWidth() == img2.getWidth() && img1.getHeight() == img2.getHeight()) { int[] img1Pixels = new int[img1.getWidth() * img1.getHeight()]; int[] img2Pixels = new int[img2.getWidth() * img2.getHeight()]; img1.getPixels(img1Pixels, 0, img1.getWidth(), 0, 0, img1.getWidth(), img1.getHeight()); img2.getPixels(img2Pixels, 0, img2.getWidth(), 0, 0, img2.getWidth(), img2.getHeight()); return Arrays.equals(img1Pixels, img2Pixels); } return false; } @Override public void describeTo(Description description) { description.appendText("has background with drawable ID: " + drawableId); } static boolean compareBitmaps(Bitmap img1, Bitmap img2) { if (img1.getWidth() == img2.getWidth() && img1.getHeight() == img2.getHeight()) { int[] img1Pixels = new int[img1.getWidth() * img1.getHeight()]; int[] img2Pixels = new int[img2.getWidth() * img2.getHeight()]; img1.getPixels(img1Pixels, 0, img1.getWidth(), 0, 0, img1.getWidth(), img1.getHeight()); img2.getPixels(img2Pixels, 0, img2.getWidth(), 0, 0, img2.getWidth(), img2.getHeight()); return Arrays.equals(img1Pixels, img2Pixels); } return false; } // Even though constructors are invoked using a "special" invoke, handles to them can't // be created using findSpecial. Callers must use findConstructor instead. if ("<init>".equals(name)) { throw new NoSuchMethodException("<init> is constructor."); } Method method = refc.getDeclaredMethod(name, type.ptypes()); return findSpecial(method, type, refc, specialCaller); } private MethodHandle findSpecial(Method method, MethodType type, Class<?> refc, Class<?> specialCaller) throws IllegalAccessException { if (Modifier.isPrivate(method.getModifiers())) { // Since this is a private method, we'll need to also make sure that the // lookup class is the same as the refering class. We've already checked that // the specialCaller is the
return new RetryStatement(base, description, retryCount); } private static class RetryStatement extends Statement { private final Statement base; private final Description description; private final int retryCount; RetryStatement(Statement base, Description description, int retryCount) { this.base = base; this.description = description; this.retryCount = retryCount; } @Override public void evaluate() throws Throwable { Throwable lastException; int attempt = 0; do { attempt++; try { base.evaluate(); return; } catch (Throwable t) { // To retry, we catch the exception from evaluate(), log an error, and loop. // We retain and rethrow the last failure if all attempts fail. lastException = t; LOG.error("{}: failed attempt {}", description.getDisplayName(), attempt, t); } } while (attempt <= retryCount); LOG.error("{}: giving up after {} attempts", description.getDisplayName(), attempt); throw lastException; } } }
public void testRetry() { if (failures < MAX_FAILURES) { failures++; assertFalse(String.format("%d failures", failures), true); } // Fall through and pass the test on the final retry. }
package com.couchbase.client.core.env; public enum NetworkResolution { DEFAULT, BLANK, EXTERNAL }
OpenBucketRequest request; if (ClusterDependentTest.minClusterVersion()[0] >= 5) { request = new OpenBucketRequest(TestProperties.bucket(), TestProperties.adminUser(), TestProperties.adminPassword()); } else { request = new OpenBucketRequest(TestProperties.bucket(), TestProperties.username(), TestProperties.password()); } core.send(request).toBlocking().single(); BackpressureException exception = RingBufferMonitor.instance().createException(); assertEquals(0, exception.diagostics().totalCount()); core.send(new CloseBucketRequest(TestProperties.bucket())).toBlocking().single(); }
/** * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.core; import com.couchbase.client.core.tracing.RingBufferDiagnostics; /** * Identifies the need to back off on the supplier side when using a service, because the consumer is overloaded. * * @author Michael Nitschinger * @since 1.0 */ public class BackpressureException extends CouchbaseException { public BackpressureException() {} public BackpressureException(RingBufferDiagnostics diagnostics) { this.diagnostics = diagnostics; } /** * Returns a {@link RingBufferDiagnostics} which, if non-null, gives a granular breakdown of the contents of the * ringbuffer at the time of this exception */ public RingBufferDiagnostics getRingBufferDiagnostics() { return diagnostics; } @Override public String toString() { return "BackpressureException{" + "diagnostics=" + diagnostics + '}'; } private RingBufferDiagnostics diagnostics; }
public RingBufferDiagnostics ringBufferDiagnostics() { return diagnostics; }
RingBufferMonitor ringBufferMonitor = RingBufferMonitor.getInstance(); ringBufferMonitor.addRequest(request); if (coreSendHook == null) { boolean published = requestRingBuffer.tryPublishEvent(REQUEST_TRANSLATOR, request); if (!published) { request.observable().onError(ringBufferMonitor.createException()); } return (Observable<R>) request.observable(); } else { Subject<CouchbaseResponse, CouchbaseResponse> response = request.observable(); Tuple2<CouchbaseRequest, Observable<CouchbaseResponse>> hook = coreSendHook.beforeSend(request, response); boolean published = requestRingBuffer.tryPublishEvent(REQUEST_TRANSLATOR, hook.value1()); if (!published) { request.observable().onError(ringBufferMonitor.createException()); } return (Observable<R>) request.observable(); }
public class RingBufferMonitor { private static RingBufferMonitor instance; static { instance = new RingBufferMonitor(); } private RingBufferMonitor() { // private constructor to prevent instantiation } public static RingBufferMonitor getInstance() { return instance; } }
private AtomicInteger getOrAddCount(CouchbaseRequest request) { if (request instanceof AbstractKeyValueRequest) { return countKeyValue; } else if (request instanceof GenericQueryRequest) { return countQuery; } else if (request instanceof ClusterRequest) { return countCluster; } else if (request instanceof ConfigRequest) { return countConfig; } else if (request instanceof InternalRequest) { return countInternal; } else if (request instanceof BinaryRequest) { return countKeyValue; // renamed to countKeyValue } else if (request instanceof SearchRequest) { return countSearch; } else if (request instanceof ViewRequest) { return countView; } else if (request instanceof AnalyticsRequest) { return countAnalytics; } else { return countOther; } }
private EncryptionConfig encryptionConfig; public static final String ENCRYPTION_PREFIX = "__encrypt_"; private JsonObject() { content = new HashMap<String, Object>(); } private JsonObject(int initialCapacity) { content = new HashMap<String, Object>(initialCapacity); } public static JsonObject empty() { return new JsonObject(); }
sb.append(", viewTimeout=").append(this.viewTimeout); sb.append(", searchTimeout=").append(this.searchTimeout); sb.append(", analyticsTimeout=").append(this.analyticsTimeout); sb.append(", kvTimeout=").append(this.kvTimeout); sb.append(", connectTimeout=").append(this.connectTimeout); sb.append(", dnsSrvEnabled=").append(this.dnsSrvEnabled); if (this.cryptoManager() != null) { sb.append(", cryptoManager=").append(this.cryptoManager.toString()); } return sb;
public class JsonObject extends JsonValue implements Serializable { private static final long serialVersionUID = 8817717605659870262L; private final Map<String, Object> content; private volatile Map<String, String> encryptionPathInfo; private EncryptionConfig encryptionConfig; public static final String ENCRYPTION_PREFIX = "__encrypt_"; private JsonObject() { content = new HashMap<String, Object>(); encryptionPathInfo = new HashMap<String, String>(); } }
public class JsonObject extends JsonValue implements Serializable { private static final long serialVersionUID = 8817717605659870262L; private final Map<String, Object> content; private final Map<String, String> encryptionPathInfo; private EncryptionConfig encryptionConfig; public static final String ENCRYPTION_PREFIX = "__encrypt_"; private JsonObject() { content = new HashMap<String, Object>(); encryptionPathInfo = new HashMap<String, String>(); } private JsonObject(int initialCapacity) { content = new HashMap<String, Object>(initialCapacity); encryptionPathInfo = new HashMap<String, String>(); } }
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.pbb.rev161214.PbbRewriteStateInterfaceAugmentationBuilder; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.pbb.rev161214.interfaces.state._interface.PbbRewriteState; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public final class InterfacesStateReaderFactory implements ReaderFactory { private final NamingContext ifcNamingCtx; private final NamingContext bdNamingCtx; private final DisabledInterfacesManager ifcDisableContext; private final FutureJVppCore jvpp; static final InstanceIdentifier<InterfacesState> IFC_STATE_ID = InstanceIdentifier.create(InterfacesState.class); static final InstanceIdentifier<Interface> IFC_ID = IFC_STATE_ID.child(Interface.class); static final InstanceIdentifier<Interface> IFC_ID_CREATE = InstanceIdentifier.create(Interface.class); @Inject public InterfacesStateReaderFactory(final FutureJVppCore jvpp, @Named("interface-context") final NamingContext ifcNamingCtx, @Named("bridge-domain-context") final NamingContext bdNamingCtx, final DisabledInterfacesManager ifcDisableContext, final InterfaceCacheDumpManager ifaceDumpManager) { this.jvpp = jvpp; this.ifcNamingCtx = ifcNamingCtx; this.bdNamingCtx = bdNamingCtx; this.ifcDisableContext = ifcDisableContext; this.ifaceDumpManager = ifaceDumpManager; } private void computeColumnSet(List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> gbyList) { columnSet.clear(); for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gbyList) { ILogicalExpression expr = p.second.getValue(); if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) { VariableReferenceExpression v = (VariableReferenceExpression) expr; columnSet.add(v.getVariableReference()); } } } private List<LogicalVariable> getGbyColumns() { return columnSet; } /** * Decrypt value if the name starts with "__encrypt_" */ private Object decrypt(JsonObject object, String providerName) throws Exception { Object decrypted; String key = object.getString("kid"); String alg = object.getString("alg"); CryptoProvider provider = this.cryptoManager.getProvider(providerName);
+ object.getString("ciphertext"); encryptedBytes = Base64.decode(object.getString("ciphertext")); if (object.containsKey("sig")) { byte[] signature = Base64.decode(object.getString("sig")); if (!provider.verifySignature(encryptedValueWithConfig.getBytes(), signature)) { throw new CryptoProviderSigningFailedException("The decryption of the field failed for the alias: " + providerName + " (Signature check for data integrity failed)"); } } byte[] decryptedBytes = provider.decrypt(encryptedBytes); String decryptedString = new String(decryptedBytes, Charset.forName("UTF-8")); decrypted = JacksonTransformers.MAPPER.readValue(decryptedString, Object.class); if (decrypted instanceof Map) { decrypted = JsonObject.from((Map<String, ?>) decrypted); } else if (decrypted instanceof List) { decrypted = JsonArray.from((List<?>) decrypted); } return decrypted; } /** * Retrieves the (potential null) content and not casting its type. * * @param name the key of the field. */
@Nonnull public static File createTempFile(@Nonnull String prefix) throws CannotCreateFileException, CannotChangePermissionException { return createTempFile(prefix, ""); } @Nonnull public static File createTempFile(@Nonnull String prefix, @Nonnull String suffix) throws CannotCreateFileException, CannotChangePermissionException { File baseDir = new File(System.getProperty("java.io.tmpdir")); return createTempFile(prefix, suffix, baseDir); } @Nonnull public static File createTempFile(@Nonnull String prefix, @Nonnull String suffix, @Nonnull Directory baseDir) throws CannotCreateFileException, CannotChangePermissionException { String baseName = prefix + System.currentTimeMillis() + "-"; Location location = null; for (int counter = 0; counter < TEMP_ATTEMPTS; counter++) { File tempFile = new File(baseDir, baseName + counter + suffix); location = new FileLocation(tempFile); try { AbstractStreamFile.create(tempFile, location); FileOrDirectory.unsetPermissions(tempFile, location, Permission.READ | Permission.WRITE | Permission.EXECUTE, ChangePermission.EVERYBODY); } catch (CannotCreateFileException | CannotChangePermissionException e) { throw e; } } return null; } SWTBotTreeItem resourceItem = treeItem[0]; assertEquals("There should be only one viewpoint node under group node", resourceItem.getItems().length); // Level2 SWTBotTreeItem groupItem = resourceItem.getItems()[0]; assertEquals("The level 2 node should be expanded with 6 sub items", 6, groupItem.getItems().length); // Level3 SWTBotTreeItem viewpointItem = groupItem.getItems()[0]; assertEquals(errorMessage(3, 7), 7, viewpointItem.getItems().length); SWTBotTreeItem viewpointItem2 = groupItem.getItems()[2]; assertEquals("The level 3 node should be expanded with 4 sub items", 4, viewpointItem2.getItems().length); // Level4 // We check without expanding the level 4 node that we have only one // sub node corresponding to the empty node. SWTBotTreeItem entitiesDiagramItem2 = viewpointItem2.getItems()[0]; assertEquals("The level 4 node should not be expanded. It should contains only the empty node.", 1, entitiesDiagramItem2.getItems().length); // Then we expand the level 4 nodes to
public Credentials(String username, String password) { this.username = username; this.password = password; }
package com.couchbase.client.dcp; import java.net.InetSocketAddress; public interface CredentialsProvider { Credentials get(InetSocketAddress address) throws RuntimeException; }
package com.couchbase.client.dcp; import java.net.InetSocketAddress; public class StaticCredentialsProvider implements CredentialsProvider { private final Credentials credentials; public StaticCredentialsProvider(String username, String password) { credentials = new Credentials(username, password); } @Override public Credentials get(InetSocketAddress address) throws RuntimeException { return credentials; } }
private SaslClient saslClient; private String selectedMechanism; AuthHandler(final InetSocketAddress address, final ClientEnvironment environment) { Credentials credentials = environment.credentialsProvider().get(address); this.username = credentials.getUsername(); this.password = credentials.getPassword(); } @Override public void channelActive(final ChannelHandlerContext ctx) throws Exception { ByteBuf request = ctx.alloc().buffer(); SaslListMechsRequest.init(request); ctx.writeAndFlush(request); } @Override protected void channelRead0(final ChannelHandlerContext ctx, final ByteBuf msg) throws Exception { // handle message according to the req/res process }
private String clientContextId; private Map<String, Object> rawParams; private boolean pretty; /** * We are exposing this as a boolean, but internally the server * wants it as int. To be forwards compatible */ private int priority; private AnalyticsParams() { pretty = false; priority = 0; }
public AnalyticsParams priority(boolean priority) { return priority(-1); }
public String toString() { return "AnalyticsParams{" + "serverSideTimeout='" + serverSideTimeout + '\'' + ", clientContextId='" + clientContextId + '\'' + ", rawParams=" + rawParams + ", pretty=" + pretty + ", priority=" + (priority != 0 ? "true" : "false") + '}'; }
} public static void setOpaque(int opaque, ByteBuf buffer) { buffer.setInt(OPAQUE_OFFSET, opaque); } public static int getOpaque(ByteBuf buffer) { return buffer.getInt(OPAQUE_OFFSET); } public static long getCas(ByteBuf buffer) { return buffer.getLong(CAS_OFFSET); } private static String formatOpcode(byte opcode) { String name = OPCODE_NAMES[0xff & opcode]; return String.format("0x%02x (%s)", opcode, name == null ? "?" : name); } private static String formatMagic(byte magic) { String name = magic == MAGIC_REQ ? "REQUEST" : (magic == MAGIC_RES) ? "RESPONSE" : "?"; return String.format("0x%02x (%s)", magic, name); }
} DcpControl control = environment.dcpControl(); Credentials credentials = environment.credentialsProvider().get((InetSocketAddress) ch.remoteAddress()); pipeline.addLast(new AuthHandler(credentials.getUsername(), credentials.getPassword())) .addLast(new DcpConnectHandler(environment.connectionNameGenerator(), environment.bucket(), control)) .addLast(new DcpControlHandler(control)); if (control.noopEnabled()) { pipeline.addLast(new IdleStateHandler(2 * control.noopIntervalSeconds(), 0, 0)); } pipeline.addLast(new DcpLoggingHandler(LogLevel.DEBUG)); DcpMessageHandler messageHandler = new DcpMessageHandler(ch, environment, controlHandler); pipeline.addLast(messageHandler); if (environment.persistencePollingEnabled()) { pipeline.addLast(new PersistencePollingHandler(environment, configProvider, messageHandler)); } }
public void shouldSerializeEjectionMethod() { BucketSettings settings = DefaultBucketSettings.builder() .ejectionMethod(EjectionMethod.FULL) .build(); DefaultAsyncClusterManager clusterManager = new DefaultAsyncClusterManager("login", "password", null, null, null); String payload = clusterManager.getConfigureBucketPayload(settings, false); assertTrue(payload.contains("evictionPolicy=fullEviction")); }
/** * An exception denoting that the search engine couldn't parse an FTS request. * * @author Simon Baslé * @since 2.3 */ public class FtsServerOverloadException extends CouchbaseException { public FtsServerOverloadException(String payload) { super("Search server is overloaded. Details: " + payload); } }
package com.couchbase.client.java.error; import com.couchbase.client.core.CouchbaseException; /** * An exception denoting that the search engine couldn't parse an FTS request. * * @author Simon Baslé * @since 2.3 */ public class FtsServerOverloadException extends CouchbaseException { public FtsServerOverloadException(String payload) { super("Search server is overloaded. Details: " + payload); } }
return applyTimeout(core.<SearchQueryResponse>send(request), request, environment, timeout, timeUnit); }) .flatMap(new Func1<SearchQueryResponse, Observable<SearchQueryResponse>>() { @Override public Observable<SearchQueryResponse> call(final SearchQueryResponse r) { if (shouldRetry(r.statusCode())) { return Observable.error(new RetryableException(r)); } return Observable.just(r); } }) .retryWhen(RetryBuilder .anyOf(RetryableException.class) .max(9) .delay(Delay.exponential(TimeUnit.MILLISECONDS, 500, 2)) .doOnRetry(new Action4<Integer, Throwable, Long, TimeUnit>() { @Override public void call(Integer attempt, Throwable error, Long delay, TimeUnit delayUnit) { LOGGER.debug("Retrying {} because of {} (attempt {}, delay {} {})", query.export(), error.getMessage(), attempt, delay, delayUnit); } }) .build() ) .map(new Func1<SearchQueryResponse, AsyncSearchQueryResult>() { @Override public AsyncSearchQueryResult call(final SearchQueryResponse response) {
public N1qlWriter(N1qlMode mode, boolean createDocuments) { this.mode = mode; this.createDocuments = createDocuments; }
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.kududb.client; import org.kududb.annotations.InterfaceAudience; import java.util.List; import java.util.PriorityQueue; import java.util.Queue; import java.util.concurrent.atomic.AtomicLong; @InterfaceAudience.Private public class RequestTracker { private final AtomicLong sequenceIdTracker = new AtomicLong(); private final Queue<Long> incompleteRpcs = new PriorityQueue<>(); static final long UNSET_SEQUENCE_ID = -1; public RequestTracker() { } public long nextSequenceId() { Long next = sequenceIdTracker.incrementAndGet(); incompleteRpcs.add(next); return next; } public long firstIncompleteRpc() { if (incompleteRpcs.isEmpty()) { return UNSET_SEQUENCE_ID; } return incompleteRpcs.peek(); } public void rpcCompleted(long sequenceId) { incompleteRpcs.remove(sequenceId); } } public void testSuggestDesiredDimensions() { final Point min = getScreenSize(); final Point screenSize = min; final int w = min.x * 3; final int h = min.y * 2; assertDesiredMinimum(new Point(min.x / 2, min.y / 2), min, screenSize); assertDesiredMinimum(new Point(w, h), new Point(w, h), screenSize); assertDesiredMinimum(new Point(min.x / 2, h), min); assertDesiredMinimum(new Point(w, min.y / 2), new Point(w, min.y), screenSize); } private static boolean hasActionView(Element intent) { NodeList children = intent.getChildNodes(); for (int i = 0; i < children.getLength(); i++) { Node child = children.item(i); if (child.getNodeType() == Node.ELEMENT_NODE && child.getNodeName().equals(NODE_ACTION)) { Element action = (Element) child; if (action.hasAttributeNS(ANDROID_URI, ATTRIBUTE_NAME)) { Attr attr = action.getAttributeNodeNS(ANDROID_URI, ATTRIBUTE_NAME); if (attr.getValue().equals("android.intent.action.VIEW")) { return true; } } } } return false; } private void
@Override public void flush(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { if (originalPromise != null) { originalPromise.tryFailure(cause); } ctx.fireExceptionCaught(cause); } @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { if (evt instanceof HandshakeDeadlineEvent) { originalPromise().tryFailure(new ConnectTimeoutException("Handshake did not complete before deadline.")); ctx.close(); return; } ctx.fireUserEventTriggered(evt); } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { if (!originalPromise().isDone()) { originalPromise().tryFailure(new ConnectException("Channel became inactive before handshake completed.")); } ctx.fireChannelInactive(); }
@Override protected Tuple2<ByteBuf, Integer> doEncode(final JsonDocument document) throws Exception { addEncryption(document.content()); return Tuple.create(jsonObjectToByteBuf(document.content()), TranscoderUtils.JSON_COMPAT_FLAGS); } @Override protected JsonDocument doDecode(String id, ByteBuf content, long cas, int expiry, int flags, ResponseStatus status) throws Exception { if (!TranscoderUtils.hasJsonFlags(flags)) { throw new TranscodingException("Flags (0x" + Integer.toHexString(flags) + ") indicate non-JSON document for " + "id " + id + ", could not decode."); } JsonObject jsonObject = byteBufToJsonObject(content); jsonObject.setEncryptionConfig(encryptionConfig); return newDocument(id, expiry, jsonObject, cas); } @Override public JsonDocument newDocument(String id, int expiry, JsonObject content, long cas) { JsonDocument document = JsonDocument.create(id, expiry, content, cas); document.content().setEncryptionConfig(this.encryptionConfig); return document; }
public JsonDocument newDocument(String id, int expiry, JsonObject content, long cas) { JsonDocument document = JsonDocument.create(id, expiry, content, cas); document.content().setEncryptionConfig(this.encryptionConfig); return document; }
public Version(String version) { String[] parts = version.split("\\."); major = Integer.valueOf(parts[0]); if (parts.length > 1) { minor = Integer.valueOf(parts[1]); } if (parts.length > 2) { micro = Integer.valueOf(parts[2]); } } JsonDocument doc = JsonDocument.create(id, data); Observable<JsonDocument> result; switch (opts.ingestMethod) { case INSERT: result = bucket.async().insert(doc); break; case UPSERT: result = bucket.async().upsert(doc); break; case REPLACE: result = bucket.async().replace(doc); break; default: return Observable.error(new UnsupportedOperationException("Unsupported ingest method")); } result = result.timeout(kvTimeout, TimeUnit.MILLISECONDS); if (opts.retryBuilder != null) { result = result.retryWhen(opts.retryBuilder.build()); } if (opts.ignoreIngestError) { result = result.onErrorResumeNext(Observable.<JsonDocument>empty()); } return result;
import libcore.util.Base64; import libcore.util.Base64InputStream; import junit.framework.TestCase; import java.io.ByteArrayInputStream; import java.io.IOException; import java.io.InputStream; import java.nio.charset.StandardCharsets; import java.util.Random; public class Base64InputStreamTest extends TestCase { static final String lipsum = "Lorem ipsum dolor sit amet, consectetur adipiscing elit. " + "Quisque congue eleifend odio, eu ornare nulla facilisis eget. " + "Integer eget elit diam, sit amet laoreet nibh. Quisque enim " + "urna, pharetra vitae consequat eget, adipiscing eu ante. " + "Aliquam venenatis arcu nec nibh imperdiet tempor. In id dui " + "eget lorem aliquam rutrum vel vitae eros. In placerat ornare " + "pretium. Curabitur non fringilla mi. Fusce ultricies, turpis " + "eu ultrices suscipit, ligula nisi consectetur eros, dapibus " + "aliquet dui sapien a turpis. Donec ultricies varius ligula, "; public void testBase64InputStream() throws IOException { byte[] data = lipsum.getBytes(StandardCharsets.UTF_8); byte[] encodedData = Base64.encode(data, Base64.DEFAULT); InputStream inputStream = new ByteArrayInputStream(encodedData); Base64InputStream base64InputStream = new Base64InputStream(inputStream, Base64.DEFAULT); byte[] decodedData = new byte[data.length]; int bytesRead = base64InputStream.read(decodedData); assertEquals(data.length, bytesRead); assertEquals(new String(data, StandardCharsets.UTF_8), new String(decodedData, StandardCharsets.UTF_8)); } }
*Refactored Code:* ```java /** * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.java.query.dsl.path; /** * . * * @author Michael Nitschinger */ public enum SelectType { DEFAULT(""), ALL("ALL"), DISTINCT("DISTINCT"), RAW("RAW"), DISTINCT_RAW("DISTINCT RAW"); private final String value; SelectType(String value) { this.value = value; } public String value() { return value; } } ```
public void shouldNotAllowReplaceAndUUID() { AnalyticsIngester.ingest(null, null, AnalyticsIngester.IngestOptions.ingestOptions().ingestMethod(AnalyticsIngester.IngestMethod.REPLACE)); }
private Button createChangeAction() { final Button createChange = new Button("Create change"); createChange.setTitle("Create change directly in browser"); createChange.addClickHandler(new ClickHandler() { @Override public void onClick(ClickEvent event) { CreateChangeAction.call(createChange, getProjectKey().toString()); } }); return createChange; } public void onResponseReceived(Request req, final Response res) { int status = res.getStatusCode(); if (status == Response.SC_NO_CONTENT) { cb.onSuccess(null); if (!background) { RpcStatus.INSTANCE.onRpcComplete(); } } else if (200 <= status && status < 300) { T data; if (isTextBody(res)) { data = NativeString.wrap(res.getText()).cast(); } else if (isJsonBody(res)) { try { // javac generics bug data = RestApi.<T>cast(parseJson(res)); } catch (JSONException e) { if (!background) { RpcStatus.INSTANCE.onRpcComplete(); } cb.onFailure(new StatusCodeException(SC_BAD_RESPONSE, "Invalid JSON: " + e.getMessage())); return; } } else { if (!background) { RpcStatus.INSTANCE.onRpcComplete(); } cb.onFailure(new StatusCodeException(SC_BAD_RESPONSE, "Expected ")); } } } public void reserveExact(int additional) { Preconditions.checkArgument(additional >= 0, "negative additional"); if (data.length - len >= additional) return; data = Arrays.copyOf(data, len + additional); } import com.couchbase.client.java.Cluster; import com.couchbase.client.java.Bucket; import com.couchbase.client.java.analytics.AnalyticsDeferredResultHandle; import com.couchbase.client.java.analytics.AnalyticsParams; import com.couchbase.client.java.analytics.AnalyticsQuery; import com.couchbase.client.java.analytics.AnalyticsQueryResult; import com.couchbase.client.java.analytics.AnalyticsQueryRow; public class AnalyticsDeferredQueryTest { public static void main(String... args) throws Exception { Cluster cluster = CouchbaseCluster.create(); cluster.authenticate("Administrator", "password"); Bucket bucket = cluster.openBucket("default"); AnalyticsQueryResult result = bucket.query(AnalyticsQuery.simple("SELECT 1=1;", AnalyticsParams.build().deferred(true))); byte[] serialized =
import com.couchbase.client.core.annotations.InterfaceAudience; import com.couchbase.client.core.annotations.InterfaceStability; /** * An async handle to fetch the status and results of a deferred Analytics Query * * @author Subhashni Balakrishnan * @since 2.7.2 */ @InterfaceStability.Experimental @InterfaceAudience.Public public interface AnalyticsDeferredResultHandle { /** * Get the status uri * * @return uri */ @InterfaceAudience.Private String getStatusHandleUri(); /** * Get the result uri if available * * @return uri */ @InterfaceAudience.Private String getResultHandleUri(); /** * Get the list of all {@link AnalyticsQueryRow}, the results of the query, if successful. * * @return the list of all {@link AnalyticsQueryRow} */ List<AnalyticsQueryRow> allRows(); /** * Get an iterator over the list of all {@link AnalyticsQueryRow}, the results of the query, if successful. * * @return an iterator over the list of all {@link AnalyticsQueryRow} */ Iterator<AnalyticsQueryRow> rows(); }
"status='" + status + '\'' + ", finalSuccess=" + finalSuccess + ", parseSuccess=" + parseSuccess + ", allRows=" + allRows + ", signature=" + signature + ", info=" + info + ", errors=" + errors + ", requestId='" + requestId + '\'' + ", clientContextId='" + clientContextId + '\'' + ", handle='" + handle + '\'' + '}';
public String getResultHandleUri() { if (this.resultHandle.length() == 0) { throw new IllegalStateException("There is no result handle available, retry status until success"); } return this.resultHandle; }
public KeysPath useNestedLoop() { element(new NestedLoopJoinHintElement()); return new DefaultKeysPath(this); }
public String export() { StringBuilder sb = new StringBuilder(); sb.append("USE HASH("); sb.append(this.side.getValue()); sb.append(")"); return sb.toString(); }
public String export() { return "USE HASH(" + this.side + ")"; }
package com.couchbase.client.java.query.dsl.path; import com.couchbase.client.core.annotations.InterfaceAudience; import com.couchbase.client.core.annotations.InterfaceStability; /** * Hash side for hash based join * * @author Subhashni Balakrishnan */ @InterfaceStability.Experimental @InterfaceAudience.Public public enum HashSide { PROBE("PROBE"), BUILD("BUILD"); private final String value; HashSide(String value) { this.value = value; } public String getValue() { return this.value; } }
/** * Hash side for hash based join * * @author Subhashni Balakrishnan */ @InterfaceStability.Experimental @InterfaceAudience.Public public enum HashSide { /*The PROBE side will use that table to find matches and perform the join*/ PROBE("PROBE"), /*The BUILD side of the join will be used to create an in-memory hash table */ BUILD("BUILD"); private final String value; HashSide(String value) { this.value = value; } public String toString() { return this.value; } }
/** * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of an specific reference name. * <p> * A number that increases when a reference is updated. Implementations define its meaning * (e.g. version counter or timestamp). When the implementation doesn't support versioning, * it throws an {@link UnsupportedOperationException}. * * @return the update index of this reference. * @throws UnsupportedOperationException if the implementation doesn't support versioning */ default long getUpdateIndex() { throw new UnsupportedOperationException(); }
Refactored Code: ```java /** * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of an specific reference name. * <p> * A number that increases when a reference is updated. Implementations define its meaning (e.g. version counter or timestamp). * When the implementation doesn't support versioning, it throws an {@link UnsupportedOperationException}. * * @return the update index of this reference. * @since 1.0 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } ```
public void testUpdateIndexNotImplemented() throws IOException { Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getVersion(); // Not implemented on FS } @Test public void testUpdateIndexNotImplemented2() throws Exception { RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref : refs) { try { ref.getVersion(); fail("FS doesn't implement update index"); } catch (UnsupportedOperationException e) { // ok } } } @Test public void testGetRefs_EmptyDatabase() throws IOException { Map<String, Ref> all; all = refdir.getRefs(RefDatabase.ALL); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_HEADS); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_TAGS); assertTrue("no references", all.isEmpty()); } @Test public void testGetRefs_HeadOnOneBranch() throws IOException { // test implementation }
public class VersionedRef implements Ref { private Ref ref; private long version; public VersionedRef(Ref ref, long version) { this.ref = ref; this.version = version; } @Override public String getName() { return ref.getName(); } @Override public boolean isSymbolic() { return ref.isSymbolic(); } @Override public Ref getLeaf() { return ref.getLeaf(); } @Override public Ref getTarget() { return ref.getTarget(); } @Override public ObjectId getObjectId() { return ref.getObjectId(); } @Override public long getUpdateTime() { return ref.getUpdateTime(); } @Override public long getCreationTime() { return ref.getCreationTime(); } @Override public long getVersion() { return version; } }
private TmfFilterHelper() { // nothing to do } /** * Build an event filter from the regex string in parameter * * @param regexes The filter regex * @param trace The trace this filter applies to * @return An event filter */ public static @Nullable ITmfFilter buildFilterFromRegex(Collection<String> regexes, ITmfTrace trace) { FilterCu compile = FilterCu.compile(IFilterStrings.mergeFilters(regexes)); if (compile == null) { LOGGER.info("Failed to compile event filter from regex"); return null; } return compile.getEventFilter(trace); } /** * Get the regex that corresponds to this filter. The regex should be in the * filter language described in the {@link org.eclipse.tracecompass.tmf.filter.parser} plugin. * And as it may be used to filter anything, so it may not be the direct string * representing of the original filter. For instance, a ITmfFilter specific * for events will do a smart conversion, so that the parameters of the * filter are not hardcoded in the regex. * * @param filter The filter to get the regex from * @return The regex string */ public static String getRegexFromFilter(ITmfFilter filter) { if (filter instanceof FilterCu) { return ((FilterCu) filter).getRegex(); } LOGGER.warning("Failed to get regex from filter"); return null; }
default long getVersion() { throw new UnsupportedOperationException(); }
package org.eclipse.jgit.lib; /** * Decorate a reference adding the update index (version) property. * * Undecorated Refs throw UnsupportedOperationException on getVersion(), * while decorated instances return the expected value. * * The client is responsible to call getVersion() only on refs obtained from * RefDatabase implementations that support versioning (e.g. reftables) * * @since 5.2 */ public class VersionedRef implements Ref { private Ref ref; private long updateIndex; /** * @param ref the Reference * @param updateIndex its update index */ public VersionedRef(Ref ref, long updateIndex) { this.ref = ref; this.updateIndex = updateIndex; } @Override public String getName() { return ref.getName(); } @Override public boolean isSymbolic() { return ref.isSymbolic(); } @Override public ObjectId getObjectId() { return ref.getObjectId(); } @Override public Storage getStorage() { return ref.getStorage(); } @Override public boolean isPeeled() { return ref.isPeeled(); } @Override public Ref getLeaf() { return ref.getLeaf(); } @Override public Ref getTarget() { return ref.getTarget(); } @Override public long getUpdateIndex() { return updateIndex; } }
} else { factory = new UMLPropertyEditorFactory(reference); } EClass type = reference.getEReferenceType(); factory.setContainerLabelProvider(new UMLFilteredLabelProvider()); factory.setReferenceLabelProvider(new EMFLabelProvider()); ITreeContentProvider contentProvider = new UMLContainerContentProvider(source, reference); ResourceSet rs = source == null ? null : source.eResource() == null ? null : source.eResource().getResourceSet(); EMFGraphicalContentProvider provider = ProviderHelper.encapsulateProvider(contentProvider, rs, HistoryUtil.getHistoryID(source, feature, "container")); factory.setContainerContentProvider(provider); factory.setReferenceContentProvider(new FeatureContentProvider(type)); return factory;
/** * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation * Christian W. Damus - bug 485220 *****************************************************************************/ package org.eclipse.papyrus.uml.tools.databinding; import org.eclipse.core.databinding.observable.IObservable; import org.eclipse.emf.edit.domain.EditingDomain; /** * @deprecated Use the {@link org.eclipse.papyrus.infra.services.edit.ui.databinding.AggregatedPapyrusObservableValue} API, instead. * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public class AggregatedPapyrusObservableValue extends org.eclipse.papyrus.infra.services.edit.ui.databinding.AggregatedPapyrusObservableValue { public AggregatedPapyrusObservableValue(EditingDomain domain, IObservable... observableValues) { super(domain, observableValues); } }
* See the License for the specific language governing permissions and * limitations under the License. */ package com.android.hierarchyviewerlib.models; import java.util.ArrayList; import java.util.HashMap; import com.android.ddmlib.IDevice; import com.android.hierarchyviewerlib.device.Window; /** * This is the model for device selection!!! * * @author Konstantin Lopyrev */ public class DeviceSelectionModel { private HashMap<IDevice, Window[]> deviceMap; private HashMap<IDevice, Integer> focusedWindowHashes; private final ArrayList<IDevice> deviceList = new ArrayList<IDevice>(); private ArrayList<WindowChangeListener> windowChangeListeners; private IDevice selectedDevice; private Window selectedWindow; public DeviceSelectionModel() { deviceMap = new HashMap<IDevice, Window[]>(); windowChangeListeners = new ArrayList<WindowChangeListener>(); focusedWindowHashes = new HashMap<IDevice, Integer>(); } public void addDevice(IDevice device, Window[] windows) { synchronized (deviceMap) { deviceMap.put(device, windows); deviceList.add(device); } notifyDeviceConnected(device); } } import org.eclipse.wst.xml.core.internal.provisional.document.IDOMAttr; import org.eclipse.wst.xml.core.internal.provisional.document.IDOMDocument; import org.eclipse.wst.xml.core.internal.provisional.document.IDOMElement; import org.eclipse.wst.xml.core.internal.provisional.document.IDOMModel; import org.w3c.dom.Attr; import org.w3c.dom.NamedNodeMap; import org.w3c.dom.Node; import org.w3c.dom.NodeList; import java.io.IOException; import java.io.UnsupportedEncodingException; import java.util.ArrayList; import java.util.List; import java.util.Set; /** * A text change that operates on android layout using WTP SSE model. * It is base class for Rename Package and Rename Type changes */ public class AndroidLayoutChange extends DocumentChange { private IDocument mDocument; private ITextFileBufferManager mManager; private IFile mFile; private IStructuredModel mModel; private Set<AndroidLayoutChangeDescription> mChanges; /** * @param file * @param lDocument * @param lManager * @param androidLayoutChangeDescription */ public AndroidLayoutChange(IFile file, IDocument document, ITextFileBufferManager manager
import android.telephony.CellLocation; import android.telephony.ServiceState; import android.telephony.gsm.GsmCellLocation; import com.android.internal.telephony.TelephonyProperties; import android.os.SystemProperties; /** * Stores the cell tower state * * {@hide} */ public class CellState { public static String TAG = "CellState"; public static int RADIO_TYPE_GPRS = 1; public static int RADIO_TYPE_CDMA = 2; public static int RADIO_TYPE_WCDMA = 3; private int mCid = -1; private int mLac = -1; private int mMcc = -1; private int mMnc = -1; private int mHomeMcc = -1; private int mHomeMnc = -1; private String mCarrier = null; private int mRadioType = -1; private long mTime = 0; public CellState() { // constructor for invalid cell location } public CellState(ServiceState service, CellLocation location) { if (location instanceof GsmCellLocation) { // code here } } } import android.telephony.CellLocation; import android.telephony.ServiceState; import android.telephony.gsm.GsmCellLocation; import com.android.internal.telephony.TelephonyProperties; import android.os.SystemProperties; /** * Stores the cell tower state * * {@hide} */ public class CellState { public static String TAG = "CellState"; public static int RADIO_TYPE_GPRS = 1; public static int RADIO_TYPE_CDMA = 2; public static int RADIO_TYPE_WCDMA = 3; private int mCid = -1; private int mLac = -1; private int mMcc = -1; private int mMnc = -1; private int mHomeMcc = -1; private int mHomeMnc = -1; private String mCarrier = null; private int mRadioType = -1; private long mTime = 0; public CellState() { // constructor for invalid cell location } public CellState(ServiceState service, CellLocation location) { if (location instanceof GsmCellLocation) { // code here } } } if (cellState.getRadioType() == CellState.RADIO_TYPE
import org.eclipse.gmf.runtime.emf.type.core.requests.SetRequest; import org.eclipse.papyrus.infra.emf.gmf.command.GMFtoEMFCommandWrapper; import org.eclipse.papyrus.infra.services.edit.service.ElementEditServiceUtils; import org.eclipse.papyrus.infra.services.edit.service.IElementEditService; import org.eclipse.papyrus.infra.ui.emf.databinding.EMFObservableList; /** * An ObservableList used to edit collections of EObjects through Papyrus commands * * @author Camille Letavernier * @deprecated Use the org.eclipse.papyrus.infra.gmfdiag.common.databinding.GMFObservableList API, instead * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated @SuppressWarnings("unchecked") public class PapyrusObservableList extends EMFObservableList { /** * Constructor. * * @param wrappedList The list to be edited when #commit() is called * @param domain The editing domain on which the commands will be executed * @param source The EObject from which the list will be retrieved * @param feature The feature representing the list */ public PapyrusObservableList(List<?> wrappedList, TransactionalEditingDomain domain, EObject source, EStructuralFeature feature) { super(wrappedList, domain, source, feature); } }
import org.eclipse.papyrus.infra.services.edit.service.ElementEditServiceUtils; import org.eclipse.papyrus.infra.services.edit.service.IElementEditService; import org.eclipse.papyrus.infra.tools.databinding.AggregatedObservable; import org.eclipse.papyrus.infra.tools.databinding.ReferenceCountedObservable; import org.eclipse.papyrus.infra.ui.emf.databinding.EMFObservableValue; import org.eclipse.papyrus.uml.tools.Activator; /** * An ObservableValue used to edit EObject properties through Papyrus commands * * @author Camille Letavernier * @deprecated Use the org.eclipse.papyrus.infra.gmfdiag.common.databinding.GMFObservableValue API, instead * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public class PapyrusObservableValue extends EMFObservableValue implements AggregatedObservable, CommandBasedObservableValue, ReferenceCountedObservable { private final ReferenceCountedObservable.Support refCount = new ReferenceCountedObservable.Support(this); /** * Constructor. * * @param eObject The EObject to edit * @param eStructuralFeature The structural feature to edit * @param domain The editing domain on which the commands will be executed */ public PapyrusObservableValue(EObject eObject, EStructuralFeature eStructuralFeature, EditingDomain domain) { super(eObject, eStructuralFeature, domain); } }
/* * SPDX-License-Identifier: EPL-2.0 * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.uml.tools.providers; import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName(); // TODO: To be refactored. Merge this class with UMLLabelProvider // should be removed in Papyrus 5.0 (see bug 540821) return name; } return super.getText(source); } } */
/** * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.uml.tools.providers; import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; /** * An implementation of ILabelProvider for UML Profiles. * * @deprecated This class should be merged with UMLLabelProvider in Papyrus 5.0 (see bug 540821) */ @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName(); if (name == null) { name = UNKNOWN_PROFILE; } if (ProfileUtil.isProfileApplied(umlPackage, profile)) { return name; } else { return name + TAG_PROFILE_CHANGED; } } return super.getText(source); } }
import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName(); if (name == null) { name = UNKNOWN_PROFILE; } if (ProfileUtil.isDirty(umlPackage, profile)) { name += TAG_PROFILE_CHANGED; } return name; } return super.getText(source); } }
long[] stack = new long[1]; stack[0] = 0; return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); private ICallStackElement getElement(ITmfEvent event) { Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(String.valueOf(name))) .findFirst();
import java.util.Collection; import java.util.Optional; import org.eclipse.tracecompass.tmf.core.event.ITmfEvent; import org.eclipse.tracecompass.tmf.core.trace.TmfTraceUtils; import org.eclipse.tracecompass.tmf.ctf.core.event.CtfTmfEventType; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTrace; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfIterator; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfIteratorFactory; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfIteratorType; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfEventIterator; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIterator; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorFactory; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorType; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory.CtfTmfTraceIteratorType; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory.CtfTmfTraceIteratorType.CtfTmfTraceIterator; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory.CtfTmfTraceIteratorType.CtfTmfTraceIterator.CtfTmfEventIterator; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory.CtfTmfTraceIteratorType.CtfTmfTraceIterator.CtfTmfEventIterator.CtfTmfEventType; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory.CtfTmfTraceIteratorType.CtfTmfTraceIterator.CtfTmfEventIterator.CtfTmfEventType.CtfTmfEventType;
public static @Nullable Integer getCpu(ITmfEvent event) { Integer cpuObj = TmfTraceUtils.resolveIntEventAspectOfClassForEvent(event.getTrace(), TmfCpuAspect.class, event); if (cpuObj == null) { /* We couldn't find any CPU information, ignore this event */ return null; } return cpuObj; } @Override public Map<String, Collection<Object>> getCallStack(ITmfEvent event) { Map<String, Collection<Object>> map = new HashMap<>(); ITmfEventField content = event.getContent(); ITmfEventField field = content.getField(KERNEL_CALLSTACK_FIELD); if (field != null) { map.put(KERNEL_STACK_NAME, getCallstack(field)); } field = content.getField(USER_CALLSTACK_FIELD); if (field != null) { map.put(USER_STACK_NAME, getCallstack(field)); } return map; } private static Collection<Object> getCallstack(ITmfEventField field) { Object value = field.getValue(); if (value instanceof long[]) { return Arrays.asList((long[]) value); } else { return Collections.emptyList(); } }
```java } long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } private ICallStackElement getElement(ITmfEvent event) { Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(String.valueOf(name))) .findFirst(); Integer threadId = TmfTraceUtils.resolveIntEventAspectOfClassForEvent(event.getTrace(), LinuxTidAspect.class, event); int tid = (threadId == null) ? -1 : threadId; } ```
if (userCs == null) { userCs = Collections.emptyList(); } if (kernelCs.size() + userCs.size() == 0) { long[] stack = new long[1]; stack[0] = 0; return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } private ICallStackElement getElement(ITmfEvent event) { // Find a root elements with the same PID Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(name)) .findFirst(); return events.orElse(null); }
Optional<Resource> representationResource = Optional.ofNullable(resource) .map(rsr -> rsr.getResourceSet()) .filter(resourceSet -> !loadOnDemand || resourceSet.getURIConverter().exists(repResourceURI, new HashMap<>())) .map(resourceSet -> { Resource res = null; try { res = resourceSet.getResource(repResourceURI, loadOnDemand); } catch (Exception e) { throw new RuntimeException(e); } return res; }); String repId = uri.get().fragment(); if (representationResource.isPresent() && repId != null) { return representationResource.get().getContents().stream() .filter(DRepresentation.class::isInstance) .map(DRepresentation.class::cast)
/***************************************************************************** * Copyright (c) 2017, 2018 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-1.0/ * * SPDX-License-Identifier: EPL-1.0 * * Contributors: * Obeo - initial API and implementation ******************************************************************************/ package org.eclipse.sirius.business.internal.representation; import java.util.HashMap; import java.util.Optional; import org.eclipse.emf.common.util.URI; import org.eclipse.emf.ecore.resource.Resource; import org.eclipse.emf.ecore.util.ECrossReferenceAdapter; import org.eclipse.sirius.business.api.resource.ResourceDescriptor; import org.eclipse.sirius.viewpoint.DRepresentation; import org.eclipse.sirius.viewpoint.DRepresentationDescriptor; /** * This class is intended to manage the link between the {@link DRepresentationDescriptor} and its * {@link DRepresentation} through the {@link DRepresentationDescriptor#repPath} attribute. * * @author fbarbin */ public class DRepresentationDescriptorToDRepresentationLinkManager { // implementation goes here }
@Test public void testMirrorAcceptAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.ACCEPT, DifferenceState.MERGED); } @Test public void testMirrorRejectAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.REJECT, DifferenceState.DISCARDED); } private IEMFCompareConfiguration createConfiguration(boolean leftEditable, boolean rightEditable) { CompareConfiguration cc = new CompareConfiguration(); cc.setProperty(EMFCompareConfiguration.MIRRORED, Boolean.TRUE); cc.setLeftEditable(leftEditable); cc.setRightEditable(rightEditable); EMFCompareConfiguration emfCC = new EMFCompareConfiguration(cc); emfCC.setEditingDomain(editingDomain); return emfCC; } class MockMergeAction extends MergeAction { public MockMergeAction(IEMFCompareConfiguration compareConfiguration, Registry mergerRegistry, MergeMode mode, INavigatable navigatable) { super(compareConfiguration, mergerRegistry, mode, navigatable); } @Override public boolean updateSelection(IStructuredSelection selection) { return super.updateSelection(selection); } @Override protected void clearCache() { super.clearCache(); } @Override protected void handleMerge() { super.handleMerge(); } }
public boolean isMirrored() { Object property = getProperty("MIRRORED"); return property instanceof Boolean && ((Boolean) property).booleanValue(); }
public void propertyChange(PropertyChangeEvent event) { if ("MIRRORED".equals(event.getProperty())) { Object newValue = event.getNewValue(); mirroredPropertyChanged(Boolean.TRUE.equals(newValue)); } }
private String getCurrentValueFromViewer(MergeViewerSide side) { boolean isLeft = MergeViewerSide.LEFT == side; if (getCompareConfiguration().isMirrored()) { isLeft = MergeViewerSide.RIGHT == side; } GetContentRunnable runnable = new GetContentRunnable(isLeft); Display.getDefault().syncExec(runnable); return (String) runnable.getResult(); }
@Test public void testMirrorAcceptAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.ACCEPT, DifferenceState.MERGED); } @Test public void testMirrorRejectAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.REJECT, DifferenceState.DISCARDED); } private IEMFCompareConfiguration createConfiguration(boolean leftEditable, boolean rightEditable) { CompareConfiguration cc = new CompareConfiguration(); cc.setProperty(EMFCompareConfiguration.MIRRORED, Boolean.TRUE); cc.setLeftEditable(leftEditable); cc.setRightEditable(rightEditable); EMFCompareConfiguration emfCC = new EMFCompareConfiguration(cc); emfCC.setEditingDomain(editingDomain); return emfCC; } class MockMergeAction extends MergeAction { public MockMergeAction(IEMFCompareConfiguration compareConfiguration, Registry mergerRegistry, MergeMode mode, INavigatable navigatable) { super(compareConfiguration, mergerRegistry, mode, navigatable); } @Override public boolean updateSelection(IStructuredSelection selection) { return super.updateSelection(selection); } @Override protected void clearCache() { super.clearCache(); } // other methods... }
try { int length = string.length(); if (length == 0) return; boolean mode = true; switch (data.textAntialias) { case SWT.DEFAULT: if (!handle.isDrawingToScreen()) mode = false; break; case SWT.OFF: mode = false; break; case SWT.ON: mode = true; break; } handle.saveGraphicsState(); handle.setShouldAntialias(mode); if (length == 1 && (flags & SWT.DRAW_TRANSPARENT) != 0) { doFastDrawText(string, x, y); } else { doDrawText(string, x, y, flags); } handle.restoreGraphicsState(); } finally { uncheckGC(pool); }
public void stop() { log.info("closing jgroups channel {}", channelName); channel.close(); synchronized (urlsByAddress) { peerInfo = Optional.absent(); peerAddress = null; urlsByAddress.clear(); } } public void close() { try { ch.close(); } catch (IOException e) { // Ignore read close failures. } } private static final class LazyReadableChannel implements ReadableChannel { private final DfsReader ctx; private final DfsReftable file; private ReadableChannel ch; LazyReadableChannel(DfsReftable file, DfsReader ctx) { this.file = file; this.ctx = ctx; } private ReadableChannel getChannel() throws IOException { if (ch == null) { ch = ctx.db.openFile(file.desc, file.ext); } return ch; } @Override public int blockSize() { try { return getChannel().blockSize(); } catch (IOException e) { return -1; } } @Override public long position() throws IOException { return getChannel().position(); } @Override public void position(long newPosition) throws IOException { getChannel().position(newPosition); } @Override public void setReadAheadBytes(int bufferSize) throws IOException { getChannel().setReadAheadBytes(bufferSize); } }
package org.eclipse.mylyn.bugzilla.rest.core.tests; import java.util.List; import org.eclipse.mylyn.commons.sdk.util.CommonTestUtil; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite.SuiteClassProvider; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite.TestConfigurationProperty; import org.eclipse.mylyn.commons.sdk.util.TestConfiguration; import org.junit.runner.RunWith; import org.junit.runners.Suite; @RunWith(ManagedSuite.class) @Suite.SuiteClasses({ RepositoryKeyTest.class, BugzillaRestFlagMapperTest.class, BugzillaRestConnectorNoFixtureTest.class }) @TestConfigurationProperty() public class AllBugzillaRestCoreTests { static { if (CommonTestUtil.fixProxyConfiguration()) {
assertTrue(new File(d, "logs/refs/heads").isDirectory()); assertFalse(new File(d, "logs/HEAD").exists()); assertEquals(0, new File(d, "logs/refs/heads").list().length); assertEquals("ref: refs/heads/master\n", read(new File(d, HEAD))); @Test(expected = UnsupportedOperationException.class) public void testVersioningNotImplemented_exactRef() throws IOException { assertFalse(refdir.hasVersioning()); Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getUpdateIndex(); // Not implemented on FS } @Test public void testVersioningNotImplemented_getRefs() throws Exception { assertFalse(refdir.hasVersioning()); RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref : refs) { try { ref.getUpdateIndex(); fail("FS doesn't implement ref versioning"); } catch (UnsupportedOperationException e) { // ok } } } @Test
public void testVersioningNotImplemented_exactRef() throws IOException { assertFalse(refdir.hasVersioning()); Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getUpdateIndex(); // Not implemented on FS } @Test public void testVersioningNotImplemented_getRefs() throws Exception { assertFalse(refdir.hasVersioning()); RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref : refs) { try { ref.getUpdateIndex(); fail("FS doesn't implement ref versioning"); } catch (UnsupportedOperationException e) { // ok } } } @Test public void testGetRefs_EmptyDatabase() throws IOException { Map<String, Ref> all; all = refdir.getRefs(RefDatabase.ALL); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_HEADS); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_TAGS); assertTrue("no references", all.isEmpty()); }
return ref; Ref dst = ref.getTarget(); if (MAX_SYMBOLIC_REF_DEPTH <= depth) { return null; // claim it doesn't exist } dst = exactRef(dst.getName()); if (dst == null) { return ref; } dst = resolve(dst, depth + 1); if (dst == null) { return null; // claim it doesn't exist } return new VersionedRef(new SymbolicRef(ref.getName(), dst), ref.getUpdateIndex()); } @Override public abstract void close() throws IOException;
/** * Get namespace used by bootstrap layer. * * @return namespace used by bootstrap layer, e.g. {@code refs/txn/}. Always * ends in {@code '/'}. */ @Nullable public String getTxnNamespace() { return txnNamespace; } /** {@inheritDoc} */ @Override public void create() throws IOException { bootstrap.create(); } /** {@inheritDoc} */ @Override public boolean hasVersioning() { return false; } /** {@inheritDoc} */ @Override public boolean performsAtomicTransactions() { return true; } /** {@inheritDoc} */ @Override public void refresh() { bootstrap.refresh(); } /** {@inheritDoc} */ @Override public void close() { refs = null; bootstrap.close(); } /** {@inheritDoc} */ @Override public Ref getRef(String name) throws IOException { String[] needle = new String[SEARCH_PATH.length];
// // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package org.eclipse.jgit.lib; import org.eclipse.jgit.annotations.NonNull; import org.eclipse.jgit.annotations.Nullable; import org.eclipse.jgit.lib.internal.VersionedRef; /** * Pairing of a name and the {@link org.eclipse.jgit.lib.ObjectId} it currently * has. * <p> * A ref in Git is (more or less) a variable that holds a single object * identifier. The object identifier can be any valid Git object (blob, tree, * commit, annotated tag, ...). * <p> * The ref name has the attributes of the ref that was asked for as well as the * ref it was resolved to for symbolic refs plus the object id it points to and */ public class Ref { private final String name; private final ObjectId objectId; private final boolean symbolic; private final String targetName; private final ObjectId targetObjectId; private final VersionedRef versionedRef; public Ref(String name, ObjectId objectId) { this(name, objectId, false, null, null, null); } public Ref(String name, ObjectId objectId, boolean symbolic, String targetName, ObjectId targetObjectId, VersionedRef versionedRef) { this.name = name; this.objectId = objectId; this.symbolic = symbolic; this.targetName = targetName; this.targetObjectId = targetObjectId; this.versionedRef = versionedRef; } public String getName() { return name; } public ObjectId getObjectId() { return objectId; } public boolean isSymbolic() { return symbolic; } public String getTargetName() { return targetName; } public ObjectId getTargetObjectId() { return targetObjectId; } public VersionedRef getVersionedRef() { return versionedRef; } }
/** * Indicator of the relative order between updates of a specific reference name. * <p> * A number that increases when a reference is updated. Implementations define its value (e.g. version counter or timestamp). * <p> * By default this throws an {@link UnsupportedOperationException}. The instantiator of the Ref must override this method (e.g. by using the {@link VersionedRef} decorator) if it can provide a version value. * * @return the version of this reference. * @throws UnsupportedOperationException if the creator of the instance (e.g. {@link RefDatabase}) doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } */
/** * Initialize a new reference database at this location. * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on update. * * @return true when the implementation assigns version numbers to sequencer numbers. * @since 5.3 */ public abstract boolean hasVersioning(); /** * Determine if a proposed reference name overlaps with an existing one. * * Reference names use '/' as a component separator, and may be stored in a * hierarchical storage such as a directory on the local filesystem. * * If the reference "refs/heads/foo" exists then "refs/heads/foo/bar" must */
public abstract void create() throws IOException; public abstract void close(); public abstract boolean hasVersioning(); public abstract boolean isReferenceOverlapping(String proposedReference, String existingReference);
return false; } else if (!block.next()) { long pos = block.endPosition(); if (pos >= scanEnd) { return false; } block = readBlock(pos, scanEnd); continue; } block.parseKey(); if (match != null && !block.match(match, prefix)) { block.skipValue(); return false; } long updateIndex = minUpdateIndex + block.readUpdateIndexDelta(); ref = block.readRef(updateIndex); if (!includeDeletes && wasDeleted()) { continue; } return true; } } @Override public Ref getRef() { return ref; } @Override public void close() { // Do nothing. } } private class LogCursorImpl extends LogCursor { private final long scanEnd; private final byte[] match; private String refName; private long updateIndex; private ReflogEntry entry; BlockReader block; LogCursorImpl(long scanEnd, byte[] match) { this.scanEnd = scanEnd; this.match = match;
public boolean hasNext() { while (true) { if (block == null) { return false; } else if (!block.next()) { long pos; if (blockPos != null) { if (listIdx >= blockPos.size()) { return false; } pos = blockPos.get(listIdx++); } else { pos = block.endPosition(); } if (pos >= scanEnd) { return false; } block = readBlock(pos, scanEnd); continue; } block.parseKey(); long updateIndex = minUpdateIndex + block.readUpdateIndexDelta(); ref = block.readRef(updateIndex); ObjectId id = ref.getObjectId(); if (id != null && match.equals(id) && (includeDeletes || !wasDeleted())) { return true; } } } @Override public Ref getRef() { return ref; } @Override public void close() { // Do nothing. }
*Refactor* ```java /** * name. A number that increases when a reference is updated. * * In case of symbolic references, the update index refers to the update of * the symbolic reference iself (e.g. if HEAD points to master, the HEAD * update index will only increase when HEAD changes, regarless how many * times master is updated). * * The update index and its meaning are usually provided by the * {@code RefDatabase} that instantiates the ref. By default this method * throws an {@link UnsupportedOperationException}. Implementors must * overrride it to return a useful value. * * @return the update index (i.e. version) of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } ``` *Refactored* ```java /** * Returns the update index (i.e. version) of this reference. * * The update index and its meaning are usually provided by the * {@code RefDatabase} that instantiates the ref. By default, this method * throws an {@link UnsupportedOperationException}. Implementors must * override it to return a useful value. * * @return the update index of this reference, or -1 if versioning is not supported * @since 5.3 */ default long getUpdateIndex() { return -1; } ```
protected Object createElementViewerInput() { List<TracePackageTraceElement> traceElements = new ArrayList<>(); for (TmfTraceElement tmfTraceElement : fSelectedTraces) { TracePackageTraceElement traceElement = new TracePackageTraceElement(null, tmfTraceElement); TracePackageFilesElement filesElement = new TracePackageFilesElement(traceElement, tmfTraceElement.getResource()); filesElement.setChecked(true); traceElement.addChild(filesElement); String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); traceElement.addChild(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { // Add supplementary files to suppFilesElement } } traceElements.add(traceElement); } return traceElements; }
filesElement.setChecked(true); children.add(filesElement); // Supplementary files try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) { // Handle exception }
// Supplementary files try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) { // Handle exception }
try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) { throw new CoreException(e); }
private T createTest(Class<? extends TestCase> testClass, String methodName, Annotation[] annotations) { return factory.createTest(testClass, methodName, annotations); } // This should close the Raf, and previous implementations wrongly returned a new // open (but useless) channel in this case. fileChannelBeforeClosing.close(); FileChannel fileChannelAfterClosing = raf.getChannel(); assertFalse(fileChannelBeforeClosing.isOpen()); // http://b/19892782 public void testCloseRafBeforeGetChannel_returnChannelWithCloseFdAfterClose() throws Exception { RandomAccessFile raf = new RandomAccessFile(file, "rw"); raf.setLength(10); raf.close(); try { raf.getChannel().size(); fail(); } catch (IOException expected) { return; } assertFalse("Exception expected", true); } private void createRandomAccessFile(File file) throws Exception { // TODO: fix our register maps and remove this otherwise unnecessary // indirection! (http://b/5412580) new RandomAccessFile(file, "rw"); } public void testDirectories() throws Exception { try { new RandomAccessFile(".", "r"); fail(); } catch (FileNotFoundException expected) { } try { new RandomAccessFile(".", "rw"); fail(); } catch (FileNotFoundException expected) { } } TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) { // Should not happen Activator.getDefault().logError("Error finding supplementary files", e
import java.io.ByteArrayOutputStream; import java.io.IOException; import java.util.ArrayList; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import org.eclipse.jgit.internal.storage.io.BlockSource; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectIdRef; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefComparator; import org.eclipse.jgit.lib.SymbolicRef; import org.junit.Test; public class MergedReftableTest { @Test public void noTables() throws IOException { MergedReftable mr = merge(new byte[0][]); try (RefCursor rc = mr.allRefs()) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRef(HEAD)) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRefsWithPrefix(R_HEADS)) { assertFalse(rc.next()); } } @Test public void oneEmptyTable() throws IOException { MergedReftable mr = merge(write()); try (RefCursor rc = mr.allRefs()) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRef(HEAD)) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRefsWithPrefix(R_HEADS)) { assertFalse(rc.next()); } } }
public abstract void create() throws IOException; public abstract void close(); public abstract boolean hasVersioning(); public abstract boolean isReferenceOverlapping(String proposedReference); public abstract boolean isReferenceOverlapping(String existingReference, String proposedReference);
public abstract boolean hasVersioning() { return false; }
*Refactored Code:* ```java /** * With symbolic references, the update index refers to updates of the * symbolic reference itself. For example, if HEAD points to * refs/heads/master, then the update index for exactRef("HEAD") will only * increase when HEAD changes to point to another ref, regardless of how * many times refs/heads/master is updated. * * Should not be used unless the RefDatabase that instantiated the ref supports versioning. * * @return the update index (i.e. version) of this reference. * @throws UnsupportedOperationException if the creator of the instance (e.g. RefDatabase) * doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } ```
public static final String ALL = ""; public abstract void create() throws IOException; public abstract void close(); public boolean hasVersioning() { return false; } public boolean isNameConflicting(String refName) { return false; }
```java boolean isPeeled(); /** * How was this ref obtained? * <p> * The current storage model of a Ref may influence how the ref must be * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of a specific reference * name. A number that increases when a reference is updated. * <p> * With symbolic references, the update index refers to updates of the * symbolic reference itself. For example, if HEAD points to * refs/heads/master, then the update index for exactRef("HEAD") will only * increase when HEAD changes to point to another ref, regardless of how * many times refs/heads/master is updated. * * Should not be used unless the {@code RefDatabase} that instantiated the * ref supports versioning (see {@link RefDatabase#hasVersioning()}) */ @NonNull UpdateIndex getUpdateIndex(); ``` ```java boolean isPeeled(); /** * How was this ref obtained? * <p> * The current storage model of a Ref may influence how the ref must be * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of a specific reference * name. A number that increases when a reference is updated. * <p> * With symbolic references, the update index refers to updates of the * symbolic reference itself. For example, if HEAD points to * refs/heads/master, then the update index for exactRef("HEAD") will only * increase when HEAD changes to point to another ref, regardless of how * many times refs/heads/master is updated. * * Should not be used unless the {@code RefDatabase} that instantiated the * ref supports versioning (see {@link RefDatabase#hasVersioning()}) */ @NonNull UpdateIndex getUpdateIndex(); ``` ```java boolean isPeeled(); /** * How was this ref obtained? * <p> * The current storage model of a Ref may influence how the ref must be * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of a specific reference * name. A number that increases when a
/***************************************************************************** * Copyright (c) 2009, 2018 THALES GLOBAL SERVICES and others. * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation ******************************************************************************/ package org.eclipse.sirius.ui.tools.internal.actions.export; import java.util.Collection; import java.util.Iterator; import java.util.LinkedHashSet; import java.util.Set; import java.util.stream.Collectors; import org.eclipse.emf.ecore.EObject; import org.eclipse.sirius.business.api.dialect.DialectManager; import org.eclipse.sirius.business.api.query.DRepresentationDescriptorQuery; import org.eclipse.sirius.business.api.session.Session; import org.eclipse.sirius.ui.business.api.dialect.DialectUIManager; import org.eclipse.sirius.ui.business.api.dialect.ExportFormat; import org.eclipse.sirius.ui.business.api.dialect.ExportFormat.ExportDocumentFormat; import org.eclipse.sirius.viewpoint.DRepresentationDescriptor; import org.eclipse.sirius.viewpoint.provider.Messages;
public void run() { Collection<DRepresentationDescriptor> repDescriptorsToExport = getRepresentationToExport().stream() .filter(Objects::nonNull) .filter(repDesc -> repDesc.getRepresentation() != null) .collect(Collectors.toList()); if (!repDescriptorsToExport.isEmpty()) { DRepresentationDescriptor firstDRepDescriptorToExport = repDescriptorsToExport.iterator().next(); firstDRepDescriptorToExport.getRepresentation(); Session session = getSession(firstDRepDescriptorToExport); if (session != null) { IPath exportPath = getExportPath(firstDRepDescriptorToExport, session); if (exportPath != null) { exportRepresentation(exportPath, repDescriptorsToExport, session); } } } else { MessageDialog.openInformation(Display.getCurrent().getActiveShell(), Messages.ExportRepresentationsAction_noRepresentationsDialog_title, Messages.ExportRepresentationsAction_noRepresentationsDialog_message); } }
@Deprecated @Nullable public abstract Ref getRef(String name) throws IOException; public Ref findRef(String name) throws IOException { return getRef(name); } /** * Read a single reference. * <p> * Aside from taking advantage of {@link #SEARCH_PATH}, this method may be * able to more quickly resolve a single reference name than obtaining the * complete namespace by {@code getRefs(ALL).get(name)}. * <p> * To read a specific reference without using @{link #SEARCH_PATH}, see * {@link #exactRef(String)}. * * @param name the name of the reference. May be a short name which must be * searched for using the standard {@link #SEARCH_PATH}. * @return the reference (if it exists); else {@code null}. * @throws IOException the reference space cannot be accessed. * @deprecated Use {@link #findRef(String)} instead. */ @Deprecated @Nullable public Ref getRef(String name) throws IOException { return findRef(name); }
public static FirstCommand fromLine(String line) { int nul = line.indexOf('\0'); if (nul < 0) { return new FirstCommand(line, Collections.emptySet()); } Set<String> opts = Arrays.asList(line.substring(nul + 1).split(" ")) .stream() .collect(Collectors.toSet()); return new FirstCommand(line.substring(0, nul), opts); }
protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); } IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (!"jar".equalsIgnoreCase(path.getFileExtension())) { //$NON-NLS-1$ IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } } return null; }
protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); } IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (!"jar".equalsIgnoreCase(path.getFileExtension())) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } } return null; }
IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); // look for files or folders with the given path IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (getType() != ARCHIVE) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); } return null;
static int read(ReadableChannel rc, ByteBuffer buf) throws IOException { int n; do { n = rc.read(buf); } while (0 < n && buf.hasRemaining()); return buf.position(); } static long elapsedMicros(long start) { return (System.nanoTime() - start) / 1000L; } /** * A supplier of readable channel that opens the channel lazily. */ private static class LazyChannel implements AutoCloseable, DfsBlockCache.ReadableChannelSupplier { final DfsReader ctx; ReadableChannel rc = null; LazyChannel(DfsReader ctx) { this.ctx = ctx; } @Override public ReadableChannel get() throws IOException { if (rc == null) { synchronized (this) { if (rc == null) { rc = ctx.db.openFile(desc, ext); } } } return rc; } @Override public void close() throws IOException { if (rc != null) { rc.close(); } } }
import org.eclipse.osgi.util.NLS; final public class ChecksumVerifier extends MessageDigestProcessingStep { private String expectedChecksum; final private String algorithmName; final private String algorithmId; // public to access from tests public ChecksumVerifier(String digestAlgorithm, String algorithmId) { this.algorithmName = digestAlgorithm; this.algorithmId = algorithmId; basicInitialize(null); } @Override public final void initialize(IProvisioningAgent agent, IProcessingStepDescriptor descriptor, IArtifactDescriptor context) { super.initialize(agent, descriptor, context); basicInitialize(descriptor); String data = descriptor.getData(); if (IArtifactDescriptor.DOWNLOAD_CHECKSUM.concat(".").concat(algorithmId).equals(data)) //$NON-NLS-1$ expectedChecksum = ChecksumHelper.getChecksums(context, IArtifactDescriptor.DOWNLOAD_CHECKSUM).get(algorithmId); else if (IArtifactDescriptor.ARTIFACT_CHECKSUM.concat(".").concat(algorithmId).equals(data)) //$NON-NLS-1$ expectedChecksum = ChecksumHelper.getChecksums(context, IArtifactDescriptor.ARTIFACT_CHECKSUM).get(algorithmId); else expectedChecksum = data; if (ofNullable(expectedChecksum).orElse("").isEmpty()) { //$NON-NLS-1$ return; } // Rest of the code } }
private static String selectionToString(Table table) { StringBuilder builder = new StringBuilder(); for (TableItem tableItem : table.getSelection()) { if (builder.length() > 0) { builder.append(System.lineSeparator()); } for (int column = 0; column < table.getColumnCount(); column++) { if (column > 0) { builder.append('\t'); } builder.append(tableItem.getText(column)); } } return builder.toString(); }
sessionId.toAPI(), userId.toAPI()); authorizationService.checkProjectAdminAccess(sessionId.toAPI(), null, ESProjectAdminPrivileges.DeleteOrgUnit); ACUser userToDelete = null; for (final Iterator<ACUser> iter = getUsers().iterator(); iter.hasNext();) { final ACUser user = iter.next(); /* check if we were created by the deleted user */ if (user.getCreatedBy() != null && user.getCreatedBy().equals(userId.getId())) { user.setCreatedBy(null); } /* check if we are the deleted user */ if (user.getId().equals(userId)) { userToDelete = user; } } for (final ACGroup group : getGroups()) { if (group.getCreatedBy() != null && group.getCreatedBy().equals(userId.getId())) { group.setCreatedBy(null); } } /* perform deletion */ if (userToDelete != null) { final List<ACGroup> groups = getGroups(sessionId, userId); save(); }
Fixed Code: ```java if (user.getCreatedBy() != null && user.getCreatedBy().equals(userId.getId())) { user.setCreatedBy(null); save(); } /* check if we are the deleted user */ if (user.getId().equals(userId)) { userToDelete = user; } for (final ACGroup group : getGroups()) { if (group.getCreatedBy() != null && group.getCreatedBy().equals(userId.getId())) { group.setCreatedBy(null); save(); } } /* perform deletion */ if (userToDelete != null) { final List<ACGroup> groups = getGroups(sessionId, userId); for (final ACGroup acGroup : groups) { removeMember(sessionId, acGroup.getId(), userId); } getAccessControl().getOrgUnitProviderService().removeUser(userToDelete.toAPI()); // TODO: move ecore delete into ServerSpace#deleteUser implementation EcoreUtil.delete(userToDelete); save(); } ``` Refactor the Buggy Code using the Review without comments
/* act */ adminBroker2.deleteUser(createdUser1.getId()); /* assert */ assertEquals(initialSize - 1, adminBroker.getUsers().size()); assertNull(findUser(USER_NAME_2).getCreatedBy()); } private ACUser findUser(String name) throws ESException { for (final ACUser user : adminBroker.getUsers()) { if (user.getName().equals(name)) { return user; } } return null; } private ACGroup findGroup(String name) throws ESException { for (final ACGroup group : adminBroker.getGroups()) { if (group.getName().equals(name)) { return group; } } return null; } @Test(expected = AccessControlException.class) public void testLoginOfCreatedUserWithNoPasswordSet() throws ESException { adminBroker.createUser(USER_NAME); ACUser user = null; for (final ACUser u : adminBroker.getUsers()) { if (u.getName().equals(USER_NAME)) { user = u; break; } } }
throw new StorageException(StorageException.NOSAVE, e); } } private void checkForNulls(Object... objects) throws InvalidInputException { for (final Object obj : objects) { if (obj == null) { throw new InvalidInputException(); } } } private <T extends ACOrgUnit<?>> List<T> removeInvisibleOrgUnits(List<T> orgUnits, ESSessionId sessionId) throws AccessControlException { /* * regular users can't see any orgunits, while server admins can see all of them. Only server admins have * reduced visibility. */ final ESOrgUnitId adminId = getAccessControl().getSessions().resolveToOrgUnitId(sessionId); final Optional<ACOrgUnit<?>> orgUnit = ACHelper.getOrgUnit( getAccessControl().getOrgUnitProviderService(), adminId); if (!orgUnit.isPresent()) { return orgUnits; } final List<Role> allRolesOfAdmin = ACHelper.getAllRoles( getAccessControl().getOrgUnitResolverServive(), orgUnit.get()); if (Iterables.any(allRolesOfAdmin, new HasRolePredicate(ServerAdmin.class))) { return orgUnits; }
package org.eclipse.emf.emfstore.server.accesscontrol.test; import static org.eclipse.emf.emfstore.client.test.common.util.ProjectUtil.share; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertTrue; import static org.junit.Assert.fail; import java.util.Arrays; import java.util.LinkedHashSet; import java.util.List; import java.util.Set; import org.eclipse.emf.emfstore.client.ESUsersession; import org.eclipse.emf.emfstore.client.test.common.dsl.Roles; import org.eclipse.emf.emfstore.client.test.common.util.ServerUtil; import org.eclipse.emf.emfstore.internal.server.model.accesscontrol.ACGroup; import org.eclipse.emf.emfstore.internal.server.model.accesscontrol.ACOrgUnit; public class AccessControlTest { /******************************************************************************* * Copyright (c) 2011-2014 EclipseSource Muenchen GmbH and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Edgar Mueller - initial API and implementation ******************************************************************************/ public void testAccessControl() { // Test code here } }
getAdminBroker().addMember(group, otherGroup); getAdminBroker().addMember(otherGroup, newUser); ProjectUtil.share(getUsersession(), getLocalProject()); final ProjectSpace clonedProjectSpace = cloneProjectSpace(getProjectSpace()); ProjectUtil.share(getSuperUsersession(), clonedProjectSpace.toAPI()); getAdminBroker().changeRole(getProjectSpace().getProjectId(), group, Roles.writer()); getAdminBroker().changeRole(getProjectSpace().getProjectId(), otherGroup, Roles.writer()); final int oldSize = getAdminBroker().getGroups().size(); getAdminBroker().deleteGroup(group); assertEquals(oldSize - 1, getAdminBroker().getGroups().size()); @Test public void deleteUser() throws ESException { makeUserPA(); final ACOrgUnitId newUser = ServerUtil.createUser(getSuperUsersession(), getNewUsername()); final ACOrgUnitId group = ServerUtil.createGroup(getSuperUsersession(), getNewGroupName()); final ACOrgUnitId otherGroup = ServerUtil.createGroup(getSuperUsersession(), getNewOtherGroupName()); }
import org.junit.runners.Parameterized.Parameters; import org.mockito.ArgumentCaptor; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @RunWith(ParameterizedPlatformTestRunner.class) public class JmsMomImplementorTest { private static final Logger LOG = LoggerFactory.getLogger(JmsMomImplementorTest.class); @ClassRule public static final ArtemisJmsBrokerTestRule ARTEMIS_RULE = new ArtemisJmsBrokerTestRule(); private IBean<? extends JmsTestMom> m_momBean; private IBean<? extends IJmsMessageHandler> m_messageHandlerBean; private List<IDisposable> m_disposables; private String m_testJobExecutionHint; @Rule public TestName m_testName = new TestName(); public long m_t0; private static final AtomicInteger MOM_COUNTER = new AtomicInteger(0); @Parameters public static List<IScoutTestParameter> getParameters() { List<IScoutTestParameter> parametersList = new LinkedList<IScoutTestParameter>(); // We do not need jmx for unit testing. Also we must disable watchTopicAdvisories else some concurrent issues with broker recreation will happen // ... } }
try { Jobs.getJobManager().awaitDone(testJobsFilter, 10, TimeUnit.SECONDS); LOG.info("All jobs have finished after {} ms", StringUtility.formatNanos(System.nanoTime() - t0)); } catch (TimedOutError e) { LOG.warn("Some cancelled jobs are still running after {} ms! Please check their implementation.", StringUtility.formatNanos(System.nanoTime() - t0)); } BeanTestingHelper.get().unregisterBean(m_messageHandlerBean); m_messageHandlerBean = null; uninstallTestMom(); // ensure activeMQ is stopped BrokerService brokerService = BrokerRegistry.getInstance().findFirst(); if (brokerService != null) { brokerService.stop(); brokerService.waitUntilStopped(); } LOG.info("Finished test in {} ms", StringUtility.formatNanos(System.nanoTime() - m_t0)); LOG.info("</{}>", m_testName.getMethodName()); } @Test @NonParameterized public void testInstanceScoped() { JmsMomImplementor mom1 = BEANS.get(JmsMomImplementor.class); }
} })); // Initiate 'request-reply' communication final String request = "hello world"; String testee = MOM.request(JmsTestMom.class, queue, request); // Verify final String expectedReply = "HELLO WORLD"; assertEquals(expectedReply, testee); IMarshaller marshaller = BEANS.get(CONFIG.getPropertyValue(DefaultMarshallerProperty.class)); verifyRequestReplyMessageLogger(queue, marshaller, request, expectedReply); } private static <DTO> void verifyRequestReplyMessageLogger(IDestination<DTO> expectedDestination, IMarshaller marshaller, DTO expectedRequest, DTO expectedReply) { verify(BEANS.get(IJmsMessageHandler.class), times(2)).handleOutgoing(any(), any(), any()); verifyMessageLoggerHandleOutgoingCalled(expectedDestination, marshaller, expectedRequest); verifyMessageLoggerHandleOutgoingCalled(null, marshaller, expectedReply); // "reply" message is sent only with JMS destination (but without a Scout MOM destination) verify(BEANS.get(IJmsMessageHandler.class), times(2)).handleIncoming(eq(expectedDestination), any(), any()); verifyMessageLoggerHandleIncomingCalled(expectedDestination, marshaller, expectedRequest, expectedReply); }
void init(Map<Object, Object> properties); void handleIncoming(IDestination<?> destination, Message message, IMarshaller marshaller); void handleOutgoing(IDestination<?> destination, Message message, IMarshaller marshaller);
/** * This method is called directly before a JMS message is "sent" by the <i>MessageProducer</i>. "Sent" means that the * <i>send</i> method of the message producer is called. Therefore it is not guaranteed that the time, at which this * method is called, is the <i>sent time</i> of the JMS message (e.g. in a transactional context). * * The message has already been processed (marshalled) by the MOM framework. * * @param destination the MOM destination this message is being sent to. <b>Attention:</b> This might be <code>null</code> in * case of a 'request-reply' communication, where the reply message is only sent back through the JMS * destination defined by {@link Message#getJMSReplyTo()} (and not through a MOM destination) */ void handleOutgoing(IDestination<?> destination, Message message, IMarshaller marshaller); }
protected Message createMessage(final int messageType, final Session session) throws JMSException { switch (messageType) { case MESSAGE_TYPE_TEXT: return session.createTextMessage(); case MESSAGE_TYPE_BYTES: return session.createBytesMessage(); case MESSAGE_TYPE_NO_PAYLOAD: return session.createMessage(); default: throw new PlatformException("Unsupported message type '{}'", messageType); } } public IMarshaller getMarshaller() { return m_marshaller; } public JmsMessageWriter writeTransferObject(final Object transferObject) throws JMSException { final Object transportObject = m_marshaller.marshall(transferObject, m_marshallerContext); m_marshallerContext.put(CTX_PROP_NULL_OBJECT, Boolean.valueOf(transferObject == null).toString()); }
protected JmsMessageWriter writeContext(final String property, final Map<String, String> context) throws JMSException { if (context.isEmpty()) { return this; } final String json = (String) BEANS.get(JsonMarshaller.class).marshall(context, new HashMap<>()); writeProperty(property, json); return this; } public Message build() throws JMSException { writeContext(JMS_PROP_MARSHALLER_CONTEXT, m_marshallerContext); if (m_message instanceof BytesMessage) { ((BytesMessage) m_message).reset(); } return m_message; }
/** * Computes the identifier to name the {@link Connection}. * * @param properties the properties map * @return the computed client ID */ protected String computeClientId(final Map<Object, Object> properties) { final String clientId = ObjectUtility.toString(properties.get(JMS_CLIENT_ID)); if (clientId != null) { return clientId; } final String nodeId = BEANS.get(NodeIdentifier.class).get(); return StringUtility.join(" ", m_symbolicName, StringUtility.box("(", nodeId, ")")); } /** * Returns the message handler. * * @return the message handler */ public IJmsMessageHandler getMessageHandler() { return m_messageHandler; } /** * Exception Handler used in MOM. */ public static class MomExceptionHandler extends ExceptionHandler { }
import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertTrue; public class BundleWriterTest extends SampleDataRepositoryTestCase { @Rule public ExpectedException thrown = ExpectedException.none(); @Test public void testEmptyBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, new byte[0]); } @Test public void testNonBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, "Not a bundle file".getBytes(StandardCharsets.UTF_8)); } @Test public void testGarbageBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, (TransportBundle.V2_BUNDLE_SIGNATURE + '\n' + "Garbage") .getBytes(StandardCharsets.UTF_8)); } @Test public void testWriteSingleRef() throws Exception { // Create a tiny bundle, (well one of) the first commits only final byte[] bundle = makeBundle("refs/heads/firstcommit", ObjectId.fromString("deadbeefdeadbeefdeadbeefdeadbeefdeadbeef")); Repository newRepo = createBareRepository(); fetchFromBundle(newRepo, bundle); Ref ref = newRepo.exactRef("refs/heads/firstcommit"); assertTrue(ref != null); assertEquals(ObjectId.fromString("deadbeefdeadbeefdeadbeefdeadbeefdeadbeef"), ref.getObjectId()); } }
* key is not specified) * @param credentialsProvider * provider to use when querying for signing key credentials (eg. * passphrase) * @throws CanceledException * when signing was canceled (eg., user aborted when entering * passphrase) */ public abstract void sign(@NonNull CommitBuilder commit, String gpgSigningKey, @NonNull PersonIdent committer, CredentialsProvider credentialsProvider) throws CanceledException; /** * Indicates is a signing key is available for the specified committer and/or signing key. * * @param gpgSigningKey * the signing key (passed as is to the GPG signing tool) * @param committer * the signing identity (to help with key lookup in case signing * key is not specified) * @param credentialsProvider * provider to use when querying for signing key credentials (eg. * passphrase) * @return <code>true</code> if a signing key is available, * <code>false</code> otherwise * @throws CanceledException */ public abstract boolean isSigningKeyAvailable(String gpgSigningKey, @NonNull PersonIdent committer, CredentialsProvider credentialsProvider) throws CanceledException;
/** * Indicates if a signing key is available for the specified committer and/or signing key. * * @param signingKey the ID of the signing key (passed as is to the GPG signing tool) * @param committer the signing identity (to help with key lookup in case signing key is not specified) * @param credentialsProvider provider to use when querying for signing key credentials (eg. passphrase) * @return true if a signing key is available, false otherwise * @throws CanceledException when signing was canceled (eg., user aborted when entering passphrase) */ public abstract boolean canLocateSigningKey(String signingKey, PersonIdent committer, CredentialsProvider credentialsProvider); /** * Signs the commit using the specified signing key, committer, and credentials provider. * * @param commit the commit to sign * @param signingKey the ID of the signing key (passed as is to the GPG signing tool) * @param committer the signing identity * @param credentialsProvider provider to use when querying for signing key credentials (eg. passphrase) * @throws CanceledException when signing was canceled (eg., user aborted when entering passphrase) */ public abstract void sign(CommitBuilder commit, String signingKey, PersonIdent committer, CredentialsProvider credentialsProvider) throws CanceledException;
protected void doSetValue(Object value) { super.doSetValue(value); }
public class RevealElementsAction extends AbstractRevealElementsAction<Object> { public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } public RevealElementsAction(final String text) { super(text); } public static boolean isHidden(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } public static boolean isHiddenSelection(List<IDiagramElementEditPart> selectedElements) { for (IDiagramElementEditPart selectedElement : selectedElements) { if (!isHidden(selectedElement)) { return false; } } return true; } }
public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } public RevealElementsAction(final String text) { super(text); } public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; }
protected ICommand getMoveCommand(MoveRequest req) { ICommand moveCommand = super.getMoveCommand(req); Map<?, ?> elementsToMove = req.getElementsToMove(); Iterator<?> iterator = elementsToMove.entrySet().iterator(); boolean moveAllowed = true; while (moveAllowed && iterator.hasNext()) { Entry<?, ?> entrySet = (Entry<?, ?>) iterator.next(); if (entrySet.getKey() instanceof MessageOccurrenceSpecification) { MessageOccurrenceSpecification mos = (MessageOccurrenceSpecification) entrySet.getKey(); EObject container = mos.eContainer(); if (null != container && container != req.getTargetContainer()) { moveAllowed = false; } } } if (!moveAllowed) { moveCommand = UnexecutableCommand.INSTANCE; } return moveCommand; } private List<Pair<NetworkSecurityConfig.Builder, Set<Domain>>> parseConfigEntry(XmlResourceParser parser, Set<String> seenDomains, NetworkSecurityConfig.Builder parentBuilder, int configType) throws IOException, XmlPullParserException, ParserException { List<Pair<NetworkSecurityConfig.Builder, Set<Domain>>> builders = new ArrayList<>(); NetworkSecurityConfig.Builder builder = new NetworkSecurityConfig.Builder(); builder.setParent(parentBuilder); Set<Domain> domains = new ArraySet<>(); boolean seenPinSet = false; boolean seenTrustAnchors = false; boolean defaultOverridePins = configType == CONFIG_DEBUG; String configName = parser.getName(); int outerDepth = parser.getDepth(); builders.add(new Pair<>(builder, domains)); for (int i = 0; i < parser.getAttributeCount(); i++) { String name = parser.getAttributeName(i); if ("hstsEnforced".equals(name)) { // ... } } // ... return anchors; } // ... public static void testArrayElementSetter() throws Throwable { MethodHandle setter = MethodHandles.arrayElementSetter(int[].class); int[] array = new int[2]; setter.invoke(array, 0, 42); setter.invoke(array, 1, 43); if (array[0] != 42) { System.out.println("Unexpected value: " + array[0]); } if (array[1] != 43) { System.out.println("Unexpected value: " + array[1]); } } // ... public RevealElementsAction
public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } public RevealElementsAction(final String text) { super(text); } public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; }
public static boolean isHidden(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } public static boolean isHidden(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isHidden((IDiagramElementEditPart) next); } } return result; }
public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); } else { result = false; } } return result; } @Override public boolean isActive(IDiagramElementEditPart selectedElement) { return isActive(selectedElement); }
public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); } else { result = false; } } return result; }
public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); } else { result = false; } } return result; }
if (vpe instanceof DDiagramElement && this.selection instanceof DiagramOutlinePage.TreeSelectionWrapper) { final DiagramOutlinePage.TreeSelectionWrapper wrapper = (DiagramOutlinePage.TreeSelectionWrapper) this.selection; final RootEditPart root = wrapper.getRoot(); final DDiagramEditor diagramEditor = (DDiagramEditor) wrapper.getViewer().getProperty(DDiagramEditor.EDITOR_ID); runRevealCommand(root, diagramEditor, (DDiagramElement) vpe); } else if (vpe instanceof IDiagramElementEditPart) { Optional<DDiagramElement> optional = Optional.of((IGraphicalEditPart) vpe) .map(IGraphicalEditPart::resolveSemanticElement) .filter(DDiagramElement.class::isInstance) .map(DDiagramElement.class::cast); if (optional.isPresent()) { IDiagramElementEditPart diagramElementEditPart = (IDiagramElementEditPart) vpe; SelectionRequest request = new SelectionRequest(); request.setType(RequestConstants.REQ_OPEN); diagramElementEditPart.performRequest(request); } }
private void runRevealCommand(final RootEditPart root, final DDiagramEditor editor, final DDiagramElement vpe) { final Object adapter = editor.getAdapter(IDiagramCommandFactoryProvider.class); final IDiagramCommandFactoryProvider cmdFactoryProvider = (IDiagramCommandFactoryProvider) adapter; final TransactionalEditingDomain transactionalEditingDomain = TransactionUtil.getEditingDomain(editor.getEditingDomain().getResourceSet()); final IDiagramCommandFactory emfCommandFactory = cmdFactoryProvider.getCommandFactory(transactionalEditingDomain); final Command cmd = emfCommandFactory.buildRevealCommand(vpe); final TransactionalEditingDomain domain = TransactionUtil.getEditingDomain(vpe); CompoundCommand allInOne = new CompoundCommand(cmd.getLabel()); allInOne.append(cmd); domain.getCommandStack().execute(allInOne); }
package org.eclipse.sirius.diagram.ui.tools.internal.actions.visibility; import org.eclipse.gef.Disposable; import org.eclipse.gmf.runtime.diagram.ui.parts.IDiagramWorkbenchPart; import org.eclipse.jface.action.IAction; import org.eclipse.jface.viewers.ISelection; import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.PlatformUI; public class TabbarRevealElementsAction extends RevealElementsAction implements Disposable { private IDiagramWorkbenchPart representationPart; public TabbarRevealElementsAction(final String text) { super(text); } public void setActionPart(IDiagramWorkbenchPart part) { this.representationPart = part; } @Override public void selectionChanged(IAction action, ISelection s) { super.selectionChanged(action, s); } }
import org.eclipse.jface.viewers.ISelection; import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.PlatformUI; public class TabbarRevealElementsAction extends RevealElementsAction implements Disposable { private IDiagramWorkbenchPart representationPart; public TabbarRevealElementsAction(final String label) { super(label); } public void setActionPart(IDiagramWorkbenchPart part) { this.representationPart = part; } @Override public void selectionChanged(IAction action, ISelection s) { IWorkbenchPart selectedPart = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage().getActivePart(); if (representationPart != null && !representationPart.equals(selectedPart)) { return; } super.selectionChanged(action, s); setEnabled(isEnabled()); } @Override public boolean isEnabled() { // implementation } }
import org.eclipse.sirius.diagram.ui.tools.internal.actions.visibility.RevealElementsAction; public class CanShowElementTester extends PropertyTester { @Override public boolean test(Object receiver, String property, Object[] args, Object expectedValue) { boolean result = false; if ("canShowElement".equals(property)) { if (receiver instanceof IStructuredSelection) { result = RevealElementsAction.isActive((IStructuredSelection) receiver); } else if (receiver instanceof IDiagramElementEditPart) { result = RevealElementsAction.isActive((IDiagramElementEditPart) receiver); } } return result; } }
private void activateShowHideModeUsingTabbar() { SWTBotGefEditPart swtBotEditPart = getEditPart("new EClass 4", DNodeNameEditPart.class); hideShow(element, swtBotEditPart, true); } private void hideShow(DDiagramElement element, SWTBotGefEditPart swtBotEditPart, boolean isLabelHidden) { int count = 1; if (!isLabelHidden) { count = 3; } for (int i = 1; i <= count; i++) { editor.reveal(swtBotEditPart.part()); OperationDoneCondition done = new OperationDoneCondition(); performHideReveal(swtBotEditPart, i, "Hide element"); bot.waitUntil(done); SWTBotUtils.waitAllUiEvents(); if (isLabelHidden) { // perform additional actions if the label is hidden } } }
bot.waitUntil(done); SWTBotUtils.waitAllUiEvents(); if (isLabelHidden) { assertFalse(element.getGraphicalFilters().stream().anyMatch(HideLabelFilter.class::isInstance)); } else { assertFalse(element.getGraphicalFilters().stream().anyMatch(HideFilter.class::isInstance)); } } private void performHideReveal(SWTBotGefEditPart swtBotEditPart, int i, String toolTip) { switch (i) { case 0: swtBotEditPart.doubleClick(); break; case 1: swtBotEditPart.contextMenu(toolTip).click(); break; case 2: swtBotEditPart.tabbarAction(toolTip).click(); break; } }
String pattern = IValueFormatConstants.DEFAULT_DATE_PATTERN; String input = "2019-01-18T12:42:03.409Z"; ScoutAssert.assertThrows(ParseException.class, () -> new SimpleDateFormat(pattern).parse(input)); ScoutAssert.assertThrows(ParseException.class, () -> new StrictSimpleDateFormat(pattern).parse(input)); pattern = IValueFormatConstants.TIMESTAMP_PATTERN; ScoutAssert.assertThrows(ParseException.class, () -> new SimpleDateFormat(pattern).parse(input)); ScoutAssert.assertThrows(ParseException.class, () -> new StrictSimpleDateFormat(pattern).parse(input));
package org.eclipse.jgit.lib; import static java.util.stream.Collectors.toList; import java.io.IOException; import java.util.ArrayList; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Set; import java.util.stream.Collectors; import org.eclipse.jgit.annotations.NonNull; import org.eclipse.jgit.annotations.Nullable; /** * Abstraction of name to {@link org.eclipse.jgit.lib.ObjectId} mapping. * <p> * A reference database stores a mapping of reference names to * {@link org.eclipse.jgit.lib.ObjectId}. Every * {@link org.eclipse.jgit.lib.Repository} has a single reference database, * mapping names to the tips of the object graph contained by the repository. * * @since 3.0 */ public abstract class RefDatabase { private static final String REFS = "refs"; private static final String HEAD = "HEAD"; private static final String TAGS = "tags"; private static final String REMOTES = "remotes"; private static final String REFS_TAGS = REFS + '/' + TAGS; private static final String REFS_REMOTES = REFS + '/' + REMOTES; private static final String REFS_HEADS = REFS + '/' + "heads"; private static final String REFS_REMOTES_PREFIX = REFS_REMOTES + '/'; private static final String REFS_TAGS_PREFIX = REFS_TAGS + '/'; private static final String REFS_HEADS_PREFIX = REFS_HEADS + '/'; private static final String REFS_HEAD = REFS + '/' + HEAD; private static final String REFS_HEAD_MASTER = REFS_HEADS_PREFIX + "master"; private static final String REFS_HEAD_DETACHED = REFS_HEADS + "/detached"; private static final String REFS_HEAD_DETACHED_PREFIX = REFS_HEAD_DETACHED + '/'; private static final String REFS_HEADS_MASTER = REFS_HEADS_PREFIX + "master"; private static final String REFS_HEADS_PREFIX_SHORT = "refs/heads/"; private static final String REFS_REMOTES_PREFIX_SHORT = "refs/remotes/"; private static final String REFS_TAGS_PREFIX_SHORT = "refs/tags/"; private static final String REFS_HEAD_MASTER_SHORT = "refs/heads/master"; private static final String REFS_HEAD_DETACHED_SHORT = "refs/heads
import java.io.IOException; import java.util.ArrayList; import java.util.Collections; import java.util.List; import org.eclipse.jgit.annotations.NonNull; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; /** * This class provides methods to retrieve references from a reference space. * * @since 5.2 */ @NonNull public class RefUtils { /** * Returns a list of references that have the given prefixes. * * @param prefixes the prefixes to match * @return a list of matching references * @throws IOException if the reference space cannot be accessed */ public List<Ref> getRefsByPrefix(String... prefixes) throws IOException { List<Ref> result = new ArrayList<>(); for (String prefix : prefixes) { result.addAll(getRefsByPrefix(prefix)); } return Collections.unmodifiableList(result); } /** * Returns all references that resolve directly to the given {@link ObjectId}. * Includes peeled {@link ObjectId}s. This is the inverse lookup of * {@link #exactRef(String...)}. * * <p> * The default implementation uses a linear scan. Implementors of {@link RefDatabase} should * override this method directly if a better implementation is possible. * * @param id the {@link ObjectId} to resolve * @return a {@link List} of {@link Ref}s whose tip points to the provided id * @throws IOException if the reference space cannot be accessed */ public List<Ref> getRefsByObjectId(ObjectId id) throws IOException { List<Ref> result = new ArrayList<>(); // Implementation goes here return Collections.unmodifiableList(result); } }
* Includes peeled {@link ObjectId}s. This is the inverse lookup if {@link #exactRef(String...)}. * The default implementation uses a linear scan. Implementors of {@link RefDatabase} should override this method directly if a better implementation is possible. * @param id {@link ObjectId} to resolve * @return a {@link Set} of {@link Ref}s whose tip points to the provided id. * @throws java.io.IOException the reference space cannot be accessed. * @since 5.3 */ @NonNull public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { return getRefs().stream() .filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())) .collect(Collectors.toSet()); } /** * Check if any refs exist in the ref database. * @return true if any refs exist, false otherwise. * @throws java.io.IOException the reference space cannot be accessed. */ public boolean hasRefs() throws IOException { return !getRefs().isEmpty(); }
import static java.util.stream.Collectors.toSet; ... /** * @return a {@link Set} of {@link Ref}s whose tip points to the provided * id. * @throws java.io.IOException * the reference space cannot be accessed. * @since 5.3 */ @NonNull public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { return getRefs().stream() .filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())) .collect(toSet()); } /** * Check if any refs exist in the ref database. * <p> * This uses the same definition of refs as {@link #getRefs()}. In * particular, returns {@code false} in a new repository with no refs * under {@code refs/} and {@code HEAD} pointing to a branch yet to be * born, and returns {@code true} in a repository with no refs under * {@code refs/} and a detached {@code HEAD} pointing to history. */
package org.eclipse.tracecompass.analysis.os.linux.core.inputoutput; import org.eclipse.jdt.annotation.Nullable; import org.eclipse.osgi.util.NLS; /** * Externalized message strings from the I/O Analysis * * @author Houssem Daoud */ public class Messages extends NLS { private static final String BUNDLE_NAME = "org.eclipse.linuxtools.lttng2.kernel.core.inputoutput.analysis.messages"; //$NON-NLS-1$ /** Help text for the Data provider */ public static @Nullable String DisksIODataProviderFactory_helpText; /** Help text for the IO analysis */ public static @Nullable String LttngInputOutputModule_Help; static { // initialize resource bundle NLS.initializeMessages(BUNDLE_NAME, Messages.class); } private Messages() { } }
import org.eclipse.osgi.util.NLS; /** * Externalized Strings for the ThreadStatusDataProvider package */ class Messages extends NLS { private static final String BUNDLE_NAME = "org.eclipse.tracecompass.internal.analysis.os.linux.core.threadstatus.messages"; //$NON-NLS-1$ /** attribute cpu name */ public static String ThreadStatusDataProvider_attributeCpuName; /** */ public static String ThreadStatusDataProviderFactory_title; /** DataProvider help text */ public static String ThreadStatusDataProviderFactory_descriptionText; static { // initialize resource bundle NLS.initializeMessages(BUNDLE_NAME, Messages.class); } private Messages() { } }
List<IDataProviderDescriptor> descriptors = new ArrayList<>(); Set<String> existingModules = new HashSet<>(); for (ISegmentStoreProvider module : modules) { IAnalysisModule analysis = (IAnalysisModule) module; if (!existingModules.contains(analysis.getId())) { DataProviderDescriptor.Builder builder = new DataProviderDescriptor.Builder(); builder.setId(encode(SegmentStoreScatterDataProvider.ID + ':' + analysis.getId())) .setName(Objects.requireNonNull(NLS.bind(Messages.SegmentStoreScatterGraphDataProvider_title, analysis.getName()))) .setDescription(Objects.requireNonNull(NLS.bind(Messages.SegmentStoreScatterGraphDataProvider_description, analysis.getName()))) .setProviderType(ProviderType.TREE_TIME_XY); descriptors.add(builder.build()); } } return descriptors;
private static void waitForShadowProjectUpdated(String parentProjectName) { for (int i = 1; i < 5000 && (TmfProjectModelHelper.getShadowProject(parentProjectName).exists()); i *= 2) { delay(i); } } public String getTypeName() { return "Insertion Feature"; } /* * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the * License for the specific language governing permissions and limitations under * the License. */ package com.google.gerrit.client; import com.google.gwt.core.client.EntryPoint; /** * Base class for writing Gerrit Web UI plugins * * Writing a plugin: * <ol> * <li>Declare subtype of Plugin</li> * <li>Bind WebUiPlugin.class to GwtWebUiPlugin implementation in Gerrit-Module class</li> * </ol> */ public abstract class Plugin implements EntryPoint { @Override public final void onModuleLoad() { // not used } /** * Initialize plugin */ protected abstract void init(); } return Status.OK_STATUS; public File getPath() { return path; } public boolean isDirty() { return false; } public InputStream read(String item, IProgressMonitor monitor) throws IOException { File file = getFile(item); return new FileInputStream(file); } public void release() { store.release(this); } public OutputStream write(String item, IProgressMonitor monitor) throws IOException { File file = getFile(item); return new BufferedOutputStream(new FileOutputStream(file)); } private File getFile(String item) { File file = new File(path, item); if (!file.getParentFile().exists()) { file.getParentFile().mkdirs(); } return file; }
package org.apache.hyracks.algebricks.core.algebra.operators.logical; import java.util.ArrayList; import java.util.List; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalOperator; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalPlan; import org.apache.hyracks.algebricks.core.algebra.base.LogicalVariable; public abstract class AbstractOperatorWithNestedPlans extends AbstractLogicalOperator { protected final List<ILogicalPlan> nestedPlans; public AbstractOperatorWithNestedPlans() { nestedPlans = new ArrayList<ILogicalPlan>(); } public AbstractOperatorWithNestedPlans(List<ILogicalPlan> nestedPlans) { this.nestedPlans = nestedPlans; } public List<ILogicalPlan> getNestedPlans() { return nestedPlans; } @Override public boolean hasNestedPlans() { return true; } } private List<AddressRangePosition> getAddressRangePositions(String category) { List<Position> list = getDocumentManagedPositions().get(category); @SuppressWarnings({ "unchecked", "cast", "rawtypes" }) private List<AddressRangePosition> getAddressRangePositions(String category) { List<Position> list = getDocumentManagedPositions().get(category); @SuppressWarnings({ "unchecked", "cast", "rawtypes" }) List<AddressRangePosition> addressRangePositions = (List<AddressRangePosition>) (List<?>) list; return addressRangePositions; } } import java.util.ArrayList; import java.util.List; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalOperator; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalPlan; import org.apache.hyracks.algebricks.core.algebra.base.LogicalVariable; public abstract class AbstractOperatorWithNestedPlans extends AbstractLogicalOperator { protected final List<ILogicalPlan> nestedPlans; public AbstractOperatorWithNestedPlans() { nestedPlans = new ArrayList<ILogicalPlan>(); } public AbstractOperatorWithNestedPlans(List<ILogicalPlan> nestedPlans) { this.nestedPlans = nestedPlans; } public List<ILogicalPlan> getNestedPlans() { return nestedPlans; } @Override public boolean has
if (!destinationFile.exists()) { destinationFile.mkdirs(); } while (entries.hasMoreElements()) { ZipEntry entry = entries.nextElement(); File outputFile = new File(destinationFile, entry.getName()); if (entry.isDirectory() && !outputFile.exists()) { outputFile.mkdirs(); continue; } if (!outputFile.getParentFile().exists()) { outputFile.getParentFile().mkdirs(); } try (InputStream inputStream = new BufferedInputStream(zipFile.getInputStream(entry)); OutputStream outStream = new BufferedOutputStream(new FileOutputStream(outputFile))) { copyStream(inputStream, outStream); } outputFiles.add(outputFile); if (monitor != null) { monitor.worked(1); } } return outputFiles; } private static void copyStream(InputStream in, OutputStream out) throws IOException { Assert.isNotNull(in); Assert.isNotNull(out); byte[] buffer = new byte[4096]; int readCount; while ((readCount = in.read(buffer)) != -1) { out.write(buffer, 0, readCount); } }
private final CommonStore store; public CommonStorable(CommonStore store, File path) { this.store = store; this.path = path; } public void delete(String item) throws CoreException { getFile(item).delete(); } public void deleteAll() throws CoreException { File[] children = path.listFiles(); if (children != null) { // validate for (File child : children) { if (child.isDirectory()) { throw new CoreException(new Status(IStatus.ERROR, CommonsCorePlugin.ID_PLUGIN, NLS.bind("The storage location ''{0}'' contains sub directories", path))); //$NON-NLS-1$ } } // delete all files for (File child : children) { child.delete(); } } if (path.exists()) { path.delete(); } } public boolean exists(String handle) { if (!path.exists()) { return false; } return getFile(handle).exists(); } public IStatus flush() { return Status.OK_STATUS; }
public static void createZipFile(File zipFile, List<File> files, String rootPath, IProgressMonitor monitor) throws FileNotFoundException, IOException { if (rootPath == null) { rootPath = ""; } else if (!rootPath.endsWith("\\") || !rootPath.endsWith("/")) { rootPath += "/"; } try (ZipOutputStream zipOut = new ZipOutputStream(new BufferedOutputStream(new FileOutputStream(zipFile)))) { for (File file : files) { try { addZipEntry(zipOut, rootPath, file); if (monitor != null) { monitor.worked(1); } } catch (Exception e) { StatusHandler.log(new Status(IStatus.ERROR, ICommonsCoreConstants.ID_PLUGIN, "Could not add " + file.getName() + " to zip", e)); } } } }
public static String changeSeparator(String path, char oldSeparator, char newSeparator) { return path.replace(oldSeparator, newSeparator); } public static void copy(File source, File dest) throws IOException { try (InputStream in = new FileInputStream(source); OutputStream out = new BufferedOutputStream(new FileOutputStream(dest))) { transferData(in, out); } } public static void copyFolder(File sourceFolder, File targetFolder) throws IOException { for (File currFile : sourceFolder.listFiles()) { if (currFile.isFile()) { File destFile = new File(targetFolder, currFile.getName()); copy(currFile, destFile); } } }
package org.eclipse.mylyn.monitor.core; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; import org.eclipse.core.runtime.IStatus; import org.eclipse.core.runtime.Status; import org.eclipse.mylyn.commons.core.StatusHandler; import org.eclipse.mylyn.internal.monitor.core.IMonitorCoreConstants; /** * Used for logging interaction events. * * @author Mik Kersten * @since 2.0 */ public abstract class AbstractMonitorLog { protected File outputFile; protected FileOutputStream outputStream; protected boolean started = false; public AbstractMonitorLog() { super(); } public void startMonitoring() { synchronized (this) { if (started) { return; } else { started = true; } } try { if (!outputFile.exists()) { outputFile.createNewFile(); } outputStream = new FileOutputStream(outputFile, true); } catch (Exception e) { StatusHandler.log(new Status(IStatus.ERROR, IMonitorCoreConstants.ID_PLUGIN, "Failed to start monitoring", e)); } } }
public void dispose() { fExpressionHistory.dispose(); fLocalExpressionHistory.clear(); if (fDocumentListener != null && getSourceViewer() != null && getSourceViewer().getDocument() != null) { getSourceViewer().getDocument().removeDocumentListener(fDocumentListener); } fListeners.clear(); super.dispose(); }
DNode element = (DNode) ((Node) part.getModel()).getElement(); assertFalse("The node should not have its label filtered.", element.getGraphicalFilters().stream().anyMatch(HideLabelFilter.class::isInstance)); activateShowHideModeUsingTabbar(); SWTBotGefEditPart swtBotEditPart = getEditPart("new EClass 4", DNodeNameEditPart.class); hideShow(element, swtBotEditPart, true); private void hideShow(DDiagramElement element, SWTBotGefEditPart swtBotEditPart, boolean isLabelHidden) { int count = 0; if (!isLabelHidden) { count = 2; } }
Diagram data = (Diagram) annotationEntry.getData(); Optional<?> missingNode = data.getChildren().stream().filter(child -> "_Sx9-MCLeEemN0s24dvRntQ".equals(((IdentifiedElement) ((Node) child).getElement()).getUid())).findFirst(); assertFalse("GMF cleaning has not been done while refreshing representation.", missingNode.isPresent()); @Override protected void tearDown() throws Exception { /* Delete the temporary project */ super.tearDown(); }
package org.eclipse.osee.framework.jdk.core.type; import java.util.ArrayList; import java.util.Collection; import java.util.List; public class TreeNode<TreeType> { private TreeType myself; private TreeNode<TreeType> parent; private List<TreeNode<TreeType>> children; protected TreeNode(TreeNode<TreeType> parent, TreeType myself) { this.parent = parent; this.myself = myself; this.children = new ArrayList<>(); } public TreeNode(TreeType myself) { this(null, myself); } @SuppressWarnings("null") public TreeNode() { this(null); } public TreeNode<TreeType> getParent() { return parent; } public TreeType getSelf() { return myself; } public List<TreeNode<TreeType>> getChildren() { return children; } }
import java.util.List; import java.util.Objects; import java.util.function.Function; import java.util.function.Predicate; import org.eclipse.tracecompass.internal.tmf.analysis.xml.core.fsm.model.values.DataDrivenValue; import org.eclipse.tracecompass.internal.tmf.analysis.xml.core.fsm.module.IAnalysisDataContainer; import org.eclipse.tracecompass.statesystem.core.ITmfStateSystem; import org.eclipse.tracecompass.tmf.core.event.ITmfEvent; public interface DataDrivenCondition extends IDataDrivenRuntimeObject { /** * Condition operators used to compare 2 values together */ public enum ConditionOperator implements Predicate<Integer> { /** equal */ EQ(i -> i == 0), /** not equal */ NE(i -> i != 0), /** Greater or equal */ GE(i -> i >= 0), /** Greater than */ GT(i -> i > 0), /** Less or equal */ LE(i -> i <= 0), /** Less than */ LT(i -> i < 0); } }
private static String[] getProtocolsToKeep(final String[] enabledProtocols) { final List<String> remainingProtocols = new ArrayList<String>(); for (final String protocol : enabledProtocols) { if (protocol.equals(SSLV3) || protocol.equals(SSLV2_HELLO)) { continue; } remainingProtocols.add(protocol); } if (remainingProtocols.isEmpty()) { throw new IllegalStateException("No other protocol allowed"); } return remainingProtocols.toArray(new String[remainingProtocols.size()]); }
final SSLContext context = SSLContext.getInstance("TLS"); //$NON-NLS-1$ context.init(ServerKeyStoreManager.getInstance().getKeyManagerFactory().getKeyManagers(), null, null); serverSocketFactory = context.getServerSocketFactory(); } catch (final NoSuchAlgorithmException exception) { shutdown(serverSocketFactory, exception); } catch (final KeyManagementException exception) { shutdown(serverSocketFactory, exception); } catch (final ServerKeyStoreException exception) { shutdown(serverSocketFactory, exception); } return disableSSLv3AndReturn(serverSocketFactory.createServerSocket(pPort, backlog, addr)); private void shutdown(SSLServerSocketFactory serverSocketFactory, Exception e) { if (serverSocketFactory == null) { ModelUtil.logException(Messages.XmlRpcBuiltinWebServer_ServerSocketInitFailed, e); EMFStoreController.getInstance().shutdown(new FatalESException()); } }
private static final String TAG_SELECTION = "selection"; //$NON-NLS-1$ private static final String TAG_EXPANDED = "expanded"; //$NON-NLS-1$ private static final String TAG_ELEMENT = "element"; //$NON-NLS-1$ private static final String TAG_IS_ENABLED = "isEnabled"; //$NON-NLS-1$ private static final String TAG_PATH = "path"; //$NON-NLS-1$ private static final String TAG_CURRENT_FRAME = "currentFrame"; //$NON-NLS-1$ private EmptyWorkspaceHelper emptyWorkspaceHelper; private IPartListener partListener = new IPartListener() { @Override public void partActivated(IWorkbenchPart part) { if (part instanceof IEditorPart) { editorActivated((IEditorPart) part); } } @Override public void partBroughtToTop(IWorkbenchPart part) { if (part instanceof IEditorPart) { editorActivated((IEditorPart) part); } } @Override public void partClosed(IWorkbenchPart part) { } @Override public void partDeactivated(IWorkbenchPart part) { } @Override public void partOpened(IWorkbenchPart part) { } };
private static final String MEMENTO_REGEXP_FILTER_REGEXP_ATTRIBUTE = "regexp"; private static final String MEMENTO_REGEXP_FILTER_ENABLED_ATTRIBUTE = "enabled"; private int rootMode; private String workingSetLabel; private List<UserFilter> userFilters; private EmptyWorkspaceHelper emptyWorkspaceHelper; @Override public void init(IViewSite site, IMemento memento) throws PartInitException { super.init(site, memento); userFilters = new ArrayList<UserFilter>(); if (memento != null) { IMemento[] filters = memento.getChildren(MEMENTO_REGEXP_FILTER_ELEMENT); for (IMemento filterMemento : filters) { String regexp = filterMemento.getString(MEMENTO_REGEXP_FILTER_REGEXP_ATTRIBUTE); Boolean enabled = filterMemento.getBoolean(MEMENTO_REGEXP_FILTER_ENABLED_ATTRIBUTE); userFilters.add(new UserFilter(regexp, enabled)); } } } @Override public void saveState(IMemento aMemento) { // Code for saving state }
public void createPartControl(Composite aParent) { emptyWorkspaceHelper = new EmptyWorkspaceHelper(aParent); super.createPartControl(aParent); getCommonViewer().setMapper(new ResourceToItemsMapper(getCommonViewer())); getCommonViewer().setData(NavigatorPlugin.RESOURCE_REGEXP_FILTER_DATA, this.userFilters); if (this.userFilters.stream().anyMatch(UserFilter::isEnabled)) { getCommonViewer().refresh(); } }
private final Map<EPackage, String> packageToInferedSource = new LinkedHashMap<EPackage, String>(); private final Map<EPackage, Text> packageToSourceText = new LinkedHashMap<EPackage, Text>(); private final Map<EPackage, Text> packageToTargetText = new LinkedHashMap<EPackage, Text>(); private final Map<EPackage, Button> packageToUpdateButton = new LinkedHashMap<EPackage, Button>(); private final Pattern VERSION_NUMBER_PATTERN = Pattern.compile("(?<=\\bv?|[-_])\\d+\\b"); private final List<EPackage> packages; private final Set<EPackage> changedPackages; protected ReleaseWizardPage(String pageName, String description, ImageDescriptor titleImage, List<EPackage> packages, Set<EPackage> changedPackages) { super(pageName, pageName, titleImage); setDescription(description); this.packages = packages; }
IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { PlatformUI.getWorkbench().getDisplay().asyncExec(() -> { Display.getDefault().timerExec(200, switchTopControlRunnable); }); return; } } }
public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions = null; private IAction newProjectAction = null; public EmptyWorkspaceHelper(Composite parent) { // code implementation } }
public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions = null; private IAction newProjectAction = null; public EmptyWorkspaceHelper(Composite parent) { displayArea = parent; layout = new StackLayout(); displayArea.setLayout(layout); createEmptyArea(displayArea); } // Rest of the code... }
public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions; private IAction newProjectAction; public EmptyWorkspaceHelper(Composite parent) { displayArea = parent; layout = new StackLayout(); displayArea.setLayout(layout); createEmptyArea(displayArea); registerListeners(); } // ... }
public void setNonEmptyControl(Control control) { this.control = control; emptyArea.setBackground(control.getBackground()); switchTopControl(); }
public void dispose() { parentControl.addDisposeListener(e -> { PlatformUI.getWorkbench().getActiveWorkbenchWindow().removePerspectiveListener(this); ResourcesPlugin.getWorkspace().removeResourceChangeListener(this); JFaceResources.getColorRegistry().removeListener(this); }); }
private void readProjectWizardActions() { IWorkbench wb = PlatformUI.getWorkbench(); IWorkbenchWindow win = wb.getActiveWorkbenchWindow(); IWorkbenchPage page = win.getActivePage(); String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { IWizardDescriptor wizardDesc = WorkbenchPlugin.getDefault().getNewWizardRegistry().findWizard(wizardId); if (wizardDesc == null) { continue; } String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(WorkbenchPlugin.getDefault().getNewWizardRegistry(), wizardId); projectWizardActions.add(action); } } } }
private void readProjectWizardActions() { IWorkbench wb = PlatformUI.getWorkbench(); IWorkbenchWindow win = wb.getActiveWorkbenchWindow(); IWorkbenchPage page = win.getActivePage(); String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { IWizardDescriptor wizardDesc = WorkbenchPlugin.getDefault().getNewWizardRegistry().findWizard(wizardId); if (wizardDesc == null) { continue; } String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(WorkbenchPlugin.getDefault().getNewWizardRegistry(), wizardId); projectWizardActions.add(action); } } } }
private boolean switchTopControl() { Control oldTop = layout.topControl; IProject[] projs = ResourcesPlugin.getWorkspace().getRoot().getProjects(); if (projs.length > 0) { if (!control.isDisposed()) { layout.topControl = control; } } else { layout.topControl = emptyArea; } return oldTop != layout.topControl; }
public void resourceChanged(IResourceChangeEvent event) { IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { Display.getDefault().asyncExec(() -> { Display.getDefault().timerExec(200, switchTopControlRunnable); return; }); } } } }
public void propertyChange(PropertyChangeEvent event) { if (JFacePreferences.HYPERLINK_COLOR.equals(event.getProperty())) { recreateEmptyArea(); } }
private Button createChangeAction() { final Button createChange = new Button("Create change"); createChange.setTitle("Create change directly in browser"); createChange.addClickHandler(new ClickHandler() { @Override public void onClick(ClickEvent event) { CreateChangeAction.call(createChange, getProjectKey().toString()); } }); return createChange; } public void reserveExact(int additional) { Preconditions.checkArgument(additional >= 0, "negative additional"); if (data.length - len >= additional) return; data = Arrays.copyOf(data, len + additional); } public Version(String version) { String[] parts = version.split("\\."); major = Integer.valueOf(parts[0]); if (parts[1] != null) { this.minor = Integer.valueOf(parts[1]); } if (parts[2] != null) { this.micro = Integer.valueOf(parts[2]); } } IWorkingSetManager workingSetManager = getPlugin().getWorkbench().getWorkingSetManager(); workingSetManager.removePropertyChangeListener(propertyChangeListener); if (collapseAllHandler != null) { collapseAllHandler.dispose(); } if (getActionGroup() != null) { getActionGroup().dispose(); } Control control = viewer.getControl(); if (dragDetectListener != null && control != null && control.isDisposed() == false) { control.removeListener(SWT.DragDetect, dragDetectListener); } emptyWorkspaceHelper.dispose(); super.dispose();
public final class EmptyWorkspaceHelper { /** * This class uses a stack layout to switch between the "original" composite of * the view and an additional composite given the user the explanatory text. * This text is displayed when no projects are in the workspace. Once projects * are created this class switches back to the "original" composite of the view. * * The explanatory text explains the current situation that no projects are * available and provides a list of options to create projects. This list * contains links to: * 1. Project creation wizards specific to the current perspective * 2. The "New Project Wizard" to allow creation of project of any type * * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown. * * This class also takes care of refreshing these links when the user switches * the perspective. */ }
private void dispose(Listener listener) { PlatformUI.getWorkbench().getActiveWorkbenchWindow().removePerspectiveListener(listener); ResourcesPlugin.getWorkspace().removeResourceChangeListener(listener); JFaceResources.getColorRegistry().removeListener(listener); parent.removeDisposeListener(listener); parent = null; }
String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { IWizardRegistry newWizardRegistry = WorkbenchPlugin.getDefault().getNewWizardRegistry(); IWizardDescriptor wizardDesc = newWizardRegistry.findWizard(wizardId); if (wizardDesc != null) { String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(newWizardRegistry, wizardId); projectWizardActions.add(action); } } } }
public void resourceChanged(IResourceChangeEvent event) { IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { PlatformUI.getWorkbench().getDisplay().asyncExec(() -> PlatformUI.getWorkbench().getDisplay().timerExec(200, switchTopControlRunnable)); return; } } } }
package org.eclipse.emfforms.spi.common.sort; import java.math.BigInteger; import java.util.Comparator; import java.util.regex.Matcher; import java.util.regex.Pattern; /** * A comparator for strings that compares numbers which are part of compared string as numbers and not as strings. * This allows string that are a mixture of numbers and text (e.g. house numbers) in an intuitive fashion. * For instance, plain string sorting sorts 200A greater than 1000A. This comparator sorts 1000A greater than 200A. * * @author Lucas Koehler * @since 1.20 */ public final class NumberAwareStringComparator implements Comparator<String> { private static final Pattern PATTERN = Pattern.compile("(\\D*)(\\d*)"); //$NON-NLS-1$ private static NumberAwareStringComparator instance; /** * @return the static {@link NumberAwareStringComparator} instance. */ }
private Action fOpenManifestAction; private Action fOpenSchemaAction; private Action fOpenSystemEditorAction; private Action fOpenClassFileAction; private Action fOpenTextEditorAction; private Action fSelectDependentAction; private Action fSelectInJavaSearchAction; private Action fSelectAllAction; private PDERefactoringAction fRefactorAction; private CollapseAllAction fCollapseAllAction; private DisabledFilter fHideExtEnabledFilter = new DisabledFilter(true); private DisabledFilter fHideExtDisabledFilter = new DisabledFilter(false); private WorkspaceFilter fHideWorkspaceFilter = new WorkspaceFilter(); private JavaFilter fJavaFilter = new JavaFilter(); private CopyToClipboardAction fCopyAction; private Clipboard fClipboard; private Object fRoot = null; class DisabledFilter extends ViewerFilter { boolean fEnabled; DisabledFilter(boolean enabled) { fEnabled = enabled; } @Override public boolean select(Viewer v, Object parent, Object element) { if (element instanceof IPluginModelBase) { IPluginModelBase model = (IPluginModelBase) element; return model.getUnderlyingResource() != null || model.isEnabled() != fEnabled; } return true; } }
boolean hideDisabledExternal = !settings.getBoolean(SHOW_EXDISABLED); if (hideWorkspace) { fTreeViewer.addFilter(fHideWorkspaceFilter); } if (hideEnabledExternal) { fTreeViewer.addFilter(fHideExtEnabledFilter); } if (hideDisabledExternal) { fTreeViewer.addFilter(fHideExtDisabledFilter); } fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); Job.createSystem("", monitor -> { PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> { fSourcePluginFilter = new SourcePluginFilter(state); fTreeViewer.addFilter(fSourcePluginFilter); }); } }).schedule();
boolean hideEnabledExternal = settings.getBoolean(HIDE_EXENABLED); boolean hideDisabledExternal = !settings.getBoolean(SHOW_EXDISABLED); if (hideWorkspace) { fTreeViewer.addFilter(fHideWorkspaceFilter); } if (hideEnabledExternal) { fTreeViewer.addFilter(fHideExtEnabledFilter); } if (hideDisabledExternal) { fTreeViewer.addFilter(fHideExtDisabledFilter); } fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); if (PDECore.getDefault().getModelManager().isInitialized()) { PDEState state = PDECore.getDefault().getModelManager().getState(); fSourcePluginFilter = new SourcePluginFilter(state); } else { Job.createSystem("", monitor -> { PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> { fSourcePluginFilter = new SourcePluginFilter(state); }); } }).schedule(); }
private long size = 0; private Path tmpFile; public CleanFilter(Repository db, InputStream in, OutputStream out) throws IOException { super(in, out); lfsUtil = new LfsUtil(db.getDirectory().toPath().resolve("lfs")); Files.createDirectories(lfsUtil.getLfsTmpDir()); tmpFile = lfsUtil.createTmpFile(); this.out = out; } return rule; private final Map<Project.NameKey, ProjectState> all; private final ProjectCache projectCache; private final CapabilityControl.Factory capabilityControlFactory; private final ChangeControl.AssistedFactory changeControlFactory; private final PermissionCollection.Factory sectionSorter; private final InMemoryRepositoryManager repoManager; private final GroupControl.Factory controlFactory; private final GroupJson json; private final Provider<ListIncludedGroups> listIncludes; private final AllProjectsName allProjectsName = new AllProjectsName("All-Projects"); private final ProjectConfig allProjects; @SuppressWarnings("unchecked") public Util() { all = new HashMap<>(); repoManager = new InMemoryRepositoryManager(); try { Repository repo = repoManager.createRepository(allProjectsName); allProjects = new ProjectConfig(new Project.NameKey(allProjectsName.get())); allProjects.load(repo); allProjects.getLabelSections().put(CR.getName(), CR); add(allProjects); } catch (IOException | ConfigInvalidException e) { throw new RuntimeException(e); } projectCache = new ProjectCache() { @Override protected ProjectState get(Project.NameKey projectName) { return all.get(projectName); } }; } public ProjectTagsScreen(Project.NameKey toShow) { super(toShow); } fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); if (PDECore.getDefault().getModelManager().isInitialized()) { PDEState state = PDECore.getDefault().getModelManager().getState(); fSourcePluginFilter = new SourcePluginFilter(state); } else { Job.createSystem("", monitor -> { PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> { fSourcePluginFilter = new SourcePluginFilter(state); fTreeViewer.addFilter(fSourcePluginFilter); });
IContainer parent = tpdFile.getParent(); String fileName = tpdFile.getFullPath().removeFileExtension().addFileExtension("target").lastSegment(); IFile portableTargetFile = parent.getFile(new Path(fileName)); IFolder eclipseFolder = parent.getParent().getFolder(new Path(targetSuffix)); if (!eclipseFolder.exists()) { eclipseFolder.create(true, true, new NullProgressMonitor()); } IFile eclipseTargetFile = eclipseFolder.getFile(fileName.replaceAll("portable", targetSuffix)); InputStream convertedStream = convert(portableTargetFile.getContents(), "http://download.eclipse.org/", "file:/home/data/httpd/download.eclipse.org/"); convertedStream = convert(convertedStream, "https://download.eclipse.org/", "file:/home/data/httpd/download.eclipse.org/"); if (eclipseTargetFile.exists()) { eclipseTargetFile.setContents(convertedStream, IResource.NONE, null); } else { eclipseTargetFile.create(convertedStream, true, null); }
/** * Resolves the tip SHA1 of an ObjectId in the RefDatabase. * * @param id The ObjectId to resolve * @return A Set of Refs whose tips point to the provided id * @throws IOException If the reference space cannot be accessed * @since 5.3 */ @NonNull public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { return getRefs().stream() .filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())) .collect(toSet()); } /** * Checks if any refs exist in the ref database. * * This uses the same definition of refs as getRefs(). In particular, it returns false in a new repository with no refs under refs/ and HEAD pointing to a branch yet to be created. * * @return True if any refs exist, false otherwise * @throws IOException If the reference space cannot be accessed */ public boolean hasRefs() throws IOException { return !getRefs().isEmpty(); }
protected IStatus run(IProgressMonitor monitor) { Diagnostic result = converter.generateTargetDefinitionFile(tpdURI, new NullProgressMonitor()); if (result.getSeverity() >= Diagnostic.WARNING) { Activator.getDefault().getLog().log(BasicDiagnostic.toIStatus(result)); } try { file.getParent().refreshLocal(IResource.DEPTH_ONE, null); generateEclipseTarget(file); } catch (CoreException ex) { return new Status(IStatus.ERROR, Activator.PLUGIN_ID, "Unexpected exception", ex);//$NON-NLS-1$ } return BasicDiagnostic.toIStatus(result); }
public final class WidgetFactory { private WidgetFactory() { } public static ButtonFactory button(int style) { return ButtonFactory.newButton(style); } public static TextFactory text(int style) { return TextFactory.newText(style); } public static LabelFactory label(int style) { return LabelFactory.newLabel(style); } }
public void testUniqueLayoutData() { GridDataFactory gridDataFactory = GridDataFactory.fillDefaults().grab(true, false); TestFactory factory = TestFactory.newTest().layoutData(gridDataFactory::create); Label label = factory.create(shell); Label label2 = factory.create(shell); assertNotEquals(label.getLayoutData(), label2.getLayoutData()); }
public void testUniqueLayoutData() { GridDataFactory gridDataFactory = GridDataFactory.fillDefaults().grab(true, false); TestFactory factory = TestFactory.newTest().tooltip("toolTip").enabled(false).layoutData(gridDataFactory::create); Label label = factory.create(shell); Label label2 = factory.create(shell); assertNotSame(label.getLayoutData(), label2.getLayoutData()); }
indent.addSelectionListener(widgetSelectedAdapter(event -> { Spinner spinner = (Spinner) event.widget; styledText.setIndent(spinner.getSelection()); })); label = new Label(composite, SWT.NONE); label.setText(getResourceString("Spacing")); //$NON-NLS-1$ Spinner spacing = new Spinner(composite, SWT.BORDER); spacing.addSelectionListener(widgetSelectedAdapter(event -> { Spinner spinner = (Spinner) event.widget; styledText.setLineSpacing(spinner.getSelection()); })); // Button to Enable Mouse Navigator in StyledText Button enableMouseNavigator = new Button(composite, SWT.CHECK); enableMouseNavigator.setText(getResourceString("MouseNav")); enableMouseNavigator.addSelectionListener(widgetSelectedAdapter(event -> styledText.setMouseNavigatorEnabled(enableMouseNavigator.getSelection()))); coolItem = new CoolItem(coolBar, SWT.NONE); coolItem.setControl(composite); CoolItem[] coolItems = coolBar.getItems(); for (CoolItem item : coolItems) { Control control = item.getControl(); Point size = control.computeSize(SWT.DEFAULT, SWT.DEFAULT); item.setMinimumSize(size); }
private static String internalGetString(String key) { try { return RESOURCE_BUNDLE.getString(key); } catch (MissingResourceException e) { return '!' + key + '!'; } }
public String toString() { if (eObject == null) { return "<null>-" + side; } return eObject.eClass().getName() + '-' + side.getName(); }
public String toString() { return super.toString() + '-' + side.getName(); }
shortMessage += "..."; //$NON-NLS-1$ } // Get the author String author = null; if (lastCommit.getFullMessage().contains(Constants.SIGNED_OFF_BY_TAG)) { try { final String subSignedOff = lastCommit.getFullMessage().substring(lastCommit.getFullMessage().indexOf(Constants.SIGNED_OFF_BY_TAG) + Constants.SIGNED_OFF_BY_TAG.length()); author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; } catch (Exception e) { // Do nothing } } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } if (!shortMessage.isEmpty() && !author.isEmpty()) { constructName.append("("); //$NON-NLS-1$ if (!shortMessage.isEmpty()) { constructName.append("\""); //$NON-NLS-1$ constructName.append(shortMessage); constructName.append("\", "); //$NON-NLS-1$ } }
final String projectName = project.getName(); // Get the branch name final String fullBranchName = branch.getName(); final String shortBranchName = fullBranchName.substring(fullBranchName.indexOf(Constants.R_REMOTES) + Constants.R_REMOTES.length() + Constants.DEFAULT_REMOTE_NAME.length() + 1); final List<IProject> importedProject = new ArrayList<IProject>(1); try { new ProgressMonitorDialog(shell).run(true, false, monitor -> { monitor.beginTask(taskName, 6); try { // First, reset the current branch monitor.subTask("Reset the branch"); GitUtils.resetHardCurrentBranch(git); monitor.worked(1); // First, checkout the master branch (else we can't delete the other branch) monitor.subTask("Checkout the master"); GitUtils.checkoutExistingBranch(git, Constants.MASTER); monitor.worked(1); // Second, we have to delete local branch if exist monitor.subTask("Delete the local branch"); GitUtils.deleteLocalBranch(git, shortBranchName); monitor.worked(1); // Third, we have to delete remote branch if exist monitor.subTask("Delete the remote branch"); GitUtils.deleteRemoteBranch(git, Constants.DEFAULT_REMOTE_NAME, shortBranchName); monitor.worked(1); // Fourth, we have to import the project monitor.subTask("Import the project"); IProject imported = importProject(projectName, git, monitor); importedProject.add(imported); monitor.worked(1); // Fifth, we have to checkout the branch monitor.subTask("Checkout the branch"); GitUtils.checkoutExistingBranch(git, shortBranchName); monitor.worked(1); } catch (Exception e) { // Handle exception } finally { monitor.done(); } }); } catch (Exception e) { // Handle exception }
protected Element getRootElement(final Object selectedObject) { Element result = null; // Manage the possible selected file final IFile file = PapyrusFileUtils.getFile(selectedObject); if (null != file) { String fullPath = file.getFullPath().toString(); if (fullPath.endsWith("DomainsDefinition.uml")) { fullPath = fullPath.replace("DomainsDefinition.uml", ".uml"); } URI modelURI = URI.createPlatformResourceURI(fullPath, false); if (!"uml".equals(modelURI.fileExtension())) { modelURI = modelURI.trimFileExtension().appendFileExtension("uml"); } final ModelSet modelSet = new ModelSet(); final Resource resource = modelSet.getResource(modelURI, true); if (null != resource) { final EObject root = resource.getContents().get(0); if (root instanceof Element) { result = (Element) root; } } } // Manage other possibilities if (null == result && selectedObject instanceof IAdaptable) { // ... } return result; }
import java.text.SimpleDateFormat; import java.util.Date; public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); PersonIdent authorIdent = lastCommit.getAuthorIdent(); Date authorDate = authorIdent.getWhen(); SimpleDateFormat dateFormat = new SimpleDateFormat("dd-MM-yyyy HH:mm:ss"); return dateFormat.format(authorDate); } return "Not specified"; }
public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); PersonIdent authorIdent = lastCommit.getAuthorIdent(); Date authorDate = authorIdent.getWhen(); SimpleDateFormat dateFormat = new SimpleDateFormat("dd-MM-yyyy HH:mm:ss"); return dateFormat.format(authorDate); } return Messages.NotSpecified; }
final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); String author = null; if (lastCommit.getFullMessage().contains(Constants.SIGNED_OFF_BY_TAG)) { try { final String subSignedOff = lastCommit.getFullMessage().substring(lastCommit.getFullMessage().indexOf(Constants.SIGNED_OFF_BY_TAG) + Constants.SIGNED_OFF_BY_TAG.length()); author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; } catch (Exception e) { // Do nothing } } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } return author; } return "Unknown";
String author = null; try { String subSignedOff = lastCommit.getFullMessage().substring(lastCommit.getFullMessage().lastIndexOf("Signed-off-by:") + 14); author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; } catch (Exception e) { // Do nothing } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } return author != null && !author.isEmpty() ? author : "Unknown";
public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); return lastCommit.getShortMessage(); } return "Not specified"; }
package org.eclipse.papyrus.gitlight.git.data; import java.util.NoSuchElementException; import java.util.StringTokenizer; /** * This class represents the catalog version. */ public class CatalogVersion { protected int major; protected int minor; private final static String SEPARATOR = "."; public static final CatalogVersion emptyVersion = new CatalogVersion(0, 0); public CatalogVersion(final int major, final int minor) { updateVersion(major, minor); } public int getMajor() { return major; } public int getMinor() { return minor; } public void updateVersion(final int major, final int minor) { if (major < 0 || minor < 0) { throw new IllegalArgumentException("Version numbers must be positive"); } this.major = major; this.minor = minor; } public static CatalogVersion parseVersion(final String version) { StringTokenizer tokenizer = new StringTokenizer(version, SEPARATOR); try { int major = Integer.parseInt(tokenizer.nextToken()); int minor = Integer.parseInt(tokenizer.nextToken()); return new CatalogVersion(major, minor); } catch (NoSuchElementException e) { throw new IllegalArgumentException("Invalid version format: " + version); } catch (NumberFormatException e) { throw new IllegalArgumentException("Invalid version format: " + version); } } @Override public String toString() { return major + SEPARATOR + minor; } }
/** * The 'version' details name key. */ public static final String VERSION_DETAILS_NAME = "current"; /** * The master repository path. */ public static final String MASTER_REPOSITORY_PATH = Constants.DEFAULT_REMOTE_NAME + "/" + Constants.MASTER; /** * The contribution branch name prefix. */ public static final String CONTRIBUTION_BRANCH_PREFIX = "Review_"; /** * The initial commit message. */ public static final String INITIAL_COMMIT_MESSAGE = "Initial commit"; /** * The git folder. */ public static final String GIT_FOLDER = "\\" + Constants.DOT_GIT; /** * The change id. */ public static final String CHANGE_ID = "Change-Id: I0000000000000000000000000000000000000000"; }
public static void copyProject(final Git git, final IProject project) { final Repository repository = git.getRepository(); final URI gitPath = URI.createURI(repository.getWorkTree().toString().replace("\\", "/")); // Copy all project and sub files copySubFolder(project, gitPath); // Add this copied files to git addGitFiles(git, repository.getWorkTree(), ""); }
public static void copyFolder(final String source, final String dest) { final File srcFolder = getFolder(source); final File destFolder = getFolder(dest); if (srcFolder.exists()) { if (!destFolder.exists()) { destFolder.mkdir(); } // Copy sub folders and files for (final File subFile : srcFolder.listFiles()) { if (subFile.isDirectory()) { copyFolder(subFile.getAbsolutePath(), dest + "/" + subFile.getName()); } else { try { copyFile(subFile.getAbsolutePath(), dest + "/" + subFile.getName()); } catch (IOException e) { Activator.getLogHelper().error(e); } } } } }
package org.eclipse.papyrus.gitlight.review.profile; import org.eclipse.emf.common.EMFPlugin; import org.eclipse.emf.common.util.ResourceLocator; public final class Activator extends EMFPlugin { public static final Activator INSTANCE = new Activator(); private static Implementation plugin; private static class Implementation extends EclipsePlugin { public Implementation() { super(new ResourceLocator[] {}); } } public Activator() { super(new ResourceLocator[] {}); } public ResourceLocator getPluginResourceLocator() { return plugin; } }
/** * Finds the active shell and moves it to the end of the given array, so the * findControl() will find the controls from the active shell first */ private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } // find the index of the active shell and exchange last one with active int activeShellIndex = -1; for (int i = 0; i < shells.length; i++) { if (shells[i] == activeShell) { activeShellIndex = i; break; } } if (activeShellIndex != -1) { Shell temp = shells[lastIndex]; shells[lastIndex] = shells[activeShellIndex]; shells[activeShellIndex] = temp; } }
import org.eclipse.pde.internal.ui.wizards.plugin.NewProjectCreationOperation; import org.eclipse.pde.internal.ui.wizards.plugin.PluginContentPage; import org.eclipse.pde.internal.ui.wizards.plugin.PluginFieldData; import org.eclipse.ui.IWorkingSet; import org.eclipse.ui.PlatformUI; public class CreateNattableConfigurationWizard extends AbstractTableWizard { private static final String DOT = "."; //$NON-NLS-1$ private final TableConfiguration configuration; private Resource initialResource; private TableConfigurationHelper helper; private boolean isProjectCreation = false; } import org.eclipse.core.internal.resources.MarkerInfo; import java.io.UnsupportedEncodingException; import java.util.Iterator; import java.util.Map; import org.eclipse.core.internal.utils.*; import org.eclipse.core.runtime.Assert; import org.eclipse.osgi.util.NLS; public class MarkerInfo implements IMarkerSetElement, Cloneable, IStringPoolParticipant { protected static final Integer INTEGER_ONE = 1; protected static final Integer INTEGER_TWO = 2; protected static final Integer INTEGER_ZERO = 0; } protected Supplier<String> internalGetAttribute(String attr) { Widget widget = getWidget(); switch(attr){ case "style": return () -> swtStyles; case "class": return () -> Objects.toString(getCSSClass(widget), ""); case "swt-data-class": return () -> getSWTDataClass(widget); default: return null; } } public static Control findControl(Display displayToSearch, Point locationToFind) { Shell[] shells = displayToSearch.getShells(); fixShellOrder(displayToSearch, shells); return findControl(shells, locationToFind); } private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } for (int i = 0; i < shells.length; i++) { if (shells[i] == activeShell) { Shell temp = shells[lastIndex]; shells[lastIndex] = activeShell; shells[i] = temp; break; } } }
private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } // Find the index of the active shell and exchange the last one with the active shell for (int i = 0; i < shells.length; i++) { if (shells[i] == activeShell) { Shell toMove = shells[lastIndex]; shells[i] = toMove; shells[lastIndex] = activeShell; break; } } }
Fixed Code: ```java package org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model; import java.util.ArrayList; import java.util.List; public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; private final ITimeGraphEntry fEntry; private final long fTime; private final long fDuration; public TimeLineEvent(ITimeGraphEntry entry, long time, long duration) { this(entry, time, duration, new ArrayList<>()); } public TimeLineEvent(ITimeGraphEntry entry, long time, long duration, List<Long> values) { super(entry, time, duration); fEntry = entry; fTime = time; fDuration = duration; fValues = values; } public List<Long> getValues() { return fValues; } public ITimeGraphEntry getEntry() { return fEntry; } public long getTime() { return fTime; } public long getDuration() { return fDuration; } } ``` Refactored Code: ```java package org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model; import java.util.ArrayList; import java.util.List; public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; public TimeLineEvent(ITimeGraphEntry entry, long time, long duration) { this(entry, time, duration, new ArrayList<>()); } public TimeLineEvent(ITimeGraphEntry entry, long time, long duration, List<Long> values) { super(entry, time, duration); fValues = values; } public List<Long> getValues() { return fValues; } } ```
int columns = headers.length; sheetWriter.startSheet(setPrimary.getName(), headers.length); sheetWriter.writeRow((Object[]) headers); for (DispoItem item : items) { Map<String, MCDCCoverageData> mcdcToCoverageData = new HashMap<>(); List<DispoAnnotationData> annotations = item.getAnnotationsList(); for (DispoAnnotationData annotation : annotations) { writeRowAnnotation(sheetWriter, columns, item, annotation, setPrimary.getName(), levelToResolutionTypesToCount, leveltoUnitToCovered, mcdcToCoverageData, levelsInSet); } } sheetWriter.endSheet(); // START COVER SHEET sheetWriter.startSheet("Cover Sheet", headers.length); List<String> coverSheetHeadersList = new ArrayList<>(); coverSheetHeadersList.add(" "); if (levelsInSet.contains(CoverageLevel.A)) { coverSheetHeadersList.add("MCDC"); } if (levelsInSet.contains(CoverageLevel.B)) { coverSheetHeadersList.add("Branch"); }
import org.eclipse.equinox.http.servlet.internal.servlet.Match; import org.eclipse.equinox.http.servlet.internal.util.Const; import org.eclipse.equinox.http.servlet.internal.util.DispatchTargets; import org.eclipse.equinox.http.servlet.internal.util.RequestInfoDTO; import java.util.Set; public class ServletPathResolver { public DispatchTargets resolve(Set<ContextController> contextControllers, String requestURI, String extension, String queryString, Match match, RequestInfoDTO requestInfoDTO) { if (contextControllers.isEmpty()) { return null; } String contextPath = contextControllers.iterator().next().getContextPath(); requestURI = requestURI.substring(contextPath.length()); int pos = requestURI.lastIndexOf('/'); String servletPath = requestURI; String pathInfo = null; if (match == Match.CONTEXT_ROOT) { pathInfo = Const.SLASH; servletPath = Const.BLANK; } else if (match == Match.DEFAULT_SERVLET) { pathInfo = servletPath; servletPath = Const.SLASH; } do { for (ContextController contextController : contextControllers) { DispatchTargets dispatchTargets = contextController.getDispatchTargets(null, requestURI, servletPath, pathInfo, extension, queryString, match, requestInfoDTO); if (dispatchTargets != null) { return dispatchTargets; } } if ((match == Match.EXACT) || (match == Match.CONTEXT_ROOT) || (match == Match.DEFAULT_SERVLET)) { break; } if (pos > -1) { String newServletPath = requestURI.substring(0, pos); pathInfo = requestURI.substring(pos); servletPath = newServletPath; pos = newServletPath.lastIndexOf('/'); } else { break; } } while (true); return null; } }
// check for new pack files. If set to true (default) we use the // lastmodified attribute of the folder and assume that no new // pack files can be in this folder if his modification time has // not changed. boolean trustFolderStat = config.getBoolean( ConfigConstants.CONFIG_CORE_SECTION, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, true ); if (force || (!trustFolderStat) || old.snapshot.isModified(packDirectory)) { PackList newList = scanPacks(old, force); return old != newList; } return false;
private static final int MENU_DELETE = 3; private static final int MENU_DIAL = 4; private static final String INTENT_EXTRA_NAME = "name"; private static final String INTENT_EXTRA_NUMBER = "number"; private static final Uri FDN_CONTENT_URI = Uri.parse("content://icc/fdn"); private static final String FDN_CONTENT_PATH_WITH_SUB_ID = "content://icc/fdn/subId/"; private SubscriptionInfoHelper mSubscriptionInfoHelper; private PersistableBundle carrierConfig; private Phone mPhone; private boolean mFdnDialDirectlySupported = false; @Override public void onCreate(Bundle icicle) { super.onCreate(icicle); ActionBar actionBar = getActionBar(); if (actionBar != null) { actionBar.setDisplayHomeAsUpEnabled(true); } mSubscriptionInfoHelper = new SubscriptionInfoHelper(this, getIntent()); mSubscriptionInfoHelper.setActionBarTitle(getActionBar(), getResources(), R.string.fdn_list_with_label); mPhone = mSubscriptionInfoHelper.getPhone(); carrierConfig = PhoneGlobals.getInstance().getCarrierConfigForSubId(mPhone.getSubId()); }
private final Map<String, Object> nameMap; public CapabilityIndex(Iterator<IInstallableUnit> itor) { nameMap = new HashMap<>(300); namespaceMap = new HashMap<>(10); while (itor.hasNext()) { IInstallableUnit iu = itor.next(); Collection<IProvidedCapability> pcs = iu.getProvidedCapabilities(); for (IProvidedCapability pc : pcs) { namespaceMap.computeIfAbsent(pc.getNamespace(), n -> new HashSet<>()).add(iu); nameMap.compute(pc.getName(), (n, v) -> { if (v == null || v == iu) { return iu; } else if (v instanceof IInstallableUnit) { Collection<IInstallableUnit> list = new HashSet<>(); list.add((IInstallableUnit) v); list.add(iu); return list; } else { ((Collection<IInstallableUnit>) v).add(iu); return v; } }); } } } private Object getRequirementIDs(IEvaluationContext ctx, IExpression requirement, Object queriedKeys) { switch (requirement.getExpressionType()) { case IExpression.TYPE_AND : // rest of the code } }
private static void collectMatchingIUs(Map<String, ?> indexToUse, String name, Collection<IInstallableUnit> collector) { Object v = indexToUse.get(name); if (v == null) return; if (v instanceof IInstallableUnit) collector.add((IInstallableUnit) v); else collector.addAll((Collection<IInstallableUnit>) v); }
private void validatePage() { String message = null; if (userText.getText().trim().isEmpty()) { message = Messages.CredentialsWizardPage_ErrorUser; } else if (passwordText.getText().trim().isEmpty()) { message = Messages.CredentialsWizardPage_ErrorPassword; } setErrorMessage(message); setPageComplete(message == null); }
private static DiffPreferencesInfo updateDefaults(DiffPreferencesInfo input) { DiffPreferencesInfo result = DiffPreferencesInfo.defaults(); try { for (Field field : update.getClass().getDeclaredFields()) { if (skipField(field)) { continue; } Object newVal = field.get(update); if (newVal != null) { field.set(def, newVal); } } } catch (IllegalAccessException e) { e.printStackTrace(); } return def; } public UUID getAnonymousId() { UUID result = anonymousId; if (result == null) { synchronized (this) { result = anonymousId; if (result == null) { result = anonymousId = readOrCreateAnonymousId(); } } } return result; } while (itor.hasNext()) { IInstallableUnit iu = itor.next(); Collection<IProvidedCapability> pcs = iu.getProvidedCapabilities(); for (IProvidedCapability pc : pcs) { namespaceMap.computeIfAbsent(pc.getNamespace(), n -> new HashSet<>()).add(iu); nameMap.compute(pc.getName(), (n, v) -> { if (v == null || v == iu) { return iu; } else if (v instanceof IInstallableUnit) { Collection<IInstallableUnit> list = new HashSet<>(); list.add((IInstallableUnit) v); list.add(iu); return list; } else { ((Collection<IInstallableUnit>) v).add(iu); return v; } }); } } private Object getRequirementIDs(IEvaluationContext ctx, IExpression requirement, Object queriedKeys) { switch (requirement.getExpressionType()) { case IExpression.TYPE_AND: // AND is OK if at least one of the branches require the queried key for (IExpression expr : ExpressionUtil.getOperands(requirement)) { // code for handling the requirement } // code for handling other expression types } }
public void createArtifact(@Nullable ArtifactToken parent, ArtifactToken artifact) { ArtifactToken art = createArtifact(artifact); if (parent != null) { addChild(parent, art); } }
public boolean post(Event event) { Lock lock = OS.lock; lock.lock(); try { synchronized (Device.class) { if (isDisposed()) error(SWT.ERROR_DEVICE_DISPOSED); if (event == null) error(SWT.ERROR_NULL_ARGUMENT); if (!OS.IS_X11) { return false; } long /*int*/ xDisplay = OS.gdk_x11_display_get_xdisplay(OS.gdk_display_get_default()); int type = event.type; switch (type) { case SWT.KeyDown: case SWT.KeyUp: { int keyCode = 0; long /*int*/ keysym = untranslateKey(event.keyCode); if (keysym != 0) keyCode = OS.XKeysymToKeycode(xDisplay, keysym); if (keyCode == 0) { char key = event.character; ... } ... } ... } } } finally { lock.unlock(); } }
import org.eclipse.uml2.uml.Type; import org.eclipse.uml2.uml.UMLFactory; import org.eclipse.uml2.uml.UMLPackage; /** * Utility class for <code>org.eclipse.uml2.uml.Package</code><BR> */ public class PackageUtil { /** * Extension of UML models (also declared in class UmlModel. This class is not accessible here, * since oep.uml.tools depends on oep.uml.tools.utils, but not vice versa */ public static final String UML_EXT = org.eclipse.papyrus.uml.tools.model.UmlModel.UML_FILE_EXTENSION; /** * Apply a profile and every subprofiles to a package. Also import types defined in profile * * @param profileToApply profile to apply on package * @param package_ on which profiles are applied * @param withSubProfiles true if subprofiles must be automatically imported * @return true if the model was modified */ public static boolean applyProfile(org.eclipse.uml2.uml.Package package_, org.eclipse.uml2.uml.Profile profileToApply, boolean withSubProfiles) { // Returns true if the model was modified // ... } }
public static Package getUserModel(ExecutionEvent event) { ServiceUtilsForHandlers serviceUtils = ServiceUtilsForHandlers.getInstance(); try { ModelSet modelSet = serviceUtils.getModelSet(event); URI uri = modelSet.getURIWithoutExtension().appendFileExtension(UML_EXT); Resource userResource = modelSet.getResource(uri, false); if (userResource != null && userResource.getContents().size() > 0) { EObject topEObj = userResource.getContents().get(0); if ((topEObj instanceof Package) && (!(topEObj instanceof Profile))) { return (Package) topEObj; } } } catch (ServiceException e) { Activator.log.error(e); } return null; }
breakStatement.setSourceRange(statement.sourceStart, statement.sourceEnd - statement.sourceStart + 1); if (statement.label != null) { final SimpleName name = new SimpleName(this.ast); name.internalSetIdentifier(new String(statement.label)); retrieveIdentifierAndSetPositions(statement.sourceStart, statement.sourceEnd, name); breakStatement.setLabel(name); } else if (statement.expression != null && this.ast.apiLevel >= AST.JLS12_INTERNAL) { final Expression expression = convert(statement.expression); breakStatement.setExpression(expression); int sourceEnd = retrieveSemiColonPosition(expression); if (sourceEnd == -1) { breakStatement.setSourceRange(statement.sourceStart, statement.sourceEnd - statement.sourceStart + 2); } else { breakStatement.setSourceRange(statement.sourceStart, sourceEnd - statement.sourceStart + 1); } } return breakStatement;
private void disposeIfExited(final Control control, MouseEvent e) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt)) { tipShell.dispose(); } } }
Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt)) { tipShell.dispose(); } }
imgData.type = getImageFormat(loader); imgDataList.add(imgData); } else { long /*int*/ start_time = OS.g_malloc(8); OS.g_get_current_time(start_time); long /*int*/ animation_iter = GDK.gdk_pixbuf_animation_get_iter(pixbuf_animation, start_time); int delay_time = 0; int time_offset = 0; int num_frames = 32; for (int i = 0; i < num_frames; i++) { delay_time = GDK.gdk_pixbuf_animation_iter_get_delay_time(animation_iter); time_offset += delay_time; OS.g_time_val_add(start_time, time_offset * 1000); boolean update = GDK.gdk_pixbuf_animation_iter_advance(animation_iter, start_time); if (update) { long /*int*/ curr_pixbuf = GDK.gdk_pixbuf_animation_iter_get_pixbuf(animation_iter);
delay_time = GDK.gdk_pixbuf_animation_iter_get_delay_time(animation_iter); time_offset += delay_time; OS.g_time_val_add(start_time, time_offset * 1000); boolean update = GDK.gdk_pixbuf_animation_iter_advance(animation_iter, start_time); if (update) { long /*int*/ curr_pixbuf = GDK.gdk_pixbuf_animation_iter_get_pixbuf(animation_iter); long /*int*/ pixbuf_copy = GDK.gdk_pixbuf_copy(curr_pixbuf); ImageData imgData = pixbufToImageData(pixbuf_copy); if (this.logicalScreenHeight == 0 && this.logicalScreenWidth == 0) { this.logicalScreenHeight = imgData.height; this.logicalScreenWidth = imgData.width; } imgData.type = getImageFormat(loader); imgData.delayTime = delay_time; imgDataList.add(imgData); } else { break; } } ImageData[] imgDataArray = new ImageData[imgDataList.size()];
public ImageData[] load(String filename) { if (filename == null) { SWT.error(SWT.ERROR_NULL_ARGUMENT); } InputStream stream = null; try { stream = new FileInputStream(filename); return load(stream); } catch (IOException e) { SWT.error(SWT.ERROR_IO, e); } finally { try { if (stream != null) { stream.close(); } } catch (IOException e) { // Ignore error } } return null; }
static long /*int*/ gdk_pixbuf_new_from_file(String filename) { int length = filename.length(); char[] chars = new char[length]; filename.getChars(0, length, chars, 0); byte[] buffer = Converter.wcsToMbcs(chars, true); long /*int*/ pixbuf = GDK.gdk_pixbuf_new_from_file(buffer, null); return pixbuf; } static long /*int*/ imageDataToPixbuf(ImageData imgData) { int colorspace = GDK.GDK_COLORSPACE_RGB; boolean has_alpha = imgData.alphaData != null; int width = imgData.width; int height = imgData.height; int rowstride = imgData.scanlinePad; long /*int*/ buffer_ptr = OS.g_malloc(imgData.data.length); C.memmove(buffer_ptr, imgData.data, imgData.data.length); long /*int*/ pixbuf = GDK.gdk_pixbuf_new_from_data(buffer_ptr, colorspace, has_alpha, 8, width, height, rowstride, null, null); return pixbuf; }
long /*int*/ [] len = new long /*int*/ [1]; if (type == null) SWT.error(SWT.ERROR_UNSUPPORTED_FORMAT); GDK.gdk_pixbuf_save_to_bufferv(pixbuf, buffer, len, type, null, null, null); byte[] byteArray = new byte[(int) len[0]]; C.memmove(byteArray, buffer[0], byteArray.length); try { stream.write(byteArray); } catch (IOException e) { SWT.error(SWT.ERROR_IO); } // FileFormat.save(stream, format, this);
/** * Abstract tool tip handler. * * @since 3.2 * @author Loic Prieur-Drevon - extracted from {@link TimeGraphTooltipHandler} */ public abstract class TmfAbstractToolTipHandler { private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; /** * Important note: this is being added to a display filter, this may leak, * make sure it is removed when not needed. */ private final Listener fListener = event -> { Shell tipShell = fTipShell; if (tipShell != null) { disposeIfExited(tipShell, event); } }; private void disposeIfExited(final Control control, Event e) { if (!control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { // Check if the mouse pointer is outside the tool tip shell if (!bounds.contains(pt)) { control.getDisplay().asyncExec(() -> { if (!control.isDisposed()) { control.dispose(); } }); } } } } } /** * Dispose the tool tip shell and remove the listener. */ public void dispose() { if (fTipShell != null && !fTipShell.isDisposed()) { fTipShell.dispose(); } if (fTipComposite != null && !fTipComposite.isDisposed()) { fTipComposite.dispose(); } Display.getDefault().removeFilter(SWT.MouseMove, fListener); } }
private void disposeIfExited(final Control control, Event e) { if (!control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); } }
Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); }
createTooltipShell(timeGraphControl.getShell()); for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { // avoid displaying empty tool tips. return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); Display.getDefault().addFilter(SWT.MouseExit, fListener);
public static void beforeClass() { SWTBotUtils.initialize(); Thread.currentThread().setName("SWTBotTest"); /* set up for swtbot */ SWTBotPreferences.TIMEOUT = 60000; /* 60 second timeout */ SWTBotPreferences.KEYBOARD_LAYOUT = "EN_US"; SWTWorkbenchBot bot = new SWTWorkbenchBot(); SWTBotUtils.closeView("welcome", bot); /* Finish waiting for eclipse to load */ WaitUtils.waitForJobs(); /* Create project */ SWTBotUtils.createProject(PROJECT_NAME); }
checkWidget(); if (listener == null) error(SWT.ERROR_NULL_ARGUMENT); if (eventTable == null) return; eventTable.unhook(SWT.Verify, listener); } @Override GdkRGBA getContextBackgroundGdkRGBA() { if (background != null && (state & BACKGROUND) != 0) { return background; } return defaultBackground(); } @Override void setBackgroundGdkRGBA(long /*int*/ context, long /*int*/ handle, GdkRGBA rgba) { if (GTK.GTK4) { background = rgba; super.setBackgroundGdkRGBA(context, handle, rgba); } else { if (rgba == null) { background = defaultBackground(); } else { background = rgba; } String css; String properties; String name; name = GTK.GTK_VERSION >= OS.VERSION(3, 20, 0) ? "spinbutton" : "GtkSpinButton"; String color = display.gtk_rgba_to_css_string(background); css = name + " { " + color + " }"; properties = "* { " + color + " }"; OS.gtk_widget_override_background_color(handle, GTK.GTK_STATE_FLAG_NORMAL, rgba); OS.gtk_widget_override_color(handle, GTK.GTK_STATE_FLAG_NORMAL, rgba); OS.gtk_css_provider_load_from_data(OS.gtk_widget_get_style_context(handle), Converter.wcsToMbcs(css, true), -1, null); OS.gtk_css_provider_load_from_data(OS.gtk_widget_get_style_context(handle), Converter.wcsToMbcs(properties, true), -1, null); } }
Buggy Code: ```java public void run() { try { Thread.sleep(2000); try { Libcore.os.shutdown(dc.socket().getFileDescriptor$(), OsConstants.SHUT_RDWR); } catch (ErrnoException expected) { assertEquals(OsConstants.ENOTCONN, expected.errno); } } catch (Exception ex) { fail(ex.getMessage()); } } ``` Fixed Code: ```java public void run() { try { Thread.sleep(2000); try { Libcore.os.shutdown(dc.socket().getFileDescriptor$(), OsConstants.SHUT_RDWR); } catch (ErrnoException expected) { assertEquals(OsConstants.ENOTCONN, expected.errno); } } catch (Exception ex) { killerThreadException.set(ex); } } ``` Buggy Code: ```java // This should close the Raf, and previous implementations wrongly returned a new // open (but useless) channel in this case. fileChannelBeforeClosing.close(); FileChannel fileChannelAfterClosing = raf.getChannel(); assertFalse(fileChannelBeforeClosing.isOpen()); } // http://b/19892782 public void testCloseRafBeforeGetChannel_returnChannelWithCloseFdAfterClose() throws Exception { RandomAccessFile raf = new RandomAccessFile(file, "rw"); raf.setLength(10); raf.close(); try { raf.getChannel().size(); fail(); } catch (IOException expected) { return; } assertFalse("Exception expected", true); } private void createRandomAccessFile(File file) throws Exception { // TODO: fix our register maps and remove this otherwise unnecessary // indirection! (http://b/5412580) new RandomAccessFile(file, "rw"); } public void testDirectories() throws Exception { try { new RandomAccessFile(".", "r"); fail(); } catch (FileNotFoundException expected) { } try { new RandomAccessFile(".", "rw"); fail(); } ``` Fixed Code: ```java // This should close the Raf, and previous implementations wrongly returned a new // open (but useless) channel in this case. fileChannelBeforeClosing.close(); FileChannel fileChannelAfterClosing = raf.getChannel(); assertFalse(fileChannelBeforeClosing.isOpen()); } // http://b/19892782 public void test
public void testNothing() { assertNotNull(editorBot); final SWTBotTable tableBot = editorBot.bot().table(); tableBot.getTableItem(0).click(3); SWTBotText textBot = editorBot.bot().text(); textBot.typeText("LoggerA|LoggerB|LoggerC"); textBot.pressShortcut(Keystrokes.CTRL, Keystrokes.CR); fBot.waitUntil(Conditions.tableHasRows(tableBot, 6), 5000); tableBot.getTableItem(1).contextMenu(EXPORT_TO_TSV).click(); assertTsvContentsEquals(ImmutableList.of(HEADER_TEXT, EVENT1_TEXT, EVENT2_TEXT, EVENT3_TEXT)); fBot.closeAllEditors(); } private static void assertTsvContentsEquals(final List<String> expected) throws FileNotFoundException, IOException { File file = new File(fAbsolutePath); fBot.waitUntil(new FileLargerThanZeroCondition(file)); try (BufferedReader br = new BufferedReader(new FileReader(file))) { List<String> lines = br.lines().collect(Collectors.toList()); assertEquals("File content", expected, lines); } finally { file.delete(); } }
import org.eclipse.sirius.viewpoint.Messages; import com.google.common.base.Preconditions; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.List; import java.util.Set; import java.util.function.Predicate; import org.eclipse.emf.common.notify.Notification; import org.eclipse.emf.ecore.EObject; /** * A class providing useful methods for refresh. * * @author mbats */ public final class RefreshHelper { private static List<Predicate<Notification>> impactingNotificationPredicates = new ArrayList<>(); /** * Prevent instantiation. */ private RefreshHelper() { } /** * Checks whether at least one changes of which we are notified, concern a semantic model or a specific graphical * change (registered through {@link #registerImpactingNotification(Predicate)}). * * @param notifications * the model changes. * @return <code>true</code> if the changes impact a semantic model or a specific graphical change. */ public static boolean isImpactingNotification(final Collection<Notification> notifications) { boolean isImpactingNotification = false; Set<EObject> alreadyDoneNotifiers = new HashSet<>(); for (Notification notification : notifications) { Object notifier = notification.getNotifier(); if (notifier instanceof EObject) { EObject eObjectNotifier = (EObject) notifier; if (alreadyDoneNotifiers.add(eObjectNotifier)) { if (isImpactingNotification(eObjectNotifier)) { isImpactingNotification = true; break; } } } } return isImpactingNotification; } /** * Register a predicate to determine if a notification is impacting. * * @param predicate * the predicate to register. */ public static void registerImpactingNotification(Predicate<Notification> predicate) { Preconditions.checkNotNull(predicate); impactingNotificationPredicates.add(predicate); } private static boolean isImpactingNotification(EObject eObject) { for (Predicate<Notification> predicate : impactingNotificationPredicates) { if (predicate.test(eObject)) { return true; } } return false; } }
import org.eclipse.sirius.viewpoint.Messages; import com.google.common.base.Preconditions; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.List; import java.util.Set; import java.util.function.Predicate; /** * A class providing useful methods for refresh. * * @author mbats */ public final class RefreshHelper { private static List<Predicate<Notification>> impactingNotificationPredicates = new ArrayList<>(); /** * Prevent instantiation. */ private RefreshHelper() { } /** * Checks whether at least one changes of which we are notified, concern a semantic model or a specific graphical * change (registered through {@link #registerImpactingNotification(Predicate)}). * * @param notifications the model changes. * @return <code>true</code> if the changes impact a semantic model or a specific graphical change. */ public static boolean isImpactingNotification(final Collection<Notification> notifications) { boolean isImpactingNotification = false; Set<EObject> alreadyDoneNotifiers = new HashSet<>(); for (Notification notification : notifications) { Object notifier = notification.getNotifier(); if (notifier instanceof EObject) { EObject eObjectNotifier = (EObject) notifier; // Check if the notifier is already processed if (alreadyDoneNotifiers.contains(eObjectNotifier)) { continue; } alreadyDoneNotifiers.add(eObjectNotifier); if (isImpactingSemanticChange(eObjectNotifier) || isImpactingGraphicalChange(notification)) { isImpactingNotification = true; break; } } } return isImpactingNotification; } /** * Checks if the given EObject is an impacting semantic change. * * @param eObject the EObject to check. * @return <code>true</code> if the EObject is an impacting semantic change, <code>false</code> otherwise. */ private static boolean isImpactingSemanticChange(EObject eObject) { // TODO: Implement the logic to check if the EObject is an impacting semantic change return false; } /** * Checks if the given notification is an impacting graphical change. * * @param notification the notification to check. * @return <code>true</code> if the notification is an impacting graphical change, <code>false</code>
protected static boolean isImpactingNotification(Notification notification, EObject notifier, Set<EObject> alreadyDoneNotifiers, Map<EObject, Resource> notifierWithResource, Map<EObject, Boolean> notifierIsInAirdOrSrmResource) { Resource notifierResource = notifierWithResource.get(notifier); // Check if the notifier has a resource if (notifierResource != null) { // Check if the notifier is in an AIRD or SRM resource boolean isInAirdOrSrmResource = notifierIsInAirdOrSrmResource.getOrDefault(notifier, ResourceQuery.isAirdOrSrmResource(notifierResource)); if (isInAirdOrSrmResource) { return true; } } // Check if the notification concerns a semantic model change if (notification.getFeature() != null && notification.getFeature().eContainer() instanceof EPackage) { return true; } // Check if the notification concerns a specific graphical change if (notification.getNotifier() instanceof View) { return true; } // Check if the notification has already been checked if (alreadyDoneNotifiers.contains(notifier)) { return false; } alreadyDoneNotifiers.add(notifier); // Check if the notification concerns a semantic model change or a specific graphical change for the notifier's children if (notifier instanceof EObject) { for (EObject child : ((EObject) notifier).eContents()) { if (isImpactingNotification(notification, child, alreadyDoneNotifiers, notifierWithResource, notifierIsInAirdOrSrmResource)) { return true; } } } return false; }
private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; private final Listener fListener = this::disposeIfExited; private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); bounds.x -= OFFSET; bounds.y -= OFFSET; if (!bounds.contains(pt)) { tipShell.dispose(); control.getDisplay().removeFilter(SWT.MouseMove, fListener); } } } }
createTooltipShell(timeGraphControl.getShell()); for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); Display.getDefault().addFilter(SWT.MouseMove, fListener);
private void createTooltipShell(Shell parent) { final Display display = parent.getDisplay(); if (fTipShell != null && !fTipShell.isDisposed()) { fTipShell.dispose(); } fTipShell = new Shell(parent, SWT.ON_TOP | SWT.TOOL); fTipShell.addDisposeListener(e -> Display.getDefault().removeFilter(SWT.MouseMove, fListener)); GridLayout gridLayout = new GridLayout(); gridLayout.numColumns = 2; gridLayout.marginWidth = 2; gridLayout.marginHeight = 2; fTipShell.setLayout(gridLayout); fTipShell.setBackground(display.getSystemColor(SWT.COLOR_INFO_BACKGROUND)); fTipComposite = new Composite(fTipShell, SWT.NONE); fTipComposite.setLayout(new GridLayout(3, false)); setupControl(fTipComposite); }
public static void cleanUp() { SWTBotUtils.closeViewById(UML2DVIEW_ID, fBot); fFileLocation.delete(); fLogger.removeAllAppenders(); tearDown(); }
public static void tearDown() { fLogger.removeAllAppenders(); fFileLocation.delete(); } Review: The tearDown() method should also delete the project.
for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); Display display = Display.getDefault(); display.addFilter(SWT.MouseMove, fListener); display.addFilter(SWT.FocusOut, fListener);
import org.eclipse.jdt.core.IJavaElement; import org.eclipse.jdt.core.IMethod; import org.eclipse.jdt.core.JavaModelException; import org.eclipse.jdt.core.dom.CompilationUnit; import org.eclipse.jdt.core.dom.ConstructorInvocation; import org.eclipse.jdt.core.dom.Expression; import org.eclipse.jdt.core.dom.IMethodBinding; import org.eclipse.jdt.core.dom.MethodInvocation; import org.eclipse.jdt.internal.corext.dom.HierarchicalASTVisitor; import org.eclipse.jdt.internal.ui.JavaPlugin; public class CalleeJavaMethodParameterVisitor extends HierarchicalASTVisitor { private final CompilationUnit cu; private final List<ICodeMining> minings; private final ICodeMiningProvider provider; public CalleeJavaMethodParameterVisitor(CompilationUnit cu, List<ICodeMining> minings, ICodeMiningProvider provider) { this.cu = cu; this.minings = minings; this.provider = provider; } @Override public boolean visit(ConstructorInvocation constructorInvocation) { List<?> arguments = constructorInvocation.arguments(); if (!arguments.isEmpty()) { IMethod method = resolveMethodBinding(constructorInvocation.resolveConstructorBinding()); collectParameterNamesCodeMinings(method, arguments); } return super.visit(constructorInvocation); } @Override public boolean visit(MethodInvocation methodInvocation) { List<?> arguments = methodInvocation.arguments(); if (!arguments.isEmpty()) { IMethod method = resolveMethodBinding(methodInvocation.resolveMethodBinding()); collectParameterNamesCodeMinings(method, arguments); } return super.visit(methodInvocation); } private IMethod resolveMethodBinding(IMethodBinding methodBinding) { IJavaElement element = methodBinding.getJavaElement(); if (element instanceof IMethod) { return (IMethod) element; } return null; } private void collectParameterNamesCodeMinings(IMethod method, List<?> arguments) { try { String[] parameterNames = method.getParameterNames(); for (int i = 0; i < arguments.size(); i++) { Expression argument = (Expression) arguments.get(i); String parameterName = parameterNames[i]; ICodeMining codeMining = provider.createCodeMining(parameterName, argument.getStartPosition()); minings.add(codeMining); } } catch (JavaModelException e) { JavaPlugin.log(e); } } }
String targets[] = { "peer1", "peer2" }; try (BufferedRandomAccessFile braf = new BufferedRandomAccessFile(fFileLocation, "rw")) { braf.writeBytes(TRACE_START); for (int i = 0; i < 20000; i++) { braf.writeBytes(makeEvent(i * 100, eventNames[i % 2], targets[i % 2], targets[(i + 1) % 2], Integer.toString(i % 2 + 1000))); } braf.writeBytes(TRACE_END); } beforeTest(); /** * Open a trace in an editor */ public static void beforeTest() { SWTBotUtils.createProject(PROJECT_NAME); SWTBotTreeItem treeItem = SWTBotUtils.selectTracesFolder(fBot, PROJECT_NAME); assertNotNull(treeItem); SWTBotUtils.openTrace(PROJECT_NAME, fFileLocation.getAbsolutePath(), XMLSTUB_ID); SWTBotUtils.openView(UML2DVIEW_ID); } /** * Delete the file */ @AfterClass public static void cleanUp() { SWTBotUtils.closeViewById(UML2DVIEW_ID, fBot); fFileLocation.delete(); }
public void tearDown() { fBot.closeAllEditors(); cleanUp(); } private void cleanUp() { SWTBotUtils.deleteProject(PROJECT_NAME, fBot); }
fBot = new SWTWorkbenchBot(); /* finish waiting for eclipse to load */ WaitUtils.waitForJobs(); fFileLocation = File.createTempFile("sample", ".xml"); try (BufferedRandomAccessFile braf = new BufferedRandomAccessFile(fFileLocation, "rw")) { braf.writeBytes(TRACE_START); for (int i = 0; i < 100; i++) { braf.writeBytes(makeEvent(i * 100, i % 4)); } braf.writeBytes(TRACE_END); } SWTBotUtils.createProject(PROJECT_NAME); SWTBotTreeItem treeItem = SWTBotUtils.selectTracesFolder(fBot, PROJECT_NAME); assertNotNull(treeItem); SWTBotUtils.openTrace(PROJECT_NAME, fFileLocation.getAbsolutePath(), XMLSTUB_ID); SWTBotUtils.openView(ColorsView.ID); fLogger.removeAllAppenders(); fFileLocation.delete(); tearDown();
public static void cleanUp() { fLogger.removeAllAppenders(); fFileLocation.delete(); tearDown(); }
mgr.addJobChangeListener(changeListener); for (int i = 0; i < 10; i++) { SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); // Add little delay so that threads have a chance to start SWTBotUtils.delay(500); workbenchbot.closeAllEditors(); if (!status.isOK()) { SWTBotUtils.deleteProject(TRACE_PROJECT_NAME, workbenchbot); fail(handleErrorStatus(status)); } } SWTBotUtils.deleteProject(TRACE_PROJECT_NAME, workbenchbot);
IKernelTrace trace = new TmfXmlKernelTraceStub(); IPath filePath = Activator.getAbsoluteFilePath(CPU_USAGE_FILE); IStatus status = trace.validate(null, filePath.toOSString()); if (!status.isOK()) { fail(status.getException().getMessage()); } try { trace.initTrace(null, filePath.toOSString(), TmfEvent.class); } catch (TmfTraceException e) { fail(e.getMessage()); } deleteSuppFiles(trace); ((TmfTrace) trace).traceOpened(new TmfTraceOpenedSignal(null, trace, null)); /* FIXME: Make sure this analysis is finished before running the CPU analysis. This block can be removed once analysis dependency and request precedence is implemented */ IAnalysisModule module = null; for (IAnalysisModule mod : TmfTraceUtils.getAnalysisModulesOfClass(trace, TidAnalysisModule.class)) { module = mod; } assertNotNull(module); module.schedule(); module.waitForCompletion(); /* End of the FIXME block */ fModule = TmfTraceUtils.getAnalysisModuleOfClass(trace, KernelCpuUsageAnalysis.class, KernelCpuUsageAnalysis.ID);
public static void setUp() { ITmfTrace trace = KERNEL_TEST_CASE.getKernelTrace(); deleteSuppFiles(trace); ((TmfTrace) trace).traceOpened(new TmfTraceOpenedSignal(null, trace, null)); IAnalysisModule module = null; for (IAnalysisModule mod : TmfTraceUtils.getAnalysisModulesOfClass(trace, KernelAnalysisModule.class)) { module = mod; } assertNotNull(module); module.schedule(); module.waitForCompletion(); fModule = TmfTraceUtils.getAnalysisModuleOfClass(trace, KernelAnalysisModule.class, KernelAnalysisModule.ID); fTrace = trace; }
private final Object fReconcilerLock= new Object(); private JavaTemplatesPage fTemplatesPage; private IJavaReconcilingListener fCodeMiningsReconcilingListener; public CompilationUnitEditor() { setDocumentProvider(JavaPlugin.getDefault().getCompilationUnitDocumentProvider()); setEditorContextMenuId("#CompilationUnitEditorContext"); setRulerContextMenuId("#CompilationUnitRulerContext"); setOutlinerContextMenuId("#CompilationUnitOutlinerContext"); fSavePolicy= null; fJavaEditorErrorTickUpdater= new JavaEditorErrorTickUpdater(this); fCorrectionCommands= null; }
package org.eclipse.jdt.ui.tests.activation; import java.util.Arrays; import java.util.HashSet; import java.util.Set; import org.junit.Assert; import org.osgi.framework.Bundle; import org.eclipse.jdt.testplugin.JavaProjectHelper; import org.eclipse.core.runtime.Platform; import org.eclipse.ui.IWorkbench; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.PlatformUI; import org.eclipse.jdt.core.ICompilationUnit; import org.eclipse.jdt.core.IJavaProject; import org.eclipse.jdt.core.IPackageFragment; import org.eclipse.jdt.core.IPackageFragmentRoot; import org.eclipse.jdt.internal.ui.javaeditor.EditorUtility; import junit.framework.TestCase; public class JavaActivationTest extends TestCase { private IJavaProject project; }
import org.osgi.framework.Bundle; import org.eclipse.jdt.testplugin.JavaProjectHelper; import org.eclipse.core.runtime.Platform; import org.eclipse.ui.IWorkbench; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.PlatformUI; import org.eclipse.jdt.core.ICompilationUnit; import org.eclipse.jdt.core.IJavaProject; import org.eclipse.jdt.core.IPackageFragment; import org.eclipse.jdt.core.IPackageFragmentRoot; import org.eclipse.jdt.internal.ui.javaeditor.EditorUtility; import junit.framework.TestCase; public class JavaActivationTest extends TestCase { private IJavaProject project; private static final String[] inactiveBundles= new String[] { "org.apache.xerces", "org.eclipse.jdt.astview", "org.eclipse.jdt.jeview", "org.eclipse.reftracker", "org.eclipse.swt.sleak", "org.eclipse.swt.spy", "com.jcraft.jsch", "javax.servlet", "javax.servlet.jsp", "org.apache.ant", "org.apache.commons.el", "org.apache.commons.logging", "org.apache.jasper", "org.apache.lucene", "org.apache.lucene.analysis" }; }
protected List<AbstractNodeMapping> getListOfMappingsToMove(DDiagram diagram) { List<AbstractNodeMapping> returnedList = new ArrayList<>(); returnedList.add(DiagramServices.getDiagramServices().getContainerMapping(diagram, IMappingNameConstants.CRB_COMPONENT_MAPPING)); return returnedList; } public List<String> getOwnerGroups(Project.NameKey project) { String[] groups = cfg.getStringList(SECTION_NAME, findSubSection(project.get()), OWNER_GROUP_NAME); return Arrays.asList(groups); } public class LocalSearchProfilerAdapter implements ILocalSearchAdapter { private final Map<MatcherReference, PlanProfile> profile = new HashMap<>(); private final Map<SearchPlanExecutor, int[]> currentBodies = new HashMap<>(); private class PlanProfile { final int[][] bodies; final ArrayList<List<ISearchOperation>> operations; public PlanProfile(LocalSearchMatcher lsMatcher) { ImmutableList<SearchPlanExecutor> plan = lsMatcher.getPlan(); bodies = new int[plan.size()][]; operations = new ArrayList<>(plan.size()); for (int i = 0; i < bodies.length; i++) { List<ISearchOperation> ops = plan.get(i).getSearchPlan().getOperations(); operations.add(ops); bodies[i] = new int[ops.size()]; } } public void register(LocalSearchMatcher lsMatcher) { ImmutableList<SearchPlanExecutor> plan = lsMatcher.getPlan(); for (int i = 0; i < bodies.length; i++) { // code omitted for brevity } } } } IPackageFragment pack = sourceFolder.createPackageFragment("pack0", false, null); StringBuffer buf = new StringBuffer(); buf.append("package pack0;\n"); buf.append("public class List1 {\n}\n"); return pack.createCompilationUnit("List1.java", buf.toString(), false, null); public void testOpenJavaEditor() throws Exception { ICompilationUnit unit = createTestCU(); EditorUtility.openInEditor(unit); Set<String> set = new HashSet<>(Arrays.asList(inactiveBundles)); checkNotLoaded(set); } public void checkNotLoaded(Set<String> inactiveBundles) { Bundle bundle = Platform.getBundle("org.eclipse.jdt.ui.tests"); Bundle[] bundles = bundle.getBundleContext().getBundles(); for (int i = 0
private static IType createAutoType(ICPPASTInitializerClause initClause, IASTDeclSpecifier declSpec, IASTDeclarator declarator) { if (initClause == null) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } IType type = AutoTypeResolver.AUTO_TYPE; IType initType = null; ValueCategory valueCat = null; ICPPClassTemplate initializer_list_template = null; if (initClause instanceof ICPPASTInitializerList) { initializer_list_template = get_initializer_list(declSpec); if (initializer_list_template == null) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } type = (IType) CPPTemplates.instantiate(initializer_list_template, new ICPPTemplateArgument[] { new CPPTemplateTypeArgument(type) }, initClause); if (type instanceof IProblemBinding) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } } type = decorateType(type, declSpec, declarator); final ICPPEvaluation evaluation = initClause.getEvaluation(); initType = evaluation.getTypeOrFunctionSet(declarator); valueCat = evaluation.getValueCategory(declarator); }
import static org.junit.Assert.assertNotNull; public ScheduleConfig(Config rc, String section, String subsection) { this(rc, section, subsection, ZonedDateTime.now(systemDefault())); } public int chooseRunningDeviceStep(String[] deviceNames) { JRadioButtonFixture chooseRunningDeviceRadioButton = new JRadioButtonFixture(robot, findRadioButtonByText("Choose a running device")); chooseRunningDeviceRadioButton.requireEnabled(); chooseRunningDeviceRadioButton.requireVisible(); chooseRunningDeviceRadioButton.click(); JBTable deviceTable = robot.finder().findByType(target, JBTable.class); assertNotNull(deviceTable); JTableFixture deviceTableFixture = new JTableFixture(robot, deviceTable); int deviceColumnIndex = deviceTable.getColumn("Device").getModelIndex(); int compatibleColumnIndex = deviceTable.getColumn("Compatible").getModelIndex(); ArrayList<Integer> rowsToSelect = new ArrayList<Integer>(deviceTable.getRowCount()); HashSet<String> deviceNameHashes = new HashSet<String>(Arrays.asList(deviceNames)); for (int i = 0; i < deviceTable.getRowCount(); ++i) { IDevice device = (IDevice) deviceTable.getModel().getValueAt(i, deviceColumnIndex); ThreeState launchCompatibility = ((LaunchCompatibility) deviceTable.getModel().getValueAt(i, compatibleColumnIndex)).isCompatible(); } } public static void findAndSetPlatformSources(@NotNull IAndroidTarget target, @NotNull SdkModificator sdkModificator) { File sources = findPlatformSources(target); if (sources != null) { VirtualFile virtualFile = VfsUtil.findFileByIoFile(sources, true); if (virtualFile != null) { for (VirtualFile file : sdkModificator.getRoots(OrderRootType.SOURCES)) { if (file.equals(virtualFile)) { return; } } } } } Ref doPeel(Ref leaf) throws MissingObjectException, IOException { try (RevWalk rw = new RevWalk(repository)) { RevObject obj = rw.parseAny(leaf.getObjectId()); if (obj instanceof RevTag) { return new ObjectIdRef.PeeledTag(leaf.getStorage(), leaf.getName(), leaf.getObjectId(), rw.peel(obj).copy(), hasVersioning() ? leaf.getUpdateIndex() : Ref.UNDEFINED_UPDATE_INDEX); } else { return new ObjectIdRef.PeeledNonTag(leaf.getStorage(), leaf.getName(),
public abstract class TmfAbstractToolTipHandler { private static final int MOUSE_DEADZONE = 5; private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; private final Listener fListener = this::disposeIfExited; private final Listener fFocusLostListener = event -> { Shell tipShell = fTipShell; if (tipShell != null) { tipShell.dispose(); } }; private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); Rectangle deadzone = fInitialDeadzone; if (deadzone == null) { deadzone = new Rectangle(bounds.x - MOUSE_DEADZONE, bounds.y - MOUSE_DEADZONE, bounds.width + 2 * MOUSE_DEADZONE, bounds.height + 2 * MOUSE_DEADZONE); fInitialDeadzone = deadzone; } if (!deadzone.contains(pt)) { tipShell.dispose(); } } } } }
private static final int MOUSE_DEADZONE = 5; private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; private final Listener fListener = this::disposeIfExited; private final Listener fFocusLostListener = event -> { Shell tipShell = fTipShell; if (tipShell != null) { tipShell.dispose(); } }; private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); } } } }
/* The match pattern for <uses-library> */ private static final Pattern PATTERN_USES_LIBRARY = Pattern.compile("^use.*library"); /** The main issue discovered by this detector */ public static final Issue ISSUE = Issue.create( "ManifestTypos", //$NON-NLS-1$ "Checks for manifest typos", "This check looks through the manifest , and if it finds any tags " + "that look like likely misspellings, they are flagged.", Category.CORRECTNESS, 5, Severity.WARNING, ManifestTypoDetector.class, Scope.MANIFEST_SCOPE ); /** Constructs a new {@link ManifestTypoDetector} check */ public ManifestTypoDetector() { } @NonNull @Override public Speed getSpeed() { return Speed.FAST; } @Override public boolean appliesTo(@NonNull Context context, @NonNull File file) { return file.getName().equals(ANDROID_MANIFEST_XML); } @Override public Collection<String> getApplicableElements() { return XmlScanner.ALL; } public int getMetricsCategory() { return MetricsEvent.QS_SCREENSHOT_TILE; } 5, Severity.WARNING, IMPLEMENTATION); /** Not explicitly defining application icon */ public static final Issue APPLICATION_ICON = Issue.create( "MissingApplicationIcon", //$NON-NLS-1$ "Missing application icon", "Checks that the application icon is set", "You should set an icon for the application as whole because there is no " + "default. This attribute must be set as a reference to a drawable resource " + "containing the image (for example `@drawable/icon`).", Category.ICONS, 5, Severity.WARNING, IMPLEMENTATION ); /** Constructs a new {@link ManifestOrderDetector} check */ public ManifestOrderDetector() { } private boolean mSeenApplication; /** Number of times we've seen the <uses-sdk> element */ private int mSeenUsesSdk; /** Activities we've encountered */ private final Set<String> mActivities = new HashSet<String>(); /** Features we've encountered */ private final Set<String> mUsesFeatures = new HashSet<String>(); /** Permission basenames */ } return result; } /** * Sets the completion proposal categories which are excluded from the * default proposal list and reloads the registry. * * @param categories the array with the IDs of the excluded categories * @see #CODEASSIST_EXCLUDED_CATEGORIES * @since
assert (myEditor.getCaptureId() != null); if (myEditor.getDeviceId() == null) { return; } DefaultListModel model = new DefaultListModel(); model.ensureCapacity(myFrameData.size()); for (ScrubberLabelData data : myFrameData) { model.addElement(data); } setModel(model); if (myFrameData.size() == 0) { myList.getEmptyText().setText(StatusText.DEFAULT_EMPTY_TEXT); } ImageFetcher imageFetcher = new ImageFetcher(client); imageFetcher.prepareFetch(myEditor.getDeviceId(), myEditor.getCaptureId(), myEditor.getContext()); myScrubberCellRenderer.setup(imageFetcher); myList.setCellRenderer(myScrubberCellRenderer); public String getUsage() { StringBuilder sb = new StringBuilder(); sb.append("<key>" + separator + "<value>"); sb.append(" where <key> is "); sb.append(keyParser.getUsage()); sb.append(" and where <value> is "); sb.append(valueParser.getUsage()); return sb.toString(); } public void testTraceSetExperiment() { TmfExperiment exp = createExperiment(trace1, trace2); openTrace(trace1); openTrace(exp); ITmfTrace[] expected = new ITmfTrace[] { trace1, trace2 }; Collection<ITmfTrace> actual = tm.getActiveTraceSet(); assertEquals(2, actual.size()); assertEquals(expected, actual); } public boolean visit(ConstructorInvocation constructorInvocation) { List<?> arguments = constructorInvocation.arguments(); if (!arguments.isEmpty()) { IMethodBinding constructorBinding = constructorInvocation.resolveConstructorBinding(); IMethod method = resolveMethodBinding(constructorBinding); collectParameterNamesCodeMinings(method, arguments, constructorBinding.isVarargs()); } return super.visit(constructorInvocation); }
public boolean visit(MethodInvocation methodInvocation) { List<?> arguments = methodInvocation.arguments(); if (!arguments.isEmpty()) { IMethodBinding methodBinding = methodInvocation.resolveMethodBinding(); IMethod method = resolveMethodBinding(methodBinding); if (method != null) { collectParameterNamesCodeMinings(method, arguments, methodBinding.isVarargs()); } } return super.visit(methodInvocation); }
/***************************************************************************** * Copyright (c) 2010-2019, Tamas Szabo, itemis AG, Gabor Bergmann, IncQuery Labs Ltd. * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v. 2.0 which is available at * http://www.eclipse.org/legal/epl-v20.html. * * SPDX-License-Identifier: EPL-2.0 *****************************************************************************/  package org.eclipse.viatra.query.runtime.matchers.memories;  /** * Represents a replacement between timestamps. * Either old or new can be null, but not at the same time. * * @author Tamas Szabo */ public class TimestampReplacement<Timestamp extends Comparable<Timestamp>> { public final Timestamp oldValue; public final Timestamp newValue;  public TimestampReplacement(final Timestamp oldValue, final Timestamp newValue) { if (oldValue == null && newValue == null) { throw new IllegalArgumentException("Old and new cannot be both null at the same time!"); } this.oldValue = oldValue; this.newValue = newValue; } }
package org.eclipse.viatra.query.runtime.matchers.memories; /** * Represents that a replacement between timestamps. * Either old or new can be null, but not at the same time. * * @author Tamas Szabo */ public class TimestampReplacement<Timestamp extends Comparable<Timestamp>> { public final Timestamp oldValue; public final Timestamp newValue; public TimestampReplacement(final Timestamp oldValue, final Timestamp newValue) { if (oldValue == null && newValue == null) { throw new IllegalArgumentException("Old and new cannot be both null at the same time!"); } this.oldValue = oldValue; this.newValue = newValue; } }
/*************************************************************************** * Copyright (c) 2019 CEA LIST and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * CEA LIST - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.model2doc.core.generatorconfiguration.operations; import org.eclipse.emf.common.util.URI; import org.eclipse.osgi.util.NLS; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentStructureGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.internal.Activator; /** * Utility class for the operations of GeneratorConfiguration metamodel */ public class GeneratorConfigurationOperations { 	/** 	 * 	 * @param generatorConfiguration 	 * a generatorConfiguration element 	 * @param uriKind 	 * the kind of expected URI 	 * @param fileExtension 	 * the expected file extension 	 * @return the computed URI 	 */ 	public static URI computeURI(DefaultDocumentGeneratorConfiguration generatorConfiguration, String uriKind, 			String fileExtension) { 		// implementation 	} 	/** 	 * 	 * @param generatorConfiguration 	 * a generatorConfiguration element 	 * @param uriKind 	 * the kind of expected URI 	 * @param fileExtension 	 * the expected file extension 	 * @return the computed URI 	 */ 	public static URI computeURI(DefaultDocumentStructureGeneratorConfiguration generatorConfiguration, String uriKind, 			String fileExtension) { 		// implementation 	} 	/** 	 * 	 * @param generatorConfiguration 	 * a generatorConfiguration element 	 * @param uriKind 	 * the kind of expected URI 	 * @param fileExtension 	 * the expected file extension 	 * @return the computed URI 	 */ 	public static URI computeURI(DefaultDocumentStructureGeneratorConfiguration generatorConfiguration, String uriKind, 			String fileExtension) { 		// implementation 	} }
/** * SPDX-License-Identifier: EPL-2.0 * Contributors: * CEA LIST - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.model2doc.core.generatorconfiguration.operations; import org.eclipse.emf.common.util.URI; import org.eclipse.osgi.util.NLS; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentStructureGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.internal.Activator; /** * Utility class for the operations of GeneratorConfiguration metamodel */ public class GeneratorConfigurationOperations { /** * @param generatorConfiguration a generatorConfiguration element * @param uriKind the kind of expected URI * @param fileExtension the extension file * @return the path of the file build from the parameters */ public static final String getDocumentStructureFileEcoreURI(final DefaultDocumentStructureGeneratorConfiguration generatorConfiguration, final String fileExtension) { final String folderName = generatorConfiguration.getStructureFolder(); final String documentName = generatorConfiguration.getDocumentName(); // Rest of the code... } }
private final String myTitle; private Combo branchText; private Combo remoteText; private Button rebase; public BranchConfigurationDialog(Shell shell, String branchName, Repository repository) { super(shell); myBranchName = branchName; myRepository = repository; myConfig = myRepository.getConfig(); setShellStyle(getShellStyle() | SWT.SHELL_TRIM); myTitle = UIText.BranchConfigurationDialog_BranchConfiguration; setHelpAvailable(false); } @Override protected Control createDialogArea(Composite parent) { Composite main = new Composite(parent, SWT.NONE); GridLayoutFactory.fillDefaults().numColumns(2).applyTo(main); GridDataFactory.fillDefaults().grab(true, false).indent(5, 5).applyTo(main); Label branchLabel = new Label(main, SWT.NONE); branchLabel.setText("Upstream &Branch:"); //$NON-NLS-1$ branchText = new Combo(main, SWT.BORDER); GridDataFactory.fillDefaults().grab(true, false).applyTo(branchText); try { // TODO: Add code here } catch (Exception e) { // Handle exception } return main; } public boolean canFlipToNextPage() { final boolean hasAtLeastOneFileToScan = !((BatchImportTraceWizard) getWizard()).getFilesToScan().isEmpty(); if (hasAtLeastOneFileToScan) { setErrorMessage(null); } else { setErrorMessage(Messages.ImportTraceWizardPageSelectDirectories_4); } return hasAtLeastOneFileToScan; } public void run() { MessageDialog.open(MessageDialog.INFORMATION, null, UIText.AutoRebaseProcess_AutoRebaseStarted, dialogMessage, SWT.NONE); } return newURI.toString(); } if (false == uri.isPlatform()) { final String projectName = generatorConfiguration.eResource().getURI().segment(1); uri = URI.createPlatformResourceURI(projectName, true).appendSegment(folderName); } if (uri.isPlatform()) { if (uri.isPlatformPlugin()) { Activator.log.warn(NLS.bind("The path {0} must not be a platform path", uri.toString())); return null; } return uri.appendSegment(documentName).appendFileExtension(fileExtension).toString(); } return null; } public static final String getDocumentFileOSURI(final DefaultDocumentGeneratorConfiguration
private final String myTitle; private Combo branchText; private Combo remoteText; private Button rebase; public BranchConfigurationDialog(Shell shell, String branchName, Repository repository) { super(shell); myBranchName = branchName; myRepository = repository; myConfig = myRepository.getConfig(); setShellStyle(getShellStyle() | SWT.SHELL_TRIM); myTitle = UIText.BranchConfigurationDialog_BranchConfiguration; setHelpAvailable(false); } @Override protected Control createDialogArea(Composite parent) { Composite main = new Composite(parent, SWT.NONE); GridLayoutFactory.fillDefaults().numColumns(2).applyTo(main); GridDataFactory.fillDefaults().grab(true, false).indent(5, 5).applyTo(main); Label branchLabel = new Label(main, SWT.NONE); branchLabel.setText("Upstream &Branch:"); //$NON-NLS-1$ branchText = new Combo(main, SWT.BORDER); GridDataFactory.fillDefaults().grab(true, false).applyTo(branchText); try { // code for creating dialog area } catch (Exception e) { // handle exception } return main; } public boolean canFlipToNextPage() { final boolean hasAtLeastOneFileToScan = !((BatchImportTraceWizard) getWizard()).getFilesToScan().isEmpty(); if (hasAtLeastOneFileToScan) { setErrorMessage(null); } else { setErrorMessage(Messages.ImportTraceWizardPageSelectDirectories_4); } return hasAtLeastOneFileToScan; } public void run() { MessageDialog.open(MessageDialog.INFORMATION, null, UIText.AutoRebaseProcess_AutoRebaseStarted, dialogMessage, SWT.NONE); } return newURI.toString(); if (false == uri.isPlatform()) { final String projectName = configuration.eResource().getURI().segment(1); uri = URI.createPlatformResourceURI(projectName, true).appendSegment(folderName); } if (uri.isPlatform()) { if (uri.isPlatformPlugin()) { Activator.log.warn(NLS.bind("The path {0} must not be a platform path", uri.toString())); return null; } uri = uri.appendSegment(documentName).appendFileExtension(fileExtension); } return null; }
import org.junit.Test; public class CtfTmfExperimentTrimmingTest { private static ITmfTrace fNewExperiment; @BeforeClass public static void beforeClass() throws IOException { SWTBotUtils.initialize(); SWTBotPreferences.TIMEOUT = 20000; fLogger.removeAllAppenders(); fLogger.addAppender(new NullAppender()); File parentDir = FileUtils.toFile(FileLocator.toFileURL(CtfTestTrace.TRACE_EXPERIMENT.getTraceURL())); File[] traceFiles = parentDir.listFiles(); ITmfTrace traceValidator = new CtfTmfTrace(); fBot = new SWTWorkbenchBot(); SWTBotUtils.createProject(PROJECT_NAME); int openedTraces = 0; for (File traceFile : traceFiles) { String absolutePath = traceFile.getAbsolutePath(); if (traceValidator.validate(null, absolutePath).isOK()) { // open trace SWTBotUtils.openTrace(absolutePath); openedTraces++; } } // create experiment fNewExperiment = new CtfTmfExperiment(); fNewExperiment.indexTrace(true); fNewExperiment.waitForCompletion(); } @Test public void testTrimExperiment() { // test code here } }
protected boolean hasJREInClassPath(IJavaProject javaProject) { if (javaProject != null) { try { IClasspathEntry[] oldClasspaths = javaProject.getRawClasspath(); for (int i = 0; i < oldClasspaths.length; i++) { if (isJREContainer(oldClasspaths[i].getPath())) { return true; } } } catch (JavaModelException e) { e.printStackTrace(); } } return false; }
getRequirementFilter(symbolicName, versionRange)); Collection<BundleCapability> matchingBundleCapabilities = fwkWiring.findProviders(ModuleContainer .createRequirement(IdentityNamespace.IDENTITY_NAMESPACE, directives, Collections.emptyMap())); if (matchingBundleCapabilities.isEmpty()) { return null; } Bundle[] results = matchingBundleCapabilities.stream() .map(c -> c.getRevision().getBundle()) .filter(bundle -> (bundle.getState() & (Bundle.INSTALLED | Bundle.UNINSTALLED)) == 0) .sorted((b1, b2) -> b2.getVersion().compareTo(b1.getVersion())) .toArray(Bundle[]::new); return results.length > 0 ? results : null;
try { XMultiServiceFactory xMultiServiceFactory = odtEditor.getXMultiServiceFactory(); // create a text table Object obj = xMultiServiceFactory.createInstance("com.sun.star.text.TextTable"); XTextTable textTable = UnoRuntime.queryInterface(XTextTable.class, obj); // Default background color Object backColor = 0x6AA84F; // If defined style then update backColor if (style != null) { backColor = style; } if (numRows > 0 && numCols > 0) { // Verify if there are row titles if (table.getRowTitles() != null && !table.getRowTitles().isEmpty()) { // update column counters numCols++; } // Verify if there are column titles if (table.getColumnTitles() != null && !table.getColumnTitles().isEmpty()) { // update row counter numRows++; } // Initialize and add table textTable.initialize(numRows, numCols); addTextContent(xTextCursor, textTable); endParagraph(xTextCursor); } } catch (Exception e) { e.printStackTrace(); }
boolean isValueDependent(); boolean isConstantExpression(); boolean isNoexcept(boolean inCalledContext); boolean isEquivalentTo(ICPPEvaluation other); IType getType(); IValue getValue();
public boolean isNoexcept(boolean inCalledContext) { return true; }
public boolean isNoexcept(boolean inCalledContext) { if (inCalledContext) { return true; } else { return false; } }
public boolean isNoexcept(boolean inCalledContext) { assert false; return true; }
public boolean isNoexcept(boolean inCalledContext) { assert false; return true; }
public boolean isNoexcept(boolean inCalledContext) { return false; }
public boolean isNoexcept(boolean inCalledContext) { assert false; return false; }
private void ensureSize(int index) { List<@Nullable IEventDeclaration> list = fEvents; if (list instanceof ArrayList) { if (index > 50000) { fEvents = new SparseList(fEvents); } ((ArrayList<@Nullable IEventDeclaration>) list).ensureCapacity(index); while (list.size() <= index) { list.add(null); } } }
public SparseList(List<@Nullable IEventDeclaration> events) { for(int i = 0; i < events.size(); i++) { IEventDeclaration event = events.get(i); if(event != null) { add(i, event); } } }
public boolean add(@Nullable IEventDeclaration e) { synchronized (this) { fInnerEvents.put(fNextAdded, e); fNextAdded++; } return true; }
public boolean addAll(int index, Collection<? extends @Nullable IEventDeclaration> c) { int key = index; for (IEventDeclaration event : c) { if (event != null) { add(key, event); } key++; } return true; }
public void add(int index, @Nullable IEventDeclaration element) { if (index > fLastAdded) { fLastAdded = index; } add(element); }
public class Text extends Scrollable { int tabs, oldStart, oldEnd; boolean doubleClick, ignoreModify, ignoreVerify, ignoreCharacter, allowPasswordChar; String message; int[] segments; int clearSegmentsCount = 0; RECT searchRect, cancelRect; boolean mouseInSearch, mouseInCancel; static final char LTR_MARK = '\u200e'; static final char RTL_MARK = '\u200f'; static final int IDI_SEARCH = 101; static final int IDI_CANCEL = 102; static final int SEARCH_ICON_MARGIN = 4; public static final int LIMIT; public static final String DELIMITER; /* This code is intentionally commented. */ }
public long getTimeWriting() { return statistics.timeWriting; } public long getTreesTraversed() { return statistics.treesTraversed; } public long getTimeTotal() { return statistics.timeCounting + statistics.timeSearchingForReuse + statistics.timeSearchingForSizes + statistics.timeCompressing + statistics.timeWriting; }
/***************************************************************************** * Copyright (c) 2019 Ericsson * * All rights reserved. This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1.0 which * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *****************************************************************************/ package org.eclipse.tracecompass.tmf.ui.viewers; import org.eclipse.swt.SWT; import org.eclipse.swt.events.MouseEvent; import org.eclipse.swt.events.MouseTrackAdapter; import org.eclipse.swt.graphics.Point; import org.eclipse.swt.graphics.Rectangle; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.layout.GridLayout; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Control; import org.eclipse.swt.widgets.Display; import org.eclipse.swt.widgets.Event; import org.eclipse.swt.widgets.Label; import org.eclipse.swt.widgets.Listener; import org.eclipse.swt.widgets.Shell; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.widgets.TimeGraphTooltipHandler; /** * Abstract tool tip handler. * * @since 3.2 */ public abstract class AbstractToolTipHandler { // TODO: Implement the abstract tool tip handler }
final Display display = parent.getDisplay(); if (fTipShell != null && !fTipShell.isDisposed()) { fTipShell.dispose(); } fTipShell = new Shell(parent, SWT.ON_TOP | SWT.TOOL); // Deregister display filters on dispose fTipShell.addDisposeListener(e -> e.display.removeFilter(SWT.MouseMove, fListener)); fTipShell.addDisposeListener(e -> e.display.removeFilter(SWT.FocusOut, fFocusLostListener)); fTipShell.addListener(SWT.Deactivate, e -> { if (fTipShell.isDisposed()) { fTipShell.dispose(); } }); GridLayout gridLayout = new GridLayout(); gridLayout.numColumns = 2; gridLayout.marginWidth = 2; gridLayout.marginHeight = 2; fTipShell.setLayout(gridLayout); fTipShell.setBackground(display.getSystemColor(SWT.COLOR_INFO_BACKGROUND)); fTipComposite = new Composite(fTipShell, SWT.NONE); fTipComposite.setLayout(new GridLayout(3, false)); setupControl(fTipComposite);
private boolean considerBinding(IBinding binding, ASTNode node) { if (!(binding instanceof IVariableBinding)) return false; boolean result = Bindings.equals(fFieldBinding, ((IVariableBinding) binding).getVariableDeclaration()); if (!result || (fEncapsulateDeclaringClass && !fGetter.isEmpty() && !fSetter.isEmpty())) return result; AbstractTypeDeclaration type = ASTNodes.getParent(node, AbstractTypeDeclaration.class); if (type != null) { ITypeBinding declaringType = type.resolveBinding(); return !Bindings.equals(fDeclaringClassBinding, declaringType); } return true; }
invocation.setName(ast.newSimpleName(fSetter)); if (receiver != null) invocation.setExpression((Expression)fRewriter.createCopyTarget(receiver)); invocation.arguments().add(argument); if ("++".equals(operator)) { //$NON-NLS-1$ argument.setOperator(InfixExpression.Operator.PLUS); } else if ("--".equals(operator)) { //$NON-NLS-1$ argument.setOperator(InfixExpression.Operator.MINUS); } else { Assert.isTrue(false, "Should not happen"); //$NON-NLS-1$ } fReferencingSetter = true; MethodInvocation getter = ast.newMethodInvocation(); getter.setName(ast.newSimpleName(fGetter)); if (receiver != null) getter.setExpression((Expression)fRewriter.createCopyTarget(receiver)); argument.setLeftOperand(getter); argument.setRightOperand(ast.newNumberLiteral("1")); //$NON-NLS-1$ fReferencingGetter = true; return invocation;
if (fEncapsulateDeclaringClass) { comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_use_accessors); } else { comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_do_not_use_accessors); } if (fGenerateJavadoc) { comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_generate_comments); } final EncapsulateFieldDescriptor descriptor = RefactoringSignatureDescriptorFactory.createEncapsulateFieldDescriptor(project, description, comment.asString(), arguments, flags); arguments.put(JavaRefactoringDescriptorUtil.ATTRIBUTE_INPUT, JavaRefactoringDescriptorUtil.elementToHandle(project, fField)); arguments.put(ATTRIBUTE_VISIBILITY, Integer.valueOf(JdtFlags.getVisibilityCode(visibility)).toString()); arguments.put(ATTRIBUTE_INSERTION, Integer.valueOf(fInsertionIndex).toString()); if (fCreateSetter) { arguments.put(ATTRIBUTE_SETTER, fSetterName); } if (fCreateGetter) { arguments.put(ATTRIBUTE_GETTER, fGetterName); } arguments.put(ATTRIBUTE_COMMENTS, Boolean.valueOf(fGenerateJavadoc).toString()); arguments.put(ATTRIBUTE_DECLARING, Boolean.valueOf(fEncapsulateDeclaringClass).toString()); final DynamicValidationRefactoringChange result = new DynamicValidationRefactoringChange(descriptor, getName()); TextChange[] changes = fChangeManager.getAllChanges(); pm.beginTask(NO_NAME, changes.length);
//extern "C"{ //void func(); //} public void testLinkage2_Bug299482() throws Exception { fOptions.put(DefaultCodeFormatterConstants.FORMATTER_INSERT_SPACE_BEFORE_OPENING_BRACE_IN_LINKAGE_DECLARATION, DefaultCodeFormatterConstants.FALSE); assertFormatterResult(); } //extern "C" { //void func(); //} //extern "C" //{ //void func(); //} public void testLinkage3_Bug299482() throws Exception { fOptions.put(DefaultCodeFormatterConstants.FORMATTER_BRACE_POSITION_FOR_LINKAGE_DECLARATION, DefaultCodeFormatterConstants.NEXT_LINE); } //#define EMPTY1(x) //#define EMPTY2(x) //int main() { // EMPTY1(bool x = true); // EMPTY2(bool x = true); // return 0; //} //#define EMPTY1(x) //#define EMPTY2(x) //int main() { // EMPTY1(bool x = true); // EMPTY2(bool x = true); // return 0; //} public void testEmptyMacros_Bug361768() throws Exception { assertFormatterResult(); }
/***************************************************************************** * Copyright (c) 2019 Obeo. * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *****************************************************************************/ package org.eclipse.sirius.tests.sample.component.service; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.List; import java.util.function.Predicate; import org.eclipse.emf.common.notify.Notification; import org.eclipse.emf.ecore.EObject; import org.eclipse.gmf.runtime.notation.DrawerStyle; import org.eclipse.gmf.runtime.notation.Node; import org.eclipse.gmf.runtime.notation.NotationPackage; import org.eclipse.sirius.diagram.DDiagram; import org.eclipse.sirius.diagram.DDiagramElement; import org.eclipse.sirius.diagram.DNodeContainer; import org.eclipse.sirius.diagram.business.api.query.EObjectQuery; import org.eclipse.sirius.diagram.ui.business.api.view.SiriusGMFHelper; import org.eclipse.sirius.ext.base.Option;
components.addAll(component.getReferences2()); for (Component child : component.getChildren()) { components.addAll(getReference2Hierarchy(child)); } return components; } /** * Determines if a reference should be displayed. * * @param source The source component * @param sourceView The source view * @param targetView The target view * @return True if the reference should be displayed; otherwise false */ public boolean isReferenceToDisplay(Component source, DNodeContainer sourceView, DNodeContainer targetView) { if (!isIndirectlyCollapsed(sourceView) && !isIndirectlyCollapsed(targetView)) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer) { if (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion")) { for (DDiagramElement child2 : ((DNodeContainer) child).getOwnedDiagramElements()) { // Check if there is a shortest reference to display if (child2 instanceof DEdge) { DEdge edge = (DEdge) child2; if (edge.getTargetNode() == targetView) { return false; } } } } } } return true; } return false; }
import java.util.Collection; import org.eclipse.gmf.runtime.notation.Node; import org.eclipse.sirius.diagram.DNodeContainer; import org.eclipse.sirius.diagram.ui.tools.api.graphical.edit.styles.DrawerStyle; import org.eclipse.sirius.diagram.ui.tools.api.graphical.edit.styles.SiriusGMFHelper; public class MyClass { protected boolean isIndirectlyCollapsed(DNodeContainer container) { if (isContainerCollapsed(container)) { return true; } else if (container.eContainer() instanceof DNodeContainer && isContainerCollapsed((DNodeContainer) container.eContainer())) { return true; } else { return false; } } protected boolean isContainerCollapsed(DNodeContainer container) { Node gmfNode = SiriusGMFHelper.getGmfNode(container); if (gmfNode != null) { for (Object subNode : gmfNode.getChildren()) { if (subNode instanceof Node) { for (Object style : ((Node) subNode).getStyles()) { if (style instanceof DrawerStyle) { return ((DrawerStyle) style).isCollapsed(); } } } } } return false; } private void appendChildren(Component component, Collection<Component> allChildren) { // implementation } }
SWTBotGefEditPart parentEdgeTargetEditPart = editor.getEditPart("DC.2.1", AbstractDiagramElementContainerEditPart.class); DEdgeEditPart edgeEditPart = (DEdgeEditPart) ((AbstractDiagramElementContainerEditPart) edgeSourceEditPart.part()).getSourceConnections().get(0); assertTrue("The edge should be visible after diagram opening.", edgeEditPart.getFigure().isVisible()); collapseOrExpandContainer(parentEdgeSourceEditPart); assertFalse("The edge should be hidden after collapsing the container of the target of the edge.", edgeEditPart.getFigure().isVisible()); assertEquals("The edge already exists, even if it is not visible.", 1, ((AbstractDiagramElementContainerEditPart) edgeSourceEditPart.part()).getSourceConnections().size()); assertEquals("No edge from the collapsed container should appear because the collapse notification has not yet been registered.", 0, ((AbstractDiagramElementContainerEditPart) edgeSourceEditPart.part()).getTargetConnections().size());
private void collapseOrExpandContainer(SWTBotGefEditPart container) { ICondition editPartResizedCondition = new CheckEditPartResized(container); // Select the region contained in the container AbstractDiagramElementContainerEditPart part = (AbstractDiagramElementContainerEditPart) container.part(); GraphicalHelper.getAbsoluteBoundsIn100Percent(part); Point top = GraphicalHelper.getAbsoluteBoundsIn100Percent(part).getTop(); editor.click(top.getTranslated(0, 40)); // Collapse the region bot.waitUntil(new ICondition() { @Override public boolean test() throws Exception { IFigure handleLayer = LayerManager.Helper.find(part).getLayer(LayerConstants.HANDLE_LAYER); Point toggleFigureLocation; if (handleLayer != null) { for (Object figure : handleLayer.getChildren()) { if (figure instanceof CompartmentCollapseHandle) { toggleFigureLocation = ((CompartmentCollapseHandle) figure).getLocation(); if (toggleFigureLocation.x != 0 && toggleFigureLocation.y != 0) { // Use the center of the figure and click on it return true; } } } } return false; } }); // Click on the toggle figure bot.waitUntil(new ICondition() { @Override public boolean test() throws Exception { IFigure handleLayer = LayerManager.Helper.find(part).getLayer(LayerConstants.HANDLE_LAYER); Point toggleFigureLocation; if (handleLayer != null) { for (Object figure : handleLayer.getChildren()) { if (figure instanceof CompartmentCollapseHandle) { toggleFigureLocation = ((CompartmentCollapseHandle) figure).getLocation(); if (toggleFigureLocation.x != 0 && toggleFigureLocation.y != 0) { // Use the center of the figure and click on it editor.click(toggleFigureLocation); return true; } } } } return false; } }); }
private Repository remoteRepository; private URIish remoteURI; @Override @Before public void setUp() throws Exception { super.setUp(); final TestRepository<Repository> src = createTestRepository(); final String srcName = src.getRepository().getDirectory().getName(); ServletContextHandler app = server.addContext("/git"); GitServlet gs = new GitServlet(); gs.setRepositoryResolver((HttpServletRequest req, String name) -> { if (!name.equals(srcName)) { throw new RepositoryNotFoundException(name); } final Repository db = src.getRepository(); db.incrementOpen(); return db; }); gs.setReceivePackFactory(new DefaultReceivePackFactory() { @Override public ReceivePack create(HttpServletRequest req, Repository db) throws ServiceNotEnabledException, ServiceNotAuthorizedException { ReceivePack rp = super.create(req, db); rp.sendError("message line 1"); rp.sendError("no soup for you!"); rp.sendError("come back next year!"); return rp; } }); app.addServlet(new ServletHolder(gs), "/*"); }
private URIish remoteURI; @Override @Before public void setUp() throws Exception { super.setUp(); final TestRepository<Repository> src = createTestRepository(); final String srcName = src.getRepository().getDirectory().getName(); ServletContextHandler app = server.addContext("/git"); GitServlet gs = new GitServlet(); gs.setRepositoryResolver((HttpServletRequest req, String name) -> { if (!name.equals(srcName)) throw new RepositoryNotFoundException(name); final Repository db = src.getRepository(); db.incrementOpen(); return db; }); gs.setReceivePackFactory(new DefaultReceivePackFactory() { @Override public ReceivePack create(HttpServletRequest req, Repository db) throws ServiceNotEnabledException, ServiceNotAuthorizedException { ReceivePack rp = super.create(req, db); rp.sendError("message line 1"); rp.sendError("no soup for you!"); rp.sendError("come back next year!"); return rp; } }); app.addServlet(new ServletHolder(gs), "/*"); server.setUp(); }
private void verifyObjectsOrder(ObjectId objectsOrder[]) { final List<PackIndex.MutableEntry> entries = new ArrayList<>(); for (MutableEntry me : pack) { entries.add(me.cloneEntry()); } Collections.sort(entries, (MutableEntry o1, MutableEntry o2) -> Long.signum(o1.getOffset() - o2.getOffset())); int i = 0; for (MutableEntry me : entries) { assertEquals(objectsOrder[i++].toObjectId(), me.toObjectId()); } }
public Optional<T> getFirstResult() { Collection<T> list = getResult(); if (list != null) { return list.stream().findFirst(); } return Optional.empty(); }
protected void setResult(Collection<T> newUserSelection) { result = newUserSelection; }
if (name1 == null) { name1 = ""; } if (name2 == null) { name2 = ""; } return coll.compare(name1, name2); // Find primary feature for (AboutInfo feature : features) { if (feature.getFeatureId().equals(primaryFeatureId)) { setInitialSelection(feature); return; } } // set a safe default setInitialSelection(Collections.emptyList());
private boolean matches(IService service, Class<?>[] argumentTypes) { assert service.getNumberOfParameters() != argumentTypes.length; boolean result = true; final List<IType> parameterTypes = service.getParameterTypes(queryEnvironment); for (int i = 0; i < parameterTypes.size() && result; i++) { if (argumentTypes[i] != null && !parameterTypes.get(i).isAssignableFrom(new ClassType(queryEnvironment, argumentTypes[i]))) { result = false; break; } } return result; } private static DiffPreferencesInfo updateDefaults(DiffPreferencesInfo input) { DiffPreferencesInfo result = DiffPreferencesInfo.defaults(); try { for (Field field : update.getClass().getDeclaredFields()) { if (skipField(field)) { continue; } Object newVal = field.get(update); if (newVal != null) { field.set(def, newVal); } } } catch (IllegalAccessException e) { e.printStackTrace(); } return def; } public UUID getAnonymousId() { UUID result = anonymousId; if (result == null) { synchronized (this) { result = anonymousId; if (result == null) { result = anonymousId = readOrCreateAnonymousId(); } } } return result; } public abstract class AbstractSelectionDialog<T> extends TrayDialog { private Collection<T> result; private List<T> initialSelection; private String title; private String message = ""; private int dialogBoundsStrategy = Dialog.DIALOG_PERSISTLOCATION | Dialog.DIALOG_PERSISTSIZE; private IDialogSettings dialogBoundsSettings = null; protected AbstractSelectionDialog(Shell parentShell) { super(parentShell); } public Collection<T> getResult() { return result != null ? result : Collections.emptyList(); } }
public Optional<T> getFirstResult() { Collection<T> list = getResult(); if (list == null) { return Optional.empty(); } Iterator<T> iterator = list.iterator(); if (iterator.hasNext()) { return Optional.of(iterator.next()); } return Optional.empty(); }
private static DiffPreferencesInfo updateDefaults(DiffPreferencesInfo input) { DiffPreferencesInfo result = DiffPreferencesInfo.defaults(); try { for (Field field : update.getClass().getDeclaredFields()) { if (skipField(field)) { continue; } Object newVal = field.get(update); if (newVal != null) { field.set(def, newVal); } } } catch (IllegalAccessException e) { e.printStackTrace(); } return def; }
private boolean matches(IService service, Class<?>[] argumentTypes) { assert service.getNumberOfParameters() != argumentTypes.length; boolean result = true; final List<IType> parameterTypes = service.getParameterTypes(queryEnvironment); for (int i = 0; i < parameterTypes.size() && result; i++) { if (argumentTypes[i] != null && !parameterTypes.get(i).isAssignableFrom(new ClassType(queryEnvironment, argumentTypes[i]))) { result = false; break; } } return result; } private static DiffPreferencesInfo updateDefaults(DiffPreferencesInfo input) { DiffPreferencesInfo result = DiffPreferencesInfo.defaults(); try { for (Field field : update.getClass().getDeclaredFields()) { if (skipField(field)) { continue; } Object newVal = field.get(update); if (newVal != null) { field.set(def, newVal); } } } catch (IllegalAccessException e) { e.printStackTrace(); } return def; } for (Object o : callbacks) { try { Object result = results.get(o); if (o instanceof AsyncCallback) { @SuppressWarnings("unchecked") AsyncCallback<Object> cb = (AsyncCallback<Object>) o; cb.onSuccess(result); } else { @SuppressWarnings("unchecked") com.google.gwtjsonrpc.common.AsyncCallback<Object> cb = (com.google.gwtjsonrpc.common.AsyncCallback<Object>) o; cb.onSuccess(result); } } catch (Throwable t) { if (caught == null) { caught = t; } } } if (caught != null) { if (caught instanceof RuntimeException) { throw (RuntimeException) caught; } else if (caught instanceof Error) { throw (Error) caught; } else { throw new RuntimeException(caught); } } protected void setResult(T... newUserSelection) { result = null; if (newUserSelection != null) { result = Arrays.asList(newUserSelection); } }
import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } }
ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } @Test public void testShouldNotSearchPacksAgainTheSecondTime() throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); assertTrue(dir.searchPacksAgain(dir.packList.get())); // Make sure that the modified and read timestamps so that a full // file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION,null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir(
assertNotNull(fIterator); assertEquals(fIterator, fIterator); try (CtfIterator obj = (CtfIterator) fTrace.createIterator();) { assertNotNull(obj); assertNotEquals(fIterator, obj); CtfLocation ctfLocation1 = new CtfLocation(new CtfLocationInfo(1, 0)); obj.setLocation(ctfLocation1); obj.increaseRank(); assertEquals(fIterator, obj); } CtfTmfTrace trace = CtfTmfTestTraceUtils.getTrace(CtfTestTrace.FUNKY_TRACE); assertNotNull(trace); try(CtfIterator funky = (CtfIterator) trace.createIterator()){ assertNotEquals(fIterator, funky); } try(CtfIterator iter = (CtfIterator) fTrace.createIterator();){ CTFTrace otherTrace = new CTFTrace(fTrace.getPath()); try(CTFTraceReader tr = new CTFTraceReader(otherTrace)){ assertNotEquals(iter, tr); } } trace.dispose(); try(CtfIterator iter1 = (CtfIterator) fTrace.createIterator(); CtfIterator iter2 = (CtfIterator) fTrace.createIterator()){ assertEquals(iter1, iter2); iter2.setRank(2); assertNotEquals(iter1, iter2); }
assertNotNull(obj); assertNotEquals(fIterator, obj); CtfLocation ctfLocation1 = new CtfLocation(new CtfLocationInfo(1, 0)); obj.setLocation(ctfLocation1); obj.increaseRank(); assertEquals(fIterator, obj); } CtfTmfTrace trace = CtfTmfTestTraceUtils.getTrace(CtfTestTrace.FUNKY_TRACE); assertNotNull(trace); try (CtfIterator funky = (CtfIterator) trace.createIterator()) { assertNotEquals(fIterator, funky); } try (CtfIterator iter = (CtfIterator) fTrace.createIterator()) { CTFTrace otherTrace = new CTFTrace(fTrace.getPath()); try (CTFTraceReader tr = new CTFTraceReader(otherTrace)) { assertNotEquals(iter, tr); } } trace.dispose(); try (CtfIterator iter1 = (CtfIterator) fTrace.createIterator(); CtfIterator iter2 = (CtfIterator) fTrace.createIterator()) { assertEquals(iter1, iter2); iter2.setRank(2); assertNotEquals(iter1, iter2); } /** * Run the boolean equals(Object) method test. Compare with an empty object. */ @Test public void testEquals_empty() {
public static double ceil(double d) { final long bits = Double.doubleToRawLongBits(d); int highBits = (int) (bits >>> 32); // high word of d int lowBits = (int) bits; // low word of d int exp = ((highBits >> 20) & 0x7ff) - 0x3ff; // value of exponent /* negative exponent */ if (exp < 0) { if (HUGE + d > 0.0) { if (highBits < 0) { // if |d| < 1 return -0 highBits = 0x80000000; } else if ((highBits | lowBits) != 0) { // raise inexact if d != 0, this is ignored by Java highBits = 0x3ff00000; // return 1 } lowBits = 0; } } /* exponent in range [0, 20) */ else if (exp < 0x014) { i = (0x000fffff) >> exp; } return d; // d is integral } /* exponent in range [21,51] */ else { i = (0xffffffff) >> (exp - 0x014); /* d is integral */ if ((lowBits & i) == 0) { return d; } /* raise inexact flag: this is ignored by Java */ if (HUGE + d > 0.0) { if (highBits > 0) { if (exp == 0x014) { highBits +=1; } else { int j = lowBits + (0x1 << (0x34 - exp)); // careful, should be unsigned if (j < lowBits) { highBits += 0x1; // carry occurred } lowBits = j; } } lowBits &= (~i); } } return Double.longBitsToDouble(((long)highBits << 32) | lowBits);
// if ret == true, then currentEvent is non-null if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); /* Update the current location accordingly */ if (ret) { fCurLocation = new CtfLocation(new CtfLocationInfo(Objects.requireNonNull(currentEvent).getTimestamp().getValue(), 0)); } else { fCurLocation = NULL_LOCATION; } return ret;
package org.eclipse.jgit.internal.storage.file; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.concurrent.Callable; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; import org.eclipse.jgit.internal.storage.pack.PackWriter; import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { // Test code here }
package org.eclipse.jgit.internal.storage.file; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.concurrent.Callable; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; import org.eclipse.jgit.internal.storage.pack.PackWriter; import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false); } }
import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); // Test code goes here } } }
import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; import java.util.Arrays; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(Boolean.TRUE, Boolean.FALSE); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime() throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); // test code continues... } }
FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); assertTrue(dir.searchPacksAgain(dir.packList.get())); // Make sure that the modified and read timestamps so that a full // file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository<>(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir(final ObjectDirectory dir) { Callable<ObjectId> callable = new Callable<ObjectId>() { public ObjectId call() throws Exception { return dir.newInserter().insert(Constants.OBJ_BLOB, new byte[0]); } }; return Collections.singleton(callable); }
// file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir(final ObjectDirectory dir) { Callable<ObjectId> callable = new Callable<ObjectId>() { public ObjectId call() throws Exception { return dir.newInserter().insert(Constants.OBJ_BLOB, new byte[0]); } }; return Collections.nCopies(4, callable); }
assertTrue(traceAdapter.isThereATraceBetween(_A, _B, upDatedTraceModel)); // Clear selection view SelectionView.getOpenedView().clearSelection(); // create a selection with class A List<Object> selection = new ArrayList<>(); selection.add(_A); // test that internal links show for direct elements ToggleTransitivityHandler.setTraceViewTransitive(false); DisplayInternalLinksHandler.showInternalLinks(true); DiagramTextProviderHandler provider = new DiagramTextProviderHandler(); String directlyConnectedElements = provider.getDiagramText(selection); assertTrue(directlyConnectedElements.equals(EXPECTED_TEXT_FOR_INTERNAL_LINKS)); }
assertEquals(1331668250328561095L, middleEvent.getTimestamp().toNanos()); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 1L))); CtfTmfEvent doubleEvent = iterator.getCurrentEvent(); assertNotNull(doubleEvent); assertEquals(1331668247328921944L, doubleEvent.getTimestamp().toNanos()); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); assertEquals("sched_switch", doubleEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 9001000000L))); CtfTmfEvent overNineThousandEvent = iterator.getCurrentEvent(); assertNotNull(overNineThousandEvent); assertEquals(1331668247328925363L, overNineThousandEvent.getTimestamp().toNanos()); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", overNineThousandEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 4L))); CtfTmfEvent quadEvent = iterator.getCurrentEvent(); assertNotNull(quadEvent); assertEquals(new CtfLocationInfo(1331668247328921944L, 1L), iterator.getLocation().getLocationInfo());
assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 1L))); CtfTmfEvent doubleEvent = iterator.getCurrentEvent(); assertNotNull(doubleEvent); assertEquals(1331668247328921944L, doubleEvent.getTimestamp().toNanos()); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); // test that events will be in cpu order assertEquals("sched_switch", doubleEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 9001000000L))); CtfTmfEvent overNineThousandEvent = iterator.getCurrentEvent(); assertNotNull(overNineThousandEvent); assertEquals(1331668247328925363L, overNineThousandEvent.getTimestamp().toNanos()); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", overNineThousandEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 4L))); CtfTmfEvent quadEvent = iterator.getCurrentEvent(); assertNotNull(quadEvent); assertEquals(1331668247328925363L, quadEvent.getTimestamp().toNanos()); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", quadEvent.getName()); assertFalse(iterator.seek(CtfLocation.INVALID_LOCATION));
} } catch (CTFException e) { Activator.getDefault().logError(e.getMessage(), e); return false; } /* * Check if there is already one or more events for that timestamp, and * assign the location index correctly */ long index = 0; ITmfEvent currentEvent = getCurrentEvent(); ret &= (currentEvent != null); ITmfEvent previousEvent = currentEvent; for (long i = 0; ret && i < ctfLocationData.getIndex(); i++) { // if ret == true, then currentEvent is non-null if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { index = 0; break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); } /* Update the current location accordingly */ if (ret) { fCurLocation = new CtfLocation(new CtfLocationInfo(Objects.requireNonNull(previousEvent).getTimestamp().getValue(), index)); } else { fCurLocation = NULL_LOCATION; }
// if ret == true, then currentEvent is non-null if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { index = 0; break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); } /* Update the current location accordingly */ if (ret) { fCurLocation = new CtfLocation(new CtfLocationInfo(Objects.requireNonNull(currentEvent).getTimestamp().getValue(), index)); } else { fCurLocation = NULL_LOCATION; } return ret;
private boolean checkNullDefaultFlow() { return !this.switchLabeledRules; } @Override public FlowInfo analyseCode(BlockScope currentScope, FlowContext flowContext, FlowInfo flowInfo) { try { flowInfo = this.expression.analyseCode(currentScope, flowContext, flowInfo); if ((this.expression.implicitConversion & TypeIds.UNBOXING) != 0 || (this.expression.resolvedType != null && (this.expression.resolvedType.id == T_JavaLangString || this.expression.resolvedType.isEnum()))) { this.expression.checkNPE(currentScope, flowContext, flowInfo, 1); } SwitchFlowContext switchContext = (SwitchFlowContext) flowContext; if (this.expression.resolvedType != null && this.expression.resolvedType.isBaseType()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.constant != Constant.NotAConstant) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.res
import java.io.IOException; import javax.servlet.Filter; import javax.servlet.FilterChain; import javax.servlet.FilterConfig; import javax.servlet.ServletException; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class MyFilter implements Filter { private FilterConfig filterConfig; @Override public void init(FilterConfig filterConfig) throws ServletException { this.filterConfig = filterConfig; } @Override public void destroy() { // Cleanup resources } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest httpRequest = (HttpServletRequest) request; HttpServletResponse httpResponse = (HttpServletResponse) response; chain.doFilter(httpRequest, httpResponse); httpResponse.sendError(HttpServletResponse.SC_NOT_FOUND); } }
package org.eclipse.tracecompass.internal.tmf.ui.views; public interface ITmfTimeNavigationProvider { void horizontalScroll(boolean left); }
public interface ITmfZoomToSelectionProvider { void zoomToSelection(); }
/* * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.views.handler; import org.eclipse.core.commands.AbstractHandler; import org.eclipse.core.commands.ExecutionEvent; import org.eclipse.core.commands.ExecutionException; import org.eclipse.tracecompass.tmf.ui.views.TmfView; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.IWorkbenchWindow; import org.eclipse.ui.PlatformUI; import org.eclipse.ui.handlers.HandlerUtil; /** * Base handler, makes sure we have a timegraph control selected * * @author Matthew Khouzam */ abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute(ExecutionEvent event) throws ExecutionException { // Check if we are closing down IWorkbenchWindow window = PlatformUI.getWorkbench().getActiveWorkbenchWindow(); if (window == null) { return null; } IWorkbenchPart part = HandlerUtil.getActivePart(event); if (part instanceof TmfView) { execute((TmfView) part); } return null; } public abstract void execute(TmfView timegraph); }
abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute(ExecutionEvent event) throws ExecutionException { IWorkbenchWindow window = PlatformUI.getWorkbench().getActiveWorkbenchWindow(); if (window == null) { return null; } IWorkbenchPart part = HandlerUtil.getActivePart(event); if (part instanceof TmfView) { execute((TmfView) part); } return null; } public abstract void execute(TmfView view); }
import org.eclipse.tracecompass.internal.tmf.ui.views.ITmfTimeZoomProvider; import org.eclipse.tracecompass.tmf.ui.views.TmfView; public class TmfViewZoomInHandler extends TmfViewBaseHandler { @Override public void execute(TmfView view) { ITmfTimeZoomProvider zoomer = view.getAdapter(ITmfTimeZoomProvider.class); if (zoomer != null) { zoomer.zoom(true); } } }
import org.eclipse.sirius.tests.swtbot.support.api.editor.SWTBotSiriusDiagramEditor; import org.eclipse.sirius.tests.swtbot.support.utils.SWTBotUtils; import org.eclipse.swt.SWT; import org.eclipse.swtbot.eclipse.gef.finder.widgets.SWTBotGefEditPart; public class EditPartSelectionTest extends AbstractSiriusSwtBotGefTestCase { private static final String DATA_UNIT_DIR = "/data/unit/selection/"; private static final String MODEL = "TestSelection.ecore"; private static final String SESSION_FILE = "TestSelection.aird"; private static final String VSM_FILE = "My.odesign"; private static final String REPRESENTATION_DECRIPTION_NAME = "Entities"; private static final String REPRESENTATION_NAME = "diagram"; private static final PrecisionPoint INITIAL_NODE_CENTER_POSITION = new PrecisionPoint(856.0, 412.0); private Session session; @Override protected void onSetUpBeforeClosingWelcomePage() throws Exception { // Code goes here } }
import org.eclipse.egerrit.core.rest.CommentRange; import com.google.gwtorm.client.Column; public class CommentRange { @Column(id = 1) protected int startLine; @Column(id = 2) protected int startCharacter; @Column(id = 3) protected int endLine; @Column(id = 4) protected int endCharacter; public CommentRange() { } public CommentRange(int sl, int sc, int el, int ec) { startLine = sl; startCharacter = sc; endLine = el; endCharacter = ec; } public int getStartLine() { return startLine; } public int getStartCharacter() { return startCharacter; } public int getEndLine() { return endLine; } public int getEndCharacter() { return endCharacter; } public void setStartLine(int sl) { startLine = sl; } public void setStartCharacter(int sc) { startCharacter = sc; } public void setEndLine(int el) { endLine = el; } public void setEndCharacter(int ec) { endCharacter = ec; } }
assertNull(getCurrentEvent(iterator)); assertEquals(0L, iterator.getCurrentTimestamp()); assertFalse(iterator.advance()); CtfLocationInfo middleLocation = new CtfLocationInfo(1331668250328561095L, 0L); assertTrue(iterator.seek(middleLocation)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561095L, getTimestampInNanos(event)); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); CtfLocationInfo middleLocationIndexedOne = new CtfLocationInfo(1331668250328561095L, 1L); assertTrue(iterator.seek(middleLocationIndexedOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561761L, getTimestampInNanos(event)); assertEquals(1331668250328561761L, iterator.getCurrentTimestamp()); assertEquals(new CtfLocationInfo(1331668250328561761L, 0L), iterator.getLocation().getLocationInfo()); CtfLocationInfo duplicateLocationIndexedOne = new CtfLocationInfo(1331668247328921944L, 1L); assertTrue(iterator.seek(duplicateLocationIndexedOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328921944L, getTimestampInNanos(event));
assertTrue(iterator.seek(middleLocation)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561095L, getTimestampInNanos(event)); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); CtfLocationInfo middleLocationIndexeOne = new CtfLocationInfo(1331668250328561095L, 1L); assertTrue(iterator.seek(middleLocationIndexeOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561761L, getTimestampInNanos(event)); assertEquals(1331668250328561761L, iterator.getCurrentTimestamp()); assertEquals(new CtfLocationInfo(1331668250328561761L, 0L), iterator.getLocation().getLocationInfo()); // double timestamp at 15:50:47.328921944 CtfLocationInfo duplicateLocationIndexedOne = new CtfLocationInfo(1331668247328921944L, 1L); assertTrue(iterator.seek(duplicateLocationIndexedOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328921944L, getTimestampInNanos(event)); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); // test that events will be in cpu order assertEquals("sched_switch", event.getName()); assertEquals(duplicateLocationIndexedOne, iterator.getLocation().getLocationInfo());
Rectangle getBoundsInPixels () { computeRuns(null); int width = 0; if (wrapWidth != -1) { width = wrapWidth; } else { for (int line=0; line<runs.length; line++) { width = Math.max(width, lineWidth[line] + getLineIndent(line)); } } return new Rectangle (0, 0, width, lineY[lineY.length - 1]); } package com.google.gerrit.server.query.change; import com.google.gerrit.reviewdb.client.Change; import com.google.gerrit.server.index.ChangeField; import com.google.gerrit.server.index.IndexPredicate; import com.google.gwtorm.server.OrmException; public class DependsOnPredicate extends IndexPredicate<ChangeData> { DependsOnPredicate(String prefix) { super(ChangeField.DEPENDS_ON, prefix); } @Override public boolean match(ChangeData object) throws OrmException { Change c = object.change(); try { for (FooterLine f : c.commitFooters()) { if (f.getKey().equals()) { return f.getValue(); } } } catch (NoSuchChangeException | IOException e) { } return null; } @Override public int getCost() { return 1; } } } progress.endTask(); return new SiteIndexer.Result(sw, ok.get(), done.get(), failed.get()); } private List<Project.NameKey> collectProjects(ProgressMonitor progress) throws OrmException { progress.beginTask("Collecting projects", ProgressMonitor.UNKNOWN); List<Project.NameKey> names = new ArrayList<>(); for (Project.NameKey nameKey : projectCache.all()) { names.add(nameKey); } progress.endTask(); return names; } CtfLocationInfo duplicateLocationOutOfBounds = new CtfLocationInfo(1331668247328921944L, 4L); assertTrue(iterator.seek(duplicateLocationOutOfBounds)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328925363L, getTimestampInNanos(event)); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", event.getName()); // next event location assertEquals(new CtfLocationInfo(1331668247328925363L, 0L), iterator.getLocation().getLocationInfo()); Ctf
import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import org.eclipse.tracecompass.ctf.core.event.CtfTmfEvent; import org.eclipse.tracecompass.ctf.core.iterator.CtfIterator; import org.eclipse.tracecompass.ctf.core.trace.CtfLocation; import org.eclipse.tracecompass.ctf.core.trace.CtfLocationInfo; import org.eclipse.tracecompass.ctf.core.trace.CtfLocation.INVALID_LOCATION; import org.eclipse.tracecompass.ctf.core.trace.CtfTmfTrace; import org.junit.After; import org.junit.Before; import org.junit.Test; public class CtfIteratorTest { private CtfIterator fIterator; private CtfTmfTrace fTrace; @Before public void setUp() throws Exception { fTrace = new CtfTmfTrace(); fIterator = new CtfIterator(fTrace); } @After public void tearDown() throws Exception { fIterator.dispose(); fTrace.dispose(); } @Test public void testGetCurrentEvent() { CtfTmfEvent event = new CtfTmfEvent(); fIterator.setCurrentEvent(event); assertEquals(event, fIterator.getCurrentEvent()); } @Test public void testGetTimestampInNanos() { CtfTmfEvent event = new CtfTmfEvent(); event.setTimestamp(1331668247328925363L); assertEquals(1331668247328925363L, getTimestampInNanos(event)); } @Test public void testSetLocation() { CtfLocation location = new CtfLocation(new CtfLocationInfo(1, 0)); fIterator.setLocation(location); } private static long getTimestampInNanos(CtfTmfEvent event) { return event.getTimestamp().toNanos(); } }
import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import org.eclipse.tracecompass.ctf.core.event.CtfTmfEvent; import org.eclipse.tracecompass.ctf.core.iterator.CtfIterator; import org.eclipse.tracecompass.ctf.core.trace.CtfLocation; import org.eclipse.tracecompass.ctf.core.trace.CtfLocationInfo; import org.eclipse.tracecompass.tmf.core.trace.location.ITmfLocation; import org.junit.Test; public class CtfIteratorTest { private CtfIterator fIterator; public CtfIteratorTest() { fIterator = new CtfIterator(); } @Test public void testGetCurrentEvent() { CtfTmfEvent event = new CtfTmfEvent(); fIterator.setCurrentEvent(event); assertEquals(event, getCurrentEvent(fIterator)); } @Test public void testGetTimestampInNanos() { CtfTmfEvent event = new CtfTmfEvent(); event.setTimestamp(1331668247328925363L); assertEquals(1331668247328925363L, getTimestampInNanos(event)); } @Test public void testSetLocation() { CtfLocation location = new CtfLocation(new CtfLocationInfo(1, 0)); fIterator.setLocation(location); } private static CtfTmfEvent getCurrentEvent(CtfIterator iterator) { return iterator.getCurrentEvent(); } private static long getTimestampInNanos(CtfTmfEvent event) { return event.getTimestamp().toNanos(); } }
public boolean isReferenceToDisplay(Component source, DNodeContainer sourceView, DNodeContainer targetView) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer && (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion"))) { for (DDiagramElement grandchild : ((DNodeContainer) child).getOwnedDiagramElements()) { if (isReferenceDisplayedByChild((DNodeContainer) grandchild, targetView)) { return false; } } } } return true; }
// if (!isIndirectlyCollapsed(sourceView) && !isIndirectlyCollapsed(targetView)) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer && (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion"))) { for (DDiagramElement grandchild : ((DNodeContainer) child).getOwnedDiagramElements()) { if (isReferenceDisplayedByChild((DNodeContainer) grandchild, targetView)) { return false; } } } } return true; // } // return false;
/** * Copyright (c) 2010, 2019 THALES GLOBAL SERVICES * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - Initial API and implementation */ package org.eclipse.sirius.tests.swtbot.support.api.editor; import java.util.Iterator; import java.util.List; import java.util.concurrent.atomic.AtomicBoolean; import org.eclipse.core.runtime.IAdaptable; import org.eclipse.draw2d.FigureCanvas; import org.eclipse.draw2d.IFigure; import org.eclipse.draw2d.Label; import org.eclipse.draw2d.LightweightSystem; import org.eclipse.draw2d.geometry.Point; import org.eclipse.draw2d.text.TextFlow; import org.eclipse.gef.EditPart; import org.eclipse.gef.GraphicalEditPart; import org.eclipse.gef.GraphicalViewer; import org.eclipse.sirius.ext.gmf.runtime.gef.ui.figures.SiriusWrapLabel; import org.eclipse.sirius.tests.swtbot.support.api.widget.SWTBotSiriusFigureCanvas;
/* * Copyright (c) 2012, 2019 THALES GLOBAL SERVICES * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - Initial API and implementation */ package org.eclipse.sirius.tests.swtbot.support.api.widget; import java.util.concurrent.atomic.AtomicBoolean; import org.eclipse.draw2d.FigureCanvas; import org.eclipse.draw2d.LightweightSystem; import org.eclipse.swt.SWT; import org.eclipse.swt.events.KeyEvent; import org.eclipse.swt.widgets.Canvas; import org.eclipse.swt.widgets.Event; import org.eclipse.swt.widgets.Text; import org.eclipse.swtbot.eclipse.gef.finder.widgets.SWTBotGefFigureCanvas; import org.eclipse.swtbot.swt.finder.exceptions.WidgetNotFoundException; import org.eclipse.swtbot.swt.finder.finders.UIThreadRunnable; import org.eclipse.swtbot.swt.finder.results.Result; import org.eclipse.swtbot.swt.finder.results.VoidResult; import org.eclipse.swtbot.swt.finder.utils.SWTUtils; /**
/***************************************************************************** * Copyright (c) 2019 THALES GLOBAL SERVICES. * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *****************************************************************************/ package org.eclipse.sirius.tests.swtbot; import org.eclipse.draw2d.IFigure; import org.eclipse.draw2d.geometry.PrecisionPoint; import org.eclipse.draw2d.geometry.Rectangle; import org.eclipse.gef.GraphicalEditPart; import org.eclipse.gef.LayerConstants; import org.eclipse.gef.editparts.LayerManager; import org.eclipse.gmf.runtime.diagram.ui.editparts.AbstractBorderedShapeEditPart; import org.eclipse.gmf.runtime.diagram.ui.editparts.ConnectionEditPart; import org.eclipse.gmf.runtime.diagram.ui.editparts.IGraphicalEditPart; import org.eclipse.gmf.runtime.draw2d.ui.figures.PolylineConnectionEx; import org.eclipse.sirius.business.api.session.Session; import org.eclipse.sirius.diagram.DDiagram; import org.eclipse.sirius.diagram.ui.edit.api.part.AbstractDiagramBorderNodeEditPart; */
Fixed Code: ```java @Override protected void tearDown() throws Exception { assertEquals("Test triggered errors.", 0, loggedErrors.get()); Platform.removeLogListener(errorLogListener); super.tearDown(); } public void testUTF8InputEven() throws Exception { processConsoleUTF8Input("", 5000); } public void testUTF8InputOdd() throws Exception { processConsoleUTF8Input("", 5001); } ```
import org.eclipse.debug.tests.AbstractDebugTest; /** * Tests the {@link StreamsProxy}. */ public class StreamsProxyTests extends AbstractDebugTest { public StreamsProxyTests() { super(StreamsProxyTests.class.getSimpleName()); } public StreamsProxyTests(String name) { super(name); } /** * Test console receiving UTF-8 output from process where two-byte UTF-8 * characters start at even offsets. * * @throws Exception if the test gets in trouble */ public void testReceiveUTF8Even() throws Exception { // 4500 characters results in 9000 byte of output which should be more // than most common buffer sizes. receiveUTF8Test("", 4500); } /** * Test console receiving UTF-8 output from process where two-byte UTF-8 * characters start at odd offsets. * * @throws Exception if the test gets in trouble */ public void testReceiveUTF8Odd() throws Exception { // 4500 characters results in 9000 byte of output which should be more // than most common buffer sizes. receiveUTF8Test("", 4500); } }
public void testSet() { List<String> reference = Arrays.asList("Pomme", "Peche", "Poire", "Banane"); List<String> test = createList(reference); assertEquals(reference, test); assertEquals(reference, test); test.set(0, "pomme"); assertNotEquals(reference, test); try { test.set(-1, "pomme"); fail("Should not get here"); } catch (IndexOutOfBoundsException e) { // correct flow } try { test.set(5, "pomme"); fail("Should not get here"); } catch (IndexOutOfBoundsException e) { // correct flow } }
assertEquals("yo", iterator.next()); iterator.previous(); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); iterator.next(); iterator.next(); iterator.next(); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.previous(); assertEquals(1, iterator.previousIndex()); assertEquals(4, iterator.nextIndex()); try { iterator.remove(); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.set("hej"); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.add("hi"); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow }
package org.eclipse.tracecompass.internal.ctf.core.utils; import java.util.Collection; import java.util.Iterator; import java.util.LinkedHashMap; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; /** * Sparse list, a list that supports * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()} , {@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li> * <li>{@link #lastIndexOf(Object)}</li> * </ul> */ public class SparseList<E> implements List<E> { private final Map<Integer, E> elements; public SparseList() { elements = new LinkedHashMap<>(); } @Override public int size() { return elements.size(); } @Override public boolean isEmpty() { return elements.isEmpty(); } @Override public boolean contains(Object o) { return elements.containsValue(o); } @Override public Iterator<E> iterator() { return elements.values().iterator(); } @Override public Object[] toArray() { return elements.values().toArray(); } @Override public <T> T[] toArray(T[] a) { return elements.values().toArray(a); } @Override public boolean add(E e) { int index = elements.size(); elements.put(index, e); return true; } @Override public boolean remove(Object o) { for (Iterator<Entry<Integer, E>> iterator = elements.entrySet().iterator(); iterator.hasNext();) { Entry<Integer, E> entry = iterator.next(); if (Objects.equals(entry.getValue(), o)) { iterator.remove(); return true; } } return false; } @Override public boolean containsAll(Collection<?> c) { return elements.values().containsAll(c); } @Override public boolean addAll(Collection<? extends E> c) { int index = elements.size(); for (E e :
protected int getThreshold() { if (!selectFeedbackEnabled) { if (getViewer().getControl() instanceof Table) return ((Table) getViewer().getControl()).getItemHeight() / 2; if (getViewer().getControl() instanceof Tree) return ((Tree) getViewer().getControl()).getItemHeight() / 2; if (getViewer().getControl() instanceof List) return ((List) getViewer().getControl()).getItemHeight() / 2; } // fixed default threshold return 5; }
public GenericReadOnlyListIterator(List<E> list, int start, int end) { fList = list; fCursor = start; fStart = start; fEnd = end; }
Fixed Code: ```java package org.eclipse.tracecompass.internal.ctf.core.utils; import java.util.Collection; import java.util.HashMap; import java.util.Iterator; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; /** * Sparse list, a list optimized for when most of the data is null. * * Note: this iterates in the sorted order. * * This implementation supports: * - add(Object) * - contains(Object) * - clear() * - iterator() * - isEmpty() * - toArray() * - toArray(Object[]) */ public class SparseList<E> implements List<E> { // Implementation details omitted for brevity } ``` Refactor the Buggy Code using the Review without comments
public class SparseList<E> implements List<E> { private final Map<Integer, E> fInnerEvents = new HashMap<>(); private int fSize = 0; public SparseList(List<E> events) { ensureSize(events.size()); for (int i = 0; i < events.size(); i++) { E element = events.get(i); fInnerEvents.put(i, element); } } // other methods... }
public class SparseList<E> implements List<E> { private final Map<Integer, E> fElements = new HashMap<>(); private int fSize = 0; public SparseList(List<E> elements) { ensureSize(elements.size()); for (int i = 0; i < elements.size(); i++) { E element = elements.get(i); if (element != null) { set(i, element); } } } public SparseList() { // Do nothing } @Override public int size() { return fSize; } @Override public boolean isEmpty() { return fSize == 0; } @Override public boolean contains(Object o) { return fElements.containsValue(o); } @Override public Iterator<E> iterator() { return fElements.values().iterator(); } @Override public Object[] toArray() { return fElements.values().toArray(); } @Override public <T> T[] toArray(T[] a) { return fElements.values().toArray(a); } @Override public boolean add(E e) { set(fSize, e); return true; } @Override public boolean remove(Object o) { for (int i = 0; i < fSize; i++) { if (Objects.equals(fElements.get(i), o)) { remove(i); return true; } } return false; } @Override public boolean containsAll(Collection<?> c) { return fElements.values().containsAll(c); } @Override public boolean addAll(Collection<? extends E> c) { for (E element : c) { add(element); } return true; } @Override public boolean addAll(int index, Collection<? extends E> c) { ensureSize(fSize + c.size()); for (E element : c) { add(index++, element); } return true; } @Override public boolean removeAll(Collection<?> c) { boolean modified = false; for (int i = 0; i < fSize; i++) { if (c.contains(fElements.get(i))) { remove(i); modified = true; } }
public boolean contains(Object o) { return fInnerEvents.containsValue(o); }
public boolean add(E e) { synchronized (this) { fInnerEvents.put(fSize, e); fSize++; } return true; }
public boolean containsAll(Collection<?> c) { return fInnerEvents.values().containsAll(c); }
public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { if (event != null) { set(key, event); key++; } } return true; }
public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { if (event != null) { set(key, event); } key++; } return true; }
@Override public boolean containsAll(Collection<?> c) { return fInnerEvents.values().containsAll(c); } @Override public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { if (event != null) { set(key, event); } key++; } return true; } @Override public E get(int index) { if (index < 0 || index >= fSize) { throw new IndexOutOfBoundsException("Tried to access index " + index + " Sparse list size " + fSize); } return fInnerEvents.get(index); } @Override public E set(int index, E element) { if (index < 0 || index >= fSize) { throw new IndexOutOfBoundsException("Tried to access index " + index + " Sparse list size " + fSize); } return fInnerEvents.put(index, element); }
public ELEMENT next() { if (!hasNext()) { throw new NoSuchElementException(); } fCursor++; ELEMENT element = fList.get(fCursor); return element; }
public int nextIndex() { return fCursor; }
public void testNoexceptOperator_545021() throws Exception { BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("fun_is_not_noexcept", 0); helper.assertVariableValue("unevaluated_fun_is_noexcept", 1); helper.assertVariableValue("fun_noexcept_is_noexcept", 1); }
helper.assertVariableValue("constexpr_ctor_is_noexcept", 1); helper.assertVariableValue("aggregate_init_is_noexcept", 1); helper.assertVariableValue("not_noexcept_conditional", 0); helper.assertVariableValue("is_noexcept_conditional", 1); helper.assertVariableValue("throw_is_not_noexcept", 0); // int fun(); // int fun(int); // template<typename T> // int funt(T); // template<typename T> // int funt_noexcept(T) noexcept; constexpr bool unevaluated_fun_is_noexcept = noexcept(fun); constexpr bool funt_is_not_noexcept = noexcept(funt(1)); constexpr bool funt_noexcept_is_noexcept = noexcept(funt_noexcept(1)); public void testNoexceptOperator2_545021() throws Exception { BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("unevaluated_fun_is_noexcept", 1); helper.assertVariableValue("funt_is_not_noexcept", 0); helper.assertVariableValue("funt_noexcept_is_noexcept", 1); } // struct type1{ // void operator=(int); // bool operator!(); // }; // type1 t1;
Fixed Code: ```cpp // void operator=(int); // bool operator!(); // }; // type1 t1; // struct type2{ // void operator=(int) noexcept; // bool operator!() noexcept; // }; // type2 t2; // constexpr bool binaryop_is_not_noexcept = noexcept(t1 = 1); // constexpr bool unaryop_is_not_noexcept = noexcept(!t1); // constexpr bool noexcept_binaryop_is_noexcept = noexcept(t2 = 1); // constexpr bool noexcept_unaryop_is_noexcept = noexcept(t2 = 1); public void testNoexceptOperator3_545021() throws Exception { BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("binaryop_is_not_noexcept", 0); helper.assertVariableValue("unaryop_is_not_noexcept", 0); helper.assertVariableValue("noexcept_binaryop_is_noexcept", 1); helper.assertVariableValue("noexcept_unaryop_is_noexcept", 1); } // void fun(); // void fun_taking_funptr(void(*ptr)()) noexcept; // // constexpr bool is_noexcept = noexcept(fun_taking_funptr(fun)); ```
private final boolean isRValueReference; private final boolean takesVarargs; private final ICPPEvaluation noexceptSpecifier; public CPPFunctionType(IType returnType, IType[] types) { this(returnType, types, false, false, false, false, false, null); }
public boolean isNoexcept(boolean inCalledContext) { ICPPFunction overload = getOverload(); if (overload != null) { return EvalUtil.evaluateNoexceptSpecifier(overload.getType().getNoexceptSpecifier()); } return fArg1.isNoexcept(inCalledContext) && fArg2.isNoexcept(inCalledContext); }
public boolean isNoexcept(boolean inCalledContext) { return fPositive.isNoexcept(inCalledContext) && fNegative.isNoexcept(inCalledContext); }
public boolean isNoexcept(boolean inCalledContext) { return EvalUtil.evaluateNoexceptSpecifier(fConstructor.getType().getNoexceptSpecifier()); }
public boolean isNoexcept(boolean inCalledContext) { return true; }
public boolean isNoexcept(boolean inCalledContext) { return true; }
public boolean isNoexcept(boolean inCalledContext) { if (inCalledContext) { return EvalUtil.bindingIsNoexcept(getMember()); } else { return true; } }
public boolean isNoexcept(boolean inCalledContext) { // This assert is used to indicate that this method should not be called. assert false; return true; }
public boolean isNoexcept(boolean inCalledContext) { if (fOperator == op_throw) { return false; } ICPPFunction overload = getOverload(); return (overload != null) && EvalUtil.evaluateNoexceptSpecifier(overload.getType().getNoexceptSpecifier()); }
public void testToString() { List<String> reference = Arrays.asList("Pomme", "Peche", "Poire", "Banane"); List<String> test = createList(reference); assertEquals("[0:Pomme, 1:Peche, 2:Poire, 3:Banane]", test.toString()); }
private static void testListIterator(List<String> test) { ListIterator<String> iterator = test.listIterator(0); assertTrue(iterator.hasNext()); assertFalse(iterator.hasPrevious()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); assertEquals("yo", iterator.next()); iterator.previous(); assertTrue(iterator.hasPrevious()); assertEquals("yo", iterator.previous()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); iterator.next(); iterator.next(); iterator.next(); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.previous(); assertEquals(3, iterator.previousIndex()); assertEquals(4, iterator.nextIndex()); try { iterator.remove(); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.set("hej"); fail("Should not get here"); } catch (IllegalStateException e) { // correct flow } }
import java.util.HashMap; import java.util.Iterator; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; import org.eclipse.jdt.annotation.Nullable; /** * Sparse list, a list optimized for when most of the data is <code>null</code>. * Nulls will increment the size of the data structure but not stored as null * means the data is not present. * * Note: this iterates in the sorted order. * * This implementation supports: * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()}</li> * <li>{@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li> * </ul> */ public class SparseList<T> implements List<T> { // implementation details }
import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; import org.eclipse.jdt.annotation.Nullable; /** * Sparse list, a list optimized for when most of the data is <code>null</code>. * Nulls will increment the size of the data structure but not stored as null * means the data is not present. * * This implementation supports: * - {@link #add(Object)} * - {@link #contains(Object)} * - {@link #clear()} * - {@link #iterator()} * - {@link #isEmpty()} * - {@link #toArray()} * - {@link #toArray(Object[])} * - {@link #set(int, Object)} */
public class SparseList<E> implements List<E> { private final Map<Integer, E> fInnerElements = new HashMap<>(); private int fSize = 0; public SparseList(List<E> events) { ensureSize(events.size()); for (int i = 0; i < events.size(); i++) { E element = events.get(i); if (element != null) { set(i, element); } } } public SparseList() { // Do nothing } @Override public int size() { return fSize; } @Override public boolean isEmpty() { return fSize == 0; } @Override public boolean contains(Object o) { return fInnerElements.containsValue(o); } @Override public Iterator<E> iterator() { return fInnerElements.values().iterator(); } @Override public Object[] toArray() { return fInnerElements.values().toArray(); } @Override public <T> T[] toArray(T[] a) { return fInnerElements.values().toArray(a); } @Override public boolean add(E e) { set(fSize, e); return true; } @Override public boolean remove(Object o) { for (Map.Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { fInnerElements.remove(entry.getKey()); return true; } } return false; } @Override public boolean containsAll(Collection<?> c) { return fInnerElements.values().containsAll(c); } @Override public boolean addAll(Collection<? extends E> c) { int index = fSize; for (E element : c) { set(index++, element); } return true; } @Override public boolean addAll(int index, Collection<? extends E> c) { ensureSize(fSize + c.size()); for (E element : c) { set(index++, element); } return true; } @Override public boolean removeAll(Collection<?> c) { boolean modified = false; for (Map.Entry<Integer, E> entry : fInnerElements.entrySet()) { if (c.contains(entry.getValue()))
public boolean isEmpty() { return super.isEmpty(); }
public boolean contains(Object o) { return fInnerElements.containsValue(o); }
int size = fInnerElements.size(); Object[] retVal = new Object[size]; Iterator<E> iterator = iterator(); for (int i = 0; i < size; i++) { Object next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } retVal[i] = next; } return retVal; } /** * {@inheritDoc} * * Warning, will throw exceptions if a[] is the wrong type. */ @Override public <T> T[] toArray(T[] a) { int size = Math.min(a.length, fInnerElements.size()); Iterator<E> iterator = iterator(); for (int i = 0; i < size; i++) { @Nullable E next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } a[i] = (T) next; } return a; } @Override public boolean add(E e) { if (e != null) { // add implementation } return false; }
public int indexOf(Object o) { for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { return entry.getKey(); } } return -1; }
public int lastIndexOf(Object o) { int last = -1; for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { last = Math.max(last, entry.getKey()); } } return last; }
private void fixSize() { perspSwitcherToolbar.pack(); perspSwitcherToolbar.getParent().pack(); perspSwitcherToolbar.requestLayout(); }
public TimeGraphEntry(@NonNull TimeGraphEntryModel model) { setModel(model); }
public boolean equals(Object obj) { if (!super.equals(obj)) { return false; } if (obj instanceof TimeLineEvent) { TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false; }
protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); if (path.getDevice() == null) { // search relative to the workspace if no device present IResource member = root.findMember(path); if (member != null) { return member; } } // look for files or folders with the given path IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (getType() != ARCHIVE) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } @SuppressWarnings("deprecation") IFile[] files = root.findFilesForLocation(path); if (files.length > 0) { return files[0]; } if (getType() != ARCHIVE) { @SuppressWarnings("deprecation") IContainer[] containers = root.findContainersForLocation(path); if (containers.length > 0) { return containers[0]; } } } return null; }
import org.eclipse.jdt.core.IMember; import org.eclipse.jdt.core.search.IJavaSearchConstants; public abstract class MethodWrapper extends PlatformObject { public static IMethodWrapperDynamic fMethodWrapperCore = new MethodWrapperDynamicCore(); public static final void setMethodWrapperDynamic(IMethodWrapperDynamic core) { fMethodWrapperCore = core; } private Map<String, MethodCall> fElements = null; private Map<String, Map<String, MethodCall>> fMethodCache; private final MethodCall fMethodCall; private final MethodWrapper fParent; private int fLevel; }
private static void testListIterator(List<String> test) { ListIterator<String> iterator = test.listIterator(0); assertTrue(iterator.hasNext()); assertFalse(iterator.hasPrevious()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); assertEquals("yo", iterator.next()); assertEquals("yo", iterator.previous()); assertEquals("Hola", iterator.previous()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } assertEquals("Hola", iterator.next()); assertEquals("yo", iterator.next()); assertEquals("quiero", iterator.next()); assertEquals("un", iterator.next()); assertEquals("UNSUPPORTEDOPERATIONEXCEPTION!", iterator.next()); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } assertEquals("UNSUPPORTEDOPERATIONEXCEPTION!", iterator.previous()); assertEquals(3, iterator.previousIndex()); }
public GenericReadOnlyListIterator(List<E> list, int startIndex) { fList = list; fStart = startIndex; fEnd = list.size(); fCursor = startIndex - 1; }
public GenericReadOnlyListIterator(List<E> list, int start, int end) { fList = list; fStart = start; fEnd = end; fCursor = start + 1; }
public boolean hasNext() { return fCursor < fEnd; }
public boolean hasPrevious() { return fCursor > 0; }
public boolean contains(Object o) { return (o == null && size() > fInnerElements.size()) || fInnerElements.containsValue(o); }
public static Matcher<View> thatFirstMatches(final Matcher<View> viewMatcher) { return new TypeSafeMatcher<View>() { private boolean matched; private View matchedView; @Override protected boolean matchesSafely(View view) { if (matched) return matchedView == view; matched = viewMatcher.matches(view); if (matched) { matchedView = view; } return matched; } @Override public void describeTo(Description description) { description.appendText("that first matches "); viewMatcher.describeTo(description); } }; } public static void printOutput(InputStream input) throws IOException { String candidate = IOUtils.toString(input, "UTF-8"); System.out.println(candidate); } protected IStatus run(final IProgressMonitor monitor) { SubMonitor subMonitor = SubMonitor.convert(monitor); if (fTraceWithSize != null) { monitor.beginTask("", traceWithSize.size()); } else { monitor.beginTask("", IProgressMonitor.UNKNOWN); } while (!monitor.isCanceled()) { try { long prevNbEvents = fTrace.getNbEvents(); Thread.sleep(250); long nbEvents = fTrace.getNbEvents(); if (fTraceWithSize != null) { final int done = traceWithSize.progress(); monitor.worked(done - alreadyDone); alreadyDone = done; } setName(Messages.TmfCheckpointIndexer_Indexing + ' ' + fTrace.getName() + " (" + String.format("%,d", nbEvents) + ")"); long rate = (nbEvents - prevNbEvents) * 4; } catch (InterruptedException e) { // Handle interruption } } } @Nullable E next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } if (next != null) { Class<? extends @NonNull Object> elementClass = next.getClass(); if (!Objects.equals(elementClass, componentType) && !elementClass.isInstance(componentType)) { throw new ArrayStoreException("Cannot convert from (" + elementClass + " to " + newArray.getClass().getComponentType()); } } newArray[i] = (T) next;
public int indexOf(Object o) { if (o == null && contains(null)) { for (int i = 0; i < size(); i++) { if (!fInnerElements.containsKey(i)) { return i; } } } for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { return entry.getKey(); } } return -1; }
public Spliterator<E> spliterator() { return fInnerElements.values().spliterator(); }
public ListIterator<E> listIterator(int index) { return new GenericReadOnlyListIterator<>(this, index, size()); }
public void add(int index, E element) { throw new UnsupportedOperationException("No add(index) in " + this.getClass().getName()); }
public E remove(int index) { throw new UnsupportedOperationException("No delete in " + this.getClass().getName()); }
public boolean remove(Object o) { throw new UnsupportedOperationException("No remove in " + this.getClass().getName()); }
public boolean addAll(int index, Collection<? extends E> c) { throw new UnsupportedOperationException("No addAll(index) in " + this.getClass().getName()); //$NON-NLS-1$ }
throw new UnsupportedOperationException("No subList(fromIndex, toIndex) in " + this.getClass().getName()); //$NON-NLS-1$
/***************************************************************************** * Copyright (c) 2019 vogella GmbH and others. * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Simon Scholz <simon.scholz@vogella.com> - initial API and implementation *****************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.di.annotations.Evaluate; import org.eclipse.e4.ui.model.application.ui.MImperativeExpression; public class ImperativeExpressionTestEvaluationPersistedState { public static final String PERSISTED_STATE_TEST = "persisted-state-test"; @Evaluate public boolean isVisible(MImperativeExpression exp) { return exp.getPersistedState().containsKey(PERSISTED_STATE_TEST); } }
final class BitmapCalculator { private final RevWalk walk; private final BitmapIndex bitmapIndex; private final ProgressMonitor pm; private long countOfBitmapIndexMisses; private final BitmapWalkHook preWalkHook; private final BitmapWalkHook postWalkHook; interface BitmapWalkHook { void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) throws IOException; } BitmapCalculator(RevWalk walk, BitmapIndex bitmapIndex, ProgressMonitor pm, BitmapWalkHook preWalkHook, BitmapWalkHook postWalkHook) { this.walk = walk; this.bitmapIndex = bitmapIndex; this.pm = pm; this.preWalkHook = preWalkHook; this.postWalkHook = postWalkHook; } }
private final RevWalk walk; private final BitmapIndex bitmapIndex; private final ProgressMonitor pm; private long countOfBitmapIndexMisses; private final BitmapWalkHook preWalkHook; private final BitmapWalkHook postWalkHook; interface BitmapWalkHook { void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) throws IOException; } private static final BitmapWalkHook NULL_BITMAP_HOOK = new BitmapWalkHook() { @Override public void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) { // implementation goes here } };
import java.util.Collection; import java.util.HashMap; import java.util.HashSet; import java.util.List; import java.util.Map; import java.util.Set; final public class PatchSetPublishDetailFactory implements Action<PatchSetPublishDetail> { final PatchSet.Id patchSetId; protected AccountInfoCache accounts; protected PatchSetInfo patchSetInfo; protected Change change; protected List<PatchLineComment> drafts; protected Map<ApprovalCategory.Id, Set<ApprovalCategoryValue.Id>> allowed; protected Map<ApprovalCategory.Id, ChangeApproval> given; public PatchSetPublishDetailFactory(PatchSet.Id patchSetId) { this.patchSetId = patchSetId; } @Override public PatchSetPublishDetail run(ReviewDb db) throws OrmException, Failure { final AccountInfoCacheFactory acc = new AccountInfoCacheFactory(db); final Account.Id me = Common.getAccountId(); final Change.Id changeId = patchSetId.getParentKey(); change = db.changes().get(changeId); try { patchSetInfo = PatchSetInfoFactory.patchSetInfoForPatchSetId(patchSetId); } catch (PatchSetInfoNotAvailableException e) { throw new Failure(e); } // Rest of the code... } }
public void set(Object[] newContents) { Assert.isNotNull(newContents); data.clear(); data.addAll(Arrays.asList(newContents)); IConcurrentModelListener[] listeners = getListeners(); for (IConcurrentModelListener listener : listeners) { listener.setContents(newContents); } }
// copy only linked resource children (267173) if (source.isLinked() && source.getLocation().equals(existing.getLocation())) { children = filterNonLinkedResources(children); ResourceDescription[] overwritten = copy(children, destinationPath, resourcesAtDestination, iterationProgress, uiInfo, false, createVirtual, createLinks, relativeToVariable); overwrittenResources.addAll(Arrays.asList(overwritten)); } else { // delete the destination folder, copying a linked folder over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(1), uiInfo, false); iterationProgress.setWorkRemaining(100); if ((createLinks || createVirtual) && (source.isLinked() == false) && (source.isVirtual() == false)) { IFolder folder = workspaceRoot.getFolder(destinationPath); if (createVirtual) { folder.create(IResource.VIRTUAL, true, iterationProgress.split(1)); } else { folder.createLink(source.getLocation(), IResource.REPLACE, iterationProgress.split(1)); } } }
if (mapping == null) continue; ResourceTraversal[] traversals = null; try { traversals = mapping.getTraversals(ResourceMappingContext.LOCAL_CONTEXT, new NullProgressMonitor()); } catch (CoreException e) { StatusManager.getManager().handle(e, IDEWorkbenchPlugin.IDE_WORKBENCH); } if (traversals != null) { IResource[] resources = null; for (ResourceTraversal traversal : traversals) { resources = traversal.getResources(); if (resources != null) { result.addAll(Arrays.asList(resources)); } } } else { result.add(resource); } // all that can be converted are done, answer new selection if (result.isEmpty()) { return StructuredSelection.EMPTY; } return new StructuredSelection(result.toArray());
static Set<IResource> getResourcesForFilter(MarkerFieldFilterGroup group, IResource[] selectedResources, IWorkspaceRoot root) { HashSet<IResource> resourceSet = new HashSet<>(); switch (group.getScope()) { case MarkerFieldFilterGroup.ON_ANY: { resourceSet.add(root); break; } case MarkerFieldFilterGroup.ON_SELECTED_ONLY: case MarkerFieldFilterGroup.ON_SELECTED_AND_CHILDREN: { resourceSet.addAll(Arrays.asList(selectedResources)); break; } case MarkerFieldFilterGroup.ON_ANY_IN_SAME_CONTAINER: { for (IResource resource : getProjects(selectedResources)) { resourceSet.add(resource); } break; } case MarkerFieldFilterGroup.ON_WORKING_SET: { group.refresh(); resourceSet.addAll(Arrays.asList(group.getResourcesInWorkingSet())); break; } } return resourceSet; }
public interface ITimeGraphEntry extends ISelection { public enum DisplayStyle { STATE, LINE } ITimeGraphEntry getParent(); boolean hasChildren(); }
public void addEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Need to be a TimeLineEvent"); } super.addEvent(event); }
public void addEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Need to be a TimeLineEvent"); } super.addEvent(event); }
public TimeLineEvent(ITimeGraphEntry entry, long time) { super(entry, time, 0); }
public TimeLineEvent(ITimeGraphEntry entry, long time, long duration, List<Long> values) { super(entry, time, duration); fValues = values; }
public boolean equals(Object obj) { if (!super.equals(obj)) { return false; } if (obj instanceof TimeLineEvent) { TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false; }
public boolean equals(Object obj) { if (!super.equals(obj)) { return false; } if (obj instanceof TimeLineEvent) { TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false; }
public String toString() { StringBuilder builder = new StringBuilder(); builder.append("[TimeLineEvent Values=").append(getValues()) .append(", Entry=").append(getEntry()) .append(", Time=").append(getTime()) .append(']'); return builder.toString(); }
private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); List<List<LongPoint>> toDraw = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); } }
private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); List<List<LongPoint>> toDraw = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); } }
// clamp 0 - max positive long long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); List<List<LongPoint>> toDraw = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } // add event to the appropriate series toDraw.get(0).add(new LongPoint(x, xEnd)); } // remaining code...
} while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x > rect.x + rect.width || xEnd < rect.x) { continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; }
if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { // rest of the code }
} int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i));
if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); if (i >= toDraw.size()) { toDraw.add(new ArrayList<>()); } toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < nbSeries; i++) { RGBA rgba = colors.get(i); // rest of the code }
long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < nbSeries; i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha); }
Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < toDraw.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha); gc.setForeground(color); List<LongPoint> series = toDraw.get(i); int[] points = new int[series.size() * 2]; for (int point = 0; point < series.size(); point++) { LongPoint longPoint = series.get(point); points[point * 2] = longPoint.x; // rest of the code } }
/***************************************************************************** * Copyright (c) 2000, 2021 IBM Corporation and others. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation *****************************************************************************/ package org.eclipse.jface.viewers; import org.eclipse.core.runtime.Assert; import org.eclipse.swt.dnd.DND; import org.eclipse.swt.dnd.DropTargetAdapter; import org.eclipse.swt.dnd.DropTargetEvent; import org.eclipse.swt.dnd.TransferData; import org.eclipse.swt.graphics.Point; import org.eclipse.swt.graphics.Rectangle; import org.eclipse.swt.widgets.Item; import org.eclipse.swt.widgets.List; import org.eclipse.swt.widgets.Table; import org.eclipse.swt.widgets.TableItem; import org.eclipse.swt.widgets.Tree; import org.eclipse.swt.widgets.TreeItem; /** * This adapter class provides generic drag-and-drop support for a viewer. * <p> */ class ViewerDropAdapter extends DropTargetAdapter { // Implementation here }
for (int i = 0; i < resources.length; i++) { // Copy the resources and record the overwrites that would // be restored if this operation were reversed ResourceDescription[] overwrites; overwrites = WorkspaceUndoUtil.copy(new IResource[] { resources[i] }, getDestinationPath(resources[i], i), resourcesAtDestination, subMonitor.split(1), uiInfo, true, fCreateGroups, fCreateLinks, fRelativeToVariable); // Accumulate the overwrites into the full list overwrittenResources.addAll(Arrays.asList(overwrites)); } // Are there any previously overwritten resources to restore now? if (resourceDescriptions != null) { for (ResourceDescription resourceDescription : resourceDescriptions) { if (resourceDescription != null) { resourceDescription.createResource(subMonitor.split(1)); } } } // Reset resource descriptions to the just overwritten resources setResourceDescriptions(overwrittenResources.toArray(new ResourceDescription[overwrittenResources.size()])); // Reset the target resources to refer to the resources in their new location. setTargetResources(resourcesAtDestination);
for (int i = 0; i < resources.length; i++) { // Move the resources and record the overwrites that would // be restored if this operation were reversed ResourceDescription[] overwrites; overwrites = WorkspaceUndoUtil.move(new IResource[] { resources[i] }, getDestinationPath(resources[i], i), resourcesAtDestination, undoDestinationPaths, subMonitor.split(1), uiInfo, true); // Accumulate the overwrites into the full list overwrittenResources.addAll(Arrays.asList(overwrites)); } // Are there any previously overwritten resources to restore now? if (resourceDescriptions != null) { for (ResourceDescription resourceDescription : resourceDescriptions) { if (resourceDescription != null) { resourceDescription.createResource(subMonitor.split(1)); } } } // Reset resource descriptions to the just overwritten resources setResourceDescriptions(overwrittenResources.toArray(new ResourceDescription[overwrittenResources.size()])); // Reset the target resources to refer to the resources in their new // location. setTargetResources(resourcesAtDestination.toArray(new IResource[resourcesAtDestination.size()]));
// copy only linked resource children (267173) if (source.isLinked() && source.getLocation().equals(existing.getLocation())) { children = filterNonLinkedResources(children); } ResourceDescription[] overwritten = copy(children, destinationPath, resourcesAtDestination, iterationProgress, uiInfo, false, createVirtual, createLinks, relativeToVariable); overwrittenResources.addAll(Arrays.asList(overwritten)); } else { // delete the destination folder, copying a linked folder over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(1), uiInfo, false); iterationProgress.setWorkRemaining(100); if ((createLinks || createVirtual) && (source.isLinked() == false) && (source.isVirtual() == false)) { IFolder folder = workspaceRoot.getFolder(destinationPath); if (createVirtual) { folder.create(IResource.VIRTUAL, true, iterationProgress.split(1)); } else { folder.createLink(source.getLocation(), IResource.NONE, iterationProgress.split(1)); } } }
IResource[] children = ((IContainer) resource).members(); // move only linked resource children (267173) if (resource.isLinked() && resource.getLocation().equals(existing.getLocation())) { children = filterNonLinkedResources(children); } ResourceDescription[] overwritten = move(children, destinationPath, resourcesAtDestination, reverseDestinations, iterationProgress.split(90), uiInfo, false); overwrittenResources.addAll(Arrays.asList(overwritten)); // Delete the source. No need to record it since it will get moved back. delete(resource, iterationProgress.split(10), uiInfo, false, false); } else { // delete the destination folder, moving a linked folder over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(10), uiInfo, false); // Record the original path reverseDestinations.add(resource.getFullPath()); }
if (mapping == null) continue; ResourceTraversal[] traversals = null; try { traversals = mapping.getTraversals(ResourceMappingContext.LOCAL_CONTEXT, new NullProgressMonitor()); } catch (CoreException e) { StatusManager.getManager().handle(e, IDEWorkbenchPlugin.IDE_WORKBENCH); } if (traversals != null) { IResource[] resources = null; for (ResourceTraversal traversal : traversals) { resources = traversal.getResources(); if (resources != null) { result.addAll(Arrays.asList(resources)); } } } else { result.add(resource); } // all that can be converted are done, answer new selection if (result.isEmpty()) { return StructuredSelection.EMPTY; } return new StructuredSelection(result.toArray());
Map<MarkerQueryResult, Collection<IConfigurationElement>> resultsTable = entry.getValue(); if (resultsTable.containsKey(result)) { Iterator<IConfigurationElement> elements = resultsTable.get(result).iterator(); while (elements.hasNext()) { IConfigurationElement element = elements.next(); IMarkerResolutionGenerator generator = null; try { generator = (IMarkerResolutionGenerator) element.createExecutableExtension(ATT_CLASS); IMarkerResolution[] res = generator.getResolutions(marker); if (res != null) { resolutions.addAll(Arrays.asList(res)); } else { StatusManager.getManager().handle(new Status(IStatus.ERROR, IDEWorkbenchPlugin.IDE_WORKBENCH, IStatus.ERROR, "Failure in " + generator.getClass().getName() + " from plugin " + element.getContributor().getName() + ": getResolutions(IMarker) must not return null", null), StatusManager.LOG); } } catch (CoreException e) { Policy.handle(e); } } } }
IPath location = resources[i].getLocation(); if (location != null) { fileNames[actualLength++] = location.toOSString(); } if (actualLength > 0) { if (actualLength < length) { String[] tempFileNames = fileNames; fileNames = new String[actualLength]; System.arraycopy(tempFileNames, 0, fileNames, 0, actualLength); } anEvent.data = fileNames; return true; } return false;
private INavigatorContentDescriptor contributor; private INavigatorContentDescriptor firstClassContributor; private NavigatorContentService contentService; public ContributorTrackingSet(NavigatorContentService aContentService) { contentService = aContentService; } public ContributorTrackingSet(NavigatorContentService aContentService, Object[] elements) { super.addAll(Arrays.asList(elements)); contentService = aContentService; } @Override public boolean add(Object o) { if (contributor != null) { contentService.rememberContribution(contributor, firstClassContributor, o); } return super.add(o); } @Override public boolean remove(Object o) { contentService.forgetContribution(o); return super.remove(o); } @Override public void clear() { Iterator it = iterator(); while (it.hasNext()) contentService.forgetContribution(it.next()); super.clear(); }
updateFilterActivation = true; } // We don't turn of non-UI visible filters here, they have to be manipulated explicitly if (!visibleFilterDescriptors[i].isVisibleInUi()) { if (nonUiVisible == null) nonUiVisible = new ArrayList<String>(); nonUiVisible.add(visibleFilterDescriptors[i].getId()); } /* If so, update */ if (updateFilterActivation) { if (nonUiVisible != null) { nonUiVisible.addAll(Arrays.asList(filterIdsToActivate)); filterIdsToActivate = nonUiVisible.toArray(new String[]{}); } setActiveFilterIds(filterIdsToActivate); persistFilterActivationState(); updateViewer(); // the action providers may no longer be enabled, so we // reset the selection. StructuredViewer commonViewer = (StructuredViewer) contentService.getViewer(); commonViewer.setSelection(StructuredSelection.EMPTY); }
new WizardPatternFilter(), true); viewer = filteredTree.getViewer(); filteredTree.setFont(parent.getFont()); filteredTree.setQuickSelectionMode(true); viewer.setContentProvider(new WizardContentProvider()); viewer.setLabelProvider(new WorkbenchLabelProvider()); viewer.setComparator(DataTransferWizardCollectionComparator.INSTANCE); ArrayList inputArray = new ArrayList(); boolean expandTop = false; if (wizardCategories != null) { if (wizardCategories.getParent() == null) { inputArray.addAll(Arrays.asList(wizardCategories.getCategories())); } else { expandTop = true; inputArray.add(wizardCategories); } } // ensure the category is expanded. If there is a remembered expansion it will // be set later. if (expandTop) { viewer.setAutoExpandLevel(2); } AdaptableList input = new AdaptableList(inputArray); // filter wizard list according to capabilities that are enabled viewer.addFilter(new WizardActivityFilter()); viewer.setInput(input);
filterTree.setQuickSelectionMode(true); final TreeViewer treeViewer = filterTree.getViewer(); treeViewer.setContentProvider(new WizardContentProvider()); treeViewer.setLabelProvider(new WorkbenchLabelProvider()); treeViewer.setComparator(NewWizardCollectionComparator.INSTANCE); treeViewer.addSelectionChangedListener(this); ArrayList inputArray = new ArrayList(); inputArray.addAll(Arrays.asList(primaryWizards)); boolean expandTop = false; if (wizardCategories != null) { if (wizardCategories.getParent() == null) { inputArray.addAll(Arrays.asList(wizardCategories.getCategories())); } else { expandTop = true; inputArray.add(wizardCategories); } } if (expandTop) { treeViewer.setAutoExpandLevel(2); } AdaptableList input = new AdaptableList(inputArray); treeViewer.setInput(input); filterTree.setBackground(parent.getDisplay().getSystemColor(SWT.COLOR_WIDGET_BACKGROUND)); treeViewer.getTree().setFont(parent.getFont()); treeViewer.addDoubleClickListener(event -> { // Double click action });
queuedEvents.add(prefId); return; if (listeners != null) { listeners.firePropertyChange(prefId); } @Override public final void addListener(String[] eventsOfInterest, IPropertyMapListener listener) { if (listeners == null) { listeners = new PropertyListenerList(); attachListener(); } listeners.add(eventsOfInterest, listener); } protected final void firePropertyChange(String[] prefIds) { if (ignoreCount > 0) { queuedEvents.addAll(Arrays.asList(prefIds)); return; } if (listeners != null) { listeners.firePropertyChange(prefIds); } } public final void startTransaction() { ignoreCount++; } public final void endTransaction() { ignoreCount--; if (ignoreCount == 0 && !queuedEvents.isEmpty()) { if (listeners != null) { listeners.firePropertyChange((String[]) queuedEvents.toArray(new String[queuedEvents.size()])); } queuedEvents.clear(); } } @Override public boolean equals(Object toCompare) {
package org.eclipse.e4.ui.tests.workbench; import java.util.ArrayList; import java.util.Arrays; /** * Class used to capture the SWT structure expected when rendering a particular UI model. */ public class SWTResult { public Class clazz; public String text; public ArrayList<SWTResult> kids = new ArrayList<>(); public SWTResult(Class theClass, String theText, SWTResult[] children) { clazz = theClass; text = theText; if (children != null) { kids.addAll(Arrays.asList(children)); } } }
public void setSize(int size) { currentElements = new TestElement[size]; System.arraycopy(allElements, 0, currentElements, 0, currentElements.length); }
public void addMember(String person) { TeamMember newMember = new TeamMember(person, this); TeamMember[] newMembers = new TeamMember[members.length + 1]; System.arraycopy(members, 0, newMembers, 0, members.length); newMembers[newMembers.length - 1] = newMember; members = null; members = newMembers; newMembers = null; fireModelChanged(new ComparatorModelChange(TestModelChange.INSERT, this, newMember)); }
protected LeasedSmtpConnection withConnectionPool(SmtpConnectionPool connectionPool) { m_smtpConnectionPool = connectionPool; return this; }
protected Transport getTransport() { return m_transport; } public ConnectionPool getConnectionPool() { return m_connectionPool; } public boolean isClosed() { return m_closed; }
@ApplicationScoped public class SmtpConnectionPool { private static final Logger LOG = LoggerFactory.getLogger(SmtpConnectionPool.class); protected static final String JOB_NAME_CLOSE_IDLE_CONNECTIONS = "smtp-close-idle-connections"; protected final Object m_poolLock = new Object(); protected final Set<SmtpConnectionPoolEntry> m_idleEntries = new HashSet<>(); protected final Set<SmtpConnectionPoolEntry> m_leasedEntries = new HashSet<>(); protected final String m_jobExecutionHint = "smtp-connection-pool." + UUID.randomUUID().toString(); protected long m_lastPoolEntryNo = 0; protected long m_maxIdleTime; protected long m_maxConnectionLifetime; protected boolean m_destroyed; // Rest of the code... }
protected void destroy() { if (m_destroyed) { return; } synchronized (m_poolLock) { if (m_destroyed) { return; } Jobs.getJobManager().cancel(Jobs.newFutureFilterBuilder() .andMatchExecutionHint(m_jobExecutionHint) .toFilter(), true); Stream.of(m_idleEntries, m_leasedEntries) .flatMap(Collection::stream) .forEach(this::safeCloseTransport); m_idleEntries.clear(); m_leasedEntries.clear(); m_destroyed = true; } }
package org.eclipse.scout.rt.mail.smtp; import javax.mail.Session; import javax.mail.Transport; import org.eclipse.scout.rt.platform.Bean; @Bean public class SmtpConnectionPoolEntry { private String m_name; private SmtpServerConfig m_smtpServerConfig; private Session m_session; private Transport m_transport; private long m_createTime; private long m_idleSince; public SmtpConnectionPoolEntry withName(String name) { m_name = name; return this; } public SmtpConnectionPoolEntry withSmtpServerConfig(SmtpServerConfig smtpServerConfig) { m_smtpServerConfig = smtpServerConfig; return this; } public SmtpConnectionPoolEntry withSession(Session session) { m_session = session; return this; } public SmtpConnectionPoolEntry withTransport(Transport transport) { m_transport = transport; return this; } public SmtpConnectionPoolEntry withCreateTime(long createTime) { m_createTime = createTime; return this; } public SmtpConnectionPoolEntry withIdleSince(long idleSince) { m_idleSince = idleSince; return this; } public Session getSession() { return m_session; } public Transport getTransport() { return m_transport; } public long getCreateTime() { return m_createTime; } public long getIdleSince() { return m_idleSince; } }
public Map<String, String> getAdditionalSessionProperties() { return m_additionalSessionProperties; } /** * These properties are added after the other properties, thus can override predefined properties such as host, port * or user. * * @param additionalSessionProperties * Additional properties used to create {@link Session} for SMTP server connection. */ public SmtpServerConfig withAdditionalSessionProperties(Map<String, String> additionalSessionProperties) { m_additionalSessionProperties = additionalSessionProperties; return this; } public int getPoolSize() { return m_poolSize; } /** * @param poolSize * Specifies the size of the connection pool to use with this {@link SmtpServerConfig#}. If 0, smtp * connection pooling is disabled. */ public SmtpServerConfig withPoolSize(int poolSize) { m_poolSize = poolSize; return this; } @Override public int hashCode() { final int prime = 31; int result = 1; // ... rest of the code }
ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = -1; while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width) { continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); // rest of the code } }
// event is out of bounds continue; TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); seriesModel.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (TimeLineEvent ref : refs) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(ref); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
} TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), 0); seriesModel.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (TimeLineEvent ref : refs) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(ref); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
/***************************************************************************** * Copyright (c) 2019 IBM Corporation and others. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation *****************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.contexts.IEclipseContext; import org.eclipse.e4.ui.internal.workbench.E4Workbench; import org.eclipse.e4.ui.internal.workbench.swt.E4Application; import org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine; import org.eclipse.e4.ui.model.application.MApplication; import org.eclipse.e4.ui.model.application.ui.advanced.MArea; import org.eclipse.e4.ui.model.application.ui.basic.MCompositePart; import org.eclipse.e4.ui.model.application.ui.basic.MPart; import org.eclipse.e4.ui.model.application.ui.basic.MPartStack; import org.eclipse.e4.ui.model.application.ui.basic.MWindow;
/***************************************************************************** * Copyright (c) 2019 IBM Corporation and others. * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation ******************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.contexts.IEclipseContext; import org.eclipse.e4.ui.internal.workbench.E4Workbench; import org.eclipse.e4.ui.internal.workbench.swt.E4Application; import org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine; import org.eclipse.e4.ui.model.application.MApplication; import org.eclipse.e4.ui.model.application.ui.advanced.MArea; import org.eclipse.e4.ui.model.application.ui.basic.MCompositePart; import org.eclipse.e4.ui.model.application.ui.basic.MPart; import org.eclipse.e4.ui.model.application.ui.basic.MPartStack; import org.eclipse.e4.ui.model.application.ui.basic.MWindow;
public void testMultipleStacksUnderTheAreaCreateACTabFolder() { MWindow window = ems.createModelElement(MWindow.class); MArea area = ems.createModelElement(MArea.class); MPartStack stack1 = ems.createModelElement(MPartStack.class); stack1.getChildren().add(ems.createModelElement(MPart.class)); stack1.getChildren().add(ems.createModelElement(MPart.class)); MPartStack stack2 = ems.createModelElement(MPartStack.class); stack2.getChildren().add(ems.createModelElement(MPart.class)); stack2.getChildren().add(ems.createModelElement(MPart.class)); area.getChildren().add(stack1); area.getChildren().add(stack2); window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext); wb.createAndRunUI(window); // Make sure the widget is now a CTabFolder }
public void testStackInsideMCompositePartDoesNotCreateACTabFolder() { MWindow window = ems.createModelElement(MWindow.class); MArea area = ems.createModelElement(MArea.class); MCompositePart composite = ems.createModelElement(MCompositePart.class); MPartStack stack1 = ems.createModelElement(MPartStack.class); stack1.getChildren().add(ems.createModelElement(MPart.class)); stack1.getChildren().add(ems.createModelElement(MPart.class)); MPartStack stack2 = ems.createModelElement(MPartStack.class); stack2.getChildren().add(ems.createModelElement(MPart.class)); stack2.getChildren().add(ems.createModelElement(MPart.class)); composite.getChildren().add(stack1); composite.getChildren().add(stack2); area.getChildren().add(composite); window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext); }
composite.getChildren().add(stack1); composite.getChildren().add(stack2); // Place the container in the area area.getChildren().add(composite); // Add area to the window window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext); wb.createAndRunUI(window); // Make sure the widget is now a CTabFolder Assert.assertFalse(area.getWidget() instanceof CTabFolder);
public void testNoSEBools() { try { assertEquals(0, getBooleanNames().length); } catch (NullPointerException e) { // expected } } public void emptyLine() { String html = parseToHtml(" "); assertEquals("", html); } public void test_SystemProperties() { Properties originalProperties = System.getProperties(); try { Properties testProperties = new Properties(); testProperties.put("testIncInt", "notInt"); System.setProperties(testProperties); assertNull("returned incorrect default Integer", Integer.getInteger("testIncInt")); assertEquals(new Integer(4), Integer.getInteger("testIncInt", 4)); assertEquals(new Integer(4), Integer.getInteger("testIncInt", new Integer(4))); } finally { System.setProperties(originalProperties); } } public void testDynamicItem_AddOne() { contextRule.createAndRunWorkbench(window); ToolBarManager tbm = getManager(toolBar); assertEquals(0, tbm.getSize()); MToolItem toolItem1 = ems.createModelElement(MDirectToolItem.class); toolBar.getChildren().add(toolItem1); assertEquals(1, tbm.getSize()); }
protected int getThreshold() { return 5; }
public void refresh() { fCategoryViewer.setInput(fModel); super.refresh(); }
import org.eclipse.cdt.core.dom.ast.cpp.ICPPConstructor; import org.eclipse.cdt.core.dom.ast.cpp.ICPPMethod; import org.eclipse.cdt.core.dom.ast.cpp.SemanticQueries; import org.eclipse.cdt.internal.core.dom.parser.ASTQueries; import org.eclipse.cdt.internal.core.dom.parser.cpp.ClassTypeHelper; import org.eclipse.cdt.internal.core.dom.parser.cpp.ICPPDeferredClassInstance; @SuppressWarnings("restriction") public class VirtualMethodCallChecker extends AbstractIndexAstChecker { public static final String VIRTUAL_CALL_ID = "org.eclipse.cdt.codan.internal.checkers.VirtualMethodCallProblem"; //$NON-NLS-1$ public static final String THROW_ID = "org.eclipse.cdt.codan.internal.checkers.ThrowInDestructorProblem"; //$NON-NLS-1$ @Override public void processAst(IASTTranslationUnit ast) { ast.accept(new OnEachClass()); } private enum DECL_TYPE { CTOR, DTOR } class OnEachClass extends ASTVisitor { private final Stack<DECL_TYPE> ctorDtorStack = new Stack<>(); OnEachClass() { shouldVisitDeclarations = true; shouldVisitDeclarators = true; shouldVisitImplicitNames = true; shouldVisitInitializers = true; shouldVisitNames = true; shouldVisitParameterDeclarations = true; shouldVisitStatements = true; shouldVisitTypeIds = true; } @Override public int visit(IASTDeclaration declaration) { if (declaration instanceof IASTFunctionDefinition) { IASTFunctionDefinition functionDefinition = (IASTFunctionDefinition) declaration; IASTFunctionDeclarator functionDeclarator = functionDefinition.getDeclarator(); IASTName functionName = functionDeclarator.getName(); ICPPMethod method = ASTQueries.findAncestorWithType(functionName, ICPPMethod.class); if (method != null) { if (method.isVirtual()) { reportProblem(VIRTUAL_CALL_ID, functionName); } if (isDestructor(method)) { ctorDtorStack.push(DECL_TYPE.DTOR); } } } return PROCESS_CONTINUE; } @Override public int leave(IASTDeclaration declaration) { if (declaration instanceof IASTFunctionDefinition) { IASTFunctionDefinition functionDefinition = (IASTFunctionDefinition) declaration; IASTFunctionDeclarator functionDe
private static SyscallLookup create() { try { IPath path = Activator.getDefault().getAbsolutePath(new Path(SYSCALL_TSV_PATH)); if (path != null) { File file = path.toFile(); if (!file.exists()) { Activator.getDefault().logError("Syscall names not available!"); //$NON-NLS-1$ return null; } return new SyscallLookup(FileUtils.readLines(file, "UTF-8")); //$NON-NLS-1$ } } catch (IOException e) { Activator.getDefault().logError("Failed to read file", e); //$NON-NLS-1$ } return new SyscallLookup(Collections.emptyList()); }
doStagefrightTest(R.raw.cve_2015_3873_b_20718524); public void testStagefright_cve_2015_3862_b_22954006() throws Exception { doStagefrightTest(R.raw.cve_2015_3862_b_22954006); } public void testStagefright_cve_2015_3867_b_23213430() throws Exception { doStagefrightTest(R.raw.cve_2015_3867_b_23213430); } public void testStagefright_cve_2015_3873_b_21814993() throws Exception { doStagefrightTest(R.raw.cve_2015_3873_b_21814993); } public void testStagefright_bug_25812590() throws Exception { doStagefrightTest(R.raw.bug_25812590); } public void testStagefright_bug_26070014() throws Exception { doStagefrightTest(R.raw.bug_26070014); } public void testStagefright_cve_2015_6608_b_23680780() throws Exception { doStagefrightTest(R.raw.cve_2015_6608_b_23680780); } private void doStagefrightTest(final int rid) throws Exception { class MediaPlayerCrashListener implements MediaPlayer.OnErrorListener, MediaPlayer.OnPreparedListener, MediaPlayer.OnCompletionListener { @Override
public boolean visit(LambdaExpression lambdaExpression) { IMethodBinding binding = lambdaExpression.resolveMethodBinding(); IVariableBinding[] synVars = binding.getSyntheticOuterLocals(); List<Field> allFields = underlyingThisObject.referenceType().fields(); ListIterator<Field> listIterator = allFields.listIterator(); int i = 0; if (getUnderlyingMethod().isStatic()) { if (synVars.length == allFields.size()) { while (listIterator.hasNext()) { FieldImpl field = (FieldImpl) listIterator.next(); String newName = synVars[i].getName(); FieldImpl newField = new FieldImpl((VirtualMachineImpl) field.virtualMachine(), (ReferenceTypeImpl) field.declaringType(), field.getFieldID(), newName, field.signature(), field.genericSignature(), field.modifiers()); listIterator.set(newField); } } } else { if (synVars.length + 1 == allFields.size()) { while (listIterator.hasNext()) { FieldImpl field = (FieldImpl) listIterator.next(); String newName = field.name(); // rest of the code } } } }
int auto = repo.getConfig().getInt(ConfigConstants.CONFIG_GC_SECTION, ConfigConstants.CONFIG_KEY_AUTO, DEFAULT_AUTOLIMIT); if (auto <= 0) { return false; } int n = 0; int threshold = (auto + 255) / 256; Path dir = repo.getObjectsDirectory().toPath().resolve("17"); //$NON-NLS-1$ if (!Files.exists(dir)) { return false; } try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir, new DirectoryStream.Filter<Path>() { public boolean accept(Path file) throws IOException { return Files.isRegularFile(file) && PATTERN_LOOSE_OBJECT .matcher(file.getFileName().toString()) .matches(); } })) { Iterator<Path> iter = stream.iterator(); while (iter.hasNext()) { if (n++ > threshold) { return true; } } } catch (IOException e) { LOG.error(e.getMessage(), e); } return false;
public void setAllChecked(boolean state) { for (TreeItem item : super.getTree().getItems()) { item.setChecked(state); } if (state) { Object[] visible = getFilteredChildren(getRoot()); ITreeContentProvider contentProvider = null; if (getContentProvider() instanceof ITreeContentProvider) { contentProvider = (ITreeContentProvider) getContentProvider(); } if (contentProvider == null) { checkState.addAll(Arrays.asList(visible)); } else { Set<Object> toCheck = new HashSet<>(); for (Object element : visible) { addFilteredChildren(element, contentProvider, toCheck); } checkState.addAll(toCheck); } } else { if (checkState != null) { Object[] visible = filter(checkState.toArray()); for (Object element : visible) { checkState.remove(element); } } } }
protected IToken scanToken() { return null; } private @NonNull Set<IHyperlinkDetector> getHyperlinkDetectors() { Set<IHyperlinkDetector> allDetectors = new LinkedHashSet<>(); IHyperlinkDetector[] configuredDetectors = configuration.getHyperlinkDetectors(viewer); if (configuredDetectors != null && configuredDetectors.length > 0) { allDetectors.addAll(Arrays.asList(configuredDetectors)); if (preferenceStore.getBoolean(URL_HYPERLINK_DETECTOR_KEY) || !preferenceStore.getBoolean(AbstractTextEditor.PREFERENCE_HYPERLINKS_ENABLED)) { return allDetectors; } allDetectors.add(new MultiURLHyperlinkDetector()); } return allDetectors; }
public static boolean evaluateNoexceptSpecifier(ICPPEvaluation noexceptSpecifier) { if (noexceptSpecifier instanceof IntegralValue) { IntegralValue v = (IntegralValue) noexceptSpecifier; if (v.numberValue() != null) { return v.numberValue().longValue() == 1; } } return false; }
candidate = entry; it.remove(); break; } if (candidate != null && !candidate.getTransport().isConnected()) { LOG.debug("Releasing pooled SMTP connection {}; transport is already closed, not returning to idle pool.", candidate); candidate = null; } if (candidate != null) { IDateProvider dateProvider = BEANS.get(IDateProvider.class); if (dateProvider.currentMillis().getTime() - candidate.getCreateTime() < m_maxConnectionLifetime) { LOG.debug("Releasing pooled SMTP connection {}; returning to idle pool.", candidate); candidate.withIdleSince(dateProvider.currentMillis().getTime()); m_idleEntries.add(candidate); } else { LOG.debug("Releasing pooled SMTP connection {}; pooled connection reached max lifetime of {}s, not returning to idle pool.", candidate, m_maxConnectionLifetime / 1000d); } } m_poolLock.notifyAll();
} public SmtpServerConfig withAdditionalSessionProperties(Map<String, String> additionalSessionProperties) { m_additionalSessionProperties = additionalSessionProperties; return this; } public int getPoolSize() { return m_poolSize; } public SmtpServerConfig withPoolSize(int poolSize) { m_poolSize = poolSize; return this; } @Override public int hashCode() { final int prime = 31; int result = 1;
int cpusNode = cpuSs.getQuarkAbsolute(Attributes.CPUS); final @NonNull List<@NonNull Integer> subAttributes = cpuSs.getSubAttributes(cpusNode, false); int cpus = Integer.MIN_VALUE; for (Integer quark : subAttributes) { cpus = Math.max(Integer.parseInt(cpuSs.getAttributeName(quark)), cpus); } return Math.max(subAttributes.size(), cpus); } catch (AttributeNotFoundException e) { Activator.getDefault().logError("Error: getting number of core" + e.getMessage(), e); //$NON-NLS-1$ } return -1;
if (cpuSs != null) { try { int cpusNode = cpuSs.getQuarkAbsolute(Attributes.CPUS); final @NonNull List<@NonNull Integer> subAttributes = cpuSs.getSubAttributes(cpusNode, false); int cpus = Integer.MIN_VALUE; for (Integer quark : subAttributes) { cpus = Math.max(Integer.parseInt(cpuSs.getAttributeName(quark)), cpus); } return Math.max(subAttributes.size(), cpus); } catch (AttributeNotFoundException e) { Activator.getDefault().logError(e.getMessage(), e); } } return -1;
public boolean isWorkspaceCompatible(URL url) { if (url == null) { return false; } if (WORKSPACE_CHECK_REFERENCE_BUNDLE_VERSION == null) { // no reference bundle installed, no check possible return true; } Version version = readWorkspaceVersion(url); // if the version could not be read, then there is not any existing // workspace data to trample, e.g., perhaps its a new directory that // is just starting to be used as a workspace if (version == null) { return true; } final Version ide_version = toMajorMinorVersion(WORKSPACE_CHECK_REFERENCE_BUNDLE_VERSION); Version workspace_version = toMajorMinorVersion(version); int versionCompareResult = workspace_version.compareTo(ide_version); // equality test is required since any version difference (newer // or older) may result in data being trampled if (versionCompareResult == 0) { return true; } // At this point workspace has been detected to be from a version // other than the current ide version -- find out if the user wants // to use it anyhow. return false; }
public @Nullable ImageDescriptor getImageDescripterFromPath(String path) { return AbstractUIPlugin.imageDescriptorFromPlugin(PLUGIN_ID, path); }
} else if (columnIndex == 1) { try { return attribute.getDisplayableString(); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else if (columnIndex == 2) { try { return attribute.getId().toString(); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else if (columnIndex == 3) { try { return attribute.getAttributeType().getIdString(); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else { return attribute.getGammaId().toString(); }
public void applyUrl(boolean include) throws CoreException { String value = include ? recomputeUrl() : null; if (getCurrentItem() != null) { getCurrentItem().setURL(value); } } private String recomputeUrl() { ISiteFeature feature = getCurrentItem(); if (feature == null) { return null; } StringBuilder sb = new StringBuilder(); sb.append("features/").append(feature.getId()).append("_"); //$NON-NLS-1$ //$NON-NLS-2$ try { sb.append(new Version(feature.getVersion())); } catch (Exception e) { sb.append("0.0.0"); //$NON-NLS-1$ } sb.append(".jar"); //$NON-NLS-1$ return sb.toString(); }
public static SyscallLookup getInstance() { SyscallLookup instance = INSTANCE; if (instance == null) { instance = create(); INSTANCE = instance; } return instance; }
private static SyscallLookup create() { try { IPath path = Activator.getDefault().getAbsolutePath(new Path(SYSCALL_TSV_PATH)); if (path != null) { File file = path.toFile(); if (!file.exists()) { Activator.getDefault().logWarning("Syscall names not available!"); //$NON-NLS-1$ return new SyscallLookup(Collections.emptyList()); } return new SyscallLookup(FileUtils.readLines(file, "UTF-8")); //$NON-NLS-1$ } } catch (IOException e) { Activator.getDefault().logError("Failed to read file", e); //$NON-NLS-1$ } return new SyscallLookup(Collections.emptyList()); }
import com.android.sched.util.log.stats.CounterImpl; import com.android.sched.util.log.stats.StatisticId; import com.android.sched.vfs.InputVFile; import com.android.sched.vfs.UnionVFSReadOnlyException; import com.android.sched.vfs.VPath; import java.io.File; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.Collections; import java.util.HashSet; import java.util.Iterator; import java.util.List; import java.util.Map; import java.util.Set; import javax.annotation.CheckForNull; import javax.annotation.Nonnull; @ImplementationName(iface = InputFilter.class, name = "incremental") @HasKeyId public class IncrementalInputFilter extends CommonFilter implements InputFilter { @Nonnull public static final BooleanPropertyId INCREMENTAL_LOG = BooleanPropertyId .create("jack.incremental.log", "Enable incremental log") .addDefaultValue(Boolean.FALSE); @Nonnull public static final StatisticId<Counter> COMPILED_FILES = new StatisticId<Counter>( "jack.compiled-files", "Number of compiled files", CounterImpl.class, CounterImpl.Factory.class); } public native void put(OcRepresentation ocRepresentation, QueryParamsMap queryParamsMap, OnPutListener onPutListener) throws OcException;
if (type == null) { return value; } IJavaStackFrame stackFrame = getStackFrame(javaValue); if (stackFrame == null) { return value; } IJavaProject project = JavaDebugUtils.resolveJavaProject(stackFrame); if (project == null) { return value; } IAstEvaluationEngine evaluationEngine = JDIDebugPlugin.getDefault().getEvaluationEngine(project, (IJavaDebugTarget) stackFrame.getDebugTarget()); EvaluationBlock evaluationBlock = new EvaluationBlock(javaValue, type, (IJavaThread) stackFrame.getThread(), evaluationEngine); if (fValue == null) { // evaluate each variable IJavaVariable[] variables = new IJavaVariable[fVariables.length]; for (int i = 0; i < fVariables.length; i++) { variables[i] = new JDIPlaceholderVariable(fVariables[i][0], evaluationBlock.evaluate(fVariables[i][1]), javaValue); } return new LogicalObjectStructureValue(javaValue, variables); } // evaluate the logical value IJavaValue logicalValue = evaluationBlock.evaluate(fValue); if (logicalValue instanceof JDIValue) { // ... handle JDIValue }
.getEvaluationEngine(project, (IJavaDebugTarget) stackFrame.getDebugTarget()); EvaluationBlock evaluationBlock = new EvaluationBlock(javaValue, type, (IJavaThread) stackFrame.getThread(), evaluationEngine); if (fValue == null) { // evaluate each variable IJavaVariable[] variables = new IJavaVariable[fVariables.length]; for (int i = 0; i < fVariables.length; i++) { variables[i] = new JDIPlaceholderVariable(fVariables[i][0], evaluationBlock.evaluate(fVariables[i][1]), javaValue); } return new LogicalObjectStructureValue(javaValue, variables); } // evaluate the logical value IJavaValue logicalValue = evaluationBlock.evaluate(fValue); if (logicalValue instanceof JDIValue) { ((JDIValue) logicalValue).setLogicalParent(javaValue); } return logicalValue; } catch (CoreException e) { if (e.getStatus().getCode() == IJavaThread.ERR_THREAD_NOT_SUSPENDED) { throw e; } JDIDebugPlugin.log(e); } return value; } /** * Returns the <code>IJavaReferenceType</code> from the specified
private void createLink(String prefix, final Artifact art, String action, Artifact thisArt, RelationTypeSide relation, TeamWf teamWf) { try { Label label = editor.getToolkit().createLabel(this, prefix + " \"" + getTeamName(thisArt) + "\" " + action + getCompletedCancelledString(art) + " \"" + getTeamName(art) + "\" "); Hyperlink link = editor.getToolkit().createHyperlink(this, String.format("\"%s\" - %s", art.getName().length() < 60 ? art.getName() : art.getName().substring(0, 60), AtsClientService.get().getAtsId(art)), SWT.NONE); if (art.equals(thisArt)) { artAndRelToHyperlink.put(thisArt, relation, link); artAndRelToLabel.put(thisArt, relation, label); } else { artAndRelToHyperlink.put(art, relation, link); artAndRelToLabel.put(art, relation, label); } link.addHyperlinkListener(new IHyperlinkListener() { @Override public void linkEntered(HyperlinkEvent e) { // do nothing } }); } catch (Exception e) { // handle exception } }
IASTExpression fNameExp = fCall.getFunctionNameExpression(); IBinding fBinding = null; if (fNameExp instanceof IASTIdExpression) { IASTIdExpression fName = (IASTIdExpression) fNameExp; fBinding = fName.getName().resolveBinding(); } else if (fNameExp instanceof IASTFieldReference) { IASTFieldReference fName = (IASTFieldReference) fNameExp; if (referencesThis(fName.getFieldOwner())) fBinding = fName.getFieldName().resolveBinding(); } if (fBinding instanceof ICPPMethod) { ICPPMethod method = (ICPPMethod) fBinding; if (method.isPureVirtual() || ClassTypeHelper.isVirtual(method)) { reportProblem(VIRTUAL_CALL_ID, expression); } } return PROCESS_CONTINUE;
fBinding = fName.getName().resolveBinding(); } else if (fNameExp instanceof IASTFieldReference) { IASTFieldReference fName = (IASTFieldReference) fNameExp; if (referencesThis(fName.getFieldOwner())) fBinding = fName.getFieldName().resolveBinding(); } if (fBinding != null && fBinding instanceof ICPPMethod) { ICPPMethod method = (ICPPMethod) fBinding; if (method.isPureVirtual() || ClassTypeHelper.isVirtual(method)) { IASTNode problemNode = expression; reportProblem(VIRTUAL_CALL_ID, problemNode); } } } } return PROCESS_CONTINUE;
if (functionDefinition.isDefaulted() && SemanticQueries.isCopyOrMoveConstructor(constructor)) { return null; } if (constructor.getClassOwner().getKey() == ICompositeType.k_union) { return null; } // Skip delegating constructors. for (ICPPASTConstructorChainInitializer memberInitializer : functionDefinition.getMemberInitializers()) { IASTName memberName = memberInitializer.getMemberInitializerId(); if (memberName != null) { IBinding memberBinding = memberName.resolveBinding(); ICPPClassType classType = null; if (memberBinding instanceof ICPPClassType || memberBinding instanceof ICPPConstructor) { classType = (ICPPClassType) memberBinding; } if (classType instanceof ICPPDeferredClassInstance) { classType = ((ICPPDeferredClassInstance) classType).getClassTemplate(); } if (classType != null && classType.isSameType(constructor.getClassOwner())) { return null; } } } return constructor;
@NonNullByDefault public class TmfEventTableColumn { private final ITmfEventAspect<?> fAspect; private final List<ITmfEventAspect<?>> fAspectDuplicate = new ArrayList<>(); public TmfEventTableColumn(ITmfEventAspect<?> aspect) { fAspect = aspect; fAspectDuplicate.add(aspect); } public void addDuplicateAspect(ITmfEventAspect<?> duplicate) { fAspectDuplicate.add(duplicate); } }
public TmfEventTableColumn(ITmfEventAspect<?> aspect) { fAspect = aspect; fAspectDuplicate.add(aspect); }
public String getItemString(ITmfEvent event) { final String EMPTY_STRING = ""; String s = NonNullUtils.nullToEmptyString(fAspect.resolve(event)); if (fAspectDuplicate.size() > 1 && s.equals(EMPTY_STRING)) { for (ITmfEventAspect<?> aspect : fAspectDuplicate) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if (!eventString.isEmpty()) { return eventString; } } } return s; }
public class MyClass { private static final String EMPTY_STRING = ""; public String getItemString(ITmfEvent event) { for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if (eventString != EMPTY_STRING) { return eventString; } } return EMPTY_STRING; } }
public String getItemString(ITmfEvent event) { final String EMPTY_STRING = ""; for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if (eventString != EMPTY_STRING) { return eventString; } } return EMPTY_STRING; }
public String getItemString(ITmfEvent event) { for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if (!eventString.isEmpty()) { return eventString; } } return EMPTY_STRING; }
/***************************************************************************** * Copyright (c) 2011-2013 EclipseSource Muenchen GmbH and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Johannes Faltermeier - initial API and implementation *****************************************************************************/ package org.eclipse.emf.emfstore.client.test.ui.controllers; import java.io.IOException; import org.eclipse.emf.emfstore.common.ESObserver; import org.eclipse.emf.emfstore.internal.client.model.ESWorkspaceProviderImpl; import org.eclipse.emf.emfstore.internal.client.ui.controller.UIShowHistoryController; import org.eclipse.emf.emfstore.internal.common.observer.ObserverExceptionListener; import org.eclipse.emf.emfstore.server.exceptions.ESException; import org.eclipse.swtbot.eclipse.finder.widgets.SWTBotView; import org.eclipse.swtbot.swt.finder.finders.UIThreadRunnable; import org.eclipse.swtbot.swt.finder.results.VoidResult; import org.junit.Test; public class UIHistoryViewCloseTest extends AbstractUIControllerTestWithCommit { @Override @Test public void testController() throws ESException { // Test implementation } }
public void init(IWorkbench workbench) { setDescription(Messages.CapraGenericPreferences_description); setPreferenceStore(new ScopedPreferenceStore(InstanceScope.INSTANCE, CAPRA_PREFERENCE_PAGE_ID)); }
@SuppressWarnings("restriction") public class TreeMasterDetailComposite extends Composite implements IEditingDomainProvider { private static final String SELECT_A_NODE = JGitText.get().selectANode; private static final String LOADING = JGitText.get().loading; private final Object input; private final EditingDomain editingDomain; private TreeViewer treeViewer; private IMasterDetailSelectionProvider selectionProvider; private Sash verticalSash; private Composite detailComposite; private DetailViewManager detailManager; private Object lastRenderedObject; private final TreeMasterDetailSWTCustomization customization; // constructor and other methods }
public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { boolean result = false; for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { String propOs = property.getOs().trim(); if (propOs.isEmpty() || os.isEmpty() || propOs.equals(os)) { String propArch = property.getArch(); if (arch.isEmpty() || propArch.isEmpty() || propArch.equals(arch)) { result = true; break; } } } } return result; }
public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { String propOs = property.getOs().trim(); if (propOs.length() == 0 || os.length() == 0) { return true; } else if (os.equals(propOs)) { String propArch = property.getArch(); if (arch.length() == 0 || propArch.length() == 0) { return true; } } } } return false; }
if (name.equals(property.getName().trim())) { String propOs = property.getOs().trim(); if (propOs.length() == 0 || os.length() == 0) { result = true; break; } else if (os.equals(propOs)) { String propArch = property.getArch(); if (arch.length() == 0 || propArch.length() == 0) { result = true; break; } } }
public boolean checkCompatibility(Property property, String os, String arch) { boolean result = false; String propOs = property.getOs().trim(); if (propOs.length() == 0 || os.length() == 0) { result = true; } else if (os.equals(propOs)) { String propArch = property.getArch(); if (arch.length() == 0 || propArch.length() == 0) { result = true; } } return result; }
String propOs = property.getOs().trim(); // length zero means all OS versions if (propOs.length() == 0 || os.length() == 0) { result = true; break; } else if (os.equals(propOs)) { String propArch = property.getArch(); // length zero means all architecture versions if (arch.length() == 0 || propArch.length() == 0) { result = true; break; } } else { continue; } } } return result;
IConfigurationProperty configuration = (IConfigurationProperty) obj; switch (index) { case 0: return configuration.getName(); case 1: return configuration.getValue(); case 2: return configuration.getOs(); case 3: return configuration.getArch(); } return null; } private class PropertyDialog extends StatusDialog { private static final String EMPTY_MESSAGE = ""; private Text fName; private Text fValue; private Combo fOS; private Combo fArch; private IConfigurationProperty fEdit; private Set<IConfigurationProperty> fExistingProperties; private String[] COMBO_OSLABELS = new String[] { PDEUIMessages.PropertiesSection_All, Platform.OS_LINUX, Platform.OS_MACOSX, Platform.OS_WIN32 }; private String[] COMBO_ARCHLABELS = new String[] { PDEUIMessages.PropertiesSection_All, Platform.ARCH_X86, Platform.ARCH_X86_64 }; public PropertyDialog(Shell shell, IConfigurationProperty property, Set<IConfigurationProperty> existingProperties) { super(shell); fEdit = property; fExistingProperties = existingProperties; } }
public void addEvent(ITimeEvent event) { if (isValidEvent(event)) { super.addEvent(event); } }
public void setEventList(List<ITimeEvent> eventList) { if (eventList != null) { List<ITimeEvent> filteredList = eventList.stream() .filter(TimeGraphLineEntry::isValidEvent) .collect(Collectors.toList()); super.setEventList(filteredList); } }
public void updateZoomedEvent(ITimeEvent event) { super.updateZoomedEvent(event); }
private static boolean isValidEvent(ITimeEvent event) { return (event instanceof TimeLineEvent); }
// add style Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } if (seriesModel.isEmpty()) { return; } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha); gc.setForeground(color); List<LongPoint> series = seriesModel.get(i); // rest of the code }
public String toString() { return getClass().getSimpleName() + " time=" + fTime + (hasValue() ? (" value=" + getLabel()) : ""); }
seriesModel.add(new ArrayList<>()); // add style Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); if (values.size() < i) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); // rest of the code }
private Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); if (values.size() < i) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); // rest of the code }
Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); if (values.size() < i) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); }
public void addEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Needs to be a TimeLineEvent"); } super.addEvent(event); }
RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); List<LongPoint> seriesToAdd = seriesModel.get(i); long val = values.size() >= nbSeries ? values.get(i) : seriesToAdd.get(seriesToAdd.size() - 1).y; max = Math.max(Math.abs(val), max); min = 0; seriesToAdd.add(new LongPoint(x, val)); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha();
public class TimeLineDisplay extends AbstractTimeEventDisplay { public TimeLineDisplay() { super(); } @Override public void setEventList(List<ITimeEvent> eventList) { super.setEventList(eventList); } @Override public void updateZoomedEvent(ITimeEvent event) { super.updateZoomedEvent(event); } @Override public DisplayStyle getStyle() { return DisplayStyle.LINE; } }
Fixed Code: ```java package org.eclipse.tracecompass.internal.tmf.ui.widgets.timegraph.model; import java.text.NumberFormat; import java.util.ArrayList; import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.StringJoiner; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.ITimeGraphEntry; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.TimeEvent; /** * Generic TimeEvent implementation * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; private String fLabel = null; /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values * The values associated with this event */ public TimeLineEvent(ITimeGraphEntry entry, long time, List<Long> values) { super(entry, time); fValues = values; } /** * Get the values associated with this event * * @return The values associated with this event */ public List<Long> getValues() { return fValues; } /** * Set the label for this event * * @param label * The label for this event */ public void setLabel(String label) { fLabel = label; } /** * Get the label for this event * * @return The label for this event */ public String getLabel() { return fLabel; } @Override public String toString() { StringJoiner joiner = new StringJoiner(", ", "[", "]"); for (Long value : fValues) { joiner.add(NumberFormat.getNumberInstance(Locale.getDefault()).format(value)); } return super.toString() + " " + joiner.toString(); } @Override public int hashCode()
package org.eclipse.tracecompass.internal.tmf.ui.widgets.timegraph.model; import java.text.NumberFormat; import java.util.ArrayList; import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.StringJoiner; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.ITimeGraphEntry; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.TimeEvent; /** * Generic TimeEvent implementation * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; private String fLabel = null; /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values * The values associated with this event */ public TimeLineEvent(ITimeGraphEntry entry, long time, List<Long> values) { super(entry, time); fValues = values; } /** * Get the values associated with this event * * @return The values associated with this event */ public List<Long> getValues() { return fValues; } /** * Set the label for this event * * @param label * The label for this event */ public void setLabel(String label) { fLabel = label; } /** * Get the label for this event * * @return The label for this event */ public String getLabel() { return fLabel; } @Override public String toString() { StringJoiner joiner = new StringJoiner(", "); for (Long value : fValues) { joiner.add(NumberFormat.getNumberInstance(Locale.getDefault()).format(value)); } return super.toString() + " - " + joiner.toString(); } @Override public int hashCode() { return Objects.hash(super.hashCode(), f
/** * Standard constructor * * @param entry The entry matching this event * @param time The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry The entry matching this event * @param time The timestamp of this event * @param values The values to display */ public TimeLineEvent(ITimeGraphEntry entry, long time, List<Long> values) { super(entry, time, 0); fValues = values; } /** * Add a value * * @param value the value to add, it will be displayed as a line */ public void addValue(long value) { fValues.add(value); } @Override public String getLabel() { String label = fLabel; if (label == null) { // ... } // ... }
private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { long max = Long.MIN_VALUE; long min = 0; List<List<LongPoint>> seriesModel = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = -1; boolean isEmpty = true; while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width) { continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } isEmpty = false; } if (isEmpty) { return; } // rest of the code }
public void setEventList(List<ITimeEvent> eventList) { if (eventList != null) { super.setEventList(eventList.stream() .filter(this::isValidEvent) .collect(Collectors.toList())); } }
public String getLabel() { String label = fLabel; if (label == null) { StringJoiner sj = new StringJoiner(", "); getValues().forEach((Long value) -> sj.add(NumberFormat.getNumberInstance(Locale.getDefault()).format(value))); label = sj.toString(); fLabel = label; } return label; }
public List<Long> getValues() { return new ArrayList<>(fValues); }
public void register() { Chart chart = getChart(); chart.getPlotArea().addMouseTrackListener(this); chart.getPlotArea().addMouseMoveListener(this); chart.getPlotArea().addPaintListener(this); fTooltipHandler.activateHoverHelp(chart.getPlotArea()); }
public void deregister() { Chart chart = getChart(); if ((chart != null) && !chart.isDisposed()) { chart.getPlotArea().removeMouseTrackListener(this); chart.getPlotArea().removeMouseMoveListener(this); chart.getPlotArea().removePaintListener(this); fTooltipHandler.deactivateHoverHelp(chart.getPlotArea()); } }
for (int i = 0; i < 10; i++) { appendRandomLine(f); git.add().addFilepattern("file").call(); git.commit().setMessage("message" + i).call(); } FileBasedConfig c = db.getConfig(); c.setInt(ConfigConstants.CONFIG_GC_SECTION, null, ConfigConstants.CONFIG_KEY_AUTOPACKLIMIT, 1); c.save(); Collection<PackFile> packs = gc(Deflater.NO_COMPRESSION); assertEquals("expected 1 packfile after gc", 1, packs.size()); PackFile p1 = packs.iterator().next(); PackFileSnapshot snapshot = p1.getFileSnapshot(); packs = gc(Deflater.BEST_COMPRESSION); assertEquals("expected 1 packfile after gc", 1, packs.size()); PackFile p2 = packs.iterator().next(); File pf = p2.getPackFile();
public void setEventList(List<ITimeEvent> eventList) { super.setEventList(eventList); }
public void addValue(@Nullable Long value) { fValues.add(value); }
protected SWTBotTreeItem[] getPaneBasedSelectionWizardTreeitems() { SWTBotSiriusDiagramEditor representation = (SWTBotSiriusDiagramEditor) openRepresentation(localSession.getOpenedSession(), REPRESENTATION_DESCRIPTION_NAME, REPRESENTATION_NAME, DDiagram.class); representation.setFocus(); representation.activateTool("Pane Based Selection"); representation.click(50, 100); bot.waitUntil(Conditions.shellIsActive("Pane Based")); SWTBot wizardBot = bot.shell("Pane Based").bot(); SWTBotTree tree = wizardBot.tree().select(0); SWTBotTreeItem swtBotTreeItem = tree.getAllItems()[0]; SWTBotTreeItem[] items = swtBotTreeItem.getItems(); return items; }
assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } public void testCancelFirstWizard() { cancelFirstWizard(); Session session = localSession.getOpenedSession(); assertNotNull(THERE_IS_NO_SESSION, session); assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } public void testCancelSecondWizard() { cancelSecondWizard(TREE_NAME); Session session = localSession.getOpenedSession(); assertNotNull(THERE_IS_NO_SESSION, session); assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } public void testEmptySirius() { createOnContextMenu(); bot.waitUntil(Conditions.shellIsActive("Create Representation Wizard")); SWTBotShell shell = bot.shell("Create Representation Wizard");
public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { String propOs = property.getOs() != null ? property.getOs().trim() : ""; if (ALL_OS.equals(propOs) || ALL_OS.equals(os) || propOs.equals(os)) { String propArch = property.getArch() != null ? property.getArch().trim() : ""; if (propArch.equals(arch) || ALL_ARCH.equals(arch) || ALL_ARCH.equals(propArch)) { return true; } } } } return false; }
import org.eclipse.mylyn.context.core.AbstractContextStructureBridge; import org.eclipse.mylyn.context.core.ContextCore; import org.eclipse.mylyn.context.core.IInteractionElement; import org.eclipse.mylyn.context.sdk.util.AbstractResourceContextTest; import org.eclipse.mylyn.context.sdk.util.ContextTestUtil; import org.eclipse.mylyn.internal.resources.ui.ResourcesUiBridgePlugin; import org.eclipse.mylyn.internal.resources.ui.ResourcesUiPreferenceInitializer; import org.eclipse.ui.IWorkingSet; import org.eclipse.ui.IWorkingSetManager; import org.eclipse.ui.PlatformUI; /** * @author Mik Kersten * @author Carsten Reckord (bug 334024: focused package explorer not working if top level element is working set) */ public class ResourceContextTest extends AbstractResourceContextTest { @Override protected void setUp() throws Exception { super.setUp(); ResourcesUiBridgePlugin.getInterestUpdater().setSyncExec(true); ContextTestUtil.triggerContextUiLazyStart(); ResourcesUiBridgePlugin.getDefault() .getPreferenceStore() .setValue(ResourcesUiPreferenceInitializer.PREF_MODIFIED_DATE_EXCLUSIONS, false); } @Override protected void tearDown() throws Exception { super.tearDown(); ResourcesUiBridgePlugin.getInterestUpdater().setSyncExec(false); } } package com.google.gerrit.server.auth.ldap; import com.google.common.cache.LoadingCache; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gerrit.server.account.GroupMembership; import com.google.gerrit.server.account.ListGroupMembership; import com.google.gerrit.server.project.ProjectCache; import java.util.HashSet; import java.util.Set; import java.util.concurrent.ExecutionException; class LdapGroupMembership implements GroupMembership { private final LoadingCache<String, Set<AccountGroup.UUID>> membershipCache; private final ProjectCache projectCache; private final String id; private GroupMembership membership; LdapGroupMembership(LoadingCache<String, Set<AccountGroup.UUID>> membershipCache, ProjectCache projectCache, String id) { this.membershipCache = membershipCache; this.projectCache = projectCache; this.id = id; } @Override public boolean contains(AccountGroup.UUID groupId) { return get().contains(groupId); } @Override public boolean containsAnyOf(Iterable<AccountGroup.UUID> groupIds) { return get().containsAnyOf(groupIds); } } import android.app.Notification
private static void sanitizeList(List<ITimeEvent> sourceList, Consumer<List<ITimeEvent>> listConsumer) { if (sourceList != null) { // Sets a filtered list List<ITimeEvent> events = new ArrayList<>(); for (ITimeEvent event : sourceList) { if (isValidEvent(event)) { events.add(event); } else { events.add(null); } } listConsumer.accept(events); } }
} private void appendRandomLine(File f, int length, Random r) throws IOException { try (Writer w = Files.newBufferedWriter(f.toPath(), StandardOpenOption.APPEND)) { appendRandomLine(w, length, r); } } private void appendRandomLine(File f) throws IOException { appendRandomLine(f, 5, new Random()); } private void appendRandomLine(Writer w, int len, Random r) throws IOException { final int a = 32; // ' ' int e = 126; // '~' for (int i = 0; i < len; i++) { w.append((char) (a + r.nextInt(1 + e - a))); } } private Git createTestRepo(int testDataSeed, int testDataLength) throws IOException, GitAPIException, NoFilepatternException, NoHeadException, NoMessageException, UnmergedPathsException, ConcurrentRefUpdateException, WrongRepositoryStateException, AbortedByHookException { // Create a repo with two commits and one file. Each commit adds // testDataLength number of bytes. Data are random bytes. Since the
appendRandomLine(f, testDataLength, r); git.add().addFilepattern("file").call(); git.commit().setMessage("message2").call().getId(); return git; } @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); PackFile pf = repackAndCheck(5, null, null, null); }
git.commit().setMessage("message2").call().getId(); return git; } @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); }
Fixed Code: ```java git.commit().setMessage("message2").call().getId(); return git; } @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); } ```
// content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); String name = pf.getPackName(); Long length = Long.valueOf(pf.getPackFile().length()); long m1 = packFilePath.toFile().lastModified(); }
@Test public void testDetectModificationAlthoughSameSizeAndModificationTime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); String name = pf.getPackName(); Long length = Long.valueOf(pf.getPackFile().length()); long m1 = packFilePath.toFile().lastModified(); }
.getPackChecksum()); assumeTrue(m3 == m2); } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // To avoid that JGit detects modifications by checking the filekey create // two new packfiles upfront and create copies of them. Then modify the // packfiles inplace by opening them for write and copy content. @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtimeAndFileKey() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile. Make a copy of it PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); Path packFileBasePath = packFilePath.resolveSibling(
@Test public void testDetetctModificationAlthoughtSameSizeAndModificationtimeAndFileKey() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); Path packFileBasePath = packFilePath.resolveSibling(); // Create two new packfiles upfront and create copies of them Path packFile1Path = packFileBasePath.resolve("pack-1.pack"); Path packFile2Path = packFileBasePath.resolve("pack-2.pack"); Files.copy(packFilePath, packFile1Path); Files.copy(packFilePath, packFile2Path); // Modify the packfiles inplace by opening them for write and copying content try (FileChannel packFile1Channel = FileChannel.open(packFile1Path, StandardOpenOption.WRITE); FileChannel packFile2Channel = FileChannel.open(packFile2Path, StandardOpenOption.WRITE)) { packFile1Channel.transferFrom(packFilePath, 0, packFile1Channel.size()); packFile2Channel.transferFrom(packFilePath, 0, packFile2Channel.size()); } // Verify that JGit detects modifications assumeFalse(pf.hasObjectFile(packFile1Path.toFile())); assumeFalse(pf.hasObjectFile(packFile2Path.toFile())); }
@Test public void shouldIndexInRemoteOnChangeIndexedEvent() throws Exception { expect(restClientMock.index(CHANGE_ID)).andReturn(true); replayAll(); indexEventHandler.onChangeIndexed(id.get()); verifyAll(); } @Test public void shouldDeleteFromIndexInRemoteOnChangeDeletedEvent() throws Exception { reset(cd); expect(restClientMock.deleteFromIndex(CHANGE_ID)).andReturn(true); replayAll(); indexEventHandler.onChangeDeleted(id.get()); verifyAll(); } @Test public void testIndexEventHandlerIsForwarded() throws Exception { setUpMocks(false); Context.setForwardedEvent(true); indexEventHandler.onChangeIndexed(id.get()); indexEventHandler.onChangeDeleted(id.get()); Context.unsetForwardedEvent(); verifyAll(); } @Test public void duplicateEventOfAQueuedEventShouldGetDiscarded() { reset(poolMock); poolMock.execute(indexEventHandler.new SyncIndexTask(CHANGE_ID, false)); expectLastCall().once(); replayAll(); indexEventHandler.onChangeIndexed(id.get()); indexEventHandler.onChangeIndexed(id.get()); verifyAll(); } @Test public void shouldNotCallRemoteWhenEventIsForwarded() throws Exception { reset(poolMock); replayAll(); Context.setForwardedEvent(true); indexEventHandler.onChangeIndexed(id.get()); indexEventHandler.onChangeDeleted(id.get()); Context.unsetForwardedEvent(); verifyAll(); } private volatile Throwable cause; private int consumed = 0; private boolean poisoned = false; public Throwable cause() { return cause; } package com.android.tools.idea.gfx.rpccore; import java.util.HashMap; import java.util.Map; public class Decoder { @NotNull private final Map<Integer, RpcObject> decoded; @NotNull private final InputStream in; @NotNull private final byte[] buf; public Decoder(com.android.tools.idea.gfx.binary.Decoder binary) { this.binary = binary; this.decoded = new HashMap<Integer, RpcObject>(); } public RpcObject object(RpcObjectFactory factory) { int key = binary.uint16(); if (key == RpcObject.NULL_ID) { return null; } RpcObject obj = decoded.get(key); if (obj != null) { return obj; } int type = binary.uint16(); obj = factory.Create(type, this); decoded.put(key, obj); } Pack
public void setImage(Image image) { checkWidget(); if ((style & SWT.SEPARATOR) != 0) { return; } if (image != null && image.isDisposed()) { error(SWT.ERROR_INVALID_ARGUMENT); } this.image = image; updateStyleBits(image == null); OS.InvalidateRect(handle, null, true); }
public void setText(String string) { checkWidget(); if (string == null) { error(SWT.ERROR_NULL_ARGUMENT); } if ((style & SWT.SEPARATOR) != 0) { return; } updateStyleBits(true); if (string.equals(text)) { return; } text = string; string = Display.withCrLf(string); TCHAR buffer = new TCHAR(getCodePage(), string, true); OS.SetWindowText(handle, buffer); if ((state & HAS_AUTO_DIRECTION) != 0) { updateTextDirection(AUTO_TEXT_DIRECTION); } }
protected List<ISourceContainer> getEntriesAsList() { ISourceContainer[] entries = getViewer().getEntries(); List<ISourceContainer> list = new ArrayList<>(entries.length); for (ISourceContainer entry : entries) { list.add(entry); } return list; }
public void setEntries(ISourceContainer[] entries) { fEntries.clear(); for (ISourceContainer entry : entries) { if (entry != null) { fEntries.add(entry); } } if (getInput() == null) { setInput(fEntries); if (!fEntries.isEmpty() && fEntries.get(0) != null) { setSelection(new StructuredSelection(fEntries.get(0))); } } else { refresh(); } fPanel.setDirty(true); fPanel.updateLaunchConfigurationDialog(); }
public void addEntries(ISourceContainer[] entries) { int index = 0; IStructuredSelection sel = getStructuredSelection(); if (!sel.isEmpty()) { index = fEntries.indexOf(sel.getFirstElement()); } for (ISourceContainer entry : entries) { if (!fEntries.contains(entry)) { fEntries.add(index, entry); index++; } } refresh(); if (entries.length > 0) { setSelection(new StructuredSelection(entries)); } fPanel.setDirty(true); fPanel.updateLaunchConfigurationDialog(); }
public void setOrganizers(IBreakpointOrganizer[] organizers) { // remove previous listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.removePropertyChangeListener(this); } } fOrganizers = organizers; if (organizers != null && organizers.length == 0) { fOrganizers = null; } // add listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.addPropertyChangeListener(this); } } if (!fDisposed) { fViewer.getControl().setRedraw(false); // maintain expansion based on visible breakpoints IBreakpoint[] breakpoints = null; if (isShowingGroups()) { breakpoints = fViewer.getVisibleBreakpoints(); } reorganize(); if (isShowingGroups() && breakpoints != null) { // restore expansion for (Object fElement : fElements) { BreakpointContainer container = (BreakpointContainer) fElement; for (IBreakpoint breakpoint : breakpoints) { if (container.contains(breakpoint)) { fViewer.expandToLevel(container, AbstractTreeViewer.ALL_LEVELS); fViewer.updateCheckedState(container); } } } } } }
public void setOrganizers(IBreakpointOrganizer[] organizers) { // remove previous listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.removePropertyChangeListener(this); } } fOrganizers = organizers; if (organizers != null && organizers.length == 0) { fOrganizers = null; } // add listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.addPropertyChangeListener(this); } } if (!fDisposed) { fViewer.getControl().setRedraw(false); // maintain expansion based on visible breakpoints IBreakpoint[] breakpoints = null; if (isShowingGroups()) { breakpoints = fViewer.getVisibleBreakpoints(); } reorganize(); if (isShowingGroups() && breakpoints != null) { // restore expansion for (Object fElement : fElements) { BreakpointContainer container = (BreakpointContainer) fElement; for (IBreakpoint breakpoint : breakpoints) { if (container.contains(breakpoint)) { fViewer.expandToLevel(container, AbstractTreeViewer.ALL_LEVELS); fViewer.updateCheckedState(container); } } } } } }
public boolean isValidProperty(String property) { if (fFilters == null) { return true; } return Arrays.asList(fFilters).contains(property); }
public String getRawMemoryString() { if (fStrRep == null) { StringBuffer buffer = new StringBuffer(); fStrRep = RenderingsUtil.convertByteArrayToHexString(getByteArray()); fStrRep = fStrRep.toUpperCase(); buffer = buffer.append(fStrRep); // pad unavailable bytes with padded string from memory block String paddedString = null; int bufferCounter = 0; for (MemoryByte fByte : fBytes) { // if byte is invalid if (!fByte.isReadable()) { if (paddedString == null) { paddedString = fPaddedString; if (paddedString.length() > TableRenderingLine.numCharPerByteForHex) { paddedString = paddedString.substring(0, TableRenderingLine.numCharPerByteForHex); } } buffer.replace(bufferCounter, bufferCounter + TableRenderingLine.numCharPerByteForHex, paddedString); } bufferCounter += TableRenderingLine.numCharPerByteForHex; } fStrRep = buffer.toString(); } return fStrRep; }
fSashForm.setMaximizedControl(variablesViewer.getControl()); fDetailsAnchor = SWTFactory.createComposite(fSashForm, parent.getFont(), 1, 1, GridData.FILL_BOTH, 0, 0); fSashForm.setWeights(getLastSashWeights()); fSelectionProvider = new SelectionProviderWrapper(variablesViewer); getSite().setSelectionProvider(fSelectionProvider); createOrientationActions(variablesViewer); IPreferenceStore prefStore = DebugUIPlugin.getDefault().getPreferenceStore(); String orientation = prefStore.getString(getDetailPanePreferenceKey()); for (ToggleDetailPaneAction fToggleDetailPaneAction : fToggleDetailPaneActions) { fToggleDetailPaneAction.setChecked(fToggleDetailPaneAction.getOrientation().equals(orientation)); } fDetailPane = new DetailPaneProxy(this); fDetailPane.addProperyListener(new IPropertyListener() { @Override public void propertyChanged(Object source, int propId) { firePropertyChange(propId); } }); setDetailPaneOrientation(orientation); IMemento memento = getMemento(); if (memento != null) { variablesViewer.initState(memento); } variablesViewer.addModelChangedListener(this); variablesViewer.addViewerUpdateListener(this); initDragAndDrop(variablesViewer); return variablesViewer;
protected void saveAllCheckedActionStates() { IToolBarManager tbm = getViewSite().getActionBars().getToolBarManager(); IContributionItem[] items = tbm.getItems(); for (IContributionItem contributionItem : items) { if (contributionItem instanceof ActionContributionItem) { ActionContributionItem item = (ActionContributionItem) contributionItem; IAction action = item.getAction(); if (action.getStyle() == IAction.AS_CHECK_BOX && action.isEnabled()) { saveCheckedActionState(action); } } } }
public ExportBreakpointsOperation(IBreakpoint[] breakpoints) { fBreakpoints = breakpoints; fWriter = new StringWriter(); } @Override public void run(IProgressMonitor monitor) throws InvocationTargetException { SubMonitor localmonitor = SubMonitor.convert(monitor, ImportExportMessages.ExportOperation_0, fBreakpoints.length); XMLMemento memento = XMLMemento.createWriteRoot(IImportExportConstants.IE_NODE_BREAKPOINTS); try (Writer writer = fWriter;) { for (IBreakpoint breakpoint : fBreakpoints) { if (localmonitor.isCanceled()) { return; } IMarker marker = breakpoint.getMarker(); IMemento root = memento.createChild(IImportExportConstants.IE_NODE_BREAKPOINT); root.putString(IImportExportConstants.IE_BP_ENABLED, Boolean.toString(breakpoint.isEnabled())); root.putString(IImportExportConstants.IE_BP_REGISTERED, Boolean.toString(breakpoint.isRegistered())); // ... continue with the rest of the code } } catch (IOException e) { throw new InvocationTargetException(e); } }
public ExportBreakpointsOperation(IBreakpoint[] breakpoints) { fBreakpoints = breakpoints; fWriter = new StringWriter(); } @Override public void run(IProgressMonitor monitor) throws InvocationTargetException { SubMonitor localmonitor = SubMonitor.convert(monitor, ImportExportMessages.ExportOperation_0, fBreakpoints.length); XMLMemento memento = XMLMemento.createWriteRoot(IImportExportConstants.IE_NODE_BREAKPOINTS); try (Writer writer = fWriter;) { for (IBreakpoint fBreakpoint : fBreakpoints) { if (localmonitor.isCanceled()) { return; } IBreakpoint breakpoint = fBreakpoint; IMarker marker = breakpoint.getMarker(); IMemento root = memento.createChild(IImportExportConstants.IE_NODE_BREAKPOINT); root.putString(IImportExportConstants.IE_BP_ENABLED, Boolean.toString(breakpoint.isEnabled())); root.putString(IImportExportConstants.IE_BP_REGISTERED, Boolean.toString(breakpoint.isRegistered())); root.putString(IImportExportConstants.IE_BP_PERSISTANT, Boolean.toString(breakpoint.isPersisted())); //write out the resource information } } catch (IOException e) { throw new InvocationTargetException(e); } }
if (scroll != null && !scroll.isDisposed()) { scroll.removeSelectionListener(fScrollbarSelectionListener); } if (!fTableCursor.isDisposed()) { fTableCursor.removeTraverseListener(fCursorTraverseListener); fTableCursor.removeKeyListener(fCursorKeyAdapter); fTableCursor.removeMouseListener(fCursorMouseListener); } fCursorEditor.dispose(); fTextViewer = null; fTableViewer = null; fTableCursor = null; for (CellEditor fEditor : fEditors) { fEditor.dispose(); } JFaceResources.getFontRegistry().removeListener(this); IMemoryRenderingSynchronizationService syncService = getMemoryRenderingContainer().getMemoryRenderingSite().getSynchronizationService(); if (syncService != null) { syncService.removePropertyChangeListener(this); } DebugUIPlugin.getDefault().getPreferenceStore().removePropertyChangeListener(this); fToolTipShell.dispose(); if (getPopupMenuManager() != null) { getPopupMenuManager().removeMenuListener(fMenuListener); } super.dispose();
import org.eclipse.emf.edit.provider.ComposedAdapterFactory; import org.eclipse.emf.edit.provider.ReflectiveItemProviderAdapterFactory; import org.eclipse.jface.databinding.swt.WidgetValueProperty; import org.eclipse.jface.viewers.CellEditor; import org.eclipse.swt.SWT; import org.eclipse.swt.events.FocusEvent; import org.eclipse.swt.events.FocusListener; import org.eclipse.swt.graphics.Image; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Control; @SuppressWarnings("restriction") public class SingleReferenceCellEditor extends CellEditor implements ECPCellEditor, ECPElementAwareCellEditor { private EObject rowElement; private ReferenceService referenceService; private EReference eReference; private Composite composite; private ComposedAdapterFactory composedAdapterFactory; private AdapterFactoryItemDelegator adapterFactoryItemDelegator; /** * The constructor. * * @param parent the parent composite */ public SingleReferenceCellEditor(Composite parent) { super(parent); } /** * Alternate constructor with SWT style bits. * * @param parent the parent composite * @param style the SWT style bits */ public SingleReferenceCellEditor(Composite parent, int style) { super(parent, style); } }
public String getFormattedString(Object value) { if (value == null) { return ""; } return adapterFactoryItemDelegator.getText(value); }
Refactored Code: ```java package org.eclipse.emf.ecp.view.internal.table.swt.cell; import org.eclipse.emf.ecore.EObject; import org.eclipse.emf.ecore.EReference; import org.eclipse.emf.ecore.EStructuralFeature; import org.eclipse.emf.ecp.edit.spi.swt.table.ECPCellEditorTester; import org.eclipse.emf.ecp.view.spi.context.ViewModelContext; /** * Single reference cell editor tester. * * @author Mat Hansen <mhansen@eclipsesource.com> * @since 1.21 */ public class SingleReferenceCellEditorTester implements ECPCellEditorTester { @Override public int isApplicable(EObject eObject, EStructuralFeature eStructuralFeature, ViewModelContext viewModelContext) { if (!EReference.class.isInstance(eStructuralFeature)) { return NOT_APPLICABLE; } final EReference eReference = EReference.class.cast(eStructuralFeature); if (eReference.getUpperBound() == 1) { return 10; } return NOT_APPLICABLE; } } ```
private void analyzeReferencedPackages(PackageVisibilityStatement[] statements, CompilationUnitScope scope) { for (PackageVisibilityStatement statement : statements) { PackageBinding packageBinding = statement.resolvedPackage; if (packageBinding == null) { continue; } packageBinding = packageBinding.getIncarnation(this.binding); if (packageBinding != null && packageBinding.hasCompilationUnit(true)) { continue; } scope.problemReporter().invalidPackageReference(IProblem.PackageDoesNotExistOrIsEmpty, statement); } }
void display(JsArray<NativeString> values) { int row = 1; for (String v : Natives.asList(values)) { populate(row, v); row++; } } String webUrl(); default String changeViewUrl(@Nullable Project.NameKey project, Change.Id id) { return Optional.of(url + "c/" + (project != null ? project.get() + "/+/" : "") + id.get()); } // Translate from the host index (local to the HdfsTable) to network address. Integer tableHostIdx = replicaHostIdxs.get(i); TNetworkAddress networkAddress = partition.getTable().getHostIndex().getEntry(tableHostIdx); Preconditions.checkNotNull(networkAddress); // Translate from network address to the global (to this request) host index. Integer globalHostIdx = analyzer.getHostIndex().getIndex(networkAddress); location.setHost_idx(globalHostIdx); location.setVolume_id(block.getDiskId(i)); location.setIs_cached(block.isCached(i)); locations.add(location); } // create scan ranges, taking into account maxScanRangeLength long currentOffset = block.getOffset(); long remainingLength = block.getLength(); while (remainingLength > 0) { long currentLength = remainingLength; if (maxScanRangeLength > 0 && remainingLength > maxScanRangeLength) { currentLength = maxScanRangeLength; } } if (checkForSplit && this.environment.useModuleSystem) { char[][] declaringModuleNames = null; if (isUnnamed()) { IModuleAwareNameEnvironment moduleEnv = (IModuleAwareNameEnvironment) this.environment.nameEnvironment; declaringModuleNames = moduleEnv.getUniqueModulesDeclaringPackage(new char[][] {packageName}, ANY); } packageBinding = combineWithPackagesFromOtherRelevantModules(packageBinding, packageBinding.compoundName, declaringModuleNames); } this.declaredPackages.put(packageName, packageBinding.getVisibleFor(this, true, true/*need to see empty parent packages, too*/)); if (packageBinding.parent == null) { this.environment.knownPackages.put(packageName, packageBinding); } return packageBinding; } private PackageBinding combineWithPackagesFromOtherRelevantModules(PackageBinding currentBinding, char[][] compoundName, char[][] declaringModuleNames) { boolean save = this.isPackageLookupActive; this.isPackageLookupActive = true; try { for (ModuleBinding moduleBinding
PackageBinding combineWithSiblings(PackageBinding childPackage, char[] name, ModuleBinding module) { ModuleBinding primaryModule = childPackage.enclosingModule; boolean activeSave = primaryModule.isPackageLookupActive; primaryModule.isPackageLookupActive = true; try { char[] flatName = CharOperation.concatWith(childPackage.compoundName, '.'); for (PackageBinding incarnation : this.incarnations) { ModuleBinding moduleBinding = incarnation.enclosingModule; if (moduleBinding == module) continue; if (childPackage.isDeclaredIn(moduleBinding)) continue; PackageBinding next = moduleBinding.getDeclaredPackage(flatName); childPackage = combine(next, childPackage, primaryModule); } return childPackage; } finally { primaryModule.isPackageLookupActive = activeSave; } }
final Object image = adapterFactoryItemDelegator.getImage(value); return SWTImageHelper.getImage(image); @Override public int getColumnWidthWeight() { return 0; } @Override public UpdateValueStrategy getTargetToModelStrategy(DataBindingContext databindingContext) { return null; } @Override public UpdateValueStrategy getModelToTargetStrategy(DataBindingContext databindingContext) { return null; } @Override public void setEditable(boolean editable) { } @Override public int getMinWidth() { return 100; } /** * {@inheritDoc} * * @see org.eclipse.jface.viewers.CellEditor#createControl(org.eclipse.swt.widgets.Composite) */ @Override protected Control createControl(Composite parent) { composite = new Composite(parent, SWT.NONE); composite.addFocusListener(new FocusListener() { private boolean focused; @Override public void focusLost(FocusEvent e) { } @Override public void focusGained(FocusEvent e) { if (focused) { return; } focused = true; try { // Code to handle focus event } finally { focused = false; } } }); return composite; }
package org.eclipse.papyrus.model2doc.odt.internal.transcription; public class CustomFields { private CustomFields() { // to prevent instantiation } public static final String AUTHORS = "Authors"; public static final String VERSION = "Version"; }
package org.eclipse.papyrus.model2doc.odt.internal.transcription; public class CustomFields { private CustomFields() { // to prevent instantiation } public static final String AUTHORS = "Authors"; public static final String VERSION = "Version"; }
public void writeAuthors(final Collection<IAuthor> authors) { if (authors.size() > 0) { final XTextDocument document = odtEditor.getXTextDocument(); final XDocumentPropertiesSupplier xsDocProp = UnoRuntime.queryInterface(XDocumentPropertiesSupplier.class, document); XDocumentProperties props = xsDocProp.getDocumentProperties(); final Iterator<IAuthor> iterator = authors.iterator(); String allAuthorsLabel = ""; if (iterator.hasNext()) { final IAuthor firstAuthor = iterator.next(); allAuthorsLabel = firstAuthor.buildMultiAuthorLabel(ECollections.toEList(authors)); props.setAuthor(firstAuthor.buildAuthorLabel()); } XPropertyContainer userDefined = props.getUserDefinedProperties(); try { userDefined.removeProperty(CustomFields.AUTHORS); } catch (UnknownPropertyException | NotRemoveableException e) { // nothing to do } try { userDefined.addProperty(CustomFields.AUTHORS, com.sun.star.beans.PropertyAttribute.REMOVABLE, allAuthorsLabel); } catch (IllegalArgumentException | PropertyExistException | IllegalTypeException e) { Activator.log.error(e); } } }
String allAuthorsLabel = ""; if (iterator.hasNext()) { final IAuthor firstAuthor = iterator.next(); allAuthorsLabel = firstAuthor.buildMultiAuthorLabel(ECollections.toEList(authors)); props.setAuthor(firstAuthor.buildAuthorLabel()); } XPropertyContainer userDefined = props.getUserDefinedProperties(); // we need to remove the property if it already exist, in order to be change its value try { userDefined.removeProperty(CustomFields.AUTHORS); } catch (UnknownPropertyException | NotRemoveableException e) { // nothing to do } try { userDefined.addProperty(CustomFields.AUTHORS, com.sun.star.beans.PropertyAttribute.REMOVABLE, allAuthorsLabel); } catch (IllegalArgumentException | PropertyExistException | IllegalTypeException e) { Activator.log.error(e); }
public void testInitialStateWithCondition() { ITmfStateSystem stateSystem = fModule.getStateSystem(fModule.getId()); assertNotNull(stateSystem); try { int quark = stateSystem.getQuarkAbsolute("fsm1"); ITmfStateInterval interval = stateSystem.querySingleState(END_TIME, quark); long count1 = interval.getStateValue().unboxLong(); quark = stateSystem.getQuarkAbsolute("fsm2"); interval = stateSystem.querySingleState(END_TIME, quark); long count2 = interval.getStateValue().unboxLong(); assertEquals("Test the count value", count1, count2); } catch (AttributeNotFoundException | StateSystemDisposedException e) { fail("Failed to query the state system"); } }
if (!isPinned) { // Remove and dispose any previous adorned image Image previouslyAdornedImage = (Image) element.getTransientData().get("previouslyAdorned"); //$NON-NLS-1$ if (previouslyAdornedImage != null && !previouslyAdornedImage.isDisposed()) { previouslyAdornedImage.dispose(); } element.getTransientData().remove(IPresentationEngine.ADORNMENT_PIN); } else { Image adornedImage = resUtils.adornImage(image, pinImage); if (adornedImage != image) { // Dispose the previous adorned image if it exists Image previouslyAdornedImage = (Image) element.getTransientData().get("previouslyAdorned"); //$NON-NLS-1$ if (previouslyAdornedImage != null && !previouslyAdornedImage.isDisposed()) { previouslyAdornedImage.dispose(); } element.getTransientData().put("previouslyAdorned", adornedImage); //$NON-NLS-1$ } return adornedImage; }
public final Image getImage(MUILabel element) { return getImage(element, false); }
private Image adornImage(MUIElement element, Image image, boolean imageChanged) { if (element.getTags().contains(IPresentationEngine.ADORNMENT_PIN)) { // Only if Pinned Image Image previousImage = (Image) element.getTransientData().get(ADORN_ICON_IMAGE_KEY); boolean exist = previousImage != null && !previousImage.isDisposed(); // Cached image exist if (imageChanged || !exist) { if (imageChanged && exist) { disposeAdornedImage(element); // Need to dispose old image. If image changed } Image adornedImage = resUtils.adornImage(image, pinImage); if (adornedImage != image) { element.getTransientData().put(ADORN_ICON_IMAGE_KEY, adornedImage); } return adornedImage; } return previousImage; } return image; }
protected void showTab(MUIElement tabElement) { MPerspective persp = (MPerspective) tabElement; Control ctrl = (Control) persp.getWidget(); if (ctrl == null) { ctrl = (Control) renderer.createGui(persp); } else if (ctrl.getParent() != persp.getParent().getWidget()) { Composite parent = (Composite) persp.getParent().getWidget(); ctrl.setParent(parent); } super.showTab(persp); // relayout the perspective Composite psComp = ctrl.getParent(); StackLayout sl = (StackLayout) psComp.getLayout(); if (sl != null) { sl.topControl = ctrl; psComp.layout(); } ctrl.moveAbove(null); // Force a context switch IEclipseContext context = persp.getContext(); context.get(EPartService.class).switchPerspective(persp); // Move any other controls to 'limbo' Control[] kids = psComp.getChildren(); Shell limbo = (Shell) context.get("limbo"); for (Control child : kids) { if (child != ctrl) { child.setParent(limbo); } } }
private boolean loadMappingsFromOldWorkspace(Map<String, Integer> map) { String STATE_FILE = ".fileTypes"; IPath pluginStateLocation = TeamPlugin.getPlugin().getStateLocation().append(STATE_FILE); File f = pluginStateLocation.toFile(); if (!f.exists()) { return false; } try (DataInputStream input = new DataInputStream(new FileInputStream(f))) { map.putAll(readOldFormatExtensionMappings(input)); } catch (IOException ex) { TeamPlugin.log(IStatus.ERROR, ex.getMessage(), ex); return false; } finally { f.delete(); } return true; }
```java public class HexUtils { private static final int ASCII_DIGITS_START_POSITION = 48; private static final int ASCII_UPPERCASE_LETTERS_START_POSITION = 65; private HexUtils() { // private constructor to prevent instantiation } public static String bytesToHex(byte[] bytes) { StringBuilder hexString = new StringBuilder(); for (byte b : bytes) { String hex = Integer.toHexString(b & 0xFF); if (hex.length() == 1) { hexString.append('0'); } hexString.append(hex); } return hexString.toString(); } public static byte[] hexToBytes(String hexString) { return hexToBytes(hexString, "(?<=\\G.{2})"); } private static byte hexCharacterToBin(char character) { if ('0' <= character && character <= '9') { return (byte) (character - ASCII_DIGITS_START_POSITION); } else if ('A' <= character && character <= 'F') { return (byte) (character - ASCII_UPPERCASE_LETTERS_START_POSITION + 10); } else { throw new IllegalArgumentException("Invalid hex character: " + character); } } private static byte[] hexToBytes(String hexString, String delimiter) { String[] hexArray = hexString.split(delimiter); byte[] bytes = new byte[hexArray.length]; for (int i = 0; i < hexArray.length; i++) { bytes[i] = hexCharacterToBin(hexArray[i].charAt(0)); } return bytes; } } ```
public TableUserFilterManager getUserFilterManager() { return (TableUserFilterManager) propertySupport.getProperty(PROP_USER_FILTER_MANAGER); } @Override public void setUserFilterManager(TableUserFilterManager m) { propertySupport.setProperty(PROP_USER_FILTER_MANAGER, m); } @Override public ITableCustomizer getTableCustomizer() { return (ITableCustomizer) propertySupport.getProperty(PROP_TABLE_CUSTOMIZER); } @Override public void setTableCustomizer(ITableCustomizer c) { propertySupport.setProperty(PROP_TABLE_CUSTOMIZER, c); } @Override public IPage<?> getParentPage() { return (IPage<?>) propertySupport.getProperty(PROP_PARENT_PAGE); } @Override public ITypeWithClassId getContainer() { IWidget parentWidget = getParent(); if (parentWidget != null) { return parentWidget; } return getParentPage(); } /** * Do not use this internal method */ public void setParentPageInternal(IPage<?> container) { propertySupport.setProperty(PROP_PARENT_PAGE, container); } @Override public boolean isSortEnabled() { return propertySupport.getPropertyBool(PROP_SORT_ENABLED); }
public class LocalSelectionTransfer extends ByteArrayTransfer { private static final String TYPE_NAME = "local-selection-transfer-format" + System.currentTimeMillis(); private static final int TYPEID = registerType(TYPE_NAME); private static final LocalSelectionTransfer INSTANCE = new LocalSelectionTransfer(); private ISelection selection; private long selectionSetTime; protected LocalSelectionTransfer() { // do nothing } public static LocalSelectionTransfer getTransfer() { return INSTANCE; } public ISelection getSelection() { return selection; } public void setSelection(ISelection selection) { this.selection = selection; this.selectionSetTime = System.currentTimeMillis(); } @Override protected int[] getTypeIds() { return new int[] { TYPEID }; } @Override protected String[] getTypeNames() { return new String[] { TYPE_NAME }; } @Override protected void javaToNative(Object object, TransferData transferData) { if (object instanceof ISelection) { ISelection selection = (ISelection) object; if (isSupportedType(transferData)) { byte[] bytes = serializeSelection(selection); if (bytes != null) { super.javaToNative(bytes, transferData); } } } } @Override protected Object nativeToJava(TransferData transferData) { if (isSupportedType(transferData)) { byte[] bytes = (byte[]) super.nativeToJava(transferData); return deserializeSelection(bytes); } return null; } private byte[] serializeSelection(ISelection selection) { // serialize the selection to bytes return null; } private ISelection deserializeSelection(byte[] bytes) { // deserialize the bytes to a selection return null; } }
private String convertToEditableTimeInterval(String string) { if (string.length() == 0) return string; long value; try { value = Long.parseLong(string); } catch (NumberFormatException e) { value = 0; } if (value == 0) return Long.toString(0); for (int i = 0; i < timeIntervalPrefixes.length - 1; i++) { if (value % timeIntervalScale[i] != 0) return Long.toString(value) + timeIntervalPrefixes[i]; value /= timeIntervalScale[i]; } return Long.toString(value) + timeIntervalPrefixes[timeIntervalPrefixes.length - 1]; } private String convertFromEditableTimeInterval(String string) { if (string.length() == 0) return string; for (int i = 1; i < timeIntervalPrefixes.length; i++) { if (string.endsWith(timeIntervalPrefixes[i])) { long value = Long.parseLong(string.substring(0, string.length() - 1)); for (int j = 0; j < i; j++) value *= timeIntervalScale[j]; return Long.toString(value); } } return string; }
public String toString() { String rv = "Item "; if (parent != null) { rv = parent.toString() + "."; } rv += counter; return rv; }
// produce = false; else { if (filter.requiresCommitBody()) c.parseBody(walker); produce = filter.include(walker, c); } for (int i = 0; i < c.parents.length; i++) { RevCommit p = c.parents[i]; if ((p.flags & SEEN) != 0) continue; if ((p.flags & PARSED) == 0) p.parseHeaders(walker); p.flags |= SEEN; if (firstParent && i > 0) { continue; } pending.add(p); } walker.carryFlagsImpl(c); if ((c.flags & UNINTERESTING) != 0) { if (pending.everbodyHasFlag(UNINTERESTING)) { final RevCommit n = pending.peek(); if (n != null && n.commitTime >= last.commitTime) { // This is too close to call. The next commit we // would pop is dated after the last one produced. // We have to keep going to ensure that we carry // flags as much as necessary. // continue; } } }
private void queryAdapterTypes(Map<String, AdapterType> adapters, Resource res) { try { QueryResponse queryResp = executeQuery("SELECT * FROM AdapterTypes", res); setAdapterTypes(queryResp.getQueryResult(), adapters); } catch (Exception e) { logger.error(MessageFormat.format(Messages.DTL_QueryFailed, "Adapter Types")); } } @Override public void createFBInstance(final FBDeploymentData fbData, final Resource res) throws DeploymentException { // check first if FBType exists Map<String, AdapterType> adapters = getAdapterTypes(fbData.getFb().getType().getInterfaceList()); if (!adapters.isEmpty()) { queryAdapterTypes(adapters, res); createAdapterTypes(adapters, res); } // if the FBType does not exist create it if (!getTypes().contains(fbData.getFb().getType().getName())) { try { createFBType(fbData.getFb().getType(), res); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fbData.getFb().getType().getName())); } } super.createFBInstance(fbData, res); } private static Map<String, AdapterType> getAdapterTypes(InterfaceList interfaceList) { // implementation omitted }
RevCommit a = commit(); RevCommit b1 = commit(a); RevCommit b2 = commit(a); RevCommit c1 = commit(b1); RevCommit c2 = commit(b2); RevCommit d = commit(c1, c2); rw.reset(); rw.setFirstParent(true); markStart(d); assertCommit(d, rw.next()); assertCommit(c1, rw.next()); assertCommit(b1, rw.next()); assertCommit(a, rw.next()); assertNull(rw.next()); @Test public void testSecondParentAncestorOfFirstParent() throws Exception { RevCommit a = commit(); RevCommit b = commit(a); RevCommit c = commit(b, a); rw.reset(); rw.setFirstParent(true); markStart(c); assertCommit(c, rw.next()); assertCommit(b, rw.next()); assertCommit(a, rw.next()); assertNull(rw.next()); } @Test public void testFirstParentMultipleOccurrences() throws Exception { RevCommit a = commit(); RevCommit b = commit(a); RevCommit c = commit(b); rw.reset(); rw.setFirstParent(true); markStart(c); assertCommit(c, rw.next()); assertCommit(b, rw.next()); assertCommit(a, rw.next()); assertNull(rw.next()); }
final class Generator { static final int HAS_REWRITE = 1 << 1; static final int NEEDS_REWRITE = 1 << 2; static final int SORT_TOPO = 1 << 3; static final int HAS_UNINTERESTING = 1 << 4; protected final boolean firstParent; protected Generator(boolean firstParent) { this.firstParent = firstParent; } void shareFreeList(BlockRevQueue q) { // Do nothing by default. } int getFlags() { // Implementation not shown } }
public <T extends ITmfTreeDataProvider<? extends ITmfTreeDataModel>> void removeDataProvider(ITmfTrace trace, T provider) { fInstances.remove(trace, provider); }
protected String getDebuggeeClassName() { return GetValues006Debuggee.class.getName(); } private void checkCreateFBType(FB fb, Resource res) { if (!getTypes().contains(fb.getType().getName())) { try { createFBType(fb.getType(), res); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fb.getType().getName())); } } }
// if the FPType does not exist create it if (!getTypes().contains(fb.getType().getName())) { try { createFBType(fb.getType()); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fb.getType().getName())); } } public void createFBType(final FBType fbType) throws DeploymentException { setAttribute(getDevice(), "FBType", getTypes()); if (fbType instanceof BasicFBType || fbType instanceof CompositeFBType) { if (fbType instanceof CompositeFBType) { createFBTypesOfCFB(fbType); } String request = createLuaRequestMessage(fbType); sendCreateFBTypeREQ(fbType, request); } } private void sendCreateFBTypeREQ(final FBType fbType, String request) throws DeploymentException { try { String result = sendREQ("", request); if (result.contains("Reason")) { // handle error } } catch (IOException e) { throw new DeploymentException(e); } }
addLocalDeclarationSplit(rewrite); else addLocalDeclarationRemoval(rewrite); if (fInitializeIn == INITIALIZE_IN_CONSTRUCTOR) addInitializersToConstructors(rewrite); addTempRenames(rewrite); addFieldDeclaration(rewrite); CompilationUnitChange result= new CompilationUnitChange(RefactoringCoreMessages.PromoteTempToFieldRefactoring_name, fCu); result.setDescriptor(new RefactoringChangeDescriptor(getRefactoringDescriptor())); TextEdit resultingEdits; Map<String, String> formatter= (this.fFormatterOptions == null) ? fCu.getJavaProject().getOptions(true) : this.fFormatterOptions; try { resultingEdits= rewrite.rewriteAST(new Document(fCu.getSource()), formatter); } catch (JavaModelException e) { resultingEdits= rewrite.rewriteAST(); } TextChangeCompatibility.addTextEdit(result, RefactoringCoreMessages.PromoteTempToFieldRefactoring_editName, resultingEdits); return result; finally { pm.done(); } } private void addTempRenames(ASTRewrite rewrite) { boolean noNameChange= fFieldName.equals(fTempDeclarationNode.getName().getIdentifier()); if (fLinkedProposalModel == null && noNameChange) { return; // no changes needed }
public CompilationUnitChange refactorCode(ASTRewrite rewrite, CompilationUnit fCu) { addInitializersToConstructors(rewrite); addTempRenames(rewrite); addFieldDeclaration(rewrite); CompilationUnitChange result = new CompilationUnitChange(RefactoringCoreMessages.PromoteTempToFieldRefactoring_name, fCu); result.setDescriptor(new RefactoringChangeDescriptor(getRefactoringDescriptor())); TextEdit resultingEdits; Map<String, String> formatter = (this.fFormatterOptions == null) ? fCu.getJavaProject().getOptions(true) : this.fFormatterOptions; try { resultingEdits = rewrite.rewriteAST(new Document(fCu.getSource()), formatter); } catch (JavaModelException e) { resultingEdits = rewrite.rewriteAST(); } TextChangeCompatibility.addTextEdit(result, RefactoringCoreMessages.PromoteTempToFieldRefactoring_editName, resultingEdits); return result; } private void addTempRenames(ASTRewrite rewrite) { boolean noNameChange = fFieldName.equals(fTempDeclarationNode.getName().getIdentifier()); if (fLinkedProposalModel == null && noNameChange) { return; // no changes needed } TempOccurrenceAnalyzer analyzer = new TempOccurrenceAnalyzer(fTempDeclarationNode, false); analyzer.perform(); }
@Override public IBaseLabelProvider getLabelProvider() { return super.getLabelProvider(); } @SuppressWarnings({ "rawtypes" }) @Override protected List getSelectionFromWidget() { if (virtualManager != null) { return getVirtualSelection(); } Widget[] items = doGetSelection(); List<Object> list = new ArrayList<>(items.length); for (Widget item : items) { Object e = item.getData(); if (e != null) { list.add(e); } } return list; }
Policy.getLog().log(new Status(IStatus.WARNING, Policy.JFACE, message, new RuntimeException())); return; } } } /** * Returns all selected items for the given SWT control. * * @param control * the control * @return the list of selected items */ protected abstract Item[] getSelection(Control control); @SuppressWarnings({ "rawtypes" }) @Override protected List getSelectionFromWidget() { Widget[] items = getSelection(getControl()); List<Object> list = new ArrayList<>(items.length); for (Widget item : items) { Object e = item.getData(); if (e != null) { list.add(e); } } return list; } /* * Overridden in AbstractTreeViewer to fix bug 108102 (code copied from * StructuredViewer to avoid introducing new API) */ @Override protected void handleDoubleSelect(SelectionEvent event) { // handle case where an earlier selection listener disposed the control. Control control = getControl();
protected void setSelectionToWidget(ISelection selection, boolean reveal) { if (selection instanceof ITreeSelection) { ITreeSelection treeSelection = (ITreeSelection) selection; setSelectionToWidget(Arrays.asList(treeSelection.getPaths()), reveal); } else { super.setSelectionToWidget(selection, reveal); } }
import java.util.Map.Entry; import java.util.Set; import java.util.TimerTask; import java.util.logging.Level; import java.util.logging.Logger; import org.apache.asterix.common.config.AsterixFeedProperties; import org.apache.asterix.external.feed.api.IFeedManager; import org.apache.asterix.external.feed.api.IFeedMessageService; import org.apache.asterix.external.feed.api.IFeedMetricCollector.ValueType; import org.apache.asterix.external.feed.api.IFeedRuntime.FeedRuntimeType; import org.apache.asterix.external.feed.api.IFeedRuntime.Mode; import org.apache.asterix.external.feed.dataflow.StorageFrameHandler; import org.apache.asterix.external.feed.management.FeedConnectionId; import org.apache.asterix.external.feed.message.FeedReportMessage; import org.apache.asterix.external.feed.message.FeedTupleCommitAckMessage; import org.apache.asterix.external.feed.message.FeedTupleCommitResponseMessage; import org.apache.asterix.external.feed.message.ScaleInReportMessage; import org.apache.asterix.external.feed.message.StorageReportFeedMessage; import org.apache.asterix.external.feed.policy.FeedPolicyAccessor; public class MonitoredBufferTimerTasks { }
private void checkCreateFBType(FBType fbType) { // if the FBType does not exist, create it if (!getTypes().contains(fbType.getName())) { try { createFBType(fbType); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fbType.getName())); } } }
private static List<IProject> getSelectedProjects(ISelection selection) { List<IProject> projectSelection = new ArrayList<>(); if (selection instanceof IStructuredSelection) { for (Object element : ((StructuredSelection) selection).toList()) { if (element instanceof AutomationSystem) { projectSelection.add(((AutomationSystem) element).getProject()); } } } return projectSelection; }
public void reveal() { // resolved.ifPresent(RevealStep::reveal); }
private static Collection<LSBasedHyperlink> collectHyperlinks(final IDocument document, final IRegion linkRegion, Either<List<? extends Location>, List<? extends LocationLink>> locations, Collection<LSBasedHyperlink> allLinks) { if (locations == null) { return allLinks; } else if (locations.isLeft()) { allLinks.addAll(locations.getLeft().stream().filter(Objects::nonNull).map(location -> new LSBasedHyperlink(location, linkRegion)).collect(Collectors.toList())); } else { allLinks.addAll(locations.getRight().stream().filter(Objects::nonNull).map(locationLink -> { IRegion selectionRegion = linkRegion; Range originSelectionRange = locationLink.getOriginSelectionRange(); if (originSelectionRange != null) { try { int offset = LSPEclipseUtils.toOffset(originSelectionRange.getStart(), document); int endOffset = LSPEclipseUtils.toOffset(originSelectionRange.getEnd(), document); selectionRegion = new Region(offset, endOffset - offset); } catch (BadLocationException e) { LanguageServerPlugin.logError(e.getMessage(), e); } } return new LSBasedHyperlink(locationLink, selectionRegion); }).collect(Collectors.toList())); } return allLinks; }
protected void addChildVisual(final EditPart childEditPart, final int index) { boolean visible = true; if (childEditPart instanceof InterfaceEditPart) { IInterfaceElement iElement = ((InterfaceEditPart) childEditPart).getModel(); if (iElement instanceof AdapterDeclaration) { visible = isVarVisible(); } } EditPart refEditPart = null; if (index < getChildren().size()) { refEditPart = (EditPart) getChildren().get(index); } if (childEditPart instanceof InterfaceEditPart) { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).getModel().isIsInput()) { if (((InterfaceEditPart) childEditPart).isEvent()) { insertChild(getLeftEventInterfaceContainer(), refEditPart, child); } else { if (visible) { insertChild(getLeftVarInterfaceContainer(), refEditPart, child); } } } } }
protected void removeChildVisual(final EditPart childEditPart) { boolean visible = true; if (childEditPart.getModel() instanceof AdapterDeclaration) { visible = isVarVisible(); } if (childEditPart instanceof InterfaceEditPart) { if (((InterfaceEditPart) childEditPart).getModel().isIsInput()) { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).isEvent()) { getLeftEventInterfaceContainer().remove(child); } else { if (visible) { getLeftVarInterfaceContainer().remove(child); } else { getLeftInterfaceContainer().remove(child); } } } else { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).isEvent()) { getRightEventInterfaceContainer().remove(child); } else { if (visible) { getRightVarInterfaceContainer().remove(child); } else { getRightInterfaceContainer().remove(child); } } } } else { super.removeChildVisual(childEditPart); } }
import org.eclipse.emf.ecore.EObject; import org.eclipse.emf.ecore.EStructuralFeature; import org.eclipse.emf.ecore.InternalEObject; import org.eclipse.emf.ecore.resource.Resource; import com.google.common.base.Objects; import java.util.HashMap; import java.util.Map; /** * An helper to check EObject equality.</br> * It extends and override EcoreUtil.EqualityHelper so that equals methods ignore EAttribute that are ID=true. * * @author mchauvin */ public final class EqualityHelper extends org.eclipse.emf.ecore.util.EcoreUtil.EqualityHelper { private static boolean enableUriFragmentCache = false; private static final Map<EObject, String> eUriFragmentCache = new HashMap<>(); private static final Map<EObject, EObject> eUriFragmentContainerCache = new HashMap<>(); private static final Map<EObject, EStructuralFeature> eUriFragmentContainingFeatureCache = new HashMap<>(); public static synchronized void setEnableUriFragmentCache(boolean enable) { enableUriFragmentCache = enable; if (!enable) { eUriFragmentCache.clear(); eUriFragmentContainerCache.clear(); eUriFragmentContainingFeatureCache.clear(); } } @Override protected boolean haveEqualAttribute(EObject eObject1, EObject eObject2, EAttribute attribute) { boolean isID = attribute.isID(); return isID || super.haveEqualAttribute(eObject1, eObject2, attribute); } }
public static boolean isInActivatedLayer(DiagramMappingsManager session, final DDiagramElement element, final DDiagram parentDiagram) { final DiagramElementMapping mapping = element.getDiagramElementMapping(); if (!LayerHelper.withoutLayersMode(mapping)) { final DDiagram diagram; if (parentDiagram != null) { diagram = parentDiagram; } else { diagram = element.getParentDiagram(); } if (diagram != null) { final Layer activeLayer = session.getActiveLayer(diagram); if (activeLayer != null) { return activeLayer.getActivatedMappings().contains(mapping); } } } return false; }
boolean reveal(EObject object, EStructuralFeature feature); RevealStep reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object,
/** * Attempt to reveal a {@code feature} of an {@code object} in the most appropriate * (by best effort) control within the given {@code scope}. * * @param object an object to reveal * @param feature a specific feature (implying a detail control) to reveal * @param scope a control within which to attempt to reveal the {@code object} * @return {@code true} if the {@code object} was revealed; {@code false}, otherwise */ RevealStep reveal(EObject object, EStructuralFeature feature, VElement scope); /** * Register a reveal provider. * * @param provider the reveal provider to register */ void addRevealProvider(EMFFormsRevealProvider provider); /** * Unregister a reveal provider. * * @param provider the reveal provider to unregister */ void removeRevealProvider(EMFFormsRevealProvider provider); }
public int getRed() { if (isDisposed()) { SWT.error(SWT.ERROR_GRAPHIC_DISPOSED); } // Convert the red value from double to short int r = (((int)(handle.red * 65535.0 + 0.5)) >> 8); return Math.min(r, 255); }
public int getRed() { if (isDisposed()) { SWT.error(SWT.ERROR_GRAPHIC_DISPOSED); } int r = (((int)(handle.red * 65535.0 + 0.5)) >> 8); return Math.min(r, 255); }
public class BucketUpdateResponseHandler extends SimpleChannelUpstreamHandler { private volatile boolean readingChunks; private String lastResponse; private ChannelFuture receivedFuture; private CountDownLatch latch; private StringBuilder partialResponse; private static final Logger LOGGER = Logger.getLogger(BucketUpdateResponseHandler.class.getName()); @Override public void messageReceived(final ChannelHandlerContext context, final MessageEvent event) { ChannelFuture channelFuture = event.getFuture(); setReceivedFuture(channelFuture); if (this.partialResponse == null) { this.partialResponse = new StringBuilder(); } if (readingChunks) { HttpChunk chunk = (HttpChunk) event.getMessage(); if (chunk.isLast()) { readingChunks = false; } else { String curChunk = chunk.getContent().toString("UTF-8"); if (curChunk.matches("\n\n\n\n")) { setLastResponse(partialResponse.toString()); partialResponse = null; getLatch().countDown(); if (monitor != null) { // do something } } } } } } private static final String PREFIX = "<entry gammaId=\""; private static final String POSTFIX = "\"/>\n"; private final Collection<Integer> gammaIds; public AttributeTaggingOperation(Collection<Integer> gammaIds) { super(AttributeTaggingOperation.class.getSimpleName(), Activator.PLUGIN_ID); this.gammaIds = gammaIds; } @Override protected void doWork(IProgressMonitor monitor) throws Exception { long start = System.currentTimeMillis(); StringBuilder response = new StringBuilder(); ByteArrayInputStream inputStream = null; try { Map<String, String> parameters = new HashMap<String, String>(); parameters.put("sessionId", ClientSessionManager.getSessionId()); if (DbUtil.isDbInit()) { parameters.put("wait", "true"); } StringBuilder payload = new StringBuilder(XML_START); for (int data : gammaIds) { payload.append(PREFIX); payload.append(data); payload.append(POSTFIX); } payload.append(XML_FINISH); // rest of the code } finally { // cleanup code } } public static List<Function> extractFunctions(String db, org.apache.hadoop.hive.metastore.api.Function function) throws ImpalaRuntimeException { List<Function> result = Lists.newArrayList(); boolean compatible = true; StringBuilder warnMessage = new StringBuilder(); if (function.get
public int compareTo(VdIcon other) { return mName.compareTo(other.mName); } registerMockResponse("GET /ccds/solution/10101010-1010-1010-1010-101010101010", MockResponse.success("mockCDSSolutionResponse.json")); registerMockResponse("GET /ccds/solution/10101010-1010-1010-1010-101010101010/revision", MockResponse.success("mockCDSSolutionRevisionsResponse.json")); registerMockResponse("GET /ccds/revision/a0a0a0a0-a0a0-a0a0-a0a0-a0a0a0a0a0a0/artifact", MockResponse.success("mockCDSSolutionRevisionArtifactsResponse.json")); registerMockResponse("GET /ccds/solution/f0f0f0f0-f0f0-f0f0-f0f0-f0f0f0f0f0f0", new MockResponse(400, "Error", "mockCDSNoEntryWithIDResponse.json")); StaticProfileTest.class, DynamicProfileTest.class, StaticStereotypeTest.class, StaticStereotypedElementChangeTests.class, DynamicStereotypeTest.class, DynamicStereotypedElementChangeTests.class, ImplicationsAssociationTest.class, ImplicationsTransitionTest.class, ImplicationsInterfaceRealizationTest.class, StaticStereotypedElementItemProviderTest.class, DynamicStereotypedElementItemProviderTest.class, OpaqueElementBodyChangeDiffTest.class, OpaqueElementBodyChangeMergeTest.class, DanglingStereotypeApplicationTest.class, TestNonRegPseudoConflict_484576.class, RemoveStereotypeApplicationPseudoConflictTest.class, MultiplicityElementChangesTest.class, InstanceSpecificationClassifiersMergeTest.class, AddMessageSubDiffTest.class, StereotypeApplicationConflictTests.class, public class AllTests { public static void main(String[] args) { TestRunner.run(suite()); } public static Test suite() { return new JUnit4TestAdapter(AllTests.class); } }
/***************************************************************************** * Copyright (c) 2014, 2017 Obeo and others. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Obeo - initial API and implementation * Christian W. Damus - bug 522080 ******************************************************************************/ package org.eclipse.emf.compare.uml2.internal.postprocessor; import java.util.Iterator; import java.util.Map; import org.eclipse.emf.common.util.Monitor; import org.eclipse.emf.common.util.URI; import org.eclipse.emf.compare.Comparison; import org.eclipse.emf.compare.ComparisonCanceledException; import org.eclipse.emf.compare.Diff; import org.eclipse.emf.compare.Match; import org.eclipse.emf.compare.diff.DefaultDiffEngine; import org.eclipse.emf.compare.diff.FeatureFilter; import org.eclipse.emf.compare.postprocessor.IPostProcessor; import org.eclipse.emf.compare.uml2.internal.postprocessor.extension.stereotype.UMLStereotypedElementChangeFactory;
static URI getStereotypeURI(EObject stereotypeApplication) { return EcoreUtil.getURI(stereotypeApplication.eClass()); }
public static <K, L, V> V put(Map<K, Map<L, V>> mapOfMaps, K key1, L key2, V value) { Map<L, V> map = mapOfMaps.get(key1); if (map == null) { map = Maps.newHashMap(); mapOfMaps.put(key1, map); } return map.put(key2, value); } protected boolean isStereotypeApplication(EObject object) { // implementation }
/***************************************************************************** * Copyright (c) 2010 Boeing. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Boeing - initial API and implementation *****************************************************************************/ package org.eclipse.ote.simple.oteide.product.load;  import java.io.IOException; import java.net.URL; import java.util.ArrayList; import java.util.List; import java.util.logging.Level;  import org.eclipse.osee.framework.jdk.core.util.Lib; import org.eclipse.osee.framework.logging.OseeLog; import org.eclipse.ote.services.core.BundleUtility; import org.eclipse.ote.services.core.LoadBundleProvider;  public class FileProvider implements LoadBundleProvider {  @Override public List<String> getBundleSymbolicNames() { List<String> names = new ArrayList<String>(); try { URL entry = BundleUtility.findEntry("org.eclipse.ote.simple.oteide.product.load", "data/precompiledServerBundleList.txt"); String fileContent = Lib.inputStreamToString(entry.openStream()); String[] strNames = fileContent.split("\n"); for(int i = 0; i < strNames.length; i++){ names.add(strNames[i].trim()); } } catch (IOException ex) { OseeLog.log(FileProvider.class, Level.SEVERE, ex); } return names; } }
import java.util.Dictionary; import java.util.logging.Level; import java.util.regex.Matcher; import java.util.regex.Pattern; import org.eclipse.core.runtime.Platform; import org.eclipse.core.runtime.preferences.IEclipsePreferences; import org.eclipse.core.runtime.preferences.InstanceScope; import org.eclipse.osee.framework.logging.OseeLog; import org.eclipse.ote.services.core.ServiceUtility; import org.eclipse.swt.widgets.Display; import org.eclipse.ui.IStartup; import org.osgi.framework.Bundle; import org.osgi.framework.BundleEvent; import org.osgi.framework.BundleListener; public class SetTitleBar implements IStartup { @Override public void earlyStartup() { String title = getTitle(); if (title != null) { setTitle(title); } else if (ServiceUtility.getContext() != null) { ServiceUtility.getContext().addBundleListener(new BundleListener() { @Override public void bundleChanged(BundleEvent event) { if (event.getType() == Bundle.ACTIVE) { if (event.getBundle().getSymbolicName().equals("bundle.to.base.off.here")) { String t = getTitle(); if (t != null) { setTitle(t); } } } } }); } } private String getTitle() { // TODO: Implement getTitle() method return null; } private void setTitle(String title) { // TODO: Implement setTitle() method } }
import java.io.File; import org.eclipse.core.resources.ResourcesPlugin; import org.eclipse.jface.action.Action; import org.eclipse.jface.action.IContributionItem; import org.eclipse.swt.program.Program; import org.eclipse.swt.widgets.Display; import org.eclipse.ui.IPartListener; import org.eclipse.ui.IViewPart; import org.eclipse.ui.IViewReference; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.IWorkbenchWindow; import org.eclipse.ui.PlatformUI; import org.eclipse.ui.part.ViewPart; import org.eclipse.ui.texteditor.StatusLineContributionItem; public class WorkspaceStatusLineContributionItem { private static String ID = "org.eclipse.ote.simple.oteide.product.load"; private String shortText; private StatusLineContributionItem item; private String path; public WorkspaceStatusLineContributionItem() { path = ResourcesPlugin.getWorkspace().getRoot().getLocation().toString(); shortText = getShortPath(path); item = new StatusLineContributionItem(ID, true, shortText.length()); } private static String getShortPath(String path) { // implementation goes here } }
private static String getUriFragment(EObject eObj) { if (eObj == null) { return null; } if (enableUriFragmentCache) { String cachedUriFragment = E_URI_FRAGMENT_CACHE.get(eObj); if (cachedUriFragment != null) { return cachedUriFragment; } } EObject container = eObj.eContainer(); EStructuralFeature eContainingFeature = eObj.eContainingFeature(); String uriFragment; if (container == null || eContainingFeature == null) { uriFragment = null; } else { uriFragment = container.eURIFragmentSegment(eContainingFeature, eObj); } if (enableUriFragmentCache) { E_URI_FRAGMENT_CACHE.put(eObj, uriFragment); } return uriFragment; } private static boolean sameType(EObject eObj1, EObject eObj2) { return eObj1 != null && eObj2 != null && eObj1.getClass() == eObj2.getClass(); } public static synchronized void setUriFragmentCacheEnabled(boolean enable) { enableUriFragmentCache = enable; if (!enable) { E_URI_FRAGMENT_CACHE.clear(); } } private static class Record { private final String uriFragment; private final EObject eContainer; private final EStructuralFeature containingFeature; Record(String uriFragment, EObject container, EStructuralFeature containingFeature) { this.uriFragment = uriFragment; this.eContainer = container; this.containingFeature = containingFeature; } }
@ApplicationScoped public class ApiDocGenerator { public static final String STATIC_RESOURCE_PARAM = "r"; protected static final String TEXT_ELEMENT_SEPARATOR = "\t"; protected static final String TEXT_LINE_SEPARATOR = "\n"; public List<ResourceDescriptor> getResourceDescriptors() { return BEANS.all(IRestResource.class).stream() .filter(this::acceptRestResource) .sorted(Comparator.comparing(res -> res.getClass().getSimpleName())) .sorted(Comparator.comparing(res -> "/" + getPath(res))) .map(this::toResourceDescriptor) .filter(Objects::nonNull) .collect(Collectors.toList()); } protected ResourceDescriptor toResourceDescriptor(IRestResource resource) { String resourcePath = "/" + getPath(resource); // rest of the code } }
public static class ResourceDescriptor { private IRestResource m_resource; private String m_path; private String m_basePath; // first segment of "path" private String m_name; private String m_anchor; private Function<Boolean, String> m_descriptionFunction; private List<MethodDescriptor> m_methods; public IRestResource getResource() { return m_resource; } public ResourceDescriptor withResource(IRestResource resource) { m_resource = resource; return this; } public String getPath() { return m_path; } public ResourceDescriptor withPath(String path) { m_path = path; return this; } public String getBasePath() { return m_basePath; } public ResourceDescriptor withBasePath(String basePath) { m_basePath = basePath; return this; } public String getDescription(boolean asHtml) { return m_descriptionFunction.apply(asHtml); } public ResourceDescriptor withDescription(Function<Boolean, String> descriptionFunction) { m_descriptionFunction = descriptionFunction; return this; } public List<MethodDescriptor> getMethods() { return m_methods; } public ResourceDescriptor withMethods(List<MethodDescriptor> methods) { m_methods = methods; return this; } } // Usage example: ResourceDescriptor descriptor = new ResourceDescriptor() .withResource(resource) .withPath(path) .withBasePath(basePath) .withDescription(asHtml -> asHtml ? m_descriptionHtml : m_descriptionText) .withMethods(methods);
import org.eclipse.scout.rt.shared.AbstractIcons; import org.eclipse.scout.rt.shared.data.basic.FontSpec; import org.eclipse.scout.rt.shared.services.lookup.ILookupCall; import org.eclipse.scout.rt.shared.services.lookup.ILookupRow; import org.eclipse.scout.rt.shared.services.lookup.LocalLookupCall; import org.eclipse.scout.rt.shared.services.lookup.LookupRow; @ClassId("c6ee18fd-e630-4d92-81b1-cd0147c902d4") public class DefaultTileTableHeaderBox extends AbstractGroupBox implements ITileTableHeaderBox { private TableListener m_tableListener; private boolean m_isGrouping; private boolean m_isSorting; protected TableListener createTableListener() { return new TableAdapter() { @Override public void tableChanged(TableEvent e) { handleTableEvent(e); } }; } protected void handleTableEvent(TableEvent e) { switch (e.getType()) { case TableEvent.TYPE_COLUMN_HEADERS_UPDATED: syncSortingGroupingFields(); break; } } protected void syncSortingGroupingFields() { try { // don't call execChangedValue since it would trigger sort/group again getSortByField().setValueChangeTriggerEnabled(false); // TODO: Add implementation for syncSortingGroupingFields } finally { getSortByField().setValueChangeTriggerEnabled(true); } } }
protected void execChangedValue() { try { m_isGrouping = true; if (getValue() == null) { getTable().getColumnSet().removeGroupColumn(CollectionUtility.firstElement(getTable().getColumnSet().getGroupedColumns())); } else { getTable().getColumnSet().handleGroupingEvent(getValue(), false, true); } ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); } finally { m_isGrouping = false; } }
protected void execChangedValue() { try { m_isSorting = true; if (getValue() == null) { getTable().getColumnSet().removeSortColumn(CollectionUtility.firstElement(getTable().getColumnSet().getSortColumns())); ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); } else { getTable().getColumnSet().handleSortEvent(getValue().getLeft(), false, getValue().getRight()); ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); } } finally { m_isSorting = false; } }
package org.eclipse.scout.rt.rest.error; import javax.ws.rs.core.MediaType; import javax.ws.rs.core.Response; import javax.ws.rs.core.Response.Status; import org.eclipse.scout.rt.platform.BEANS; import org.eclipse.scout.rt.platform.Bean; import org.eclipse.scout.rt.platform.context.CorrelationId; /** * Builder for {@link ErrorDo} and {@link ErrorResponse} objects. */ @Bean public class ErrorResponseBuilder { private int m_httpStatus; private String m_code; private String m_title; private String m_message; public ErrorResponseBuilder withStatus(int httpStatus) { m_httpStatus = httpStatus; return this; } public ErrorResponseBuilder withStatus(Status status) { m_httpStatus = status.getStatusCode(); return this; } public ErrorResponseBuilder withTitle(String title) { m_title = title; return this; } public ErrorResponseBuilder withMessage(String message) { m_message = message; return this; } public ErrorResponseBuilder withCode(int code) { m_code = code; return this; } public ErrorResponseBuilder withCode(String code) { m_code = code; return this; } public ErrorResponseBuilder withCode(Enum<?> code) { m_code = code.name(); return this; } public ErrorResponseBuilder withCode(Enum<?> code, String prefix) { m_code = prefix + code.name(); return this; } public ErrorResponseBuilder withCode(Enum<?> code, Class<?> prefixClass) { m_code = prefixClass.getSimpleName() + "." + code.name(); return this; } public ErrorResponseBuilder withCode(Enum<?> code, Class<?> prefixClass, String prefix) { m_code = prefixClass.getSimpleName() + "." + prefix + code.name(); return this; } public ErrorResponseBuilder withCode(Enum<?> code, String prefix, String suffix) { m_code = prefix + code.name() + suffix; return this; } public ErrorResponseBuilder withCode(Enum<?> code, Class<?> prefixClass, String prefix, String suffix) { m_code = prefixClass.getSimpleName() + "." + prefix + code.name() + suffix; return this; } public ErrorResponseBuilder withCode(Enum<?> code, String prefix, Class<?> suffixClass) { m_code = prefix + code.name() + "." + suffixClass.getSimpleName(); return this;
/******************************************************************************/ package org.eclipse.scout.rt.rest.error; import javax.ws.rs.core.MediaType; import javax.ws.rs.core.Response; import javax.ws.rs.core.Response.Status; import org.eclipse.scout.rt.platform.BEANS; import org.eclipse.scout.rt.platform.Bean; import org.eclipse.scout.rt.platform.context.CorrelationId; /** * Builder for {@link ErrorDo} and {@link ErrorResponse} objects. */ @Bean public class ErrorResponseBuilder { private int m_status; private String m_errorCode; private String m_title; private String m_message; public ErrorResponseBuilder withStatus(int status) { m_status = status; return this; } public ErrorResponseBuilder withStatus(Status status) { m_status = status.getStatusCode(); return this; } public ErrorResponseBuilder withTitle(String title) { m_title = title; return this; } public ErrorResponseBuilder withMessage(String message) { m_message = message; return this; } public ErrorResponseBuilder withCode(int code) { m_errorCode = String.valueOf(code); return this; } }
public ErrorResponseBuilder withHttpStatus(int status) { m_status = status; return this; }
public ErrorResponseBuilder withErrorCode(int code) { m_code = String.valueOf(code); return this; }
public ErrorResponseBuilder withErrorCode(String errorCode) { m_code = errorCode; return this; }
import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.jface.window.Window; import org.eclipse.ltk.ui.refactoring.RefactoringWizardOpenOperation; import org.eclipse.swt.widgets.Shell; import org.eclipse.ui.handlers.HandlerUtil; import org.eclipse.core.commands.AbstractHandler; import org.eclipse.core.commands.ExecutionEvent; import org.eclipse.core.commands.ExecutionException; import org.eclipse.core.resources.IResource; import org.eclipse.jface.dialogs.MessageDialog; import org.eclipse.jface.wizard.WizardDialog; import org.eclipse.ltk.core.refactoring.RefactoringStatus; import org.eclipse.ltk.ui.refactoring.RefactoringUIPlugin; import org.eclipse.ltk.ui.refactoring.resource.RenameResourceWizard; import org.eclipse.ui.PlatformUI; public class RenameResourceHandler extends AbstractHandler { @Override public Object execute(ExecutionEvent event) throws ExecutionException { Shell activeShell = HandlerUtil.getActiveShell(event); IStructuredSelection selection = (IStructuredSelection) HandlerUtil.getCurrentSelection(event); if (selection != null && !selection.isEmpty()) { IResource resource = (IResource) selection.getFirstElement(); if (resource != null) { RenameResourceWizard wizard = new RenameResourceWizard(resource); WizardDialog dialog = new WizardDialog(activeShell, wizard); if (dialog.open() == Window.OK) { return null; } } } return null; } }
protected void addUserInputPages() { RenameResourceProcessor processor = getRefactoring().getAdapter(RenameResourceProcessor.class); RenameResourceRefactoringConfigurationPage page = new RenameResourceRefactoringConfigurationPage(processor); addPage(page); }
@Override public Object execute(ExecutionEvent event) throws ExecutionException { Shell activeShell = HandlerUtil.getActiveShell(event); Object newNameValue = HandlerUtil.getVariable(event, LTK_RENAME_COMMAND_NEWNAME_PARAMETER_KEY); String newName = null; if (newNameValue instanceof String) { newName = (String) newNameValue; } else if (newNameValue != null) { RefactoringUIPlugin.logErrorMessage(RefactoringUIMessages.RenameResourceHandler_ERROR_EXPECTED_STRING + newNameValue.getClass().getName()); } ISelection sel = HandlerUtil.getCurrentSelection(event); if (sel instanceof IStructuredSelection) { IResource resource = getCurrentResource((IStructuredSelection) sel); if (resource != null) { RenameResourceWizard refactoringWizard; if (newName != null) { refactoringWizard = new RenameResourceWizard(resource, newName); } else { refactoringWizard = new RenameResourceWizard(resource); } RefactoringWizardOpenOperation op = new RefactoringWizardOpenOperation(refactoringWizard); try { op.run(activeShell, RefactoringUIMessages.RenameResourceHandler_title); } catch (InterruptedException e) { // do nothing } } } return null; }
private static List<String> convert(Collection<StyleWrapper> themesRaw) { List<String> themes = new ArrayList<String>(themesRaw.size()); for (StyleWrapper theme : themesRaw) { themes.add(theme.getName()); } Collections.sort(themes); return themes; } private static final String PENDING_REVIEWER_FIELD = ChangeField.PENDING_REVIEWER.getName(); private static final String PENDING_REVIEWER_BY_EMAIL_FIELD = ChangeField.PENDING_REVIEWER_BY_EMAIL.getName(); private static final String REF_STATE_FIELD = ChangeField.REF_STATE.getName(); private static final String REF_STATE_PATTERN_FIELD = ChangeField.REF_STATE_PATTERN.getName(); private static final String REVIEWEDBY_FIELD = ChangeField.REVIEWEDBY.getName(); private static final String REVIEWER_FIELD = ChangeField.REVIEWER.getName(); private static final String REVIEWER_BY_EMAIL_FIELD = ChangeField.REVIEWER_BY_EMAIL.getName(); private static final String HASHTAG_FIELD = ChangeField.HASHTAG_CASE_AWARE.getName(); private static final String STAR_FIELD = ChangeField.STAR.getName(); private static final String SUBMIT_RECORD_LENIENT_FIELD = ChangeField.STORED_SUBMIT_RECORD_LENIENT.getName(); private static final String SUBMIT_RECORD_STRICT_FIELD = ChangeField.STORED_SUBMIT_RECORD_STRICT.getName(); private static final String UNRESOLVED_COMMENT_COUNT_FIELD = ChangeField.UNRESOLVED_COMMENT_COUNT.getName(); private ISubject stockMarketSubject; Market market; Map<String, List<Double>> history; public MarketHistory(Market market) { super(); this.market = market; history = new HashMap<String, List<Double>>(); } @Override public void setSubject(ISubject priceSetter) { this.stockMarketSubject = priceSetter; } public void startHistoryWithPrice(String symbol, Double newPrice) throws StockMarketExpection { if (!history.containsKey(symbol)) { List<Double> priceList = new ArrayList<Double>(); priceList.add(newPrice); history.put(symbol, priceList); } } @Override public void update() { Stock updatedStock = (Stock) stockMarketSubject.getUpdate(); if (market.getStockForSymbol(updatedStock.getSymbol()) == null) { return; } } private class CellModifier implements ICellModifier { @Override public boolean canModify(final Object element, final String property) { return (VALUE_PROPERTY.equals(property) || COMMENT_PROPERTY.equals(property)); } @Override
import org.eclipse.fordiac.ide.model.commands.change.ChangeCommentCommand; import org.eclipse.fordiac.ide.model.commands.change.ChangeNameCommand; import org.eclipse.fordiac.ide.model.libraryElement.Device; import org.eclipse.gef.EditPart; import org.eclipse.swt.SWT; import org.eclipse.swt.events.SelectionAdapter; import org.eclipse.swt.events.SelectionEvent; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.layout.GridLayout; import org.eclipse.swt.widgets.Button; import org.eclipse.swt.widgets.Combo; import org.eclipse.swt.widgets.Composite; public class DeviceSection extends AbstractDevResInterfaceSection { protected static String[] profileNames = null; protected Combo profile; protected Button getResources; @Override public void refresh() { super.refresh(); if (null != type) { setProfile(); getResources.setEnabled("DynamicTypeLoad".equals(((Device) getType()).getProfile())); } } private void setProfile() { int i = 0; for (String p : profile.getItems()) { if (p.equals(((Device) getType()).getProfile())) { profile.select(i); break; } i++; } } }
teamArt.getAtsId()); // Confirm that all blocking reviews are completed // Loop through this state's blocking reviews to confirm complete if (teamArt.isTeamWorkflow()) { for (IAtsAbstractReview review : ReviewManager.getReviewsFromCurrentState(teamArt)) { AbstractReviewArtifact reviewArt = (AbstractReviewArtifact) AtsClientService.get().getQueryService().getArtifact(review); if (reviewArt.getReviewBlockType() == ReviewBlockType.Commit && !reviewArt.isCompletedOrCancelled()) { AWorkbench.popup("Committing Branch Error!", "All blocking reviews must be completed before committing a new branch. Please complete all blocking reviews in order to continue."); return; } } } if (!overrideStateValidation) { final MutableBoolean adminOverride = new MutableBoolean(false); // Check extension points for valid commit for (IAtsStateItem item : AtsStateItemManager.getStateItems()) { final Result tempResult = item.committing(teamArt); if (tempResult.isFalse()) { // Allow Admin to override state validation if (isAdmin()) { adminOverride.setTrue(); } else { AWorkbench.popup("Committing Branch Error!", "The branch cannot be committed due to state validation rules. Please contact an administrator for assistance."); return; } } } if (adminOverride.isFalse()) { AWorkbench.popup("Committing Branch Error!", "The branch cannot be committed due to state validation rules. Please contact an administrator for assistance."); return; } }
null); @Override public String getMarkingTag() { return ManagedEntityArtifact.MARKING_TAG; } @Override public IAbstractArtifactInternal getModel() { return MODEL; } public String getLabel() { return getMetadata().getLabel(this); } public ManagedEntityArtifact(ArtifactManager artifactMgr) { super(artifactMgr); setIStandardSpecifics(new OssjEntitySpecifics(this)); } @Override public IAbstractArtifactInternal extractFromClass(JavaClass javaClass, ArtifactManager artifactMgr, IProgressMonitor monitor) { ManagedEntityArtifact result = new ManagedEntityArtifact(javaClass, artifactMgr, monitor); return result; } public ManagedEntityArtifact(JavaClass javaClass, ArtifactManager artifactMgr, IProgressMonitor monitor) { super(javaClass, artifactMgr, monitor); OssjEntitySpecifics specifics = new OssjEntitySpecifics(this); specifics.build(); setIStandardSpecifics(specifics); }
} else if (OS.RegOpenKeyEx(OS.HKEY_LOCAL_MACHINE, key, 0, OS.KEY_READ, phkResult) == 0) { // Try reading from HKLM regKeyFound = true; } if (regKeyFound) { int[] lpcbData = new int[1]; TCHAR buffer = new TCHAR(0, "AppsUseLightTheme", true); //$NON-NLS-1$ int result = OS.RegQueryValueEx(phkResult[0], buffer, 0, null, (TCHAR) null, lpcbData); if (result == 0) { int[] lpData = new int[1]; result = OS.RegQueryValueEx(phkResult[0], buffer, 0, null, lpData, lpcbData); if (result == 0) { isDarkTheme = (lpData[0] == 0); } } OS.RegCloseKey(phkResult[0]); } return isDarkTheme;
public abstract class AnyObjectId implements Comparable<AnyObjectId> { /** * Compare two object identifier byte sequences for equality. * * @param firstObjectId the first identifier to compare. Must not be null. * @param secondObjectId the second identifier to compare. Must not be null. * @return true if the two identifiers are the same. */ @Deprecated @SuppressWarnings("AmbiguousMethodReference") public static boolean equals(final AnyObjectId firstObjectId, final AnyObjectId secondObjectId) { if (firstObjectId == secondObjectId) return true; // We test word 3 first since the git file-based ODB // uses the first byte of w1, and we use w2 as the // hash code, one of those probably came up with these // two instances which we are comparing for equality. // Therefore the first two words are very likely to be // the same, and the third word is very likely different. return firstObjectId.w3 == secondObjectId.w3 && firstObjectId.w2 == secondObjectId.w2 && firstObjectId.w1 == secondObjectId.w1; } }
handleMiddleClick(event); }); private void handleMiddleClick(MouseEvent event) throws CoreException { if (event.button == 2 && event.widget instanceof Tree) { TreeItem item = ((Tree) event.widget).getItem(new Point(event.x, event.y)); if (item == null) { return; } Object data = item.getData(); if (data instanceof IProject) { IProject project = (IProject) data; if (project.isOpen()) { project.close(new NullProgressMonitor()); } } } }
} @Override public boolean isHidden(File path) throws IOException { return FileUtil.isHidden(path); } @Override public void setHidden(File path, boolean hidden) throws IOException { FileUtil.setHidden(path, hidden); } @Override public String readSymLink(File path) throws IOException { return FileUtil.readSymlink(path); } @Override public void createSymLink(File path, String target) throws IOException { FileUtil.createSymLink(path, target); } @Override public Attributes getAttributes(File path) { return FileUtil.getFileAttributesBasic(this, path); } }
RebaseTodoLine line = null; String commentString = RawParseUtils.decode(buf, tokenBegin, lineEnd + 1); try { int skip = tokenBegin + 1; // skip '#' skip = nextParsableToken(buf, skip, lineEnd); if (skip != -1) { line = parseLine(buf, skip, lineEnd); if (line != null) { line.setAction(Action.COMMENT); line.setComment(commentString); } } } catch (Exception e) { line = null; } finally { if (line == null) { line = new RebaseTodoLine(commentString); } r.add(line); }
package edu.wpi.cs.wpisuitetng.modules.taskmanager.model; import java.util.List; import edu.wpi.cs.wpisuitetng.Session; import edu.wpi.cs.wpisuitetng.database.Data; import edu.wpi.cs.wpisuitetng.exceptions.BadRequestException; import edu.wpi.cs.wpisuitetng.exceptions.ConflictException; import edu.wpi.cs.wpisuitetng.exceptions.NotFoundException; import edu.wpi.cs.wpisuitetng.exceptions.NotImplementedException; import edu.wpi.cs.wpisuitetng.exceptions.WPISuiteException; import edu.wpi.cs.wpisuitetng.modules.EntityManager; import edu.wpi.cs.wpisuitetng.modules.Model; public class ActivityEntityManager implements EntityManager<ActivityModel> { private Data db; /** * Constructs the entity manager. This constructor is called by * {@link edu.wpi.cs.wpisuitetng.ManagerLayer#ManagerLayer()}. To make sure * this happens, be sure to place add this entity manager to the map in the * ManagerLayer file. * * @param db a reference to the persistent database */ }
private void addPatterns(String... searchStrings) { if (searchStrings == null) { return; } for (String searchString : searchStrings) { if (searchString == null || searchString.isEmpty()) { continue; } Node node = root; for (char c : searchString.toCharArray()) { node = node.add(c); } node.match = searchString; } }
public class MultiStringMatcher { public static interface Match { String getText(); int getOffset(); } }
public Match indexOf(String text, int offset) { if (strings.isEmpty()) { throw new IllegalStateException("No strings to search for have been added to this matcher"); } List<Match> matches = find(text, offset, true); if (matches.isEmpty()) { return null; } // Find the leftmost longest match Iterator<Match> iterator = matches.iterator(); Match result = iterator.next(); while (iterator.hasNext()) { Match candidate = iterator.next(); int comparison = Integer.compare(candidate.getOffset(), result.getOffset()); if (comparison < 0) { result = candidate; } } return result; }
// we have a full match. Standard Aho-Corasick would take the fail link on // the next character, which may or may not take us to root, and keep on // looking for more matches. We stop instead if we are looking only for the // first match. Note that we _do_ have a match at least from this node itself, // since terminal nodes in the trie always match, and it is by definition // also the longest match. matches.add(new MatchResult(node.match, i - node.match.length() + 1)); break; if (node.match != null) { matches.add(new MatchResult(node.match, i - node.match.length() + 1)); } if (!firstOnly || matches.isEmpty()) { Node out = node.output; while (out != null) { matches.add(new MatchResult(out.match, i - out.match.length() + 1)); out = out.output; } } return matches;
@Test public void noStrings003() throws Exception { thrown.expect(IllegalStateException.class); MultiStringMatcher.builder().add((String[]) null).build(); } @Test public void fluent001() throws Exception { MultiStringMatcher m = MultiStringMatcher.builder().add("he", "she", "his", "hers").build(); test(m.indexOf("ushers", 0), "she", 1); } @Test public void fluent002() throws Exception { MultiStringMatcher m = MultiStringMatcher.builder().add("he", "she").add("his", "hers").build(); testList(m.find("ushers", 0), "[[she, 1], [he, 2], [hers, 2]]"); }
public Match indexOf(String text, int offset) { List<Match> matches = find(text, offset, true); if (matches.isEmpty()) { return null; } // Find the leftmost longest match. Match result = matches.get(0); for (int i = 1; i < matches.size(); i++) { Match cand = matches.get(i); if (cand.getOffset() > result.getOffset()) { // Results are ordered by offset. There will be no leftmost match as all we checked. break; } if (cand.getText().length() > result.getText().length()) { result = cand; } } return result; }
package org.eclipse.tycho.pomless; import java.io.File; import java.io.FileFilter; import java.io.IOException; import org.apache.maven.model.Model; import org.apache.maven.model.io.ModelParseException; import org.codehaus.plexus.component.annotations.Component; import org.sonatype.maven.polyglot.mapping.Mapping; import org.w3c.dom.Element; @Component(role = Mapping.class, hint = "eclipse-target-definition") public class TychoTargetMapping extends AbstractXMLTychoMapping { private static final String TARGET_EXTENSION = ".target"; public static final String ROLE = "eclipse-target-definition"; @Override public String getFlavour() { return ROLE; } @Override protected boolean isValidLocation(String location) { return location.endsWith(TARGET_EXTENSION); } @Override protected File getPrimaryArtifact(File dir) { File file = new File(dir, dir.getName() + TARGET_EXTENSION); if (file.exists()) { return file; } File[] listFiles = dir.listFiles(new FileFilter() { @Override public boolean accept(File file) { return file.getName().endsWith(TARGET_EXTENSION); } }); if (listFiles != null && listFiles.length > 0) { return listFiles[0]; } return null; } @Override protected Model parseModel(File file) throws IOException, ModelParseException { return super.parseModel(file); } @Override protected void writeModel(Model model, Element root) { super.writeModel(model, root); } }
@Override public void checkPermission(Permission requested) { for (Permission permission : permissions) { if (permission.implies(requested)) { return; } } super.checkPermission(requested); } @After public void tearDown() throws Exception { System.setSecurityManager(originalSecurityManager); FileUtils.delete(root, FileUtils.RECURSIVE); } @Test public void testInitAndClone() throws IOException, GitAPIException { File remote = new File(root, "remote"); File local = new File(root, "local"); try (Git git = Git.init().setDirectory(remote).call()) { JGitTestUtil.write(new File(remote, "hello.txt"), "Hello world!"); git.add().addFilepattern(".").call(); git.commit().setMessage("Initial commit").call(); } }
protected static File searchPath(String path, String... lookFor) { if (path == null) return null; for (String p : path.split(File.pathSeparator)) { for (String command : lookFor) { final File file = new File(p, command); try { if (file.isFile()) { return file.getAbsoluteFile(); } } catch (SecurityException e) { LOG.warn(JGitText.get().pathNotAccessibleSkipIt(file.getPath())); } } } return null; }
protected Control createDialogArea(Composite parent) { Composite main = new Composite(parent, SWT.NONE); GridLayoutFactory.fillDefaults().numColumns(2).applyTo(main); GridDataFactory.fillDefaults().grab(true, false).indent(5, 5).applyTo(main); Label branchLabel = new Label(main, SWT.NONE); branchLabel.setText(UIText.BranchConfigurationDialog_UpstreamBranchLabel); branchText = new Combo(main, SWT.BORDER); GridDataFactory.fillDefaults().grab(true, false).applyTo(branchText); try { for (Ref ref : myRepository.getRefDatabase().getRefs(Constants.R_HEADS).values()) { branchText.add(ref.getName()); } for (Ref ref : myRepository.getRefDatabase().getRefs(Constants.R_REMOTES).values()) { branchText.add(ref.getName()); } } catch (IOException e) { Activator.logError("Exception getting Refs", e); } Label remoteLabel = new Label(main, SWT.NONE); remoteLabel.setText("Rem&ote:"); // TODO } public void createControl(Composite parent) { Composite container = new Composite(parent, SWT.NULL); GridLayout layout = new GridLayout(); container.setLayout(layout); layout.numColumns = 3; layout.verticalSpacing = 9; Label label = new Label(container, SWT.NULL); label.setText(Messages.getString("StapNewWizardPage.ScriptName")); //$NON-NLS-1$ fileText = new Text(container, SWT.BORDER | SWT.SINGLE); GridData gd = new GridData(GridData.FILL_HORIZONTAL); fileText.setLayoutData(gd); fileText.addModifyListener(new ModifyListener() { public void modifyText(ModifyEvent e) { dialogChanged(); } }); label = new Label(container, SWT.NULL); // XXX just create a new layout with different width label = new Label(container, SWT.NULL); label.setText("&Directory:"); containerText = new Text(container, SWT.BORDER | SWT.SINGLE); gd = new GridData(GridData.FILL_HORIZONTAL); containerText.setLayoutData(gd); containerText.addModifyListener(new ModifyListener() { public void modifyText(ModifyEvent e) { dialogChanged(); } }); } public void refreshTraceType() { try { fTraceTypeId = getResource().getPersistentProperty
@Override public void synchronize(final IProject project, RemoteLocation rl, IResourceDelta delta, IProgressMonitor monitor, Set<SyncFlag> syncFlags) throws CoreException { if (project == null || rl == null) { throw new NullPointerException(); } if (project != null && delta != null && project.getFile(gitDir).getFullPath().isPrefixOf(delta.getFullPath())) { return; } RemoteLocation remoteLoc = new RemoteLocation(rl); ProjectAndRemoteLocationPair syncTarget = new ProjectAndRemoteLocationPair(project, remoteLoc); if(syncFlags.contains(SyncFlag.WAIT_FOR_LR)) { try { SyncInt si = syncLRPending.get(syncTarget); // ... } catch (InterruptedException e) { // ... } } // ... }
@Override public void synchronize(final IProject project, RemoteLocation rl, IResourceDelta delta, IProgressMonitor monitor, Set<SyncFlag> syncFlags) throws CoreException { if (project == null || rl == null) { throw new NullPointerException(); } if (project != null && delta != null && project.getFile(gitDir).getFullPath().isPrefixOf(delta.getFullPath())) { return; // ignore deltas prefixed by gitDir } RemoteLocation remoteLoc = new RemoteLocation(rl); ProjectAndRemoteLocationPair syncTarget = new ProjectAndRemoteLocationPair(project, remoteLoc); if(syncFlags.contains(SyncFlag.WAIT_FOR_LR)) { try { SyncInt si = syncLRPending.get(syncTarget); if (si != null) { si.waitForZero(); } } catch (InterruptedException e) { Activator.log(e); } return; } }
public void paste() { checkWidget(); if ((style & SWT.READ_ONLY) != 0) return; OS.SendMessage(handle, OS.WM_PASTE, 0, 0); } void stateFlagsAdd(int flags) { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); if (tagCBoxPtr == 0) return; final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); stateFlags[0] |= flags; OS.MoveMemory(stateFlagsPtr, stateFlags, 4); }
private boolean stateFlagsTest() { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); if (tagCBoxPtr == 0) { return false; } final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); return (stateFlags[0] == 0x02006002); }
boolean stateFlagsTest() { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); if (tagCBoxPtr != 0) { final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); return (stateFlags[0] == 0x02006002); } return false; } @Override void register() { // Bug 550423: When non-XP-theme COMMCTL32.DLL gets loaded, undocumented internal data is not there. We do not support that. }
protected void execute() { MetroOrchestrationService ceManager = get(MetroOrchestrationService.class); argEvcConnIdList.forEach(id -> { EvcConnId evcId = EvcConnId.of(id); if (ceManager.evcMap.containsKey(evcId)) { ceManager.removeEvc(evcId); print("Removed EVC %s", evcId.toString()); } else { print("EVC %s doesn't exist", evcId.toString()); } }); } if (Predicate.isEquivalencePredicate(e)) { BinaryPredicate bp = ((BinaryPredicate) e); if (bp.isSingleColumnPredicate(slotRef, null)) { columnNames.add(slotRef.getRef().getDesc().getColumn().getName()); } else { ignore = true; logExpr = e; break; } } else if (e instanceof IsNullPredicate) { IsNullPredicate nullPredicate = (IsNullPredicate) e; Column partColumn = nullPredicate.getBoundSlot().getDesc().getColumn(); Preconditions.checkState(clusterColumns.contains(partColumn)); partColNames.add(partColumn.getName()); } else { ignore = true; logExpr = e; break; } if (ignore) { partitionShouldExist_ = null; LOG.info(String.format("Ignoring IF EXISTS since there are more general partition expr %s.", logExpr)); } else if (columnNames.size() < table.getMetaStoreTable().getPartitionKeysSize()) { partitionShouldExist_ = null; } if (length == OS.CB_ERR) { int count = (int)/*64*/OS.SendMessage(handle, OS.CB_GETCOUNT, 0, 0); if (0 <= index && index < count) { error(SWT.ERROR_ITEM_NOT_REMOVED); } error(SWT.ERROR_INVALID_RANGE); } buffer = new TCHAR(getCodePage(), length + 1); int result = (int)/*64*/OS.SendMessage(handle, OS.CB_GETLBTEXT, index, buffer); if (result == OS.CB_ERR) { int count = (int)/*64*/OS.SendMessage(handle, OS.CB_GETCOUNT, 0, 0); if (0 <= index && index < count) { error(SWT.ERROR_ITEM_NOT_REMOVED); } error(SWT.ERROR_INVALID_RANGE);
private static final String pageName = "Scripts"; private ToolItem abortButton; private ToolItem abortBatchButton; private CoolBar coolBar; private ToolItem deleteButton; private Label hostConnectLabel; private LoadWidget loadWidget; protected ToolItem runButton; private SaveWidget saveWidget; private ScriptTableViewer scriptTable; private StatusWindowWidget statusWindow; private final TestManagerEditor testManagerEditor; private ProgramButtonProviderService programButtonProviderService; public ScriptPage(Composite parent, int style, TestManagerEditor parentTestManager) { super(parent, style, parentTestManager); this.testManagerEditor = parentTestManager; } public void addFile(String fullPath) { scriptTable.addFile(fullPath); } @Override public void createPage() { super.createPage(); Composite parent = (Composite) getContent(); coolBar = new CoolBar(parent, SWT.FLAT); createControlsToolBar(coolBar); createConfigurationToolBar(coolBar); packCoolBar(); }
} // Example: As above, but to be moved to the appropriate class/location. ILibraryLinkerProviderService libraryLinkerProviderService = OsgiUtil.getService(ILibraryLinkerProvider.class, LibraryLinkerProviderService.class); for (ILibraryLinkerProvider provider : libraryLinkerProviderService.getLibraryLinkerProviders()) { provider.getLibraryLinkers(); } // Example: As above, but to be moved to the appropriate class/location. ILaunchAndKillProviderService launchAndKillProviderService = OsgiUtil.getService(ILaunchAndKillProvider.class, LaunchAndKillProviderService.class); // @formatter:off // Example to launch and kill processes: for (ILaunchAndKillProvider provider : launchAndKillProviderService.getLaunchAndKillProviders()) { Collection<ILaunchAndKill> launchers = provider.getLaunchers(); Collection<ILaunchAndKill> killers = provider.getKillers(); for (ILaunchAndKill launcher : launchers) { Process launchProcess; // To access Process methods //launchProcess = launcher.executeProcess(); // Launches the process break; } for (ILaunchAndKill killer : killers) { Process killProcess; // To access Process methods
if (selection.getFirstElement() instanceof Table) { this.exportedTable = (Table) selection.getFirstElement(); } else if (selection instanceof TableStructuredSelection) { final TableStructuredSelection tss = (TableStructuredSelection) selection; final INattableModelManager tableModelManager = (INattableModelManager) tss.getAdapter(INattableModelManager.class); if (null != tableModelManager) { this.exportedTable = tableModelManager.getTable(); } } Assert.isNotNull(this.exportedTable, "We can't found the table to export"); //$NON-NLS-1$ IStatus status = TableChecker.checkTable(this.exportedTable); if (false == status.isOK()) { addPage(new WarningOnCurrentTableWizardPage(status)); } this.outputPage = new DefineOutputPluginWizardPage(); this.tableDataPage = new DefineTableConfigurationDataWizardPage(); this.outputPage.setExportedTable(this.exportedTable); this.tableDataPage.setExportedTable(this.exportedTable); addPage(outputPage); addPage(tableDataPage);
if (field != null) { return new JDIFieldVariable(debugTarget, field, getUnderlyingObject(), fLogicalParent); } // Check possible references of variables defined in outer class for (Field outer : synteticFields) { // retrieve the reference to the "outer" object JDIFieldVariable syntVariable = new JDIFieldVariable(debugTarget, outer, getUnderlyingObject(), fLogicalParent); IValue value = syntVariable.getValue(); if (value instanceof JDIObjectValue) { JDIObjectValue outerObject = (JDIObjectValue) value; if (outerObject != null) { // ask "outer" object about field probably declared within return outerObject.getField(name, outer.signature()); } } } } catch (RuntimeException e) { targetRequestFailed( MessageFormat.format(JDIDebugModelMessages.JDIObjectValue_exception_retrieving_field, e.toString()), e); } // it is possible to return null return null; } static List<ReferenceType> superTypes(ReferenceType type) { List<ReferenceType> superTypes = new ArrayList<>(); ReferenceType t = type;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.Routing; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.RoutingBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class InterfaceRoutingCustomizerTest extends WriterCustomizerTest { private static final String IFACE_CTX_NAME = "interface-ctx"; private static final String IF_NAME = "eth1"; private static final int IF_INDEX = 1; private static final InstanceIdentifier<Routing> IID = InstanceIdentifier.create(Interfaces.class) .child(Interface.class, new InterfaceKey(IF_NAME)) .augmentation(VppInterfaceAugmentation.class) .child(Routing.class); private InterfaceRoutingCustomizer customizer; @Override protected void setUpTest() throws Exception { customizer = new InterfaceRoutingCustomizer(api, new NamingContext("ifacePrefix", IFACE_CTX_NAME)); } }
import java.util.Collections; import java.util.Set; import org.junit.Test; import org.mockito.ArgumentCaptor; import org.mockito.Captor; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.Interfaces; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.interfaces.Interface; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.interfaces.InterfaceKey; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.SubinterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.SubInterfaces; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.sub.interfaces.SubInterface; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.sub.interfaces.SubInterfaceBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VxlanVni; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.Vxlan; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.VxlanBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class VxlanCustomizerTest extends WriterCustomizerTest implements AddressTranslator { private static final byte ADD_VXLAN = 1; private static final byte DEL_VXLAN = 0; @Mock private DisabledInterfacesManager disableContext; private VxlanCustomizer customizer; private String ifaceName; private InstanceIdentifier<Vxlan> id; private static Vxlan generateVxlan(long vni) { final VxlanBuilder builder = new VxlanBuilder(); builder.setSrc(new IpAddressNoZone(new Ipv4AddressNoZone("192.168.20.10"))); // rest of the code } }
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceStateAugmentationBuilder; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces.state._interface.Routing; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces.state._interface.RoutingBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class InterfaceRoutingCustomizerTest extends ReaderCustomizerTest<Routing, RoutingBuilder> { private static final String IFC_CTX_NAME = "ifc-test-instance"; private static final String IF_NAME = "local0"; private static final int IF_ID = 1; private static final Long IP4_VRF_ID = 1L; private static final Long IP6_VRF_ID = 2L; private NamingContext interfacesContext; public InterfaceRoutingCustomizerTest() { super(Routing.class, VppInterfaceStateAugmentationBuilder.class); } @Override public void setUp() { // Code for setup } }
namingContext.removeChild(PARENT_1, CHILD_1, mappingContext); verify(mappingContext, times(1)).put(instanceIdentifierArgumentCaptor.capture(), mappingArgumentCaptor.capture()); assertEquals(instanceIdentifierArgumentCaptor.getValue(), parentKey(PARENT_1)); final Mapping mapping = mappingArgumentCaptor.getValue(); final List<Value> values = mapping.getValue(); assertEquals(PARENT_1, mapping.getName()); assertThat(values, hasSize(2)); assertThat(values, containsInAnyOrder(valueFor(CHILD_2, 2), valueFor(CHILD_3, 3))); @Test public void removeChildNonExistingParent() { namingContext.removeChild(NON_EXISTING_PARENT, CHILD_1, mappingContext); // if parent does not exist, do nothing verify(mappingContext, times(0)).put(Mockito.any(), Mockito.any()); } private Value valueFor(final String name, final int index) { return new ValueBuilder().setName(name).setIndex(index).withKey(new ValueKey(name)).build(); }
import io.fd.hc2vpp.ipsec.read.IpsecReaderFactory; import io.fd.hc2vpp.ipsec.write.IpsecWriterFactory; import io.fd.honeycomb.translate.read.ReaderFactory; import io.fd.honeycomb.translate.write.WriterFactory; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * Module class instantiating nat plugin components. */ public class IpsecModule extends AbstractModule { private static final Logger LOG = LoggerFactory.getLogger(IpsecModule.class); public static final String SAD_ENTRIES_MAPPING = "sad-entries-mapping"; @Override protected void configure() { LOG.info("Installing IPSec module"); bind(MultiNamingContext.class).toInstance(new MultiNamingContext(SAD_ENTRIES_MAPPING, 1)); LOG.info("Injecting writers factories"); final Multibinder<WriterFactory> writerFactoryBinder = Multibinder.newSetBinder(binder(), WriterFactory.class); writerFactoryBinder.addBinding().to(IpsecWriterFactory.class).in(Singleton.class); LOG.info("Injecting readers factories"); final Multibinder<ReaderFactory> readerFactoryBinder = Multibinder.newSetBinder(binder(), ReaderFactory.class); readerFactoryBinder.addBinding().to(IpsecReaderFactory.class).in(Singleton.class); } }
import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecStateSpdAugmentationBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.Spd; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.spd.SpdEntries; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public final class IpsecReaderFactory implements ReaderFactory { private static final InstanceIdentifier<IpSecState> IPSEC_STATE_ID = InstanceIdentifier.create(IpSecState.class); private FutureJVppCore vppApi; @Inject public IpsecReaderFactory(final FutureJVppCore vppApi) { this.vppApi = vppApi; } @Override public void init(@Nonnull final ModifiableReaderRegistryBuilder registry) { registry.subtreeAdd(Sets.newHashSet( InstanceIdentifier.create(IpSecState.class).child(Sa.class), InstanceIdentifier.create(IpSecState.class).augmentation(IpsecStateSpdAugmentation.class).child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpSecStateCustomizer(vppApi))); } }
import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecStateSpdAugmentationBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.Spd; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.spd.SpdEntries; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public final class IpsecReaderFactory implements ReaderFactory { private static final InstanceIdentifier<IpsecState> IPSEC_STATE_ID = InstanceIdentifier.create(IpsecState.class); private FutureJVppCore vppApi; @Inject public IpsecReaderFactory(final FutureJVppCore vppApi) { this.vppApi = vppApi; } @Override public void init(@Nonnull final ModifiableReaderRegistryBuilder registry) { registry.subtreeAdd(Sets.newHashSet( InstanceIdentifier.create(IpsecState.class).child(Sa.class), InstanceIdentifier.create(IpsecState.class).augmentation(IpsecStateSpdAugmentation.class).child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpsecStateCustomizer(vppApi))); } }
InstanceIdentifier.create(IpsecState.class) .augmentation(IpsecStateSpdAugmentation.class) .child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpsecStateCustomizer(vppApi))); registry.addStructuralReader(IPSEC_STATE_ID.augmentation(IpsecStateSpdAugmentation.class), IpsecStateSpdAugmentationBuilder.class); registry.subtreeAdd(Sets.newHashSet(InstanceIdentifier.create(Spd.class).child(SpdEntries.class)), new GenericInitListReader<>(IPSEC_STATE_ID.augmentation(IpsecStateSpdAugmentation.class).child(Spd.class), new IpsecStateSpdCustomizer(vppApi)));
public IpsecStateCustomizer(final FutureJVppCore vppApi) { super(vppApi); this.ipsecSaDetailsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSaDetailsReplyDump, Void>() .withExecutor(new IpsecStateCustomizer.IpsecStateSaDetailsDumpExecutor(vppApi)) .acceptOnly(IpsecSaDetailsReplyDump.class) .build(); }
return Initialized.create(id, readValue); } @Nonnull @Override public IpsecStateBuilder getBuilder(@Nonnull final InstanceIdentifier<IpsecState> id) { return new IpsecStateBuilder(); } @Override public void readCurrentAttributes(@Nonnull final InstanceIdentifier<IpsecState> id, @Nonnull final IpsecStateBuilder builder, @Nonnull final ReadContext ctx) throws ReadFailedException { final Optional<IpsecSaDetailsReplyDump> dumpSa = ipsecSaDetailsReplyDumpManager.getDump(id, ctx.getModificationCache()); if (dumpSa.isPresent()) { LinkedList<Sa> listSa = new LinkedList<>(); IpsecSaDetailsReplyDump reply = dumpSa.get(); for (IpsecSaDetails details : reply.ipsecSaDetails) { SaBuilder saBuilder = new SaBuilder(); saBuilder.setSpi(Integer.toUnsignedLong(details.spi)); saBuilder.setAntiReplayWindow(Long.valueOf(details.replayWindow).intValue()); saBuilder.setAuthenticationAlgorithm(IkeIntegrityAlgorithmT.forValue(details.integAlg)); saBuilder.setEncryptionAlgorithm(IkeEncryptionAlgorithmT.forValue(details.cryptoAlg)); listSa.add(saBuilder.build()); } builder.setSa(listSa); } } @Override
if (dumpSa.isPresent()) { LinkedList<Sa> listSa = new LinkedList<>(); IpsecSaDetailsReplyDump reply = dumpSa.get(); for (IpsecSaDetails details : reply.ipsecSaDetails) { SaBuilder saBuilder = new SaBuilder(); saBuilder.setSpi(Integer.toUnsignedLong(details.spi)); saBuilder.setAntiReplayWindow(Long.valueOf(details.replayWindow).intValue()); saBuilder.setAuthenticationAlgorithm(IkeIntegrityAlgorithmT.forValue(details.integAlg)); saBuilder.setEncryptionAlgorithm(IkeEncryptionAlgorithmT.forValue(details.cryptoAlg)); listSa.add(saBuilder.build()); } builder.setSa(listSa); } @Override public void merge(@Nonnull final Builder<? extends DataObject> parentBuilder, @Nonnull final IpsecState readValue) { IpsecStateBuilder ipsecParentBuilder = (IpsecStateBuilder)parentBuilder; ipsecParentBuilder.setHoldDown(readValue.getHoldDown()); ipsecParentBuilder.setPolicy(readValue.getPolicy()); ipsecParentBuilder.setProposal(readValue.getProposal()); ipsecParentBuilder.setRedundancy(readValue.getRedundancy()); ipsecParentBuilder.setSa(readValue.getSa()); }
implements EntityDumpExecutor<IpsecSaDetailsReplyDump, Void>, JvppReplyConsumer { private final FutureJVppCore jvpp; IpsecStateSaDetailsDumpExecutor(final FutureJVppCore jvpp) { this.jvpp = jvpp; } @Nonnull @Override public IpsecSaDetailsReplyDump executeDump(final InstanceIdentifier<?> identifier, final Void params) throws ReadFailedException { IpsecSaDump dump = new IpsecSaDump(); dump.saId = -1; return getReplyForRead(jvpp.ipsecSaDump(dump).toCompletableFuture(), identifier); } }
Fixed Code: } } } @Override public void updateCurrentAttributes(@Nonnull final InstanceIdentifier<IkeGlobalConfiguration> id, @Nonnull final IkeGlobalConfiguration dataBefore, @Nonnull final IkeGlobalConfiguration dataAfter, @Nonnull final WriteContext writeContext) throws WriteFailedException { writeCurrentAttributes(id, dataAfter, writeContext); } @Override public void deleteCurrentAttributes(@Nonnull final InstanceIdentifier<IkeGlobalConfiguration> id, @Nonnull final IkeGlobalConfiguration dataBefore, @Nonnull final WriteContext writeContext) throws WriteFailedException { // TODO Auto-generated method stub }
String name = id.firstKeyOf(Policy.class).getName(); if (dataAfter.getLocal() != null) { setProfileId(id, name, dataAfter.getLocal().getIdentity(), true); } if (dataAfter.getRemote() != null) { setProfileId(id, name, dataAfter.getRemote().getIdentity(), false); } @Override public void deleteCurrentAttributes(@Nonnull final InstanceIdentifier<Identity> id, @Nonnull final Identity dataBefore, @Nonnull final WriteContext writeContext) throws WriteFailedException { } @Override public void updateCurrentAttributes(@Nonnull final InstanceIdentifier<Identity> id, @Nonnull final Identity dataBefore, @Nonnull final Identity dataAfter, @Nonnull final WriteContext writeContext) throws WriteFailedException { writeCurrentAttributes(id, dataAfter, writeContext); } private void setProfileId(final InstanceIdentifier<Identity> id, final String profileName, final org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.identity.grouping.Identity data, final boolean isLocalId) throws WriteFailedException { // implementation goes here }
IpsecSadEntriesAugmentation augment = dataAfter.augmentation(IpsecSadEntriesAugmentation.class); if (augment != null && augment.getSaId() != null) { entry.sadId = augment.getSaId(); } if (dataAfter.getSpi() != null) { entry.spi = dataAfter.getSpi().intValue(); } if (dataAfter.getAntiReplayWindow() != null) { entry.useAntiReplay = dataAfter.getAntiReplayWindow() > 0 ? BYTE_TRUE : BYTE_FALSE; } if (dataAfter.getSaMode() != null) { entry.isTunnel = Integer.valueOf(dataAfter.getSaMode().getIntValue()).byteValue(); } entry.isAdd = adding ? ByteDataTranslator.BYTE_TRUE : ByteDataTranslator.BYTE_FALSE; if (dataAfter.getEsp() != null) { entry.protocol = 1; fillEspAuthentication(entry, dataAfter.getEsp()); fillEspEncryption(entry, dataAfter.getEsp()); } else if (dataAfter.getAh() != null) { entry.protocol = 0; }
import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecIkeGlobalConfAugmentation; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecSadEntriesAugmentation; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecSpdEntriesAugmentation; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public final class IpsecWriterFactory implements WriterFactory { private static final InstanceIdentifier<Ikev2> IKE2_ID = InstanceIdentifier.create(Ikev2.class); private static final InstanceIdentifier<Ipsec> IPSEC_ID = InstanceIdentifier.create(Ipsec.class); private static final InstanceIdentifier<Sad> SAD_ID = IPSEC_ID.child(Sad.class); private static final InstanceIdentifier<SadEntries> SAD_ENTRIES_ID = SAD_ID.child(SadEntries.class); private static final InstanceIdentifier<Spd> SPD_ID = IPSEC_ID.child(Spd.class); private final FutureJVppCore vppApi; private MultiNamingContext sadEntriesMapping; @Inject public IpsecWriterFactory(FutureJVppCore vppApi) { this.vppApi = vppApi; } }
public void init(@Nonnull final ModifiableWriterRegistryBuilder registry) { registry.subtreeAdd(Sets.newHashSet( InstanceIdentifier.create(SadEntries.class).child(SourceAddress.class), InstanceIdentifier.create(SadEntries.class).child(DestinationAddress.class), InstanceIdentifier.create(SadEntries.class).child(Ah.class) .child(org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ipsec.sa.ah.grouping.ah.authentication.algorithm.hmac.sha1._96.HmacSha196.class), InstanceIdentifier.create(SadEntries.class).child(Ah.class) .child(org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ipsec.sa.ah.grouping.ah.authentication.algorithm.hmac.md5._96.HmacMd596.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Authentication.class).child(HmacSha196.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Authentication.class).child(HmacMd596.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Encryption.class).child(Aes128Cbc.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Encryption.class).child(Aes192Cbc.class) )); }
org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ikev2.policy.profile.grouping.Authentication.class), InstanceIdentifier.create(Policy.class).child(TrafficSelectors.class)), new GenericListWriter<>(IKE2_ID.child(Policy.class), new Ikev2PolicyCustomizer(vppApi))); registry.subtreeAdd(Sets.newHashSet(InstanceIdentifier.create(Identity.class).child(Local.class), InstanceIdentifier.create(Identity.class).child(Remote.class)), new GenericWriter<>(IKE2_ID.child(Policy.class).child(Identity.class), new Ikev2PolicyIdentityCustomizer(vppApi)));
package io.fd.hc2vpp.ipsec; import com.google.inject.AbstractModule; import com.google.inject.Singleton; import com.google.inject.multibindings.Multibinder; import io.fd.hc2vpp.common.translate.util.MultiNamingContext; import io.fd.hc2vpp.ipsec.read.IpsecReaderFactory; import io.fd.hc2vpp.ipsec.write.IpsecWriterFactory; import io.fd.honeycomb.translate.read.ReaderFactory; import io.fd.honeycomb.translate.write.WriterFactory; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class IpsecModule extends AbstractModule { private static final Logger LOG = LoggerFactory.getLogger(IpsecModule.class); private static final String SAD_ENTRIES_MAPPING = "sad-entries-mapping"; @Override protected void configure() { LOG.info("Installing IPSec module"); bind(MultiNamingContext.class).toInstance(new MultiNamingContext(SAD_ENTRIES_MAPPING, 1)); LOG.info("Injecting writers factories"); final Multibinder<WriterFactory> writerFactoryBinder = Multibinder.newSetBinder(binder(), WriterFactory.class); writerFactoryBinder.addBinding().to(IpsecWriterFactory.class).in(Singleton.class); } }
super(vppApi); IpsecStateSpdsReplyDumpExecutor spdsExecutor = new IpsecStateSpdCustomizer.IpsecStateSpdsReplyDumpExecutor(vppApi); this.ipsecSpdsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSpdsDetailsReplyDump, Void>() .withExecutor(spdsExecutor) .acceptOnly(IpsecSpdsDetailsReplyDump.class) .build(); this.ipsecSpdDetailsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSpdDetailsReplyDump, Void>() .withExecutor(new IpsecStateSpdCustomizer.IpsecStateSpdDetailsDumpExecutor(vppApi, spdsExecutor)) .acceptOnly(IpsecSpdDetailsReplyDump.class) .build();
public void init(@Nonnull final ModifiableWriterRegistryBuilder registry) { InstanceIdentifier<Policer> IID = InstanceIdentifier.create(Policer.class); registry.subtreeAdd( Sets.newHashSet( IID.child(ConformAction.class), IID.child(ExceedAction.class), IID.child(ViolateAction.class) ), new GenericListWriter<>( POLICER_IID, new PolicerCustomizer(vppApi, policerContext), new PolicerValidator(policerContext) ) ); }
/* Copyright (c) 2017 Cisco and/or its affiliates. * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at: * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package io.fd.hc2vpp.l3.write.ipv4; import static com.google.common.base.Preconditions.checkNotNull; import io.fd.hc2vpp.common.translate.util.NamingContext; import io.fd.honeycomb.translate.write.DataValidationFailedException; import io.fd.honeycomb.translate.write.Validator; import io.fd.honeycomb.translate.write.WriteContext; import javax.annotation.Nonnull;
public static final class StatsConnectionInfo { public final long queueAddress; public final int clientIndex; public final int status; // FIXME throw exception instead public final int pid; public StatsConnectionInfo(long queueAddress, int clientIndex, int status, int pid) { this.queueAddress = queueAddress; this.clientIndex = clientIndex; this.status = status; this.pid = pid; } } private static native StatsConnectionInfo statsConnect(String clientName); private static native void statsDisconnect();
public void onInterfaceStatisticsDetails(final io.fd.jvpp.stats.dto.InterfaceStatisticsDetails reply) { io.fd.jvpp.stats.callback.InterfaceStatisticsDetailsCallback callback; final int replyId = reply.context; if (LOG.isLoggable(java.util.logging.Level.FINE)) { LOG.fine(String.format("Received InterfaceStatisticsDetails event message: %s", reply)); } synchronized (requests) { callback = (io.fd.jvpp.stats.callback.InterfaceStatisticsDetailsCallback) requests.remove(replyId); } if (callback != null) { callback.onInterfaceStatisticsDetails(reply); } }
package io.fd.jvpp.stats.dto; public final class InterfaceStatisticsDump implements io.fd.jvpp.dto.JVppDump { @Override public int hashCode() { return java.util.Objects.hash(); } @Override public boolean equals(final Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } return true; } @Override public String toString() { return "InterfaceStatisticsDump{}"; } @Override public void writeObject(BufferWriter writer) { // TODO: Implement writeObject method } @Override public void readObject(BufferReader reader) { // TODO: Implement readObject method } }
} synchronized(requests) { CompletableFuture<? extends JVppReply<?>> replyFuture = requests.get(contextId); if (replyFuture == null) { // reply not received yet, put new future to map replyDumpFuture = new CompletableDumpFuture<>(contextId, emptyReplyDump); requests.put(contextId, replyDumpFuture); } else { // reply already received, save existing future replyDumpFuture = (CompletableDumpFuture<DUMP>) replyFuture; } } synchronized (requests) { // reply already received, complete future replyDumpFuture.complete(replyDumpFuture.getReplyDump()); requests.remove(contextId); } // TODO in case of timeouts/missing replies, requests from the map are not removed // consider adding cancel method, that would remove requests from the map and cancel // associated replyCompletableFuture return replyDumpFuture; } catch (VppInvocationException ex) { final CompletableFuture<DUMP> replyCompletableFuture = new CompletableFuture<>(); replyCompletableFuture.completeExceptionally(ex); return replyCompletableFuture; } }
.get(replyId); if (completableFuture == null) { // reply received before writer created future, // create new future, and put into map to notify sender that reply is already received, // following details replies will add information to this future completableFuture = new io.fd.jvpp.stats.future.AbstractFutureJVppInvoker.CompletableDumpFuture<>(replyId, new InterfaceStatisticsDetailsReplyDump()); requests.put(replyId, completableFuture); } completableFuture.getReplyDump().interfaceStatisticsDetails = reply; }
public InterfaceStatisticsCustomizer(final NamingContext ifcNamingCtx, final FutureJVppStatsFacade jvppStats, final InterfaceStatisticsCollectionManager statisticsManager) { this.ifcNamingCtx = checkNotNull(ifcNamingCtx, "Naming context should not be null"); this.jvppStats = checkNotNull(jvppStats, "JVpp Stats facade should not be null"); this.statisticsManager = checkNotNull(statisticsManager, "Statistics Collection Manager should not be null"); }
.setInMulticastPkts(new Counter64(BigInteger.valueOf(detail.inMulticastPkts))) .setInBroadcastPkts(new Counter64(BigInteger.valueOf(detail.inBroadcastPkts))) .setInErrors(new Counter32(new Long(detail.inErrors))); } } } @Override public void merge(@Nonnull final Builder<? extends DataObject> builder, @Nonnull final Statistics statistics) { ((InterfaceBuilder) builder).setStatistics(statistics); } private InterfaceStatisticsDetails getStatisticsDump(InstanceIdentifier<Statistics> id) throws ReadFailedException { LOG.info("Sending InterfaceStatisticsDump request..."); final InterfaceStatisticsDump request = new InterfaceStatisticsDump(); final Future<InterfaceStatisticsDetailsReplyDump> replyFuture = jvppStats.interfaceStatisticsDump(request).toCompletableFuture(); final InterfaceStatisticsDetailsReplyDump reply; try { reply = replyFuture.get(); } catch (Exception e) { throw new ReadFailedException(id, e); } if (reply == null || reply.interfaceStatisticsDetails == null) { throw new ReadFailedException(id, new IllegalStateException("Received null response for empty dump: " + reply)); } return reply.interfaceStatisticsDetails; }
public L2Validator(final NamingContext interfaceContext, final NamingContext bridgeDomainContext) { checkNotNull(interfaceContext, "interfaceContext should not be null"); checkNotNull(bridgeDomainContext, "bridgeDomainContext should not be null"); }
public SubInterfaceL2Validator(final NamingContext interfaceContext, final NamingContext bridgeDomainContext) { checkNotNull(interfaceContext, "interfaceContext should not be null"); checkNotNull(bridgeDomainContext, "bridgeDomainContext should not be null"); }
public VxlanValidator(@Nonnull final NamingContext interfaceNamingContext, @Nonnull final DisabledInterfacesManager disabledInterfacesManager) { checkNotNull(interfaceNamingContext, "interfaceContext should not be null"); checkNotNull(disabledInterfacesManager, "DisabledInterfacesManager should not be null"); }
private void validateVxlan(final Vxlan data) { checkNotNull(data.getSrc()); checkNotNull(data.getDst()); if (data.getSrc().getIpv4AddressNoZone() == null) { checkArgument(data.getDst().getIpv4AddressNoZone() == null, "Inconsistent ip addresses: %s, %s", data.getSrc(), data.getDst()); } else { checkArgument(data.getDst().getIpv6AddressNoZone() == null, "Inconsistent ip addresses: %s, %s", data.getSrc(), data.getDst()); } checkArgument(data.getEncapVrfId() != null && data.getEncapVrfId().getValue() != null, "encap-vrf-id is mandatory but was not given"); checkNotNull(data.getVni()); }
public String getTxtProjectName() { return mProjectNameResult; } private void createTxtProjectName(Composite parent) { mTxtProjectName = new Text(parent, SWT.BORDER); mTxtProjectName.addModifyListener(new ModifyListener() { @Override public void modifyText(ModifyEvent e) { mProjectNameResult = mTxtProjectName.getText(); } }); }
public String getTxtProjectID() { return mTxtProjectID.getText(); }
public String getTxtProjectPath() { return mTxtProjectPath.getText(); }
import javax.annotation.PostConstruct; import org.eclipse.jface.viewers.TreeViewer; import org.eclipse.swt.SWT; import org.eclipse.swt.layout.FormAttachment; import org.eclipse.swt.layout.FormData; import org.eclipse.swt.layout.FormLayout; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Tree; import com.samsung.dali.modelconverter.view.dialogs.TizenPathDialog; public class SceneGraphPart { @PostConstruct public void createComposite(Composite parent) { TizenPathDialog.VerifyTizenPath(parent.getShell(), false); parent.setLayout(new FormLayout()); TreeViewer treeViewer = new TreeViewer(parent, SWT.BORDER); Tree tree = treeViewer.getTree(); FormData fd_tree = new FormData(); fd_tree.bottom = new FormAttachment(100, -10); fd_tree.right = new FormAttachment(100, -5); fd_tree.top = new FormAttachment(0, 5); // Set the layout data for the tree tree.setLayoutData(fd_tree); } }
package com.ibm.disni.nvmef; import java.io.IOException; import java.net.URI; import java.nio.ByteBuffer; import com.ibm.disni.DiSNIEndpoint; import com.ibm.disni.nvmef.spdk.*; public class NvmeEndpoint implements DiSNIEndpoint { private final NvmeEndpointGroup group; private NvmeQueuePair queuePair; private NvmeNamespace namespace; private NvmeController controller; private volatile boolean open; private NvmeControllerOptions controllerOptions; public NvmeEndpoint(NvmeEndpointGroup group, NvmfConnection newConnection) { this.group = group; this.queuePair = null; this.namespace = null; this.open = newConnection != null; } public synchronized void connect(URI uri) throws IOException { if (open) { return; } NvmeResourceIdentifier nvmeResource = NvmeResourceIdentifier.parse(uri); NvmeTransportId transportId = nvmeResource.toTransportId(); this.controller = group.probe(transportId, nvmeResource.getController()); } }
private boolean isComparable(Object value) { return (value != null) && (value instanceof Comparable<?>); } return namespace; } NvmeQueuePair getQueuePair() { return queuePair; } public boolean isOpen() { return open; } public synchronized void close() throws IOException, InterruptedException { queuePair.free(); open = false; } public synchronized int processCompletions(long[] completed) throws IOException { return queuePair.processCompletions(completed); } public int getSectorSize() { return namespace.getSectorSize(); } public long getNamespaceSize() { return namespace.getSize(); } public int getMaxTransferSize() { return namespace.getMaxIOTransferSize(); } public int getIOQueueSize() { return controllerOptions.getIOQueueSize(); } public void keepAlive() throws IOException { controller.keepAlive(); }
public void run() { Status status = new Status(IStatus.ERROR, "Error writing file", e.getLocalizedMessage()); ErrorDialog.openError(Display.getDefault().getActiveShell(), String.format("Error writing %s.uix", filepath), e.getLocalizedMessage(), status); } public ScreenshotAction(UiAutomatorViewer viewer, boolean compressed) { super("&Device Screenshot " + (compressed ? "with Compressed Hierarchy" : "") + "(uiautomator dump" + (compressed ? " --compressed)" : ")")); mViewer = viewer; mCompressed = compressed; } public void initializeFiles() throws IOException { File scriptFile = new File(scriptPath); File graphDataFile = new File(graphDataPath); scriptFile.createNewFile(); graphDataFile.createNewFile(); } this.open = false; } public synchronized void connect(URI uri) throws IOException { if (open) { return; } NvmeResourceIdentifier nvmeResource = NvmeResourceIdentifier.parse(uri); NvmeTransportId transportId = nvmeResource.toTransportId(); NvmeController nvmecontroller = group.probe(transportId, nvmeResource.getController()); this.namespace = nvmecontroller.getNamespace(nvmeResource.getNamespace()); this.queuePair = nvmecontroller.allocQueuePair(); this.open = true; this.controllerOptions = nvmecontroller.getOptions(); } private enum Operation { READ, WRITE } private NvmeCommand op(Operation op, ByteBuffer buffer, long linearBlockAddress) throws IOException { if (open) { throw new IOException("endpoint is closed"); } if (buffer.remaining() % namespace.getSectorSize() != 0) { throw new IOException("Remaining buffer a multiple of sector size"); } IOCompletion completion = new IOCompletion(); return new NvmeCommand(this, buffer, linearBlockAddress, completion, op == Operation.WRITE); }
package com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonIgnore; public class Camera { @JsonIgnore public int getId() { return mId; } public void setId(int id) { mId = id; } @Override public String toString() { return "Camera " + mId; } public double getFov() { return mFov; } public void setFov(double fov) { mFov = fov; } public double getNear() { return mNear; } public void setNear(double near) { mNear = near; } public double getFar() { return mFar; } public void setFar(double far) { mFar = far; } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } private int mId; private double mFov; private double mNear; private double mFar; private double[] mMatrix; }
} public ArrayList<Mesh> getMeshes() { return mMeshes; } public void setMeshes(ArrayList<Mesh> meshes) { mMeshes = meshes; } public ArrayList<Material> getMaterials() { return mMaterials; } public void setMaterials(ArrayList<Material> materials) { mMaterials = materials; } public ArrayList<Shader> getShaders() { return mShaders; } public void setShaders(ArrayList<Shader> shaders) { mShaders = shaders; } @JsonProperty("environment") public ArrayList<Environment> getEnvironment() { return mEnvironments; } public void setEnvironment(ArrayList<Environment> environments) { mEnvironments = environments; } public void setNodeParents() { for (Node n : mNodes) { for (Integer i : n.getChildIds()) { mNodes.get(i.intValue()).setParent(n); } } } public void setIds() { int id = 1; for (Scene s : mScenes) { s.setId(id); ++id; } }
package com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Environment { @JsonProperty("cubeSpecular") public String getSpecularPath() { return mSpecularPath; } public void setSpecularPath(String path) { mSpecularPath = path; } @JsonProperty("cubeDiffuse") public String getDiffusePath() { return mDiffusePath; } public void setDiffusePath(String path) { mDiffusePath = path; } private String mSpecularPath; private String mDiffusePath; }
public void setMatrix(double[] data) { if (data != null) { mMatrix = MatrixHelper.createMatrix(data); } else { mMatrix = MatrixHelper.createMatrix(); } }
package com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Asset { private String version; public String getVersion() { return version; } public void setVersion(String version) { this.version = version; } @JsonProperty("version") private String mVersion; }
implements DataSource<AccountState>, Matchable<AccountState> { public IndexedAccountQuery(Index<Account.Id, AccountState> index, Predicate<AccountState> pred, QueryOptions opts) throws QueryParseException { super(index, pred, opts.convertForBackend()); } @Override public boolean match(AccountState accountState) throws OrmException { Predicate<AccountState> pred = getChild(0); checkState(pred.isMatchable(), "match invoked, but child predicate %s doesn't implement %s", pred, Matchable.class.getName()); return pred.asMatchable().match(accountState); } @Override public int getCost() { return 1; } } public interface ITextEditorExtension6 { boolean isWordWrapActivated(); void setWordWrap(boolean wordWrapHint); } public class MyClass { private double mFov; private double mNear; private double mFar; private double[] mMatrix = MatrixHelper.createMatrix(); private int mId; public double getFov() { return mFov; } public void setFov(double fov) { mFov = fov; } public double getNear() { return mNear; } public void setNear(double near) { mNear = near; } public double getFar() { return mFar; } public void setFar(double far) { mFar = far; } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } @JsonProperty("fov") private double mFov; @JsonProperty("near") private double mNear; @JsonProperty("far") private double mFar; @JsonProperty("matrix") private double[] mMatrix = MatrixHelper.createMatrix(); @JsonIgnore private int mId; }
public interface ITextEditorExtension6 { boolean isWordWrapActivated(); void setWordWrap(boolean wordWrapHint); } public final double getLatitude() { return mLatitude; } protected Vector<URL> filterResources(Vector<URL> urlList) { if (isUseResourceFilteringEnabled()) { Vector<URL> newUrlList = new Vector<URL>(); Vector<URL> customUrlList = new Vector<URL>(); Enumeration<URL> elements = urlList.elements(); while (elements.hasMoreElements()) { URL resource = elements.nextElement(); newUrlList.add(resource); if (isUrlFromBundlePrefixes(resource)) { customUrlList.add(resource); } } if (!customUrlList.isEmpty()) { urlList = customUrlList; } else { urlList = newUrlList; } } return urlList; } public Asset getAsset() { return mAsset; } public int getDefaultSceneId() { return mDefaultSceneId; } public ArrayList<Scene> getScenes() { return mScenes; } public ArrayList<Node> getNodes() { return mNodes; } public ArrayList<Camera> getCameras() { return mCameras; } public Skybox getSkybox() { return mSkybox; } public ArrayList<Mesh> getMeshes() { return mMeshes; }
import com.fasterxml.jackson.annotation.JsonIgnore; import com.fasterxml.jackson.annotation.JsonGetter; import com.fasterxml.jackson.annotation.JsonSetter; import java.util.ArrayList; public class Scene { @JsonIgnore private int mId = -1; @JsonIgnore private boolean mIsOrphan = false; @JsonIgnore private Integer mRootId = -1; @JsonSetter("nodes") public void setNodes(ArrayList<Integer> nodes) { if (nodes.size() != 1) { throw new IllegalArgumentException("Scene.nodes must be an array of a single node index. Sorry about that."); } mRootId = nodes.get(0).intValue(); } @JsonGetter("nodes") public ArrayList<Integer> getNodes() { ArrayList<Integer> nodes = new ArrayList<Integer>(); nodes.add(new Integer(mRootId)); return nodes; } }
} } else { throw new IllegalArgumentException("Unknown type: " + value.getClass().getName()); } } @JsonAnyGetter public Map<String, Object> get() { Map<String, Object> values = new TreeMap<String, Object>(); for (Entry<String, Uniform> u : mUniforms.entrySet()) { values.put(u.getKey(), u.getValue().getValue()); } return values; } @JsonProperty("vertex") private String mVertexPath; @JsonProperty("fragment") private String mFragmentPath; @JsonProperty("renderMode") private int mRenderMode; @JsonIgnore private Map<String, Uniform> mUniforms; }
package com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Skybox { private String texture; public String getTexture() { return texture; } public void setTexture(String texture) { this.texture = texture; } @JsonProperty("texture") public String getTextureJsonProperty() { return texture; } }
public class ModelExporter { private static boolean sInitialised = false; public static void initialise() { if (!sInitialised) { System.loadLibrary("model-exporter-jni"); sInitialised = true; } } /** * @brief Performs model export, loading a .dae file, and writing .bin and * .dli files. * @param inputFile - path to the .dae file to process. Required. * @param outputName - the name and path to save the .dli and .bin files to. * Optional. Will use the input path and name if omitted. */ }
/** * See the License for the specific language governing permissions and * limitations under the License. */ public class ModelExporter { static { System.loadLibrary("model-exporter-jni"); } /** * Performs model export, loading a .dae file, and writing .bin and .dli files. * * @param inputPath - path to the .dae file to process. Required. * @param outputPath - the name and path to save the .dli and .bin files to. Optional. * Will use the input path and name if omitted. * @return 0 on success, 1 on failure. */ public static native int nativeExport(String inputPath, String outputPath); /** * Performs model conversion, loading a .dae file, and converting it to the DLI format. * In case of success, the dli and binary contents can be retrieved by calling nativeGetDli/BinContents(). * * @param inputPath - path to the .dae file to process. Required. * @return 0 on success, 1 on failure. */ public static native int nativeConvert(String inputPath); }
import com.fasterxml.jackson.annotation.JsonIgnore; import com.samsung.dali.modelconverter.data.document.property.Property; public class Camera implements Property.Provider { @JsonIgnore public int getId() { return mId; } public void setId(int id) { mId = id; } @Override public String toString() { return "Camera " + mId; } public double getFov() { return mFov; } public void setFov(Number fov) { mFov = fov.doubleValue(); } public double getNear() { return mNear; } public void setNear(Number near) { mNear = near.doubleValue(); } public double getFar() { return mFar; } public void setFar(Number far) { mFar = far.doubleValue(); } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } @Override public Property getProperty(String name) { // Implementation of getProperty method } }
for (int i = 0; i < 3; ++i) { matrix[12 + i] = translation[i]; } public static double[] getRotation(double[] matrix) { double[] rotation = new double[] { Math.atan2(matrix[6], matrix[10]), Math.atan2(-matrix[2], Math.sqrt(matrix[6] * matrix[6] + matrix[10] * matrix[10])), Math.atan2(matrix[1], matrix[0]) }; return rotation; } public static void setRotation(double[] rotation, double[] matrix) { // TODO: Implement this method } public static double[] getScale(double[] matrix) { double[] scale = new double[] { getColumnMagnitude(matrix, 0), getColumnMagnitude(matrix, 1), getColumnMagnitude(matrix, 2) }; return scale; } public static void setScale(double[] scale, double[] matrix) { double[] scaleCurr = getScale(matrix); for (int i = 0; i < 3; ++i) { scale[i] /= scaleCurr[i]; } }
public static SceneGraphPart getSceneGraphPart() { if (SceneGraphPart.sActiveInstance == null) { createPart("com.samsung.dali.modelconverter.part.scenegraph"); assert SceneGraphPart.sActiveInstance != null; } return SceneGraphPart.sActiveInstance; } public static NodePropertiesPart getNodePropertiesPart() { if (NodePropertiesPart.sActiveInstance == null) { createPart("com.samsung.dali.modelconverter.part.nodeproperties"); assert NodePropertiesPart.sActiveInstance != null; } return NodePropertiesPart.sActiveInstance; } static void createPart(String id) { Bundle bundle = FrameworkUtil.getBundle(EPartService.class); BundleContext bundleContext = bundle.getBundleContext(); IEclipseContext eclipseContext = EclipseContextFactory.getServiceContext(bundleContext); EPartService partService = (EPartService)eclipseContext.get(EPartService.class); partService.showPart(id, PartState.CREATE); }
public void createComposite(Composite parent) { parent.setLayout(new GridLayout(1, false)); mParent = parent; resetProperties(); sActiveInstance = this; }
public void populate(SceneGraphContentProvider provider, SceneGraphSelectionChangedListener selectionChangedListener) { mTree.removeAll(); if (mSelectionChangedListener != null) { mTreeViewer.removeSelectionChangedListener(mSelectionChangedListener); } mTreeViewer.addSelectionChangedListener(selectionChangedListener); mTreeViewer.setContentProvider(provider); mTreeViewer.setInput(provider.getDocument()); mTreeViewer.refresh(); }
GridData gd_mOptions = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1); gd_mOptions.widthHint = 240; mOptions.setLayoutData(gd_mOptions); public IdPropertyWidget setRange(Collection<?> values) { mOptions.removeAll(); for(Object o: values) { mOptions.add(o.toString()); } return this; } public IdPropertyWidget setWritable(boolean isWritable) { mOptions.setEnabled(isWritable); return this; } public IdPropertyWidget setSelection(int i) { mOptions.select(i); mOptions.update(); return this; } private Combo mOptions;
package com.samsung.dali.modelconverter.view.widgets; import org.eclipse.swt.SWT; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Text; public class TextPropertyWidget extends PropertyWidgetBase { private Text mText; public TextPropertyWidget(Composite parent, int style) { super(parent, style); mText = new Text(parent, SWT.BORDER); GridData gd_mText = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1); gd_mText.widthHint = 200; mText.setLayoutData(gd_mText); } public TextPropertyWidget setWritable(boolean isWritable) { mText.setEnabled(isWritable); return this; } public TextPropertyWidget setValue(String value) { mText.setText(value); return this; } }
mRx.setText(df.format(rotation[0])); mRy.setText(df.format(rotation[1])); mRz.setText(df.format(rotation[2])); return this; } public TransformPropertyWidget setWritable(boolean isWritable) { mTx.setEnabled(isWritable); mTy.setEnabled(isWritable); mTz.setEnabled(isWritable); mSx.setEnabled(isWritable); mSy.setEnabled(isWritable); mSz.setEnabled(isWritable); mRx.setEnabled(isWritable); mRy.setEnabled(isWritable); mRz.setEnabled(isWritable); return this; } private Text mTx; private Text mTy; private Text mTz; private Text mSx; private Text mSy; private Text mSz; private Text mRx; private Text mRy; private Text mRz;
public class Document { static public Document fromDli(String dli) throws JsonParseException, JsonMappingException, IOException { ObjectMapper mapper = new ObjectMapper(); mapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); Document d = mapper.readValue(dli, Document.class); d.setNodeParents(); d.setIds(); d.organizeOrphans(); return d; } public String toDliString() throws JsonProcessingException { ObjectMapper mapper = new ObjectMapper(); DefaultPrettyPrinter.Indenter indenter = new DefaultIndenter(" ", DefaultIndenter.SYS_LF); DefaultPrettyPrinter printer = new DefaultPrettyPrinter(); printer.indentObjectsWith(indenter); return mapper.writer(printer).writeValueAsString(this); } public Asset getAsset() { return mAsset; } public void setAsset(Asset asset) { mAsset = asset; } @JsonProperty("scene") public int getDefaultSceneId() { return mDefaultSceneId; } public void setDefaultSceneId(int defaultSceneId) { mDefaultSceneId = defaultSceneId; } }
public static void execute(Shell shell, List<String> outProfiles) { assert outProfiles != null; OutputPart op = GlobalParts.getOutputPart(); LoggingProcessRunner lpr = LoggingProcessRunner.create(shell.getDisplay(), op.getText()); lpr.addCommand(GlobalData.get().getTizenPath() + " security-profiles list", new LoggingProcessRunner.Parser() { @Override public void parseLine(String line) { if (mCare) { if (!line.isEmpty()) { int iSpace = line.indexOf(' '); if (iSpace != -1) { line = line.substring(0, iSpace); } outProfiles.add(line); } } else { mCare = line.startsWith("[Profile Name]"); } } private boolean mCare = false; }).run(); }
package com.samsung.dali.modelconverter.controller; import java.util.ArrayList; import org.eclipse.jface.viewers.ITreeContentProvider; import com.samsung.dali.modelconverter.data.document.Document; public class ResourceContentProvider implements ITreeContentProvider { private Document mDocument; private Class<?> mType; public ResourceContentProvider(Document doc, Class<?> type) { mDocument = doc; mType = type; } public Object getDocument() { return mDocument; } @Override public Object[] getElements(Object inputElement) { assert inputElement == mDocument; ArrayList<Object> kids = new ArrayList<Object>(); return kids.toArray(); } @Override public Object[] getChildren(Object parentElement) { return null; } @Override public Object getParent(Object element) { return null; } @Override public boolean hasChildren(Object element) { return false; } }
import org.eclipse.jface.viewers.ITreeContentProvider; import com.samsung.dali.modelconverter.data.document.Document; public class ResourceContentProvider implements ITreeContentProvider { public ResourceContentProvider(Document doc, Class<?> type) { mDocument = doc; mType = type; } public Object getDocument() { return mDocument; } @Override public Object[] getElements(Object inputElement) { assert inputElement == mDocument; ArrayList<Object> kids = new ArrayList<Object>(); return kids.toArray(); } @Override public Object[] getChildren(Object parentElement) { return null; } @Override public Object getParent(Object element) { return null; } @Override public boolean hasChildren(Object element) { return false; } private Document mDocument; private Class<?> mType; }
import javax.annotation.PostConstruct; import org.eclipse.jface.viewers.ISelectionChangedListener; import org.eclipse.jface.viewers.TreeViewer; import org.eclipse.swt.SWT; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Tree; public class AnimationPart { public static final String sId = "com.samsung.dali.modelconverter.part.animations"; @PostConstruct public void createComposite(Composite parent) { TreeViewer treeViewer = new TreeViewer(parent, SWT.BORDER); Tree tree = treeViewer.getTree(); } public void populate(ResourceContentProvider provider, ISelectionChangedListener listener) { Tree tree = treeViewer.getTree(); tree.removeAll(); if (mSelectionChangedListener != null) { treeViewer.removeSelectionChangedListener(mSelectionChangedListener); } treeViewer.addSelectionChangedListener(listener); treeViewer.setContentProvider(provider); treeViewer.setInput(null); treeViewer.refresh(); } }
public void populate(ITreeContentProvider provider, ISelectionChangedListener listener) { mTree.removeAll(); if (mSelectionChangedListener != null) { mTreeViewer.removeSelectionChangedListener(mSelectionChangedListener); } mTreeViewer.addSelectionChangedListener(listener); mTreeViewer.setContentProvider(provider); mTreeViewer.setInput(null); mTreeViewer.refresh(); }
mAttributes = a; public String getAttributeFlags() { String flags = ""; if (mIndices != null) { flags += "I"; } if (mUvs != null) { flags += "U"; } if (mNormals != null) { flags += "N"; } if (mTangents != null) { flags += "T"; } if (mBitangents != null) { flags += "B"; } return flags; } public BufferRef getIndices() { return mIndices; } public void setIndices(BufferRef br) { mIndices = br; } public BufferRef getPositions() { return mPositions; } public void setPositions(BufferRef br) { mPositions = br; } public BufferRef getNormals() { return mNormals; } public void setNormals(BufferRef br) { mNormals = br; }
public void provideProperties(Document context, Property.IReceiver receiver) { try { for (int index = 0; index < mTextures.length; index++) { receiver.register("Texture" + (index + 1), new Property(this, "TextureArray", Property.Type.String, true, null, new ArrayElementSetter(index), String[].class)); } } catch (NoSuchFieldException | NoSuchMethodException e) { e.printStackTrace(); } }
Collection<?> values = property.getRange(); try { switch (property.getType()) { case Integer: { // TODO: enable editing Integer number = 0; Object object = property.get(); if (null != object) { number = (Integer) object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false) .setValue(Integer.toString(number)).setName(name); break; } case Number: { // TODO: enable editing Double number = 0.0; Object object = property.get(); if (null != object) { number = (Double) object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false) .setValue(Double.toString(number)).setName(name); break; } case String: { // TODO: enable editing String string = ""; Object object = property.get(); if (null != object) { string = (String) object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false) .setValue(string).setName(name); break; } } } catch (Exception e) { // handle exception }
String issuanceProtCertNick = cmd.getOptionValue("n"); String output = cmd.getOptionValue("o"); try { CryptoManager.initialize(databaseDir); CryptoManager manager = CryptoManager.getInstance(); CryptoToken token = CryptoUtil.getKeyStorageToken(tokenName); tokenName = token.getName(); manager.setThreadToken(token); Password password = new Password(tokenPassword.toCharArray()); token.login(password); X509Certificate issuanceProtCert = null; if (issuanceProtCertFilename != null) { if (verbose) System.out.println("Loading issuance protection certificate"); String encoded = new String(Files.readAllBytes(Paths.get(issuanceProtCertFilename))); byte[] issuanceProtCertData = Cert.parseCertificate(encoded); issuanceProtCert = manager.importCACertPackage(issuanceProtCertData); if (verbose) System.out.println("issuance protection certificate imported"); } else { // must have issuance protection cert nickname if file not provided if (issuanceProtCertNick == null) { throw new Exception("Issuance protection cert nickname is required"); } issuanceProtCert = manager.getCACert(issuanceProtCertNick); } // rest of the code } catch (Exception e) { throw new Exception("Unable to login: " + e, e); }
public void handleWriteEvent() throws IOException { try { for (int i = 0; i < maxBatchIoOps; i++) { final NetlinkRequest request = writeQueue.poll(); if (request == null) { break; } final int ret = processWriteToChannel(request); if (ret <= 0) { if (ret < 0) { log.warn("NETLINK write() error: {}", CLibrary.strerror(Native.getLastError())); } break; } } } finally { expireOldRequests(); dispatcher.endBatch(); } } private int processWriteToChannel(final NetlinkRequest request) { if (request == null) { return 0; } ByteBuffer outBuf = request.releaseRequestPayload(); if (outBuf == null) { return 0; } int seq = writeSeqToNetlinkRequest(request, outBuf); if (request.hasCallback()) { pendingRequests.put(seq, request); } log.trace("Sending message for id {}", seq); int bytes = 0; try { bytes = channel.write(outBuf); if (request.hasCallback()) { expirationQueue.add(request); } } catch (IOException e) { log.error("Error writing to channel: {}", e.getMessage()); } return bytes; }
wrList_recv.add(recvWR); VerbsTools commRdma = new VerbsTools(context, compChannel, qp, cq); commRdma.initSGRecv(wrList_recv); RdmaConnParam connParam = new RdmaConnParam(); connParam.setRetry_count((byte) 2); ret = idPriv.connect(connParam); if (ret < 0){ System.out.println("VerbsClient::connect failed"); return; } cmEvent = cmChannel.getCmEvent(-1); if (cmEvent == null){ System.out.println("VerbsClient::cmEvent null"); return; } else if (cmEvent.getEvent() != RdmaCmEvent.EventType.RDMA_CM_EVENT_ESTABLISHED.ordinal()) {
RdmaCmId connId = cmEvent.getConnIdPriv(); if (connId == null){ System.out.println("VerbsServer::connId null"); return; } //get the device context of the new connection, typically the same as with the server id IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } // Query for on demand paging memory prefecth support int rcOdpCaps = context.queryOdpSupport(); if (rcOdpCaps == -1){ System.out.println("VerbsServer::On demand paging is not supported for this device"); } //create a new protection domain, we will use the pd later when registering memory IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } //the comp channel is used to get CQ notifications IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; }
if (qp == null) { System.out.println("VerbsServer::qp null"); return; } int buffercount = 3; int buffersize = 100; ByteBuffer buffers[] = new ByteBuffer[buffercount]; IbvMr mrlist[] = new IbvMr[buffercount]; int access = IbvMr.IBV_ACCESS_LOCAL_WRITE | IbvMr.IBV_ACCESS_REMOTE_WRITE | IbvMr.IBV_ACCESS_REMOTE_READ; RdmaConnParam connParam = new RdmaConnParam(); connParam.setRetry_count((byte) 2); ret = connId.accept(connParam); if (ret < 0) { System.out.println("VerbsServer::accept failed"); return; } cmEvent = cmChannel.getCmEvent(-1); if (cmEvent.getEvent() != RdmaCmEvent.EventType.RDMA_CM_EVENT_ESTABLISHED.ordinal()) { System.out.println("VerbsServer::wrong event received: " + cmEvent.getEvent()); return; }
System.out.println("VerbsServer::connId null"); return; //get the device context of the new connection, typically the same as with the server id IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } // Query for on demand paging memory prefecth support int rcOdpCaps = context.queryOdpSupport(); if (rcOdpCaps == -1){ System.out.println("VerbsServer::On demand paging is not supported for this device"); } //create a new protection domain, we will use the pd later when registering memory IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } //the comp channel is used to get CQ notifications IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; } //create a completion queue IbvCQ cq = context.createCQ(compChannel, 50, 0);
return; } IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } int rcOdpCaps = context.queryOdpSupport(); if (rcOdpCaps == -1){ System.out.println("VerbsServer::On demand paging is not supported for this device"); } IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; } IbvCQ cq = context.createCQ(compChannel, 50, 0); if (cq == null){
// have a chance to capture user identification info if (issuerANY != null) { try { byte[] issuerBytes = issuerANY.getEncoded(); X500Name issuerName = new X500Name(issuerBytes); CMS.debug(method + "revRequest issuer name = " + issuerName.toString()); // capture issuer principal to be checked against // cert issuer principal later in CMCOutputTemplate auditContext.put(SessionContext.CMC_ISSUER_PRINCIPAL, issuerName); } catch (Exception e) { // Handle the exception appropriately } } //authToken.set("uid", uid); //authToken.set("userid", userid); } // ... else { CMS.debug(method + "numReqs not 0, assume enrollment request"); // enrollment request // reset value of auditReqType auditReqType = SIGNED_AUDIT_ENROLLMENT_REQUEST_TYPE; X509CertInfo[] certInfoArray = new X509CertInfo[numReqs]; String[] reqIdArray = new String[numReqs]; }
public ASN1Value create_EPKI_with_PBE_SHA1_DES3_CBC(CryptoToken token, PrivateKey privateKey, Password password) throws Exception { byte[] salt = new byte[16]; random.nextBytes(salt); return EncryptedPrivateKeyInfo.createPBE( PBEAlgorithm.PBE_SHA1_DES3_CBC, password, salt, 100000, new PasswordConverter(), privateKey, token ); } public ASN1Value create_EPKI_with_PBE_PKCS5_PBES2(CryptoToken token, PrivateKey privateKey, Password password) throws Exception { CryptoStore store = token.getCryptoStore(); byte[] bytes = store.getEncryptedPrivateKeyInfo( new PasswordConverter(), password, privateKey, token ); return EncryptedPrivateKeyInfo.getInstance(bytes); }
public void performCollectionAndGetResult(String requestId, JsonObject feature, Handler<AsyncResult<CollectorJobResult>> resultHandler) { dcs.performCollectionAndGetResult(requestId, feature, res -> resultHandler.handle(checkForError(res))); }
package info.pascalkrause.vertx.datacollector.client.error; import info.pascalkrause.vertx.datacollector.client.error.DataCollectorError; public class QueueLimitReached extends DataCollectorError { private static final long serialVersionUID = 1L; }
package info.pascalkrause.vertx.datacollector.job; import io.vertx.core.AsyncResult; import io.vertx.core.Future; import io.vertx.core.Handler; import io.vertx.core.json.JsonObject; /** * A generic interface which must be implemented to run the collection job inside the CollectorJobExecutor worker pool. */ public interface CollectorJob { /** * This method should be used to create a Future that contains the collection logic. The Future will be executed in * a worker thread pool, which allows blocking operations inside. * * @param requestId A request id to identify the collection request. * @param feature A JSON object to pass attributes and properties which are needed for the collection process. * @return A Handler with the Future which contains the collection logic. */ public Handler<Future<CollectorJobResult>> collect(String requestId, JsonObject feature); /** * This method will be called after the {@link #collect(String, JsonObject)} and returns a Future which can be used * inside the future. * * @param result The result of the collection job. */ public void handleResult(AsyncResult<CollectorJobResult> result); }
public Handler<Future<CollectorJobResult>> postCollectAction(AsyncResult<CollectorJobResult> result) { return new Handler<Future<CollectorJobResult>>() { @Override public void handle(Future<CollectorJobResult> future) { // Perform post collect action here } }; }
```java public class CollectorJobResult { private static final String KEY_ERROR = "error"; private JsonObject data; public CollectorJobResult(JsonObject data) { this.data = data; } public Optional<Error> getError() { return Error.fromJson(data.getJsonObject(KEY_ERROR)); } public JsonObject toJson() { return data; } @Override public int hashCode() { return data.hashCode(); } @Override public boolean equals(Object obj) { if (obj instanceof CollectorJobResult) { return hashCode() == obj.hashCode(); } return false; } @Override public String toString() { return data.toString(); } } ```
public static final String METRIC_TOTAL_JOBS_COUNT = "totalJobsCount"; private final Counter totalJobsCounter; public static final String METRIC_TOTAL_JOBS_FAILED = "totalJobsFailed"; private final Counter totalJobsFailed; public static final String METRIC_TOTAL_JOBS_SUCCEEDED = "totalJobsSucceeded"; private final Counter totalJobsSucceeded; public static final String METRIC_TOTAL_JOBS_EXCEPTION = "totalJobsException"; private final Counter totalJobsException; private final MetricRegistry metricRegistry; private Map<String, AtomicLong> qualityMap = new ConcurrentHashMap<>(); private Map<String, AtomicLong> errorMap = new ConcurrentHashMap<>(); private Map<String, Object> sortDescendingAndSlice(Map<String, AtomicLong> unsorted, long maxEntries) { return unsorted.entrySet().stream() .map(e -> new SimpleEntry<String, Long>(e.getKey(), e.getValue().get())) .sorted(Map.Entry.comparingByValue()) .limit(maxEntries) .collect(Collectors.toMap(e -> e.getKey(), e -> e.getValue(), (oldValue, newValue) -> oldValue, LinkedHashMap::new)); }
public void registerQueueMetrics(AtomicInteger currentQueueSize, int queueSize) { metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_MAX_SIZE), (Gauge<Integer>) () -> queueSize); metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_FREE), (Gauge<Integer>) () -> queueSize - currentQueueSize.get()); metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_OCCUPIED), (Gauge<Integer>) () -> currentQueueSize.get()); }
public void registerTotalMetrics(AsyncResult<CollectorJobResult> postResult) { totalJobsCounter.inc(); if (postResult.succeeded()) { final Optional<Error> e = postResult.result().getError(); if (e.isPresent()) { totalJobsFailed.inc(); addOrIncrease(errorMap, e.get().getName()); } else { totalJobsSucceeded.inc(); addOrIncrease(qualityMap, postResult.result().getQuality()); } } else { totalJobsException.inc(); } }
public static double ceil(double d) { final long bits = Double.doubleToRawLongBits(d); int highBits = (int) (bits >>> 32); // high word of d int lowBits = (int) bits; // low word of d int exp = ((highBits >> 20) & 0x7ff) - 0x3ff; // value of exponent /* negative exponent */ if (exp < 0) { if (HUGE + d > 0.0) { if (highBits < 0) { // if |d| < 1 return -0 highBits = 0x80000000; } else if ((highBits | lowBits) != 0) { // raise inexact if d != 0, this is ignored by Java highBits = 0x3ff00000; // return 1 } lowBits = 0; } } /* exponent in range [0, 20) */ else if (exp < 0x014) { i = (0x000fffff) >> exp; } return d; // d is integral } /* exponent in range [21,51] */ else { i = (0xffffffff) >> (exp - 0x014); /* d is integral */ if ((lowBits & i) == 0) { return d; } /* raise inexact flag: this is ignored by Java */ if (HUGE + d > 0.0) { if (highBits > 0) { if (exp == 0x014) { highBits +=1; } else { int j = lowBits + (0x1 << (0x34 - exp)); // careful, should be unsigned if (j < lowBits) { highBits += 0x1; // carry occurred } lowBits = j; } } lowBits &= (~i); } } return Double.longBitsToDouble(((long)highBits << 32) | lowBits); * Copyright 2009-2013 by The Regents of the University of California * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except
private CollectorJobResult generateResult(String requestId, CollectorJobResult.Error error) { return new CollectorJobResult(requestId, "test-source", "test-quality", "test-created", new JsonObject(), error); }
} catch (final InterruptedException e) { e.printStackTrace(); } if (Objects.nonNull(stopper) && feature.containsKey(KEY_STOP)) { stopper.await(TimeUnit.SECONDS.toMillis(1)); } if (feature.containsKey(KEY_UNHANDLED_EXCEPTION)) { throw new RuntimeException("Some unhandled exception"); } else if (feature.containsKey(KEY_HANDLED_EXCEPTION)) { fut.fail(new RuntimeException("Some handled exception")); } else { fut.complete(jobResult); }
import java.util.Collection; import java.util.logging.Logger; import javax.net.ssl.X509TrustManager; import org.mozilla.jss.CryptoManager; import org.mozilla.jss.CryptoManager.NotInitializedException; import netscape.security.x509.X509CertImpl; public class PKITrustManager implements X509TrustManager { final static Logger logger = Logger.getLogger(PKITrustManager.class.getName()); @Override public void checkClientTrusted(X509Certificate[] certs, String authType) throws CertificateException { logger.fine("PKITrustManager: checkClientTrusted(" + authType + "):"); for (X509Certificate cert : certs) { logger.fine("PKITrustManager: - " + cert.getSubjectDN()); } try { CryptoManager manager = CryptoManager.getInstance(); if (certs != null && certs.length > 0) { X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLClient)) { throw new CertificateException("Missing SSLClient certificate usage: " + cert.getSubjectDN()); } } logger.fine("PKITrustManager: certificate is valid"); } catch (CertificateException e) { throw e; } catch (Exception e) { // Handle exception } } // Other methods... }
private static void waitForShadowProjectUpdated(String parentProjectName) { for (int i = 1; i < 5000 && (TmfProjectModelHelper.getShadowProject(parentProjectName).exists()); i *= 2) { delay(i); } } private boolean mSentLowBatteryBroadcast = false; public BatteryService(Context context) { mContext = context; mBatteryStats = BatteryStatsService.getService(); mLowBatteryWarningLevel = mContext.getResources().getInteger(com.android.internal.R.integer.config_lowBatteryWarningLevel); mLowBatteryCloseWarningLevel = mContext.getResources().getInteger(com.android.internal.R.integer.config_lowBatteryCloseWarningLevel); mUEventObserver.startObserving("SUBSYSTEM=power_supply"); // set initial status update(); } private final boolean isPowered() { return (mBatteryStatus == BatteryManager.BATTERY_STATUS_CHARGING || mBatteryStatus == BatteryManager.BATTERY_STATUS_UNKNOWN); } try { CryptoManager manager = CryptoManager.getInstance(); X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLClient)) { throw new CertificateException("Missing SSLClient certificate usage: " + cert.getSubjectDN()); } logger.fine("PKITrustManager: certificate is valid"); } catch (CertificateException e) { throw e; } catch (Exception e) { throw new CertificateException(e); } @Override public void checkServerTrusted(X509Certificate[] certs, String authType) throws CertificateException { logger.fine("PKITrustManager: checkServerTrusted(" + authType + "):"); for (X509Certificate cert : certs) { logger.fine("PKITrustManager: - " + cert.getSubjectDN()); } try { CryptoManager manager = CryptoManager.getInstance(); X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLServer)) { throw new CertificateException("Missing SSLServer certificate usage: " + cert.getSubjectDN()); } } catch (CertificateException e) { throw e; } catch (Exception e) { throw new CertificateException(e); } }
} } if (aid != null && adn != null) { throw new Exception("--issuer-id and --issuer-dn options are mutually exclusive"); } MainCLI mainCLI = (MainCLI)parent.getParent(); File certDatabase = mainCLI.certDatabase; String password = mainCLI.config.getCertPassword(); if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)) { csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)) { csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else { throw new Exception("Invalid algorithm specified."); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate
MainCLI mainCLI = (MainCLI)parent.getParent(); File certDatabase = mainCLI.certDatabase; String password = mainCLI.config.getCertPassword(); if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else{ throw new Exception("Invalid algorithm specified."); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate mainCLI.init(); client = getClient(); String encoded; if (transportCertFilename == null) { // ... } else { // ... } } else { throw new Exception("Invalid request type specified."); } // ...
if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else{ throw new Exception("Invalid algorithm: " + algorithm); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate mainCLI.init(); client = getClient(); String encoded; if (transportCertFilename == null) { SystemCertClient certClient = new SystemCertClient(client, "ca"); encoded = certClient.getTransportCert().getEncoded(); } else { encoded = new String(Files.readAllBytes(Paths.get(transportCertFilename))); } // rest of the code... }
CACertCLI.printCertRequestInfos(infos); public String generatePkcs10Request(File certDatabase, String password, String algorithm, Integer length, String curve, String subjectDN) throws Exception { File csrFile = File.createTempFile("pki-client-cert-request-", ".csr", certDatabase); csrFile.deleteOnExit(); List<String> commands = new ArrayList<>(); commands.add("/usr/bin/PKCS10Client"); commands.add("-d"); commands.add(certDatabase.getAbsolutePath()); commands.add("-p"); commands.add(password); commands.add("-a"); commands.add(algorithm); if (length != null) { commands.add("-l"); commands.add(length.toString()); } if (curve != null) { commands.add("-c"); commands.add(curve); } commands.add("-o"); commands.add(csrFile.getAbsolutePath()); commands.add("-n"); commands.add(subjectDN); try { runExternal(commands.toArray(new String[0])); } catch (Exception e) { throw new Exception("CSR generation failed", e); } if (verbose) { System.out.println("CSR generated: " + csrFile); } return new String(Files.readAllBytes(csrFile.toPath())); } public String generateCrmfRequest(X509Certificate transportCert, String subjectDN, boolean attributeEncoding, String algorithm, int length, String curve, boolean sslECDH, boolean temporary, ...) { // existing code }
int sd_ee_port = config.getInteger("securitydomain.httpseeport", -1); MultivaluedMap<String, String> content = new MultivaluedHashMap<String, String>(); content.putSingle("requestor_name", sysType + "-" + machineName + "-" + securePort); logger.debug("configRemoteCert: subsystemCert: setting profileId to: " + profileId); String actualProfileId = request.getSystemCertProfileID(certTag, profileId); logger.debug("configRemoteCert: subsystemCert: calculated profileId: " + actualProfileId); content.putSingle("profileId", actualProfileId); content.putSingle("cert_request_type", "pkcs10"); content.putSingle("cert_request", b64Request); content.putSingle("xmlOutput", "true"); content.putSingle("sessionID", session_id); cert = CertUtil.createRemoteCert(sd_hostname, sd_ee_port, content, response); if (cert == null) { throw new IOException("Error: remote certificate is null"); } else if (v.equals("sdca")) { String ca_hostname = ""; int ca_port = -1; try { // code omitted for brevity } catch (Exception e) { // code omitted for brevity } }
try (InputStream in = new BufferedInputStream(getInputStream())) { // TODO: expose XStream the driver from XStream if (nullOut) { return ((XStream2) xs).unmarshal(DEFAULT_DRIVER.createReader(in), o, null, true); } else { return xs.unmarshal(DEFAULT_DRIVER.createReader(in), o); } } catch (RuntimeException | Error e) { throw new IOException("Unable to read " + file, e); } private InputStream getInputStream() throws IOException { InputStream is = Files.newInputStream(file.toPath()); if (file.getName().toLowerCase().endsWith(".gz")) { is = new GZIPInputStream(is); } return is; } public void write(Object o) throws IOException { mkdirs(); AtomicFileWriter w = new AtomicFileWriter(file); try { w.write("<?xml version='1.1' encoding='UTF-8'?>\n"); beingWritten.put(o, null); writing.set(file); try { xs.toXML(o, w); } finally { beingWritten.remove(o); } } finally { w.close(); } }
public char[] getSharedToken(BigInteger serial) throws EBaseException { String method = "SharedSecret.getSharedToken(BigInteger serial): "; CMS.debug(method + serial.toString()); ICertRecord record = null; try { record = certRepository.readCertificateRecord(serial); } catch (EBaseException ee) { CMS.debug(method + "Exception: " + ee.toString()); throw ee; } MetaInfo metaInfo = (MetaInfo) record.get(ICertRecord.ATTR_META_INFO); if (metaInfo == null) { throw new EBaseException("cert record metaInfo not found"); } return metaInfo.getSharedToken(); }
private static Properties readProperties() throws IOException { FileInputStream in = new FileInputStream("/etc/pki/pki.conf"); Properties props = new Properties(); props.load(in); return props; } public void setVerbose(boolean verbose) { this.verbose = verbose; } public boolean isVerbose() { return verbose; } public KeyPair generateECCKeyPair(CryptoToken token, String curve, boolean sslECDH, boolean temporary, int sensitive, int extractable) throws Exception { org.mozilla.jss.crypto.KeyPairGeneratorSpi.Usage[] usagesMaskECDH = { org.mozilla.jss.crypto.KeyPairGeneratorSpi.Usage.SIGN, ... }; // Rest of the code } if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)) { csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)) { csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else { throw new Exception("Invalid algorithm: " + algorithm); } mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { mainCLI.init(); client = getClient(); String encoded; if (transportCertFilename == null) { SystemCertClient certClient = new SystemCertClient(client, "ca"); encoded = certClient.getTransportCert().getEncoded(); } else { encoded = new String(Files.readAllBytes(Paths.get(transportCertFilename))); } // Rest of the code } public static void checkConfiguration(byte[] in, boolean requireProfileId, boolean requireDisabled) throws PKIException { Properties p = new Properties(); try { p.load(new ByteArrayInputStream(in)); } catch (IOException e) { throw new PKIException("Failed to parse profile configuration: " + e.toString()); } if (requireProfileId && p.getProperty("profileId") == null) { throw new PKIException("Missing profileId property in profile data."); } String enabled = p.getProperty("enable"); if (requireDisabled && Boolean.valueOf(enabled)) { throw new PKIException("Cannot edit profile
private static final Pattern PLUGIN_PERMISSION_NAME_IN_CONFIG_PATTERN = Pattern.compile("^" + "plugin-" + PLUGIN_NAME_PATTERN_STRING + "-[a-zA-Z]+" + "$"); private static final Pattern PLUGIN_NAME_PATTERN = Pattern.compile("^" + PLUGIN_NAME_PATTERN_STRING + "$"); private final DynamicMap<CapabilityDefinition> capabilityDefinitions; private final DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions; @Inject private PluginPermissionsUtil(DynamicMap<CapabilityDefinition> capabilityDefinitions, DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions) { this.capabilityDefinitions = capabilityDefinitions; this.pluginProjectPermissionDefinitions = pluginProjectPermissionDefinitions; } /** * Collects all the plugin declared capabilities. */
private PluginPermissionsUtil(DynamicMap<CapabilityDefinition> capabilityDefinitions, DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions) { this.capabilityDefinitions = capabilityDefinitions; this.pluginProjectPermissionDefinitions = pluginProjectPermissionDefinitions; }
public boolean testOrFalse(ProjectPermission perm) { try { return test(perm); } catch (PermissionBackendException e) { logger.warn("Cannot test " + perm + "; assuming false", e); return false; } } public BooleanCondition testCond(ProjectPermission perm) { return new PermissionBackendCondition.ForProject(this, perm); } public abstract Map<String, Ref> filter(Map<String, Ref> refs, Repository repo, RefFilterOptions opts) throws PermissionBackendException; @AutoValue public abstract static class RefFilterOptions { public abstract boolean filterMeta(); public abstract boolean filterTagsSeparately(); public abstract Builder toBuilder(); }
public Map<String, Ref> filter(Map<String, Ref> refs, Repository repo, RefFilterOptions opts) throws PermissionBackendException { if (refFilter == null) { refFilter = refFilterFactory.create(ProjectControl.this); } return refFilter.filter(refs, repo, opts); } private boolean can(CoreOrPluginProjectPermission perm) throws PermissionBackendException { if (perm instanceof ProjectPermission) { return can((ProjectPermission) perm); } else if (perm instanceof PluginProjectPermission) { return false; } throw new PermissionBackendException(perm.describeForException() + " unsupported"); } private boolean can(ProjectPermission perm) throws PermissionBackendException { switch (perm) { case ACCESS: return user.isInternalUser() || isOwner() || canPerformOnAnyRef(Permission.READ); case READ: return allRefsAreVisible(Collections.emptySet()); case CREATE_REF: return canAddRefs(); case CREATE_TAG_REF: return canAddTagRefs(); case CREATE_CHANGE: return canCreateChanges(); default: return false; } }
private final Timer1<String> latencyPerPush; private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("number of changes uploaded in a single push.").setCumulative(), Field.ofEnum(ResultChangeIds.Key.class, "type", "type of update (replace, create, autoclose)") ); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description("average delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)") ); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)") ); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate() ); }
Field.ofEnum(ResultChangeIds.Key.class, "type", "type of update (replace, create, autoclose)")); latencyPerChange = metricMaker.newTimer("receivecommits/latency", new Description("average delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer("receivecommits/push_latency", new Description("delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); timeouts = metricMaker.newCounter("receivecommits/timeout", new Description("rate of push timeouts").setRate()); private final Metrics metrics; private final ReceiveCommits receiveCommits; private final ResultChangeIds resultChangeIds; private final PermissionBackend.ForProject perm; private final ReceivePack receivePack; private final ExecutorService executor; private final RequestScopePropagator scopePropagator;
metricMaker.newTimer( "receivecommits/latency", new Description("average delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)") ); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)") ); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate() ); private final Metrics metrics; private final ReceiveCommits receiveCommits; private final ResultChangeIds resultChangeIds; private final PermissionBackend.ForProject perm; private final ReceivePack receivePack; private final ExecutorService executor; private final RequestScopePropagator scopePropagator; private final ReceiveConfig receiveConfig; private final ContributorAgreementsChecker contributorAgreements; private final long timeoutMillis; private final ProjectState projectState; private final IdentifiedUser user;
List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); metrics.changes.record(ResultChangeIds.Key.CREATED, created.size()); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(ResultChangeIds.Key.REPLACED, replaced.size()); totalChanges += replaced.size() + created.size(); if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; } else if (totalChanges > 0) { pushType = ResultChangeIds.Key.AUTOCLOSED.name(); } else { pushType = "NORMAL"; } if (totalChanges > 0 && !pushType.equals("NORMAL")) { metrics.latencyPerChange.record(pushType, deltaNanos / totalChanges, NANOSECONDS); } metrics.latencyPerPush.record(pushType, deltaNanos, NANOSECONDS);
Optional<Checker> checker = getChecker(checkerUuid); checkState(checker.isPresent(), "Tried to get a non-existing test checker as CheckerInfo"); return checkerJson.format(checker.get()); public TestCheckerUpdate.Builder forUpdate() { return TestCheckerUpdate.builder(this::updateChecker); } private void updateChecker(TestCheckerUpdate testCheckerUpdate) throws Exception { CheckerUpdate checkerUpdate = toCheckerUpdate(testCheckerUpdate); checkersUpdate.updateChecker(checkerUuid, checkerUpdate); if (testCheckerUpdate.forceInvalidConfig().orElse(false)) { try (Repository repo = repoManager.openRepository(allProjectsName)) { new TestRepository<>(repo) .branch(CheckerRef.refsCheckers(checkerUuid)) .commit() .add(CheckerConfig.CHECKER_CONFIG_FILE, "invalid-config") .create(); } } } private CheckerUpdate toCheckerUpdate(TestCheckerUpdate checkerUpdate) { CheckerUpdate.Builder builder = CheckerUpdate.builder(); checkerUpdate.name().ifPresent(builder::setName); checkerUpdate.description().ifPresent(builder::setDescription); checkerUpdate.url().ifPresent(builder::setUrl); }
import com.google.gerrit.reviewdb.client.Project; import java.util.Arrays; import java.util.Optional; import java.util.stream.Stream; @AutoValue public abstract class TestCheckerUpdate { public abstract Optional<String> name(); public abstract Optional<String> description(); public abstract Optional<String> url(); public abstract Optional<Project.NameKey> repository(); public abstract Optional<CheckerStatus> status(); public abstract Optional<ImmutableSortedSet<BlockingCondition>> blockingConditions(); public abstract Optional<String> query(); public abstract boolean forceInvalidConfig(); // Changed from Optional<Boolean> to boolean abstract ThrowingConsumer<TestCheckerUpdate> checkerUpdater(); public static Builder builder(ThrowingConsumer<TestCheckerUpdate> checkerUpdater) { return new AutoValue_TestCheckerUpdate.Builder().checkerUpdater(checkerUpdater); } @AutoValue.Builder public abstract static class Builder { public abstract Builder name(String name); public abstract Builder description(String description); public Builder clearDescription() { return description(""); } public abstract Builder url(String url); public Builder clearUrl() { return url(""); } public abstract Builder repository(Project.NameKey repository); public abstract Builder forceInvalidConfig(boolean forceInvalidConfig); // Changed from Optional<Boolean> to boolean public abstract TestCheckerUpdate build(); } }
checkOperations.newCheck(key).setState(CheckState.RUNNING).upsert(); checkerOperations.checker(checkerUuid).forUpdate().forceInvalidConfig().update(); exception.expect(RestApiException.class); exception.expectMessage("Cannot retrieve checker " + checkerUuid); checksApiFactory.revision(patchSetId).id(checkerUuid.toString()).get(); @Test public void getNonExistingCheckFails() throws Exception { exception.expect(ResourceNotFoundException.class); exception.expectMessage("Not found: non-existing"); checksApiFactory.revision(patchSetId).id("non-existing").get(); }
parseTag(commit); if (branch == null) { branch = parseBranch(commit); } PatchSet.Id psId = parsePatchSetId(commit); PatchSetState psState = parsePatchSetState(commit); if (psState != null) { patchSetStates.putIfAbsent(psId, psState); if (psState == PatchSetState.DELETED) { deletedPatchSets.add(psId); } } Account.Id accountId = parseIdent(commit); ownerId = Optional.ofNullable(accountId); Account.Id realAccountId = parseRealAccountId(commit, accountId); if (changeId == null) { changeId = parseChangeId(commit); } String currSubject = parseSubject(commit); if (currSubject != null) { subject = subject != null ? subject : currSubject; originalSubject = currSubject; } parseChangeMessage(psId, accountId, realAccountId, commit, ts); topic = Optional.ofNullable(parseTopic(commit));
@Singleton private static class Metrics { private final Histogram1<ResultChangeIds.Key> changes; private final Timer1<String> latencyPerChange; private final Timer1<String> latencyPerPush; private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("number of changes uploaded in a single push.") .setCumulative(), Field.ofEnum(ResultChangeIds.Key.class, "type", "type of push (create/replace, autoclose)")); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description("processing delay per push, averaged over the updated changes in a push.") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("processing delay per push.") .setUnit(Units.MILLISECONDS) .setCumulative()); timeouts = metricMaker.newCounter( "receivecommits/timeouts", new Description("number of timeouts during push processing.") .setCumulative()); } public void flush() { receiveCommits.getMessageSender().flush(); } }
private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("Number of changes uploaded in a single push.") .setCumulative(), Field.ofEnum(ResultChangeIds.Key.class, "type", "Type of push (replace, create, autoclose)") ); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description("Processing delay per push, averaged over the updated changes in a push.") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "Type of push (create/replace, autoclose)") ); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("Processing delay for a single push") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "Type of push (create/replace, autoclose, normal)") ); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("Rate of push timeouts") .setRate() ); }
private static ProjectAccessInput createAccessInput(String accessSection, String permissionName) { ProjectAccessInput accessInput = new ProjectAccessInput(); PermissionRuleInfo ruleInfo = new PermissionRuleInfo(PermissionRuleInfo.Action.ALLOW, false); PermissionInfo email = new PermissionInfo(null, null); email.rules = ImmutableMap.of(SystemGroupBackend.REGISTERED_USERS.get(), ruleInfo); AccessSectionInfo accessSectionInfo = new AccessSectionInfo(); accessSectionInfo.permissions = ImmutableMap.of(permissionName, email); accessInput.add = ImmutableMap.of(accessSection, accessSectionInfo); return accessInput; }
public void isPluginPermissionNameValid() { ImmutableList<String> validPluginPermissions = ImmutableList.of("plugin-foo-a", "plugin-foo-a-b"); for (String permission : validPluginPermissions) { assertThat(isPluginPermission(permission)) .named("valid plugin permission: %s", permission) .isTrue(); } }
public void isPluginPermissionNameInvalidReturnFalse() { ImmutableList<String> validPluginPermissions = ImmutableList.of( "create", "label-Code-Review", "plugin-foo", "plugin-foo", "plugin-foo-a-", "plugin-foo-a1" ); for (String permission : validPluginPermissions) { assertThat(isPluginPermission(permission)) .named("invalid plugin permission: %s", permission) .isFalse(); } }
public void testIsPluginPermissionInvalidNameReturnFalse() { ImmutableList<String> invalidPluginPermissions = ImmutableList.of( "create", "label-Code-Review", "plugin-foo", "plugin-foo", "plugin-foo-a-", "plugin-foo-a1" ); for (String permission : invalidPluginPermissions) { assertThat(isPluginPermission(permission)) .named("invalid plugin permission: %s", permission) .isFalse(); } }
import com.google.common.base.Objects; import com.google.common.base.Preconditions; public class BoolTestPredicate extends Predicate { private final String UNKNOWN_LITERAL = "UNKNOWN"; private final boolean isNegated_; public BoolTestPredicate(Expr e, LiteralExpr v, boolean isNegated) { super(); this.isNegated_ = isNegated; Preconditions.checkNotNull(e); Preconditions.checkNotNull(v); children_.add(e); children_.add(v); } protected BoolTestPredicate(BoolTestPredicate other) { super(other); isNegated_ = other.isNegated_; } public boolean isNegated() { return isNegated_; } @Override public boolean equals(Object obj) { // implementation } } public class LttngRelayDConnector_NOTSUPPORTED implements ILttngRelaydConnector { @Override public List<SessionResponse> getSessions() throws IOException { throw new UnsupportedOperationException(); } @Override public AttachSessionResponse attachToSession(SessionResponse lttngViewerSession) throws IOException { throw new UnsupportedOperationException(); } @Override public String getMetadata(AttachSessionResponse attachedSession) throws IOException { throw new UnsupportedOperationException(); } @Override public TracePacketResponse getNextPacket(StreamResponse stream) throws IOException { throw new UnsupportedOperationException(); } @Override public TracePacketResponse getPacketFromStream(IndexResponse index, long id) throws IOException { throw new UnsupportedOperationException(); } @Override public List<StreamResponse> getNewStreams() throws IOException { throw new UnsupportedOperationException(); } } public class MyClass { // other code public void configure() { bind(CapabilityDefinition.class) .annotatedWith(Exports.named(TEST_PLUGIN_CAPABILITY)) .toInstance(new CapabilityDefinition() { @Override public String getDescription() { return "A Plugin Capability"; } }); bind(PluginProjectPermissionDefinition.class) .annotatedWith(Exports.named(TEST_PLUGIN_PROJECT_PERMISSION)) .toInstance(new PluginProjectPermissionDefinition() { @Override public String getDescription() { return "A Plugin Project Permission"; } }); } // other code @Test public void setAccess_addPluginCapability_succeed() throws Exception { String pluginCapability = TEST_PLUGIN_NAME + "-"
} @Override public void addRelatedLink(String issueKey, URL relatedUrl, String description) throws IOException { addComment( issueKey, "Related URL: " + createLinkForWebui(relatedUrl.toExternalForm(), description)); } @Override public void addValueToField(String issueKey, String value, String fieldId) throws IOException { execute( () -> { log.debug("Adding value {} to field {} on issue {}", value, fieldId, issueKey); jiraClient.addValueToField(issueKey, value, fieldId); return null; }); } @Override public void performAction(String issueKey, String actionName) throws IOException { execute( () -> { log.debug("Performing action {} on issue {}", actionName, issueKey); doPerformAction(issueKey, actionName); return issueKey; }); } private void doPerformAction(String issueKey, String actionName) throws IOException, InvalidTransitionException { log.debug("Trying to perform action: {} on issue {}", actionName, issueKey);
private final Checks checks; private final Provider<ChecksUpdate> checksUpdate; private final CheckJson checkJson; @Inject PostCheck(Checks checks, @UserInitiated Provider<ChecksUpdate> checksUpdate, CheckJson checkJson) { this.checks = checks; this.checksUpdate = checksUpdate; this.checkJson = checkJson; } @Override public CheckInfo apply(RevisionResource rsrc, CheckInput input) throws OrmException, IOException, RestApiException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { throw new BadRequestException("checkerUuid is required"); } CheckKey key = CheckKey.create(rsrc.getProject(), rsrc.getPatchSet().getId(), CheckerUuid.parse(input.checkerUuid)); Optional<Check> check = checks.getCheck(key); if (!check.isPresent()) { if (input.state == null) { throw new BadRequestException("state is required on creation"); } Check updatedCheck = checksUpdate.get().createCheck(key, toCheckUpdate(input)); // rest of the code } // rest of the code }
import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.plugins.checks.PostCheck; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; @Singleton public class UpdateCheck implements RestModifyView<CheckResource, CheckInput> { private final PostCheck postCheck; @Inject UpdateCheck(PostCheck postCheck) { this.postCheck = postCheck; } @Override public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, OrmException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().toString(); } else if (!checkResource.getCheckerUuid().toString().equals(input.checkerUuid)) { throw new BadRequestException( String.format( "checkerUuid must either be null or the same as on the resource:\n" + "the check resource belongs to checker %s," + " but in the input checker %s was specified", checkResource.getCheckerUuid(), input.checkerUuid ) ); } // Rest of the code } }
private static int getInt(Config cfg, String section, String name, int defaultValue) { try { return cfg.getInt(section, name, defaultValue); } catch (IllegalArgumentException e) { multisiteLog.error("invalid value for {}; using default value {}", name, defaultValue); multisiteLog.debug("Failed to retrieve integer value: {}", e.getMessage(), e); return defaultValue; } }
Buggy Code: public CachedPage(int cpid, ByteBuffer buffer, IPageReplacementStrategy pageReplacementStrategy) { this.cpid = cpid; this.buffer = buffer; this.pageReplacementStrategy = pageReplacementStrategy; pinCount = new AtomicInteger(); dirty = new AtomicBoolean(); latch = new ReentrantReadWriteLock(true); replacementStrategyObject = pageReplacementStrategy.createPerPageStrategyObject(cpid); dpid = -1; valid = false; confiscated = new AtomicBoolean(false); queueInfo = null; ctorStack = new Throwable().getStackTrace(); } Fixed Code: public CachedPage(int cpid, ByteBuffer buffer, IPageReplacementStrategy pageReplacementStrategy) { this.cpid = cpid; this.buffer = buffer; this.pageReplacementStrategy = pageReplacementStrategy; pinCount = new AtomicInteger(); dirty = new AtomicBoolean(); latch = new ReentrantReadWriteLock(true); replacementStrategyObject = pageReplacementStrategy.createPerPageStrategyObject(cpid); dpid = -1; valid = false; confiscated = new AtomicBoolean(false); queueInfo = null; }
private static boolean getBoolean(Config cfg, String section, String name, boolean defaultValue) { try { return cfg.getBoolean(section, name, defaultValue); } catch (IllegalArgumentException e) { multisiteLog.error("invalid value for {}; using default value {}", name, defaultValue); multisiteLog.debug("Failed to retrieve boolean value: {}", e.getMessage(), e); return defaultValue; } }
import com.googlesource.gerrit.plugins.multisite.forwarder.ForwarderModule; import com.googlesource.gerrit.plugins.multisite.forwarder.broker.BrokerForwarderModule; import com.googlesource.gerrit.plugins.multisite.index.IndexModule; import com.googlesource.gerrit.plugins.multisite.kafka.consumer.KafkaConsumerModule; import com.googlesource.gerrit.plugins.multisite.kafka.router.ForwardedEventRouterModule; import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.FileReader; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Paths; import java.util.UUID; public class Module extends AbstractModule { private final Configuration config; @Inject public Module(Configuration config) { this.config = config; } @Override protected void configure() { bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(MultiSiteLogFile.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } install(new LifecycleModule() { @Override protected void configure() { listener().to(MultiSiteLogFile.class); } }); } }
protected void configure() { bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(MultiSiteLogFile.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class); }
// You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.broker.kafka; import static com.googlesource.gerrit.plugins.multisite.MultiSiteLogFile.multisiteLog; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.InstanceId; import com.googlesource.gerrit.plugins.multisite.broker.BrokerSession; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.UUID; import java.util.concurrent.ExecutionException; import java.util.concurrent.Future; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; public class KafkaSession implements BrokerSession { private final Configuration properties; private final Producer<String, byte[]> producer; private final String instanceId; @Inject public KafkaSession(Configuration properties, InstanceId instanceId) { this.properties = properties; this.instanceId = instanceId.get(); this.producer = createProducer(); } private Producer<String, byte[]> createProducer() { return new KafkaProducer<>(properties.getKafkaConfig()); } @Override public void send(EventFamily eventFamily, byte[] event) { String topic = properties.getKafkaTopic(eventFamily); String key = UUID.randomUUID().toString(); ProducerRecord<String, byte[]> record = new ProducerRecord<>(topic, key, event); Future<RecordMetadata> future = producer.send(record); try { RecordMetadata metadata = future.get(); multisiteLog().atFine().log("Sent event to Kafka topic %s, partition %d, offset %d", metadata.topic(), metadata.partition(), metadata.offset()); } catch (InterruptedException | ExecutionException e) { multisiteLog().atSevere().withCause(e).
public void connect() { if (isOpen()) { return; } multisiteLog.info("Connect to {}...", properties.getKafka().getBootstrapServers()); setConnectionClassLoader(); producer = new KafkaProducer<>(properties.kafkaPublisher()); multisiteLog.info("Connection established."); }
Fixed Code: public void evict(CacheEntry entry) throws CacheNotFoundException { Cache<?, ?> cache = cacheMap.get(entry.getPluginName(), entry.getCacheName()); if (cache == null) { throw new CacheNotFoundException(entry.getPluginName(), entry.getCacheName()); } try { Context.setForwardedEvent(true); if (Constants.PROJECT_LIST.equals(entry.getCacheName())) { cache.invalidateAll(); multisiteLog.debug("Invalidated cache {}", entry.getCacheName()); } else { cache.invalidate(entry.getKey()); multisiteLog.debug("Invalidated cache {}[{}]", entry.getCacheName(), entry.getKey()); } } finally { Context.unsetForwardedEvent(); } }
Buggy Code: public CachedPage(int cpid, ByteBuffer buffer, IPageReplacementStrategy pageReplacementStrategy) { this.cpid = cpid; this.buffer = buffer; this.pageReplacementStrategy = pageReplacementStrategy; pinCount = new AtomicInteger(); dirty = new AtomicBoolean(); latch = new ReentrantReadWriteLock(true); replacementStrategyObject = pageReplacementStrategy.createPerPageStrategyObject(cpid); dpid = -1; valid = false; confiscated = new AtomicBoolean(false); queueInfo = null; ctorStack = new Throwable().getStackTrace(); } Fixed Code: public CachedPage(int cpid, ByteBuffer buffer, IPageReplacementStrategy pageReplacementStrategy) { this.cpid = cpid; this.buffer = buffer; this.pageReplacementStrategy = pageReplacementStrategy; pinCount = new AtomicInteger(); dirty = new AtomicBoolean(); latch = new ReentrantReadWriteLock(true); replacementStrategyObject = pageReplacementStrategy.createPerPageStrategyObject(cpid); dpid = -1; valid = false; confiscated = new AtomicBoolean(false); queueInfo = null; }
SourceAwareEventWrapper event = valueDeserializer.deserialize(consumerRecord.topic(), consumerRecord.value()); if (event.getHeader().getSourceInstanceId().equals(instanceId)) { multisiteLog.debug("Dropping event {} produced by our instanceId {}", event.toString(), instanceId.toString()); droppedEventListeners.forEach(l -> l.onEventDropped(event)); } else { try { multisiteLog.info("Header[{}] Body[{}]", event.getHeader(), event.getBody()); eventRouter.route(event.getEventBody(gsonProvider)); } catch (IOException e) { multisiteLog.error("Malformed event '{}': [Exception: {}]", event.getHeader().getEventType(), e); } catch (PermissionBackendException | OrmException e) { multisiteLog.error("Cannot handle message {}: [Exception: {}]", event.getHeader().getEventType(), e); } } catch (Exception e) { multisiteLog.error("Malformed event '{}': [Exception: {}]", new String(consumerRecord.value()), e); }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. // Copyright (C) 2018 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software
public static String stripEndSlash(String name) { name = LintUtils.getFormattedParameters("/$", name).get(0); return name; }
private static String strip(String name) { String projectName = ProjectUtil.stripGitSuffix(name); projectName = ProjectUtil.stripEndSlash(projectName); return projectName; }
@Test public void createProjectWithGitSuffix() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + ".git").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } @Test public void createProjectThatEndsWithSlash() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + "/").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } @Test public void createProjectThatContainsSlash() throws Exception { String newProjectName = name("newProject/newProject"); ProjectInfo p = gApi.projects().create(newProjectName).get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); }
assertHead(newProjectName, "refs/heads/master"); } public void createProjectThatEndsWithSlash() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + "/").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } public void createProjectThatContainsSlash() throws Exception { String newProjectName = name("newProject/newProject"); ProjectInfo p = gApi.projects().create(newProjectName).get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } @Test public void createProjectWithProperties() throws Exception { String newProjectName = name("newProject");
adminSshSession.assertFailure(); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNull(); } @Test public void withDotGit() throws Exception { String newGroupName = "newGroup"; adminRestSession.put("/groups/" + newGroupName); String newProjectName = "newProject"; adminSshSession.exec("gerrit create-project --branch master --owner " + newGroupName + " " + newProjectName + ".git"); adminSshSession.assertSuccess(); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertThat(projectState.getName()).isEqualTo(newProjectName); } @Test public void withEndSlash() throws Exception { String newGroupName = "newGroup"; adminRestSession.put("/groups/" + newGroupName); String newProjectName = "newProject"; adminSshSession.exec("gerrit create-project --branch master --owner " + newGroupName + " " + newProjectName + "/"); adminSshSession.assertSuccess(); }
} @VisibleForTesting void setReportSyntaxError(boolean value) { reportSyntaxError = value; } int getMinOwnerVoteLevel(ProjectState projectState, ChangeData c) { if (projectState == null) { logger.atSevere().log("Null projectState for change %s", getChangeId(c)); return minOwnerVoteLevel; } return getPluginConfig(projectState).getInt(MIN_OWNER_VOTE_LEVEL, minOwnerVoteLevel); } } enum EnforcementLevel { DISABLED, WARN, ENFORCE; static final String CONFIG_NAME = "ENFORCE_LEVEL"; }
protected Destination(Injector injector, RemoteSiteUser.Factory replicationUserFactory, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, GroupBackend groupBackend, ReplicationStateListener stateLog, GroupIncludeCache groupIncludeCache, DynamicItem<EventDispatcher> eventDispatcher, @Assisted DestinationConfiguration cfg) { config = cfg; this.eventDispatcher = eventDispatcher; gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.stateLog = stateLog; CurrentUser remoteUser; if (!cfg.getAuthGroupNames().isEmpty()) { ImmutableSet.Builder<AccountGroup.UUID> builder = ImmutableSet.builder(); for (String name : cfg.getAuthGroupNames()) { GroupReference g = GroupBackends.findExactSuggestion(groupBackend, name); if (g != null) { builder.add(g.getUUID()); addRecursiveParents(g.getUUID(), builder, groupIncludeCache); } else { // Handle error case } } authGroups = builder.build(); } else { authGroups = ImmutableSet.of(); } // Rest of the constructor code }
protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class); bind(DfsRefDatabase.class).to(InMemoryDfsRefDatabase.class); }
private boolean isImmutableRef(String refName) { return refName.startsWith("refs/changes") && !refName.endsWith("/meta"); }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.server.git.validators.RefOperationValidationListener; import com.google.inject.AbstractModule; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.NoOpDfsRefDatabase; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.SharedRefDatabase; public class ValidationModule extends AbstractModule { @Override protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class); } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import static com.google.common.truth.Truth.assertThat; import static org.hamcrest.CoreMatchers.nullValue; import static org.hamcrest.CoreMatchers.sameInstance; import static org.mockito.Mockito.any; import static org.mockito.Mockito.argThat; import static org.mockito.Mockito.doReturn; import static org.mockito.Mockito.doThrow; import static org.mockito.Mockito.eq; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.verifyZeroInteractions;
Refactored Code: .when(dfsRefDatabase) .compareAndPut(any(), eq(null), any()); doThrow(new NullPointerException("newRef is null")) .when(dfsRefDatabase) .compareAndPut(any(), any(), eq(null)); doThrow(new NullPointerException("project name is null")) .when(dfsRefDatabase) .compareAndPut(eq(null), any(), any()); validator = new InSyncChangeValidator(dfsRefDatabase, repoManager); repoManager.createRepository(PROJECT_NAMEKEY); } @Test public void shouldNotVerifyStatusOfImmutablePatchSetRefs() throws Exception { testRefReceivedEvent.command = RECEIVE_COMMAND_CREATE_PATCHSET_REF; final List<ValidationMessage> validationMessages = validator.onRefOperation(testRefReceivedEvent); assertThat(validationMessages).isEmpty(); verifyZeroInteractions(dfsRefDatabase); } @Test public void shouldInsertNewRefInDfsDatabaseWhenHandlingRefCreationEvents() throws Exception { testRefReceivedEvent.command = RECEIVE_COMMAND_CREATE_REF; }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.common.flogger.FluentLogger; import com.google.gerrit.acceptance.LightweightPluginDaemonTest; import com.google.gerrit.acceptance.LogThreshold; import com.google.gerrit.acceptance.NoHttpd; import com.google.gerrit.acceptance.PushOneCommit; import com.google.gerrit.acceptance.TestPlugin; import com.google.inject.AbstractModule; import org.junit.Test; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin(name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.validation.Module") public class MultiSiteValidationIT extends LightweightPluginDaemonTest { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); @Override public void setUpTestPlugin() throws Exception { installPlugin("multi-site"); } @Test public void testValidation() throws Exception { logger.atInfo().log("Running testValidation"); PushOneCommit.Result result = createChange(); result.assertOkStatus(); } }
public static void floatTest() { float f = 0; float fc = 1f; for (int i = 0; i < 2; i++) { f -= fc; f = (-f); } System.out.println(f); } public static final String KUDU_STORAGE_HANDLER = "com.cloudera.kudu.hive.KuduStorageHandler"; public static final String KEY_TABLET_REPLICAS = "kudu.num_tablet_replicas"; public static final long KUDU_RPC_TIMEOUT_MS = 50000; private String kuduTableName_; private String kuduMasters_; Device d = getDevice(sdk); File location = sdk.getLocation(); assert location != null; SystemImageDescription systemImageDescription = getSystemImageDescription(location.getAbsolutePath()); String cardSize = AvdEditWizard.toIniString(DEFAULT_INTERNAL_STORAGE, false); File hardwareSkinPath = AvdEditWizard.resolveSkinPath(d.getDefaultHardware().getSkinFile(), systemImageDescription); String displayName = String.format("%1$s %2$s %3$s", d.getDisplayName(), systemImageDescription.getVersion(), systemImageDescription.getAbiType()); String internalName = AvdEditWizard.cleanAvdName(connection, displayName, true); Map<String, String> settings = getAvdSettings(internalName, d); settings.put(AvdManagerConnection.AVD_INI_DISPLAY_NAME, displayName); return connection.createOrUpdateAvd(null, internalName, d, systemImageDescription, ScreenOrientation.PORTRAIT, false, cardSize, hardwareSkinPath, settings, false); public PerCheckOperations check(CheckKey key) { // implementation } public TestCheckUpdate.Builder newCheck(CheckKey key) { // implementation }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.server.notedb.NotesMigration; import com.google.inject.Inject; public class GerritNoteDbStatus implements NoteDbStatus { private final NotesMigration notesMigration; @Inject public GerritNoteDbStatus(NotesMigration notesMigration) { this.notesMigration = notesMigration; } @Override public boolean enabled() { return notesMigration.commitChangeWrites(); } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; /** * Returns the status of changes migration. */ public interface NoteDbStatus { /** * Status of NoteDb migration. * * @return true if Gerrit has been migrated to NoteDb */ boolean enabled(); }
// Name of plugin and namespace. static final String PLUGIN_NAME = "find-owners"; static final String PROLOG_NAMESPACE = "find_owners"; private final PluginConfigFactory configFactory; // Global/plugin config parameters. private boolean addDebugMsg = false; private int minOwnerVoteLevel = 1; private int maxCacheAge = 0; private int maxCacheSize = 1000; private boolean reportSyntaxError = false; private boolean alwaysShowButton = false; private String ownersFileName = OWNERS; private static final FluentLogger logger = FluentLogger.forEnclosingClass(); Config(PluginConfigFactory configFactory) { this.configFactory = configFactory; if (configFactory == null) { // When called from integration tests. return; } PluginConfig gc = configFactory.getFromGerritConfig(PLUGIN_NAME); // Get config variables from the plugin section of gerrit.config addDebugMsg = gc.getBoolean(ADD_DEBUG_MSG, false); reportSyntaxError = gc.getBoolean(REPORT_SYNTAX_ERROR, false); alwaysShowButton = gc.getBoolean(ALWAYS_SHOW_BUTTON, false); }
import com.google.inject.Inject; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import com.google.inject.Provider; import com.google.gerrit.extensions.annotations.RequiresCapability; import com.google.gerrit.extensions.common.GroupInfo; import com.google.gerrit.extensions.common.TopLevelResource; import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.NameAlreadyUsedException; import com.google.gerrit.extensions.restapi.OrmException; import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.GerritPersonIdent; import com.google.gerrit.server.config.GerritServerConfig; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.gerrit.server.group.GroupsCollection; import com.google.gerrit.server.group.PerformCreateGroup; import com.google.gerrit.server.group.PerformCreateGroup.Factory; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group
import com.googlesource.gerrit.plugins.multisite.forwarder.events.ChangeIndexEvent; import java.util.ArrayList; import java.util.List; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Before; import org.junit.Test; import org.testcontainers.containers.KafkaContainer; @NoHttpd @LogThreshold(level = "INFO") @Sandboxed @TestPlugin(name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.kafka.consumer.EventConsumerIT$KafkaTestContainerModule") public class EventConsumerIT extends LightweightPluginDaemonTest { private static final int QUEUE_POLL_TIMEOUT_MSECS = 30000; static { System.setProperty("gerrit.notedb", "READ_WRITE"); } public static class KafkaTestContainerModule extends LifecycleModule { public class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) { this.kafka = kafka; } @Override public void start() throws Exception { } @Override public void stop() throws Exception { kafka.stop(); } } private final KafkaContainer kafka; public KafkaTestContainerModule() { kafka = new KafkaContainer(); } @Override protected void configure() { bind(KafkaContainer.class).toInstance(kafka); bind(LifecycleListener.class).annotatedWith(Names.named("KafkaStopAtShutdown")) .toInstance(new KafkaStopAtShutdown(kafka)); } } // Test methods }
public boolean isPreview() { return !mItems.isEmpty() && mItems.get(mItems.size() - 1).isPreview(); } super.setUpTestPlugin(); if (!notesMigration.commitChangeWrites()) { throw new IllegalStateException("NoteDb is mandatory for running the multi-site plugin"); } @Test public void createChangeShouldPropagateChangeIndexAndRefUpdateStreamEvent() throws Exception { LinkedBlockingQueue<SourceAwareEventWrapper> droppedEventsQueue = captureDroppedEvents(); drainQueue(droppedEventsQueue); PushOneCommit.Result r = createChange(); List<Event> createdChangeEvents = receiveFromQueue(droppedEventsQueue, 4); assertThat(createdChangeEvents).hasSize(4); ChangeData change = r.getChange(); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("change-index")) .collect(toSet()) ).containsExactlyElementsIn( ImmutableList.of( createChangeIndexEvent(change.project().get(), change.getId().get(), getParentCommit(change)) ) ); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("ref-updated")) .map(RefUpdatedEvent.class::cast) .map(e -> e.getRefName()) .collect(toSet()) ).containsExactlyElementsIn( ImmutableList.of( RefNames.fullName(change.getDest().branch()), RefNames.fullName(change.getDest().branch() + "-meta"), RefNames.fullName(change.getDest().branch() + "-drafts") ) ); }
.collect(toSet())) .containsExactlyElementsIn( ImmutableList.of( createChangeIndexEvent( change.project().get(), change.getId().get(), getParentCommit(change) ) ) ); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("ref-updated")) .map(RefUpdatedEvent.class::cast) .map(e -> e.getRefName()) .collect(toSet()) ) .containsExactlyElementsIn( ImmutableList.of( "refs/sequences/changes", change.currentPatchSet().getRefName(), "refs/meta" ) ); PatchSetCreatedEvent patchSetCreated = createdChangeEvents .stream() .filter(e -> e.type.equals("patchset-created")) .map(PatchSetCreatedEvent.class::cast) .findFirst() .get(); PatchSetAttribute patchSetAttribute = patchSetCreated.patchSet.get(); PatchSet currentPatchSet = change.currentPatchSet(); assertThat(patchSetAttribute.number).isEqualTo(currentPatchSet.getPatchSetId()); assertThat(patchSetAttribute.revision).isEqualTo(currentPatchSet.getRevision().get()); assertThat(patchSetAttribute.ref).isEqualTo(currentPatchSet.getRefName());
import com.google.inject.TypeLiteral; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.Module; import com.googlesource.gerrit.plugins.multisite.broker.GsonProvider; import com.googlesource.gerrit.plugins.multisite.forwarder.events.ChangeIndexEvent; import java.util.ArrayList; import java.util.List; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Test; import org.testcontainers.containers.KafkaContainer; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin(name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.kafka.consumer.EventConsumerIT$KafkaTestContainerModule") public class EventConsumerIT extends LightweightPluginDaemonTest { private static final int QUEUE_POLL_TIMEOUT_MSECS = 30000; public static class KafkaTestContainerModule extends LifecycleModule { public class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) { this.kafka = kafka; } @Override public void start() throws Exception { } @Override public void stop() throws Exception { kafka.stop(); } } } }
protected void configure() { if (!noteDb.enabled()) { throw new ProvisionException("Gerrit is still running on ReviewDb: please migrate to NoteDb and then reload the multi-site plugin."); } listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } install(new ValidationModule()); bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class); }
import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.Singleton; import java.util.List; import java.util.stream.Stream; @Singleton public class PendingChecksImpl implements PendingChecks { private final Provider<ListPendingChecks> listPendingChecksProvider; @Inject PendingChecksImpl(Provider<ListPendingChecks> listPendingChecksProvider) { this.listPendingChecksProvider = listPendingChecksProvider; } @Override public List<PendingChecksInfo> list(String checkerUuidString, CheckState... checkStates) throws RestApiException { CheckerUuid checkerUuid = CheckerUuid.tryParse(checkerUuidString) .orElseThrow(() -> new BadRequestException(String.format("invalid checker UUID: %s", checkerUuidString))); try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setChecker(checkerUuid); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } } @Override // other methods }
this.listPendingChecksProvider = listPendingChecksProvider; } @Override public List<PendingChecksInfo> list(String checkerUuidString, CheckState... checkStates) throws RestApiException { CheckerUuid checkerUuid = CheckerUuid.tryParse(checkerUuidString) .orElseThrow(() -> new BadRequestException(String.format("invalid checker UUID: %s", checkerUuidString))); try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setChecker(checkerUuid); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } } @Override public List<PendingChecksInfo> listForScheme(String scheme, CheckState... checkStates) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setScheme(scheme); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } }
if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } @Override public List<PendingChecksInfo> listForScheme(String scheme, CheckState... checkStates) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setScheme(scheme); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks for scheme", e); } }
import com.google.gerrit.extensions.annotations.Exports; import com.google.gerrit.extensions.annotations.PluginName; import com.google.gerrit.server.config.PluginConfigFactory; import com.google.gerrit.server.config.ProjectConfigEntry; import com.google.inject.AbstractModule; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.its.base.ItsHookModule; import com.googlesource.gerrit.plugins.its.base.its.ItsConfig; import com.googlesource.gerrit.plugins.its.base.its.ItsFacade; import com.googlesource.gerrit.plugins.its.base.its.ItsFacadeFactory; import com.googlesource.gerrit.plugins.its.base.workflow.CustomAction; import static com.googlesource.gerrit.plugins.its.jira.JiraConfig.*; package com.googlesource.gerrit.plugins.its.jira; public class JiraModule extends AbstractModule { private final String pluginName; @Inject public JiraModule(@PluginName String pluginName) { this.pluginName = pluginName; } @Override protected void configure() { bind(ItsConfig.class).annotatedWith(Exports.named(pluginName)).to(JiraConfig.class); bind(ItsFacade.class).annotatedWith(Exports.named(pluginName)).to(JiraItsFacade.class); bind(ItsFacadeFactory.class).annotatedWith(Exports.named(pluginName)).to(JiraItsFacadeFactory.class); bind(ItsHookModule.class).annotatedWith(Exports.named(pluginName)).to(JiraHookModule.class); bind(PluginConfigFactory.class).annotatedWith(Exports.named(pluginName)).toInstance(new PluginConfigFactory(pluginName)); bind(ProjectConfigEntry.class).annotatedWith(Exports.named(pluginName)).toInstance(new ProjectConfigEntry("Jira", null)); bind(CustomAction.class).annotatedWith(Exports.named(pluginName)).to(JiraCustomAction.class); } }
String email = preferredEmails.get(owner); for (String path : result.owner2paths.get(owner)) { addOwnerPathPair(email, path); } for (String glob : result.noParentGlobs) { add2dir2Globs(Util.getDirName(glob) + "/", glob); } if (config.getReportSyntaxError()) { Ordering.natural().sortedCopy(result.errors).forEach(e -> logger.atSevere().log(e)); Ordering.natural().sortedCopy(result.warnings).forEach(w -> logger.atWarning().log(w)); }
private static void saveReadFile(Map<String, String> readFiles, String project, String file, String content) { if (readFiles != null) { readFiles.put(project + ":" + file, content); } }
private static void checkIncludeOrFile(List<CommitValidationMessage> messages, String path, int num, String line) { // TODO: Check if an included file exists and with valid syntax. // An included file could be a new file added by a CL and not in the repository yet add(messages, "unchecked: " + path + ":" + num + ": " + Parser.getIncludeOrFile(line), false); }
private GitRepositoryManager repoManager; private String branch; private IncludeStack stack; private List<String> logs; private Map<String, Result> savedResults; static class IncludeStack { Deque<String> projectName; Deque<String> filePath; Set<String> allFiles; IncludeStack(String project, String file) { projectName = new ArrayDeque<>(); filePath = new ArrayDeque<>(); allFiles = new HashSet<>(); push(project, file); } void push(String project, String file) { projectName.push(project); filePath.push(file); allFiles.add(project + ":" + file); } void pop() { allFiles.remove(currentProject() + ":" + currentFile()); projectName.pop(); filePath.pop(); } }
void push(String project, String file) { projectName.push(project); filePath.push(file); allFiles.add(project + ":" + file); }
void pop() { allFiles.remove(currentProject() + ":" + currentFile()); projectName.pop(); filePath.pop(); }
boolean contains(String project, String file) { return allFiles.contains(project + ":" + file); }
rp.sendError("internal error while processing changes"); // ReceiveCommits has tried its best to catch errors, so anything at this // point is very bad. for (ReceiveCommand c : commands) { if (c.getResult() == Result.NOT_ATTEMPTED) { c.setResult(Result.REJECTED_OTHER_REASON, "internal error"); } } } finally { w.sendMessages(); } long deltaNanos = System.nanoTime() - startNanos; int totalChanges = 0; String pushType; if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(pushType, created.size() + replaced.size()); totalChanges += replaced.size() + created.size(); } else { List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED); if (!autoclosed.isEmpty()) { pushType = ResultChangeIds.Key.AUTOCLOSED.name();
} finally { w.sendMessages(); } long deltaNanos = System.nanoTime() - startNanos; int totalChanges = 0; String pushType; if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(pushType, created.size() + replaced.size()); totalChanges = replaced.size() + created.size(); } else { List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED); if (!autoclosed.isEmpty()) { pushType = ResultChangeIds.Key.AUTOCLOSED.name(); metrics.changes.record(ResultChangeIds.Key.AUTOCLOSED.name(), autoclosed.size()); totalChanges = autoclosed.size(); } else { pushType = "NORMAL"; } } if (totalChanges > 0) { metrics.latencyPerChange.record(pushType, deltaNanos / totalChanges, NANOSECONDS); } metrics.latencyPerPush.record(pushType, deltaNanos, NANOSECONDS);
String patchsetRevision = change.currentPatchSet().getRevision().get(); String patchsetRef = change.currentPatchSet().getRefName(); Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue); assertThat(eventsByType.get("change-index")) .containsExactly(createChangeIndexEvent(project, changeNum, getParentCommit(change))); assertThat(eventsByType.get("ref-updated") .stream() .map(e -> ((RefUpdatedEvent) e).getRefName()) .collect(toSet())) .containsAllOf(changeNotesRef, patchsetRef); List<Event> patchSetCreatedEvents = eventsByType.get("patchset-created"); assertThat(patchSetCreatedEvents).hasSize(1); assertPatchSetAttributes((PatchSetCreatedEvent) patchSetCreatedEvents.get(0), patchsetNum, patchsetRevision, patchsetRef); } private void assertPatchSetAttributes(PatchSetCreatedEvent patchSetCreated, int patchsetNum, String patchsetRevision, String patchsetRef) { PatchSetAttribute patchSetAttribute = patchSetCreated.patchSet.get(); assertThat(patchSetAttribute.number).isEqualTo(patchsetNum); assertThat(patchSetAttribute.revision).isEqualTo(patchsetRevision); }
import java.util.List; import java.util.ArrayList; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; import java.util.stream.Collectors; public class EventProcessor { private static final int QUEUE_POLL_TIMEOUT_MSECS = 1000; public List<Event> processEvents(LinkedBlockingQueue<SourceAwareEventWrapper> queue) throws InterruptedException { GsonProvider gsonProvider = plugin.getSysInjector().getInstance(Key.get(GsonProvider.class)); List<Event> eventsList = new ArrayList<>(); SourceAwareEventWrapper event; while ((event = queue.poll(QUEUE_POLL_TIMEOUT_MSECS, TimeUnit.MILLISECONDS)) != null) { eventsList.add(event.getEventBody(gsonProvider)); } return eventsList; } }
private final CheckResource checkResource; @Inject CheckApiImpl(GetCheck getCheck, UpdateCheck updateCheck, @Assisted CheckResource checkResource) { this.getCheck = getCheck; this.updateCheck = updateCheck; this.checkResource = checkResource; } @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { try { Arrays.stream(options).forEach(getCheck::addOption); return getCheck.apply(checkResource); } catch (Exception e) { throw asRestApiException("Cannot retrieve check", e); } } @Override public CheckInfo update(CheckInput input) throws RestApiException { try { return updateCheck.apply(checkResource, input); } catch (Exception e) { throw asRestApiException("Cannot update check", e); } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.client; import java.lang.reflect.InvocationTargetException; import java.util.EnumSet; /** * Enum that can be expressed as a bitset in query parameters. */ public interface ListOption { int getValue(); static <T extends Enum<T> & ListOption> EnumSet<T> fromBits(Class<T> clazz, int v) { EnumSet<T> r = EnumSet.noneOf(clazz); T[] values; try { @SuppressWarnings("unchecked") T[] tmp = (T[]) clazz.getMethod("values").invoke(null); values = tmp; } catch (IllegalAccessException | NoSuchMethodException | InvocationTargetException e) { throw new IllegalStateException(e); } for (T o : values) { if ((v & (1 << o.getValue())) != 0) { r.add(o); v &= ~(1 << o.getValue()); } } if (v != 0) { throw new IllegalArgumentException("Unknown bits set in " + v); } return r; } }
import com.google.gerrit.server.git.PureRevertCache; import com.google.gerrit.server.notedb.ChangeNotes; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.InvalidObjectIdException; import org.eclipse.jgit.lib.ObjectId; @Singleton public class PureRevert { private final PureRevertCache pureRevertCache; @Inject PureRevert(PureRevertCache pureRevertCache) { this.pureRevertCache = pureRevertCache; } public boolean isPureRevert(ChangeNotes notes, @Nullable String claimedOriginal) throws OrmException, IOException, BadRequestException, ResourceConflictException { PatchSet currentPatchSet = notes.getCurrentPatchSet(); if (currentPatchSet == null) { throw new ResourceConflictException("current revision is missing"); } if (claimedOriginal == null) { return pureRevertCache.isPureRevert(notes); } ObjectId claimedOriginalObjectId; try { claimedOriginalObjectId = ObjectId.fromString(claimedOriginal); } catch (InvalidObjectIdException e) { throw new BadRequestException("invalid object ID"); } return pureRevertCache.isPureRevert(notes, claimedOriginalObjectId); } }
@Override public boolean isPureRevert(String projectName, String currentRevision, String claimedOriginal) { PatchSet currentPatchSet = notes.getCurrentPatchSet(); if (currentPatchSet == null) { throw new ResourceConflictException("current revision is missing"); } if (claimedOriginal == null) { return pureRevertCache.isPureRevert(notes); } ObjectId claimedOriginalObjectId; try { claimedOriginalObjectId = ObjectId.fromString(claimedOriginal); } catch (InvalidObjectIdException e) { throw new BadRequestException("invalid object ID"); } boolean result = pureRevertCache.isPureRevert(notes.getProjectName(), ObjectId.fromString(notes.getCurrentPatchSet().getRevision().get()), claimedOriginalObjectId); return result; }
import org.eclipse.jgit.diff.DiffFormatter; import org.eclipse.jgit.errors.InvalidObjectIdException; import org.eclipse.jgit.errors.MissingObjectException; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectInserter; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.merge.ThreeWayMerger; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; @Singleton public class PureRevertCache { static final String ID_CACHE = "pure_revert"; public static class Module extends CacheModule { @Override protected void configure() { persist(ID_CACHE, Cache.PureRevertKeyProto.class, Boolean.class) .maximumWeight(100) .loader(Loader.class) .version(1) .keySerializer(new ProtobufSerializer<>(Cache.PureRevertKeyProto.parser())) .valueSerializer(BooleanCacheSerializer.INSTANCE); } } private final LoadingCache<PureRevertKeyProto, Boolean> cache; private final PatchSetUtil psUtil; private final ChangeNotes.Factory notesFactory; @Inject PureRevertCache(LoadingCache<PureRevertKeyProto, Boolean> cache, PatchSetUtil psUtil, ChangeNotes.Factory notesFactory) { this.cache = cache; this.psUtil = psUtil; this.notesFactory = notesFactory; } // rest of the code... }
private final LoadingCache<PureRevertKeyProto, Boolean> cache; private final PatchSetUtil psUtil; private final ChangeNotes.Factory notesFactory; @Inject PureRevertCache( @Named(ID_CACHE) LoadingCache<PureRevertKeyProto, Boolean> cache, PatchSetUtil psUtil, ChangeNotes.Factory notesFactory ) { this.cache = cache; this.psUtil = psUtil; this.notesFactory = notesFactory; } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code claimedOriginal}. * * @param claimedRevert the claimed revert to check * @return {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code claimedOriginal} * @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ChangeNotes} */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { // implementation }
import com.google.gerrit.server.project.ProjectControl; import com.google.gerrit.sshd.BaseCommand.UnloggedFailure; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import java.util.ArrayList; import java.util.Arrays; import java.util.List; import java.util.Map; import java.util.Optional; import java.util.stream.Collectors; public class ChangeArgumentParser { private final CurrentUser currentUser; private final ChangesCollection changesCollection; private final ChangeFinder changeFinder; private final ReviewDb db; private final ChangeNotes.Factory changeNotesFactory; private final ChangeControl.GenericFactory changeControlFactory; @Inject ChangeArgumentParser(CurrentUser currentUser, ChangesCollection changesCollection, ChangeFinder changeFinder, ReviewDb db, ChangeNotes.Factory changeNotesFactory, ChangeControl.GenericFactory changeControlFactory) { this.currentUser = currentUser; this.changesCollection = changesCollection; this.changeFinder = changeFinder; this.db = db; this.changeNotesFactory = changeNotesFactory; this.changeControlFactory = changeControlFactory; } public void addChange(String id, Map<Change.Id, ChangeResource> changes) throws UnloggedFailure, OrmException { // Code implementation } } public class Definition<T, Q extends QueryBuilder<T>> { private final Map<String, OperatorFactory<T, Q>> opFactories = new HashMap<>(); public Definition(Class<Q> clazz) { if (clazz != null) { Class<?> c = clazz; while (c != QueryBuilder.class) { registerOperatorFactories(c, null); c = c.getSuperclass(); } } } public Definition(Iterable<? extends DynamicBuilder<T>> builders) { if (builders != null) { for (DynamicBuilder<T> builder : builders) { registerOperatorFactories(builder); } } } } public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { if (claimedRevert.getChange().getRevertOf() == null) { throw new BadRequestException("revertOf not set"); } PatchSet ps = psUtil.current(notesFactory.createChecked(claimedRevert.getProjectName(), claimedRevert.getChange().getRevertOf())); return isPureRevert(claimedRevert.getProjectName(), ObjectId.fromString(claimedRevert.getCurrent
ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(ps.getRevision().get())); } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * * @return {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * @throws IOException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ObjectId}s */ public boolean isPureRevert(Project.NameKey project, ObjectId claimedRevert, ObjectId claimedOriginal) throws IOException, BadRequestException { try { return cache.get(key(project, claimedRevert, claimedOriginal)); } catch (ExecutionException e) { Throwables.throwIfInstanceOf(e.getCause(), BadRequestException.class); throw new IOException(e); } } @VisibleForTesting static PureRevertKeyProto key(
Project.NameKey project = new Project.NameKey(key.getProject()); try (Repository repo = repoManager.openRepository(project); ObjectInserter oi = repo.newObjectInserter(); RevWalk rw = new RevWalk(repo)) { RevCommit claimedOriginalCommit; try { claimedOriginalCommit = rw.parseCommit(original); } catch (InvalidObjectIdException | MissingObjectException e) { throw new BadRequestException("invalid object ID"); } if (claimedOriginalCommit.getParentCount() == 0) { return false; } RevCommit claimedRevertCommit = rw.parseCommit(revert); if (claimedRevertCommit.getParentCount() == 0) { return false; } // Rebase claimed revert onto claimed original ThreeWayMerger merger = mergeUtilFactory .create(projectCache.checkedGet(project)) .newThreeWayMerger(oi, repo.getConfig()); merger.setBase(claimedRevertCommit.getParent(0)); boolean success = merger.merge(claimedRevertCommit, claimedOriginalCommit); if (!success || merger.getResultTreeId() == null) { // Merge conflict during rebase return false; } }
public void createProject(CredentialsProvider credentialsProvider, URIish uri, String projectName, String head) { OutputStream errStream = newErrorBufferStream(); String cmd = "gerrit create-project --branch " + head + " " + projectName; try { execute(credentialsProvider, uri, cmd, errStream); } catch (IOException e) { log.error(String.format("Error creating remote repository at %s:%n" + " Exception: %s%n Command: %s%n Output: %s", uri, e, cmd, errStream), e); } } Ref destRef = git.getRefDatabase().exactRef(resource.getRef()); if (destRef == null) { throw new ResourceNotFoundException(resource.getRef()); } RevCommit targetCommit = rw.parseCommit(destRef.getObjectId()); RevCommit sourceCommit = MergeUtil.resolveCommit(git, rw, source); if (!resource.getControl().canReadCommit(db.get(), git, sourceCommit)) { throw new BadRequestException("Do not have read permission for: " + source); } if (rw.isMergedInto(sourceCommit, targetCommit)) { throw new ChangeAlreadyMergedException("'" + source + "' has already been merged!"); } result.mergeable = m.merge(false, targetCommit, sourceCommit); if (m instanceof ResolveMerger) { result.conflicts = ((ResolveMerger) m).getUnmergedPaths(); } TUpdateCatalogCacheRequest req = new TUpdateCatalogCacheRequest(); TUniqueId default_catalog_service_id = new TUniqueId(0L, 0L); for (byte[] catalogUpdate : thriftCatalogUpdates) { TUpdateCatalogCacheRequest incrementalRequest = new TUpdateCatalogCacheRequest(); JniUtil.deserializeThrift(protocolFactory_, incrementalRequest, catalogUpdate); if (!req.isSetIs_delta()) { req.setIs_delta(incrementalRequest.isIs_delta()); } if (!incrementalRequest.getCatalog_service_id().equals(default_catalog_service_id)) { req.setCatalog_service_id(incrementalRequest.getCatalog_service_id()); } if (!req.isSetUpdated_objects()) { req.setUpdated_objects(incrementalRequest.getUpdated_objects()); } else { req.getUpdated_objects().addAll(incrementalRequest.getRemoved_objects()); } if (!req.isSetRemoved_objects()) { req.setRemoved_objects(incrementalRequest.removed_objects); } else
public void testPureRevertCacheKey() { ObjectId revert = ObjectId.zeroId(); ObjectId original = ObjectId.fromString("deadbeefdeadbeefdeadbeefdeadbeefdeadbeef"); byte[] serializedRevert = new byte[20]; byte[] serializedOriginal = new byte[20]; revert.copyRawTo(serializedRevert, 0); original.copyRawTo(serializedOriginal, 0); Cache.PureRevertKeyProto key = PureRevertCache.key(new Project.NameKey("test"), revert, original); assertThat(key) .isEqualTo(Cache.PureRevertKeyProto.newBuilder() .setProject("test") .setClaimedRevert(ByteString.copyFrom(serializedRevert)) .setClaimedOriginal(ByteString.copyFrom(serializedOriginal)) .build()); }
static String getFileKey(String project, String file) { return project + ":" + file; }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper; import static com.google.common.base.Preconditions.checkArgument; import java.io.IOException; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.ExponentialBackoffRetry; public class CuratorFrameworkBuilder { private ZkConfig config = null; public CuratorFrameworkBuilder config(ZkConfig config) { this.config = config; return this; } public CuratorFramework build() throws IOException { // Implementation goes here } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper; import com.google.common.base.MoreObjects; import java.io.Serializable; import org.apache.curator.framework.CuratorFrameworkFactory; import org.eclipse.jgit.lib.Config; /** Configuration for a Zookeeper setup. */ public class ZkConfig implements Serializable { private static final long serialVersionUID = 1L; public static final int DEFAULT_SESSION_TIMEOUT_MS; public static final int DEFAULT_CONNECTION_TIMEOUT_MS; static { // Initialize constants } // Rest of the code }
public static final int DEFAULT_CONNECTION_TIMEOUT_MS; static { CuratorFrameworkFactory.Builder b = CuratorFrameworkFactory.builder(); DEFAULT_SESSION_TIMEOUT_MS = b.getSessionTimeoutMs(); DEFAULT_CONNECTION_TIMEOUT_MS = b.getConnectionTimeoutMs(); } private static final String SECTION = "zookeeper"; private static final String KEY_CONNECT_STRING = "connectString"; private static final String KEY_SESSION_TIMEOUT = "sessionTimeout"; private static final String KEY_CONNECTION_TIMEOUT = "connectionTimeout"; // TODO(dborowitz): Configure RetryPolicy. private final String connectString; private final int sessionTimeoutMs; private final int connectionTimeoutMs; private final String zookeeperRoot; ZkConfig( final String connectString, final String zookeeperRoot, final int sessionTimeoutMs, final int connectionTimeoutMs) { this.connectString = connectString; this.sessionTimeoutMs = sessionTimeoutMs; this.connectionTimeoutMs = connectionTimeoutMs; this.zookeeperRoot = zookeeperRoot; } public static ZkConfig fromConfig(Config cfg) { return new ZkConfig( cfg.getString(SECTION, null, KEY_CONNECT_STRING), cfg.getInt(SECTION, null, KEY_SESSION_TIMEOUT, DEFAULT_SESSION_TIMEOUT_MS), cfg.getInt(SECTION, null, KEY_CONNECTION_TIMEOUT, DEFAULT_CONNECTION_TIMEOUT_MS), cfg.getString(SECTION, null, KEY_ZOOKEEPER_ROOT)); }
return true; } private boolean doCreate(ZkRefInfoMarshaller marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception { if (infoCurrentlyInZkMaybe.isPresent()) { logger.atWarning().log("Asked to create ref %s but it is already in ZK at path %s", newRefInfo.refName(), ZkRefInfoMarshaller.pathFor(newRefInfo)); return false; } marshaller.create(newRefInfo); return true; } static class TombstoneRef implements Ref { static TombstoneRef forRef(final Ref targetRef) { return new TombstoneRef(targetRef.getName()); } private final String name; private TombstoneRef(String name) { this.name = name; } @Override public String getName() { return name; } @Override public boolean isSymbolic() { return false; } @Override public Ref getLeaf() { return null; } @Override public Ref getTarget() { return null; } }
assertThat(marshaller.read(aProjectName(), aChangeRefName())).isEqualTo(Optional.empty()); @Test public void shouldUpdateAZrefInfo() throws Exception { ZkRefInfo newRefInfo = aZkRefInfo(); ZkRefInfo updateRefInfo = new ZkRefInfo( newRefInfo.projectName(), newRefInfo.refName(), anObjectId(), Instant.now(), UUID.randomUUID()); // Make sure new refInfo and updateRefInfo are never the same assertThat(newRefInfo).isNotEqualTo(updateRefInfo); marshaller.create(newRefInfo); marshaller.update(updateRefInfo); Optional<ZkRefInfo> readUpdatedRefInfo = marshaller.read(updateRefInfo.projectName(), updateRefInfo.refName()); assertThat(readUpdatedRefInfo).isEqualTo(Optional.of(updateRefInfo)); } @Test public void shouldFailToReadZkRefInfoIfSomeOfTheInfoIsMissing() throws Exception { String projectName = aProjectName(); String refName = aChangeRefName(); curator.createContainers(ZkRefInfoMarshaller.pathFor(projectName, refName)); expectedException.expect(CorruptedZkStorageException.class); }
public boolean equals(Object other) { if (this == other) { return true; } if (other == null || getClass() != other.getClass()) { return false; } ZkRefInfo zkRefInfo = (ZkRefInfo) other; return Objects.equal(refName, zkRefInfo.refName) && Objects.equal(projectName, zkRefInfo.projectName) && Objects.equal(objectId, zkRefInfo.objectId) && Objects.equal(lastWriterInstanceId, zkRefInfo.lastWriterInstanceId) && Objects.equal(lastUpdatedAt, zkRefInfo.lastUpdatedAt); }
marshaller.read(projectName, newRef.getName()); final ZkRefInfo newRefInfo = new ZkRefInfo(projectName, newRef, instanceId); if (isCreate) { return doCreate(marshaller, infoCurrentlyInZkMaybe, newRefInfo); } else { return doUpdate(oldRef, marshaller, infoCurrentlyInZkMaybe, newRefInfo); } } catch (Exception e) { logger.atWarning().withCause(e).log( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)); throw new IOException( String.format("Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)), e); } private boolean doUpdate( Ref oldRef, ZkRefInfoMarshaller marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo ) throws Exception { if (!infoCurrentlyInZkMaybe.isPresent()) { logger.atWarning().log( "Asked to update ref %s but it is not in ZK at path %s", newRef.getName(), ZkRefInfoMarshaller.pathFor(projectName, newRef) ); throw new IOException( String.format( "Asked to update ref %s but it is not in ZK at path %s", newRef.getName(), ZkRefInfoMarshaller.pathFor(projectName, newRef) ) ); } // Perform the update logic here return true; }
} } catch (Exception e) { logger.atWarning().withCause(e).log( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)); throw new IOException( String.format( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)), e); } } private boolean doUpdate( Ref oldRef, ZkRefInfoMarshaller marshaller, ZkRefInfo infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception { if (infoCurrentlyInZkMaybe == null) { logger.atWarning().log( "Asked to update ref %s but it is not in ZK at path %s", newRefInfo.refName(), ZkRefInfoMarshaller.pathFor(newRefInfo)); return false; } if (!infoCurrentlyInZkMaybe.objectId().equals(oldRef.getObjectId())) { logger.atWarning().log(
import java.io.IOException; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.test.TestingServer; import org.junit.Test; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin(name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.validation.ValidationIT$Module") public class ValidationIT extends LightweightPluginDaemonTest { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); CuratorFramework framework; public static class Module extends LifecycleModule { public class ZookeeperStopAtShutdown implements LifecycleListener { private final TestingServer zookeeper; public ZookeeperStopAtShutdown(TestingServer zookeeper) { this.zookeeper = zookeeper; } @Override public void stop() { try { zookeeper.stop(); } catch (IOException e) { logger.atWarning().withCause(e).log("Cannot start zookeeper"); throw new RuntimeException("Cannot start zookeeper", e); } } @Override public void start() { try { zookeeper.start(); } catch (Exception e) { logger.atWarning().withCause(e).log("Cannot start zookeeper"); throw new RuntimeException("Cannot start zookeeper", e); } } } } }
protected void configure() { TestingServer zookeeper = null; try { zookeeper = new TestingServer(); } catch (Exception e) { throw new RuntimeException("Cannot init zookeeper", e); } install(new ValidationModule()); super.configure(); listener().toInstance(new ZookeeperStopAtShutdown(zookeeper)); }
import org.junit.Ignore; @Ignore public interface RefFixture { String ALLOWED_CHARS = "abcdefghilmnopqrstuvz"; String ALLOWED_DIGITS = "1234567890"; String ALLOWED_NAME_CHARS = ALLOWED_CHARS + ALLOWED_CHARS.toUpperCase() + ALLOWED_DIGITS; static ZkRefInfo aZkRefInfo() { return new ZkRefInfo(aProjectName(), aChangeRefName(), anObjectId(), Instant.now(), UUID.randomUUID()); } static String aProjectName() { return generateRandomString(20, ALLOWED_NAME_CHARS); } static ObjectId anObjectId() { return ObjectId.fromString(generateRandomNumericString(40)); } static String aChangeRefName() { return "refs/for/" + generateRandomString(10, ALLOWED_NAME_CHARS); } static Ref aRefObject(String refName, ObjectId objectId) { return new TestRef(refName, objectId); } static Ref aRefObject(String refName) { return aRefObject(refName, anObjectId()); } static Ref aRefObject() { return aRefObject(aChangeRefName(), anObjectId()); } static String generateRandomString(int length, String allowedChars) { StringBuilder sb = new StringBuilder(length); Random random = new Random(); for (int i = 0; i < length; i++) { int index = random.nextInt(allowedChars.length()); sb.append(allowedChars.charAt(index)); } return sb.toString(); } static String generateRandomNumericString(int length) { StringBuilder sb = new StringBuilder(length); Random random = new Random(); for (int i = 0; i < length; i++) { int digit = random.nextInt(10); sb.append(digit); } return sb.toString(); } }
import static RefFixture.anObjectId; import static RefFixture.aChangeRefName; public void shouldCreateANewRef() { ObjectId objectId = anObjectId(); String refName = aChangeRefName(); Ref aNewRef = zkSharedRefDatabase.newRef(refName, objectId); assertThat(aNewRef.getName()).isEqualTo(refName); assertThat(aNewRef.getObjectId()).isEqualTo(objectId); assertThat(aNewRef.getStorage()).isEqualTo(Storage.NETWORK); }
import java.util.Arrays; import javax.crypto.Cipher; import javax.crypto.KeyGenerator; import javax.crypto.NoSuchPaddingException; import javax.crypto.SecretKey; import javax.crypto.spec.IvParameterSpec; @Singleton public class LfsAuthTokenHandler { private static final Logger log = LoggerFactory.getLogger(LfsAuthTokenHandler.class); private static final int IV_LENGTH = 16; private static final String ALGORITHM = "AES"; static final DateTimeFormatter DATE_TIME = DateTimeFormat.forPattern("YYYYMMDDHHmmss"); private final SecureRandom random; private final SecretKey key; @Inject public LfsAuthTokenHandler() { this.random = new SecureRandom(); this.key = generateKey(); } public String generateToken(int expirationSeconds, String... params) { try { byte[] initVector = new byte[IV_LENGTH]; random.nextBytes(initVector); Cipher cipher = cipher(initVector, Cipher.ENCRYPT_MODE); return Base64.encodeBytes(Bytes.concat(initVector, cipher.doFinal(String.format("%s~%s", Joiner.on('~').join(params), DATE_TIME.print(DateTime.now().plusSeconds(expirationSeconds)))))); } catch (Exception e) { log.error("Error generating token", e); return null; } } private SecretKey generateKey() { try { KeyGenerator keyGen = KeyGenerator.getInstance(ALGORITHM); keyGen.init(128); return keyGen.generateKey(); } catch (NoSuchAlgorithmException e) { log.error("Error generating key", e); return null; } } }
marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); assertThat(zkSharedRefDatabase.compareAndRemove(projectName, oldRef)).isTrue(); Optional<ZkRefInfo> inZk = marshaller.read(projectName, oldRef.getName()); assertThat(inZk.isPresent()).isTrue(); assertThat(inZk.get().projectName()).isEqualTo(projectName); assertThat(inZk.get().refName()).isEqualTo(oldRef.getName()); assertThat(inZk.get().objectId()).isEqualTo(ObjectId.zeroId()); @Test public void shouldNotCompareAndPutSuccessfullyAfterACompareAndRemove() throws Exception { Ref oldRef = aRefObject(); String projectName = RefFixture.aProjectName(); marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); zkSharedRefDatabase.compareAndRemove(projectName, oldRef); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, aRefObject(oldRef.getName()))).isFalse(); }
return "/" + projectName + "/" + refName; } private final CuratorFramework client; public ZkRefInfoDAO(CuratorFramework client) { this.client = client; } public ZkRefInfo read(String projectName, String refName) throws Exception { final String rootPath = pathFor(projectName, refName); if (!exists(rootPath)) { throw new Exception("Root path does not exist"); } final Optional<ObjectId> objectId = readObjectIdAt(rootPath + "/" + OBJECT_ID_PATH); if (!objectId.isPresent()) { throw new CorruptedZkStorageException( String.format("Corrupted content for ref %s, missing some of the sub info, %s present: %b", refName, OBJECT_ID_PATH, objectId.isPresent())); } return new ZkRefInfo(projectName, refName, objectId.get()); } public void update(ZkRefInfo info) throws Exception { writeInTransaction(info, () -> client.transactionOp().setData()); } public void create(ZkRefInfo info) throws Exception { writeInTransaction(info, () -> client.transactionOp().create()); }
import org.apache.curator.framework.recipes.locks.InterProcessMutex; import org.apache.curator.framework.recipes.locks.Locker; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; public class ZkSharedRefDatabase implements SharedRefDatabase { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CuratorFramework client; private final Duration lockTimeout; private final UUID instanceId; @Inject public ZkSharedRefDatabase(CuratorFramework client, @Named("ZkLockTimeout") Duration lockTimeout, @InstanceId UUID instanceId) { this.client = client; this.lockTimeout = lockTimeout; this.instanceId = instanceId; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, TombstoneRef.forRef(oldRef)); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { boolean isCreate = oldRef == NULL_REF; final ZkRefInfoDAO marshaller = new ZkRefInfoDAO(client); final InterProcessMutex refPathMutex = new InterProcessMutex(client, getRefPath(projectName)); try (Locker locker = new Locker(refPathMutex, lockTimeout)) { if (!locker.lock()) { logger.atWarning().log("Failed to acquire lock for project: %s", projectName); return false; } RefInfo oldRefInfo = marshaller.getRefInfo(projectName, oldRef.getName()); if (oldRefInfo == null) { if (!isCreate) { logger.atWarning().log("Failed to compare and put ref for project: %s", projectName); return false; } } else { if (!oldRefInfo.getRef().getObjectId().equals(oldRef.getObjectId())) { logger.atWarning().log("Failed to compare and put ref for project: %s", projectName); return false; } } RefInfo newRefInfo = new RefInfo(newRef, instanceId); marshaller.putRefInfo(projectName, newRef.getName(), newRefInfo); return true; } catch (Exception e) { logger.atWarning().withCause(e).log("Failed to compare and put ref for project: %s", projectName); return false;
import com.google.gerrit.extensions.annotations.Exports; import com.google.gerrit.extensions.config.FactoryModule; import com.google.gerrit.plugins.checks.Checker; import com.google.gerrit.plugins.checks.Checkers; import com.google.gerrit.plugins.checks.api.BlockingCondition; import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.plugins.checks.api.CombinedCheckState; import com.google.gerrit.plugins.checks.api.ListChecks; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.project.SubmitRuleOptions; import com.google.gerrit.server.query.change.ChangeData; import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; import java.util.Map; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder() }
import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId; private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); result.assertOkStatus(); testChangeId = result.getChangeId(); testPatchSetId = result.getPatchSetId(); approve(testChangeId); testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED); } }
import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); result.assertOkStatus(); testPatchSetId = result.getPatchSetId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(result.getChangeId()); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED); assertThat(checkerOperations.checker(testCheckerUuid).get().getBlockingConditions()) .containsExactly(BlockingCondition.STATE_NOT_PASSING); } }
// about checks. approve(testChangeId); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED); assertThat(checkerOperations.checker(testCheckerUuid).get().getBlockingConditions()) .containsExactly(BlockingCondition.STATE_NOT_PASSING); @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. Project.NameKey otherRepo = new Project.NameKey("other-project"); gApi.projects().create(otherRepo.get()); checkerOperations.checker(testCheckerUuid).forUpdate().repository(otherRepo).update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getRepository()) .isEqualTo(otherRepo); gApi.changes().id(testChangeId).current().submit(); }
@Test public void disabledCheckerNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations.checker(testCheckerUuid).forUpdate().disable().update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.DISABLED); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void enabledCheckerNotBlockingSubmitIfNoBlockingCondition() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations .checker(testCheckerUuid) .forUpdate() .repository(otherRepo) .update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getRepository()) .isEqualTo(otherRepo); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); }
gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); @Test public void enabledCheckerBlockingSubmitIfInBlockingState() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); exception.expect(ResourceConflictException.class); exception.expectMessage("Passing all blocking checks required"); gApi.changes().id(testChangeId).current().submit(); } @Test public void multipleCheckerBlockingSubmit() throws Exception { // Two enabled and required checkers. They are blocking if any of them isn't passing. CheckerUuid testCheckerUuid2 = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .create(); postCheckResult(testCheckerUuid, CheckState.SUCCESSFUL); postCheckResult(testCheckerUuid2, CheckState.FAILED); exception.expect(ResourceConflictException.class); exception.expectMessage("Passing all blocking checks required"); gApi.changes().id(testChangeId).current().submit(); } @Test public void multipleCheckerNotBlockingSubmit() throws Exception { // Two enabled and required checkers. They are not blocking if all of them are passing. CheckerUuid testCheckerUuid2 = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .create(); postCheckResult(testCheckerUuid, CheckState.SUCCESSFUL); postCheckResult(testCheckerUuid2, CheckState.SUCCESSFUL); gApi.changes().id(testChangeId).current().submit(); }
public class OwnersParser { public Result parseFile(String dir, String[] lines) { Result result = new Result(); int n = 0; for (String line : lines) { parseLine(result, dir, line, ++n); } return result; } public Result parseFile(String dir, String content) { Result result = new Result(); int n = 0; String[] lines = content.split("\n"); for (String line : lines) { parseLine(result, dir, line, ++n); } return result; } private void parseLine(Result result, String dir, String line, int lineNumber) { // Parse the line and add the parsed data to the result } } public class Result { // Define the data structure for storing the parsed result }
public static void parseIncludedFile(Result result, String dir, int num, String[] parsedKPF, boolean isInclude) { if (isInclude) { includeFile(result, dir, num, parsedKPF, true); } else { result.errors.add(errorMsg(stack.currentFile(), num, "ignored unknown line", line)); } } public static void includeFile(Result result, String dir, int num, String[] parsedKPF, boolean isInclude) { // implementation }
} } /** * Find and parse an included file and append data to the 'result'. * For an 'include' statement, parsed data is all append to the given result parameter. * For a 'file:' statement or directive, only owner emails are appended. * If the project+file name is found in the stored result set, the stored result is reused. * The inclusion is skipped if to be included file is already on the including file stack. * * @param result to where the included file data should be added. * @param dir the including file's directory or glob. * @param num source code line number * @param parsedKPF the parsed line of include or file directive. * @param addAll to add all parsed data into result or not. */ private void includeFile(Result result, String dir, int num, String[] parsedKPF, boolean addAll) { String keyword = parsedKPF[0]; String project = parsedKPF[1];
assertThat(r2.owner2paths).isEmpty(); assertThat(r2.warnings).containsExactly(w2, w1); assertThat(r2.noParentGlobs).containsExactly(b2, b1); assertThat(r1.noParentGlobs).containsExactly(b1); assertThat(r2.errors).containsExactly(e2, e1); r1.append(r2, "", true); assertThat(r1.owner2paths).isEmpty(); assertThat(r2.owner2paths).isEmpty(); assertThat(r1.warnings).containsExactly(w1, w2); assertThat(r1.warnings).containsExactly(w2, w1); assertThat(r1.noParentGlobs).containsExactly(b2, b1); assertThat(r1.errors).containsExactly(e1, e2); assertThat(r1.errors).containsExactly(e2, e1);
import org.eclipse.jgit.treewalk.filter.PathFilterGroup; import org.junit.Test; @TestPlugin(name = "find-owners", sysModule = "com.googlesource.gerrit.plugins.findowners.Module") public class OwnersFileSubmitRuleIT extends AbstractDaemonTest { @Test public void TestChangeWithoutPermissions() throws Exception { createTestRepositoryContent(); setProjectConfig("enforceLevel", "ENFORCE"); PushOneCommit.Result r = createCommitAndPush(testRepo, "refs/for/master", "test message", "A/1/foo.c", "void main()"); approve(r.getChangeId()); ChangeInfo result = gApi.changes().id(r.getChangeId()).get(); assertThat(result.submittable).isFalse(); } private void createTestRepositoryContent() throws Exception { grant(project, "refs/for/master", Permission.PUSH); TestRepository<InMemoryRepository>.CommitBuilder cb = testRepo.branch("master").commit(); cb.add("OWNERS", "alice@example.com\nbob@example.com\n"); cb.add("A/1/foo.c", "int main()\n"); } }
import com.google.gerrit.reviewdb.client.ChangeNotes; import com.google.gerrit.server.cache.CacheModule; import com.google.gerrit.server.cache.proto.Cache.PureRevertKeyProto; import com.google.gerrit.server.change.ChangeNotes.Factory; import com.google.gerrit.server.change.ChangeNotes.RevId; import com.google.gerrit.server.change.ChangeNotes.RevertOf; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.Builder; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.Builder; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.Builder; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.RevertOfKeyProtoTypeTypeType; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.Builder; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.RevertOfKeyProtoTypeTypeType; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.Builder; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.RevertOfKeyProtoTypeTypeType; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey
/** * @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ChangeNotes} */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { if (claimedRevert.getChange().getRevertOf() == null) { throw new BadRequestException("revertOf not set"); } ChangeNotes changeNotes = notesFactory.createChecked( claimedRevert.getProjectName(), claimedRevert.getChange().getRevertOf()); return isPureRevert( claimedRevert.getProjectName(), ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(changeNotes.getCurrentPatchSet().getRevision().get())); } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. */
private final GitRepositoryManager repositoryManager; private final Set<Project.NameKey> repositoryNameKeys; @Inject public JGitHealthCheck(ListeningExecutorService executor, HealthCheckConfig config, GitRepositoryManager repositoryManager) { super(executor, config, JGIT); this.repositoryManager = repositoryManager; this.repositoryNameKeys = config.getJGITRepositories(JGIT); } @Override protected Result doCheck() throws Exception { for (Project.NameKey repoNameKey : repositoryNameKeys) { try (Repository repo = repositoryManager.openRepository(repoNameKey)) { repo.open(repo.resolve("refs/meta/config")).getType(); } } return Result.PASSED; } }
generateSshHostKeys(); remover.remove("bc(pg|pkix|prov)-.*[.]jar"); private static boolean isOff(String listenHostname) { return "off".equalsIgnoreCase(listenHostname) || "none".equalsIgnoreCase(listenHostname) || "no".equalsIgnoreCase(listenHostname); } private void generateSshHostKeys() throws InterruptedException, IOException { if (!exists(site.ssh_key) && (!exists(site.ssh_rsa) || !exists(site.ssh_dsa) || !exists(site.ssh_ed25519) || !exists(site.ssh_ecdsa))) { System.err.print("Generating SSH host key ..."); System.err.flush(); // Generate the SSH daemon host key using ssh-keygen. // final String comment = "gerrit-code-review@" + hostname(); // Workaround for JDK-6518827 - zero-length argument ignored on Win32 String emptyPassphraseArg = HostPlatform.isWin32() ? "\"\"" : ""; if (!exists(site.ssh_rsa)) { System.err.print(" rsa..."); System.err.flush(); new ProcessBuilder( Review: This should be formatted with gjf. Fixed Code: generateSshHostKeys(); remover.remove("bc(pg|pkix|prov)-.*[.]jar"); private static boolean isOff(String listenHostname) { return "off".equalsIgnoreCase(listenHostname) || "none".equalsIgnoreCase(listenHostname) || "no".equalsIgnoreCase(listenHostname); } private void generateSshHostKeys() throws InterruptedException, IOException { if (!exists(site.ssh_key) && (!exists(site.ssh_rsa) || !exists(site.ssh_dsa) || !exists(site.ssh_ed25519) || !exists(site.ssh_ecdsa))) { System.err.print("Generating SSH host key ..."); System.err.flush(); // Generate the SSH daemon host key using ssh-keygen. // final String comment = "gerrit-code-review@" + hostname(); // Workaround for JDK-6518827 - zero-length argument ignored on Win32 String emptyPassphraseArg = HostPlatform.isWin32() ? "\"\"" : ""; if (!exists(site.ssh_rsa)) { System.err.print(" rsa..."); System.err.flush(); new ProcessBuilder( Buggy Code: private String keyToString(Object key) { if(key instanceof StringKey) { return ((String
public Collection<SubmitRecord> evaluate(ChangeData cd, SubmitRuleOptions options) { ProjectState projectState = projectCache.get(cd.project()); PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance(projectState, pluginName); EnforcementLevel enforce_level = pluginConfig.getEnum(EnforcementLevel.CONFIG_NAME, EnforcementLevel.DISABLED); if (enforce_level == EnforcementLevel.DISABLED) { return ImmutableList.of(); } Checker checker = new Checker(repoManager, pluginConfigFactory, projectState, cd, 1); int result; try { OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager) .get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } }
public Collection<SubmitRecord> evaluate(ChangeData cd, SubmitRuleOptions options) { ProjectState projectState = projectCache.get(cd.project()); PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance(projectState, pluginName); EnforcementLevel enforceLevel = pluginConfig.getEnum(EnforcementLevel.CONFIG_NAME, EnforcementLevel.DISABLED); if (enforceLevel == EnforcementLevel.DISABLED) { return ImmutableList.of(); } Checker checker = new Checker(repoManager, pluginConfigFactory, projectState, cd, 1); int result; try { OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager) .get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } }
protected void writeLog(IStatus[] statuses) { if (logFile.exists()) { logFile.delete(); } for (IStatus status : statuses) { RuntimeLog.log(status); } } throws ResourceNotFoundException, OrmException, IOException { if (input == null) { input = new Input(); } Account a = dbProvider.get().accounts().get(user.getAccountId()); if (a == null) { throw new ResourceNotFoundException("account not found"); } a.setStatus(input.status); dbProvider.get().accounts().update(Collections.singleton(a)); byIdCache.evict(a.getId()); return Strings.isNullOrEmpty(a.getStatus()) ? Response.<String>none() : Response.ok(a.getFullName()); } writeTrashFile("target/com/B.java", ""); writeTrashFile("target/org/A.java", ""); writeTrashFile("target/org/B.java", ""); writeTrashFile(".gitignore", "/target"); git.add().addFilepattern("readme").call(); git.commit().setMessage("initial").call(); diff = new IndexDiff(db, Constants.HEAD, new FileTreeIterator(db)); diff.diff(); assertEquals(new HashSet<String>(Arrays.asList("src")), diff.getUntrackedFolders()); git.add().addFilepattern("src").call(); writeTrashFile("sr/com/X1.java", ""); writeTrashFile("src/tst/A.java", ""); writeTrashFile("src/tst/B.java", ""); deleteTrashFile(".gitignore"); diff = new IndexDiff(db, Constants.HEAD, new FileTreeIterator(db)); diff.diff(); assertEquals(new HashSet<String>(Arrays.asList("target", "src/tst")), diff.getUntrackedFolders()); pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } SubmitRecord sr = new SubmitRecord(); sr.requirements = SUBMIT_REQUIREMENTS; if (result >= 0) { sr.status = Status.OK; return ImmutableList.of(sr); } sr.status = enforceLevel == ENFORCE ? Status.NOT_READY : Status.OK; return ImmutableList.of(sr);
import com.google.gerrit.extensions.api.changes.SubmitInput; import com.google.gerrit.extensions.common.ChangeInfo; import com.google.gerrit.server.config.PluginConfig; import org.eclipse.jgit.lib.ObjectLoader; import org.eclipse.jgit.revwalk.RevObject; import org.eclipse.jgit.revwalk.RevTree; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Test; @TestPlugin(name = "find-owners", sysModule = "com.googlesource.gerrit.plugins.findowners.Module") public class OwnersFileSubmitRuleIT extends LightweightPluginDaemonTest { @Test public void testChangeWithoutPermissions() throws Exception { createTestRepositoryContent(); configurePlugin("enforceLevel", "ENFORCE"); PushOneCommit.Result r = createChange("test message", "A/1/foo.c", "void main()\n"); approve(r.getChangeId()); ChangeInfo result = gApi.changes().id(r.getChangeId()).get(); assertThat(result.submittable).isFalse(); } private void createTestRepositoryContent() throws Exception { addFile("init", "OWNERS", "per-file *.c = alice@example.com, bob@example.com\n"); } }
public String pathFor(String projectName, String refName) { return "/" + projectName + "/" + refName; } public static String pathFor(String projectName, String refName) { return "/" + projectName + "/" + refName; } private final CuratorFramework client; public ZkRefInfoDAO(CuratorFramework client) { this.client = client; } public Optional<ZkRefInfo> read(String projectName, String refName) throws Exception { final String rootPath = pathFor(projectName, refName); if (!exists(rootPath)) return Optional.empty(); final ObjectId objectId = readObjectIdAt(rootPath + "/" + OBJECT_ID_PATH); return Optional.of(new ZkRefInfo(projectName, refName, objectId)); } public void update(ZkRefInfo info) throws Exception { writeInTransaction(info, () -> client.transactionOp().setData()); } public void create(ZkRefInfo info) throws Exception { client.createContainers(pathFor(info)); writeInTransaction(info, () -> client.transactionOp().create().withMode(PERSISTENT)); } private void writeInTransaction(
import com.google.gerrit.server.query.change.ChangeData; import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder() .setFallbackText("All required checks must pass") .setType("passing_all_blocking_checks") .build(); public static class Module extends FactoryModule { @Override public void configure() { bind(SubmitRule.class) .annotatedWith(Exports.named("ChecksSubmitRule")) .to(ChecksSubmitRule.class); } } private final Checks checks; @Inject public ChecksSubmitRule(Checks checks) { this.checks = checks; } @Override public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) { Project.NameKey project = changeData.project(); Change.Id changeId = changeData.getId(); // rest of the code } }
import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder() .setFallbackText("Passing all blocking checks required") .setType("checks_pass") .build(); public static class Module extends FactoryModule { @Override public void configure() { bind(SubmitRule.class) .annotatedWith(Exports.named("ChecksSubmitRule")) .to(ChecksSubmitRule.class); } } private final Checks checks; @Inject public ChecksSubmitRule(Checks checks) { this.checks = checks; } @Override public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) { Project.NameKey project = changeData.project(); Change.Id changeId = changeData.getId(); PatchSet.Id currentPathSetId; try { // code logic here } catch (OrmException | IOException e) { logger.atSevere().withCause(e).log("Failed to evaluate submit rule for change %s", changeId); return Collections.emptyList(); } } }
import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId; private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); result.assertOkStatus(); testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); approve(testChangeId); testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { // Test code here } }
testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. Project.NameKey otherRepo = new Project.NameKey("other-project"); checkerOperations.checker(testCheckerUuid).forUpdate().repository(allProjects).update(); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations.checker(testCheckerUuid).forUpdate().disable().update(); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); }
private static class Helper { public static String pathFor(String projectName, Ref ref) { return pathFor(projectName, ref.getName()); } public static String pathFor(String projectName, String refName) { return "/" + projectName + "/" + refName; } public static ObjectId readObjectId(byte[] value) { return ObjectId.fromRaw(value); } public static byte[] writeObjectId(ObjectId value) throws IOException { final ByteArrayOutputStream out = new ByteArrayOutputStream(); final DataOutputStream stream = new DataOutputStream(out); value.copyRawTo(stream); return out.toByteArray(); } }
import com.google.common.collect.ImmutableList; import com.google.gerrit.extensions.api.changes.RevisionApi; import com.google.gerrit.extensions.common.CheckInfo; import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.ResourceConflictException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.server.change.RevisionResource; import com.google.inject.Inject; import java.io.IOException; import java.util.Map; import java.util.stream.Collectors; import static java.util.stream.Collectors.toMap; public class ListChecks implements RevisionApi.ListChecks { private final CheckBackfiller checkBackfiller; private final CheckJson.Factory checkJsonFactory; private final Checkers checkers; private final Checks checks; @Inject ListChecks( CheckBackfiller checkBackfiller, CheckJson.Factory checkJsonFactory, Checkers checkers, Checks checks) { this.checkBackfiller = checkBackfiller; this.checkJsonFactory = checkJsonFactory; this.checkers = checkers; this.checks = checks; } @Override public ImmutableList<CheckInfo> apply(RevisionResource resource) throws AuthException, BadRequestException, ResourceConflictException, RestApiException, IOException { CheckJson checkJson = checkJsonFactory.create(options); Map<CheckerUuid, Checker> checkersByUuid = checkers.checkersOf(resource.getProject()).stream() .collect(toMap(Checker::getUuid, c -> c)); ImmutableList.Builder<CheckInfo> result = ImmutableList.builderWithExpectedSize(checkersByUuid.size()); for (Check check : checks.getChecks(resource.getProject(), resource.getPatchSet().getId())) { checkersByUuid.remove(check.key().checkerUuid()); result.add(checkJson.format(check)); } for (Check check : checkBackfiller.getBackfilledChecksForRelevantCheckers( checkersByUuid.values(), resource.getNotes(), resource.getPatchSet().getId())) { result.add(checkJson.format(check)); } return result.build(); } }
Optional<Check> getCheck(CheckKey checkKey) throws OrmException, IOException; @AutoValue abstract class GetChecksOptions { public abstract boolean backfillChecks(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_Checks_GetChecksOptions.Builder().setBackfillChecks(false); } public static GetChecksOptions defaults() { return builder().build(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setBackfillChecks(boolean backfillChecks); public abstract GetChecksOptions build(); } }
private final CuratorFramework client; private final RetryPolicy retryPolicy; @Inject public ZkSharedRefDatabase(CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } else { final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } }
@Inject public ZkSharedRefDatabase(CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } else { final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } } catch (Exception e) { logger.atWarning().withCause(e).log("Failed to compare and put ref"); throw new IOException("Failed to compare and put ref", e); } }
import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.server.config.AllProjectsName; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private static final SubmitRequirementInfo SUBMIT_REQUIREMENT_INFO = new SubmitRequirementInfo( "NOT_READY", "All required checks must pass", "checks_pass", ImmutableMap.of()); @Inject private AllProjectsName allProjects; private String testChangeId; private PatchSet.Id testPatchSetId; @Before public void setUp() throws Exception { allProjects = plugin.getSysInjector().getInstance(AllProjectsName.class); PushOneCommit.Result result = createChange(); testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { // Test code here } }
protected void configure() { bind(ChangesCollection.class); bind(Revisions.class); bind(Reviewers.class); bind(DraftComments.class); bind(Comments.class); bind(Files.class); bind(Votes.class); bind(BlameCache.class).to(BlameCacheImpl.class); DynamicMap.mapOf(binder(), CHANGE_KIND); DynamicMap.mapOf(binder(), COMMENT_KIND); DynamicMap.mapOf(binder(), DRAFT_COMMENT_KIND); DynamicMap.mapOf(binder(), FILE_KIND); DynamicMap.mapOf(binder(), REVIEWER_KIND); DynamicMap.mapOf(binder(), REVISION_KIND); DynamicMap.mapOf(binder(), CHANGE_EDIT_KIND); DynamicMap.mapOf(binder(), VOTE_KIND); get(CHANGE_KIND).to(GetChange.class); get(CHANGE_KIND, "detail").to(GetDetail.class); get(CHANGE_KIND, "topic").to(GetTopic.class); get(CHANGE_KIND, "in").to(IncludedIn.class); get(CHANGE_KIND, "hashtags").to(GetHashtags.class); } // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.gerrit.sshd.CommandMetaData; import com.google.gerrit.sshd.SshCommand; import com.google.gson.JsonObject; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.replication.ReplicationConfig.FilterType; import org.kohsuke.args4j.Option; import java.util.List; @CommandMetaData(name = "list", description = "List specific slaves information") final class ListCommand extends SshCommand { private static final char endl = '\n'; @Option(name = "--detail", usage = "Display slave detail information") private boolean detail; @Option(name = "--slave", metaVar = "PATTERN", usage = "pattern to match slave name on") private String slave; @Option(name = "--format", usage = "plain|json output format, plain is the default") private String format; @Inject private ReplicationConfig config; @Override protected void run() { List<Destination> dest = config.getDestinations(FilterType.ALL); for (Destination d : dest) { // code logic here } } } import org.eclipse.sirius.diagram
public String getStoreKey() { return m_storeKey; } protected String getStoreKey() { return m_storeKey; } public boolean isTypeSupported(Class<T> clazz) { // TODO: Add other types? Float, etc if (String.class.isAssignableFrom(clazz) || Integer.class.isAssignableFrom(clazz) || Boolean.class.isAssignableFrom(clazz)) { return true; } return false; } protected boolean isTypeSupported(Class<T> clazz) { // TODO: Add other types? Float, etc if (String.class.isAssignableFrom(clazz) || Integer.class.isAssignableFrom(clazz) || Boolean.class.isAssignableFrom(clazz)) { return true; } return false; } @Before public void setUpCheckersPlugin() throws Exception { checkerOperations = plugin.getSysInjector().getInstance(CheckerOperations.class); checkOperations = plugin.getSysInjector().getInstance(CheckOperations.class); checkersApi = plugin.getHttpInjector().getInstance(Checkers.class); checksApiFactory = plugin.getHttpInjector().getInstance(ChecksFactory.class); pendingChecksApi = plugin.getHttpInjector().getInstance(PendingChecks.class); allowGlobalCapabilities(group("Administrators").getGroupUUID(), "checks-administrateCheckers"); } protected TestCheckerCreation.Builder newRequiredChecker() { return checkerOperations .newChecker() .repository(project) .status(CheckerStatus.ENABLED) .blockingConditions(BlockingCondition.STATE_NOT_PASSING); }
Buggy Code: ```java fetch(repo, checkerRef + ":checkerRef"); repo.reset("checkerRef"); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.PUSH); PushOneCommit.Result r = pushFactory.create(admin.getIdent(), repo).to(checkerRef); r.assertErrorStatus(); r.assertMessage("direct update of checker ref not allowed"); } @Test public void submitToCheckerRefsIsDisabled() throws Exception { // TODO(xchangcheng): remove the "disable" after figuring out the expecting behavior of // CombinedCheckState. Currently, this **not-required** checker is blocking submission but // it shouldn't. CheckerUuid checkerUuid = checkerOperations.newChecker().status(CheckerStatus.DISABLED).create(); String checkerRef = checkerUuid.toRefName(); String changeId = createChangeWithoutCommitValidation(checkerRef); grantLabel( "Code-Review", -2, 2, allProjects, CheckerRef.REFS_CHECKERS + "*", false, adminGroupUuid(), false ); approve(changeId); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.SUBMIT); exception.expect(ResourceConflictException.class); } ``` Refactored Code: ```java fetch(repo, checkerRef + ":checkerRef"); repo.reset("checkerRef"); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.PUSH); PushOneCommit.Result r = pushFactory.create(admin.getIdent(), repo).to(checkerRef); r.assertErrorStatus(); r.assertMessage("direct update of checker ref not allowed"); } @Test public void submitToCheckerRefsIsDisabled() throws Exception { CheckerUuid checkerUuid = checkerOperations.newChecker().status(CheckerStatus.DISABLED).create(); String checkerRef = checkerUuid.toRefName(); String changeId = createChangeWithoutCommitValidation(checkerRef); grantLabel( "Code-Review", -2, 2, allProjects, CheckerRef.REFS_CHECKERS + "*", false, adminGroupUuid(), false ); approve(changeId); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.SUBMIT); exception.expect(ResourceConflictException.class); } ```
@Inject private AllProjectsName allProjects; testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. Project.NameKey otherRepo = new Project.NameKey(allProjects.get()); checkerOperations.checker(checkerUuid).forUpdate().repository(otherRepo).update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); checkerOperations.checker(checkerUuid).forUpdate().disable().update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } // @Test
public void emptyString() { ParameterizedString p = new ParameterizedString(""); assertThat(p.getPattern()).isEqualTo(""); assertThat(p.getRawPattern()).isEqualTo(""); assertThat(p.getParameterNames().isEmpty()).isTrue(); Map<String, String> a = new HashMap<>(); assertThat(p.bind(a)).isNotNull(); assertThat(p.bind(a)).isEmpty(); assertThat(p.replace(a)).isEmpty(); } import org.eclipse.jgit.api.errors.GitAPIException; import org.junit.Test; import java.io.IOException; import java.util.List; public class GetRelatedIT extends AbstractDaemonTest { @Inject private ChangeEditUtil editUtil; @Inject private ChangeEditModifier editModifier; @Test public void getRelatedNoResult() throws GitAPIException, IOException, Exception { PushOneCommit push = pushFactory.create(db, admin.getIdent()); PatchSet.Id ps = push.to(git, "refs/for/master").getPatchSetId(); List<ChangeAndCommit> related = getRelated(ps); assertThat(related).isEmpty(); } @Test public void getRelatedLinear() throws GitAPIException, IOException, Exception { add(git, "a.txt", "1"); Commit c1 = createCommit(git, admin.getIdent(), "subject: 1"); add(git, "b.txt", "2"); Commit c2 = createCommit(git, admin.getIdent(), "subject: 2"); pushHead(git, "refs/for/master", false); for (Commit c : ImmutableList.of(c2, c1)) { // code block } } public void emptyString() { ParameterizedString p = new ParameterizedString(""); assertThat(p.getPattern()).isEqualTo(""); assertThat(p.getRawPattern()).isEqualTo(""); assertThat(p.getParameterNames().isEmpty()).isTrue(); Map<String, String> a = new HashMap<>(); assertThat(p.bind(a)).isNotNull(); assertThat(p.bind(a)).isEmpty(); assertThat(p.replace(a)).isEmpty(); } import org.eclipse.jgit.api.errors.GitAPIException; import org.junit.Test; import java.io.IOException; import java.util.List; public class GetRelatedIT extends AbstractDaemonTest { @Inject private ChangeEditUtil editUtil; @Inject private ChangeEditModifier editModifier; @Test public void
CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.SUCCESSFUL); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isFalse(); CheckerUuid checkerUuid = newRequiredChecker().create(); CheckerUuid testCheckerUuid2 = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.SUCCESSFUL); postCheckResult(testCheckerUuid2, CheckState.FAILED); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isFalse();
import com.google.gwt.user.client.ui.Anchor; import com.google.gwt.user.client.ui.Composite; import com.google.gwt.user.client.ui.HTMLPanel; import com.google.gwt.user.client.ui.Label; import com.google.gwtorm.client.KeyUtil; import java.util.LinkedList; import java.util.List; public class PatchSetSelectBox extends Composite { interface Binder extends UiBinder<HTMLPanel, PatchSetSelectBox> { } private static Binder uiBinder = GWT.create(Binder.class); interface BoxStyle extends CssResource { String selected(); String sideMarker(); String hidden(); } PatchScript script; Patch.Key patchKey; PatchSet.Id idSideA; PatchSet.Id idSideB; PatchSet.Id idActive; Side side; PatchScreen.Type screenType; List<Anchor> links; @UiField HTMLPanel linkPanel; @UiField BoxStyle style; @UiField SpanElement sideMarker; public enum Side { A, B } public PatchSetSelectBox(Side side, final PatchScreen.Type type) { this.side = side; this.screenType = type; return Collections.emptyList(); } public int getCount() { return count; } public void reset() { count = 0; } @Override public Module createModule() { return new AbstractModule() { @Override protected void configure() { testRefOperationListener = new TestRefOperationValidationListener(); DynamicSet.bind(binder(), RefOperationValidationListener.class) .toInstance(testRefOperationListener); } }; } static { System.setProperty("gerrit.notedb", "ON"); } @After public void cleanup() { testRefOperationListener.reset(); } @Test public void aNormalPushShouldTriggerARefOperationValidation() throws Exception { PushOneCommit.Result r = createCommitAndPush(testRepo, "refs/heads/master", "msg", "file", "content"); assertThat(testRefOperationListener.getCount()).isEqualTo(1); } @Test public void aMagicRefUpdateShouldTriggerARefOperationValidationOnChangesBranch() throws Exception { PushOneCommit.Result r = createChange("refs/for/master"); } }
String.format("checker %s not found", checkerUuid))); if (checker.getStatus() == CheckerStatus.DISABLED) { return ImmutableList.of(); } List<ChangeData> changes = queryMatchingChangesFor(checker); List<PendingChecksInfo> pendingChecks = new ArrayList<>(changes.size()); for (ChangeData cd : changes) { getMatchingPendingChecks(cd.project(), cd.currentPatchSet().getId()) .ifPresent(pendingChecks::add); } return pendingChecks; } private List<ChangeData> queryMatchingChangesFor(Checker checker) throws ConfigInvalidException, OrmException { Predicate<ChangeData> predicate = new ProjectPredicate(checker.getRepository().get()); if (checker.getQuery().isPresent()) { String query = checker.getQuery().get(); try { predicate = Predicate.and(predicate, queryBuilderProvider.get().parse(query)); } catch (QueryParseException e) { logger.atWarning().withCause(e).log( "Invalid query for checker %s: %s", checker.getUuid(), query); } } return queryProvider.get().query(predicate); }
CheckablePatchSetInfo patchSet = actual().patchSet; Truth.assertThat(patchSet).named("patch set").isNotNull(); return patchSet;
install(new NoteDbCheckersModule()); bind(CapabilityDefinition.class) .annotatedWith(Exports.named(AdministrateCheckersCapability.NAME)) .to(AdministrateCheckersCapability.class); DynamicSet.bind(binder(), CommitValidationListener.class) .to(CheckerCommitValidator.class) .in(SINGLETON); DynamicSet.bind(binder(), MergeValidationListener.class) .to(CheckerMergeValidator.class) .in(SINGLETON); DynamicSet.bind(binder(), RefOperationValidationListener.class) .to(CheckerRefOperationValidator.class) .in(SINGLETON); bind(ChangeAttributeFactory.class) .annotatedWith(Exports.named("checks")) .to(ChangeCheckAttributeFactory.class); bind(DynamicOptions.DynamicBean.class) .annotatedWith(Exports.named(GetChange.class)) .to(GetChangeOptions.class); install(new ApiModule());
import org.eclipse.jgit.lib.ObjectId; import org.junit.Test; public class CheckerDefinitionTest { @Test public void notRequiredIfNoBlockingCondition() { Checker checker = newChecker().setBlockingConditions(ImmutableSortedSet.of()).build(); assertThat(checker.isRequired()).isFalse(); } @Test public void requiredIfHasBlockingConditionStateNotPassing() { Checker checker = newChecker().setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)).build(); assertThat(checker.isRequired()).isTrue(); } private Checker.Builder newChecker() { return Checker.builder() .setRepository(new NameKey("test-repo")) .setStatus(CheckerStatus.ENABLED) .setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)) .setUuid(CheckerUuid.parse("schema:any-id")) .setCreatedOn(TimeUtil.nowTs()) .setUpdatedOn(TimeUtil.nowTs()) .setRefState(ObjectId.zeroId()); } }
import org.assertj.core.api.Assertions; import org.junit.Test; public class CheckerTest { @Test public void requiredIfHasNoBlockingCondition() { Checker checker = newChecker().build(); Assertions.assertThat(checker.isRequired()).isFalse(); } @Test public void requiredIfHasBlockingConditionStateNotPassing() { Checker checker = newChecker() .setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)) .build(); Assertions.assertThat(checker.isRequired()).isTrue(); } private Checker.Builder newChecker() { return Checker.builder() .setRepository(new NameKey("test-repo")) .setStatus(CheckerStatus.ENABLED) .setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)) .setUuid(CheckerUuid.parse("schema:any-id")) .setCreatedOn(TimeUtil.nowTs()) .setUpdatedOn(TimeUtil.nowTs()) .setRefState(ObjectId.zeroId()); } }
public CombinedCheckState reload(Project.NameKey project, PatchSet.Id psId) throws OrmException { CombinedCheckStateCacheKeyProto key = key(project, psId); CombinedCheckState newState = loader.load(key); CombinedCheckState oldState = cache.getIfPresent(key); if (newState != oldState) { cache.put(key, newState); } return newState; } @VisibleForTesting public void putForTest(Project.NameKey project, PatchSet.Id psId, CombinedCheckState state) { cache.put(key(project, psId), state); } @VisibleForTesting public CacheStats getStats() { return cache.stats(); }
private ChangeCheckInfo forGetChange(ChangeData cd, GetChangeOptions opts) throws OrmException { if (opts != null && opts.combined) { return new ChangeCheckInfo(combinedCheckStateCache.reload(cd.project(), cd.change().currentPatchSetId())); } return null; } private ChangeCheckInfo forQueryChanges(ChangeData cd, QueryChangesOptions opts) throws OrmException { if (opts != null && opts.combined) { return new ChangeCheckInfo(combinedCheckStateCache.get(cd.project(), cd.change().currentPatchSetId())); } return null; }
RefUpdate refUpdate = repo.updateRef(refName); refUpdate.setExpectedOldObjectId(parent); refUpdate.setNewObjectId(newCommitId); refUpdate.setRefLogIdent(personIdent); refUpdate.setRefLogMessage(message, false); refUpdate.update(); RefUpdateUtil.checkResult(refUpdate); try { combinedCheckStateCache.reload(checkKey.project(), checkKey.patchSet()); } catch (OrmException e) { logger.atWarning().withCause(e).log("failed to reload CombinedCheckState for %s", checkKey); } gitRefUpdated.fire(checkKey.project(), refUpdate, currentUser.map(user -> user.state()).orElse(null)); return readSingleCheck(checkKey, repo, rw, newCommitId); } private void assertCheckerIsPresent(CheckerUuid checkerUuid) throws ConfigInvalidException, IOException { checkers.getChecker(checkerUuid).orElseThrow(() -> new IOException(checkerUuid + " missing")); } private boolean updateNotesMap(CheckKey checkKey, CheckUpdate checkUpdate, Repository repo, RevWalk rw, ObjectInserter ins, ObjectId curr, ObjectId newCommitId) throws IOException { try (ObjectReader reader = rw.getObjectReader()) { NoteMap noteMap = NoteMap.read(reader, curr); Note note = noteMap.get(checkKey.patchSet()); if (note == null) { return false; } CheckState oldState = note.getState(); CheckState newState = checkUpdate.getState(); if (oldState == newState) { return false; } note.setState(newState); noteMap.set(checkKey.patchSet(), note); noteMap.write(reader, ins); return true; } }
public void setReviewerUpdates(List<ReviewerStatusUpdate> reviewerUpdates) { this.reviewerUpdates = reviewerUpdates; } @Test public void updatingCheckStateUpdatesCache() throws Exception { CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); cache.putForTest(project, psId, CombinedCheckState.IN_PROGRESS); CacheStats start = clone(cache.getStats()); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.IN_PROGRESS)); CacheStats stats = cache.getStats().minus(start); assertThat(stats.hitCount()).isEqualTo(1); assertThat(stats.missCount()).isEqualTo(0); // Set non-required checker to FAILED, updating combined check state to WARNING. stats = cache.getStats().minus(start); assertThat(stats.hitCount()).isEqualTo(2); assertThat(stats.missCount()).isEqualTo(0); }
protected JComponent createNorthPanel() { JPanel titlePanel = new JPanel(new BorderLayout()); JBLabel label = new JBLabel("Your Virtual Devices"); Font font = label.getFont(); if (font == null) { font = UIUtil.getLabelFont(); } font = new Font(font.getName(), font.getStyle() | Font.BOLD, font.getSize() + 4); label.setFont(font); label.setBorder(new EmptyBorder(18, 12, 12, 12)); titlePanel.add(label, BorderLayout.WEST); return titlePanel; } public CreateAvdAction(@NotNull AvdInfoProvider avdInfoProvider) { super(avdInfoProvider, "Create Virtual Device...", "Create a new Android Virtual Device", AllIcons.General.Add); } @Singleton public class ForwardedIndexChangeHandler extends ForwardedIndexingHandler<String> { private final ChangeIndexer indexer; private final SchemaFactory<ReviewDb> schemaFactory; private final ChangeFinder changeFinder; @Inject ForwardedIndexChangeHandler(ChangeIndexer indexer, SchemaFactory<ReviewDb> schemaFactory, ChangeFinder changeFinder) { this.indexer = indexer; this.schemaFactory = schemaFactory; this.changeFinder = changeFinder; } @Override protected void doIndex(String id, Optional<?> body) throws IOException, OrmException { ChangeNotes change = null; try (ReviewDb db = schemaFactory.open()) { change = changeFinder.findOne(id); if (change != null) { indexer.index(db, change.getChange()); log.debug("Change {} successfully indexed", id); } } catch (Exception e) { if (!isCausedByNoSuchChangeException(e)) { throw e; } log.debug("Change {} was deleted, aborting forwarded indexing the change.", id); } if (change == null) { // Handle the case when change is null } } public Account.Id getAccountId() { return accountId; } ExternalId.Key getExternalId() { return externalId; } String getSessionId() { return sessionId; } String getAuth() { return auth; } boolean needsCookieRefresh() { return refreshCookieAt <= nowMs(); } boolean isPersistentCookie() { return persistentCookie; } private void
private transient String auth; Val( Account.Id accountId, long refreshCookieAt, boolean persistentCookie, ExternalId.Key externalId, long expiresAt, String sessionId, String auth) { this.accountId = accountId; this.refreshCookieAt = refreshCookieAt; this.persistentCookie = persistentCookie; this.externalId = externalId; this.expiresAt = expiresAt; this.sessionId = sessionId; this.auth = auth; } public long getExpiresAt() { return expiresAt; } public Account.Id getAccountId() { return accountId; } ExternalId.Key getExternalId() { return externalId; } String getSessionId() { return sessionId; } String getAuth() { return auth; } boolean needsCookieRefresh() { return refreshCookieAt <= nowMs(); } boolean isPersistentCookie() { return persistentCookie; } private void writeObject(ObjectOutputStream out) throws IOException { writeVarInt32(out, 1); writeVarInt32(out, accountId.get()); }
// See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.server.git.validators.RefOperationValidationListener; import com.google.inject.AbstractModule; import com.google.inject.name.Names; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.SharedRefDatabase; public class ValidationModule extends AbstractModule { private Configuration cfg; public ValidationModule(Configuration cfg) { this.cfg = cfg; } @Override protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class); bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getSplitBrain().getZookeeper().buildCurator()); bind(RetryPolicy.class).annotatedWith(Names.named("ZkLockRetryPolicy")); } }
ZookeeperTestContainerSupport zookeeperContainer; ZkSharedRefDatabase zkSharedRefDatabase; @Before public void setup() { zookeeperContainer = new ZookeeperTestContainerSupport(); zkSharedRefDatabase = new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); } @After public void cleanup() { zookeeperContainer.cleanup(); } @Test public void shouldCompareAndCreateSuccessfully() throws Exception { Ref ref = refOf(AN_OBJECT_ID_1); zookeeperContainer.createRefInZk(A_TEST_PROJECT_NAME, ref); assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue(); assertThat(zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref)) .isEqualTo(ref.getObjectId()); } @Test public void shouldCompareAndPutSuccessfully() throws Exception { Ref oldRef = refOf(AN_OBJECT_ID_1); Ref newRef = refOf(AN_OBJECT_ID_2); String projectName = A_TEST_PROJECT_NAME; zookeeperContainer.createRefInZk(projectName, oldRef); zkSharedRefDatabase.compareAndPut(projectName, oldRef, newRef); assertThat(zookeeperContainer.readRefValueFromZk(projectName, newRef)) .isEqualTo(newRef.getObjectId()); }
private static void assertInvalidQuery(String query, String expectedMessage) { try { CheckerQuery.clean(query); assert_().fail("expected BadRequestException"); } catch (BadRequestException e) { assertThat(e).hasMessageThat().isEqualTo(expectedMessage); } }
private void hasType(int expectedType) { isNotNull(); int actualType = actual().getType(); check("type()") .that(actualType) .named("expected %s, actual %s", typeName(expectedType), typeName(actualType)) .isEqualTo(expectedType); }
for (GitReferenceUpdatedListener.Update u : event.getUpdates()) { if (u.getRefName().startsWith("refs/changes/")) { cache.invalidate(new Project.NameKey(event.getProjectName())); break; } } static class Loader extends CacheLoader<Project.NameKey, List<Change>> { private final SchemaFactory<ReviewDb> schema; @Inject Loader(SchemaFactory<ReviewDb> schema) { this.schema = schema; } @Override public List<Change> load(Project.NameKey key) throws Exception { final ReviewDb db = schema.open(); try { return Collections.unmodifiableList(db.changes().byProject(key).toList()); } finally { db.close(); } } } }
private void reflowAsync() { Display.getDefault().asyncExec(new Runnable() { @Override public void run() { getParentSection().getTaskEditorPage().reflow(); } }); } public void handleEvent(Event event) { if (columnDataList.get(event.index).getPercentageProvider() != null) { TmfStatisticsTreeNode node = (TmfStatisticsTreeNode) event.item.getData(); if (TmfBaseColumnDataProvider.HIDDEN_FOLDER_LEVELS.contains(node.getName())) { return; } double percentage = columnDataList.get(event.index).getPercentageProvider().getPercentage(node); if ((event.detail & SWT.SELECTED) > 0) { event.gc.fillRectangle(event.x, event.y, event.width, event.height); event.detail &= ~SWT.SELECTED; } // Drawing the percentage text // if events are present in top node // and the current node is not the top node // and if is total or partial events column. // If not, exit the method. } } if (checkerUuid == null) { throw new BadRequestException("checker UUID is required"); } Checker checker = checkers.getChecker(checkerUuid) .orElseThrow(() -> new UnprocessableEntityException(String.format("checker %s not found", checkerUuid))); if (checker.getStatus() == CheckerStatus.DISABLED) { return ImmutableList.of(); } // The query system can only match against the current patch set; ignore non-current patch sets // for now. List<ChangeData> changes = checker.queryMatchingChanges(retryHelper, queryBuilderProvider.get(), changeQueryProvider); List<PendingChecksInfo> pendingChecks = new ArrayList<>(changes.size()); for (ChangeData cd : changes) { getPostFilteredPendingChecks(cd.project(), cd.currentPatchSet().getId()) .ifPresent(pendingChecks::add); } return pendingChecks; private Optional<PendingChecksInfo> getPostFilteredPendingChecks(Project.NameKey project, PatchSet.Id patchSetId) throws OrmException, IOException { CheckState checkState = getCheckState(project, patchSetId); // ... implementation details ... }
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.plugins.checks.index; import static com.google.common.base.Preconditions.checkNotNull; import com.google.gerrit.index.query.QueryParseException; import com.google.gerrit.plugins.checks.Check; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gwtorm.server.OrmException; public class CheckStatePredicate extends CheckPredicate { public static CheckStatePredicate parse(String value) throws QueryParseException { return new CheckStatePredicate( CheckState.tryParse(value) .orElseThrow( () -> new QueryParseException(String.format("invalid check state: %s", value)))); } private final CheckState checkState; public CheckStatePredicate(CheckState checkState) { super(CheckQueryBuilder.FIELD_STATE, checkState.name()); this.checkState = checkNotNull(checkState, "checkState"); } @Override public boolean match(Check check) throws OrmException { return checkState.equals(check.state()); } }
public CheckerPredicate(CheckerUuid checkerUuid) { super(CheckQueryBuilder.FIELD_CHECKER, Objects.requireNonNull(checkerUuid, "checkerUuid must not be null").toString()); this.checkerUuid = checkerUuid; }
boolean isRest(ServletRequest req) { return req instanceof HttpServletRequest && resturi.matcher(((HttpServletRequest) req).getServletPath()).matches(); }
public void containsMessages(String... expectedLines) { checkArgument(expectedLines.length > 0, "use hasNoMessages()"); isNotNull(); Iterable<String> got = Splitter.on("\n").split(trimMessages()); check("trimmedMessages()").that(got).containsAllIn(expectedLines).inOrder(); }
@Test public void insertCheckerTwice() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); CheckerUuid checkerUuid = CheckerUuid.parse("foo:bar"); Project.NameKey project = new Project.NameKey("some-project"); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid); } @Test public void removeCheckers() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project = new Project.NameKey("some-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("bar:baz"); CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:bar"); CheckerUuid checkerUuid3 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project); checkersByRepositoryNotes.insert(checkerUuid2, project); checkersByRepositoryNotes.insert(checkerUuid3, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project)); }
CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project1); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1)).containsExactly(checkerUuid1); assertThat(checkersByRepositoryNotes.get(project2)).isEmpty(); checkersByRepositoryNotes.remove(checkerUuid2, project1); checkersByRepositoryNotes.remove(checkerUuid1, project2); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1)).containsExactly(checkerUuid1); assertThat(checkersByRepositoryNotes.get(project2)).isEmpty(); @Test public void updateCheckers() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project1 = new Project.NameKey("some-project"); Project.NameKey project2 = new Project.NameKey("other-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("foo:bar"); CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project1); checkersByRepositoryNotes.insert(checkerUuid2, project1); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1)).containsExactly(checkerUuid1); assertThat(checkersByRepositoryNotes.get(project2)).isEmpty(); }
Fixed Code: ```java CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); CheckerUuid checkerUuid = CheckerUuid.parse("foo:bar"); Project.NameKey project = new Project.NameKey("some-project"); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThatCommitMessage() .isEqualTo("Update checkers by repository\n\nChecker: " + checkerUuid.toString() + "\nRepository: " + project.get()); @Test public void noNewCommitOnNoOp() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project = new Project.NameKey("some-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("foo:bar"); checkersByRepositoryNotes.insert(checkerUuid1, project); commit(checkersByRepositoryNotes); ObjectId commitId = getRefsMetaCheckersState(); checkersByRepositoryNotes.insert(checkerUuid1, project); commit(checkersByRepositoryNotes); assertThat(getRefsMetaCheckersState()).isEqualTo(commitId); checkersByRepositoryNotes.update(checkerUuid1, project, project); commit(checkersByRepositoryNotes); assertThat(getRefsMetaCheckersState()).isEqualTo(commitId); } ```
List<SQLEntry> entries = new ArrayList<>(); for (Entry<String, Collection<SQLEntry>> entry : eventsDb.getEvents(query).asMap().entrySet()) { String projectName = entry.getKey(); try { permissionBackend .currentUser() .project(new Project.NameKey(projectName)) .check(ProjectPermission.ACCESS); entries.addAll(entry.getValue()); } catch (AuthException e) { // Ignore } catch (PermissionBackendException e) { log.atFine().withCause(e).log("Cannot check project access permission"); } } return entries.stream().sorted().map(SQLEntry::getEvent).collect(toList()); @Override public void storeEvent(ProjectEvent event) { Project.NameKey projectName = event.getProjectNameKey(); // Rest of the method implementation }
private final ListMultimap<GitilesView.Type, Filter> filters = LinkedListMultimap.create(); private final Map<GitilesView.Type, HttpServlet> servlets = Maps.newHashMap(); private final Config config; private final Renderer renderer; private final GitilesUrls urls; private final Linkifier linkifier; private final GitilesAccess.Factory accessFactory; private final RepositoryResolver<HttpServletRequest> resolver; private final VisibilityCache visibilityCache; private final TimeCache timeCache; private final BlameCache blameCache; private final GitwebRedirectFilter gitwebRedirect; private final Filter errorHandler; private boolean initialized; GitilesFilter() {} GitilesFilter(Config config, Renderer renderer, GitilesUrls urls, GitilesAccess.Factory accessFactory, RepositoryResolver<HttpServletRequest> resolver, VisibilityCache visibilityCache, TimeCache timeCache, BlameCache blameCache, GitwebRedirectFilter gitwebRedirect, Filter errorHandler) { this.config = checkNotNull(config, "config"); this.renderer = renderer; this.urls = urls; this.accessFactory = accessFactory; this.resolver = resolver; this.visibilityCache = visibilityCache; this.timeCache = timeCache; this.blameCache = blameCache; this.gitwebRedirect = gitwebRedirect; this.errorHandler = errorHandler; }
package com.google.gitiles; import javax.annotation.Nullable; import javax.servlet.http.HttpServletResponse; public class RequestFailureException extends RuntimeException { private final FailureReason reason; private String publicErrorMessage = null; public RequestFailureException(FailureReason reason) { super(); this.reason = reason; } public RequestFailureException(FailureReason reason, Throwable cause) { super(cause); this.reason = reason; } public RequestFailureException withPublicErrorMessage(String format, Object... params) { this.publicErrorMessage = String.format(format, params); return this; } public FailureReason getReason() { return reason; } @Nullable public String getPublicErrorMessage() { return publicErrorMessage; } public enum FailureReason { AMBIGUOUS_OBJECT(HttpServletResponse.SC_BAD_REQUEST), BLAME_REGION_NOT_FOUND(HttpServletResponse.SC_NOT_FOUND), CANNOT_PARSE_GITILES_VIEW(HttpServletResponse.SC_NOT_FOUND), INCORECT_PARAMETER(HttpServletResponse.SC_BAD_REQUEST), INCORRECT_OBJECT_TYPE(HttpServletResponse.SC_NOT_FOUND), // Add more failure reasons here } }
public MultiSiteGitRepositoryManager(MultiSiteRepository.Factory multiSiteRepoFactory, GitRepositoryManager gitRepositoryManager) { this.gitRepositoryManager = gitRepositoryManager; this.multiSiteRepoFactory = multiSiteRepoFactory; }
protected void configure() { factory(MultiSiteRepository.Factory.class); factory(MultiSiteRefDatabase.Factory.class); factory(MultiSiteRefUpdate.Factory.class); bind(GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); install(new ZkValidationModule(cfg)); }
protected void configure() { factory(MultiSiteRepository.Factory.class); factory(MultiSiteRefDatabase.Factory.class); factory(MultiSiteRefUpdate.Factory.class); DynamicSet.bind(binder(), GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); DynamicSet.bind(binder(), SharedRefDatabase.class).to(ZkSharedRefDatabase.class); install(new ZkValidationModule(cfg)); }
import com.google.gerrit.reviewdb.client.Project.SubmitType; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.config.AllProjectsName; import com.google.gerrit.server.project.PerformCreateProject; import com.google.gerrit.server.project.CreateProject.Input; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.assistedinject.Assisted; import java.util.Collections; @RequiresCapability(GlobalCapability.CREATE_PROJECT) class CreateProject implements RestModifyView<TopLevelResource, Input> { static class Input { String name; String parent; boolean permissionsOnly; boolean createEmptyCommit; } static class ProjectInfo { final String kind = "gerritcodereview#project"; String id; Input createdWith; void finish(Input input, final AllProjectsName allProjectName) { createdWith = input; id = Url.encode(createdWith.name); if (Strings.isNullOrEmpty(createdWith.parent)) { createdWith.parent = allProjectName.get(); } } } static interface Factory { CreateProject create(String name); } private final PerformCreateProject.Factory createProjectFactory; }
public MultiSiteRepository(MultiSiteRefDatabase.Factory multiSiteRefDbFactory, @Assisted String projectName, @Assisted Repository repository, @Assisted BaseRepositoryBuilder repositoryBuilder) { super(repositoryBuilder); this.multiSiteRefDbFactory = multiSiteRefDbFactory; this.projectName = projectName; this.repository = repository; }
public RefDatabase getRefDatabase() { return multiSiteRefDbFactory.create(projectName, repository.getRefDatabase()); }
import com.googlecode.prolog_cafe.lang.SymbolTerm; import java.io.File; import java.io.IOException; import java.util.ArrayList; import java.util.List; import org.kohsuke.args4j.Option; public class PrologShell extends AbstractProgram { @Option(name = "-s", metaVar = "FILE.pl", usage = "file to load") private List<String> fileName = new ArrayList<>(); @Option(name = "-q", usage = "quiet mode without banner") private boolean quiet; @Override public int run() { if (!quiet) { banner(); } BufferingPrologControl pcl = new BufferingPrologControl(); pcl.setPrologClassLoader(new PrologClassLoader(getClass().getClassLoader())); pcl.setEnabled(Prolog.Feature.IO, true); pcl.setEnabled(Prolog.Feature.STATISTICS, true); pcl.configureUserIO(System.in, System.out, System.err); pcl.initialize(Prolog.BUILTIN); for (String file : fileName) { String path; try { path = new File(file).getCanonicalPath(); } catch (IOException e) { // Handle exception } pcl.load(path); } pcl.run(); return 0; } private void banner() { // Display banner } }
public void replaceChangeMessage(ChangeUpdate update, String targetMessageId, String newMessage) { update.deleteChangeMessageByRewritingHistory(targetMessageId, newMessage); } public static boolean isAutogenerated(@Nullable String tag) { return tag != null && tag.startsWith(AUTOGENERATED_TAG_PREFIX); } public static ChangeMessageInfo createChangeMessageInfo(ChangeMessage message, AccountLoader accountLoader) { PatchSet.Id patchNum = message.getPatchSetId(); }
@Singleton public class MultiSiteGitRepositoryManager implements GitRepositoryManager { private final GitRepositoryManager gitRepositoryManager; @Inject MultiSiteRepository.Factory multiSiteRepoFactory; @Inject public MultiSiteGitRepositoryManager(LocalDiskRepositoryManager localDiskRepositoryManager) { this.gitRepositoryManager = localDiskRepositoryManager; } public MultiSiteGitRepositoryManager(GitRepositoryManager gitRepositoryManager) { this.gitRepositoryManager = gitRepositoryManager; } @Override public Repository openRepository(NameKey name) throws RepositoryNotFoundException, IOException { Repository openRepository = gitRepositoryManager.openRepository(name); return multiSiteRepoFactory.create(name.get(), openRepository); } @Override public Repository createRepository(NameKey name) throws RepositoryCaseMismatchException, RepositoryNotFoundException, IOException { Repository createdRepository = gitRepositoryManager.createRepository(name); return multiSiteRepoFactory.create(name.get(), createdRepository); } @Override public SortedSet<NameKey> list() { return gitRepositoryManager.list(); } }
@Inject public JGitHealthCheck(ListeningExecutorService executor, HealthCheckConfig config, GitRepositoryManager repositoryManager) { super(executor, config, JGIT); this.repositoryManager = repositoryManager; this.repositoryNameKeys = config.getJGITRepositories(JGIT); } @Override protected Result doCheck() throws Exception { for (Project.NameKey repoNameKey : repositoryNameKeys) { try (Repository repo = repositoryManager.openRepository(repoNameKey)) { repo.open(repo.resolve("refs/meta/config")).getType(); } } return Result.PASSED; } public List<String> getMenuIdNames() { if (myMenus != null) { return myMenus; } boolean token = RenderSecurityManager.enterSafeRegion(myCredential); try { final XmlFile xmlFile = myRenderTask.getPsiFile(); String commaSeparatedMenus = xmlFile == null ? null : AndroidPsiUtils.getRootTagAttributeSafely(xmlFile, ATTR_MENU, TOOLS_URI); if (commaSeparatedMenus != null) { myMenus = new ArrayList<String>(); Iterables.addAll(myMenus, Splitter.on(',').trimResults().omitEmptyStrings().split(commaSeparatedMenus)); } else { final String fqn = xmlFile == null ? null : AndroidPsiUtils.getDeclaredContextFqcn(myRenderTask.getModule(), xmlFile); if (fqn != null) { final Project project = xmlFile.getProject(); DumbService.getInstance(project).smartInvokeLater(new Runnable() { @Override public void run() { // Glance at the onCreateOptionsMenu of the associated context and use any menus found there. } }); } } } finally { RenderSecurityManager.exitSafeRegion(token); } return myMenus; } public int getNavigationMode() { XmlFile xmlFile = myRenderTask.getPsiFile(); String navMode = StringUtil.notNullize(xmlFile == null ? null : AndroidPsiUtils.getRootTagAttributeSafely(xmlFile, ATTR_NAV_MODE, TOOLS_URI)).trim(); if (navMode.equalsIgnoreCase(VALUE_NAV_MODE_TABS)) { return NAVIGATION_MODE_TABS; } if (navMode.equalsIgnoreCase(VALUE_NAV_MODE_LIST)) { return NAVIGATION_MODE_LIST; } return NAVIGATION_MODE_STANDARD; } this.gitRepositoryManager = localDiskRepositoryManager; public MultiSiteGitRepositoryManager
import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Configuration { private static final Logger log = LoggerFactory.getLogger(Configuration.class); public static final String PLUGIN_NAME = "multi-site"; static final String INSTANCE_ID_FILE = "instanceId.data"; static final String THREAD_POOL_SIZE_KEY = "threadPoolSize"; static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; static final int DEFAULT_THREAD_POOL_SIZE = 4; static final String NUM_STRIPED_LOCKS = "numStripedLocks"; static final int DEFAULT_NUM_STRIPED_LOCKS = 10; }
import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate; private final RefDatabase refDb; private final SharedRefDatabase sharedRefDb; private final List<ReceiveCommand> receiveCommands; private final String projectName; public static class RefPair { final Ref oldRef; final Ref newRef; final Exception exception; RefPair(Ref oldRef, Ref newRef) { this.oldRef = oldRef; this.newRef = newRef; this.exception = null; } RefPair(Ref newRef, Exception e) { this.newRef = newRef; this.oldRef = SharedRefDatabase.NULL_REF; this.exception = e; } public boolean hasFailed() { return exception != null; } } }
private final Index index; private final KafkaSubscriber subscriber; private final Kafka kafka; private final ZookeeperConfig zookeeperConfig; @Inject Configuration(SitePaths sitePaths) { this(new FileBasedConfig(sitePaths.etc_dir.resolve(PLUGIN_NAME + ".config").toFile(), FS.DETECTED)); load(); }
protected void configure() { bind(ReplicationQueue.class).in(Scopes.SINGLETON); bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(ReplicationQueue.class); DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), HeadUpdatedListener.class).to(ReplicationQueue.class); bind(OnStartStop.class).in(Scopes.SINGLETON); bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(OnStartStop.class); bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(ReplicationLogFile.class); bind(CredentialsFactory.class) .to(AutoReloadSecureCredentialsFactoryDecorator.class) .in(Scopes.SINGLETON); bind(CapabilityDefinition.class) .annotatedWith(Exports.named(START_REPLICATION)) .to(StartReplicationCapability.class); install(new FactoryModuleBuilder().build(PushAll.Factory.class)); install(new FactoryModuleBuilder().build(ReplicationState.Factory.class)); bind(ReplicationConfig.class).to(AutoReloadConfigDecorator.class); DynamicSet.setOf(binder(), ReplicationStateListener.class); }
try { rateLimiterHolder = limitsPerAccount.get(accountId); } catch (ExecutionException e) { rateLimiterHolder = Holder.EMPTY; log.warn("Cannot get rate limits for account ''{}''", accountId, e); } } else { try { rateLimiterHolder = limitsPerRemoteHost.get(req.getRemoteHost()); } catch (ExecutionException e) { rateLimiterHolder = Holder.EMPTY; log.warn("Cannot get rate limits for anonymous access from remote host ''%s''", req.getRemoteHost(), e); } } if (!rateLimiterHolder.hasGracePermits() && rateLimiterHolder.get() != null && !rateLimiterHolder.get().tryAcquire()) { String msg = MessageFormat.format(limitExceededMsg, rateLimiterHolder.get().getRate() * SECONDS_PER_HOUR, rateLimiterHolder.getBurstPermits()); ((HttpServletResponse) res).sendError(SC_TOO_MANY_REQUESTS, msg); return; } } chain.doFilter(req, res); } boolean isRest(ServletRequest req) {
public void run() { try { dispatcher.get().postEvent(new HeartbeatEvent()); } catch (OrmException e) { logger.error("Failed to post heartbeat event: {}", e.getMessage(), e); } }
if (itemTs.isPresent()) { count++; newLastIndexTs = maxTimestamp(newLastIndexTs, itemTs.get()); } catch (Exception e) { log.atSevere().withCause(e).log("Unable to reindex %s %s", itemNameString, c); errors++; } long elapsedNanos = stopwatch.stop().elapsed(TimeUnit.NANOSECONDS); if (count > 0) { log.atInfo().log("%s %ss reindexed in %d msec (%d/sec), %d failed", count, itemNameString, elapsedNanos / 1000000L, (count * 1000L) / (elapsedNanos / 1000000L), errors); } else if (errors > 0) { log.atInfo().log("%d %ss failed to reindex", errors, itemNameString); } else { log.atFine().log("Scanning finished"); } indexTs.update(itemName, newLastIndexTs.toLocalDateTime()); } catch (Exception e) { log.atSevere().withCause(e).log("Unable to scan %ss", itemNameString); }
try { ChangeChecker checker = changeCheckerFactory.create(id); Optional<ChangeNotes> changeNotes = checker.getChangeNotes(); if (changeNotes.isPresent()) { ChangeNotes notes = changeNotes.get(); reindex(notes); if (checker.isChangeUpToDate(indexEvent)) { if (retryCount > 0) { log.atWarning().log("Change %s has been eventually indexed after %d attempt(s)", id, retryCount); } else { log.atFine().log("Change {} successfully indexed", id); } } else { log.atWarning().log("Change %s seems too old compared to the event timestamp (event-Ts=%s >> change-Ts=%s)", id, indexEvent, checker); rescheduleIndex(id, indexEvent, retryCount + 1); } } else { indexer.delete(parseChangeId(id)); log.atWarning().log("Change %s could not be found in the local Git repository (eventTs=%s), deleted from index", id, indexEvent); } } catch (Exception e) { // Handle exception }
setHeaders(rsp); try { List<String> params = Splitter.on('/').splitToList(req.getPathInfo()); String cacheName = params.get(CACHENAME_INDEX); String json = req.getReader().readLine(); forwardedCacheEvictionHandler.evict(CacheEntry.from(cacheName, GsonParser.fromJson(cacheName, json))); rsp.setStatus(SC_NO_CONTENT); } catch (CacheNotFoundException e) { log.atSevere().log("Failed to process eviction request: {}", e.getMessage()); sendError(rsp, SC_BAD_REQUEST, e.getMessage()); } catch (IOException e) { log.atSevere().withCause(e).log("Failed to process eviction request"); sendError(rsp, SC_BAD_REQUEST, e.getMessage()); }
for (; ; ) { try { execCnt++; tryOnce(); log.atFine().log("%s %s towards %s OK", action, key, destination); return true; } catch (ForwardingException e) { int maxTries = cfg.http().maxTries(); log.atFine().withCause(e).log("Failed to %s %s on %s [%d/%s]", action, key, destination, execCnt, maxTries); if (!e.isRecoverable()) { log.atSevere().withCause(e).log("%s %s towards %s failed with unrecoverable error; giving up", action, key, destination); return false; } if (execCnt >= maxTries) { log.atSevere().log("Failed to %s %s on %s after %d tries; giving up", action, key, destination, maxTries); return false; } log.atFine().log("Retrying to %s %s on %s", action, key, destination); try { Thread.sleep(cfg.http().retryInterval()); } catch (InterruptedException ie) { log.atFine().withCause(ie).log("Interrupted while sleeping"); return false; } } }
try { action, key, destination); return false; } if (execCnt >= maxTries) { log.atSevere().log( "Failed to %s %s on %s after %d tries; giving up", action, key, destination, maxTries); return false; } log.atFine().log("Retrying to %s %s on %s", action, key, destination); try { Thread.sleep(cfg.http().retryInterval()); } catch (InterruptedException ie) { log.atSevere().withCause(e).log( "%s %s towards %s was interrupted; giving up", action, key, destination); Thread.currentThread().interrupt(); return false; }
public void viewAccepted(View view) { log.atInfo().log("viewAccepted(view: %s) called", view); synchronized (this) { if (view.getMembers().size() > 2) { log.atWarning().log("%d members joined the jgroups cluster %s (%s). Only two members are supported. Members: {}", view.getMembers().size(), jgroupsConfig.clusterName(), channel.getName(), view.getMembers()); } if (peerAddress != null && !view.getMembers().contains(peerAddress)) { log.atInfo().log("viewAccepted(): removed peerInfo"); peerAddress = null; peerInfo = Optional.empty(); } } if (view.size() > 1) { try { channel.send(new Message(null, myUrl)); } catch (Exception e) { log.atSevere().withCause(e).log("Sending a message over channel %s to cluster %s failed", channel.getName(), jgroupsConfig.clusterName()); } } }
public void connect() { try { channel = getChannel(); Optional<InetAddress> address = finder.findAddress(); if (address.isPresent()) { log.atFine().log("Protocol stack: %s", channel.getProtocolStack()); channel.getProtocolStack().getTransport().setBindAddress(address.get()); log.atFine().log("Channel bound to {}", address.get()); } else { log.atWarning().log("Channel not bound: address not present"); } channel.setReceiver(this); channel.setDiscardOwnMessages(true); channel.connect(jgroupsConfig.clusterName()); log.atInfo().log( "Channel %s successfully joined jgroups cluster %s", channel.getName(), jgroupsConfig.clusterName() ); } catch (Exception e) { if (channel != null) { log.atSevere().withCause(e).log( "joining cluster %s (channel %s) failed", jgroupsConfig.clusterName(), channel.getName() ); } else { log.atSevere().withCause(e).log( "joining cluster %s failed", jgroupsConfig.clusterName() ); } } }
import com.google.gerrit.extensions.annotations.Listen; import com.google.gerrit.server.events.CommitReceivedEvent; import com.google.gerrit.server.git.validators.CommitValidationException; import com.google.gerrit.server.git.validators.CommitValidationListener; import com.google.gerrit.server.git.validators.CommitValidationMessage; import com.google.inject.Singleton; @Listen @Singleton public class CommitMessageLengthValidation implements CommitValidationListener { @Override public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException { final RevCommit commit = receiveEvent.commit; final AbbreviatedObjectId id = commit.abbreviate(7); List<CommitValidationMessage> messages = new ArrayList<CommitValidationMessage>(); if (65 < commit.getShortMessage().length()) { messages.add(new CommitValidationMessage("(W) " + id.name() + ": commit subject >65 characters; use shorter first paragraph", false)); } int longLineCnt = 0, nonEmptyCnt = 0; for (String line : commit.getFullMessage().split("\n")) { if (!line.trim().isEmpty()) { nonEmptyCnt++; } } return messages; } } // Install breakpoint on the expected line logWriter.println("Install breakpoint in " + BreakpointOnCatchDebuggee.BREAKPOINT_METHOD_NAME); int requestID = installBreakpointOnCatch(classID, methodID); // execute the breakpoint synchronizer.sendMessage(JPDADebuggeeSynchronizer.SGNL_CONTINUE); CommandPacket event = debuggeeWrapper.vmMirror.receiveCertainEvent(JDWPConstants.EventKind.BREAKPOINT); ParsedEvent[] parsedEvents = ParsedEvent.parseEventPacket(event); assertEquals("Invalid number of events:", 1, parsedEvents.length); assertEquals("Invalid request ID:", requestID, parsedEvents[0].getRequestID()); long eventThreadID = ((EventThread) parsedEvents[0]).getThreadID(); checkThreadState(eventThreadID, JDWPConstants.ThreadStatus.RUNNING, JDWPConstants.SuspendStatus.SUSPEND_STATUS_SUSPENDED); logWriter.println("Successfully suspended on a catch statement"); logWriter.println("testBreakpointOnCatch done"); } // ACCEPT cases: 1. Notify, no verify; 2. no notify, no verify; // 3. privacy override. if (!notif.needVerify || notif.privacyOverride) {
import javax.servlet.http.HttpServletResponse; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class RestApiRateLimiter extends AllRequestFilter { private static final Logger log = LoggerFactory.getLogger(RestApiRateLimiter.class); private static final int SECONDS_PER_HOUR = 3600; static final int SC_TOO_MANY_REQUESTS = 429; private final Provider<CurrentUser> user; private final LoadingCache<Account.Id, Holder> limitsPerAccount; private final LoadingCache<String, Holder> limitsPerRemoteHost; private final Pattern servletPath = Pattern.compile("^/(?:a/)?" + "(access|accounts|changes|config|groups|plugins|projects|Documentation|tools)/(.*)$"); private final String limitExceededMsg; @Inject RestApiRateLimiter(Provider<CurrentUser> user, @Named(HttpModule.CACHE_NAME_RESTAPI_ACCOUNTID) LoadingCache<Account.Id, Holder> limitsPerAccount, @Named(HttpModule.CACHE_NAME_RESTAPI_REMOTEHOST) LoadingCache<String, Holder> limitsPerRemoteHost, @Named(RateMsgHelper.RESTAPI_CONFIGURABLE_MSG_ANNOTATION) String limitExceededMsg) { this.user = user; this.limitsPerAccount = limitsPerAccount; this.limitsPerRemoteHost = limitsPerRemoteHost; this.limitExceededMsg = limitExceededMsg; } }
public class ExampleClass { private Self self; private PermissionBackend permissionBackend; private RestView<TopLevelResource> listCheckers; private Checkers checkers; private DynamicMap<RestView<CheckerResource>> views; private AdministrateCheckersPermission permission; public ExampleClass(Self self, PermissionBackend permissionBackend, RestView<TopLevelResource> listCheckers, Checkers checkers, DynamicMap<RestView<CheckerResource>> views, AdministrateCheckersPermission permission) { this.self = self; this.permissionBackend = permissionBackend; this.listCheckers = listCheckers; this.checkers = checkers; this.views = views; this.permission = permission; } @Override public RestView<TopLevelResource> list() throws RestApiException { return listCheckers; } @Override public CheckerResource parse(TopLevelResource parent, IdString id) throws AuthException, ResourceNotFoundException, PermissionBackendException, IOException, ConfigInvalidException { if (!self.get().isIdentifiedUser()) { throw new AuthException("Authentication required"); } permissionBackend.currentUser().check(permission); Checker checker = checkers.getChecker(id.get()).orElseThrow(() -> new ResourceNotFoundException(id)); return new CheckerResource(checker); } @Override public DynamicMap<RestView<CheckerResource>> views() { return views; } }
import com.google.common.collect.ImmutableList; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectIdRef; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.Storage; import java.util.List; public interface RefUtils { Ref newRef(String refName, ObjectId objectId); default Ref newRef(String refName, ObjectId objectId, Storage storage) { return new ObjectIdRef.Unpeeled(storage, refName, objectId); } default Ref newRef(String refName, ObjectId objectId, ObjectId peeledObjectId, Storage storage) { return new ObjectIdRef.PeeledNonTag(storage, refName, objectId, peeledObjectId); } default Ref newRef(String refName, ObjectId objectId, ObjectId peeledObjectId) { return newRef(refName, objectId, peeledObjectId, Storage.LOOSE); } default Ref newRef(String refName, ObjectId objectId, Storage storage, boolean isPeeled) { if (isPeeled) { return newRef(refName, objectId, storage); } else { return new ObjectIdRef.Unpeeled(storage, refName, objectId); } } default Ref newRef(String refName, ObjectId objectId, ObjectId peeledObjectId, Storage storage, boolean isPeeled) { if (isPeeled) { return newRef(refName, objectId, peeledObjectId, storage); } else { return newRef(refName, objectId, storage); } } default List<String> getRefsToIgnoreInSharedDb() { return ImmutableList.of("refs/draft-comments/.*", "refs/changes/[0-9]+/[0-9]+/[0-9]+"); } default Ref newRef(String project, String newRef) { return newRef(project, newRef, Storage.LOOSE); } }
Refactor: ```java boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); return refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } ```
@Inject public ZkSharedRefDatabase(CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { if (newRef != NULL_REF && ignoreRefInSharedDb(newRef)) { return true; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } catch (Exception e) { throw new IOException(e); } }
static final ObjectId AN_OBJECT_ID_2 = new ObjectId(1, 2, 3, 4, 6); static final ObjectId AN_OBJECT_ID_3 = new ObjectId(1, 2, 3, 4, 7); static final String A_TEST_REF_NAME = "refs/heads/master"; default String aBranchRef() { return RefNames.REFS_HEADS + testBranch(); } default Ref newRef(String refName, ObjectId objectId) { return new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, refName, objectId); } String testBranch();
boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); }
CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } catch (Exception e) { logger.atWarning().withCause(e).log("Failed to compare and put reference"); return false; } }
new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); @After public void cleanup() { zookeeperContainer.cleanup(); } @Test public void shouldCompareAndCreateSuccessfully() throws Exception { Ref ref = refOf(AN_OBJECT_ID_1); assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue(); String data = zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref).getName(); assertThat(data).isEqualTo(ref.getObjectId().getName()); } @Test public void shouldCompareAndPutSuccessfully() throws Exception { Ref oldRef = refOf(AN_OBJECT_ID_1); Ref newRef = refOf(AN_OBJECT_ID_2); String projectName = A_TEST_PROJECT_NAME; zookeeperContainer.createRefInZk(projectName, oldRef); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, newRef)).isTrue(); } @Test public void shouldCompareAndPutWithNullOldRefSuccessfully() throws Exception { Ref oldRef = refOf(null); Ref newRef = refOf(AN_OBJECT_ID_2);
private final AtomicReference<Command> atomicCmd; private final DynamicSet<SshCommandPreExecutionFilter> commandFilters; @Argument(index = 0, required = false, metaVar = "COMMAND", handler = SubcommandHandler.class) private String commandName; @Argument(index = 1, multiValued = true, metaVar = "ARG") private List<String> args = new ArrayList<>(); @Inject DispatchCommand(PermissionBackend permissionBackend, @Assisted Map<String, CommandProvider> all, DynamicSet<SshCommandPreExecutionFilter> commandFilters) { this.permissionBackend = permissionBackend; commands = all; atomicCmd = Atomics.newReference(); this.commandFilters = commandFilters; } Map<String, CommandProvider> getMap() { return commands; } @Override public void start(Environment env) throws IOException { try { parseCommandLine(); if (Strings.isNullOrEmpty(commandName)) { StringWriter msg = new StringWriter(); msg.write(usage()); throw die(msg.toString()); } final CommandProvider p = commands.get(commandName); if (p == null) { String msg = "git-upload-pack: '" + commandName + "' is not a git command. See 'git --help'."; throw die(msg); } final Command cmd = p.get(); atomicCmd.set(cmd); cmd.setArguments(args); cmd.setInputStream(env.getInputStream()); cmd.setOutputStream(env.getOutputStream()); cmd.setErrorStream(env.getErrorStream()); cmd.setEnvironment(env); cmd.setRepository(repoManager.openRepository(env, getProjectName())); cmd.setPermissionBackend(permissionBackend); cmd.setCommandFilters(commandFilters); cmd.execute(); } catch (UnloggedFailure e) { throw die(e.getMessage(), e); } catch (Die e) { throw die(e.getMessage(), e); } catch (Exception e) { throw die("fatal: internal server error", e); } }
Optional<ExternalId> other = null; try { other = externalIds.get(key); } catch (IOException | ConfigInvalidException e) { throw new IllegalArgumentException("Internal error while fetching username='" + username + "'"); } try { accountsUpdateProvider.get().update("Set Username from GitHub", accountId, u -> u.addExternalId(ExternalId.create(key, accountId, null, null))); } catch (OrmDuplicateKeyException dupeErr) { if (!other.isPresent() || !other.get().accountId().equals(accountId)) { throw new IllegalArgumentException("username " + username + " already in use"); } } catch (Exception e) { throw new IllegalArgumentException("Internal error while trying to set username='" + username + "'"); } log.debug("Account {} updated with preferredEmail = {}, fullName = {}, username = {}", accountId, email, fullName, username);
import java.util.Collections; import java.util.List; import java.util.Objects; import java.util.Set; import java.util.function.Predicate; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.URIish; /** Collection of Git repositories destinations for replication. */ public class DestinationsCollection { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final ReplicationConfig replicationConfig; private final Destination.Factory destinationFactory; private final List<Destination> allDestinations; @Inject DestinationsCollection(ReplicationConfig replicationConfig, Destination.Factory destinationFactory) { this.replicationConfig = replicationConfig; this.destinationFactory = destinationFactory; this.allDestinations = Collections.emptyList(); } /** * Get all destinations matching the specified type. * * @param filterType type of destination. * @return list of destinations matching the specified filter type. */ public List<Destination> getAll(FilterType filterType) { if (replicationConfig.reloadIfNeeded()) { try { load(); } catch (ConfigInvalidException e) { // Handle exception } } return Collections.unmodifiableList(allDestinations); } }
import java.util.Objects; import java.util.Set; import java.util.function.Predicate; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.URIish; /** * Collection of Git repositories destinations for replication. */ public class DestinationsCollection { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final ReplicationConfig replicationConfig; private final Destination.Factory destinationFactory; private List<Destination> allDestinations = Collections.emptyList(); @Inject DestinationsCollection(ReplicationConfig replicationConfig, Destination.Factory destinationFactory) { this.replicationConfig = replicationConfig; this.destinationFactory = destinationFactory; } /** * Get all destinations matching the specified type. * * @param filterType type of destination. * @return list of destinations matching the specified filter type. */ public List<Destination> getAll(FilterType filterType) { if (replicationConfig.reloadIfNeeded()) { try { load(); } catch (ConfigInvalidException e) { logger.atSevere().withCause(e).log("Cannot load replication destinations"); } } return allDestinations.stream() .filter(filterType.getPredicate()) .collect(toImmutableList()); } /** * Load the destinations from the replication configuration. * * @throws ConfigInvalidException if the configuration is invalid. */ public void load() throws ConfigInvalidException { List<Destination> destinations = new ArrayList<>(); Config cfg = replicationConfig.getConfig(); Set<String> remoteNames = cfg.getSubsections(REMOTE_SECTION); for (String remoteName : remoteNames) { RemoteConfig remoteConfig = new RemoteConfig(cfg, remoteName); List<URIish> uris = remoteConfig.getURIs(); for (URIish uri : uris) { destinations.add(destinationFactory.create(remoteName, uri)); } } allDestinations = Collections.unmodifiableList(destinations); } }
CheckerUuid checkerUuid = createCheckerInServer(createArbitraryCheckerInput()); boolean exists = checkerOperations.checker(checkerUuid).exists(); assertThat(exists).isTrue(); @Test public void notExistingCheckerCanBeCheckedForExistence() throws Exception { String notExistingCheckerUuid = "test:not-existing-checker"; boolean exists = checkerOperations.checker(notExistingCheckerUuid).exists(); assertThat(exists).isFalse(); } @Test public void retrievingCheckerForInvalidUuidFails() throws Exception { exception.expect(IllegalArgumentException.class); checkerOperations.checker(CheckerTestData.INVALID_UUID).get(); } @Test public void retrievingNotExistingCheckerFails() throws Exception { String notExistingCheckerUuid = "foo:bar"; exception.expect(IllegalStateException.class); checkerOperations.checker(notExistingCheckerUuid).get(); } @Test public void checkerNotCreatedByTestApiCanBeRetrieved() throws Exception { CheckerInput input = createArbitraryCheckerInput(); input.uuid = "test:unique-checker-not-created-via-test-API"; CheckerUuid checkerUuid = createCheckerInServer(input); }
@Override public Check get() throws Exception { return checks .getCheck(key, GetCheckOptions.defaults()) .orElseThrow(() -> new IllegalStateException("Tried to get non-existing test check")); } @Override public ImmutableMap<RevId, String> notesAsText() throws Exception { try (Repository repo = repoManager.openRepository(key.repository()); RevWalk rw = new RevWalk(repo); ObjectReader reader = repo.newObjectReader()) { Ref checkRef = repo.getRefDatabase().exactRef(CheckerRef.checksRef(key.patchSet().changeId)); checkNotNull(checkRef); NoteMap notes = NoteMap.read(reader, rw.parseCommit(checkRef.getObjectId())); ImmutableMap.Builder<RevId, String> raw = ImmutableMap.builder(); for (Note note : notes) { raw.put(new RevId(note.name()), new String(notes.getCachedBytes(note.toObjectId(), Integer.MAX_VALUE))); } return raw.build(); } } @Override public CheckInfo asInfo(ListChecksOption... options) throws Exception { // Implementation }
Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/heads/stable-2.16", AN_OBJECT_ID_1); assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse(); @Test public void compareAndPutShouldAlwaysIngoreIgnoredRefs() throws Exception { Ref existingRef = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_1); Ref oldRefToIgnore = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_2); Ref newRef = SharedRefDatabase.NULL_REF; String projectName = A_TEST_PROJECT_NAME; assertThat(zkSharedRefDatabase.compareAndPut(A_TEST_PROJECT_NAME, existingRef, SharedRefDatabase.NULL_REF)).isTrue(); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRefToIgnore, newRef)).isTrue(); } @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); }
@Test public void compareAndPutShouldAlwaysIngoreIgnoredRefs() throws Exception { Ref existingRef = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_1); Ref oldRefToIgnore = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_2); Ref newRef = SharedRefDatabase.NULL_REF; String projectName = A_TEST_PROJECT_NAME; assertThat(zkSharedRefDatabase.compareAndPut(A_TEST_PROJECT_NAME, existingRef, SharedRefDatabase.NULL_REF)) .isTrue(); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRefToIgnore, newRef)) .isTrue(); } @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); }
private List<ChangeData> executeIndexQueryWithRetry(RetryHelper retryHelper, Provider<ChangeQueryProcessor> changeQueryProcessorProvider, Predicate<ChangeData> predicate) throws OrmException { try { return retryHelper.execute(ActionType.INDEX_QUERY, () -> changeQueryProcessorProvider.get().query(predicate).entities(), OrmException.class::isInstance); } catch (Exception e) { Throwables.throwIfUnchecked(e); Throwables.throwIfInstanceOf(e, OrmException.class); throw new OrmException(e); } }
@Deprecated public static int forkSystemServer(int uid, int gid, int[] gids, boolean enableDebugger, int[][] rlimits) { int debugFlags = enableDebugger ? DEBUG_ENABLE_DEBUGGER : 0; return forkAndSpecialize(uid, gid, gids, debugFlags, rlimits, null, null); } native public static int nativeForkSystemServer(int uid, int gid, int[] gids, int debugFlags, int[][] rlimits, long permittedCapabilities, long effectiveCapabilities); /** * Executes "/system/bin/sh -c <command>" using the exec() system call. * This method throws a runtime exception if exec() failed, otherwise, this * method never returns. * * @param command The shell command to execute. */ public static void execShell(String command) { nativeExecShell(command); } /** * Appends quotes shell arguments to the specified string builder. * The arguments are quoted using single-quotes, escaped if necessary, * prefixed with a space, and appended to the command. * * @param command A string builder for the shell command being constructed. */ public static void appendQuotedShellArguments(StringBuilder command, String... args) { for (String arg : args) { command.append(' '); command.append('\''); command.append(escapeSingleQuotes(arg)); command.append('\''); } } public boolean checkIfYDescriptorValid(IDataChartDescriptor<?, ?> desc, @Nullable IDataChartDescriptor<?, ?> filter) { DescriptorTypeVisitor visitor = new DescriptorTypeVisitor(); desc.accept(visitor); if (visitor.isIndividualType(DescriptorType.STRING)) { return false; } // Only allow descriptors of the same type, that will mean the same // thing. It is hard to compare durations to timestamps for instance return IChartTypeDefinition.filterSameDescriptor(desc, filter); } /** * An implementation of BaseConfig specifically for sending as part of the Android model * through the Gradle tooling API. */ abstract class BaseConfigImpl implements BaseConfig, Serializable { private static final long serialVersionUID = 1L; @NonNull private final Map<String, String> mManifestPlaceholders; @NonNull private final Map<String, ClassField> mBuildConfigFields; @NonNull private final Map<String, ClassField> mResValues; protected BaseConfigImpl(@NonNull BaseConfig
try { UrlValidator.clean(CheckerTestData.INVALID_URL); assert_().fail("expected BadRequestException"); } catch (BadRequestException e) { assertMessage(e, "only http/https URLs supported", CheckerTestData.INVALID_URL); } @Test public void verifyTestQueries() throws Exception { assertInvalidQuery(CheckerTestData.QUERY_WITH_UNSUPPORTED_OPERATOR, "unsupported operator", CheckerTestData.UNSUPPORTED_OPERATOR); assertInvalidQuery(CheckerTestData.INVALID_QUERY, "invalid", CheckerTestData.INVALID_QUERY); } private static void assertInvalidQuery(String query, String... expectedMessageParts) { try { CheckerQuery.clean(query); assert_().fail("expected ConfigInvalidException"); } catch (ConfigInvalidException e) { assertMessage(e, expectedMessageParts); } } private static void assertMessage(Exception e, String... expectedMessageParts) { for (String expectedMessagePart : expectedMessageParts) { assertThat(e).hasMessageThat().ignoringCase().contains(expectedMessagePart); } }
private void queueEvaluationIfNecessary(String repositoryPath) { if (lastCheckExpired(repositoryPath)) { EvaluationTask evaluationTask = evaluationTaskFactory.create(repositoryPath); if (queuedEvaluationTasks.add(evaluationTask)) { Future<?> future = executor.submit(evaluationTask); addTaskListener(future, evaluationTask); timestamps.put(repositoryPath, System.currentTimeMillis()); } } }
private void addTaskListener(Future<?> future, EvaluationTask evaluationTask) { ListenableFuture<?> listenableFuture = JdkFutureAdapters.listenInPoolThread(future); listenableFuture.addListener( new Runnable() { public void run() { queuedEvaluationTasks.remove(evaluationTask); } }, MoreExecutors.directExecutor() ); }
private void addTaskListener(Future<?> future, EvaluationTask evaluationTask) { ListenableFuture<?> listenableFuture = JdkFutureAdapters.listenInPoolThread(future); listenableFuture.addListener( new Runnable() { public void run() { queuedEvaluationTasks.remove(evaluationTask); } }, MoreExecutors.directExecutor() ); }
public void createEvaluator() { when(event.getProjectName()).thenReturn(NAME_KEY.get()); when(config.getExpireTimeRecheck()).thenReturn(0L); when(gerritConfig.getInt("receive", null, "threadPoolSize", Runtime.getRuntime().availableProcessors())) .thenReturn(1); when(repository.getDirectory()).thenReturn(new File(REPOSITORY_PATH)); when(repositoryOther.getDirectory()).thenReturn(new File(REPOSITORY_PATH_OTHER)); taskSamePathCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH); taskSamePathNotCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH); taskDifferentPath = new EvaluationTask(null, null, null, REPOSITORY_PATH_OTHER); Factory eventTaskFactory = mock(Factory.class); when(eventTaskFactory.create(REPOSITORY_PATH)) .thenReturn(taskSamePathNotCompleted) .thenReturn(taskSamePathCompleted); when(eventTaskFactory.create(REPOSITORY_PATH_OTHER)).thenReturn(taskDifferentPath); when(executor.submit(taskSamePathCompleted)).thenReturn(CompletableFuture.completedFuture(null)); }
taskDifferentPath = new EvaluationTask(null, null, null, REPOSITORY_PATH_OTHER); /** Task factory */ Factory eventTaskFactory = mock(Factory.class); when(eventTaskFactory.create(REPOSITORY_PATH)) .thenReturn(taskSamePathNotCompleted) .thenReturn(taskSamePathCompleted); when(eventTaskFactory.create(REPOSITORY_PATH_OTHER)).thenReturn(taskDifferentPath); /** Executor */ when(executor.submit(taskSamePathCompleted)) .thenReturn(CompletableFuture.completedFuture(null)); when(executor.submit(taskSamePathNotCompleted)).thenReturn(new CompletableFuture<>()); when(executor.submit(taskDifferentPath)).thenReturn(CompletableFuture.completedFuture(null)); evaluator = new Evaluator(executor, eventTaskFactory, repoManager, config, gerritConfig);
public static final String GLOBAL_CAPABILITIES = "GLOBAL_CAPABILITIES"; public static final String ALL = "refs/*"; public static final String HEADS = "refs/heads/*"; public static final String REGEX_PREFIX = "^"; private String name; private List<Permission> permissions; public AccessSection(String name) { this.name = name; this.permissions = new ArrayList<>(); } public static boolean isValidRefSectionName(String name) { return name.startsWith("refs/") || name.startsWith("^refs/"); } public String getName() { return name; } public ImmutableList<Permission> getPermissions() { // implementation }
public static final String GLOBAL_CAPABILITIES = "GLOBAL_CAPABILITIES"; /** Pattern that matches all references in a project. */ public static final String ALL = "refs/*"; /** Pattern that matches all branches in a project. */ public static final String HEADS = "refs/heads/*"; /** Prefix that triggers a regular expression pattern. */ public static final String REGEX_PREFIX = "^"; /** Name of the ref pattern or access section. */ private String refPattern; private List<Permission> permissions; public AccessSection(String refPattern) { this.refPattern = refPattern; this.permissions = new ArrayList<>(); } /** @return true if the ref pattern is likely to be a valid reference section name. */ public static boolean isValidRefSectionName(String refPattern) { return refPattern.startsWith("refs/") || refPattern.startsWith("^refs/"); } public String getRefPattern() { return refPattern; } public ImmutableList<Permission> getPermissions() { // implementation }
public AccessSection(String name) { this.name = name; this.permissions = new ArrayList<>(); }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.ConfigInvalidException; /** * Listener of the configuration loading events. */ public interface ReplicationConfigListener { /** * Invoked just before replication.config is about to be loaded. */ void beforeLoad(); /** * Invoked just after replication.config is loaded into memory. * * @throws ConfigInvalidException if the loaded configuration is not valid */ }
Fixed Code: private void innerTest() throws Exception { try { outer(); fail("should throw"); } catch (IllegalStateException e) { StackTraceElement[] trimmed = SuperManifestRefUpdatedListener.trimStack(e.getStackTrace(), Thread.currentThread().getStackTrace()[1]); String str = Arrays.toString(trimmed); assertThat(str).doesNotContain("trimStackTrace"); assertThat(str).contains("innerTest"); }
// Project name is scoped by test, so we need to get it from our initial change Project.NameKey projectNameKey = initialResult.getChange().project(); String projectName = projectNameKey.get(); createBranch(new Branch.NameKey(projectName, "ds_one")); createBranch(new Branch.NameKey(projectName, "ds_two")); initialResult.assertOkStatus(); // Create normalUserGroup, containing current user, and contextUserGroup, containing contextUser String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get(); gApi.groups().id(normalUserGroup).addMembers(user.id().toString()); AccountApi contextUserApi = gApi.accounts().create("someContextUser"); String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get(); gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name); // Grant exclusive +2 to context user grantLabel("Code-Review", -2, 2, projectNameKey, "refs/heads/ds_one", false,
// Project name is scoped by test, so we need to get it from our initial change Project.NameKey projectNameKey = initialResult.getChange().project(); String projectName = projectNameKey.get(); createBranch(new Branch.NameKey(projectName, "ds_one")); createBranch(new Branch.NameKey(projectName, "ds_two")); initialResult.assertOkStatus(); // Create normalUserGroup, containing current user, and contextUserGroup, containing contextUser String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get(); gApi.groups().id(normalUserGroup).addMembers(user.id().toString()); AccountApi contextUserApi = gApi.accounts().create("randomContextUser"); String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get(); gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name); // Grant +2 to context user, since it doesn't have it by default grantLabel("Code-Review", -2, 2, projectNameKey, "refs/heads/*", false);
private final PermissionBackend permissionBackend; private final Map<String, CommandProvider> commands; private final AtomicReference<Command> atomicCmd; private final DynamicSet<SshExecuteCommandInterceptor> commandInterceptors; @Argument(index = 0, required = false, metaVar = "COMMAND", handler = SubcommandHandler.class) private String commandName; @Argument(index = 1, multiValued = true, metaVar = "ARG") private List<String> args = new ArrayList<>(); @Inject DispatchCommand(PermissionBackend permissionBackend, Map<String, CommandProvider> all, DynamicSet<SshExecuteCommandInterceptor> commandInterceptors) { this.permissionBackend = permissionBackend; this.commandInterceptors = commandInterceptors; commands = all; atomicCmd = Atomics.newReference(); } Map<String, CommandProvider> getMap() { return commands; } @Override public void start(Environment env) throws IOException { try { parseCommandLine(); if (Strings.isNullOrEmpty(commandName)) { StringWriter msg = new StringWriter(); msg.write(usage()); throw die(msg.toString()); } // rest of the code }
public void mouseMove(MouseEvent e) { getShell().setCursor(new Cursor(getDisplay(), SWT.CURSOR_CROSS)); if (mModel != null) { int x = getInverseScaledSize(e.x - mDx); int y = getInverseScaledSize(e.y - mDy); coordinateLabel.setText(String.format("(%d,%d)", x, y)); if (mModel.isExploreMode()) { BasicTreeNode node = mModel.updateSelectionForCoordinates(x, y); if (node != null) { updateTreeSelection(node); } } } } import javax.servlet.http.HttpServletResponse; import com.google.gerrit.httpd.HtmlDomUtil; import com.google.inject.Singleton; @Singleton public class HelloWorldServlet extends HttpServlet { private static final long serialVersionUID = 1L; @Override protected void doGet(final HttpServletRequest req, final HttpServletResponse rsp) throws IOException, ServletException { doPost(req, rsp); } @Override protected void doPost(final HttpServletRequest req, final HttpServletResponse rsp) throws IOException, ServletException { rsp.setContentType("text/html"); rsp.setCharacterEncoding("UTF-8"); final Writer out = rsp.getWriter(); out.write("<html>"); out.write("<body>"); out.write("<h2>Hello world!</h2>"); out.write("</body>"); out.write("</html>"); out.close(); } } choseSubmitTypeFrom = cd; } else if (st != submitType) { commitStatus.problem(changeId, String.format( "Change has submit type %s, but previously chose submit type %s " + "from change %s in the same batch", st, submitType, choseSubmitTypeFrom.getId())); continue; } if (chg.currentPatchSetId() == null) { String msg = "Missing current patch set on change"; logger.atSevere().log("%s %s", msg, changeId); commitStatus.problem(changeId, msg); continue; } PatchSet ps; Branch.NameKey destBranch = chg.getDest(); try { ps = cd.currentPatchSet(); } catch (OrmException e) { commitStatus.logProblem(changeId, e); continue; } if (ps == null || ps.getRevision() == null || ps.getRevision().get() == null) { commitStatus.logProblem(changeId, "Missing patch set or revision on change
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.sshd; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; @ExtensionPoint public interface SshExecuteCommandInterceptor { /** * Check the command and return false if this command must not be run. * * @param command the command * @param arguments the list of arguments * @return whether or not this command with this arguments can be executed */ boolean accept(String command, List<String> arguments); default String name() { return this.getClass().getSimpleName(); } }
private void setAccount() throws OrmException, IOException, UnloggedFailure { user = genericUserFactory.create(id); rsrc = new AccountResource(user); try { for (String email : addEmails) { addEmail(email); } for (String email : deleteEmails) { deleteEmail(email); } if (preferredEmail != null) { if (isRegistered(preferredEmail)) { putPreferred(preferredEmail); } else { System.err.println("WARNING: preferred email not set, " + preferredEmail + " not registered"); } } if (fullName != null) { PutName.Input in = new PutName.Input(); in.name = fullName; putName.apply(rsrc, in); } if (httpPassword != null || clearHttpPassword) { PutHttpPassword.Input in = new PutHttpPassword.Input(); in.httpPassword = httpPassword; putHttpPassword.apply(rsrc, in); } if (active) { putActive.apply(rsrc, null); } else if (inactive) { try { deleteActive.apply(rsrc, null); } catch (UnloggedFailure e) { String msg = e.getMessage(); if (!msg.endsWith("\n")) { msg += "\n"; } err.write(msg.getBytes(ENC)); err.flush(); onExit(e.exitCode); } } } catch (UnloggedFailure e) { String msg = e.getMessage(); if (!msg.endsWith("\n")) { msg += "\n"; } err.write(msg.getBytes(ENC)); err.flush(); onExit(e.exitCode); } } // key both send an escape sequence (due to this method) and switch focus // to the Workbench File menu (forcing the user to click in the Terminal // view again to continue entering text). This fixes that. event.doit = false; char character = event.character; int modifierKeys = event.stateMask & SWT.MODIFIER_MASK; boolean ctrlKeyPressed = (event.stateMask & SWT.CTRL) != 0; boolean onlyCtrlKeyPressed = modifierKeys == SWT.CTRL; boolean macCmdKeyPressed = (event.stateMask & SWT.COMMAND) != 0; // To fix SPR 110341, we consider the Alt key to be pressed only when the // Control key is
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.sshd; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; @ExtensionPoint public interface SshExecuteCommandInterceptor { /** * Check the command and return false if this command must not be run. * * @param command the command * @param arguments the list of arguments * @return whether or not this command with these arguments can be executed */ boolean accept(String command, List<String> arguments); default String name() { return this.getClass().getSimpleName(); } }
RevisionCreatedListener.Event event, Map<String, ImmutableList<Match>> findings) throws RestApiException { long startNanos = System.nanoTime(); metrics.reviewCount.increment(); metrics.reviewCountByProject.increment(project); try { boolean tpAllowed = scannerConfig.isThirdPartyAllowed(project); boolean reviewRequired = false; boolean hasAlwaysReview = false; for (Map.Entry<String, ImmutableList<Match>> entry : findings.entrySet()) { if (entry.getValue() == ALWAYS_REVIEW) { reviewRequired = true; hasAlwaysReview = true; break; } PartyType pt = partyType(entry.getValue()); if (pt.compareTo(THIRD_PARTY) > 0) { reviewRequired = true; break; } if (pt == THIRD_PARTY && !tpAllowed) { reviewRequired = true; break; } } ChangeResource change = getChange(event, scannerConfig.fromAccountId); ReviewInput ri = new ReviewInput() .message("Copyright scan") .label(scannerConfig.reviewLabel, reviewRequired ? -1 : +2); if (reviewRequired) { // Set the review flag ri.setReviewFlag(true); } changeApi.revision(change.getId()).review(ri); } catch (Exception e) { // Handle exception } long elapsedNanos = System.nanoTime() - startNanos; metrics.reviewTime.record(elapsedNanos, TimeUnit.NANOSECONDS); }
public String toString() { return "FlatFile WebSession Cleaner"; }
batchUpdate.addCommand(new ReceiveCommand(ref.getObjectId(), ObjectId.zeroId(), refName)); } batchUpdate.execute(rw, NullProgressMonitor.INSTANCE); for (ReceiveCommand command : batchUpdate.getCommands()) { if (command.getResult() != ReceiveCommand.Result.OK) { throw new IOException( String.format("Unstar change %d failed, ref %s could not be deleted: %s", changeId.get(), command.getRefName(), command.getResult())); } } indexer.index(project, changeId); } catch (IOException e) { throw new OrmException(String.format("Unstar change %d failed", changeId.get()), e); }
void execute(PersonIdent refLogIdent, String refLogMessage, PushCertificate pushCert) { if (allUsersRepo == null || allUsersRepo.cmds.isEmpty()) { return; } canCloseEarly = false; @SuppressWarnings("unused") Future<?> possiblyIgnoredError = executor.submit(() -> { try { allUsersRepo.flush(); BatchRefUpdate bru = allUsersRepo.repo.getRefDatabase().newBatchUpdate(); bru.setPushCertificate(pushCert); if (refLogMessage != null) { bru.setRefLogMessage(refLogMessage, false); } else { bru.setRefLogMessage(firstNonNull(NoteDbUtil.guessRestApiHandler(), "Update NoteDb refs"), false); } bru.setRefLogIdent(refLogIdent != null ? refLogIdent : serverIdent.get()); bru.setAtomic(true); allUsersRepo.cmds.addTo(bru); bru.setAllowNonFastForwards(true); RefUpdateUtil.executeChecked(bru, allUsersRepo.rw); } catch (IOException e) { log.error("Error executing batch ref update", e); } finally { allUsersRepo.close(); allUsersRepo.deleteComments(); } }); }
import com.google.gerrit.server.config.AllProjectsName; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.inject.Inject; import com.google.inject.Singleton; /** * Schema upgrade implementation. * * <p>Implementations must have a single non-private constructor with no arguments (e.g. the default * constructor). */ interface NoteDbSchemaVersion { @Singleton class Arguments { final GitRepositoryManager repoManager; final AllProjectsName allProjects; final AllUsersName allUsers; @Inject Arguments(GitRepositoryManager repoManager, AllProjectsName allProjects, AllUsersName allUsers) { this.repoManager = repoManager; this.allProjects = allProjects; this.allUsers = allUsers; } } void upgrade(Arguments args, UpdateUI ui) throws Exception; }
protected boolean shouldSendMessage() { if (sshKey == null && gpgKeys == null) { // Don't email if no keys were added. return false; } if (user.equals(callingUser)) { // Send email if the user self-added a key; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly added. return true; } try { // Don't email if an administrator added a key on behalf of the user. permissionBackend.user(callingUser).check(GlobalPermission.ADMINISTRATE_SERVER); return false; } catch (AuthException | PermissionBackendException e) { // Send email if a non-administrator modified the keys, e.g. by MODIFY_ACCOUNT. return true; } }
@Use(SourceInfoFactory.class) @Filter(TypeWithoutPrebuiltFilter.class) public class CfgBuilder implements RunnableSchedulable<JMethod> { @Nonnull public static final StatisticId<Counter> CREATED_BASIC_BLOCK = new StatisticId<>("jack.cfg.create-basic-block", "Basic block created", CounterImpl.class, Counter.class); @Nonnull public static final StatisticId<Counter> REMOVED_BASIC_BLOCK = new StatisticId<>("jack.cfg.removed-basic-blocks", "Basic blocks removed", CounterImpl.class, Counter.class); @Nonnull private final com.android.jack.util.filter.Filter<JMethod> filter = ThreadConfig.get(Options.METHOD_FILTER); @Nonnull private final Tracer tracer = TracerFactory.getTracer(); private final JSession session = Jack.getSession(); private static class JCaseStatementComparator implements Comparator<JCaseStatement>, Serializable { private static final long serialVersionUID = 1L; @Override public int compare(JCaseStatement case1, JCaseStatement case2) { JLiteral lit1 = case1.getExpr(); JLiteral lit2 = case2.getExpr(); assert lit1 instanceof JValueLiteral; // TODO: Implement the comparison logic return 0; } } } protected void initModel(String projectName, String modelName, Bundle bundle) throws CoreException, IOException { project = ProjectUtils.createProject(projectName); diModelFile = PapyrusProjectUtils.copyPapyrusModel(project, bundle, getSourcePath(), modelName); } protected String getSourcePath() { return "models/"; } protected Bundle getBundle() { return Activator.getDefault().getBundle(); } public ICellEditor getICellEditor(Table table, Object axisElement, ITableAxisElementProvider elementProvider) { super.getICellEditor(table, axisElement, elementProvider); AbstractPapyrusStyledTextCellEditor editor = new UMLReferenceTextWithCompletionCellEditor(table, axisElement, elementProvider); AbstractOpenDialogCellEditorButtonAction openDialog = getCellEditorWithDialogToOpen(axisElement, elementProvider); editor.setOpenDialogCellEditorButtonAction(openDialog); openDialog.setText("..."); openDialog.setTooltipText(Messages.UMLReferenceCellEditorConfiguration_OpenDialogToChooseTheValue); return editor; } protected boolean shouldSendMessage() { if (sshKey == null && gpgKeys
@Override public Response<?> apply(AccountResource.SshKey rsrc, Input input) throws AuthException, OrmException, RepositoryNotFoundException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.user(self).check(GlobalPermission.ADMINISTRATE_SERVER); } IdentifiedUser user = rsrc.getUser(); authorizedKeys.deleteKey(user.getAccountId(), rsrc.getSshKey().getKey().get()); try { deleteKeyFactory.create(user, "SSH").send(); } catch (EmailException e) { log.error("Cannot send SSH key deletion message to " + user.getAccount().getPreferredEmail(), e); } sshKeyCache.evict(user.getUserName()); return Response.none(); }
if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.user(self).check(GlobalPermission.ADMINISTRATE_SERVER); } IdentifiedUser user = rsrc.getUser(); authorizedKeys.deleteKey(user.getAccountId(), rsrc.getSshKey().getKey().get()); try { deleteKeyFactory.create(rsrc.getUser(), "SSH").send(); } catch (EmailException e) { log.error("Cannot send SSH key deletion message to {}", user.getAccount().getPreferredEmail(), e); } sshKeyCache.evict(user.getUserName()); return Response.none();
import java.util.List; import java.util.stream.Collectors; import java.util.stream.Stream; import org.eclipse.jgit.lib.BatchRefUpdate; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.transport.ReceiveCommand.Result; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final BatchRefUpdate batchRefUpdate; private final RefDatabase refDb; private final SharedRefDatabase<? extends AutoCloseable> sharedRefDb; private final String projectName; public static class RefPair { public final Ref oldRef; public final Ref newRef; public final Exception exception; RefPair(Ref oldRef, Ref newRef) { this.oldRef = oldRef; this.newRef = newRef; this.exception = null; } } }
@Override public BatchRefUpdate addProposedTimestamp(ProposedTimestamp ts) { return batchRefUpdate.addProposedTimestamp(ts); } @Override public void execute(RevWalk walk, ProgressMonitor monitor, List<String> options) throws IOException { executeWrapper(walk, monitor, options); } @Override public void execute(RevWalk walk, ProgressMonitor monitor) throws IOException { executeWrapper(walk, monitor, Collections.EMPTY_LIST); } @Override public String toString() { return batchRefUpdate.toString(); } private void updateSharedRefDb(Stream<RefPair> oldRefs, RevWalk walk, ProgressMonitor monitor, List<String> options) throws Exception { List<RefPair> refsToUpdate = oldRefs.sorted(comparing(RefPair::hasFailed).reversed()).collect(Collectors.toList()); if (refsToUpdate.isEmpty()) { return; } if (refsToUpdate.get(0).hasFailed()) { RefPair failedRef = refsToUpdate.get(0); throw new IOException("Failed to fetch ref entries" + failedRef.newRef.getName(), failedRef.exception); } }
try (CloseableSet<AutoCloseable> locks = new CloseableSet()) { assertBatchCommandsAreInSync(refsToUpdate, locks); if (options.isEmpty()) { batchRefUpdate.execute(walk, monitor); } else { batchRefUpdate.execute(walk, monitor, options); } updateSharedDBForSuccessfulCommands(batchRefUpdate.getCommands().stream()); } catch (Exception e) { logger.atWarning().log("Failed to apply full batch %s", e.getMessage()); throw e; } private void updateSharedDBForSuccessfulCommands(Stream<ReceiveCommand> commandStream) throws IOException { List<RefPair> successfulRefPairs = commandStream .filter(cmd -> cmd.getResult() == Result.OK) .map(cmd -> new RefPair( cmd.getOldId() == null ? sharedRefDb.NULL_REF : sharedRefDb.newRef(cmd.getRefName(), cmd.getOldId()), sharedRefDb.newRef(cmd.getRefName(), cmd.getNewId()))) .collect(Collectors.toList()); for (RefPair successfulRefPair : successfulRefPairs) { // Update shared DB } }
logger.atWarning().log("Failed to apply full batch %s", e.getMessage()); throw e; } private void updateSharedDBForSuccessfulCommands(Stream<ReceiveCommand> commandStream) throws IOException { List<RefPair> successfulRefPairs = commandStream .filter(cmd -> cmd.getResult() == Result.OK) .map(cmd -> new RefPair( cmd.getOldId() == null ? sharedRefDb.NULL_REF : sharedRefDb.newRef(cmd.getRefName(), cmd.getOldId()), sharedRefDb.newRef(cmd.getRefName(), cmd.getNewId()))) .collect(Collectors.toList()); for (RefPair successfulRefPair : successfulRefPairs) { sharedRefDb.compareAndPut(projectName, successfulRefPair.oldRef, successfulRefPair.newRef); } } private void assertBatchCommandsAreInSync(List<RefPair> refsToUpdate, CloseableSet<AutoCloseable> locks) throws Exception { for (RefPair refPair : refsToUpdate) { Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null ? sharedRefDb.exactRef(refPair.newRef.getName()) : sharedRefDb.exactRef(refPair.oldRef.getName()); if (nonNullRef == null) { throw new IOException("Ref " + refPair.newRef.getName() + " does not exist"); } try (AutoCloseable lock = locks.acquire(nonNullRef.getName())) { RefUpdate.Result result = updateRef(refPair.newRef, nonNullRef); if (result != RefUpdate.Result.FORCED && result != RefUpdate.Result.NEW) { throw new IOException("Failed to update ref " + refPair.newRef.getName() + ": " + result.name()); } } } }
} } private void assertBatchCommandsAreInSync(List<RefPair> refsToUpdate, CloseableSet<AutoCloseable> locks) throws Exception { for (RefPair refPair : refsToUpdate) { Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null ? refPair.newRef : refPair.oldRef; String resourceLockKey = String.format("%s-%s", projectName, nonNullRef.getName()); locks.addResourceIfNotExist(resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); boolean isInnSync; if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInnSync = sharedRefDb.isMostRecentRefVersion(projectName, refPair.oldRef); } else { isInnSync = !sharedRefDb.isPresent(projectName, refPair.getName()); } if (!isInnSync) { String errorMessage = String.format(
Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null ? refPair.newRef : refPair.oldRef; String resourceLockKey = String.format("%s-%s", projectName, nonNullRef.getName()); locks.addResourceIfNotExist(resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); boolean isInSync; if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInSync = sharedRefDb.isMostRecentRefVersion(projectName, refPair.oldRef); } else { isInSync = !sharedRefDb.isPresent(projectName, refPair.getName()); } if (!isInSync) { String errorMessage = String.format("Ref %s not in sync with sharedDb, aborting batch", refPair.oldRef.getName()); logger.atWarning().log(errorMessage); throw new Exception(errorMessage); }
private static NumberFormat getInstance(Locale desiredLocale, int choice) { DecimalFormatSymbols symbols = new DecimalFormatSymbols(desiredLocale); String pattern = ""; switch (choice) { case CURRENCYSTYLE: pattern = LocaleData.get(desiredLocale).currencyPattern; break; case INTEGERSTYLE: pattern = LocaleData.get(desiredLocale).integerPattern; break; case PERCENTSTYLE: pattern = LocaleData.get(desiredLocale).percentPattern; break; case NUMBERSTYLE: pattern = LocaleData.get(desiredLocale).numberPattern; break; default: throw new IllegalArgumentException("Unknown Choice: " + choice); } return new DecimalFormat(pattern, symbols); }
private void addReplacedMessage(ReplaceRequest u, boolean edit, Boolean isPrivate, Boolean wip) { String subject; if (edit) { try { subject = receivePack.getRevWalk().parseCommit(u.newCommitId).getShortMessage(); } catch (IOException e) { logger.atWarning().withCause(e).log("failed to get subject for edit patch set"); subject = u.notes.getChange().getSubject(); } } else { subject = u.info.getSubject(); } if (isPrivate == null) { isPrivate = u.notes.getChange().isPrivate(); } if (wip == null) { wip = u.notes.getChange().isWorkInProgress(); } ChangeReportFormatter.Input input = ChangeReportFormatter.Input.builder() .setChange(u.notes.getChange()) .setSubject(subject) .setIsEdit(edit) .setIsPrivate(isPrivate) .setIsWorkInProgress(wip) .build(); addMessage(changeFormatter.changeUpdated(input)); } private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException { logger.atFine().log("Found magic branch %s", cmd.getRefName()); MagicBranchInput magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration); logDebug("Found magic branch %s", cmd.getRefName()); magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration); magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER)); magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC)); String ref; magicBranch.cmdLineParser = optionParserFactory.create(magicBranch); try { ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions); } catch (CmdLineException e) { if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) { logger.atFine().log("Invalid branch syntax"); reject(cmd, e.getMessage()); return; } ref = null; // never happens } if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) { reject(cmd, "topic length exceeds the maximum limit"); return; } magicBranch.dest = new Branch.NameKey(project.getName
// changes (weighted 1d). Map<Account.Id, MutableDouble> reviewers = new LinkedHashMap<>(); if (candidates.size() == 0) { return reviewers; } List<Predicate<ChangeData>> predicates = new ArrayList<>(); for (Account.Id id : candidates) { try { Predicate<ChangeData> projectQuery = changeQueryBuilder.project(projectControl.getProject().getName()); // Get all labels for this project and create a compound OR query to // fetch all changes where users have applied one of these labels Predicate<ChangeData> compoundLabelPredicate = null; for (LabelType type : projectControl.getLabelTypes().getLabelTypes()) { Predicate<ChangeData> labelPredicate = changeQueryBuilder.label(type.getName() + ",user=" + id); if (compoundLabelPredicate == null) { compoundLabelPredicate = labelPredicate; } else { compoundLabelPredicate = Predicate.or(compoundLabelPredicate, labelPredicate); } } Predicate<ChangeData> reviewerQuery = Predicate.and(projectQuery, compoundLabelPredicate); Predicate<ChangeData> ownerQuery = Predicate.and(projectQuery, ownerPredicate); predicates.add(reviewerQuery); predicates.add(ownerQuery); } catch (Exception e) { // Handle exception } } // Rest of the code... protected void configure() { DynamicMap.mapOf(binder(), IMAGE_KIND); bind(ImagesCollection.class); child(PROJECT_KIND, "images").to(ImagesCollection.class); delete(IMAGE_KIND).to(DeleteImage.class); postOnCollection(IMAGE_KIND).to(PostImage.class); } super(config, uriInfo, context, dataClient, validator); this.routerId = routerId; } /** * Handler for creating a router route. * * @param route Route object. * @throws StateAccessException Data access error. * @return Response object with 201 status code set if successful. */ @POST @RolesAllowed({ AuthRole.ADMIN, AuthRole.TENANT_ADMIN }) @Consumes({ VendorMediaType.APPLICATION_ROUTE_JSON, MediaType.APPLICATION_JSON }) public Response create(Route route) throws StateAccessException, SerializationException { route.routerId = routerId; validate(route); throwIfNextPortNotValid(route); authoriser.tryAuthoriseRouter(routerId, "add route to this router"); UUID id = dataClient.routesCreate(RouteDataConverter.toData(route)); routerEvent.routeCreate(router
boolean compareAndRemove(String project, Ref oldRef) throws IOException; default boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); }
public ZkSharedRefDatabase(CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return ignoreRefInSharedDb(oldRef) || compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { if (newRef != NULL_REF && ignoreRefInSharedDb(newRef)) { return true; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } catch (Exception e) { throw new IOException("Failed to compare and put ref", e); } }
// When validation of status fails doReturn(false).when(sharedRefDb).isMostRecentRefVersion(A_TEST_PROJECT_NAME, oldRef); RefUpdate refUpdate = RefFixture.RefUpdateStub.forSuccessfulUpdate(oldRef, newRef.getObjectId()); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, A_TEST_PROJECT_NAME, refUpdate); multiSiteRefUpdate.update(); @Test(expected = Exception.class) public void newUpdateShouldFailIfSharedDBUpdateFailsLeavingSystemInInconsistentStatus() throws Exception { // When validation succeeds doReturn(true).when(sharedRefDb).isMostRecentRefVersion(A_TEST_PROJECT_NAME, oldRef); // When compareAndPut fails doReturn(false).when(sharedRefDb).compareAndPut(A_TEST_PROJECT_NAME, oldRef, newRef); RefUpdate refUpdate = RefFixture.RefUpdateStub.forSuccessfulUpdate(oldRef, newRef.getObjectId()); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, A_TEST_PROJECT_NAME, refUpdate); multiSiteRefUpdate.update(); } @Test public void deleteShouldValidateAndSucceed() throws Exception { // When validation succeeds doReturn(true).when(sharedRefDb).isMostRecentRefVersion(A_TEST_PROJECT_NAME, oldRef); // When compareAndPut succeeds doReturn(true).when(sharedRefDb).compareAndPut(A_TEST_PROJECT_NAME, oldRef, newRef); RefUpdate refUpdate = RefFixture.RefUpdateStub.forSuccessfulUpdate(oldRef, newRef.getObjectId()); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, A_TEST_PROJECT_NAME, refUpdate); multiSiteRefUpdate.update(); }
protected int getStackFrameIndex(IStackFrame stackFrame) { int stackFrameIndex = 0; if (((IJavaDebugTarget) fDebugTarget).supportsMonitorInformation()) { IThread thread = stackFrame.getThread(); IDebugElement[] ownedMonitors = JavaDebugUtils.getOwnedMonitors(thread); stackFrameIndex += ownedMonitors.length; IDebugElement contendedMonitor = JavaDebugUtils.getContendedMonitor(thread); if (contendedMonitor != null) { ++stackFrameIndex; } } return stackFrameIndex; } public void lineBreak() { assertOpenBlock(); try { if (currentBlock instanceof MarkdownBlock) { ((MarkdownBlock) currentBlock).lineBreak(); } else { currentBlock.write("\n"); //$NON-NLS-1$ } } catch (IOException e) { throw new RuntimeException(e); } } return; Object value = myAttributesTable.getValueAt(selectedRow, selectedColumn); if (value == null || !(value instanceof EditedStyleItem)) { return; } Component cellComponent = myAttributesTable.getCellRenderer(selectedRow, selectedColumn) .getTableCellRendererComponent(myAttributesTable, selectedItem, false, false, selectedRow, selectedColumn); if (!(cellComponent instanceof JComponent)) { // Doesn't have a tooltip. return; } EditedStyleItem item = (EditedStyleItem)value; Project project = e.getProject(); DocumentationManager documentationManager = DocumentationManager.getInstance(project); final DocumentationComponent docComponent = new DocumentationComponent(documentationManager); docComponent.setText(((JComponent)cellComponent).getToolTipText(), e.getData(CommonDataKeys.PSI_FILE), true); JBPopup hint = JBPopupFactory.getInstance().createComponentPopupBuilder(docComponent, docComponent).setProject(project) .setDimensionServiceKey(project, DocumentationManager.JAVADOC_LOCATION_AND_SIZE, false).setResizable(true).setMovable(true) .setRequestFocus(true).setTitle(item.getName()).setCancelCallback(new Computable<Boolean>() { @Override public Boolean compute() { return true; } }); // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package
public void setup() { zookeeperContainer = new ZookeeperTestContainerSupport(false); zkSharedRefDatabase = new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); }
protected boolean shouldSendMessage() { if (user.equals(callingUser)) { return true; } try { permissionBackend.user(callingUser).check(GlobalPermission.ADMINISTRATE_SERVER); return false; } catch (AuthException | PermissionBackendException e) { return true; } }
if (extId == null) { throw new ResourceNotFoundException(); } ExternalId newExtId = ExternalId.createWithPassword(extId.key(), extId.accountId(), extId.email(), newPassword); externalIdsUpdate.create().upsert(newExtId); try { httpPasswordSenderFactory.create(user).send(); } catch (EmailException e) { log.error("Cannot send HttpPassword added or changed message to {}", user.getAccount().getPreferredEmail(), e); } return Strings.isNullOrEmpty(newPassword) ? Response.<String>none() : Response.ok(newPassword); public static String generate() { byte[] rand = new byte[LEN]; rng.nextBytes(rand); byte[] enc = Base64.encodeBase64(rand, false); StringBuilder r = new StringBuilder(enc.length); for (int i = 0; i < enc.length; i++) { if (enc[i] == '=') { break; } r.append((char) enc[i]); } return r.toString(); }
protected String subject; protected String message; protected UserIdentity author; protected UserIdentity committer; protected List<ParentInfo> parents; protected ObjectId commitId; protected String description; protected PatchSetInfo() {} public PatchSetInfo(PatchSet.Id k) { key = k; } public PatchSet.Id getKey() { return key; } public String getSubject() { return subject; } public void setSubject(String s) { if (s != null && s.length() > 255) { subject = s.substring(0, 255); } else { subject = s; } }
public String message; public String parentUuid; public Range range; public String tag; private String revId; public String serverId; public boolean unresolved; public transient boolean legacyFormat; public Comment(Comment c) { this(new Key(c.key), c.author.getId(), new Timestamp(c.writtenOn.getTime()), c.side, c.message, c.serverId, c.unresolved); this.lineNbr = c.lineNbr; this.realAuthor = c.realAuthor; }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.reviewdb.converter; import com.google.gerrit.proto.Entities; import com.google.protobuf.Parser; import org.eclipse.jgit.lib.ObjectId; /** * Proto converter for {@code ObjectId}s. * * <p>This converter uses the hex representation of object IDs embedded in a wrapper proto type, * rather than a more parsimonious implementation (e.g. a raw byte array), for two reasons: * * <ul> * <li>It allows for easier integration with existing protobuf-based APIs. * <li>It provides a more human-readable representation when inspecting the database. * </ul> */ public class ObjectIdProtoConverter extends ProtoConverter<ObjectId, Entities.ObjectId> { @Override protected ObjectId fromProto(Entities.ObjectId proto) { return ObjectId.fromString(proto.getId()); } @Override protected Entities.ObjectId toProto(ObjectId objectId) { return Entities.ObjectId.newBuilder().setId(objectId.name()).build(); } @Override protected Parser<Entities.ObjectId> getParser() { return Entities.ObjectId.parser(); } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.reviewdb.converter; import static com.google.common.truth.Truth.assertThat; import static com.google.gerrit.proto.testing.SerializedClassSubject.assertThatSerializedClass; import com.google.common.collect.ImmutableMap; import com.google.gerrit.proto.Entities; import com.google.gerrit.proto.testing.SerializedClassSubject; import com.google.protobuf.Parser; import org.eclipse.jgit.lib.ObjectId; import org.junit.Test; public class ObjectIdProtoConverterTest { // Test code goes here }
public static String abbreviateName(AnyObjectId id) { return abbreviateName(id, ABBREVIATED_STRING_LENGTH); }
// Abbreviate an ID's hex string representation to 7 chars. public static String abbreviateName(AnyObjectId id) { return abbreviateName(id, 7); } // Abbreviate an ID's hex string representation to n chars. public static String abbreviateName(AnyObjectId id, int n) { checkValidLength(n); return requireNonNull(id).abbreviate(n).name(); } // Abbreviate an ID's hex string representation uniquely to at least 7 chars. public static String abbreviateName(AnyObjectId id, ObjectReader reader) { return abbreviateName(id, reader, 7); } // Abbreviate an ID's hex string representation uniquely to at least n chars. public static String abbreviateName(AnyObjectId id, ObjectReader reader, int n) { checkValidLength(n); return requireNonNull(id).abbreviate(reader, n).name(); }
public static String abbreviateName(AnyObjectId id, int n) { checkValidLength(n); return requireNonNull(id).abbreviate(n).name(); } public static String abbreviateName(AnyObjectId id, ObjectReader reader) throws IOException { return abbreviateName(id, ABBREVIATED_STRING_LENGTH, reader); }
// avoid conficts. TODO: Remove this when Kudu supports databases. // 2. The user may specify a table name using the 'kudu.table_name' table property. private String kuduTableName_; // Comma separated list of Kudu master hosts with optional ports. private String kuduMasters_; // Primary key column names. private final List<String> primaryKeyColumnNames_ = Lists.newArrayList(); // Distribution schemes of this Kudu table. Both range and hash-based distributions are supported. private final List<DistributeParam> distributeBy_ = Lists.newArrayList(); protected KuduTable(TableId id, org.apache.hadoop.hive.metastore.api.Table msTable, Db db, String name, String owner) { super(id, msTable, db, name, owner); kuduTableName_ = getKuduTableNameFromTblProperties(msTable); kuduMasters_ = getKuduMasterAddrsFromTblProperties(msTable); } @Override public TCatalogObjectType getCatalogObjectType() { return TCatalogObjectType.TABLE; } @Override public String getStorageHandlerClassName() { return KUDU_STORAGE_HANDLER; } private PatchLineComment update(PatchLineComment e, Input in) { if (in.side != null) { e.setSide(in.side == Side.PARENT ? (short) 0 : (short) 1); } if (in.line != null) { e.setLine(in.line); } if (in.inReplyTo != null) { e.setParentUuid(Url.decode(in.inReplyTo)); } e.setMessage(in.message.trim()); e.updated(); return e; } public static CommentInfo createRange(String path, Side side, int line, String in_reply_to, String message, CommentRange range) { CommentInfo info = createFile(path, side, in_reply_to, message); info.setRange(range); return info; } /** * Abbreviate an ID's hex string representation uniquely to at least {@code n} chars. * * @param id object ID. * @param n minimum number of hex chars. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least {@code n} chars. */ public static String abbreviateName(AnyObjectId id, int n, ObjectReader reader) throws IOException { checkValidLength(n); return reader
import org.bouncycastle.crypto.generators.BCrypt; import org.bouncycastle.util.Arrays; /** * HashedPassword holds logic for salted, hashed passwords. It uses BCrypt from BouncyCastle, which * truncates passwords at 72 bytes. */ public class HashedPassword { private static final String ALGORITHM = "bcrypt"; private static SecureRandom secureRandom = new SecureRandom(); private static Base64 codec = new Base64(-1); /** * The decode method decodes a hashed password encoded with {@link #encode}. It throws * DecoderException for malformed input. */ public static HashedPassword decode(String encoded) { Preconditions.checkState(encoded.startsWith(ALGORITHM + ":")); String[] fields = encoded.split(":"); Preconditions.checkState(fields.length == 4); int cost = Integer.parseInt(fields[1]); return new HashedPassword(codec.decodeBase64(fields[3]), codec.decodeBase64(fields[2]), cost); } private static byte[] hashPassword(String password, byte[] salt, int cost) { byte pwBytes[] = password.getBytes(StandardCharsets.UTF_8); } } TmfCpuAspect.class, event); if (cpu == null) { return null; } /* Find the analysis module for the trace */ TidAnalysisModule analysis = TmfTraceUtils.getAnalysisModuleOfClass(event.getTrace(), TidAnalysisModule.class, TidAnalysisModule.ID); if (analysis == null) { return null; } long ts = event.getTimestamp().toNanos(); while (block && !analysis.isQueryable(ts) && !monitor.isCanceled()) { Thread.sleep(100); } return analysis.getThreadOnCpuAtTime(cpu, ts); } /** * This is used to acquire an <code>InputStream</code> for the * part. Acquiring the stream allows the content of the part to * be consumed by reading the stream. Each invocation of this * method will produce a new stream starting from the first byte. * * @return this returns the stream for this part object */ private String getContent(ContentType type) throws IOException { String charset = type.getCharset(); if (charset == null) { charset = "ISO-8859-1"; } return body.getContent(charset); } /** * Abbreviate an ID's hex string representation uniquely to at least {@code n
private static String implicitMergeOf(ObjectId commit) { return "implicit merge of " + abbreviateName(commit, 7); }
} @FunctionalInterface private interface Func { void call() throws Exception; } private static void assertRuntimeException(Func func) throws Exception { try { func.call(); assert_().fail("Expected RuntimeException"); } catch (RuntimeException e) { // Expected. } } private static ObjectReader newReaderWithAmbiguousIds() throws Exception { // Recipe for creating ambiguous IDs courtesy of t1512-rev-parse-disambiguation.sh in git core. TestRepository<?> tr = new TestRepository<>(new InMemoryRepository(new DfsRepositoryDescription("repo"))); String blobData = "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nb1rwzyc3\n"; RevBlob blob = tr.blob(blobData); assertThat(blob.name()).isEqualTo(AMBIGUOUS_BLOB_ID.name()); assertThat(tr.tree(tr.file("a0blgqsjc", blob)).name()).isEqualTo(AMBIGUOUS_TREE_ID.name()); return tr.getRevWalk().getObjectReader(); }
private static String implicitMergeOf(ObjectId commit) { return "implicit merge of " + abbreviateName(commit, 7); }
import com.googlesource.gerrit.plugins.lfs.LfsConfigurationFactory; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; @Singleton public class LfsFsDataDirectoryManager { private static final String KEY_DIRECTORY = "directory"; private final LfsConfigurationFactory configFactory; private final Path defaultDataDir; @Inject LfsFsDataDirectoryManager(LfsConfigurationFactory configFactory, @PluginData Path defaultDataDir) { this.configFactory = configFactory; this.defaultDataDir = defaultDataDir; } public Path getForBackend(LfsBackend backend, boolean ensure) throws IOException { String dataDir = configFactory.getGlobalConfig().getString(backend.type.name(), backend.name, KEY_DIRECTORY); if (Strings.isNullOrEmpty(dataDir)) { return defaultDataDir; } if (ensure) { Path ensured = Files.createDirectories(Paths.get(dataDir.toString())); return ensured; } else { return Paths.get(dataDir.toString()); } } }
public Path getForBackend(LfsBackend backend, boolean ensure) throws IOException { String dataDir = configFactory.getGlobalConfig().getString(backend.type.name(), backend.name, KEY_DIRECTORY); if (Strings.isNullOrEmpty(dataDir)) { return defaultDataDir; } if (ensure) { Path ensured = Files.createDirectories(Paths.get(dataDir.toString())); if (!Files.isReadable(ensured)) { throw new IOException("Path '" + ensured.toAbsolutePath() + "' cannot be accessed"); } return ensured; } return Paths.get(dataDir); }
Integer id = Ints.tryParse(email.substring(0, at)); if (id != null) { return Optional.of(Account.id(id)); } } } return Optional.empty(); } public static String formatTime(PersonIdent ident, Timestamp t) { GitDateFormatter dateFormatter = new GitDateFormatter(Format.DEFAULT); PersonIdent newIdent = new PersonIdent(ident, t); return dateFormatter.formatDate(newIdent); } static String guessRestApiHandler() { StackTraceElement[] trace = Thread.currentThread().getStackTrace(); int i = findRestApiServlet(trace); if (i < 0) { return null; } try { for (i--; i >= 0; i--) { String cn = trace[i].getClassName(); Class<?> cls = Class.forName(cn); if (RestModifyView.class.isAssignableFrom(cls) && cls != RetryingRestModifyView.class) { return viewName(cn); } } return null; }
Future<?> possiblyIgnoredError = executor.submit(() -> { try (OpenRepo allUsersRepo = OpenRepo.open(repoManager, allUsersName)) { allUsersRepo.addUpdates(draftUpdates); allUsersRepo.flush(); BatchRefUpdate bru = allUsersRepo.repo.getRefDatabase().newBatchUpdate(); bru.setPushCertificate(pushCert); if (refLogMessage != null) { bru.setRefLogMessage(refLogMessage, false); } else { bru.setRefLogMessage(firstNonNull(NoteDbUtil.guessRestApiHandler(), "Update NoteDb refs"), false); } bru.setRefLogIdent(refLogIdent != null ? refLogIdent : serverIdent.get()); bru.setAtomic(true); allUsersRepo.cmds.addTo(bru); bru.setAllowNonFastForwards(true); RefUpdateUtil.executeChecked(bru, allUsersRepo.rw); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to delete draft comments asynchronously after publishing them"); } });
private void deletePublishedComment(Comment c) { verifyComment(c); delete.put(key(c), DeleteReason.PUBLISHED); }
private void addCommands() throws IOException { changeRepo.addUpdates(changeUpdates, Optional.of(maxUpdates)); if (!draftUpdates.isEmpty()) { boolean publishOnly = draftUpdates.values().stream().anyMatch(ChangeDraftUpdate::isPublishOnly); if (publishOnly) { updateAllUsersAsync.setDraftUpdates(draftUpdates); } else { allUsersRepo.addUpdates(draftUpdates); } } if (!robotCommentUpdates.isEmpty()) { changeRepo.addUpdates(robotCommentUpdates); } if (!rewriters.isEmpty()) { addRewrites(rewriters, changeRepo); } for (Change.Id id : toDelete) { doDelete(id); } }
import com.google.gerrit.common.errors.EmailException; import com.google.gerrit.extensions.api.changes.RecipientType; import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; public class HttpPasswordUpdateSender extends OutgoingEmail { public interface Factory { HttpPasswordUpdateSender create(IdentifiedUser user); } private final IdentifiedUser callingUser; private final IdentifiedUser user; @AssistedInject public HttpPasswordUpdateSender(EmailArguments ea, IdentifiedUser callingUser, @Assisted IdentifiedUser user) { super(ea, "HttpPasswordUpdate"); this.callingUser = callingUser; this.user = user; } @Override protected void init() throws EmailException { super.init(); setHeader("Subject", "[Gerrit Code Review] HTTP password was either added, changed or deleted"); add(RecipientType.TO, new Address(getEmail())); } @Override protected boolean shouldSendMessage() { return true; } }
package com.google.gerrit.extensions.api.config; import com.google.gerrit.extensions.client.DiffPreferencesInfo; import com.google.gerrit.extensions.client.EditPreferencesInfo; import com.google.gerrit.extensions.client.GeneralPreferencesInfo; import com.google.gerrit.extensions.common.ServerInfo; import com.google.gerrit.extensions.restapi.NotImplementedException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.webui.TopMenu; import java.util.List; public interface Server { String getVersion() throws RestApiException; ServerInfo getInfo() throws RestApiException; GeneralPreferencesInfo getDefaultPreferences() throws RestApiException; GeneralPreferencesInfo setDefaultPreferences(GeneralPreferencesInfo in) throws RestApiException; DiffPreferencesInfo getDefaultDiffPreferences() throws RestApiException; DiffPreferencesInfo setDefaultDiffPreferences(DiffPreferencesInfo in) throws RestApiException; EditPreferencesInfo getDefaultEditPreferences() throws RestApiException; EditPreferencesInfo setDefaultEditPreferences(EditPreferencesInfo in) throws RestApiException; }
throws RestApiException { throw new NotImplementedException(); } @Override public EditPreferencesInfo getDefaultEditPreferences() throws RestApiException { throw new NotImplementedException(); } @Override public EditPreferencesInfo setDefaultEditPreferences(EditPreferencesInfo in) throws RestApiException { throw new NotImplementedException(); } @Override public ConsistencyCheckInfo checkConsistency(ConsistencyCheckInput in) throws RestApiException { throw new NotImplementedException(); } @Override public List<TopMenu.MenuEntry> topMenus() throws RestApiException { throw new NotImplementedException(); }
ChangeCheckerImpl.Factory changeCheckerFactory) { super(configuration.index().numStripedLocks()); this.indexer = indexer; this.indexExecutor = indexExecutor; this.oneOffCtx = oneOffCtx; this.changeCheckerFactory = changeCheckerFactory; Index indexConfig = configuration.index(); this.retryInterval = indexConfig != null ? indexConfig.retryInterval() : 0; this.maxTries = indexConfig != null ? indexConfig.maxTries() : 0; } @Override protected void doIndex(String id, Optional<ChangeIndexEvent> indexEvent) throws IOException { doIndex(id, indexEvent, 0); } private void doIndex(String id, Optional<ChangeIndexEvent> indexEvent, int retryCount) throws IOException { try { ChangeChecker checker = changeCheckerFactory.create(id); Optional<ChangeNotes> changeNotes = checker.getChangeNotes(); if (changeNotes.isPresent()) { ChangeNotes notes = changeNotes.get(); reindex(notes); if (checker.isChangeUpToDate(indexEvent)) { if (retryCount > 0) { return; } retryCount++; try { Thread.sleep(retryInterval); } catch (InterruptedException e) { throw new IOException("Interrupted while waiting to retry indexing", e); } doIndex(id, indexEvent, retryCount); } } } catch (StorageException e) { throw new IOException("Failed to index change " + id, e); } }
ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns(colsProto.toBuilder()) .setOriginalSubject("The first patch set") .setHasOriginalSubject(true) .build()); @Test public void serializeOriginalSubject() throws Exception { assertRoundTrip( newBuilder() .columns(cols.toBuilder().originalSubject("The first patch set").build()) .build(), ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns(colsProto.toBuilder() .setOriginalSubject("The first patch set") .setHasOriginalSubject(true)) .build()); } @Test public void serializeSubmissionId() throws Exception { assertRoundTrip( newBuilder().columns(cols.toBuilder().submissionId("xyz").build()).build(), ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns(colsProto.toBuilder() .setSubmissionId("xyz") .setHasSubmissionId(true)) .build()); } @Test public void serializeAssignee() throws Exception { // code for serializeAssignee test }
public void onProjectDeleted(Event event) { String projectName = event.getProjectName(); logger.atInfo().log("Deleting project '%s'. Will perform a cleanup in Shared-Ref database.", projectName); try { sharedDb.removeProject(projectName); } catch (IOException e) { logger.atSevere().log(String.format("Project '%s' deleted from GIT but it was not able to fully cleanup from Shared-Ref database", projectName), e); } }
public void addChange(String id, Map<Change.Id, ChangeResource> changes) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { addChange(id, changes, null); } public void addChange(String id, Map<Change.Id, ChangeResource> changes, ProjectState projectState) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { addChange(id, changes, projectState, true); } public void addChange(String id, Map<Change.Id, ChangeResource> changes, @Nullable ProjectState projectState, boolean useIndex) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { List<ChangeNotes> matched = useIndex ? changeFinder.find(id) : changeFromNotesFactory(id); List<ChangeNotes> toAdd = new ArrayList<>(changes.size()); boolean canMaintainServer; try { permissionBackend.currentUser().check(GlobalPermission.MAINTAIN_SERVER); canMaintainServer = true; } catch (AuthException | PermissionBackendException e) { canMaintainServer = false; } for (ChangeNotes notes : matched) { if (!changes.containsKey(notes.getChangeId())) { continue; } ChangeResource changeResource = changes.get(notes.getChangeId()); if (projectState != null && !projectState.statePermitsRead()) { continue; } if (!canMaintainServer && !changeResource.getChange().isPrivate()) { continue; } toAdd.add(notes); } addChange(toAdd); }
import java.io.IOException; import java.util.concurrent.ExecutionException; import java.util.concurrent.TimeUnit; @Singleton public class CombinedCheckStateCache { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String NAME = "combined_check_state"; public static Module module() { return new CacheModule() { @Override public void configure() { persist(NAME, CombinedCheckStateCacheKeyProto.class, CombinedCheckState.class) .version(1) .maximumWeight(10000) .diskLimit(-1) .keySerializer(new ProtobufSerializer<>(CombinedCheckStateCacheKeyProto.parser())) .valueSerializer(new EnumCacheSerializer<>(CombinedCheckState.class)) .loader(Loader.class); } }; } @Singleton static class Metrics { // Metrics implementation } }
// Pair of metric and manual counters, to work around the fact that metric classes have no getters. private final Timer1<Boolean> reloadLatency; private final AtomicLongMap<Boolean> reloadCount; @Inject Metrics(MetricMaker metricMaker) { reloadLatency = metricMaker.newTimer( "checks/reload_combined_check_state", new Description("Latency for reloading combined check state") .setCumulative() .setUnit(Units.MILLISECONDS), Field.ofBoolean("updated", "whether reloading resulted in updating the cached value") ); reloadCount = AtomicLongMap.create(); } void recordReload(boolean updated, long elapsed, TimeUnit timeUnit) { reloadLatency.record(updated, elapsed, timeUnit); reloadCount.incrementAndGet(updated); } long getReloadCount(boolean updated) { return reloadCount.get(updated); } private final LoadingCache<CombinedCheckStateCacheKeyProto, CombinedCheckState> cache; private final Loader loader; private final Metrics metrics; @Inject CombinedCheckStateCache( @Named(NAME) LoadingCache<CombinedCheckStateCacheKeyProto, CombinedCheckState> cache, Loader loader, Metrics metrics ) { this.cache = cache; this.loader = loader; this.metrics = metrics; }
void recordReload(boolean dirty, Duration elapsed) { reloadLatency.record(dirty, elapsed.toNanos(), TimeUnit.NANOSECONDS); reloadCount.incrementAndGet(dirty); }
CombinedCheckState newState = loader.load(key); CombinedCheckState oldState = cache.getIfPresent(key); boolean dirty; if (newState != oldState) { dirty = true; cache.put(key, newState); } else { dirty = false; } return newState; finally { if (dirty == null) { dirty = true; } metrics.recordReload(dirty, sw.elapsed(NANOSECONDS), NANOSECONDS); }
assertThat(cache.getStats()).since(start).hasHitCount(1); assertThat(cache.getStats()).since(start).hasMissCount(0); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(0); // Set non-required checker to FAILED, updating combined check state to WARNING. checkOperations.newCheck(CheckKey.create(project, psId, checkerUuid)) .state(CheckState.FAILED) .upsert(); // Incurs reload after updating check state. assertThat(cache.getStats()).since(start).hasHitCount(2); assertThat(cache.getStats()).since(start).hasMissCount(0); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(1); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.WARNING)); assertThat(cache.getStats()).since(start).hasHitCount(3); assertThat(cache.getStats()).since(start).hasMissCount(0);
import org.easymock.EasyMock; import org.junit.Test; public class ChecksSubmitRuleTest extends GerritBaseTests { @Test public void loadingCurrentPatchSetFails() throws Exception { ChecksSubmitRule checksSubmitRule = new ChecksSubmitRule(EasyMock.createStrictMock(CombinedCheckStateCache.class)); ChangeData cd = EasyMock.createStrictMock(ChangeData.class); expect(cd.project()).andReturn(new Project.NameKey("My-Project")); expect(cd.getId()).andReturn(new Change.Id(1)); expect(cd.currentPatchSet()).andThrow(new OrmException("Fail for test")); replay(cd); Collection<SubmitRecord> submitRecords = checksSubmitRule.evaluate(cd, SubmitRuleOptions.defaults()); assertErrorRecord(submitRecords, "failed to load the current patch set of change 1"); } @Test public void getCombinedCheckStateFails() throws Exception { CombinedCheckStateCache cache = EasyMock.createStrictMock(CombinedCheckStateCache.class); expect(cache.reload(anyObject(), anyObject())).andThrow(new OrmException("Fail for test")); replay(cache); ChecksSubmitRule checksSubmitRule = new ChecksSubmitRule(cache); } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.events; import com.google.gson.Gson; import com.google.gson.TypeAdapter; import com.google.gson.TypeAdapterFactory; import com.google.gson.reflect.TypeToken; public final class AutoValueAdapterFactory implements TypeAdapterFactory { @SuppressWarnings("unchecked") @Override public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) { Class<? super T> rawType = type.getRawType(); // TODO: Implement the logic for creating the TypeAdapter return null; } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.events; import com.google.common.base.Supplier; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.inject.Provider; public class GsonEventDeserializerProvider implements Provider<Gson> { @Override public Gson get() { return new GsonBuilder() .registerTypeAdapter(Event.class, new EventDeserializer()) .registerTypeAdapter(Supplier.class, new SupplierSerializer()) .registerTypeAdapter(Supplier.class, new SupplierDeserializer()) .create(); } }
private Change newChange(String changeKey) { Change change = new Change( Change.key(changeKey), Change.id(1000), Account.id(1000), Branch.nameKey(Project.nameKey("myproject"), "mybranch"), new Timestamp(System.currentTimeMillis()) ); return change; }
private static final String REF_NAME = "refs/heads/master"; private static final String SUBMITTER_EMAIL = "some.user@domain.com"; public void refUpdatedEvent() { RefUpdatedEvent event = new RefUpdatedEvent(); RefUpdateAttribute refUpdatedAttribute = new RefUpdateAttribute(); refUpdatedAttribute.refName = REF_NAME; event.refUpdate = createSupplier(refUpdatedAttribute); AccountAttribute accountAttribute = new AccountAttribute(); accountAttribute.email = SUBMITTER_EMAIL; event.submitter = createSupplier(accountAttribute); assertThatJsonMap(event) .containsExactly( "submitter", ImmutableMap.of("email", SUBMITTER_EMAIL), "refUpdate", ImmutableMap.of("refName", REF_NAME), "type", "ref-updated", "eventCreatedOn", 1.2543444E9 ); }
public static CombinedCheckState combine(ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { CheckStateCount checkStateCount = CheckStateCount.create(statesAndRequired); return combine(checkStateCount); } private static CombinedCheckState combine(CheckStateCount checkStateCount) { if (checkStateCount.failedRequiredCount() > 0) { return FAILED; } if (checkStateCount.inProgressOptionalCount() > 0 || checkStateCount.inProgressRequiredCount() > 0) { return IN_PROGRESS; } if (checkStateCount.failedOptionalCount() > 0) { return WARNING; } if (checkStateCount.successfulCount() > 0) { return SUCCESSFUL; } return NOT_RELEVANT; }
public boolean isPassing() { return passing; } @AutoValue public abstract static class CheckStateCount { public static CheckStateCount create(ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { int failedRequiredCount = 0; int failedOptionalCount = 0; int inProgressRequiredCount = 0; int inProgressOptionalCount = 0; int successfulCount = 0; for (Map.Entry<CheckState, Boolean> e : statesAndRequired.entries()) { CheckState state = e.getKey(); if (state.isInProgress()) { if (e.getValue()) { inProgressRequiredCount++; } else { inProgressOptionalCount++; } } else if (state.isFailed()) { if (e.getValue()) { failedRequiredCount++; } else { failedOptionalCount++; } } else if (state.isSuccessful()) { successfulCount++; } } return new AutoValue_CheckStateCount( failedRequiredCount, failedOptionalCount, inProgressRequiredCount, inProgressOptionalCount, successfulCount ); } public abstract int getFailedRequiredCount(); public abstract int getFailedOptionalCount(); public abstract int getInProgressRequiredCount(); public abstract int getInProgressOptionalCount(); public abstract int getSuccessfulCount(); }
public static CheckStateCount create(ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { int failedRequiredCount = 0; int failedOptionalCount = 0; int inProgressRequiredCount = 0; int inProgressOptionalCount = 0; int successfulCount = 0; for (Map.Entry<CheckState, Boolean> entry : statesAndRequired.entries()) { CheckState state = entry.getKey(); if (state.isInProgress()) { if (entry.getValue()) { inProgressRequiredCount++; } else { inProgressOptionalCount++; } } else if (state == CheckState.FAILED) { if (entry.getValue()) { failedRequiredCount++; } else { failedOptionalCount++; } } else if (state == CheckState.SUCCESSFUL) { successfulCount++; } } return new CheckStateCount( failedRequiredCount, failedOptionalCount, inProgressRequiredCount, inProgressOptionalCount, successfulCount ); }
import java.io.IOException; import java.util.Collection; import java.util.Map; import com.google.common.collect.ImmutableMap; import com.google.gerrit.extensions.api.changes.SubmitRuleOptions; import com.google.gerrit.extensions.common.CheckInfo; import com.google.gerrit.extensions.common.SubmitRecord; import com.google.gerrit.server.change.ChangeData; import com.google.gerrit.server.change.SubmitRuleEvaluator; import com.google.gerrit.server.change.SubmitRuleEvaluator.Result; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleEvaluationException; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleEvaluator; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult.Status; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult.Type; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult.Value; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult.Value.Type; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult.Value.ValueCase; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change
public EnforcePolicy getPolicy(String projectName, String refName); public EnforcePolicy getPolicy(String projectName); default boolean doesRefNeedClusterSynchronisation(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); }
Module sitePathModule = new AbstractModule() { @Override protected void configure() { bind(Path.class).annotatedWith(SitePath.class).toInstance(sitePath); } }; modules.add(sitePathModule); Module configModule = new GerritServerConfigModule(); modules.add(configModule); modules.add(new DropWizardMetricMaker.ApiModule()); return Guice.createInjector(PRODUCTION, LibModuleLoader.loadModules(cfgInjector, LibModuleType.DB_MODULE));
// You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server; /** * Loadable module type for the different Gerrit server injectors. */ public enum LibModuleType { /** * Module for the sysInjector. */ SYS_MODULE("Module"), /** * Module for the dbInjector. */ DB_MODULE("DbModule"); private final String configKey; LibModuleType(String configKey) { this.configKey = configKey; } /** * Returns the module type for loading from gerrit.config. * * @return module type string */ public String getConfigKey() { return configKey; } }
package com.google.gerrit.server; public enum LibModuleType { SYS_MODULE("Module"), DB_MODULE("DbModule"); private final String configKey; LibModuleType(String configKey) { this.configKey = configKey; } public String getConfigKey() { return configKey; } }
@Singleton public class ForwardedIndexAccountHandler extends ForwardedIndexingHandler<Account.Id> { private final AccountIndexer indexer; @Inject ForwardedIndexAccountHandler(AccountIndexer indexer, Configuration config) { super(config.index()); this.indexer = indexer; } @Override protected void doIndex(Account.Id id, Optional<IndexEvent> indexEvent) throws IOException { indexer.index(id); log.atFine().log("Account %s successfully indexed", id); } @Override protected void doDelete(Account.Id id, Optional<IndexEvent> indexEvent) { throw new UnsupportedOperationException("Delete from account index not supported"); } }
import com.google.gerrit.testing.TestTimeUtil; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.gson.reflect.TypeToken; import java.util.Map; import java.util.concurrent.TimeUnit; import org.junit.Before; import org.junit.Test; public class EventJsonTest extends GerritBaseTests { private static final String BRANCH = "mybranch"; private static final String CHANGE_ID = "Ideadbeefdeadbeefdeadbeefdeadbeefdeadbeef"; private static final int CHANGE_NUM = 1000; private static final double CHANGE_NUM_DOUBLE = CHANGE_NUM; private static final String COMMIT_MESSAGE = "This is a test commit message"; private static final String PROJECT = "myproject"; private static final String REF = "refs/heads/" + BRANCH; private static final double TS1 = 1.2543444E9; private static final double TS2 = 1.254344401E9; private static final String URL = "http://somewhere.com"; private final Gson gson = new GsonBuilder() .setPrettyPrinting() .registerTypeAdapter(new TypeToken<Map<String, Object>>() {}.getType(), new StreamEvents.MapDeserializer()) .create(); @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); } @Test public void testEventJson() { // Test code here } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb; import com.google.common.base.MoreObjects; import com.google.common.collect.ImmutableMap; import com.google.common.flogger.FluentLogger; import java.util.HashMap; import java.util.List; import java.util.Map; public class CustomSharedRefEnforcementByProject implements SharedRefEnforcement { private static final String ALL = ".*"; private final Map<String, Map<String, EnforcePolicy>> PREDEF_ENFORCEMENTS; private final FluentLogger logger = FluentLogger.forEnclosingClass(); public CustomSharedRefEnforcementByProject(List<String> enforcementRules) { logger.atInfo().log( String.format("Running with Custom Shared Ref-Db Enforcement Policy with following rules %s", enforcementRules.toString())); this.PREDEF_ENFORCEMENTS = parseDryRunEnforcementsToMap(enforcementRules); } private Map<String, Map<String, EnforcePolicy>> parseDryRunEnforcementsToMap(List<String> dryRunRefEnforcement) { // Implementation details } }
assert (refAndPolicy.length == 2); String refName = refAndPolicy[0].trim().isEmpty() ? ALL : refAndPolicy[0].trim(); Map<String, EnforcePolicy> existingOrDefaultRef = projectAndRefsEnforcements.getOrDefault(projectName, new HashMap<>()); existingOrDefaultRef.put(refName, EnforcePolicy.valueOf(refAndPolicy[1].trim().toUpperCase())); projectAndRefsEnforcements.put(projectName, existingOrDefaultRef); } catch (AssertionError e) { throw e; } return projectAndRefsEnforcements; } @Override public EnforcePolicy getPolicy(String projectName, String refName) { if (isRefToBeIgnoredBySharedRefDb(refName)) { return EnforcePolicy.IGNORED; } return getRefEnforcePolicy(projectName, refName); } private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { if (!PREDEF_ENFORCEMENTS.containsKey(projectName) && PREDEF_ENFORCEMENTS.containsKey(ALL)) { return PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED); } EnforcePolicy policyFromProjectRefOrProjectAllRefs =
private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { if (!PREDEF_ENFORCEMENTS.containsKey(projectName) && PREDEF_ENFORCEMENTS.containsKey(ALL)) { return PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED); } EnforcePolicy policyFromProjectRefOrProjectAllRefs = PREDEF_ENFORCEMENTS.get(projectName).get(refName); if (policyFromProjectRefOrProjectAllRefs == null) { policyFromProjectRefOrProjectAllRefs = PREDEF_ENFORCEMENTS.get(projectName).get(ALL); } return MoreObjects.firstNonNull(policyFromProjectRefOrProjectAllRefs, EnforcePolicy.REQUIRED); }
private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { return Optional.ofNullable(PREDEF_ENFORCEMENTS.get(projectName)) .map(enforcements -> enforcements.getOrDefault(refName, PREDEF_ENFORCEMENTS.get(ALL).get(refName))) .orElse(PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED)); }
boolean isUpToDate(String project, Ref ref) throws IOException { return compareAndCreate(project, ref); } boolean isMostRecentRefVersion(String project, Ref ref) throws IOException { // implementation here } boolean compareAndCreate(String project, Ref newRef) throws IOException { return compareAndPut(project, NULL_REF, newRef); } boolean compareAndPut(String project, Ref oldRef, Ref newRef) throws IOException { // implementation here }
/** * Compare a reference, and delete if it matches. * * @param project project name of the ref * @param oldRef the old reference information that was previously read. * @return true if the remove was successful; false otherwise. * @throws java.io.IOException the reference could not be removed due to a system error. */ boolean compareAndRemove(String project, Ref oldRef) throws IOException; /** * Acquires a lock on the specified reference. * * @param projectName the name of the project * @param ref the reference to lock * @return an AutoCloseable object representing the lock * @throws IOException if an I/O error occurs while acquiring the lock */ AutoCloseable lockRef(String projectName, Ref ref) throws IOException; /** * Determines if a reference should be ignored in the SharedRefDatabase. * * @param refName the name of the reference * @return true if the reference should be ignored; false otherwise */ default boolean ignoreRefInSharedDb(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } /** * Verifies if the DB contains a value for the specific project and ref name. * * @param project the name of the project * @param refName the name of the reference * @return true if the DB contains a value for the project and ref name; false otherwise */ boolean contains(String project, String refName);
boolean compareAndRemove(String projectName, Ref oldRef) throws IOException; AutoCloseable lockRef(String projectName, Ref ref) throws IOException; default boolean ignoreRefInSharedDb(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } boolean containsValue(String projectName, String refName);
import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.recipes.atomic.AtomicValue; import org.apache.curator.framework.recipes.atomic.DistributedAtomicValue; import org.apache.curator.framework.recipes.locks.InterProcessMutex; import org.apache.curator.framework.recipes.locks.Locker; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; public class ZkSharedRefDatabase implements SharedRefDatabase { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CuratorFramework client; private final RetryPolicy retryPolicy; private final SharedRefEnforcement refEnforcement; private final Long transactionLockTimeOut; @Inject public ZkSharedRefDatabase( CuratorFramework client, ZkConnectionConfig connConfig, SharedRefEnforcement refEnforcement) { this.client = client; this.retryPolicy = connConfig.curatorRetryPolicy; this.transactionLockTimeOut = connConfig.transactionLockTimeout; this.refEnforcement = refEnforcement; } @Override public boolean isMostRecentRefVersion(String project, Ref ref) throws IOException { if (!exists(project, ref.getName())) { logger.atWarning().log( "Ref %s does not exist in project %s", ref.getName(), project); return false; } try (Locker locker = new InterProcessMutex(client, getLockPath(project, ref.getName()))) { if (!locker.acquire(transactionLockTimeOut, TimeUnit.MILLISECONDS)) { logger.atWarning().log( "Failed to acquire lock for ref %s in project %s", ref.getName(), project); return false; } ObjectId currentRefObjectId = getObjectId(project, ref.getName()); ObjectId refObjectId = ref.getObjectId(); return currentRefObjectId != null && currentRefObjectId.equals(refObjectId); } catch (Exception e) { logger.atSevere().withCause(e).log( "Failed to check if ref %s is most recent in project %s", ref.getName(), project); return false; } } }
public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } public boolean exists(String projectName, String refName) throws IOException { try { String path = pathFor(projectName, refName); byte[] valueInZk = client.getData().forPath(path); return valueInZk != null; } catch (Exception e) { throw new IOException(String.format("Unable to read data for path %s", pathFor(projectName, refName)), e); } } public boolean isMostRecentRef(Ref ref) throws IOException { if (!sharedDbExists()) { return true; } String path = pathFor(ref.getProject(), ref.getName()); if (!client.checkExists().forPath(path)) { return true; } byte[] valueInZk = client.getData().forPath(path); if (valueInZk == null) { return false; } ObjectId objectIdInZk = readObjectId(valueInZk); return objectIdInZk.equals(ref.getObjectId()); }
@Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean exists(String projectName, String refName) throws IOException { try { return client.checkExists().forPath(pathFor(projectName, refName)) != null; } catch (Exception e) { throw new IOException("Failed to check if path exists in Zookeeper", e); } } public Locker lockRef(String projectName, Ref ref) throws IOException { InterProcessMutex refPathMutex = new InterProcessMutex(client, "/locks" + pathFor(projectName, ref.getName())); try { return new Locker(refPathMutex, transactionLockTimeOut, MILLISECONDS); } catch (Exception e) { throw new IOException("Failed to create lock in ZK", e); } } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { EnforcePolicy enforcementPolicy = refEnforcement.getPolicy(...); // implementation details }
} catch (Exception e) { throw new LockException("Failed to create lock in ZK", e); }
import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate; private final String project; private final RefUpdateValidator.Factory batchRefValidatorFactory; private final RefDatabase refDb; public static interface Factory { MultiSiteBatchRefUpdate create(String project, RefDatabase refDb); } @Inject public MultiSiteBatchRefUpdate( RefUpdateValidator.Factory batchRefValidatorFactory, @Assisted String project, @Assisted RefDatabase refDb) { super(refDb); this.refDb = refDb; this.project = project; this.batchRefUpdate = refDb.newBatchUpdate(); this.batchRefValidatorFactory = batchRefValidatorFactory; } @Override public int hashCode() { return batchRefUpdate.hashCode(); } @Override public boolean equals(Object obj) { return batchRefUpdate.equals(obj); } @Override public void addCommand(ReceiveCommand cmd, ProgressMonitor monitor) { batchRefUpdate.addCommand(cmd, monitor); } @Override public void addCommand(ReceiveCommand cmd, ProgressMonitor monitor, ProposedTimestamp timestamp) { batchRefUpdate.addCommand(cmd, monitor, timestamp); } // Other methods... }
* All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * wim.jongman@remainsoftware.com - initial API and implementation *******************************************************************************/ package org.eclipse.tips.ui.internal; import org.eclipse.swt.widgets.Slider; import org.eclipse.tips.core.TipProvider; /** * Interface for TipProvider listeners. */ @FunctionalInterface public interface ProviderSelectionListener { /** * Is called when the provider is selected in the {@link Slider}. * * @param pProvider the {@link TipProvider} that was selected */ public void selected(TipProvider pProvider); } createCheckManifestTask(tasks, variantScope); // Add a task to create the res values ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_GENERATE_RES_VALUES_TASK, new Recorder.Block<Void>() { @Override public Void call() throws Exception { createGenerateResValuesTask(tasks, variantScope); return null; } }); // Add a task to process the manifest(s) ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_MERGE_MANIFEST_TASK, new Recorder.Block<Object>() { @Override public Void call() throws Exception { createMergeLibManifestsTask(tasks, variantScope); return null; } }); // Add a task to compile renderscript files. ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_CREATE_RENDERSCRIPT_TASK, new Recorder.Block<Void>() { @Override public Void call() throws Exception { createRenderscriptTask(tasks, variantScope); return null; } }); AndroidTask<MergeResources> packageRes = ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_MERGE_RESOURCES_TASK, createCheckManifestTask(tasks, variantScope); // Add a task to create the res values ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_GENERATE_RES_VALUES_TASK, new Recorder.Block<Void>() { @Override public Void call() throws Exception { createGenerateResValuesTask(tasks, variantScope); return null; } }); // Add a task to process the manifest(s) ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_MERGE_MANIFEST_TASK
throws IOException { batchRefValidatorFactory.create(projectName, refDb) .executeBatchUpdateWithValidation(batchRefUpdate, () -> { batchRefUpdate.execute(walk, monitor, options); return null; }); } @Override public void execute(RevWalk walk, ProgressMonitor monitor) throws IOException { batchRefValidatorFactory.create(projectName, refDb) .executeBatchUpdateWithValidation(batchRefUpdate, () -> { batchRefUpdate.execute(walk, monitor); return null; }); } @Override public String toString() { return batchRefUpdate.toString(); }
public RefUpdateValidator(SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; }
} public String getName() { return MoreObjects.firstNonNull(oldRef == null ? null : oldRef.getName(), newRef == null ? null : newRef.getName()); } public boolean hasFailed() { return exception != null; } } protected void executeBatchUpdateWithPolicy(String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy(String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException {
String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { // If ignored we just do the GIT update if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy(String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException { // If ignored we just do the GIT update if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { return gitUpdateFun.apply(); } try { return delegateValidation.apply(gitUpdateFun, refUpdate); } catch (IOException e) { if (e.getClass() == SharedDbSplitBrainException.class) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } }
return; try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy( String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { return gitUpdateFun.apply(); } try { return delegateValidation.apply(gitUpdateFun, refUpdate); } catch (IOException e) { if (e.getClass() == SharedDbSplitBrainException.class) { validationMetrics.incrementSplitBrain(); } logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } return null; }
List<RefPair> refsToUpdate = getRefsPairs(commands) .sorted(comparing(RefPair::hasFailed).reversed()) .collect(Collectors.toList()); if (refsToUpdate.isEmpty()) { return; } if (refsToUpdate.get(0).hasFailed()) { RefPair failedRef = refsToUpdate.get(0); logger.atWarning().withCause(failedRef.exception).log("Failed to fetch ref entries"); throw new IOException("Failed to fetch ref entries" + failedRef.newRef.getName(), failedRef.exception); } Map<ObjectId, Ref> oldRefsMap = refsToUpdate.stream() .collect(Collectors.toMap(refPair -> refPair.newRef.getObjectId(), refPair -> refPair.oldRef)); try (CloseableSet<AutoCloseable> locks = new CloseableSet()) { assertRefPairsAreInSyncWithSharedDb(refsToUpdate, locks); delegateUpdate.apply(); updateSharedRefDbForSuccessfulCommands(batchRefUpdate.getCommands().stream(), oldRefsMap); }
protected RefPair newRefPairFrom(RefUpdate refUpdate) { return new RefPair(refUpdate.getRef(), sharedRefDb.newRef(refUpdate.getName(), refUpdate.getOldObjectId())); }
protected RefPair newRefPairFrom(RefUpdate refUpdate) { return new RefPair(refUpdate.getRef(), refUpdate.getRef()); }
public BatchRefUpdateValidator(SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, String projectName, RefDatabase refDb) { super(sharedRefDb, validationMetrics, refEnforcement, projectName, refDb); }
public RefUpdateValidator(SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; }
public static interface Factory { RefUpdateValidator create(String projectName, RefDatabase refDb); } @Inject public RefUpdateValidator(SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; } protected final SharedRefEnforcement refEnforcement; protected void executeBatchUpdateWithPolicy(String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } public static int calculateGroupByTableCardinality(long memoryBudgetByteSize, int numberOfGroupByColumns, int frameSize) { int tupleByteSize = 4 + 8 * numberOfGroupByColumns; int maxNumberOfTuplesInDataTable = memoryBudgetInBytes / tupleByteSize; int numberOfBits = Math.min(61, numberOfGroupByColumns * 4 * 8); long possibleNumberOfHashEntries = (long) 2 << numberOfBits; return Math.min(maxNumberOfTuplesInDataTable, possibleNumberOfHashEntries); } void join(IFrameTupleAccessor accessorProbe, int tid, IFrameWriter writer) throws HyracksDataException { this.accessorProbe = accessorProbe; boolean matchFound = false; if (tableSize != 0) { int entry = tpcProbe.partition(accessorProbe, tid, tableSize); int offset = 0; do { table.getTuplePointer(entry, offset++, storedTuplePointer); if (storedTuplePointer.frameIndex < 0) break; int bIndex = storedTuplePointer.frameIndex; int tIndex = storedTuplePointer.tupleIndex; accessorBuild.reset(buffers.get(bIndex)); int c =
public Builder setOldRevision(Revision revision) { switch (type) { case DIFF: case LOG: this.oldRevision = revision; break; default: throw new IllegalStateException(String.format("cannot set old revision on %s view", type)); } return this; } public RefUpdateValidator create(String projectName, RefDatabase refDb); @Inject public RefUpdateValidator(SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; } protected void executeBatchUpdateWithPolicy(String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy(String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { return refUpdate.update(); } try { return delegateValidation.apply(refUpdate); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } return RefUpdate.Result.LOCK_FAILURE; } }
try { locks.addResourceIfNotExist(resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); } catch (Exception e) { throw new IOException(String.format("Unable to prepare locks for project %s and reference %s", projectName, nonNullRef.getName()), e); } boolean isInSync; if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInSync = sharedRefDb.isUpToDate(projectName, refPair.oldRef); } else { isInSync = !sharedRefDb.exists(projectName, refPair.getName()); } if (!isInSync) { failWith(new IOException(String.format("Ref '%s' for project '%s' not in sync with shared Ref-Db. Trying to change the Ref-Db from oldRefId '%s' to newRefId '%s'. Aborting batch update.", refPair.getName(), projectName, refPair.oldRef.getObjectId(), refPair.newRef.getObjectId()))); }
import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.RefUpdateStub; import java.io.IOException; import org.eclipse.jgit.lib.ObjectIdRef; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.lib.RefUpdate; import org.eclipse.jgit.lib.RefUpdate.Result; import org.junit.Before; import org.junit.Rule; import org.junit.Test; import org.junit.rules.TestName; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.junit.MockitoJUnitRunner; @RunWith(MockitoJUnitRunner.class) public class MultiSiteRefUpdateTest implements RefFixture { @Mock SharedRefDatabase sharedRefDb; @Mock ValidationMetrics validationMetrics; private final Ref oldRef = new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, A_TEST_REF_NAME, AN_OBJECT_ID_1); private final Ref newRef = new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, A_TEST_REF_NAME, AN_OBJECT_ID_2); @Rule public TestName nameRule = new TestName(); @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); } @Before public void setUp() { // TODO: Add setup code here } @Test public void testRefUpdate() { // TODO: Add test code here } }
if (policy == EnforcePolicy.REQUIRED) { throw e; } } protected RefUpdate.Result doExecuteRefUpdate(RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> refUpdateFunction) throws IOException { try (CloseableSet<AutoCloseable> locks = new CloseableSet<>()) { RefPair refPair = newRefPairFrom(refUpdate); checkIfLocalRefIsUpToDateWithSharedRefDb(refPair.getName(), locks); RefUpdate.Result result = refUpdateFunction.invoke(); if (isSuccessful(result)) { updateSharedDbOrThrowExceptionFor(refPair); } return result; } } protected void updateSharedDbOrThrowExceptionFor(RefPair refPair) throws IOException { // We are not checking refs that should be ignored final EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refPair.getName()); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return; } String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been " + "successfully applied to the local ref '%s' but not to the shared refdb.", projectName, refPair.getName(), refPair.getName()); throw new IOException(errorMessage); }
assertThat(created.ref).isEqualTo(branch.branch()); private void assertCreateFails(BranchNameKey branch, Class<? extends RestApiException> errType, String errMsg) throws Exception { assertCreateFails(branch, null, errType, errMsg); } private void assertCreateFails(BranchNameKey branch, String revision, Class<? extends RestApiException> errType, String errMsg) throws Exception { BranchInput in = new BranchInput(); in.revision = revision; if (errMsg != null) { assertThrows(errType, () -> branch(branch).create(in)); } } private void assertCreateFails(BranchNameKey branch, Class<? extends RestApiException> errType) throws Exception { assertCreateFails(branch, errType, null); }
@Test public void customLabel_DisallowPostSubmit() throws Exception { label.setFunction(NO_OP); label.setAllowPostSubmit(false); P.setFunction(NO_OP); saveLabelConfig(); PushOneCommit.Result r = createChange(); revision(r).review(ReviewInput.approve()); revision(r).submit(); ChangeInfo info = getWithLabels(r); assertPermitted(info, "Code-Review", 2); assertPermitted(info, P.getName(), 0, 1); assertPermitted(info, label.getName()); ReviewInput preSubmitReview = new ReviewInput(); preSubmitReview.label(P.getName(), P.getMax().getValue()); revision(r).review(preSubmitReview); ReviewInput postSubmitReview = new ReviewInput(); postSubmitReview.label(label.getName(), label.getMax().getValue()); ResourceConflictException thrown = assertThrows(ResourceConflictException.class, () -> revision(r).review(postSubmitReview)); assertThat(thrown) .hasMessageThat() .contains("Voting on labels disallowed after submit: " + label.getName()); } @Test public void customLabelWithUserPermissionChange() throws Exception { // Test code here }
staticPath = cdnPath; } else if (canonicalPath != null) { staticPath = canonicalPath; } SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer.ordainAsSafe( staticPath, SanitizedContent.ContentKind.TRUSTED_RESOURCE_URI); Map<String, Object> data = new HashMap<>(); data.put("canonicalPath", canonicalPath); data.put("staticResourcePath", sanitizedStaticPath); data.put("faviconPath", faviconPath); return data; }
String staticPath = ""; if (cdnPath != null) { staticPath = cdnPath; } else if (canonicalPath != null) { staticPath = canonicalPath; } Map<String, Object> data = new HashMap<>(); data.put("canonicalPath", canonicalPath); data.put("staticResourcePath", staticPath); data.put("faviconPath", faviconPath); return data;
// implied. // See the License for the specific language governing permissions and // limitations under the License. package com.vmware.gerrit.owners.common; import static org.junit.Assert.assertEquals; import com.google.gerrit.acceptance.LightweightPluginDaemonTest; import com.google.gerrit.acceptance.Sandboxed; import com.google.gerrit.acceptance.TestPlugin; import com.google.gerrit.extensions.events.GitReferenceUpdatedListener; import com.google.gerrit.reviewdb.client.RefNames; import com.google.inject.AbstractModule; import org.eclipse.jgit.transport.ReceiveCommand.Type; import org.junit.Test; @Sandboxed @TestPlugin( name = "owners-autoassign", sysModule = "com.vmware.gerrit.owners.common.GitRefListenerIT$TestModule") public class GitRefListenerIT extends LightweightPluginDaemonTest { public static class TestModule extends AbstractModule { @Override protected void configure() { bind(GitReferenceUpdatedListener.class).to(TestGitRefListener.class); } } @Test public void shouldNotProcessNoteDbOnlyRefs() { TestGitRefListener gitRefListener = getPluginInstance(TestGitRefListener.class); String aRefChange = RefNames.REFS_CHANGES + "01/01" + RefNames.META_SUFFIX; // Test code goes here } }
public PatchSet fromProto(Entities.PatchSet proto) { PatchSet.Builder builder = PatchSet.builder().id(patchSetIdConverter.fromProto(proto.getId())); builder.setGroups(proto.hasGroups() ? PatchSet.splitGroups(proto.getGroups()) : ImmutableList.of()); builder.setPushCertificate(proto.hasPushCertificate() ? proto.getPushCertificate() : null); builder.setDescription(proto.hasDescription() ? proto.getDescription() : null); // The following fields used to theoretically be nullable in PatchSet, but in practice no // production codepath should have ever serialized an instance that was missing one of these // fields. // // However, since some protos may theoretically be missing these fields, we need to support // them. Populate specific sentinel values for each field as documented in the PatchSet javadoc. return builder.build(); }
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.manager; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.manager.GerritVersionBranch.getBranch; import org.junit.Test; public class GerritVersionBranchTest { @Test public void getBranchReturnsCorrectBranchForVersion() throws Exception { // Regular 2.x versions assertBranch("2.13", "stable-2.13"); assertBranch("2.14", "stable-2.14"); assertBranch("2.15", "stable-2.15"); assertBranch("2.16", "stable-2.16"); // 2.x.y version assertBranch("2.16.10", "stable-2.16"); // 2.x-rcx version assertBranch("2.16-rc1", "stable-2.16"); // 3.0.0 version assertBranch("3.0.0", "stable-3.0"); } }
public void remove(AccessSection section, Permission permission) { if (section != null) { AccessSection a = accessSections.get(section.getName()); a.remove(permission); if (a.getPermissions().size() == 0) { remove(a); } } } return obj; } for (Field f : fields) { if (f.getAnnotation(DefaultInput.class) != null && f.getType() == String.class) { f.setAccessible(true); f.set(obj, value); return obj; } } throw new BadRequestException("Expected JSON object"); } private static Object createInstance(Type type) throws NoSuchMethodException, InstantiationException, IllegalAccessException, InvocationTargetException { if (type instanceof Class) { @SuppressWarnings("unchecked") Class<Object> clazz = (Class<Object>) type; Constructor<Object> c = clazz.getDeclaredConstructor(); c.setAccessible(true); return c.newInstance(); } throw new InstantiationException("Cannot make " + type); } public static long replyJson(@Nullable HttpServletRequest req, HttpServletResponse res, ListMultimap<String, String> config, Object result) throws IOException { TemporaryBuffer.Heap buf = heap(HEAP_EST_SIZE, Integer.MAX_VALUE); buf.write(JSON_MAGIC); Writer w = new BufferedWriter(new OutputStreamWriter(buf, UTF_8)); // Rest of the code... } public void doFilter(HttpServletRequest req, HttpServletResponse res, FilterChain chain) throws IOException, ServletException { try { delegate.doFilter(req, res, chain); } catch (MyRequestFailureException e) { res.setHeader(DefaultErrorHandlingFilter.GITILES_ERROR, e.getReason().toString()); res.sendError(e.getReason().getHttpStatusCode()); } }
protected void initDragAndDrop() { Transfer[] transfers = new Transfer[] { FileTransfer.getInstance() }; DropTarget dropTarget = new DropTarget(viewer, DND.DROP_COPY | DND.DROP_DEFAULT); dropTarget.setTransfer(transfers); dropTarget.addDropListener(new WebBrowserViewDropAdapter(viewer)); } private final static Logger LOG = LoggerFactory.getLogger(PartitionStatsUtil.class); public static TPartitionStats partStatsFromCompressedBytes(byte[] compressedStats, FeFsPartition part) throws ImpalaException { if (compressedStats == null) return null; TCompactProtocol.Factory protocolFactory = new TCompactProtocol.Factory(); TPartitionStats ret = new TPartitionStats(); byte[] decompressed = CompressionUtil.deflateDecompress(compressedStats); if (decompressed == null) { LOG.warn("Error decompressing partition stats for partition: " + part.getPartitionName()); return null; } JniUtil.deserializeThrift(protocolFactory, ret, decompressed); return ret; } private PatchSet getCurrentPatchSet(String changeId) throws Exception { return db.patchSets().get(getChange(changeId).currentPatchSetId()); } private static byte[] toBytes(BinaryResult content) throws Exception { ByteArrayOutputStream os = new ByteArrayOutputStream(); content.writeTo(os); return os.toByteArray(); } private String url() { return "/changes/" + change.getChangeId() + "/edit"; } private EditInfo toEditInfo() throws IOException { RestResponse r = session.get(url()); assertEquals(HttpStatus.SC_OK, r.getStatusCode()); return newGson().fromJson(r.getReader(), EditInfo.class); } protected enum ErrorCode { BLAME_REGION_NOT_FOUND(SC_NOT_FOUND), CANNOT_PARSE_GITILES_VIEW(SC_NOT_FOUND), INCORRECT_PARAMETER(SC_BAD_REQUEST), INCORRECT_OBJECT_TYPE(SC_NOT_FOUND), MARKDOWN_NOT_ENABLED(SC_NOT_FOUND), NOT_AUTHORIZED(SC_UNAUTHORIZED), OBJECT_NOT_FOUND(SC_NOT_FOUND), OBJECT_TOO_LARGE(SC_INTERNAL_SERVER_ERROR), REPOSITORY_NOT_FOUND(SC_NOT_FOUND), SERVICE_NOT_ENABLED(SC_FORBIDDEN), UNSUPPORTED_GITWEB_URL(SC_GONE); private final int statusCode; private ErrorCode(int statusCode) { this.statusCode = statusCode; } public int getStatusCode() { return statusCode; } }
// you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // https://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gitiles; public class MoreAssert { private MoreAssert() {} /** * Simple version of assertThrows that will be introduced in JUnit 4.13. */ public static <T extends Throwable> T assertThrows(Class<T> expected, ThrowingRunnable r) { try { r.run(); throw new AssertionError("Expected " + expected.getSimpleName() + " to be thrown"); } catch (Throwable actual) { if (expected.isAssignableFrom(actual.getClass())) { return (T) actual; } throw new AssertionError("Expected " + expected.getSimpleName() + " to be thrown, but got " + actual.getClass().getSimpleName()); } } }
factory(MultiSiteBatchRefUpdate.Factory.class); factory(RefUpdateValidator.Factory.class); factory(BatchRefUpdateValidator.Factory.class); if (!disableGitRepositoryValidation) { bind(GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); } if (cfg.getZookeeperConfig().getEnforcementRules().isEmpty()) { bind(SharedRefEnforcement.class).to(DefaultSharedRefEnforcement.class).in(Scopes.SINGLETON); } else { bind(SharedRefEnforcement.class).to(CustomSharedRefEnforcementByProject.class).in(Scopes.SINGLETON); } install(new ZkValidationModule(cfg));
private String resolveUrl(URI uri, String link) { String url = cfg.getString("gerrit", null, "canonicalWebUrl"); if (Strings.isNullOrEmpty(url)) { url = uri.toString(); } if (!url.endsWith("/")) { url += "/"; } if (!Strings.isNullOrEmpty(link)) { url += "#" + link; } return url; } void setPluginName(String name) { if (!Strings.isNullOrEmpty(name)) { this.pluginName = name; } } if (!id.isScheme(AccountExternalId.SCHEME_USERNAME) || !username.equals(id.getSchemeRest())) { continue; } String hashedStr = id.getHashedPassword(); if (hashedStr != null && !hashedStr.isEmpty()) { try { return HashedPassword.decode(hashedStr).checkPassword(password); } catch (DecoderException e) { return false; } } String want = id.getPassword(); if (!Strings.isNullOrEmpty(want)) { byte wantBytes[] = want.getBytes(); byte gotBytes[] = password.getBytes(); // Constant-time comparison. return Arrays.areEqual(wantBytes, gotBytes); } return false; // and then query the secondary index for each user but this way is less // efficient. queryPredicate = Predicate.or(AccountPredicates.isActive(), AccountPredicates.isNotActive()); for (AccountState accountState : accountQueryProvider.get().query(queryPredicate)) { Account account = accountState.getAccount(); String out = new StringBuilder() .append(account.getId().toString()) .append(" |") .append(accountState.getUserName().isPresent() ? " " + accountState.getUserName().get() : "") .append(" |") .append(Strings.isNullOrEmpty(account.getFullName()) ? "" : " " + account.getFullName()) .append(" |") .append(Strings.isNullOrEmpty(account.getPreferredEmail()) ? "" : " " + account.getPreferredEmail()) .append(" |") .append(account.isActive() ? " active" : " inactive") .toString(); }
if (args.getSchema().hasField(ChangeField.EXTENSION)) { FileExtensionPredicate extensionPredicate = new FileExtensionPredicate(ext); if (ext.isEmpty()) { RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^.{0}$"); return emptyExtPredicate; } return extensionPredicate; } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException("'onlyextensions' operator is not supported by change index version"); }
Buggy Code: private String getHostPICCoreImagePath() { return androidHostOut + "/framework/core-optimizing-pic.art"; } public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log( "Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } if (mandatoryPlugins.contains(name)) { logger.atInfo().log("Mandatory plugin %s cannot be disabled", name); continue; } logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin"); // In theory we could still unload the plugin even if the rename // failed. However, it would be reloaded on the next server startup, // so we don't bother trying to unload it. continue; } unload(active); } } } Refactored Code: private String getHostCoreImagePathNoArch() { return androidHostOut + "/framework/core.art"; } public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log( "Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } if (mandatoryPlugins.contains(name)) { logger.atInfo().log("Mandatory plugin %s cannot be disabled", name); continue; } logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin
.state(CheckState.FAILED) .upsert(); assertThat(getChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.FAILED)); } @Test public void combinedCheckStateViaQuery() throws Exception { CacheStats start = cloneStats(cache.getStats()); long startReloadsFalse = cache.getReloadCount(false); long startReloadsTrue = cache.getReloadCount(true); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.NOT_RELEVANT)); // Cache hasn't yet populated during update. assertThat(cache.getStats()).since(start).hasHitCount(0); assertThat(cache.getStats()).since(start).hasMissCount(1); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(0); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.NOT_RELEVANT)); assertThat(cache.getStats()).since(start).hasHitCount(1); assertThat(cache.getStats()).since(start).hasMissCount(1); // TODO: Adjust behavior change in the commit message. }
} return EqualsFilePredicate.create(args, file); } @Operator public Predicate<ChangeData> path(String path) { if (path.startsWith("^")) { return new RegexPathPredicate(path); } return new EqualsPathPredicate(FIELD_PATH, path); } @Operator public Predicate<ChangeData> ext(String ext) throws QueryParseException { return extension(ext); } @Operator public Predicate<ChangeData> extension(String ext) throws QueryParseException { if (args.getSchema().hasField(ChangeField.EXTENSION)) { return new FileExtensionPredicate(ext); } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException( "'onlyextensions' operator is not supported by change index version"); }
public MissingMandatoryPluginsException(Collection<String> pluginNames) { super(getMessage(pluginNames)); }
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.plugins; import java.util.Set; /** * Raised when one or more mandatory plugins are missing. */ public class MissingMandatoryPluginsException extends RuntimeException { private static final long serialVersionUID = 1L; public MissingMandatoryPluginsException(Set<String> pluginNames) { super(getMessage(pluginNames)); } public MissingMandatoryPluginsException(Set<String> pluginNames, Throwable why) { super(getMessage(pluginNames), why); } private static String getMessage(Set<String> pluginNames) { return String.format("Cannot find or load the following mandatory plugins: %s", pluginNames); } }
"%s plugin %s, version %s", active == null ? "Loaded" : "Reloaded", loadedPlugin.getName(), loadedPlugin.getVersion()); } } catch (PluginInstallException e) { logger.atWarning().withCause(e.getCause()).log("Cannot load plugin %s", name); } } } Set<String> missingMandatory = Sets.difference(mandatoryPlugins, loadedPlugins); if (!missingMandatory.isEmpty()) { throw new PluginLoaderException("Failed to load mandatory plugins: " + missingMandatory, e); } cleanInBackground(); } private void addAllEntries(Map<String, Path> from, TreeSet<Map.Entry<String, Path>> to) { Iterator<Map.Entry<String, Path>> it = from.entrySet().iterator(); while (it.hasNext()) { Map.Entry<String, Path> entry = it.next(); to.add(new AbstractMap.SimpleImmutableEntry<>(entry.getKey(), entry.getValue())); } } private TreeSet<Map.Entry<String, Path>> jarsFirstSortedPluginsSet( Map<String, Path> activePlugins) {
public void batchAbandon(BatchUpdate.Factory updateFactory, Project.NameKey project, CurrentUser user, Collection<ChangeData> changes, String msgTxt, boolean cleanupAccountPatchReview, NotifyResolver.Result notify) throws RestApiException, UpdateException { if (changes.isEmpty()) { return; } AccountState accountState = user.isIdentifiedUser() ? user.asIdentifiedUser().state() : null; try (BatchUpdate u = updateFactory.create(project, user, TimeUtil.nowTs())) { u.setNotify(notify); for (ChangeData change : changes) { if (!project.equals(change.project())) { throw new ResourceConflictException( String.format("Project name \"%s\" doesn't match \"%s\"", project.get(), change.project().get())); } Change.Id changeId = change.getId(); ChangeUpdate update = u.getChangeUpdate(changeId); update.setChangeMessage(msgTxt); update.setStatus(Change.Status.ABANDONED); if (cleanupAccountPatchReview) { update.setPatchSets(PatchSetUtil.EMPTY); update.setReviewers(Collections.emptySet()); update.setPendingReviewers(Collections.emptySet()); update.setReviewerUpdates(Collections.emptySet()); } if (accountState != null) { update.setAccountState(accountState); } } u.execute(); } }
public static IndexType getIndexType(Injector injector) { Config cfg = injector.getInstance(Key.get(Config.class, GerritServerConfig.class)); return cfg.getEnum("index", null, "type", IndexType.LUCENE); } Refactored Code: return injector.getInstance(Key.get(Config.class, GerritServerConfig.class)).getEnum("index", null, "type", IndexType.LUCENE);
public static IndexType getIndexType(@Nullable Config cfg) { if (cfg == null) { return IndexType.LUCENE; } return cfg.getEnum("index", null, "type", IndexType.LUCENE); }
import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.After; import org.junit.Before; import org.junit.Test; import java.io.ByteArrayOutputStream; import java.io.IOException; import java.sql.Timestamp; import java.util.Collections; import java.util.List; public abstract class AbstractSubmit extends AbstractDaemonTest { @Inject private ChangeNotes.Factory notesFactory; @Inject private ApprovalsUtil approvalsUtil; @Inject private IdentifiedUser.GenericFactory factory; @Inject ChangeHooks hooks; @Before public void setUp() throws Exception { CurrentUser listenerUser = factory.create(user.id); hooks.addChangeListener(new ChangeListener() { @Override public void onChangeEvent(ChangeEvent event) { if (event instanceof ChangeMergedEvent) { setLatestMergeResult(((ChangeMergedEvent)event).mergeResult.revision); } } }, listenerUser); project = new Project.NameKey("p2"); } @After public void cleanup() { db.close(); } } Boolean isPrivate = null; Boolean wip = null; if (!updated.isEmpty()) { edit = getEditValue(); isPrivate = getPrivateValue(); wip = getWipValue(); } for (String commit : commitSequence) { if (created.get(commit) != null) { addCreatedMessage(created.get(commit), " *NEW*"); } else if (updated.get(commit) != null) { addReplacedMessage(updated.get(commit), edit, isPrivate, wip); } } addMessage(""); private void addCreatedMessage(CreateRequest c) { addMessage(changeFormatter.newChange(ChangeReportFormatter.Input.builder().setChange(c.change).build()) + suffix); } private void addReplacedMessage(ReplaceRequest u, boolean edit, Boolean isPrivate, Boolean wip) { String subject; if (edit) { try { subject = receivePack.getRevWalk().parseCommit(u.newCommitId).getShortMessage(); } catch (IOException e) { // Log and fall back to original change subject } } } try (Repository repo = new FileRepository(uri.getPath())) { repo.create(true /* bare */); if (head !=
import com.google.inject.Provides; import com.google.inject.ProvisionException; import com.google.inject.Singleton; import org.eclipse.jgit.lib.Config; import java.util.Collection; import java.util.Set; /** * Module for non-indexer-specific secondary index setup. * <p> * This module should not be used directly except by specific secondary indexer * implementations (e.g. Lucene). */ public class IndexModule extends LifecycleModule { public enum IndexType { LUCENE } public static final ImmutableCollection<SchemaDefinitions<?>> ALL_SCHEMA_DEFS = ImmutableList.<SchemaDefinitions<?>>of( AccountSchemaDefinitions.INSTANCE, ChangeSchemaDefinitions.INSTANCE, GroupSchemaDefinitions.INSTANCE); /** * Type of secondary index. */ public static IndexType getIndexType(Injector injector) { Config cfg = injector.getInstance(Key.get(Config.class, GerritServerConfig.class)); return cfg.getEnum("index", null, "type", IndexType.LUCENE); } private final int threads; private final ListeningExecutorService interactiveExecutor; private final ListeningExecutorService batchExecutor; public IndexModule(int threads) { this.threads = threads; this.interactiveExecutor = null; this.batchExecutor = null; } @Override protected void configure() { bind(ChangeIndexCollection.class).in(Singleton.class); bind(ChangeIndexer.class).in(Singleton.class); bind(IndexRewriter.class).in(Singleton.class); } @Provides @Singleton public ChangeIndexDefintion provideChangeIndexDefinition() { return new ChangeIndexDefintion(); } @Provides @Singleton public Set<ChangeIndexDefintion> provideChangeIndexDefinitions(ChangeIndexDefintion changeIndexDefintion) { return ImmutableSet.of(changeIndexDefintion); } @Provides @Singleton public ChangeIndexCollection provideChangeIndexCollection(Set<ChangeIndexDefintion> changeIndexDefinitions) { return new ChangeIndexCollection(changeIndexDefinitions); } @Provides @Singleton public ChangeIndexer provideChangeIndexer(ChangeIndexCollection changeIndexCollection) { return changeIndexCollection.getSearchIndex(); } @Provides @Singleton public IndexRewriter provideIndexRewriter(ChangeIndexCollection changeIndexCollection) { return changeIndexCollection.getIndexRewriter(); } }
private final DynamicItem<UrlFormatter> urlFormatter; private final Optional<Schedule> schedule; private final long abandonAfter; private final boolean abandonIfMergeable; private final String abandonMessage; @Inject ChangeCleanupConfig(@GerritServerConfig Config cfg, DynamicItem<UrlFormatter> urlFormatter) { this.urlFormatter = urlFormatter; schedule = ScheduleConfig.createSchedule(cfg, SECTION); abandonAfter = readAbandonAfter(cfg); abandonIfMergeable = cfg.getBoolean(SECTION, null, KEY_ABANDON_IF_MERGEABLE, true); abandonMessage = readAbandonMessage(cfg); } private long readAbandonAfter(Config cfg) { long abandonAfter = ConfigUtil.getTimeUnit(cfg, SECTION, null, KEY_ABANDON_AFTER, 0, TimeUnit.MILLISECONDS); return abandonAfter >= 0 ? abandonAfter : 0; } private String readAbandonMessage(Config cfg) { String abandonMessage = cfg.getString(SECTION, null, KEY_ABANDON_MESSAGE); return Strings.isNullOrEmpty(abandonMessage) ? DEFAULT_ABANDON_MESSAGE : abandonMessage; } public Optional<Schedule> getSchedule() { return schedule; } public long getAbandonAfter() { return abandonAfter; }
Project.NameKey key = projectOperations.newProject().create(); ProjectConfig projectConfig = projectOperations.project(key).getProjectConfig(); ProjectState cachedProjectState1 = projectCache.checkedGet(key); assertThat(cachedProjectState1).isNotNull(); assertThat(cachedProjectState1.getProject().getDescription()).isEmpty(); assertThat(projectConfig.getProject().getDescription()).isEmpty(); projectConfig.getProject().setDescription("my fancy project"); ProjectState cachedProjectState2 = projectCache.checkedGet(key); assertThat(cachedProjectState2).isSameInstanceAs(cachedProjectState1); assertThat(cachedProjectState2.getProject().getDescription()).isEmpty(); @Test public void getProjectConfigNoRefsMetaConfig() throws Exception { Project.NameKey key = projectOperations.newProject().create(); deleteRefsMetaConfig(key); ProjectConfig projectConfig = projectOperations.project(key).getProjectConfig(); assertThat(projectConfig.getName()).isEqualTo(key); assertThat(projectConfig.getRevision()).isNull(); } @Test public void getConfig() throws Exception { Project.NameKey key = projectOperations.newProject().create(); }
public IterableSubject sections() { isNotNull(); return check("getSections()").that(config.getSections()); }
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.common; import static java.lang.annotation.ElementType.FIELD; import static java.lang.annotation.ElementType.METHOD; import static java.lang.annotation.ElementType.TYPE; import static java.lang.annotation.RetentionPolicy.RUNTIME; import java.lang.annotation.Retention; import java.lang.annotation.Target; /** * A marker to say a method/type/field is added or public solely because it is called from inside a * project or an organisation using Gerrit. */ @Target({METHOD, TYPE, FIELD}) @Retention(RUNTIME) public @interface UsedAt { /** * Enumeration of projects that call a method/type/field. */ enum Project { GOOGLE, PLUGIN_CHECKS, PLUGIN_DELETE_PROJECT, PLUGIN_SERVICEUSER, PLUGINS_ALL // Use this project if a method/type is generally made available to all plugins. } /** Reference to the project that uses the method annotated with this annotation. */ Project value(); }
public int compare(RevisionInfo a, RevisionInfo b) { return num(a) - num(b); } final ReviewResult result = new ReviewResult(); final PatchSet patch = db.patchSets().get(patchSetId); final Change.Id changeId = patchSetId.getParentKey(); final ChangeControl control = changeControlFactory.validateFor(changeId); result.setChangeId(changeId); if (patch == null) { throw new NoSuchChangeException(changeId); } List<SubmitRecord> submitResult = control.canSubmit(db, patchSetId); if (submitResult.isEmpty()) { throw new IllegalStateException("ChangeControl.canSubmit returned empty list"); } for (SubmitRecord submitRecord : submitResult) { switch (submitRecord.status) { case OK: if (!control.getRefControl().canSubmit()) { result.addError(new ReviewResult.Error(ReviewResult.Error.Type.SUBMIT_NOT_PERMITTED)); } break; case NOT_READY: StringBuilder errMsg = new StringBuilder(); for (SubmitRecord.Label lbl : submitRecord.labels) { switch (lbl.status) { case OK: break; case REJECT: // Handle reject case break; } } break; } } public void run() { try { final SharedLockResponse response = requestHandler.handleRequest(request); log.handle(Priority.INFO, "response = " + response.toString()); if (response.isSucessful()) { log.handle(Priority.INFO, requestType + " was successfull"); } else { log.handle(Priority.INFO, requestType + " is not successfull"); } String responseString = Helper.toJson(response); asyncResponse.resume(Response.ok(responseString, MediaType.APPLICATION_JSON).build()); } catch (Exception e) { log.error("handleRequest Exception", e); asyncResponse.resume(Response.ok("handleRequest Exception", MediaType.APPLICATION_JSON).build()); } } // Other code... boolean requestRunway(PushOne op) { synchronized (stateLock) { if (op.wasCanceled()) { return false; } pending.remove(op.getURI()); if (inFlight.containsKey(op.getURI())) { return false; } inFlight.put(op.getURI(), op); } return true; } void notifyFinished(PushOne op) { synchronized (stateLock) { inFlight.remove(op.getURI());
public class DeleteGpgKey implements RestModifyView<GpgKey, Input> { private static final Logger log = LoggerFactory.getLogger(DeleteGpgKey.class); public static class Input {} private final Provider<PersonIdent> serverIdent; private final Provider<PublicKeyStore> storeProvider; private final ExternalIdsUpdate.User externalIdsUpdateFactory; private final DeleteKeySender.Factory deleteKeySenderFactory; @Inject DeleteGpgKey( @GerritPersonIdent Provider<PersonIdent> serverIdent, Provider<PublicKeyStore> storeProvider, ExternalIdsUpdate.User externalIdsUpdateFactory, DeleteKeySender.Factory deleteKeySenderFactory) { this.serverIdent = serverIdent; this.storeProvider = storeProvider; this.externalIdsUpdateFactory = externalIdsUpdateFactory; this.deleteKeySenderFactory = deleteKeySenderFactory; } @Override public Response<?> apply(GpgKey rsrc, Input input) throws ResourceConflictException, PGPException, OrmException, IOException, ConfigInvalidException { PGPPublicKey key = rsrc.getKeyRing().getPublicKey(); externalIdsUpdateFactory .create() .delete( rsrc.getUser().getAccountId(), ExternalId.Key.create( SCHEME_GPGKEY, BaseEncoding.base16().encode(key.getFingerprint()))); // Rest of the method implementation } }
import org.slf4j.LoggerFactory; @Singleton public class PostGpgKeys implements RestModifyView<AccountResource, Input> { public static class Input { public List<String> add; public List<String> delete; } private final Logger log = LoggerFactory.getLogger(getClass()); private final Provider<PersonIdent> serverIdent; private final Provider<CurrentUser> self; private final Provider<PublicKeyStore> storeProvider; private final GerritPublicKeyChecker.Factory checkerFactory; private final AddKeySender.Factory addKeyFactory; private final DeleteKeySender.Factory deleteKeyFactory; private final Provider<InternalAccountQuery> accountQueryProvider; private final ExternalIds externalIds; private final ExternalIdsUpdate.User externalIdsUpdateFactory; @Inject PostGpgKeys( @GerritPersonIdent Provider<PersonIdent> serverIdent, Provider<CurrentUser> self, Provider<PublicKeyStore> storeProvider, GerritPublicKeyChecker.Factory checkerFactory, AddKeySender.Factory addKeyFactory, DeleteKeySender.Factory deleteKeyFactory, Provider<InternalAccountQuery> accountQueryProvider, ExternalIds externalIds, ExternalIdsUpdate.User externalIdsUpdateFactory) { this.serverIdent = serverIdent; this.self = self; this.storeProvider = storeProvider; this.checkerFactory = checkerFactory; this.addKeyFactory = addKeyFactory; this.deleteKeyFactory = deleteKeyFactory; this.accountQueryProvider = accountQueryProvider; this.externalIds = externalIds; this.externalIdsUpdateFactory = externalIdsUpdateFactory; } }
case NEW: case FAST_FORWARD: case FORCED: if (!addedKeys.isEmpty()) { try { addKeyFactory.create(user, addedKeys).send(); } catch (EmailException e) { log.error( "Cannot send GPG key added message to " + user.getAccount().getPreferredEmail(), e); } } if (!toRemove.isEmpty()) { try { deleteKeyFactory.create(user, toRemove.stream().map(Fingerprint::toString).collect(toList())).send(); } catch (EmailException e) { log.error( "Cannot send GPG key deleted message to " + user.getAccount().getPreferredEmail(), e); } } break; case NO_CHANGE: break; case IO_FAILURE: case LOCK_FAILURE: case NOT_ATTEMPTED: case REJECTED: case REJECTED_CURRENT_BRANCH: case RENAMED: case REJECTED_MISSING_OBJECT: case REJECTED_OTHER_REASON: default: // TODO(dborowitz): Backoff and retry on LOCK_FAILURE.
import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.errors.RepositoryNotFoundException; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class DeleteSshKey implements RestModifyView<AccountResource.SshKey, Input> { private static final Logger log = LoggerFactory.getLogger(DeleteSshKey.class); public static class Input {} private final Provider<CurrentUser> self; private final PermissionBackend permissionBackend; private final VersionedAuthorizedKeys.Accessor authorizedKeys; private final SshKeyCache sshKeyCache; private final DeleteKeySender.Factory deleteKeyFactory; @Inject DeleteSshKey( Provider<CurrentUser> self, PermissionBackend permissionBackend, VersionedAuthorizedKeys.Accessor authorizedKeys, SshKeyCache sshKeyCache, DeleteKeySender.Factory deleteKeyFactory) { this.self = self; this.permissionBackend = permissionBackend; this.authorizedKeys = authorizedKeys; this.sshKeyCache = sshKeyCache; this.deleteKeyFactory = deleteKeyFactory; } @Override public Response<?> apply(AccountResource.SshKey rsrc, Input input) throws AuthException, OrmException, RepositoryNotFoundException, IOException, ConfigInvalidException, PermissionBackendException { // Implementation goes here } }
import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.reviewdb.client.AccountSshKey; import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import java.util.List; public class DeleteKeySender extends OutgoingEmail { public interface Factory { DeleteKeySender create(IdentifiedUser user, AccountSshKey sshKey); DeleteKeySender create(IdentifiedUser user, List<String> gpgKeys); } private final PermissionBackend permissionBackend; private final IdentifiedUser callingUser; private final IdentifiedUser user; private final AccountSshKey sshKey; private final List<String> gpgKeys; @AssistedInject public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.sshKey = sshKey; } }
import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import java.util.List; public class DeleteKeySender extends OutgoingEmail { public interface Factory { DeleteKeySender create(IdentifiedUser user, AccountSshKey sshKey); DeleteKeySender create(IdentifiedUser user, List<String> gpgKeyFingerprints); } private final PermissionBackend permissionBackend; private final IdentifiedUser callingUser; private final IdentifiedUser user; private final AccountSshKey sshKey; private final List<String> gpgKeyFingerprints; @AssistedInject public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeyFingerprints = null; this.sshKey = sshKey; } @AssistedInject public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted List<String> gpgKeyFingerprints) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeyFingerprints = gpgKeyFingerprints; this.sshKey = null; } }
public DeleteKeySender(EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeys = Collections.emptyList(); this.sshKey = sshKey; }
public DeleteKeySender(EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted List<String> gpgKeys) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeys = gpgKeys; this.sshKey = null; }
public DeleteKeySender(EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted List<String> gpgKeys) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeys = gpgKeys; this.sshKey = null; }
public String getKeyType() { if (sshKey != null) { return "SSH"; } else if (gpgKeys != null) { return "GPG"; } throw new IllegalArgumentException("Unknown key type"); }
public String getGpgKeys() { if (gpgKeys != null) { return Joiner.on("\n").join(gpgKeys); } return null; }
return TestPermission.builder().name(name).action(PermissionRule.Action.ALLOW); } /** Start a builder for denying a permission. */ public static TestPermission.Builder deny(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.DENY); } /** Start a builder for blocking a permission. */ public static TestPermission.Builder block(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.BLOCK); } /** * Records a permission to be updated. * * <p>Not used for permissions that have ranges (label permissions) or global capabilities. */ @AutoValue public abstract static class TestPermission { private static Builder builder() { return new AutoValue_TestProjectUpdate_TestPermission.Builder().force(false); } abstract String name(); abstract String ref(); abstract AccountGroup.UUID group(); abstract PermissionRule.Action action(); abstract boolean force(); /** Builder for {@link TestPermission}. */ @AutoValue.Builder public abstract static class Builder {
@AutoValue public abstract static class TestPermission { private static Builder builder() { return new AutoValue_TestProjectUpdate_TestPermission.Builder().force(false); } abstract String name(); abstract String ref(); abstract AccountGroup.UUID group(); abstract PermissionRule.Action action(); abstract boolean force(); @AutoValue.Builder public abstract static class Builder { public abstract Builder name(String name); public abstract Builder ref(String ref); public abstract Builder group(AccountGroup.UUID groupUuid); abstract Builder action(PermissionRule.Action action); public abstract Builder force(boolean force); public abstract TestPermission build(); } }
public void deleteUserBranch_Conflict() throws Exception { projectOperations .project(allUsers) .forUpdate() .add(TestProjectUpdate.allow(Permission.CREATE) .ref(RefNames.REFS_USERS + "*") .group(REGISTERED_USERS)) .add(TestProjectUpdate.allow(Permission.PUSH) .ref(RefNames.REFS_USERS + "*") .group(REGISTERED_USERS)) .update(); ResourceConflictException thrown = assertThrows(ResourceConflictException.class, () -> branch(BranchNameKey.create(allUsers, RefNames.refsUsers(admin.id()))).delete()); assertThat(thrown).hasMessageThat().contains("Not allowed to delete user branch."); } @Test public void deleteGroupBranch_Conflict() throws Exception { allow(allUsers, RefNames.REFS_GROUPS + "*", Permission.CREATE, REGISTERED_USERS); allow(allUsers, RefNames.REFS_GROUPS + "*", Permission.PUSH, REGISTERED_USERS); ResourceConflictException thrown = assertThrows(ResourceConflictException.class, () -> branch(BranchNameKey.create(allUsers, RefNames.refsGroups(admin.id()))).delete()); assertThat(thrown).hasMessageThat().contains("Not allowed to delete group branch."); }
@NoHttpd public class PluginLoaderIT extends AbstractDaemonTest { Description testDescription; @Override protected void beforeTest(Description description) throws Exception { this.testDescription = description; } @Override protected void afterTest() throws Exception {} @Test(expected = MissingMandatoryPluginsException.class) @GerritConfig(name = "plugins.mandatory", value = "my-mandatory-plugin") public void shouldFailToStartGerritWhenMandatoryPluginsAreMissing() throws Exception { super.beforeTest(testDescription); } }
public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log("Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } if (mandatoryPlugins.contains(name)) { logger.atInfo().log("Mandatory plugin %s cannot be disabled", name); continue; } logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin"); // In theory we could still unload the plugin even if the rename // failed. However, it would be reloaded on the next server startup, } } } }
/*******************************************************************************/ package org.eclipse.egit.gitflow.ui.internal; import java.net.MalformedURLException; import java.net.URL; import org.eclipse.egit.ui.Activator; import org.eclipse.jface.resource.ImageDescriptor; /** * Icons for Gitflow integration. */ public class UIIcons { /** Decoration for initialized Gitflow repository. */ public final static ImageDescriptor OVR_GITFLOW; /** base URL */ public final static URL base; static { base = init(); OVR_GITFLOW = map("ovr/git-flow.gif"); //$NON-NLS-1$ } private static ImageDescriptor map(final String icon) { if (base != null) try { return ImageDescriptor.createFromURL(new URL(base, icon)); } catch (MalformedURLException mux) { Activator.logError(UIText.UIIcons_errorLoadingPluginImage, mux); } return ImageDescriptor.getMissingImageDescriptor(); } private static URL init() { try { return new URL(Activator.getDefault().getBundle().getEntry("/"), //$NON-NLS-1$ "icons/"); //$NON-NLS-1$ } catch (MalformedURLException mux) { Activator.logError(UIText.UIIcons_errorLoadingPluginImage, mux); } return null; } }
public void setUp() { globalPluginConfig = new Config(); replicationConfig = new Config(); } private Configuration getConfiguration() { return new Configuration(globalPluginConfig, replicationConfig); } @Test public void testGetIndexThreadPoolSize() throws Exception { assertThat(getConfiguration().index().threadPoolSize()).isEqualTo(DEFAULT_THREAD_POOL_SIZE); globalPluginConfig.setInt(INDEX_SECTION, null, THREAD_POOL_SIZE_KEY, THREAD_POOL_SIZE); assertThat(getConfiguration().index().threadPoolSize()).isEqualTo(THREAD_POOL_SIZE); } @Test public void testGetIndexSynchronize() throws Exception { assertThat(getConfiguration().index().synchronize()).isEqualTo(DEFAULT_SYNCHRONIZE); globalPluginConfig.setBoolean(INDEX_SECTION, null, SYNCHRONIZE_KEY, false); assertThat(getConfiguration().index().synchronize()).isFalse(); globalPluginConfig.setBoolean(INDEX_SECTION, null, SYNCHRONIZE_KEY, true); assertThat(getConfiguration().index().synchronize()).isTrue(); } @Test public void testGetCacheThreadPoolSize() throws Exception { // Add assertions for cache thread pool size here }
drainQueue(droppedEventsQueue); ChangeData change = createChange().getChange(); String project = change.project().get(); int changeNum = change.getId().get(); String changeNotesRef = change.notes().getRefName(); int patchsetNum = change.currentPatchSet().getPatchSetId(); String patchsetRevision = change.currentPatchSet().getRevision().get(); String patchsetRef = change.currentPatchSet().getRefName(); Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue); assertThat(eventsByType.get("change-index")) .containsExactly(createChangeIndexEvent(project, changeNum, getParentCommit(change))); assertThat(eventsByType.get("ref-updated") .stream() .map(e -> ((RefUpdatedEvent) e).getRefName()) .collect(toSet())) .containsAllOf(changeNotesRef, patchsetRef); // 'refs/sequences/changes' not always updated thus not checked List<Event> patchSetCreatedEvents = eventsByType.get("patchset-created"); assertThat(patchSetCreatedEvents).hasSize(1); assertPatchSetAttributes(patchSetCreatedEvents.get(0), project, changeNum, patchsetNum, patchsetRevision, patchsetRef);
import java.util.Arrays; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.commons.lang.StringUtils; import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Configuration { private static final Logger log = LoggerFactory.getLogger(Configuration.class); public static final String PLUGIN_NAME = "multi-site"; static final String INSTANCE_ID_FILE = "instanceId.data"; // common parameters to cache and index sections static final String THREAD_POOL_SIZE_KEY = "threadPoolSize"; static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000; }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.base.Suppliers.memoize; import static com.googlesource.gerrit.plugins.multisite.ConfigurationHelper.getString; import com.google.common.annotations.VisibleForTesting; import com.google.common.base.CaseFormat; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.HashMap;
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.multisite.Configuration.ENABLE_KEY; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KAFKA_PROPERTY_PREFIX; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KAFKA_SECTION; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaPublisher.KAFKA_PUBLISHER_SUBSECTION; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaSubscriber.KAFKA_SUBSCRIBER_SUBSECTION; import org.eclipse.jgit.lib.Config;
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.acceptance.testsuite.project; import com.google.auto.value.AutoValue; import com.google.common.collect.ImmutableList; import com.google.gerrit.acceptance.testsuite.ThrowingConsumer; import com.google.gerrit.common.data.PermissionRule; import com.google.gerrit.reviewdb.client.AccountGroup; @AutoValue public abstract class TestProjectUpdate { /** * Starts a builder for allowing a capability. */ public static TestPermission.Builder allow(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.ALLOW); } /** * Starts a builder for denying a permission. */ public static TestPermission.Builder deny(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.DENY); } /** * Starts a builder for blocking a permission. */ public static TestPermission.Builder block(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.BLOCK); } // Rest of the code... }
import com.google.gerrit.extensions.annotations.Listen; import com.google.gerrit.server.events.CommitReceivedEvent; import com.google.gerrit.server.git.validators.CommitValidationException; import com.google.gerrit.server.git.validators.CommitValidationListener; import com.google.gerrit.server.git.validators.CommitValidationMessage; import com.google.inject.Singleton; @Listen @Singleton public class CommitMessageLengthValidation implements CommitValidationListener { @Override public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException { final RevCommit commit = receiveEvent.commit; final AbbreviatedObjectId id = commit.abbreviate(7); List<CommitValidationMessage> messages = new ArrayList<CommitValidationMessage>(); if (65 < commit.getShortMessage().length()) { messages.add(new CommitValidationMessage("(W) " + id.name() + ": commit subject >65 characters; use shorter first paragraph", false)); } int longLineCnt = 0, nonEmptyCnt = 0; for (String line : commit.getFullMessage().split("\n")) { if (!line.trim().isEmpty()) { nonEmptyCnt++; } } return messages; } } assertSubmitter(change3); // Also check submitters for changes submitted via the topic relationship. assertSubmitter(change1); assertSubmitter(change2); } private void assertSubmitter(PushOneCommit.Result change) throws Exception { ChangeInfo info = get(change.getChangeId(), ListChangesOption.MESSAGES); assertThat(info.messages).isNotNull(); Iterable<String> messages = Iterables.transform(info.messages, new Function<ChangeMessageInfo, String>() { @Override public String apply(ChangeMessageInfo in) { return in.message; } }); assertThat(messages).hasSize(3); String last = Iterables.getLast(messages); if (getSubmitType() == SubmitType.CHERRY_PICK) { assertThat(Iterables.getLast(info.messages).message).startsWith("Change has been successfully cherry-picked as "); } else { assertThat(last).isEqualTo("Change has been successfully merged by Administrator"); } } @Override protected void updateProjectInput(ProjectInput in) { in.submitType = getSubmitType(); if (in.useContentMerge == InheritableBoolean.INHERIT) { in.useContentMerge = InheritableBoolean.FALSE; }
import com.google.gerrit.reviewdb.client.RefNames; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.GerritPersonIdent; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import java.io.IOException; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import java.sql.Timestamp; import java.util.HashMap; import java.util.Map; import import java.util.logging.Logger; import org.eclipse.jgit.lib.CommitBuilder; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectInserter; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefUpdate; import org.eclipse.jgit.lib.RefUpdate.Result; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevSort; import org.eclipse.jgit.revwalk.RevWalk; public class MyClass { // Class implementation goes here }
String refName = RefNames.refsUsers(e.getKey()); Ref ref = repo.exactRef(refName); if (ref != null) { rewriteUserBranch(repo, rw, oi, emptyTree, ref, e.getValue()); } else { createUserBranch(repo, oi, emptyTree, e.getKey(), e.getValue()); } i++; if (i % 100 == 0) { LOG.info(String.format("Migrated %d users to schema 146", i)); } } catch (IOException e) { throw new OrmException("Failed to rewrite user branches.", e); } private void rewriteUserBranch(Repository repo, RevWalk rw, ObjectInserter oi, ObjectId emptyTree, Ref ref, Timestamp registeredOn) throws IOException { ObjectId current = createInitialEmptyCommit(oi, emptyTree, registeredOn); rw.reset(); rw.sort(RevSort.TOPO); rw.sort(RevSort.REVERSE, true); rw.markStart(rw.parseCommit(ref.getObjectId())); RevCommit c;
// and the start() methods of each such listener are executed in the // order they are declared. // Makes sure that PluginLoader.start() is executed before the // LuceneIndexModule.start() so that plugins get loaded and the respective // Guice modules installed so that the on-line reindexing will happen // with the proper classes (e.g. group backends, custom Prolog // predicates) and the associated rules ready to be evaluated. modules.add(new PluginModule()); modules.add(new RestApiModule()); modules.add(new GpgModule(config)); modules.add(new StartupChecks.Module()); modules.add(createIndexModule()); modules.add(new WorkQueue.Module()); modules.add(new GerritInstanceNameModule()); modules.add(new CanonicalWebUrlModule() { @Override protected Class<? extends Provider<String>> provider() { return HttpCanonicalWebUrlProvider.class; } });
try { u = new URL(p.substring(0, p.indexOf('!'))); } catch (MalformedURLException e) { FileNotFoundException fnfe = new FileNotFoundException("Not a valid jar file: " + u); fnfe.initCause(e); throw fnfe; } if (!"file".equals(u.getProtocol())) { throw new FileNotFoundException("Cannot extract path from " + u); } // Pop up to the top-level source folder by looking for .buckconfig. dir = Paths.get(u.getPath()); while (!Files.isRegularFile(dir.resolve("WORKSPACE"))) { Path parent = dir.getParent(); if (parent == null) { throw new FileNotFoundException("Cannot find source root from " + u); } dir = parent; } Path ret = dir.resolve(name); if (!Files.exists(ret)) { throw new FileNotFoundException(name + " not found in source root " + dir); } return ret;
protected String getDeleteActions(Id c) { if (!client.adapter().useType()) { return delete(client.adapter().getType(""), c); } return delete(OPEN_CHANGES, c) + delete(CLOSED_CHANGES, c); }
private final boolean useV6Type; private final boolean omitTypeFromSearch; private final String searchFilteringName; private final String indicesExistParam; private final String exactFieldType; private final String stringFieldType; private final String indexProperty; private final String versionDiscoveryUrl; private final String includeTypeNameParam; ElasticQueryAdapter(ElasticVersion version) { this.ignoreUnmapped = false; this.useType = !version.isV6OrLater(); this.useV6Type = version.isV6(); this.omitTypeFromSearch = version.isV7OrLater(); this.versionDiscoveryUrl = version.isV6OrLater() ? "/%s*" : "/%s*/_aliases"; this.searchFilteringName = "_source"; this.indicesExistParam = "?allow_no_indices=false"; this.exactFieldType = "keyword"; this.stringFieldType = "text"; this.indexProperty = "true"; this.includeTypeNameParam = version.isV6() ? "?include_type_name=true" : ""; } public boolean isUseV6Type() { return useV6Type; } public boolean isOmitTypeFromSearch() { return omitTypeFromSearch; } public String getSearchFilteringName() { return searchFilteringName; } public String getIndicesExistParam() { return indicesExistParam; } public String getExactFieldType() { return exactFieldType; } public String getStringFieldType() { return stringFieldType; } public String getIndexProperty() { return indexProperty; } public String getVersionDiscoveryUrl() { return versionDiscoveryUrl; } public String getIncludeTypeNameParam() { return includeTypeNameParam; }
public class ElasticVersion { private String version; public ElasticVersion(String version) { this.version = version; } public static String supportedVersions() { return Joiner.on(", ").join(ElasticVersion.values()); } public boolean isV6() { return isVersion(6); } public boolean isV6OrLater() { return isAtLeastVersion(6); } public boolean isV7OrLater() { return isAtLeastVersion(7); } private boolean isAtLeastVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) >= v; } private boolean isVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) == v; } @Override public String toString() { return version; } }
RawInputUtil.create(HTML_PLUGIN.getBytes(UTF_8)); private static final ImmutableList<String> PLUGINS = ImmutableList.of( "plugin-a.js", "plugin-b.html", "plugin-c.js", "plugin-d.html", "plugin_e.js" ); @Inject private RequestScopeOperations requestScopeOperations; @Inject private MandatoryPluginsCollection mandatoryPluginsCollection; @Test @GerritConfig(name = "plugins.allowRemoteAdmin", value = "true") public void pluginManagement() throws Exception { // No plugins are loaded assertThat(list().get()).isEmpty(); assertThat(list().all().get()).isEmpty(); PluginApi api; // Install all the plugins InstallPluginInput input = new InstallPluginInput(); for (String plugin : PLUGINS) { input.raw = plugin.endsWith(".js") ? JS_PLUGIN_CONTENT : HTML_PLUGIN_CONTENT; api = gApi.plugins().install(plugin, input); assertThat(api).isNotNull(); PluginInfo info = api.get(); // Perform assertions on the installed plugin } }
public TestLabelPermission build() { TestLabelPermission result = autoBuild(); checkLabelName(result.name()); return result; }
"queryLimit", "+0..+" + DEFAULT_MAX_QUERY_LIMIT + " group global:Registered-Users"); } @Test public void removePermission() throws Exception { Project.NameKey key = projectOperations.newProject().create(); projectOperations .project(key) .forUpdate() .add(TestProjectUpdate.allow(Permission.ABANDON).ref("refs/foo").group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .containsKey("abandon"); projectOperations .project(key) .forUpdate() .remove(TestProjectUpdate.permissionKey(Permission.ABANDON).ref("refs/foo").group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .doesNotContainKey("abandon"); } @Test public void removeLabelPermission() throws Exception { Project.NameKey key = projectOperations.newProject().create(); projectOperations .project(key) .forUpdate() .add(TestProjectUpdate.allowLabel("Code-Review").ref("refs/foo").group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .containsKey("label-Code-Review"); projectOperations .project(key) .forUpdate() .remove(TestProjectUpdate.permissionKey("label-Code-Review").ref("refs/foo").group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .doesNotContainKey("label-Code-Review"); }
private void rcpt(@Nullable RecipientType type, String email, boolean expected) { if (recipients.get(type).contains(email) != expected) { failWithoutActual(fact(expected ? "should notify" : "shouldn't notify", type + ": " + users.emailToName(email))); } if (expected) { accountedFor.add(email); } }
private static String formatDate(PersonIdent author) { SimpleDateFormat df = new SimpleDateFormat("EEE, dd MMM yyyy HH:mm:ss Z", Locale.US); df.setCalendar(Calendar.getInstance(author.getTimeZone(), Locale.US)); return df.format(author.getWhen()); } private boolean isFullMatch(Account.Id id, String nameOrEmail) { Optional<AccountState> account = byId.get(id); return account.isPresent() && Objects.toString(account.get().getAccount().getFullName(), "") .trim() .equalsIgnoreCase(nameOrEmail) || account.get() .getExternalIds() .stream() .anyMatch(extId -> getSchemeRest(extId.key().scheme(), extId.key().get()) .trim() .equalsIgnoreCase(nameOrEmail)); } // of C Git's format-patch .append("From: ").append(author.getName()).append(" <") .append(author.getEmailAddress()).append(">\n") .append("Date: ").append(formatDate(author)).append('\n') .append("Subject: [PATCH] ").append(subject).append('\n') .append('\n').append(msg); if (!msg.endsWith("\n")) { b.append('\n'); } return b.append("---\n\n").toString(); r.assertNoContent(); assertThat(projectDir.exists()).isFalse(); @Test @UseLocalDisk public void testSshDeleteProjectWithoutOptions() throws Exception { createChange(); String cmd = Joiner.on(" ").join(PLUGIN, "delete", project.get()); String expected = String.format( "Really delete '%s'?\n" + "This is an operation which permanently deletes data. This cannot be undone!\n" + "If you are sure you wish to delete this project, re-run with the --yes-really-delete flag.\n\n", project.get()); adminSshSession.exec(cmd); assertThat(projectDir.exists()).isTrue(); assertThat(adminSshSession.getError()).isEqualTo(expected); } @Test @UseLocalDisk public void testSshDeleteProjYesReallyDelete() throws Exception { createChange(); String cmd = createDeleteCommand(project.get()); String expected = String.format( "Project '%s' has open changes. - To really delete '%s', re-run with the --force", project.get(), project.get()); adminSshSession.exec(cmd); assertThat(adminSshSession.getError()).isEqualTo(expected); }
// // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.schema; import com.google.common.collect.Iterables; import com.google.common.collect.Sets; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.client.RefNames; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.GerritPersonIdent; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import java.io.IOException; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import java.sql.Timestamp; import java.time.Duration; import java.time.Instant; import java.util.Date; import java.util.HashMap; import java.util.List; public class SchemaUpdater { @Inject public SchemaUpdater(Provider<ReviewDb> dbProvider, GitRepositoryManager repoManager, AllUsersName allUsersName, GerritPersonIdent gerritIdent) { this.dbProvider = dbProvider; this.repoManager = repoManager; this.allUsersName = allUsersName; this.gerritIdent = gerritIdent; } public void update() throws OrmException, IOException, SQLException { try (ReviewDb db = dbProvider.get(); Statement stmt = ((JdbcSchema) db).getConnection().createStatement()) { // Update account IDs updateAccountIds(db, stmt); } } private void updateAccountIds(ReviewDb db, Statement stmt) throws SQLException { ResultSet rs = stmt.executeQuery("SELECT account_id FROM accounts"); HashMap<Account.Id, Account.Id> accountIds = new HashMap<>(); while (rs.next()) { Account.Id oldId = new Account.Id(rs.getInt(1)); Account.Id newId = Account.Id.create(); accountIds.put(oldId, newId); } rs.close(); for (Account.Id oldId : accountIds.keySet()) { Account.Id newId = accountIds.get(oldId); stmt.executeUpdate("UPDATE accounts SET account_id = " + newId.get() + " WHERE account_id = " + oldId.get()); stmt.executeUpdate("UPDATE account_external
assertThat(accountState.getAccount().getFullName()).isEqualTo(fullName); AccountInfo info = gApi.accounts().id(accountId.get()).get(); assertThat(info.name).isEqualTo(fullName); List<EmailInfo> emails = gApi.accounts().id(accountId.get()).getEmails(); assertThat(emails.stream().map(e -> e.email).collect(toSet())).containsExactly(extId.email()); RevCommit commitUserBranch = projectOperations.project(allUsers).getHead(RefNames.refsUsers(accountId)); RevCommit commitRefsMetaExternalIds = projectOperations.project(allUsers).getHead(RefNames.REFS_EXTERNAL_IDS); assertThat(commitUserBranch.getCommitTime()) .isEqualTo(commitRefsMetaExternalIds.getCommitTime()); } finally { TestTimeUtil.useSystemTime(); } } @Test public void updateNonExistingAccount() throws Exception { Account.Id nonExistingAccountId = Account.id(999999); AtomicBoolean consumerCalled = new AtomicBoolean(); Optional<AccountState> accountState = accountsUpdateProvider .get() .update(nonExistingAccountId, account -> consumerCalled.set(true)); assertThat(accountState).isEmpty(); assertThat(consumerCalled).isFalse(); }
private int populateCombo() { int width = 0; String lastResourceClassId = getDialogSettings().get("resourceClass"); //$NON-NLS-1$ int index = -1; int i = 0; GC gc = new GC(fResourceClassCombo); for (i = 0; i < resourceClasses.length; ++i) { String description = resourceClasses[i].getHumanDescription(); width = Math.max(width, gc.textExtent(description).x); fResourceClassCombo.add(description); if (resourceClasses[i].getId().equals(lastResourceClassId)) index = i; } if (index != -1) { fResourceClassId = lastResourceClassId; fResourceClassCombo.select(index); } if (width == 0) { width = gc.textExtent("Shared memory regions").x; //$NON-NLS-1$ } }
import com.google.gwt.event.shared.HandlerRegistration; import com.google.gwt.user.client.DOM; import com.google.gwt.user.client.Window; import com.google.gwt.user.client.ui.FlowPanel; import net.codemirror.lib.CodeMirror; import net.codemirror.lib.Configuration; import net.codemirror.lib.ModeInjector; import java.util.ArrayList; import java.util.List; public class CodeMirrorDemo extends Screen { private static final int HEADER_FOOTER = 60 + 15 * 2 + 38; private final PatchSet.Id base; private final PatchSet.Id revision; private final String path; private DiffTable diffTable; private CodeMirror cmA; private CodeMirror cmB; private HandlerRegistration resizeHandler; public CodeMirrorDemo(PatchSet.Id base, PatchSet.Id revision, String path) { this.base = base; this.revision = revision; this.path = path; } @Override protected void onInitUI() { super.onInitUI(); add(editorContainer = new FlowPanel()); } @Override protected void onLoad() { super.onLoad(); } }
metaRef3, "refs/heads/master", "refs/tags/master-tag", "refs/users/00/1000000/edit-" + cd3.getId() + "/1", "refs/users/01/1000001/edit-" + cd3.getId() + "/1"); } @Test public void uploadPackSubsetOfRefsVisibleWithAccessDatabase() throws Exception { projectOperations .project(allProjects) .forUpdate() .add(allowCapability(GlobalCapability.ACCESS_DATABASE).group(REGISTERED_USERS)) .add(deny(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(admin.id()); gApi.changes().id(cd3.getId().get()).edit().create(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( // Change 1 is visible due to accessDatabase capability, even though // refs/heads/master is not. psRef1, metaRef1, psRef2, metaRef2, psRef3, metaRef3, psRef4, metaRef4,
ProjectConfig allProjectsConfig = projectConfigFactory.create(allProjectsName); allProjectsConfig.load(md); LabelType cr = Util.codeReview(); allProjectsConfig.getLabelSections().put(cr.getName(), cr); allProjectsConfig.commit(md); repoManager.createRepository(parentKey).close(); repoManager.createRepository(localKey).close(); try (MetaDataUpdate md = metaDataUpdateFactory.create(localKey)) { ProjectConfig newLocal = projectConfigFactory.create(localKey); newLocal.load(md); newLocal.getProject().setParentName(parentKey); newLocal.commit(md); } requestContext.setContext(() -> null); } @After public void tearDown() throws Exception { requestContext.setContext(null); } @Test public void ownerProject() throws Exception { projectOperations .project(localKey) .forUpdate() .add(allow(OWNER).ref("refs/*").group(ADMIN)) .update(); assertAdminsAreOwnersAndDevsAreNot(); } @Test public void denyOwnerProject() throws Exception { projectOperations .project(localKey) .forUpdate()
projectOperations.project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .update(); ProjectControl u = user(localKey, DEVS); assertCannotUpdate("refs/heads/master", u); @Test public void unblockMoreSpecificRefInLocal_Fails() throws Exception { projectOperations.project(parentKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .update(); ProjectControl u = user(localKey, DEVS); assertCannotUpdate("refs/heads/master", u); } @Test public void unblockMoreSpecificRefWithExclusiveFlag() throws Exception { projectOperations.project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .setExclusiveGroup(permissionKey(PUSH).ref("refs/heads/master"), true) .update();
private final PerformCreateProject.Factory createProjectFactory; private final Provider<ProjectsCollection> projectsCollection; private final Provider<GroupsCollection> groupsCollection; private final ProjectJson json; private final String name; @Inject CreateProject(PerformCreateProject.Factory performCreateProjectFactory, Provider<ProjectsCollection> projectsCollection, Provider<GroupsCollection> groupsCollection, ProjectJson json, @Assisted String name) { this.createProjectFactory = performCreateProjectFactory; this.projectsCollection = projectsCollection; this.groupsCollection = groupsCollection; this.json = json; this.name = name; } @Override public Object apply(TopLevelResource resource, Input input) throws BadRequestException, UnprocessableEntityException, ProjectCreationFailedException { if (input == null) { input = new Input(); } if (input.name != null && !name.equals(input.name)) { throw new BadRequestException("name must match URL"); } final CreateProjectArgs args = new CreateProjectArgs(); args.setProjectName(name); if (!Strings.isNullOrEmpty(input.parent)) { args.newParent = projectsCollection.get().parse(input.parent).getProject(); } args.createEmptyCommit = input.createEmptyCommit; args.permissionsOnly = input.permissionsOnly; args.projectDescription = input.projectDescription; args.projectState = input.projectState; args.pluginConfigValues = input.pluginConfigValues; args.submitType = input.submitType; args.branch = input.branch; args.branches = input.branches; args.contributorAgreements = input.contributorAgreements; args.signedOffBy = input.signedOffBy; args.contentMerge = input.contentMerge; args.changeIdRequired = input.changeIdRequired; args.maxObjectSizeLimit = input.maxObjectSizeLimit; args.submitType = input.submitType; args.useContributorAgreements = input.useContributorAgreements; args.useContentMerge = input.useContentMerge; args.useSignedOffBy = input.useSignedOffBy; args.useContentMerge = input.useContentMerge; args.useSignedOffBy = input.useSignedOffBy; args.useContributorAgreements = input.useContributorAgreements; args.useSignedOffBy = input.useSignedOffBy; args.useContentMerge = input.useContentMerge; args.useContributorAgreements = input.useContributorAgreements;
package com.google.gerrit.index.query; import static com.google.common.base.Preconditions.checkNotNull; import com.google.common.collect.ImmutableList; import java.util.Iterator; import java.util.function.Supplier; /** * Result set that allows for asynchronous execution of the actual query. Callers should dispatch * the query and call the constructor of this class with a supplier that fetches the result and * blocks on it if necessary. * <p> * If the execution is synchronous or the results are known a-priori, consider using {@link * ListResultSet}. */ public class LazyResultSet<T> implements ResultSet<T> { private final Supplier<ImmutableList<T>> resultsCallback; private boolean resultsReturned = false; public LazyResultSet(Supplier<ImmutableList<T>> r) { resultsCallback = checkNotNull(r, "results can't be null"); } @Override public Iterator<T> iterator() { return toList().iterator(); } @Override public ImmutableList<T> toList() { if (resultsReturned) { throw new IllegalStateException("Results already obtained"); } resultsReturned = true; return resultsCallback.get(); } }
public LazyResultSet(Supplier<ImmutableList<T>> r) { resultsCallback = requireNonNull(r, "results can't be null"); }
public ListResultSet(List<T> r) { results = ImmutableList.copyOf(Objects.requireNonNull(r, "results can't be null")); }
@Test public void testCapabilityAllowsZeroRangeOnCapabilityThatHasRange() throws Exception { TestCapability c = allowCapability(QUERY_LIMIT) .group(REGISTERED_USERS) .range(0, 0) .build(); assertThat(c.min()).isEqualTo(0); assertThat(c.max()).isEqualTo(0); } @Test public void testCapabilityDisallowsInvertedRange() throws Exception { assertThrows(RuntimeException.class, () -> allowCapability(ADMINISTRATE_SERVER) .group(REGISTERED_USERS) .range(1, 0) .build()); } @Test public void testCapabilityDisallowsRangeIfCapabilityDoesNotSupportRange() throws Exception { assertThrows(RuntimeException.class, () -> allowCapability(ADMINISTRATE_SERVER) .group(REGISTERED_USERS) .range(-1, 1) .build()); } @Test public void testCapabilityRangeIsZeroIfCapabilityDoesNotSupportRange() throws Exception { TestCapability c = allowCapability(ADMINISTRATE_SERVER) .group(REGISTERED_USERS) .build(); assertThat(c.min()).isEqualTo(0); assertThat(c.max()).isEqualTo(0); } @Test public void testCapabilityUsesDefaultRangeIfUnspecified() throws Exception { // Test code here }
// limitations under the License. package com.ericsson.gerrit.plugins.highavailability.forwarder.rest; import com.ericsson.gerrit.plugins.highavailability.cache.Constants; import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gerrit.server.events.Event; import com.google.gerrit.server.events.EventDeserializer; import com.google.gerrit.server.events.SupplierDeserializer; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.inject.Singleton; @Singleton final class GsonParser { private final Gson gson = new GsonBuilder() .registerTypeAdapter(Event.class, new EventDeserializer()) .registerTypeAdapter(Supplier.class, new SupplierDeserializer()) .create(); public Gson gson() { return gson; } Object fromJson(String cacheName, String json) { Object key; // Need to add a case for 'adv_bases' switch (cacheName) { case Constants.ACCOUNTS: key = gson.fromJson(Strings.nullToEmpty(json).trim(), Account.Id.class); break; case Constants.GROUPS: key = gson.fromJson(Strings.nullToEmpty(json).trim(), AccountGroup.UUID.class); break; default: throw new IllegalArgumentException("Unknown cache name: " + cacheName); } return key; } }
public class BranchCommitValidator { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CommitValidators.Factory commitValidatorsFactory; private final IdentifiedUser user; private final PermissionBackend.ForProject permissions; private final Project project; private final BranchNameKey branch; private final SshInfo sshInfo; interface Factory { BranchCommitValidator create(ProjectState projectState, BranchNameKey branch, IdentifiedUser user); } public static class Result { static Result create(boolean isValid, List<CommitValidationMessage> messages) { return new Result(isValid, messages); } private final boolean isValid; private final List<CommitValidationMessage> messages; private Result(boolean isValid, List<CommitValidationMessage> messages) { this.isValid = isValid; this.messages = messages; } public boolean isValid() { return isValid; } public List<CommitValidationMessage> messages() { return messages; } } @Inject public BranchCommitValidator(CommitValidators.Factory commitValidatorsFactory, PermissionBackend permissionBackend, SshInfo sshInfo) { this.commitValidatorsFactory = commitValidatorsFactory; this.user = user; this.permissions = permissions; this.project = project; this.branch = branch; this.sshInfo = sshInfo; } }
static Result create(boolean isValid, List<CommitValidationMessage> messages) { return new AutoValue_BranchCommitValidator_Result(isValid, ImmutableList.copyOf(messages)); }
@AutoValue public static abstract class Result { static Result create(boolean isValid, List<CommitValidationMessage> messages) { return new AutoValue_BranchCommitValidator_Result(isValid, messages); } /** Whether the commit is valid. */ abstract boolean isValid(); /** A list of messages related to the validation. Messages may be present regardless of the {@link #isValid()} status. */ abstract List<CommitValidationMessage> messages(); } @Inject BranchCommitValidator( CommitValidators.Factory commitValidatorsFactory, PermissionBackend permissionBackend, SshInfo sshInfo, @Assisted ProjectState projectState, @Assisted BranchNameKey branch, @Assisted IdentifiedUser user) { this.sshInfo = sshInfo; this.user = user; this.branch = branch; this.commitValidatorsFactory = commitValidatorsFactory; project = projectState.getProject(); permissions = permissionBackend.user(user).project(project.getNameKey()); } /** * Validates a single commit. If the commit does not validate, the command is rejected. */
if (args.getSchema().hasField(ChangeField.EXTENSION)) { FileExtensionPredicate extensionPredicate = new FileExtensionPredicate(ext); if (ext.isEmpty()) { RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^.{0}$"); return emptyExtPredicate; } return extensionPredicate; } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException("'onlyextensions' operator is not supported by change index version"); } @Operator
ChecksCollection(Checks checks, DynamicMap<RestView<CheckResource>> views, ListChecks listChecks) { this.checks = checks; this.views = views; this.listChecks = listChecks; } @Override public RestReadView<RevisionResource> list() throws RestApiException { return listChecks; } @Override public CheckResource parse(RevisionResource parent, IdString id) throws RestApiException, PermissionBackendException, IOException, StorageException { if (parent.getEdit().isPresent()) { throw new ResourceConflictException("checks are not supported on edit"); } CheckerUuid checkerUuid = CheckerUuid.tryParse(id.get()) .orElseThrow(() -> new BadRequestException(String.format("invalid checker UUID: %s", id.get()))); CheckKey checkKey = CheckKey.create(parent.getProject(), parent.getPatchSet().id(), checkerUuid); Optional<Check> check = checks.getCheck(checkKey, GetCheckOptions.withBackfilling()); return new CheckResource(parent, check.orElseThrow(() -> new ResourceNotFoundException( String.format("check not found for checker UUID: %s", id.get())))); }
@Inject Schema_146(Provider<Schema_145> prior, GitRepositoryManager repoManager, AllUsersName allUsersName, @GerritPersonIdent PersonIdent serverIdent) { super(prior); this.repoManager = repoManager; this.allUsersName = allUsersName; this.serverIdent = serverIdent; } @Override protected void migrateData(ReviewDb db, UpdateUI ui) throws OrmException, SQLException { ui.message("Migrating accounts"); gc(ui); Set<Entry<Account.Id, Timestamp>> accounts = scanAccounts(db, ui).entrySet(); Set<List<Entry<Account.Id, Timestamp>>> batches = Sets.newHashSet(Iterables.partition(accounts, 500)); ExecutorService pool = createExecutor(ui); try { batches.stream().forEach(batch -> pool.submit(() -> processBatch(batch, ui))); pool.shutdown(); pool.awaitTermination(Long.MAX_VALUE, TimeUnit.DAYS); } catch (InterruptedException e) { throw new RuntimeException(e); } ui.message(String.format("... (%.3f s) Migrated all %d accounts to schema 146", elapsed(), i.get())); }
import com.google.common.cache.CacheBuilder; import com.google.common.cache.Cache; import java.util.concurrent.TimeUnit; public class VisibilityCache { private final Cache<Object, Object> cache; public VisibilityCache(boolean topoSort) { this(topoSort, defaultBuilder()); } public VisibilityCache(boolean topoSort, CacheBuilder<Object, Object> builder) { this(new VisibilityChecker(topoSort), builder); } public VisibilityCache(VisibilityChecker checker) { this(checker, defaultBuilder()); } public VisibilityCache(VisibilityChecker checker, CacheBuilder<Object, Object> builder) { this.cache = builder.build(); } public static CacheBuilder<Object, Object> defaultBuilder() { return CacheBuilder.newBuilder().maximumSize(1 << 10).expireAfterWrite(30, TimeUnit.MINUTES); } }
import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevSort; import org.eclipse.jgit.revwalk.RevWalk; /** * Checks for object visibility * * <p>Objects are visible if they are reachable from any of the references visible to the user. */ public class VisibilityChecker { private boolean topoSort; /** * Constructs a VisibilityChecker. * * @param topoSort whether to use a more thorough reachability check by sorting in topological order */ public VisibilityChecker(boolean topoSort) { this.topoSort = topoSort; } /** * Check if any of the refs in {@code refDb} points to the object {@code id}. * * @param refDb a reference database * @param id object we are looking for * @return true if any of the references in the db points directly to the id * @throws IOException if the reference space cannot be accessed */ public boolean checkVisibility(RefDatabase refDb, ObjectId id) throws IOException { RevWalk revWalk = new RevWalk(refDb.getRepository()); revWalk.setRevFilter(RevSort.TOPO); revWalk.markStart(revWalk.parseCommit(id)); for (Ref ref : refDb.getRefs()) { RevCommit commit = revWalk.parseCommit(ref.getObjectId()); if (revWalk.isMergedInto(commit, revWalk.parseCommit(id))) { return true; } } return false; } }
import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.JUnit4; @RunWith(JUnit4.class) public class VisibilityCacheTest { private InMemoryRepository repo; private GitilesAccess access = new FakeGitilesAccess(); private RevCommit baseCommit; private RevCommit commit1; private RevCommit commit2; private RevCommit commitA; private RevCommit commitB; private RevCommit commitC; private VisibilityCache visibilityCache; private RevWalk walk; @Before public void setUp() throws Exception { repo = new InMemoryRepository(new DfsRepositoryDescription()); TestRepository<InMemoryRepository> git = new TestRepository<>(repo); baseCommit = git.commit().message("baseCommit").create(); commit1 = git.commit().parent(baseCommit).message("commit1").create(); commit2 = git.commit().parent(commit1).message("commit2").create(); commitA = git.commit().parent(baseCommit).message("commitA").create(); commitB = git.commit().parent(commitA).message("commitB").create(); commitC = git.commit().parent(commitB).message("commitC").create(); } }
private final byte reserved3; private final int itemflags; private int itemexpiry; private final int vbucketstate; private final byte[] key; private final byte[] value; private final byte[] revid; /** * Creates a ResponseMessage from binary data. * @param buffer The binary data sent from the tap stream server. */ public ResponseMessage(byte[] b) { super(b); if (!opcode.equals(TapOpcode.NOOP)) { engineprivate = decodeShort(b, ENGINE_PRIVATE_OFFSET); flags = TapFlag.getFlags(decodeShort(b, FLAGS_OFFSET)); ttl = b[TTL_OFFSET]; reserved1 = b[RESERVED1_OFFSET]; reserved2 = b[RESERVED2_OFFSET]; reserved3 = b[RESERVED3_OFFSET]; } else { engineprivate = 0; flags = new LinkedList<TapFlag>(); ttl = 0; reserved1 = 0; reserved2 = 0; reserved3 = 0; } } for (String line : lines) { int c = line.indexOf(": "); if (c < 0) { rec = new SubmitRecord(); submitRecords.add(rec); int s = line.indexOf(' '); String statusStr = s >= 0 ? line.substring(0, s) : line; Optional<SubmitRecord.Status> status = Enums.getIfPresent(SubmitRecord.Status.class, statusStr); checkFooter(status.isPresent(), FOOTER_SUBMITTED_WITH, line); rec.status = status.get(); if (s >= 0) { rec.errorMessage = line.substring(s); } } else { checkFooter(rec != null, FOOTER_SUBMITTED_WITH, line); SubmitRecord.Label label = new SubmitRecord.Label(); if (rec.labels == null) { rec.labels = Lists.newArrayList(); } rec.labels.add(label); Optional<SubmitRecord.Label.Status> status = Enums.getIfPresent( SubmitRecord.Label.Status.class, line.substring(0, c)); checkFooter(status.isPresent(), FOOTER_SUBMITTED_WITH, line); } } public boolean provides(IOperation operation) { CreateEditPoliciesOperation epOperation = (CreateEditPoliciesOperation) operation; if (!(epOperation.getEditPart() instanceof IGraphicalEditPart)) { return false; } IGraphicalEditPart gep = (IGraphicalEdit
static void call(final Button b, final String project) { b.setEnabled(false); ChangeApi.createChange(project, "refs/meta/config", Util.C.editConfigMessage(), null, new GerritCallback<ChangeInfo>() { @Override public void onSuccess(ChangeInfo result) { Gerrit.display(Dispatcher.toEditScreen(new PatchSet.Id(result.legacy_id(), 1), "project.config")); } @Override public void onFailure(Throwable caught) { b.setEnabled(true); super.onFailure(caught); } }); } private Injector createSysInjector() { final List<Module> modules = new ArrayList<>(); modules.add(SchemaVersionCheck.module()); modules.add(new DropWizardMetricMaker.RestModule()); modules.add(new LogFileCompressor.Module()); if (onlineReindexMode) { modules.add(new PluginModule()); } } public NameAlreadyUsedException(String name) { super(MESSAGE + ": " + name); } package com.ericsson.gerrit.plugins.highavailability.forwarder.rest; import com.ericsson.gerrit.plugins.highavailability.cache.Constants; import com.google.common.base.Strings; import com.google.gerrit.reviewdb.client.Account; import com.google.gson.Gson; import com.google.gson.JsonElement; import com.google.gson.JsonObject; import com.google.inject.Inject; import com.google.inject.Singleton; @Singleton class GsonParser { private final Gson gson; @Inject GsonParser(GsonProvider gson) { this.gson = gson.get(); } public Object fromJson(String cacheName, String jsonString) { JsonElement json = gson.fromJson(Strings.nullToEmpty(jsonString), JsonElement.class); Object key; if (!json.isJsonObject()) { return json.getAsString(); } JsonObject asJsonObject = json.getAsJsonObject(); switch (cacheName) { case Constants.ACCOUNTS: key = asJsonObject.has("id") ? Account.id(asJsonObject.get("id").getAsInt()) : null; break; // other cases... } // other code... } }
import java.io.File; import java.util.ArrayList; import java.util.Arrays; import java.util.List; public class CheckConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String toolName = "check_new_config"; private static final String ACCESS = "access"; private static final String LABEL = "label"; private static final String PLUGIN = "plugin"; private static final int BUFFER_SIZE = 2048; private String pluginName; private Config configProject; private ScannerConfig scannerConfig; public CheckConfig(String pluginName, String projectConfigContents) throws ConfigInvalidException { this.pluginName = pluginName; configProject = new Config(); configProject.fromText(projectConfigContents); Config config = new Config(); for (String name : configProject.getNames(PLUGIN, pluginName)) { config.setStringList(PLUGIN, pluginName, name, Arrays.asList(configProject.getStringList(PLUGIN, pluginName, name))); } PluginConfig pluginConfig = new PluginConfig(pluginName, config); } public void checkFile(File file) { char[] buffer = new char[BUFFER_SIZE]; // perform file checking using the buffer } }
public class CheckConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String toolName = "check_new_config"; private static final String ACCESS = "access"; private static final String LABEL = "label"; private static final String PLUGIN = "plugin"; private static final int BUFFER_SIZE = 2048; private static final char[] BUFFER = new char[BUFFER_SIZE]; private String pluginName; private Config configProject; ScannerConfig scannerConfig; public CheckConfig(String pluginName, String projectConfigContents) throws ConfigInvalidException { this.pluginName = pluginName; configProject = new Config(); configProject.fromText(projectConfigContents); Config config = new Config(); for (String name : configProject.getNames(PLUGIN, pluginName)) { config.setStringList(PLUGIN, pluginName, name, Arrays.asList(configProject.getStringList(PLUGIN, pluginName, name))); } PluginConfig pluginConfig = new PluginConfig(pluginName, config); } }
public class MDNSFilterPlugin { private String mName; private CharSequence mPackageName; private List<String> mMDNSNames; private MDNSFilteredDiscovery mMDNSFilteredDiscovery; public MDNSFilterPlugin(@NonNull Context context, @NonNull String name, @NonNull CharSequence packageName, @NonNull List<String> mDNSNames) { mName = context.getResources().getIdentifier(name, null, "com.android.printservice.recommendation"); mPackageName = packageName; mMDNSNames = mDNSNames; mMDNSFilteredDiscovery = new MDNSFilteredDiscovery(context, PRINTER_SERVICE_TYPES, new VendorNameFilter(new HashSet<>(mMDNSNames))); } } public class SomeClass { private Set<LogicalVariable> findFDHeaderVariables(IOptimizationContext context, ILogicalOperator operator) throws AlgebricksException { PhysicalOptimizationsUtil.computeFDsAndEquivalenceClasses((AbstractLogicalOperator) operator, context); List<FunctionalDependency> fds = context.getFDList(operator); context.clearAllFDAndEquivalenceClasses(); Set<LogicalVariable> liveVars = new HashSet<>(); VariableUtilities.getSubplanLocalLiveVariables(operator, liveVars); Set<LogicalVariable> key = new HashSet<>(); Set<LogicalVariable> cover = new HashSet<>(); for (FunctionalDependency fd : fds) { // process functional dependencies } // return the set of covering variables return cover; } } public class SomeOtherClass { private List<Finding> scanCommitMessage(String commitMessage) { List<Finding> findings = new ArrayList<>(); // scan the commit message for copied texts // add findings to the list return findings; } }
import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectLoader; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevTree; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.treewalk.TreeWalk; @Singleton class CopyrightConfig implements CommitValidationListener, RevisionCreatedListener, GitReferenceUpdatedListener { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final long DEFAULT_MAX_ELAPSED_SECONDS = 8; private final Metrics metrics; private final AllProjectsName allProjectsName; private final String pluginName; private final GitRepositoryManager repoManager; private final ProjectCache projectCache; private final PluginConfigFactory pluginConfigFactory; private final CopyrightReviewApi reviewApi; private PluginConfig gerritConfig; private CheckConfig checkConfig; static AbstractModule module() { return new AbstractModule() { @Override protected void configure() { DynamicSet.bind(binder(), CommitValidationListener.class).to(CopyrightConfig.class); } }; } }
if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { clearConfig(); checkConfig = readConfig(event.getNewObjectId()); } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); checkConfig = null; return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); }
private void logError(String message) { logger.atSevere().log(message); } ... String errorMessage = String.format("%s plugin revision %s: error posting review: %s", pluginName, event.getChange().currentRevision, result.error); logError(errorMessage); for (Map.Entry<String, AddReviewerResult> entry : result.reviewers.entrySet()) { AddReviewerResult arr = entry.getValue(); if (!Strings.isNullOrEmpty(arr.error)) { String error = String.format("%s plugin revision %s: error adding reviewer %s: %s", pluginName, event.getChange().currentRevision, entry.getKey(), arr.error); logError(error); } }
private ReviewResult review(ChangeResource change, ReviewInput ri) throws RestApiException { try { PatchSet ps = psUtil.current(change.getNotes()); if (ps == null) { throw new ResourceNotFoundException(IdString.fromDecoded("current")); } RevisionResource revision = RevisionResource.createNonCacheable(change, ps); return revisionApi.review(revision.getPatchSet().getId().get(), ri); } catch (Exception e) { Throwables.throwIfUnchecked(e); throw e instanceof RestApiException ? (RestApiException) e : new RestApiException("Cannot post review", e); } }
private void scanRevision(String project, String branch, RevisionCreatedListener.Event event) throws IOException, RestApiException { Map<String, ImmutableList<Match>> findings = new HashMap<>(); ArrayList<String> containedPaths = new ArrayList<>(); long scanStart = System.nanoTime(); metrics.scanCount.increment(); metrics.scanCountByProject.increment(project); metrics.scanCountByBranch.increment(branch); try (Repository repo = repoManager.openRepository(Project.nameKey(project)); RevWalk revWalk = new RevWalk(repo); TreeWalk tw = new TreeWalk(revWalk.getObjectReader())) { RevCommit commit = repo.parseCommit(ObjectId.fromString(event.getRevision().commit.commit)); tw.setRecursive(true); tw.setFilter(TreeFilter.ANY_DIFF); tw.addTree(commit.getTree()); if (commit.getParentCount() > 0) { // rest of the code } } }
import com.google.gerrit.server.git.validators.ValidationMessage; import com.google.gerrit.server.project.ProjectConfig; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightPatterns; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightPatterns.UnknownPatternName; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightScanner; import java.util.ArrayList; import java.util.Collection; import java.util.LinkedHashSet; import java.util.Objects; import java.util.function.Consumer; import java.util.regex.Pattern; import java.util.regex.PatternSyntaxException; class ScannerConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String KEY_ENABLE = "enable"; static final String KEY_TIME_TEST_MAX = "timeTestMax"; static final String DEFAULT_REVIEW_LABEL = "Copyright-Review"; static final String KEY_REVIEWER = "reviewer"; static final String KEY_CC = "cc"; static final String KEY_FROM = "fromAccountId"; static final String KEY_REVIEW_LABEL = "reviewLabel"; static final String KEY_EXCLUDE = "exclude"; }
} public boolean isV6() { return isVersion(6); } public boolean isV6OrLater() { return isAtLeastVersion(6); } public boolean isV7OrLater() { return isAtLeastVersion(7); } private boolean isAtLeastVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) >= v; } private boolean isVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) == v; } @Override public String toString() { return version; } }
boolean oldForceLogging = loggingCtx.isLoggingForced(); boolean oldPerformanceLogging = loggingCtx.isPerformanceLogging(); ImmutableList<PerformanceLogRecord> oldPerformanceLogRecords = loggingCtx.getPerformanceLogEntries(); loggingCtx.setTags(tags); loggingCtx.forceLogging(forceLogging); loggingCtx.performanceLogging(performanceLogging); loggingCtx.setPerformanceLogEntries(performanceLogRecords); try { runnable.run(); } finally { loggingCtx.setTags(oldTags); loggingCtx.forceLogging(oldForceLogging); loggingCtx.performanceLogging(oldPerformanceLogging); loggingCtx.setPerformanceLogEntries(oldPerformanceLogRecords); }
public void close() { if (LoggingContext.getInstance().isPerformanceLogging()) { runEach(performanceLoggers, LoggingContext.getInstance().getPerformanceLogEntries()); } LoggingContext.getInstance().performanceLogging(oldPerformanceLogging); LoggingContext.getInstance().setPerformanceLogEntries(oldPerformanceLogRecords); }
private byte[] stringToByte(String mediaId) { if (!mHmap.containsValue(mediaId)) { int uid = mHmap.size() + 1; mHmap.put(uid, mediaId); return intToByteArray(uid); } else { for (int key : mHmap.keySet()) { if (mHmap.get(key).equals(mediaId)) { return intToByteArray(key); } } } return null; } return OpenSSLX509Certificate.fromX509PemInputStream(is); } public void test_deletingCTPoisonExtension() throws Exception { OpenSSLX509Certificate cert = loadTestCertificate("cert.pem"); OpenSSLX509Certificate certPoisoned = loadTestCertificate("cert-ct-poisoned.pem"); assertEqualByteArrays( certPoisoned.withDeletedExtension(CT_POISON_EXTENSION).getTBSCertificate(), cert.getTBSCertificate() ); } public void test_deleteExtensionMakesCopy() throws Exception { OpenSSLX509Certificate certPoisoned = loadTestCertificate("cert-ct-poisoned.pem"); assertTrue(certPoisoned.getCriticalExtensionOIDs().contains(CT_POISON_EXTENSION)); OpenSSLX509Certificate certWithoutExtension = certPoisoned.withDeletedExtension(CT_POISON_EXTENSION); assertFalse(certWithoutExtension.getCriticalExtensionOIDs().contains(CT_POISON_EXTENSION)); } .forUpdate() .add(allow(Permission.READ).ref("refs/*").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref(RefNames.REFS_CONFIG).group(REGISTERED_USERS)) .update(); assertUploadPackRefs( "HEAD", psRef1, metaRef1, psRef2, metaRef2, psRef3, metaRef3, psRef4, metaRef4, "refs/heads/branch", "refs/heads/master", RefNames.REFS_CONFIG, "refs/tags/branch-tag", "refs/tags/master-tag" ); @Test public void uploadPackSubsetOfBranchesVisibleIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(allow(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(deny(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update();
@Test public void uploadPackSubsetOfBranchesVisibleIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(allow(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(deny(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( "HEAD", psRef1, metaRef1, psRef3, metaRef3, "refs/heads/master", "refs/tags/master-tag"); } @Test public void uploadPackSubsetOfBranchesVisibleNotIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(deny(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs(psRef2, metaRef2); }
// Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.readonly; import static com.google.common.truth.Truth.assertThat; import com.google.gerrit.acceptance.RestResponse; import com.google.gerrit.server.config.GerritServerConfig; import com.google.gerrit.testutil.ConfigSuite; import com.google.inject.Inject; import org.eclipse.jgit.lib.Config; public class ReadOnlyByHttpIT extends AbstractReadOnlyTest { @ConfigSuite.Default public static Config withPluginNamePrefix() { Config cfg = new Config(); cfg.setString("readonly", "test", "endpoint", "readonly~readonly"); return cfg; } @ConfigSuite.Config public static Config withoutPluginNamePrefix() { Config cfg = new Config(); cfg.setString("readonly", "test", "endpoint", "readonly"); return cfg; } }
} else if (input.httpPassword == null) { newPassword = null; } else { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); newPassword = input.httpPassword; } return apply(rsrc.getUser(), newPassword); public Response<String> apply(IdentifiedUser user, String newPassword) throws ResourceNotFoundException, ResourceConflictException, OrmException, IOException, ConfigInvalidException { String userName = user.getUserName().orElseThrow(() -> new ResourceConflictException("username must be set")); Optional<ExternalId> optionalExtId = externalIds.get(ExternalId.Key.create(SCHEME_USERNAME, userName)); ExternalId extId = optionalExtId.orElseThrow(ResourceNotFoundException::new); accountsUpdateProvider .get() .update("Set HTTP Password via API", extId.accountId(), u -> u.updateExternalId(ExternalId.createWithPassword( extId.key(), extId.accountId(), extId.email(), newPassword))); return Response.ok("Password updated"); }
// included: pA:d2/OWNERS, pA:d2/../f1, pA:d1/f1 // inherited: pA:OWNERS String owners = "owners:[ " + concat(ownerJson("pAd1f1@g"), ", ") + concat(ownerJson("pAd2@g"), ", ") + concat(ownerJson("pAf1@g"), ", ") + concat(ownerJson("pA@g", 0, 1, 0), " ]"); assertThat(getOwnersResponse(c1)).contains(owners);
private void handleGitReferenceUpdatedAsUser(Event event, Account.Id updaterAccountId) { try (ManualRequestContext ctx = oneOffReqCtx.openAs(updaterAccountId)) { handleGitReferenceUpdated(event); } catch (OrmException e) { logger.warn("Unable to process event {} on project {}", event, event.getProjectName(), e); } }
public void onGitReferenceUpdated(Event event) { AccountInfo updaterAccountInfo = event.getUpdater(); CurrentUser currentUser = currentUserProvider.get(); if (currentUser.isIdentifiedUser()) { handleGitReferenceUpdated(event); } else if (updaterAccountInfo != null) { handleGitReferenceUpdatedAsUser(event, new Account.Id(updaterAccountInfo._accountId)); } else { // Handle null case here } }
// For the performance log records, use a thread-safe list instance from the logging context of the calling // thread in the logging context of the new thread. This way, performance log records that are // created from the new thread are available from the logging context of the calling thread. // This is important since performance log records are processed only at the end of the request // and performance log records that are created in another thread should not get lost. loggingCtx.setMutablePerformanceLogRecordList(Collections.synchronizedList(mutablePerformanceLogRecords)); try { return callable.call(); } finally { loggingCtx.setTags(oldTags); loggingCtx.forceLogging(oldForceLogging); loggingCtx.performanceLogging(oldPerformanceLogging); loggingCtx.setPerformanceLogRecords(oldPerformanceLogRecords); }
Fixed Code: ```java @Inject CopyrightConfig( Metrics metrics, AllProjectsName allProjectsName, @PluginName String pluginName, GitRepositoryManager repoManager, ProjectCache projectCache, PluginConfigFactory pluginConfigFactory, CopyrightReviewApi reviewApi ) throws IOException, ConfigInvalidException { this.metrics = metrics; this.allProjectsName = allProjectsName; this.pluginName = pluginName; this.repoManager = repoManager; this.projectCache = projectCache; this.pluginConfigFactory = pluginConfigFactory; this.reviewApi = reviewApi; long nanoStart = System.nanoTime(); try { checkConfig = readConfig(projectCache.getAllProjects().getProject().getConfigRefState()); } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); } } ``` Review: Doing work in a constructor is strongly discouraged. Doing work which throws exceptions such as these and additionally having Guice for DI might cause serious issues (e.g. server can't even start if one of the exceptions is thrown). Please find a different way or tell me if you need further ideas.
throws ConfigInvalidException { metrics = new Metrics(metricMaker); allProjectsName = new AllProjectsName("All-Projects"); pluginName = "copyright"; repoManager = null; projectCache = null; pluginConfigFactory = null; this.reviewApi = reviewApi; checkConfig = new CheckConfig(pluginName, projectConfigContents); } @VisibleForTesting static CopyrightConfig createTestInstance( MetricMaker metricMaker, CopyrightReviewApi reviewApi, String projectConfigContents) throws ConfigInvalidException { return new CopyrightConfig(metricMaker, reviewApi, projectConfigContents); } ScannerConfig getScannerConfig() { return checkConfig.scannerConfig; } @Override public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { // ... } catch (IOException | ConfigInvalidException e) { // ... } }
public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { logger.log(Level.SEVERE, "\n\nonGitRefUpdated\n\n"); checkConfig = readConfig(event.getNewObjectId()); logger.log(Level.SEVERE, "\n\nonGitRefUpdated: '{0}'\n\n", checkConfig); } catch (IOException | ConfigInvalidException e) { logger.log(Level.SEVERE, "{0} plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); } }
public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { logger.atSevere().log("onGitRefUpdated"); checkConfig = readConfig(event.getNewObjectId()); logger.atSevere().log("onGitRefUpdated: '%s'", checkConfig); } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); } }
throw new CmlpDataSrcException("Please provide a predictor", 400); if (!(codeCloudAuthorization != null) && !(codeCloudAuthorization.isEmpty())) { throw new CmlpDataSrcException("Please provide CodeCloudAuthorization header", 400); } if (!(objCatalog.getPublisherUrl() != null) && objCatalog.getPublisherUrl().isEmpty()) { throw new CmlpDataSrcException("Please provide a publisher URL", 400); } try { log.info("RestCatalogServiceImpl::updateCatalog()::intiating update request."); String responseCatalogKey = aCatalogService.updateCatalog(user, authorization, codeCloudAuthorization, catalogKey, objCatalog); log.info("RestCatalogServiceImpl::updateCatalog()::update completed for key: " + responseCatalogKey); URI location = new URI(url + objCatalog.getCatalogKey()); } catch (Exception e) { log.error("Exception in RestCatalogServiceImpl:updateCatalog" + e.getMessage()); aResponseMessage.setCode(500); aResponseMessage.setMessage(e.getMessage()); return Response.status(Status.BAD_REQUEST).entity(aResponseMessage).build(); } import org.eclipse.mylyn.wikitext.parser.builder.HtmlDocumentBuilder; import org.junit.Before; /** * Test base for asciidoc language tests. provides base set-up functionalities, like parsing markup to html * * @author Max Rydahl Andersen */ public abstract class AsciiDocLanguageTestBase { private MarkupParser parser; @Before public void setUp() throws Exception { parser = new MarkupParser(new AsciiDocLanguage()); } public String parseToHtml(String markup) { return parseAsciiDocToHtml(markup, parser); } protected static String parseAsciiDocToHtml(String markup, MarkupParser parser) { StringWriter out = new StringWriter(); HtmlDocumentBuilder builder = new HtmlDocumentBuilder(out); builder.setEmitAsDocument(false); parser.setBuilder(builder); parser.parse(markup); return out.toString(); } } public void set(int index, byte value) { if (index >= len) { throw new IndexOutOfBoundsException(String.format("index: %s, len: %s", index, len)); } data[index] = value; } public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return;
private static class DbsMetadata { public List<String> dbs = Lists.newArrayList(); public List<List<String>> tableNames = Lists.newArrayList(); public List<List<String>> comments = Lists.newArrayList(); public List<List<List<Column>>> columns = Lists.newArrayList(); public List<List<Function>> functions = Lists.newArrayList(); } public void shutdown() { shuttingDown = true; if (process != null) { process.destroy(); log.info("Process stopped"); } } public String cstString() { throw new UnsupportedOperationException("Not supported."); } public String cstComment() { throw new UnsupportedOperationException("Not supported."); } CommentInfo draftInfo = Iterables.getOnlyElement(drafts.get(draft.path)); ReviewInput reviewInput = new ReviewInput(); reviewInput.drafts = DraftHandling.KEEP; reviewInput.message = "foo"; CommentInput comment = newComment(file, Side.REVISION, 0, "comment", false); comment.id = draftInfo.id; reviewInput.comments = new HashMap<>(); reviewInput.comments.put(comment.path, ImmutableList.of(comment)); revision(r).review(reviewInput); drafts = getDraftComments(changeId, revId); assertThat(drafts).isEmpty(); @Test public void listComments() throws Exception { String file = "file"; PushOneCommit push = pushFactory.create(admin.newIdent(), testRepo, "first subject", file, "contents"); PushOneCommit.Result r = push.to("refs/for/master"); String changeId = r.getChangeId(); String revId = r.getCommit().getName(); assertThat(getPublishedComments(changeId, revId)).isEmpty(); }
(metadata, value) -> elementAssertThatFunction.apply(value); return assertThat(optional, valueSubjectFactory); } public static <S extends Subject, T> OptionalSubject<S, T> assertThat(Optional<T> optional, Subject.Factory<S, T> valueSubjectFactory) { return assertAbout(optionals()).thatCustom(optional, valueSubjectFactory); } public static OptionalSubject<Subject, ?> assertThat(Optional<?> optional) { return assertAbout(optionals()) .that(optional, StandardSubjectBuilder::that); } public static CustomSubjectBuilder.Factory<OptionalSubjectBuilder> optionals() { return OptionalSubjectBuilder::new; } private OptionalSubject(FailureMetadata failureMetadata, Optional<T> optional, BiFunction<StandardSubjectBuilder, ? super T, ? extends S> valueSubjectCreator) { super(failureMetadata, optional); this.optional = optional; this.valueSubjectCreator = valueSubjectCreator; } public void isPresent() { isNotNull(); if (!optional.isPresent()) { failWithoutActual(fact("expected to have", "value")); } } public void isAbsent() { isNotNull(); if (optional.isPresent()) { failWithoutActual(fact("expected to be", "absent")); } }
private boolean isAddAccessEnabled() { boolean returnValue; try { if (!SystemGroup.OseeAccessAdmin.isCurrentUserMember() && policyTableViewer.getAccessControlList().size() > 0) { returnValue = AccessControlManager.hasPermission(accessControlledObject, PermissionEnum.FULLACCESS); } else { returnValue = true; } } catch (OseeCoreException ex) { OseeLog.log(Activator.class, Level.SEVERE, ex); returnValue = false; } return returnValue; } gApi.accounts().id(admin.getId().toString()).setPreferences(i); @Test public void userReceivesHtmlAndPlaintextEmail() throws Exception { PushOneCommit.Result r = createChange(); setApiUser(user); gApi.changes() .id(r.getChangeId()) .revision(r.getCommit().name()) .review(ReviewInput.recommend()); assertThat(sender.getMessages()).hasSize(1); FakeEmailSender.Message m = sender.getMessages().get(0); assertThat(m.body()).isNotNull(); assertThat(m.htmlBody()).isNotNull(); assertMailReplyTo(m, admin.email); assertMailReplyTo(m, user.email); } public GeneralPreferencesInfo setDefaultPreferences(GeneralPreferencesInfo in) { throw new NotImplementedException(); } @Override public DiffPreferencesInfo getDefaultDiffPreferences() { throw new NotImplementedException(); } @Override public DiffPreferencesInfo setDefaultDiffPreferences(DiffPreferencesInfo in) { throw new NotImplementedException(); } @Override public ConsistencyCheckInfo checkConsistency(ConsistencyCheckInput in) { throw new NotImplementedException(); } @Override public AccessCheckInfo checkAccess(AccessCheckInput in) throws RestApiException { throw new NotImplementedException(); } public static class OptionalSubjectBuilder extends CustomSubjectBuilder { OptionalSubjectBuilder(FailureMetadata failureMetadata) { super(failureMetadata); } public <S extends Subject, T> OptionalSubject<S, T> thatCustom( Optional<T> optional, Subject.Factory<S, T> valueSubjectFactory) { return that(optional, (builder, value) -> builder.about(valueSubjectFactory).that(value)); } public OptionalSubject<Subject, ?> that(Optional<?> optional) { return that(optional, (builder, value) -> (DefaultSubject) builder.that(value)); } public <S extends Subject, T> OptionalSubject<S
private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final long DEFAULT_MAX_ELAPSED_SECONDS = 8; private final Metrics metrics; private final AllProjectsName allProjectsName; private final String pluginName; private final GitRepositoryManager repoManager; private final ProjectCache projectCache; private final PluginConfigFactory pluginConfigFactory; private final CopyrightReviewApi reviewApi; private @Nullable PluginConfig gerritConfig; private @Nullable CheckConfig checkConfig; static AbstractModule module() { return new AbstractModule() { @Override protected void configure() { DynamicSet.bind(binder(), CommitValidationListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), LifecycleListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), RevisionCreatedListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(CopyrightConfig.class); } }; } @Inject CopyrightConfig( Metrics metrics, AllProjectsName allProjectsName, @PluginName String pluginName, GitRepositoryManager repoManager, ProjectCache projectCache, PluginConfigFactory pluginConfigFactory, CopyrightReviewApi reviewApi ) { this.metrics = metrics; this.allProjectsName = allProjectsName; this.pluginName = pluginName; this.repoManager = repoManager; this.projectCache = projectCache; this.pluginConfigFactory = pluginConfigFactory; this.reviewApi = reviewApi; }
protected boolean showUserInReview; @Column(id = 12) protected boolean relativeDateInChangeTable; @Column(id = 13, length = 20, notNull = false) protected String commentVisibilityStrategy; @Column(id = 14, length = 20, notNull = false) protected String diffView; @Column(id = 15, length = 20, notNull = false) protected String changeScreen; @Column(id = 16) protected boolean sizeBarInChangeTable; @Column(id = 17) protected boolean legacyCIDInChangeTable; public AccountGeneralPreferences() { } public short getMaximumPageSize() { return maximumPageSize; } public void setMaximumPageSize(final short s) { maximumPageSize = s; } public boolean isShowSiteHeader() { return showSiteHeader; } public void setShowSiteHeader(final boolean b) { showSiteHeader = b; } public boolean isUseFlashClipboard() { return useFlashClipboard; } public void setUseFlashClipboard(final boolean b) { useFlashClipboard = b; }
@Nullable private CheckConfig readConfig(String projectConfigObjectId) throws IOException, ConfigInvalidException { CheckConfig checkConfig = null; // new All-Projects project.config not yet in cache -- read from repository ObjectId id = ObjectId.fromString(projectConfigObjectId); if (ObjectId.zeroId().equals(id)) { return checkConfig; } try (Repository repo = repoManager.openRepository(allProjectsName)) { checkConfig = new CheckConfig(pluginName, readFileContents(repo, id, ProjectConfig.PROJECT_CONFIG)); } gerritConfig = pluginConfigFactory.getFromGerritConfig(pluginName, true); return checkConfig; }
Buggy Code: ```java // new All-Projects project.config not yet in cache -- read from repository ObjectId id = ObjectId.fromString(projectConfigObjectId); if (ObjectId.zeroId().equals(id)) { return checkConfig; } try (Repository repo = repoManager.openRepository(allProjectsName)) { checkConfig = new CheckConfig(pluginName, readFileContents(repo, id, ProjectConfig.PROJECT_CONFIG)); } gerritConfig = pluginConfigFactory.getFromGerritConfig(pluginName, true); if (gerritConfig == null) { // throw IllegalStateException? RestApiException? checkConfig.scannerConfig.messages.add( ScannerConfig.hintMessage("missing [plugin \"" + pluginName + "\"] section in gerrit.config")); } else { checkConfig.scannerConfig.defaultEnable = gerritConfig.getBoolean(ScannerConfig.KEY_ENABLE, false); } return checkConfig; } private void logReviewResultErrors(RevisionCreatedListener.Event event, ReviewResult result) { if (!Strings.isNullOrEmpty(result.error)) { logger.atSevere().log(result.error); } } ``` Fixed Code: ```java // new All-Projects project.config not yet in cache -- read from repository ObjectId id = ObjectId.fromString(projectConfigObjectId); if (ObjectId.zeroId().equals(id)) { return checkConfig; } try (Repository repo = repoManager.openRepository(allProjectsName)) { checkConfig = new CheckConfig(pluginName, readFileContents(repo, id, ProjectConfig.PROJECT_CONFIG)); } gerritConfig = pluginConfigFactory.getFromGerritConfig(pluginName, true); if (gerritConfig == null) { throw new RestApiException( HttpStatus.SC_INTERNAL_SERVER_ERROR, "missing [plugin \"" + pluginName + "\"] section in gerrit.config" ); } else { checkConfig.scannerConfig.defaultEnable = gerritConfig.getBoolean(ScannerConfig.KEY_ENABLE, false); } return checkConfig; } private void logReviewResultErrors(RevisionCreatedListener.Event event, ReviewResult result) { if (!Strings.isNullOrEmpty(result.error)) { throw new RestApiException(HttpStatus.SC_INTERNAL_SERVER_ERROR, result.error); } } ```
AddReviewerResult arr = entry.getValue(); if (!Strings.isNullOrEmpty(arr.error)) { logger.atSevere().log( "revision %s: error adding reviewer %s: %s", event.getChange().currentRevision, entry.getKey(), arr.error ); metrics.addReviewerErrors.increment(event.getChange().project); metrics.errors.increment(); } } private String readFileContents(Repository repo, ObjectId objectId, String filename) throws IOException { try (RevWalk rw = new RevWalk(repo)) { RevTree tree = rw.parseTree(objectId); try (TreeWalk tw = TreeWalk.forPath(rw.getObjectReader(), filename, tree)) { ObjectLoader loader = repo.open(tw.getObjectId(0), Constants.OBJ_BLOB); return new String(loader.getCachedBytes(), UTF_8); } } }
private String readFileContents(Repository repo, ObjectId objectId, String filename) throws IOException { RevWalk rw = new RevWalk(repo); RevTree tree = rw.parseTree(objectId); try (TreeWalk tw = TreeWalk.forPath(rw.getObjectReader(), filename, tree)) { if (tw != null) { ObjectLoader loader = repo.open(tw.getObjectId(0), Constants.OBJ_BLOB); return new String(loader.getCachedBytes(), UTF_8); } } return null; }
import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.ZkValidationModule; import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; import java.util.Collection; import java.util.UUID; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class Module extends LifecycleModule { private static final Logger log = LoggerFactory.getLogger(Module.class); private Configuration config; private NoteDbStatus noteDb; private final boolean disableGitRepositoryValidation; @Inject public Module(Configuration config, NoteDbStatus noteDb) { this(config, noteDb, false); } // TODO: It is not possible to properly test the libModules in Gerrit. // Disable the Git repository validation during integration test and then build the necessary // support // in Gerrit for it. @VisibleForTesting public Module( Configuration config, NoteDbStatus noteDb, boolean disableGitRepositoryValidation) { this.config = config; this.noteDb = noteDb; this.disableGitRepositoryValidation = disableGitRepositoryValidation; } }
install(new IndexModule()); if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } install(new MultiSiteValidationModule(config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); if (config.getSharedRefDb().isEnabled()) { install(new ZkValidationModule(config.getSharedRefDb().getZkConfig())); } bind(Gson.class) .annotatedWith(BrokerGson.class) .toProvider(GsonProvider.class) .in(Singleton.class);
import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class ZookeeperConfig { private static final Logger log = LoggerFactory.getLogger(ZookeeperConfig.class); public static final String ZOOKEEPER_MS_CONFIG = "multi-site.config"; public static final int defaultSessionTimeoutMs; public static final int defaultConnectionTimeoutMs; public static final String DEFAULT_ZK_CONNECT = "localhost:2181"; private final int DEFAULT_RETRY_POLICY_BASE_SLEEP_TIME_MS = 1000; private final int DEFAULT_RETRY_POLICY_MAX_SLEEP_TIME_MS = 3000; private final int DEFAULT_RETRY_POLICY_MAX_RETRIES = 3; private final int DEFAULT_CAS_RETRY_POLICY_BASE_SLEEP_TIME_MS = 100; private final int DEFAULT_CAS_RETRY_POLICY_MAX_SLEEP_TIME_MS = 300; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3; }
public ZkValidationModule(ZookeeperConfig cfg) { this.cfg = cfg; this.multiSiteConfig = MultiSiteConfig.getInstance(); }
static { System.setProperty("gerrit.notedb", "ON"); } public static class KafkaTestContainerModule extends LifecycleModule { public static class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) { this.kafka = kafka; } @Override public void stop() { kafka.stop(); } @Override public void start() { // Do nothing } } private final FileBasedConfig multiSiteConfig; private final FileBasedConfig sharedRefConfig; private final Module multiSiteModule; @Inject public KafkaTestContainerModule(SitePaths sitePaths, NoteDbStatus noteDb) { this.multiSiteConfig = new FileBasedConfig( sitePaths.etc_dir.resolve(Configuration.MULTI_SITE_CONFIG).toFile(), FS.DETECTED); this.sharedRefConfig = new FileBasedConfig( sitePaths.etc_dir.resolve(ZookeeperConfig.ZOOKEEPER_MS_CONFIG).toFile(), FS.DETECTED); this.multiSiteModule = new Module( new Configuration(multiSiteConfig, new Config()), new ZookeeperConfig(sharedRefConfig), new KafkaConfig()); } }
import com.google.gerrit.server.change.ChangeResource; import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.update.CommentsRejectedException; import com.google.gerrit.server.update.UpdateException; import com.google.inject.Inject; import com.google.inject.Module; import com.google.inject.Provider; import java.sql.Timestamp; import org.junit.Before; import org.junit.Test; /** * Tests for comment validation in {@link PostReview}. */ @NoHttpd public class PostReviewIT extends AbstractDaemonTest { @Inject private Provider<ChangesCollection> changes; @Inject private Provider<PostReview> postReview; @Inject private RequestScopeOperations requestScopeOperations; @Override public Module createModule() { return new FactoryModule() { @Override public void configure() { bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); } }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception { gApi.changes().id(<the id you want>).current().review(in); } }
import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.update.CommentsRejectedException; import com.google.gerrit.server.update.UpdateException; import com.google.inject.Inject; import com.google.inject.Module; import com.google.inject.Provider; import java.sql.Timestamp; import org.junit.Before; import org.junit.Test; /** Tests for comment validation in {@link PostReview}. */ @NoHttpd public class PostReviewIT extends AbstractDaemonTest { @Inject private Provider<ChangesCollection> changes; @Inject private Provider<PostReview> postReview; @Inject private RequestScopeOperations requestScopeOperations; @Override public Module createModule() { return new FactoryModule() { @Override public void configure() { bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); } }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception { String file = "file"; gApi.changes().id(someid).current().review(ent); } }
public void configure() { bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); }
} }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception { String file = "file"; PushOneCommit.Result r = createChange(); String changeId = r.getChange().changeId; String revId = r.getCommit().getName(); ReviewInput input = new ReviewInput(); ChangeResource changeResource = changes.get().parse(TopLevelResource.INSTANCE, IdString.fromDecoded(changeId)); RevisionResource revisionResource = revisions.parse(changeResource, IdString.fromDecoded(revId)); assertThat(getPublishedComments(changeId)).isEmpty();
private UUID tryToLoadSavedInstanceId(String serverIdFile) { if (Files.exists(Paths.get(serverIdFile))) { try (BufferedReader br = new BufferedReader(new FileReader(serverIdFile))) { return UUID.fromString(br.readLine()); } catch (IOException e) { multisiteLog.warn(String.format("Cannot read instance ID from path '%s', deleting the old file and generating a new ID: (%s)", serverIdFile, e.getMessage())); try { Files.delete(Paths.get(serverIdFile)); } catch (IOException e1) { multisiteLog.warn(String.format("Cannot delete old instance ID file at path '%s' with instance ID while generating a new one: (%s)", serverIdFile, e1.getMessage())); } } } return null; }
protected void configure() { bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getZookeeperConfig().buildCurator()); bind(ZkConnectionConfig.class) .toInstance(new ZkConnectionConfig(cfg.getZookeeperConfig().buildCasRetryPolicy(), cfg.getZookeeperConfig().getZkInterProcessLockTimeOut())); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ProjectDeletedSharedDbCleanup.class); }
Throwable t = e.getCause(); if (t instanceof LockFailureException) { logger.atSevere().withCause(t).log("Error in %s %s", req.getMethod(), uriForLogging(req)); responseBytes = replyError(req, res, status = SC_SERVICE_UNAVAILABLE, messageOr(t, "Lock failure"), e); } else if (t instanceof CommentsRejectedException) { responseBytes = replyError(req, res, status = SC_BAD_REQUEST, messageOr(t, "Comments rejected"), e); } else { status = SC_INTERNAL_SERVER_ERROR; responseBytes = handleException(e, req, res); } } catch (QuotaException e) { responseBytes = replyError(req, res, status = 429, messageOr(e, "Quota limit reached"), e.caching(), e); } catch (Exception e) { status = SC_INTERNAL_SERVER_ERROR; responseBytes = handleException(e, req, res); } finally { String metric = viewData != null && viewData.view != null ? globals.metrics.view(viewData) : "_unknown";
public static List<CommentValidationFailure> findInvalidComments(PluginSetContext<CommentValidator> commentValidators, ImmutableList<CommentForValidation> commentsForValidation) { List<CommentValidationFailure> commentValidationFailures = new ArrayList<>(); commentValidators.runEach(listener -> commentValidationFailures.addAll(listener.validateComments(commentsForValidation))); return Collections.unmodifiableList(commentValidationFailures); }
comments.addAll(toPublish); return !toPublish.isEmpty(); } private boolean insertRobotComments(ChangeContext ctx) throws OrmException, PatchListNotAvailableException { if (in.robotComments == null) { return false; } List<RobotComment> newRobotComments = getNewRobotComments(ctx); commentsUtil.putRobotComments(ctx.getUpdate(psId), newRobotComments); comments.addAll(newRobotComments); return !newRobotComments.isEmpty(); } private List<RobotComment> getNewRobotComments(ChangeContext ctx) throws OrmException, PatchListNotAvailableException { List<RobotComment> toAdd = new ArrayList<>(in.robotComments.size()); Set<CommentSetEntry> existingIds = in.omitDuplicateComments ? readExistingRobotComments(ctx) : Collections.emptySet(); for (Map.Entry<String, List<RobotCommentInput>> ent : in.robotComments.entrySet()) { String path = ent.getKey(); for (RobotCommentInput c : ent.getValue()) { RobotComment e = createRobotCommentFromInput(ctx, path, c); if (existingIds.contains(CommentSetEntry.create(e))) { continue; } toAdd.add(e); } } validateComments(toAdd); return toAdd; }
import java.util.concurrent.locks.ReentrantLock; import com.google.common.collect.ImmutableList; import com.google.common.collect.Iterables; import com.google.common.util.concurrent.Retryer; public class SequenceGenerator { private final String refName; private final long seed; private final long floor; private final int batchSize; private final Runnable afterReadRef; private final Retryer<?> retryer; private final ReentrantLock counterLock; private long counter; private long limit; public SequenceGenerator(String name, long seed, long floor, int batchSize, Runnable afterReadRef, Retryer<?> retryer) { this.refName = RefNames.REFS_SEQUENCES + name; this.seed = seed; this.floor = floor; checkArgument(batchSize > 0, "expected batchSize > 0, got: %s", batchSize); this.batchSize = batchSize; this.afterReadRef = requireNonNull(afterReadRef, "afterReadRef"); this.retryer = requireNonNull(retryer, "retryer"); counterLock = new ReentrantLock(true); } /** * Generates the next sequence number. * * @return the next sequence number */ public int next() { return Iterables.getOnlyElement(next(1)); } /** * Generates the next sequence numbers. * * @param count the number of sequence numbers to generate * @return a list of generated sequence numbers */ public ImmutableList<Integer> next(int count) { if (count == 0) { return ImmutableList.of(); } checkArgument(count > 0, "count is negative: %s", count); try { return retryer.call(() -> { counterLock.lock(); try { if (count == 1) { if (counter >= limit) { acquire(batchSize); } return ImmutableList.of((int) counter++); } List<Integer> ids = new ArrayList<>(count); while (counter < limit) { ids.add((int) counter++); if (ids.size() == count) { return ImmutableList.copyOf(ids); } } acquire(batchSize); return ImmutableList.copyOf(ids); } finally { counterLock.unlock(); } }); } catch (Exception e) { throw new RuntimeException("Failed to generate sequence numbers
// from the sequence. Creating an ID requires the RepoSequence.counterLock, if it's not free // (because we forgot to release it before blocking) the call in the other thread would hang and // the test would time out. // We can set the runnable that consumes the ID from another thread only after RepoSequence was // created, because we need the RepoSequence instance to get the next ID. BlockStrategyThatTriggersRunnable blockStrategy = new BlockStrategyThatTriggersRunnable(); // Use batch size = 1 to make each call go to NoteDb. RepoSequence s = newSequence("id", 1, 1, bgUpdate, RepoSequence.retryerBuilder().withBlockStrategy(blockStrategy).build()); blockStrategy.runOnBlock = () -> { try { Executors.newFixedThreadPool(1) .submit(() -> { // This call hangs if we don't release the RepoSequence.counterLock while we // are blocking until the next try. If this happens we block until the test // times out. }); } catch (Exception e) { // Handle exception } };
assertThat(getEmails()).containsExactly(previous); assertThat(gApi.accounts().self().get().email).isNull(); } @Test @Sandboxed public void deleteAllEmails() throws Exception { EmailInput input = new EmailInput(); input.email = "foo.bar@example.com"; input.noConfirmation = true; gApi.accounts().self().addEmail(input); resetCurrentApiUser(); Set<String> allEmails = getEmails(); assertThat(allEmails).hasSize(2); accountIndexedCounter.clear(); for (String email : allEmails) { gApi.accounts().self().deleteEmail(email); } resetCurrentApiUser(); assertThat(getEmails()).isEmpty(); assertThat(gApi.accounts().self().get().email).isNull(); } @Test public void deleteEmailFromCustomExternalIdSchemes() throws Exception { String email = "foo.bar@example.com"; String extId1 = "foo:bar"; String extId2 = "foo:baz"; List<ExternalId> extIds = ImmutableList.of( // rest of the code }
public void deleteInstanceIdFile(String serverIdFile) { try { Files.delete(Paths.get(serverIdFile)); } catch (IOException e) { multisiteLog.warn(String.format("Cannot delete old instance ID file at path '%s' while generating a new one: (%s)", serverIdFile, e.getMessage())); } }
/** * Wraps a {@link Callable} and provides logging context awareness. */ class LoggingContextAwareCallable<T> implements Callable<T> { private final Callable<T> callable; private final Thread callingThread; private final ImmutableSetMultimap<String, String> tags; private final boolean forceLogging; private final boolean performanceLogging; private final MutablePerformanceLogRecords mutablePerformanceLogRecords; LoggingContextAwareCallable(Callable<T> callable, MutablePerformanceLogRecords mutablePerformanceLogRecords) { this.callable = callable; this.callingThread = Thread.currentThread(); this.tags = LoggingContext.getInstance().getTagsAsMap(); this.forceLogging = LoggingContext.getInstance().isLoggingForced(); this.performanceLogging = LoggingContext.getInstance().isPerformanceLogging(); this.mutablePerformanceLogRecords = mutablePerformanceLogRecords; } @Override public T call() throws Exception { try { LoggingContext.getInstance().setTags(tags); LoggingContext.getInstance().setLoggingForced(forceLogging); LoggingContext.getInstance().setPerformanceLogging(performanceLogging); LoggingContext.getInstance().setPerformanceLogRecords(mutablePerformanceLogRecords); return callable.call(); } finally { LoggingContext.getInstance().clear(); } } }
import static org.junit.Assert.*; import static org.mockito.Mockito.*; import org.easymock.EasyMock; import org.junit.Rule; import org.junit.Test; import org.junit.rules.ExpectedException; import com.google.common.collect.ImmutableList; import com.google.common.collect.ImmutableMap; import com.google.gerrit.extensions.api.changes.ReviewInput; import com.google.gerrit.extensions.common.CommentInput; import com.google.gerrit.extensions.common.CommentInfo; import com.google.gerrit.extensions.common.CommentRange; import com.google.gerrit.extensions.common.CommentRange.Range; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.server.CommentsRejectedException; import com.google.gerrit.server.change.ChangeResource; import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.change.TestCommentUtil; import com.google.gerrit.server.change.TestCommentUtil.CommentForValidation; import com.google.gerrit.server.change.TestCommentUtil.CommentValidationMessage; import com.google.gerrit.server.change.TestCommentUtil.CommentValidationMessage.Type; import com.google.gerrit.server.change.TestCommentUtil.CommentValidationMessageFormatter; import com.google.gerrit.server.change.TestCommentUtil.CommentValidationMessageFormatterImpl; import com.google.gerrit.server.change.TestCommentUtil.CommentValidator; import com.google.gerrit.server.change.TestCommentUtil.CommentValidatorImpl; import com.google.gerrit.server.change.TestCommentUtil.TestComment; import com.google.gerrit.server.change.TestCommentUtil.TestCommentFormatter; import com.google.gerrit.server.change.TestCommentUtil.TestCommentFormatterImpl; import com.google.gerrit.server.change.TestCommentUtil.TestCommentValidator; import com.google.gerrit.server.change.TestCommentUtil.TestCommentValidatorImpl; import com.google.gerrit.server.change.TestCommentUtil.ValidationResult; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultImpl; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatter; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatterImpl; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatterImpl.Format; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatterImpl.FormatOptions; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatterImpl.FormatOptionsImpl; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatterImpl.FormatOptionsImpl.Builder; import com.google.gerrit.server
public OrmException convertError(String op, SQLException err) { switch (getSQLStateInt(err)) { case 23000: return new OrmDuplicateKeyException("ACCOUNT_PATCH_REVIEWS", err); default: if (err.getCause() == null && err.getNextException() != null) { err.initCause(err.getNextException()); } return new OrmException(op + " failure on ACCOUNT_PATCH_REVIEWS", err); } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.base.Preconditions.checkArgument; import static com.google.common.base.Suppliers.memoize; import static com.google.common.base.Suppliers.ofInstance; import com.google.common.annotations.VisibleForTesting; import com.google.common.base.CaseFormat; import com.google.common.base.Strings; import com.google.common.collect.ImmutableList; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.google.inject.Singleton; import com.google.inject.spi.Message; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.io.IOException; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.commons.lang.StringUtils; import org.apache.curator.RetryPolicy; public class Main { public static void main(String[] args) { // Main method implementation } }
private final boolean enabled; private final Map<EventFamily, Boolean> eventsEnabled; private KafkaPublisher(Supplier<Config> cfg) { enabled = cfg.get().getBoolean(KAFKA_SECTION, KAFKA_PUBLISHER_SUBSECTION, ENABLE_KEY, DEFAULT_BROKER_ENABLED); eventsEnabled = eventsEnabled(cfg, KAFKA_PUBLISHER_SUBSECTION); if (enabled) { setDefaults(); applyKafkaConfig(cfg, KAFKA_PUBLISHER_SUBSECTION, this); } }
import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import com.google.common.base.CaseFormat; import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String KAFKA_CONFIG = "multi-site.config"; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; public KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = lazyLoad(kafkaConfig); // Rest of the code } }
ProvisionException pe = new ProvisionException("error opening ReviewDb"); pe.initCause(e); throw pe; } dbRef.set(db); } return db; } @Override public CurrentUser getUser() { throw new OutOfScopeException("No user during ChangeIndexer"); } RequestContext oldCtx = context.setContext(newCtx); try { if (this instanceof IndexTask) { queuedIndexTasks.remove(this); } else if (this instanceof ReindexIfStaleTask) { queuedReindexIfStaleTasks.remove(this); } return callImpl(newCtx.getReviewDbProvider()); } finally { context.setContext(oldCtx); Provider<ReviewDb> db = dbRef.get(); if (db != null) { db.get().close(); } } } catch (Exception e) { log.error("Failed to execute " + this, e); throw e; }
bind(PersonIdent.class) // .annotatedWith(GerritPersonIdent.class) // .toProvider(GerritPersonIdentProvider.class); bind(AllProjectsName.class).toInstance(new AllProjectsName("All-Projects")); bind(AllUsersName.class).toInstance(new AllUsersName("All-Users")); bind(GitRepositoryManager.class).toInstance(new InMemoryRepositoryManager()); bind(String.class) // .annotatedWith(AnonymousCowardName.class) // .toProvider(AnonymousCowardNameProvider.class); bind(DataSourceType.class).to(InMemoryH2Type.class); install(new ConfigNotesMigration.Module()); admin = accountCreator.admin(); user = accountCreator.user(); // Evict and reindex accounts in case tests modify them. evictAndReindexAccount(admin.getId()); evictAndReindexAccount(user.getId()); adminRestSession = new RestSession(server, admin); userRestSession = new RestSession(server, user); anonymousRestSession = new RestSession(server, null); initSsh(); resourcePrefix = UNSAFE_PROJECT_NAME.matcher(description.getClassName() + "_" + description.getMethodName() + "_") .replaceAll(""); Context ctx = newRequestContext(admin); atrScope.set(ctx); ProjectInput in = projectInput(description); gApi.projects().create(in); project = new Project.NameKey(in.name); testRepo = cloneProject(project, getCloneAsAccount(description)); public Module createModule() { return null; } protected void initSsh() throws Exception { if (testRequiresSsh && SshMode.useSsh() && (adminSshSession == null || userSshSession == null)) { protected void configure() { install(SchemaVersionCheck.module()); bind(ApprovalTypes.class).toProvider(ApprovalTypesProvider.class).in(Scopes.SINGLETON); bind(String.class).annotatedWith(CanonicalWebUrl.class) .toProvider(CanonicalWebUrlProvider.class).in(Scopes.SINGLETON); install(AccountCacheImpl.module()); install(GroupCacheImpl.module()); install(new EhcachePoolImpl.Module()); install(new FactoryModule() { @Override protected void configure() { factory(CreateCodeReviewNotes.Factory.class); factory(NotesBranchUtil.Factory.class); } }); install(new LifecycleModule() { @Override protected void configure() { listener().to(LocalDiskRepositoryManager.Lifecycle.class); }
import com.android.tools.idea.tests.gui.framework.GuiTestCase; import com.android.tools.idea.tests.gui.framework.IdeGuiTest; import com.android.tools.idea.tests.gui.framework.fixture.IdeFrameFixture; import com.android.tools.idea.tests.gui.framework.fixture.RenameRefactoringDialogFixture; import com.android.tools.idea.tests.gui.framework.fixture.ThemeSelectionDialogFixture; import com.android.tools.idea.tests.gui.framework.fixture.theme.ThemeEditorFixture; import com.google.common.collect.ImmutableList; import org.fest.swing.fixture.JComboBoxFixture; import org.fest.swing.fixture.JListFixture; import org.fest.swing.fixture.JTreeFixture; import org.junit.BeforeClass; import org.junit.Test; import java.io.IOException; import java.util.List; import static com.android.tools.idea.tests.gui.framework.TestGroup.THEME; import static com.android.tools.idea.tests.gui.theme.ThemeEditorTest.openThemeEditor; import static org.fest.assertions.Assertions.assertThat; import static org.junit.Assert.assertEquals; @BelongsToTestGroups({THEME}) public class ThemeSelectorTest extends GuiTestCase { @BeforeClass public static void setUp() throws IOException { IdeGuiTest.setUp(); } @Test public void testThemeSelector() throws IOException { IdeFrameFixture ideFrameFixture = openThemeEditor(myProject); ThemeEditorFixture themeEditorFixture = ideFrameFixture.getThemeEditor(); ThemeSelectionDialogFixture themeSelectionDialogFixture = themeEditorFixture.openThemeSelectionDialog(); JComboBoxFixture themeComboBoxFixture = themeSelectionDialogFixture.getThemeComboBox(); JListFixture themeListFixture = themeComboBoxFixture.dropDown(); List<String> themes = themeListFixture.contents(); assertThat(themes).contains("AppTheme", "Theme.Material.Light"); themeListFixture.clickItem(Index.atIndex(1)); themeSelectionDialogFixture.clickOk(); assertEquals("Theme.Material.Light", themeComboBoxFixture.selectedItem()); } }
import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.HashMap; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String PLUGIN_NAME = "kafka"; public static final String KAFKA_CONFIG = PLUGIN_NAME + ".config"; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject public KafkaConfiguration(Supplier<KafkaSubscriber> subscriber, Supplier<Kafka> kafka, Supplier<KafkaPublisher> publisher) { this.subscriber = subscriber; this.kafka = kafka; this.publisher = publisher; } }
import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String PLUGIN_NAME = "kafka"; public static final String KAFKA_CONFIG = PLUGIN_NAME + ".config"; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); } }
import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String PLUGIN_NAME = "kafka"; public static final String KAFKA_CONFIG = MultiSiteConfig.MULTI_SITE_CONFIG; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); } @VisibleForTesting public KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = ConfigurationHelper.lazyLoad(kafkaConfig); } }
import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.InstanceId; import com.googlesource.gerrit.plugins.multisite.KafkaConfiguration; import com.googlesource.gerrit.plugins.multisite.broker.BrokerSession; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.UUID; public class KafkaSession implements BrokerSession { private static final Logger LOGGER = LoggerFactory.getLogger(KafkaSession.class); private KafkaConfiguration kafkaConfig; private final UUID instanceId; private volatile Producer<String, String> producer; @Inject public KafkaSession(KafkaConfiguration kafkaConfig, @InstanceId UUID instanceId) { this.kafkaConfig = kafkaConfig; this.instanceId = instanceId; } @Override public boolean isOpen() { return producer != null; } @Override public void connect() { if (isOpen()) { LOGGER.debug("Already connected."); return; } // Connect to Kafka } // Other methods }
package com.googlesource.gerrit.plugins.multisite.kafka.consumer; import java.util.concurrent.Executor; import java.util.concurrent.Executors; import org.apache.kafka.common.serialization.ByteArrayDeserializer; import org.apache.kafka.common.serialization.Deserializer; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.lifecycle.LifecycleModule; import com.google.inject.TypeLiteral; import com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaSubscriber; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import com.googlesource.gerrit.plugins.multisite.forwarder.events.MultiSiteEvent; public class KafkaConsumerModule extends LifecycleModule { private final KafkaSubscriber kafkaSubscriber; public KafkaConsumerModule(KafkaSubscriber kafkaSubscriber) { this.kafkaSubscriber = kafkaSubscriber; } @Override protected void configure() { MultiSiteEvent.registerEventTypes(); bind(new TypeLiteral<DynamicSet<MultiSiteEvent.Listener>>() {}) .toProvider(KafkaSubscriberProvider.class); bind(KafkaSubscriber.class).toInstance(kafkaSubscriber); bind(Executor.class).annotatedWith(EventFamily.class) .toInstance(Executors.newSingleThreadExecutor()); bind(new TypeLiteral<Deserializer<byte[]>>() {}) .to(ByteArrayDeserializer.class); } }
package com.googlesource.gerrit.plugins.multisite; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.multisite.Configuration.DEFAULT_THREAD_POOL_SIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.THREAD_POOL_SIZE_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.CACHE_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.PATTERN_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Event.EVENT_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.DEFAULT_SYNCHRONIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.SYNCHRONIZE_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Index.INDEX_SECTION; import org.eclipse.jgit.lib.Config; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.junit.MockitoJUnitRunner; import static com.googlesource.gerrit.plugins.multisite.Configuration.DEFAULT_THREAD_POOL_SIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.THREAD_POOL_SIZE_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.CACHE_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.PATTERN_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Event.EVENT_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.DEFAULT_SYNCHRONIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.SYNCHRONIZE_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Index.INDEX_SECTION; import static com.google.common.truth.Truth.assertThat; @RunWith(MockitoJUnitRunner.class) public class MultiSiteConfigurationTest { private MultiSiteConfiguration multiSiteConfig; @Before public void setUp() { multiSiteConfig = new MultiSiteConfiguration(); } @Test public void testDefaultThreadPoolSize() { Config config = new Config(); int defaultThreadPoolSize = multiSiteConfig.getDefaultThreadPoolSize(config); assertThat(defaultThreadPoolSize).isEqualTo(DEFAULT_THREAD_POOL_SIZE); } @Test
static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000; static final int DEFAULT_THREAD_POOL_SIZE = 4; static final String NUM_STRIPED_LOCKS = "numStripedLocks"; static final int DEFAULT_NUM_STRIPED_LOCKS = 10; static final String ENABLE_KEY = "enabled"; private final Supplier<Cache> cache; private final Supplier<Event> event; private final Supplier<Index> index; private final Supplier<Collection<Message>> replicationConfigValidation; @Inject Configuration(SitePaths sitePaths) { this(getConfigFile(sitePaths, MULTI_SITE_CONFIG), getConfigFile(sitePaths, REPLICATION_CONFIG)); } @VisibleForTesting public Configuration(Config multiSiteConfig, Config replicationConfig) { Supplier<Config> lazyMultiSiteCfg = lazyLoad(multiSiteConfig); replicationConfigValidation = lazyValidateReplicatioConfig(replicationConfig); cache = memoize(() -> new Cache(lazyMultiSiteCfg)); event = memoize(() -> new Event(lazyMultiSiteCfg)); index = memoize(() -> new Index(lazyMultiSiteCfg)); } public Cache cache() { return cache.get(); }
private final int threadPoolSize; private final List<String> patterns; private Cache(Supplier<Config> cfg) { super(cfg, CACHE_SECTION); threadPoolSize = getInt(cfg, CACHE_SECTION, null, THREAD_POOL_SIZE_KEY, DEFAULT_THREAD_POOL_SIZE); patterns = getList(cfg, CACHE_SECTION, null, PATTERN_KEY); }
import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; private static final String KAFKA_CONFIG = Configuration.KAFKA_CONFIG; private static final String ENABLE_KEY = "enabled"; private static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; private static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); } @VisibleForTesting KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = lazyLoad(kafkaConfig); // rest of the code } }
public void init(IWorkbench workbench) { // TODO Auto-generated method stub } public void testTypeErasure() { List<Integer> list = new ArrayList<>(); list.add(1); IEclipseContext context = EclipseContextFactory.create(); context.set(List.class, list); TestNamedObject userObject = new TestNamedObject(); ContextInjectionFactory.inject(userObject, context); assertEquals(list, userObject.field); userObject.combineIt(); } // Set new parent ProjectAccessInput accessInput = newProjectAccessInput(); accessInput.parent = newParentProjectName; setApiUser(user); exception.expect(AuthException.class); exception.expectMessage("not administrator"); gApi.projects().name(newProjectName).access(accessInput); @Test public void updateParentAsAdministrator() throws Exception { String newParentProjectName = createProject(PROJECT_NAME + "PA").get(); ProjectAccessInput accessInput = newProjectAccessInput(); accessInput.parent = newParentProjectName; gApi.projects().name(newProjectName).access(accessInput); assertThat(pApi.access().inheritsFrom.name).isEqualTo(newParentProjectName); } @Test public void addGlobalCapabilityAsUser() throws Exception { ProjectAccessInput accessInput = newProjectAccessInput(); AccessSectionInfo accessSectionInfo = createDefaultGlobalCapabilitiesAccessSectionInfo(); accessInput.additions.put(AccessSection.GLOBAL_CAPABILITIES, accessSectionInfo); setApiUser(user); exception.expect(AuthException.class); gApi.projects().name(allProjects.get()).access(accessInput); } projectOperations.allProjectsForUpdate() .add(allow(Permission.READ).ref("refs/*").group(admins)) .update(); try (ProjectConfigUpdate u = updateProject(allUsers)) { for (AccessSection sec : u.getConfig().getAccessSections()) { sec.removePermission(Permission.READ); } u.save(); } private void setUpChanges() throws Exception { gApi.projects().name(project.get()).branch("branch").create(new BranchInput()); projectOperations.project(project) .forUpdate() .add(allow(Permission.SUBMIT).ref("refs/for/refs/heads/*").group(admins)) .update(); PushOneCommit.Result mr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/master%submit"); mr.assertOkStatus(); cd1 = mr
// Remove all read permissions on All-Users. try (ProjectConfigUpdate u = updateProject(allUsers)) { for (AccessSection sec : u.getConfig().getAccessSections()) { sec.removePermission(Permission.READ); } u.save(); } private void setUpChanges() throws Exception { gApi.projects().name(project.get()).branch("branch").create(new BranchInput()); // First 2 changes are merged, which means the tags pointing to them are visible. projectOperations .project(project) .forUpdate() .add(allow(Permission.SUBMIT).ref("refs/for/refs/heads/*").group(admins)) .update(); PushOneCommit.Result mr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/master%submit"); mr.assertOkStatus(); cd1 = mr.getChange(); rc1 = mr.getCommit(); psRef1 = cd1.currentPatchSet().id().toRefName(); metaRef1 = RefNames.changeMetaRef(cd1.getId()); PushOneCommit.Result br = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/branch%submit"); br.assertOkStatus(); cd2 = br.getChange(); rc2 = br.getCommit(); psRef2 = cd2.currentPatchSet().id().toRefName(); metaRef2 = RefNames.changeMetaRef(cd2.getId()); PushOneCommit.Result cr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/refs/changes/01/1%submit"); cr.assertOkStatus(); cd3 = cr.getChange(); rc3 = cr.getCommit(); psRef3 = cd3.currentPatchSet().id().toRefName(); metaRef3 = RefNames.changeMetaRef(cd3.getId()); PushOneCommit.Result dr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/refs/changes/02/2%submit"); dr.assertOkStatus(); cd4 = dr.getChange(); rc4 = dr.getCommit(); psRef4 = cd4.currentPatchSet().id().toRefName(); metaRef4 = RefNames.changeMetaRef(cd4.getId()); }
/** * .haves}. This is a heuristical approach that aims at scaling down the number of unnecessary * objects that client sends to the server. Unnecessary here refers to objects that the server * already has. * * <p>For some code paths in {@link com.google.gerrit.server.git.DefaultAdvertiseRefsHook}, we * already removed refs/changes, so the logic to skip these in this class become a no-op. * * <p>TODO(hiesel): Instrument this heuristic and proof its value. */ public class ReceiveCommitsAdvertiseRefsHook implements AdvertiseRefsHook { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final Provider<InternalChangeQuery> queryProvider; private final Project.NameKey projectName; public ReceiveCommitsAdvertiseRefsHook( Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName) { this.queryProvider = queryProvider; this.projectName = projectName; } @Override public void advertiseRefs(UploadPack us) { throw new UnsupportedOperationException( "ReceiveCommitsAdvertiseRefsHook cannot be used for UploadPack"); } @Override public void advertiseRefs(ReceivePack rp) { throw new UnsupportedOperationException( "ReceiveCommitsAdvertiseRefsHook cannot be used for ReceivePack"); } }
@VisibleForTesting public static AdvertiseRefsHook createForTest( PermissionBackend.ForProject perm, Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName) { return create(new AllRefsWatcher(), perm, queryProvider, projectName, true); } private static AdvertiseRefsHook create( AllRefsWatcher allRefsWatcher, PermissionBackend.ForProject perm, Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName, boolean skipHackPushNegotiateHook) { List<AdvertiseRefsHook> advHooks = new ArrayList<>(); advHooks.add(allRefsWatcher); advHooks.add(/* ... */); // ... return new ChainAdvertiseRefsHook(advHooks); }
/** Returns the URL for viewing a comment in a file in a given patch set of a change. */ default Optional<String> getInlineCommentView(Change change, int patchsetId, String filename, short side, int startLine) { return getPatchFileView(change, patchsetId, filename) .map(url -> url + String.format("@%s%d", side == 0 ? "a" : "", startLine)); } /** * Returns a URL pointing to the settings page. */ default Optional<String> getSettingsUrl(@Nullable String section) { return getWebUrl() .map(url -> url + "settings" + (Strings.isNullOrEmpty(section) ? "" : "#" + section)); } /** Returns a URL pointing to a documentation page, at a given named anchor. */ default Optional<String> getDocUrl(String page, String anchor) { return getWebUrl().map(url -> url + "Documentation/" + page + "#" + anchor); }
public void connect() { if (isOpen()) { multisiteLog.debug("Already connected."); return; } multisiteLog.info("Connect to {}...", properties.getKafka().getBootstrapServers()); /* Need to make sure that the thread of the running connection uses * the correct class loader otherwise you can end up with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader(); producer = new KafkaProducer<>(properties.kafkaPublisher()); multisiteLog.info("Connection established."); }
public void connect() { if (isOpen()) { LOGGER.debug("Already connected."); return; } setConnectionClassLoader(); producer = producerProvider.get(); LOGGER.info("Connection established."); }
private static final String ERROR_MESSAGE_NEGATIVE_VALUE = "Invalid value: function %1$s expects" + " its %2$s input parameter to be a non-negative value, but gets %3$s"; private static final String ERROR_MESSAGE_OUT_OF_BOUND = "Index out of bound in %1$s: %2$s"; private static final String ERROR_MESSAGE_COERCION = "Invalid implicit scalar to collection coercion in %1$s"; private static final String ERROR_MESSAGE_DUPLICATE_FIELD = "Duplicate field name \"%1$s\""; private static final String ERROR_MESSAGE_INVALID_EXPRESSION = "Invalid expression: function %1$s expects" + " its %2$s input parameter to be a %3$s expression, but the actual expression is %4$s"; private static final String ERROR_MESSAGE_INVALID_PARAMETER_NUMBER = "Invalid parameter number: function %1$s " + "cannot take %2$s parameters"; private static Map<Integer, String> errorMessageMap = new HashMap<>(); static { // runtime errors errorMessageMap.put(1, ERROR_MESSAGE_NEGATIVE_VALUE); errorMessageMap.put(2, ERROR_MESSAGE_OUT_OF_BOUND); errorMessageMap.put(3, ERROR_MESSAGE_COERCION); errorMessageMap.put(4, ERROR_MESSAGE_DUPLICATE_FIELD); errorMessageMap.put(5, ERROR_MESSAGE_INVALID_EXPRESSION); errorMessageMap.put(6, ERROR_MESSAGE_INVALID_PARAMETER_NUMBER); } private List<File> mSourcePaths; private List<File> mJarPaths; private File mOutputDir; private String mPackage; private List<File> mLocalProguardFiles; private List<File> mSdkProguardFiles; private List<EclipseProject> mAllLibraries; private EclipseProject(@NonNull GradleImport importer, @NonNull File dir) throws IOException { mImporter = importer; mDir = dir; mCanonicalDir = dir.getCanonicalFile(); mImporter.registerProject(this); File file = getClassPathFile(); mClassPathDoc = GradleImport.getXmlDocument(file, false); initProjectName(); initAndroidProject(); initLanguageLevel(); if (isAndroidProject()) { Properties properties = getProjectProperties(); initProguard(properties); initVersion(properties); initLibraries(properties); initLibrary(properties); initPackage(); initMinSdkVersion(); } else { mDirectLibraries = new ArrayList<EclipseProject>(4); } initClassPathEntries(); initPathVariables(); }
out.hashtags = cd.hashtags(); out.changeId = in.getKey().get(); if (in.isNew()) { SubmitTypeRecord str = cd.submitTypeRecord(); if (str.isOk()) { out.submitType = str.type; } if (!excludeMergeableInChangeInfo && !has(SKIP_MERGEABLE)) { out.mergeable = cd.isMergeable(); } if (has(SUBMITTABLE)) { out.submittable = submittable(cd); } } if (!has(SKIP_INSERT_DELETE)) { Optional<ChangedLines> changedLines = cd.changedLines(); if (changedLines.isPresent()) { out.insertions = changedLines.get().insertions; out.deletions = changedLines.get().deletions; } } out.isPrivate = in.isPrivate() ? true : null; out.workInProgress = in.isWorkInProgress() ? true : null; out.hasReviewStarted = in.hasReviewStarted(); out.subject = in.getSubject(); out.status = in.getStatus().asChangeStatus(); out.owner = accountLoader.get(in.getOwner());
if (pr.getAction() == PermissionRule.Action.ALLOW && projectControl.match(pr, isChangeOwner)) { voteMin = Math.min(voteMin, pr.getMin()); voteMax = Math.max(voteMax, pr.getMax()); } voteMin = Math.max(voteMin, blockAllowMin); voteMax = Math.min(voteMax, blockAllowMax); if (voteMin > voteMax) { voteMin = 0; voteMax = 0; } return new PermissionRange(permissionName, voteMin, voteMax);
public TestRefValidator(ReceiveCommand.Type rejectType) { this.rejectType = rejectType; this.rejectRef = TEST_REF; this.handle = validators.add(this); }
protected static TestGroup FailedGroup; public static void setUp() throws Exception { System.out.println("Starting setup"); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Starting setup"); } System.setProperty(GlobalConfig.CONFIG_FILE_PROPERTY, TEST_CONFIG_FILE_NAME); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("initializing pseudo cluster"); } AsterixHyracksIntegrationUtil.init(true); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("initializing HDFS"); } HDFSCluster.getInstance().setup(); System.setProperty(ExternalDataConstants.NODE_RESOLVER_FACTORY_PROPERTY, IdentitiyResolverFactory.class.getName()); FailedGroup = new TestGroup(); FailedGroup.setName("failed"); } private static void validateBufferCacheState() { for (NodeControllerService nc : AsterixHyracksIntegrationUtil.ncs) { IAsterixAppRuntimeContext appCtx = (IAsterixAppRuntimeContext) nc.getApplicationContext().getApplicationObject(); } } @Override public void setParams(ListMultimap<String, String> params) throws BadRequestException { this.hasQuery = params.containsKey("query"); } @Override public RestView<TopLevelResource> list() { if (hasQuery) { return queryProjects.get(); } return list.get().setFormat(OutputFormat.JSON); } @Override public ProjectResource parse(TopLevelResource parent, IdString id) throws RestApiException, IOException, PermissionBackendException { ProjectResource rsrc = _parse(id.get(), true); if (rsrc == null) { throw new ResourceNotFoundException(id); } return rsrc; } fmt.addStyleName(row, i, Gerrit.RESOURCES.css().dataCell()); fmt.addStyleName(row, C_SUBJECT, Gerrit.RESOURCES.css().cSUBJECT()); fmt.addStyleName(row, C_STATUS, Gerrit.RESOURCES.css().cSTATUS()); fmt.addStyleName(row, C_OWNER, Gerrit.RESOURCES.css().cOWNER()); fmt.addStyleName(row, C_LAST_UPDATE, Gerrit.RESOURCES.css().cLastUpdate()); if (!Gerrit.isSignedIn() || (!Gerrit.getUserAccount().getGeneralPreferences().isLegacycidInChangeTable())) { fmt.addStyleName(row, C_ID, Gerrit.RESOURCES.css().dataCellHidden()); } int i = C_SIZE; if (use
private Function<T, String> formatter; public abstract String name(); public abstract Class<T> valueType(); public abstract Optional<String> description(); public Function<T, String> formatter() { if (formatter == null) { formatter = initFormatter(valueType()); } return formatter; } private static <T> Function<T, String> initFormatter(Class<T> valueType) { if (valueType == String.class) { return s -> (String) s; } else if (valueType == Integer.class || valueType == Boolean.class) { return Object::toString; } else if (Enum.class.isAssignableFrom(valueType)) { return in -> ((Enum<?>) in).name(); } throw new IllegalStateException("unsupported type " + valueType.getName()); } @AutoValue.Builder
reject(cmd, "not valid ref"); return; } if (RefNames.isNoteDbMetaRef(cmd.getRefName())) { // Reject pushes to NoteDb refs without a special option and permission. Note that this // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will // migrate to NoteDb eventually, and we don't want garbage data waiting there when the // migration finishes. logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption); if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) { // Only reject this command, not the whole push. This supports the use case of "git clone // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone // or mirror the NoteDb data; there is no single refspec that describes all refs *except* // NoteDb refs. reject(cmd, "NoteDb refs require special option and permission"); } }
public Context start(F1 f1) { return new Context(this, f1); }
.valueType(Boolean.class) .formatter(Object::toString) .name(name); } public static <E extends Enum<E>> Field.Builder<E> ofEnum(Class<E> enumType, String name) { return new AutoValue_Field.Builder<E>() .valueType(enumType) .formatter(Enum::name) .name(name); } public static Field.Builder<Integer> ofInteger(String name) { return new AutoValue_Field.Builder<Integer>() .valueType(Integer.class) .formatter(Object::toString) .name(name); }
public RequestMetrics(MetricMaker metricMaker) { Field<Integer> statusCodeField = Field.ofInteger("status", metadataBuilder::httpStatus) .description("HTTP status code") .build(); errors = metricMaker.newCounter("http/server/error_count", new Description("Rate of REST API error responses").setRate().setUnit("errors"), statusCodeField); successes = metricMaker.newCounter("http/server/success_count", new Description("Rate of REST API success responses").setRate().setUnit("successes"), statusCodeField); }
package com.google.gerrit.metrics; import static com.google.common.base.Preconditions.checkArgument; import com.google.auto.value.AutoValue; import java.util.Optional; import java.util.function.Function; /** * Describes a bucketing field used by a metric. * * @param <T> type of field */ @AutoValue public abstract class Field<T> { /** * Break down metrics by boolean true/false. * * @param name field name * @return builder for the boolean field */ public static Field.Builder<Boolean> ofBoolean(String name) { return new AutoValue_Field.Builder<Boolean>() .valueType(Boolean.class) .formatter(Object::toString) .name(name); } /** * Break down metrics by cases of an enum. * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static <E extends Enum<E>> Field.Builder<E> ofEnum(Class<E> enumType, String name) { return new AutoValue_Field.Builder<E>() .valueType(enumType) .formatter(Enum::name) .name(name); } // Builder class public abstract static class Builder<T> { public abstract Builder<T> valueType(Class<T> valueType); public abstract Builder<T> formatter(Function<T, String> formatter); public abstract Builder<T> name(String name); public abstract Field<T> build(); } }
public abstract Class<T> valueType(); /** * Returns the description text for the field explaining its range of values. * * @return the description text for the field */ public abstract Optional<String> description(); /** * Returns the formatter to format field values. * * @return the formatter to format field values */ public abstract Function<T, String> formatter(); @AutoValue.Builder public abstract static class Builder<T> { abstract Builder<T> name(String name); abstract Builder<T> valueType(Class<T> type); abstract Builder<T> formatter(Function<T, String> formatter); /** * Sets the description for the field. * * @param description the description for the field * @return the builder instance */ public abstract Builder<T> description(String description); abstract Field<T> autoBuild(); /** * Builds the field object. * * @return the built field object */ public Field<T> build() { Field<T> field = autoBuild(); checkArgument(field.name().matches("^[a-z_]+$"), "name must match [a-z_]"); return field; } } }
@Singleton public class UploadPackMetricsHook implements PostUploadHook { enum Operation { CLONE, FETCH; } private final Counter1<Operation> requestCount; private final Timer1<Operation> counting; private final Timer1<Operation> compressing; private final Timer1<Operation> writing; private final Histogram1<Operation> packBytes; @Inject UploadPackMetricsHook(MetricMaker metricMaker) { Field<Operation> operationField = Field.ofEnum(Operation.class, "operation", (metadataBuilder, fieldValue) -> metadataBuilder.gitOperation(fieldValue.name())).build(); requestCount = metricMaker.newCounter("git/upload-pack/request_count", new Description("Total number of git-upload-pack requests") .setRate() .setUnit("requests"), operationField); counting = metricMaker.newTimer("git/upload-pack/phase_counting", new Description("Time spent in the 'Counting...' phase") .setCumulative() .setUnit(Units.MILLISECONDS), operationField); compressing = metricMaker.newTimer("git/upload-pack/phase_compressing", new Description("Time spent in the 'Compressing...' phase") .setCumulative() .setUnit(Units.MILLISECONDS), operationField); writing = metricMaker.newTimer("git/upload-pack/phase_writing", new Description("Time spent in the 'Writing...' phase") .setCumulative() .setUnit(Units.MILLISECONDS), operationField); packBytes = metricMaker.newHistogram("git/upload-pack/pack_bytes", new Description("Size of the pack file in bytes") .setCumulative() .setUnit(Units.BYTES), operationField); } }
public abstract Optional<String> branchName(); public abstract Optional<String> cacheKey(); public abstract Optional<String> cacheName(); public abstract Optional<String> className(); public abstract Optional<Integer> changeId(); public abstract Optional<String> changeIdType(); public abstract Optional<String> eventType(); public abstract Optional<String> exportName(); public abstract Optional<String> garbageCollectorName(); public abstract Optional<String> gitOperation(); public abstract Optional<Integer> groupId(); public abstract Optional<String> groupName();
public abstract Optional<String> cacheName(); public abstract Optional<String> className(); public abstract Optional<Integer> changeId(); public abstract Optional<String> changeIdType(); public abstract Optional<String> eventType(); public abstract Optional<String> pluginExtensionName(); public abstract Optional<String> garbageCollectorName(); public abstract Optional<String> gitOperation(); public abstract Optional<Integer> groupId(); public abstract Optional<String> groupName(); public abstract Optional<String> groupUuid(); public abstract Optional<Integer> httpStatus(); public abstract Optional<String> secondaryIndexName();
public abstract Optional<Integer> groupId(); public abstract Optional<String> groupName(); public abstract Optional<String> groupUuid(); public abstract Optional<Integer> httpStatus(); public abstract Optional<String> indexName(); public abstract Optional<Integer> indexVersion(); public abstract Optional<String> authDomainName(); public abstract Optional<String> methodName(); public abstract Optional<Boolean> multiple(); public abstract Optional<String> noteDbFileName(); public abstract Optional<String> noteDbRefName(); public abstract Optional<String> noteDbSequenceType();
public abstract Optional<String> restViewName(); public abstract Optional<String> revision(); public abstract Optional<String> username(); public static Metadata.Builder builder() { return new AutoValue_Metadata.Builder(); } public static Metadata empty() { return builder().build(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder accountId(int accountId); public abstract Builder actionType(@Nullable String actionType); public abstract Builder branchName(@Nullable String branchName); public abstract Builder cacheKey(@Nullable String cacheKey); public abstract Builder cacheName(@Nullable String cacheName); public abstract Builder className(@Nullable String className); public abstract Builder changeId(int changeId); public abstract Builder changeIdType(@Nullable String changeIdType); public abstract Builder eventType(@Nullable String eventType); public abstract Builder exportName(@Nullable String exportName); public abstract Builder garbageCollectorName(@Nullable String garbageCollectorName); public abstract Builder gitOperation(@Nullable String gitOperation); }
package com.google.gerrit.server.logging; import static java.util.Objects.requireNonNull; import com.google.auto.value.AutoValue; import com.google.gerrit.common.Nullable; /** * The record of an operation for which the execution time was measured. * Meta data is stored in separate key/value fields to avoid expensive instantiations of Map objects. */ @AutoValue public abstract class PerformanceLogRecord { /** * Creates a performance log record without meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs) { return new AutoValue_PerformanceLogRecord(operation, durationMs, null); } /** * Creates a performance log record with meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @param metaData the meta data associated with the operation * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs, @Nullable MetaData metaData) { return new AutoValue_PerformanceLogRecord(operation, durationMs, metaData); } /** * Returns the name of the operation. * * @return the name of the operation */ public abstract String getOperation(); /** * Returns the execution time in milliseconds. * * @return the execution time in milliseconds */ public abstract long getDurationMs(); /** * Returns the meta data associated with the operation. * * @return the meta data associated with the operation */ @Nullable public abstract MetaData getMetaData(); /** * Meta data associated with a performance log record. */ @AutoValue public abstract static class MetaData { /** * Creates a meta data object. * * @param key the key of the meta data * @param value the value of the meta data * @return the meta data object */ public static MetaData create(String key, String value) { return new AutoValue_PerformanceLogRecord_MetaData(key, value); } /** * Returns the key of the meta data. * * @return the key
} /** * Creates a performance log record with meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @param metadata metadata * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs, Metadata metadata) { return new AutoValue_PerformanceLogRecord(operation, durationMs, requireNonNull(metadata)); } public abstract String operation(); public abstract long durationMs(); @Nullable public abstract Metadata metadata(); void writeTo(PerformanceLogger performanceLogger) { if (metadata() != null) { performanceLogger.log(operation(), durationMs(), metadata()); } else { performanceLogger.log(operation(), durationMs()); } }
if (refEnforcementPolicy == EnforcePolicy.IGNORED) return; String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been " + "persisted locally but not in SharedRef the value %s", projectName, refPair.getName(), refPair.putValue); boolean succeeded; try { succeeded = sharedRefDb.compareAndPut(projectName, getLatestLocalRef(refPair), refPair.putValue); } catch (IOException e) { throw new SharedDbSplitBrainException(errorMessage, e); } if (!succeeded) { throw new SharedDbSplitBrainException(errorMessage); } } protected void checkIfLocalRefIsUpToDateWithSharedRefDb( RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return; }
private void updateSharedRefDb(Stream<ReceiveCommand> commandStream, List<RefPair> refsToUpdate) throws IOException { if (commandStream.anyMatch(cmd -> cmd.getResult() != ReceiveCommand.Result.OK)) { return; } List<RefPair> updatedRefPairs = refsToUpdate.stream() .filter(distinctByKey(BatchRefUpdateValidator::getName)) .map(p -> { try { Ref current = getLatestLocalRef(p); return new RefPair(p.compareRef, current.getObjectId()); } catch (IOException e) { throw new RuntimeException(e); } }) .collect(Collectors.toList()); for (RefPair refPair : updatedRefPairs) { updateSharedDbOrThrowExceptionFor(refPair); } } public static String getName(RefPair p) { return p.compareRef.getName(); } public static <T> Predicate<T> distinctByKey(Function<? super T, ?> keyExtractor) { Set<Object> seen = ConcurrentHashMap.newKeySet(); return t -> seen.add(keyExtractor.apply(t)); }
import java.util.Arrays; import java.util.EnumSet; import java.util.List; public interface ChangeApi { ChangeInfo get(List<ListChangesOption> options) throws RestApiException; default ChangeInfo get(ListChangesOption... options) throws RestApiException { return get(Arrays.asList(options)); } default ChangeInfo get() throws RestApiException { return get(EnumSet.complementOf(EnumSet.of(ListChangesOption.CHECK, ListChangesOption.SKIP_MERGEABLE, ListChangesOption.SKIP_DIFFSTAT))); } default ChangeInfo info() throws RestApiException { return get(EnumSet.noneOf(ListChangesOption.class)); } @Deprecated default ChangeEditApi edit() throws RestApiException { return new ChangeEditApi(this); } }
private static void runOneBenchmark(@NonNull CtfTestTrace testTrace, String testName, RunMethod method, Dimension dimension) { Performance perf = Performance.getDefault(); PerformanceMeter pm = perf.createPerformanceMeter(TEST_ID + testName); perf.tagAsSummary(pm, "Execution graph " + testName, dimension); for (int i = 0; i < LOOP_COUNT; i++) { LttngKernelTrace trace = null; IAnalysisModule module = null; String path = CtfTmfTestTraceUtils.getTrace(testTrace).getPath(); try { trace = new LttngKernelTrace(); module = new LttngKernelExecutionGraph(); module.setId("test"); trace.initTrace(null, path, CtfTmfEvent.class); module.setTrace(trace); method.execute(pm, module); /* Delete the supplementary files, so that the next iteration rebuilds the state system. */ File suppDir = new File(TmfTraceManager.getSupplementaryFileDir(trace)); for (File file : suppDir.listFiles()) { file.delete(); } } catch (TmfAnalysisException | TmfTraceException e) { // Handle exception } } } public void removeMember(UUID memberId) { if (members == null) { members = new ArrayList<>(); return; } members.remove(memberId); } bind(AccountCreator.class); factory(PushOneCommit.Factory.class); }; return sysInjector.createChildInjector(module); } @SuppressWarnings("unchecked") private static <T> T get(Object obj, String field) throws SecurityException, NoSuchFieldException, IllegalArgumentException, IllegalAccessException { Field f = obj.getClass().getDeclaredField(field); f.setAccessible(true); return (T) f.get(obj); } private static InetAddress getLocalHost() throws UnknownHostException { return InetAddress.getLoopbackAddress(); } private Daemon daemon; private ExecutorService daemonService; private Injector testInjector; private String url; private InetSocketAddress sshdAddress; private InetSocketAddress httpAddress; private GerritServer(File sitePath, Injector testInjector, Daemon daemon, ExecutorService daemonService) throws IOException, ConfigInvalidException { this.sitePath = sitePath; this.testInjector = testInjector; this.daemon = daemon; this.daemonService = daemonService; Config cfg = testInjector.getInstance(Key.get(Config.class, GerritServerConfig.class
protected RefPair getRefPairToUpdate(RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist( String.format("%s-%s", projectName, refName), () -> sharedRefDb.lockRef(projectName, refName) ); RefPair latestRefPair = getLatestLocalRef(refPair); boolean isInSync = latestRefPair.compareRef.equals(refPair.compareRef); if (!isInSync) { throw new OutOfSyncException( String.format("The local ref %s in project %s is out of sync with the shared ref database", refName, projectName) ); } return latestRefPair; }
info = getPatchSetInfo(ctx); ChangeUpdate update = ctx.getUpdate(psId); Change.Status status = change.getStatus(); if (status == Change.Status.MERGED) { return true; } change.setCurrentPatchSet(info); change.setStatus(Change.Status.MERGED); update.fixStatus(Change.Status.MERGED); update.setCurrentPatchSet(); if (change.isWorkInProgress()) { change.setWorkInProgress(false); update.setWorkInProgress(false); } StringBuilder msgBuf = new StringBuilder(); msgBuf.append("Change has been successfully pushed"); if (!refName.equals(change.getDest().get())) { msgBuf.append(" into "); if (refName.startsWith(Constants.R_HEADS)) { msgBuf.append("branch "); msgBuf.append(Repository.shortenRefName(refName)); } else { msgBuf.append(refName); } } msgBuf.append("."); ChangeMessage msg = ChangeMessagesUtil.newMessage(
public Result render(long timeout, boolean forceMeasure) { return NOT_IMPLEMENTED.createResult(); } public Result render() { return render(RenderParams.DEFAULT_TIMEOUT); } import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.osee.framework.jdk.core.type.Pair; @Path("word") public interface WordUpdateEndpoint { @POST @Consumes({MediaType.APPLICATION_JSON}) @Produces({MediaType.APPLICATION_JSON}) @Path("update") WordUpdateChange updateWordArtifacts(WordUpdateData data); @POST @Consumes({MediaType.APPLICATION_JSON}) @Produces({MediaType.APPLICATION_JSON}) @Path("render") Pair<String, Set<String>> renderWordTemplateContent(WordTemplateContentData data); } import java.util.Map; public class MenuLayoutParserFactory extends LayoutPullParserFactory { private static final String FRAME_LAYOUT_XML = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n" + "<FrameLayout\n" + " xmlns:android=\"http://schemas.android.com/apk/res/android\"\n" + " android:layout_width=\"match_parent\"\n" + " android:layout_height=\"match_parent\" />\n"; private final RenderService myRenderService; public MenuLayoutParserFactory(RenderService renderService) { assert renderService.supportsCapability(Capability.ACTION_BAR) : "Action Bar not supported."; this.myRenderService = renderService; } fields = config.getBoolean("logFormat", pretty, "verbose", false) ? VERBOSE_FIELDS : FIELDS; variant = firstNonNull(config.getString("logFormat", pretty, "variant"), pretty); } public void renderStreaming(Paginator paginator, @Nullable String revision, Renderer renderer, Writer out, DateFormatter df, FooterBehavior footerBehavior) throws IOException { out.write(renderer .newRenderer("gitiles.logEntriesHeader") .setData(toHeaderSoyData(paginator, revision)) .render() .get()); SoySauce.Renderer entryRenderer = renderer.newRenderer("gitiles.logEntryWrapper"); boolean renderedEntries = false; for (RevCommit c : paginator) { out.write(entryRenderer.setData(toEntrySoyData(paginator, c, df)).render().get()); out.flush(); renderedEntries = true; } if (!renderedEntries) {
private boolean isInternalRef(String refName) { return RefNames.isGerritRef(refName) || RefNames.isNoteDbMetaRef(refName); }
private boolean isInternalRef(String refName) { return refName.startsWith(RefNames.REFS_STARRED_CHANGES) || refName.startsWith(RefNames.REFS_SEQUENCES); }
EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist(String.format("%s-%s", projectName, refName), () -> sharedRefDb.lockRef(projectName, refName)); Ref localRef = getLatestLocalRef(refPair); boolean isInSync = (localRef != null) ? sharedRefDb.isUpToDate(projectName, localRef) : !sharedRefDb.exists(projectName, refName); if (!isInSync) { validationMetrics.incrementSplitBrainPrevention(); softFailBasedOnEnforcement(new OutOfSyncException(projectName, localRef), refEnforcementPolicy); } return new RefPair(localRef == null ? nullRef(refName) : localRef, refPair.putValue); private Ref getLatestLocalRef(RefPair refPair) throws IOException { return refDb.exactRef(refPair.getName()); } protected boolean isSuccessful(RefUpdate.Result result) { switch (result) { case NEW: case FORCED: case FAST_FORWARD: case NO_CHANGE: return true; default: return false; } }
HttpServletResponse res, int statusCode, String msg, CacheControl c, @Nullable Throwable err) throws IOException { if (err != null) { RequestUtil.setErrorTraceAttribute(req, err); } configureCaching(req, res, null, null, c); checkArgument(statusCode >= 400, "non-error status: %s", statusCode); res.setStatus(statusCode); logger.atWarning().withCause(err).log("REST call failed: %d", statusCode); return replyText(req, res, true, msg); } /** * Sets a text reply on the given HTTP servlet response. * * @param req the HTTP servlet request * @param res the HTTP servlet response on which the reply should be set * @param allowTracing whether it is allowed to log the reply if tracing is enabled, must not be * set to {@code true} if the reply may contain sensitive data * @param text the text reply */
} return Optional.empty(); } private Optional<Project.NameKey> getProjectNameForChangeId(String changeId) { Optional<Project.NameKey> projectName = extractProjectNameFromChangeId(changeId); if (projectName.isPresent()) { return projectName; } try { List<ChangeData> changeData = globals .queryProvider .get() .setRequestedFields(ChangeField.PROJECT) .setLimit(1) .query(globals.changeQueryBuilder.change(changeId)); if (changeData.isEmpty()) { return Optional.empty(); } return Optional.of(changeData.get(0).project()); } catch (QueryParseException e) { return Optional.empty(); } } @VisibleForTesting static Optional<Project.NameKey> extractProjectNameFromChangeId(String changeId) { int projectEndPosition = changeId.indexOf('~'); if (projectEndPosition <= 0) { return Optional.empty(); } return Optional.of( Project.nameKey(IdString.fromUrl(changeId.substring(0, projectEndPosition)).get())); } private boolean isDelete(HttpServletRequest req)
package com.google.gerrit.server; import com.google.auto.value.AutoValue; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.logging.TraceContext; import java.util.Optional; /** Information about a request that was received from a user. */ @AutoValue public abstract class RequestInfo { public enum RequestType { GIT_RECEIVE, GIT_UPLOAD, REST, SSH } /** Type of the request, telling through which channel the request was coming in (REST, Git receive, git upload, SSH). */ public abstract RequestType getRequestType(); /** The user that has sent the request. */ public abstract CurrentUser getCallingUser(); /** The trace context of the request. */ public abstract TraceContext getTraceContext(); /** * The name of the project for which the request is being done. Only available if the request is * tied to a project or change. If a project is available it's not guaranteed that it actually * exists. */ public abstract Optional<Project.NameKey> getProjectName(); }
import com.google.common.hash.Hashing; import com.google.gerrit.common.data.GroupReference; import com.google.gerrit.extensions.annotations.PluginCanonicalWebUrl; import com.google.gerrit.extensions.annotations.PluginName; import com.google.gerrit.extensions.api.groups.Groups; import com.google.gerrit.extensions.common.GroupInfo; import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.ResourceConflictException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.reviewdb.client.Project.NameKey; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.account.GroupMembership; import com.google.gerrit.server.config.AllProjectsNameProvider; import com.google.gerrit.server.config.PluginConfigFactory; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.gerrit.server.permissions.ProjectPermission; import com.google.gerrit.server.project.CreateProjectArgs; import com.google.gerrit.server.project.NoSuchProjectException; import com.google.gerrit.server.validators.ProjectCreationValidationListener; import com.google.gerrit.server.validators.ValidationException;
private boolean isOwner(Project.NameKey project) { try { permissionBackend.user(self.get()).project(project).check(ProjectPermission.WRITE_CONFIG); } catch (AuthException | PermissionBackendException noWriter) { try { permissionBackend.user(self.get()).check(GlobalPermission.ADMINISTRATE_SERVER); } catch (AuthException | PermissionBackendException noAdmin) { return false; } } return true; }
/** * Returns the result of {@link #get(ListChangesOption...)} with all options included, except for the following: * - {@code CHECK} is omitted, to skip consistency checks. * - {@code SKIP_MERGEABLE} is omitted, so the {@code mergeable} bit is set. * - {@code SKIP_DIFFSTAT} is omitted to skip diffstat calculations. */ default ChangeInfo get() throws RestApiException { return get(EnumSet.complementOf(EnumSet.of( ListChangesOption.CHECK, ListChangesOption.SKIP_MERGEABLE, ListChangesOption.SKIP_DIFFSTAT))); } /** * Returns the result of {@link #get(ListChangesOption...)} with no options included. */ default ChangeInfo info() throws RestApiException { return get(EnumSet.noneOf(ListChangesOption.class)); } /** * Retrieves the change edit when it exists. * * @deprecated Replaced by {@link ChangeApi#edit()} in combination with {@link * ChangeApi#getEdit()}. */ default EditApi getEdit() throws RestApiException { return changeApi().edit(); }
import org.eclipse.jgit.revwalk.RevCommit; /** * Allows to modify message for new commits generated by submit strategies. * * Invoked by Gerrit when all information about new commit is already known such * as parent(s), tree hash, etc, but commit's message can still be modified. */ @ExtensionPoint public interface ChangeMessageModifier { /** * @param newCommitMessage * @param original * @param mergeTip * @param ctl * @return */ String onCommitBeingCreated(String newCommitMessage, RevCommit original, RevCommit mergeTip, ChangeControl ctl); } import org.eclipse.jgit.revwalk.RevCommit; /** * Allows to modify message for new commits generated by submit strategies. * * Invoked by Gerrit when all information about new commit is already known such * as parent(s), tree hash, etc, but commit's message can still be modified. */ @ExtensionPoint public interface ChangeMessageModifier { /** * @param newCommitMessage * @param original * @param mergeTip * @param ctl * @return */ String onSubmit(String newCommitMessage, RevCommit original, RevCommit mergeTip, Branch.NameKey destination); } } } throw new IllegalStateException(); } private void checkSubmitRulesAndState(ChangeSet cs) throws ResourceConflictException, OrmException { StringBuilder msgbuf = new StringBuilder(); List<Change.Id> problemChanges = new ArrayList<>(); for (PatchSet.Id id : cs.patchIds()) { try { ChangeData cd = changeDataFactory.create(db, id.getParentKey()); if (!cd.change().currentPatchSetId().equals(id)) { throw new ResourceConflictException( "Submission depends on revision " + id.get() + " of Change " + id.getParentKey().get() + ", but latest revision is " + cd.change().currentPatchSetId().get()); } if (cd.change().getStatus() != Change.Status.NEW) { throw new ResourceConflictException("Change " + cd.change().getChangeId() + " is in state " + cd.change().getStatus()); } else { records.put(cd.change().getId(), checkSubmitRule(cd)); } } catch (ResourceConflictException e) { } } throw new IllegalStateException(); } private void checkSubmitRulesAndState(ChangeSet cs) throws ResourceConflictException, OrmException { StringBuilder msgbuf =
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api.changes; import java.util.List; /** * Detailed information about who should be notified about an update. */ public class NotifyInfo { public List<String> accounts; /** * @param accounts may be either just a list of: account IDs, Full names, usernames, or emails. * It can also be a list of those in the format "Full name <email@example.com>" * or "Full name (<ID>)" */ public NotifyInfo(List<String> accounts) { this.accounts = accounts; } }
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api.changes; import java.util.List; /** * Detailed information about who should be notified about an update. */ public class NotifyInfo { public List<String> accounts; /** * @param accounts a list of account IDs, full names, or usernames. It can also be a list of * "Full name <email@example.com>" or "Full name (<ID>)" */ public NotifyInfo(List<String> accounts) { this.accounts = accounts; } }
addDraft(changeId, revId, comment); assertThat(gApi.changes().query("change:" + changeId + " has:draft").get()).hasSize(1); } @Test public void publishCommentsAllRevisions() throws Exception { PushOneCommit.Result result = createChange(); String changeId = result.getChangeId(); pushFactory .create(db, admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "initial content\n", changeId) .to("refs/heads/master"); PushOneCommit.Result r1 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "old boring content\n") .to("refs/for/master"); PushOneCommit.Result r2 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "new interesting\ncntent\n", r1.getChangeId()) .to("refs/for/master"); addDraft(r1.getChangeId(), r1.getCommit().getName(), comment); assertThat(gApi.changes().query("change:" + changeId + " has:draft").get()).hasSize(1); }
@Test public void publishCommentsAllRevisions() throws Exception { PushOneCommit.Result result = createChange(); String changeId = result.getChangeId(); pushFactory .create(db, admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "initial content\n", changeId) .to("refs/heads/master"); PushOneCommit.Result r1 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "old boring content\n") .to("refs/for/master"); PushOneCommit.Result r2 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "new interesting\ncntent\n", r1.getChangeId()) .to("refs/for/master"); addDraft(r1.getChangeId(), r1.getCommit().getName(), comment); assertThat(gApi.changes().query("change:" + changeId + " has:draft").get()).hasSize(1); }
protected void configure() { if (!noteDb.enabled()) { throw new ProvisionException("Gerrit is still running on ReviewDb: please migrate to NoteDb and then reload the multi-site plugin."); } Collection<Message> validationErrors = config.validate(); if (!validationErrors.isEmpty()) { throw new CreationException(validationErrors); } listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); DynamicItem.itemOf(binder(), BrokerSession.class); DynamicItem.bind(binder(), BrokerSession.class).to(BrokerSessionNoOp.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } install(kafkaForwardedEventRouterModule); install(kafkaBrokerForwarderModule); install(new ValidationModule(config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); }
import java.io.IOException; import java.util.Properties; /** * Wrapper around data passed from the installer. */ public class InstallerData { @VisibleForTesting static final ScopedStateStore.Key<InstallerData> CONTEXT_KEY = ScopedStateStore.createKey("installer.handoff.data", ScopedStateStore.Scope.WIZARD, InstallerData.class); public static final String PATH_FIRST_RUN_PROPERTIES = FileUtil.join("studio", "installer", "firstrun.properties"); @VisibleForTesting InstallerData(@Nullable String javaDir, @Nullable String androidSrc, @Nullable String androidDest) { myJavaDir = javaDir; myAndroidSrc = androidSrc; myAndroidDest = androidDest; } private static InstallerData parse() { Properties properties = readProperties(); return new InstallerData(getIfExists(properties, "jdk.dir"), getIfExists(properties, "androidsdk.repo"), properties.getProperty("androidsdk.dir")); } private static Properties readProperties() { Properties properties = new Properties(); try { // Read properties from file } catch (IOException e) { // Handle exception } return properties; } public void testEncode() { assertEquals("ab%2F$%C4%82%2512", CODEC.encode("ab/$\u0102%12", StandardCharsets.UTF_8)); } public void setGameField(int xPos, int yPos, int color) { if (field[xPos][yPos] == EMPTY) { if (color == WHITE_PLAYER) { field[xPos][yPos] = WHITE; } if (color == BLACK_PLAYER) { field[xPos][yPos] = BLACK; } } } public void someMethod() { try { // Kafka consumer subscribing to topic consumer.subscribe(Collections.singleton(topic)); while (!closed.get()) { ConsumerRecords<byte[], byte[]> consumerRecords = consumer.poll(Duration.ofMillis(configuration.kafkaSubscriber().getPollingInterval())); consumerRecords.forEach(this::processRecord); } } catch (WakeupException e) { // Ignore exception if closing if (!closed.get()) { throw e; } } catch (KafkaException e) { subscriberMetrics.incrementSubscriberFailedToPollMessages(); throw e; } finally { consumer.close(); } } }
subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (IOException e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (PermissionBackendException | OrmException e) { logger.atSevere().withCause(e).log( "Cannot handle message %s: [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } } catch (Exception e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", new String(consumerRecord.value(), UTF_8)); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); }
for (String src : delta) { Ref r = local.get(src); if (r != null) { n.put(src, r); } } local = n; } local = forProject.filter(local, git, RefFilterOptions.builder().setFilterMeta(true).build()); List<RemoteRefUpdate> remoteUpdatesList = pushAllRefs ? doPushAll(tn, local) : doPushDelta(local); ReplicationPushFilter pushFilter = replicationPushFilter.get(); remoteUpdatesList = pushFilter == null ? remoteUpdatesList : pushFilter.filter(projectName.get(), remoteUpdatesList); return remoteUpdatesList; } private List<RemoteRefUpdate> doPushAll(Transport tn, Map<String, Ref> local) throws NotSupportedException, TransportException, IOException { List<RemoteRefUpdate> cmds = new ArrayList<>(); boolean noPerms = !pool.isReplicatePermissions(); Map<String, Ref> remote = listRemote(tn); for (Ref src : local.values()) { if (!canPushRef(src.getName(), noPerms)) { continue; } // rest of the code } // rest of the code }
protected void configure() { DynamicItem.itemOf(binder(), BeforeReplicationPushFilter.class); DynamicItem.bind(binder(), BeforeReplicationPushFilter.class).to(BeforeReplicationPushFilterNoOP.class); }
return java.nio.file.Files.createTempDirectory(prefix); } @Test public void shouldLoadNotEmptyInitialReplicationConfig() throws Exception { FileBasedConfig replicationConfig = newReplicationConfig(); replicationConfig.setString("remote", "foo", "url", "ssh://git@git.somewhere.com/${name}"); replicationConfig.save(); autoReloadConfig = new AutoReloadConfigDecorator( sitePaths, destinationFactoryMock, Providers.of(replicationQueueMock), pluginDataPath, "replication", workQueueMock); assertThat(autoReloadConfig.getDestinations(FilterType.ALL)).isNotEmpty(); } @Test public void shouldAutoReloadReplicationConfig() throws Exception { FileBasedConfig replicationConfig = newReplicationConfig(); replicationConfig.setBoolean("gerrit", null, "autoReload", true); replicationConfig.setString("remote", "foo", "url", "ssh://git@git.foo.com/${name}"); replicationConfig.save(); autoReloadConfig = new AutoReloadConfigDecorator( sitePaths, destinationFactoryMock, Providers.of(replicationQueueMock), pluginDataPath, "replication", workQueueMock); autoReloadConfig.startup(workQueueMock); }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.index; import java.util.Optional; public class OnlineReindexMode { private static ThreadLocal<Boolean> isOnlineReindex = new ThreadLocal<>(); public static boolean get() { return Optional.ofNullable(isOnlineReindex.get()).orElse(Boolean.FALSE); } public static void begin() { isOnlineReindex.set(Boolean.TRUE); } public static void end() { isOnlineReindex.set(Boolean.FALSE); } }
public static boolean isActive() { return Optional.ofNullable(isOnlineReindex.get()).orElse(Boolean.FALSE); }
import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class JgitWrapper { private static final Logger log = LoggerFactory.getLogger(JgitWrapper.class); public static Optional<byte[]> getBlobAsBytes(Repository repository, String revision, String path) throws IOException { ObjectId objectId = repository.resolve(revision); if (objectId == null) { return Optional.empty(); } try (final TreeWalk w = TreeWalk.forPath(repository, path, parseCommit(repository, objectId).getTree())) { return Optional.ofNullable(w) .filter(walk -> (walk.getRawMode(0) & TYPE_MASK) == TYPE_FILE) .map(walk -> walk.getObjectId(0)) .flatMap(id -> readBlob(repository, id)); } } private static RevCommit parseCommit(Repository repository, ObjectId commit) throws IOException { try (final RevWalk walk = new RevWalk(repository)) { walk.setRetainBody(true); return walk.parseCommit(commit); } } private static Optional<byte[]> readBlob(Repository repository, ObjectId id) { // implementation } }
// You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.quota; public class QuotaGroupDefinitions { public static final String REPOSITORY_SIZE_GROUP = "/repository:size"; private QuotaGroupDefinitions() {} }
private static boolean isContentTooLargeForDisplay(String content) { int lines = 0; int nl = -1; while (true) { nl = nextLineBreak(content, nl + 1, content.length()); if (nl < 0) { return false; } else if (++lines == MAX_LINE_COUNT) { return true; } } }
private static boolean isContentTooLargeForDisplay(String content) { Matcher m = Pattern.compile("\r\n|\r|\n").matcher(content); int lines = 0; while (m.find() && lines < MAX_LINE_COUNT) { lines++; } return lines >= MAX_LINE_COUNT; }
at, Duration.ofMillis(cfg.getTimeUnit("retry", at.name(), "timeout", SECONDS.toMillis(defaultTimeout.getSeconds()), MILLISECONDS))); this.waitStrategy = WaitStrategies.join( WaitStrategies.exponentialWait( cfg.getTimeUnit("retry", null, "maxWait", SECONDS.toMillis(5), MILLISECONDS), MILLISECONDS), WaitStrategies.randomWait(50, MILLISECONDS)); this.overwriteDefaultRetryerStrategySetup = overwriteDefaultRetryerStrategySetup; this.retryWithTraceOnFailure = cfg.getBoolean("retry", "retryWithTraceOnFailure", false);
package com.google.gerrit.server.logging; import com.google.auto.value.AutoValue; import java.util.Optional; /** * The record of an operation for which the execution time was measured. * Metadata to provide additional context can be included by provided a {@link Metadata} instance. */ @AutoValue public abstract class PerformanceLogRecord { /** * Creates a performance log record without meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs) { return new AutoValue_PerformanceLogRecord(operation, durationMs, Optional.empty()); } /** * Creates a performance log record with meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @param metadata the metadata to provide additional context * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs, Metadata metadata) { return new AutoValue_PerformanceLogRecord(operation, durationMs, Optional.of(metadata)); } /** * Returns the name of the operation. * * @return the operation name */ public abstract String getOperation(); /** * Returns the execution time in milliseconds. * * @return the execution time */ public abstract long getDurationMs(); /** * Returns the metadata associated with the performance log record. * * @return the metadata */ public abstract Optional<Metadata> getMetadata(); /** * Metadata to provide additional context for the performance log record. */ @AutoValue public abstract static class Metadata { /** * Creates a metadata instance. * * @param key the metadata key * @param value the metadata value * @return the metadata instance */ public static Metadata create(String key, String value) { return new AutoValue_PerformanceLogRecord_Metadata(key, value); } /** * Returns the metadata key. * * @return the metadata key */ public abstract String getKey(); /** * Returns the metadata value. * * @return the metadata value */ public abstract String getValue
public abstract static class Builder { public abstract Builder listener(RetryListener listener); public abstract Builder timeout(Duration timeout); public abstract Options build(); } @VisibleForTesting @Singleton public static class Metrics { final Counter1<ActionType> attemptCounts; final Counter1<ActionType> timeoutCount; @Inject Metrics(MetricMaker metricMaker) { Field<ActionType> actionTypeField = Field.ofEnum( ActionType.class, "action_type", (metadataBuilder, fieldValue) -> metadataBuilder.actionType(fieldValue.name()) ).build(); attemptCounts = metricMaker.newCounter( "action/retry_attempt_count", new Description("Number of retry attempts made by RetryHelper to execute an action" + " (0 == single attempt, no retry)") .setCumulative() .setUnit("attempts"), actionTypeField ); timeoutCount = metricMaker.newCounter( "action/retry_timeout_count", new Description("Number of action executions of RetryHelper that ultimately timed out") .setCumulative() .setUnit("attempts"), actionTypeField ); } }
public void setup() { projectCreationListener = new TraceValidatingProjectCreationValidationListener(); projectCreationListenerRegistrationHandle = projectCreationValidationListeners.add("gerrit", projectCreationListener); commitValidationListener = new TraceValidatingCommitValidationListener(); commitValidationRegistrationHandle = commitValidationListeners.add("gerrit", commitValidationListener); changeIndexedListener = new TraceChangeIndexedListener(); changeIndexedListenerRegistrationHandle = changeIndexedListeners.add("gerrit", changeIndexedListener); testPerformanceLogger = new TestPerformanceLogger(); performanceLoggerRegistrationHandle = performanceLoggers.add("gerrit", testPerformanceLogger); }
package com.google.gerrit.util.cli; import java.util.Optional; /** * Classes that define command-line options by using the {@link org.kohsuke.args4j.Option} * annotation can implement this class to accept and handle unknown options. * * <p>If a user specifies an unknown option and this unknown options doesn't get accepted, the * parsing of the command-line options fails and the user gets an error (this is the default * behavior if classes do not implement this interface). */ public interface UnknownOptionHandler { /** * Whether an unknown option should be accepted. * * <p>If an unknown option is not accepted, the parsing of the command-line options fails and the * user gets an error. * * <p>This method can be used to ignore unknown options (without failure for the user) or to * handle them in a custom way. * * @param option the unknown option * @return {@code true} if the unknown option should be accepted, {@code false} otherwise */ boolean acceptUnknownOption(String option); }
boolean accept(String name, String value);
.buildRepeatable(a -> { if (a.getAccount().getMetaId() == null) { return ImmutableList.of(); } return ImmutableList.of( RefState.create( RefNames.refsUsers(a.getAccount().getId()), ObjectId.fromString(a.getAccount().getMetaId()) ) .toByteArray(new AllUsersName(AllUsersNameProvider.DEFAULT)) ); }); /** * All note values of all external IDs that were used in the course of indexing this document. * * <p>Emitted as UTF-8 encoded strings of the form {@code [hex sha of external ID]:[hex sha of * note blob]}, or with other words {@code [note ID]:[note data ID]}. */
Ref ref = repo.exactRef(RefNames.refsUsers(id)); return ref != null; } for (Map.Entry<Project.NameKey, RefState> e : RefState.parseStates(result.get().getValue(AccountField.REF_STATE)).entries()) { Project.NameKey repoName = e.getKey().get().equals(AllUsersNameProvider.DEFAULT) ? allUsersName : e.getKey(); try (Repository repo = repoManager.openRepository(repoName)) { if (!e.getValue().match(repo)) { return true; } } } Set<ExternalId> extIds = externalIds.byAccount(id); ListMultimap<ObjectId, ObjectId> extIdStates = parseExternalIdStates(result.get().getValue(AccountField.EXTERNAL_ID_STATE)); if (extIdStates.size() != extIds.size()) {
stateLog.error(String.format("source project %s not available", project), err, state); return; } } synchronized (stateLock) { PushOne e = pending.get(uri); if (e == null) { e = opFactory.create(project, uri); addRef(e, ref); e.addState(ref, state); pool.schedule(e, now ? 0 : config.getDelay(), TimeUnit.SECONDS); pending.put(uri, e); eventsStorage.persist(project.get(), ref, e.getURI()); } else if (!e.getRefs().contains(ref)) { addRef(e, ref); e.addState(ref, state); } state.increasePushTaskCount(project.get(), ref); repLog.info("scheduled {}:{} => {} to run after {}s", project, ref, e, config.getDelay()); }
private static Node processNodeWithoutAttributes(Node node, Document doc) { Node localNode = node; Element elem = null; String URI = Strings.nullToEmpty(node.getNamespaceURI()); String name = node.getNodeName().toLowerCase(); if (name.equals("#text")) { localNode = processTextNode(node, doc); } else if (name.length() == 1) { switch (name.charAt(0)) { case 'b': try { localNode = doc.renameNode(localNode, URI, "strong"); } catch (DOMException ex) { // do nothing cannot rename this node type (text node) } break; case 'i': try { localNode = doc.renameNode(localNode, URI, "em"); } catch (DOMException ex) { // do nothing cannot rename this node type (text node) } break; case 'u': if (localNode instanceof Element) { try { localNode = doc.renameNode(localNode, URI, "u"); } catch (DOMException ex) { // do nothing cannot rename this node type (text node) } } break; } } return localNode; } public boolean isRepresentationsResource() { boolean isRepresentationsResource = false; try { URI uri = resource.getURI(); isRepresentationsResource = uri != null && new FileQuery(uri.fileExtension()).isSessionResourceFile(); } catch (IllegalStateException e) { // Silent catch: if an issue occurred while getting this Resource's // URI, then it will not be considered as a representation resource } isRepresentationsResource = isRepresentationsResource || resource instanceof AirdResource; if (!isRepresentationsResource && !resource.getContents().isEmpty()) { for (EObject contentEObject : resource.getContents()) { if (contentEObject instanceof DAnalysis) { isRepresentationsResource = true; break; } } } return isRepresentationsResource; } if (null == selectedFile) { monitor.worked(1); result.add(new Status(IStatus.ERROR, Activator.PLUGIN_ID, Messages.DeployCreationMenuModelHandler_ElementNotAFile + selectedElement.toString())); } else { String fileName = selectedFile.getFullPath().removeFileExtension().lastSegment(); monitor
public void delete(String project, String ref, URIish uri) { String eventKey = getEventKey(getEventJson(project, ref, uri)); try { logger.atFiner().log("**DELETE** %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); } }
if (watchedTypes.contains(type)) { matching.bcc.accounts.add(accountId); } logger.atFine().log("Added account %s as watcher", accountId); return true; } catch (QueryParseException e) { logger.atWarning().withCause(e).log("Account %s has invalid filter in project watch %s: %s", accountId, key, e.getMessage()); } return false;
@VisibleForTesting private ImmutableList<RefUpdatedEvent> getRefUpdatedEvents(String project, String refName, int expectedSize) { String key = refEventKey(RefUpdatedEvent.TYPE, project, refName); if (expectedSize == 0) { assertThat(recordedEvents).doesNotContainKey(key); return ImmutableList.of(); } assertThat(recordedEvents).containsKey(key); ImmutableList<RefUpdatedEvent> events = FluentIterable.from(recordedEvents.get(key)) .transform(RefUpdatedEvent.class::cast) .toList(); assertThat(events).hasSize(expectedSize); return events; } @VisibleForTesting public ImmutableList<ChangeMergedEvent> getChangeMergedEvents(String project, String branch, int expectedSize) { String key = refEventKey(ChangeMergedEvent.TYPE, project, branch); if (expectedSize == 0) { assertThat(recordedEvents).doesNotContainKey(key); return ImmutableList.of(); } assertThat(recordedEvents).containsKey(key); ImmutableList<ChangeMergedEvent> events = FluentIterable.from(recordedEvents.get(key)) .transform(ChangeMergedEvent.class::cast) .toList(); assertThat(events).hasSize(expectedSize); return events; }
assertThat(cd.change().getStatus()).isEqualTo(Change.Status.MERGED); assertSubmitApproval(psId); assertThat(cd.patchSets()).hasSize(1); assertThat(cd.patchSet(psId).getRevision().get()).isEqualTo(c.name()); @Test public void correctNewRevOnMergeByPushToBranch() throws Exception { grant(project, "refs/heads/master", Permission.PUSH); PushOneCommit.Result r1 = push("refs/for/master", PushOneCommit.SUBJECT, "one.txt", "One"); PushOneCommit.Result r2 = push("refs/for/master", PushOneCommit.SUBJECT, "two.txt", "Two"); startEventRecorder(); git().push().setRefSpecs(new RefSpec(r2.getCommit().name() + ":refs/heads/master")).call(); List<ChangeMergedEvent> changeMergedEvents = eventRecorder.getChangeMergedEvents(project.get(), "refs/heads/master", 2); assertThat(changeMergedEvents.get(0).newRev).isEqualTo(r2.getPatchSet().getRevision().get()); }
import org.eclipse.jdt.core.IJavaProject; import org.eclipse.jdt.core.IModuleDescription; import org.eclipse.jdt.internal.launching.LaunchingMessages; import org.eclipse.jdt.launching.sourcelookup.advanced.AdvancedJavaLaunchDelegate; import org.eclipse.osgi.util.NLS; /** * A launch delegate for launching local Java applications. * <p> * Clients may subclass and instantiate this class. * </p> * * @see AdvancedJavaLaunchDelegate * @since 3.1 */ public class JavaLaunchDelegate extends AbstractJavaLaunchConfigurationDelegate { /* (non-Javadoc) * @see org.eclipse.debug.core.model.ILaunchConfigurationDelegate#launch(org.eclipse.debug.core.ILaunchConfiguration, java.lang.String, org.eclipse.debug.core.ILaunch, org.eclipse.core.runtime.IProgressMonitor) */ @Override public void launch(ILaunchConfiguration configuration, String mode, ILaunch launch, IProgressMonitor monitor) throws CoreException { if (monitor == null) { monitor = new NullProgressMonitor(); } } } public void test_getRootDirectories() { Iterable<Path> rootDirectories = fileSystem.getRootDirectories(); Map<Path, Boolean> pathMap = new HashMap<>(); rootDirectories.forEach(path -> pathMap.put(path, true)); assertEquals(1, pathMap.size()); assertTrue(pathMap.get(Paths.get("/"))); } private void handleEvent(RefEvent refEvent) { Set<Map<String, String>> properties = propertyExtractor.extractFrom(refEvent); for (Map<String, String> propertiesMap : properties) { Collection<ActionRequest> actions = ruleBase.actionRequestsFor(propertiesMap); if (!actions.isEmpty()) { actionExecutor.execute(actions, propertiesMap); } } } uri); } else { if (canceledWhileRunning.get()) { logCanceledWhileRunningException(e); } else { repLog.error("Cannot replicate to {}", uri, e); pool.reschedule(this, Destination.RetryReason.TRANSPORT_ERROR); } } } catch (IOException e) { stateLog.error("Cannot replicate to " + uri, e, getStatesAsArray()); } catch (PermissionBackendException | RuntimeException | Error e) { stateLog.error("Unexpected error during replication to " + uri, e, getStatesAsArray()); } finally { pool.notifyFinished(this); if (git != null) { git
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; import org.eclipse.jgit.transport.RemoteRefUpdate; /** * Filter that is invoked before list of remote ref updates is pushed to remote instance. It can be * used to filter out unwanted updates. */ @ExtensionPoint public interface ReplicationPushFilter { public List<RemoteRefUpdate> filter(String projectName, List<RemoteRefUpdate> remoteUpdatesList); }
import java.util.Set; import javax.servlet.http.HttpServletRequest; class AccountSecurityImpl extends BaseServiceImplementation implements AccountSecurity { private final Logger log = LoggerFactory.getLogger(getClass()); private final GerritServer server; private final ContactStore contactStore; private final RegisterNewEmailSender.Factory emailSenderFactory; @Inject AccountSecurityImpl(final SchemaFactory<ReviewDb> sf, final GerritServer gs, final ContactStore cs, final RegisterNewEmailSender.Factory esf) { super(sf); server = gs; contactStore = cs; emailSenderFactory = esf; } public void mySshKeys(final AsyncCallback<List<AccountSshKey>> callback) { run(callback, new Action<List<AccountSshKey>>() { public List<AccountSshKey> run(ReviewDb db) throws OrmException { return db.accountSshKeys().byAccount(Common.getAccountId()).toList(); } }); } public void addSshKey(final String keyText, final AsyncCallback<AccountSshKey> callback) { run(callback, new Action<AccountSshKey>() { public AccountSshKey run(final ReviewDb db) throws OrmException, Failure { // implementation } }); } }
private Renderer renderer(String templateName) { return args.soySauce .renderTemplate("com.google.gerrit.server.mail.template." + templateName) .setData(soyContext); }
// limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.server.util.SystemLog; import com.google.inject.Inject; import com.google.inject.Singleton; import org.apache.log4j.PatternLayout; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Log4jSharedRefLogger extends LibModuleLogFile implements SharedRefLogger { private static final String LOG_NAME = "sharedref_log"; private final Logger sharedRefDBLog; @Inject public Log4jSharedRefLogger(SystemLog systemLog) { super(systemLog, LOG_NAME, new PatternLayout("[%d{ISO8601}] [%t] %-5p : %m%n")); sharedRefDBLog = LoggerFactory.getLogger(LOG_NAME); } @Override public void log(String project, Ref currRef, ObjectId newRefValue) { sharedRefDBLog.info( "project:{}|ref:{}|oldId:{}|newId:{}", project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName()); } }
public void logRefUpdate(String project, Ref currRef, ObjectId newRefValue) { sharedRefDBLog.info("project:{}|ref:{}|oldId:{}|newId:{}", project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName()); }
public void logProjectDelete(String project) { sharedRefDBLog.info("project:{}|DELETED", project); }
public void onProjectDeleted(Event event) { String projectName = event.getProjectName(); logger.atInfo().log("Deleting project '%s'. Will perform a cleanup in Shared-Ref database.", projectName); try { sharedDb.removeProject(projectName); sharedRefLogger.logDeletion(projectName); } catch (IOException e) { validationMetrics.incrementSplitBrain(); logger.atSevere().withCause(e).log("Project '%s' deleted from GIT but it was not able to cleanup from Shared-Ref database", projectName); } }
String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been " + "persisted locally but not in SharedRef the value %s", projectName, refPair.getName(), refPair.putValue); boolean succeeded; try { succeeded = sharedRefDb.compareAndPut(projectName, refPair.compareRef, refPair.putValue); sharedRefLogger.log(projectName, refPair.compareRef, refPair.putValue); } catch (IOException e) { throw new SharedDbSplitBrainException(errorMessage, e); } if (!succeeded) { throw new SharedDbSplitBrainException(errorMessage); } protected RefPair compareAndGetLatestLocalRef(RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist( new SharedLock(projectName, refName, refEnforcementPolicy, sharedRefDb)); RefPair latestRefPair = sharedRefDb.get(projectName, refName); if (latestRefPair == null) { throw new OutOfSyncException( String.format("The ref '%s' does not exist in SharedRef", refName)); } if (!latestRefPair.compareRef.equals(refPair.compareRef)) { throw new OutOfSyncException( String.format("The ref '%s' is out of sync in SharedRef", refName)); } return latestRefPair; }
private String replaceInUrl(String placeholder, String url, String replacement, boolean lowerCase) { if (url == null || replacement == null || !url.contains(placeholder)) { return url; } if (lowerCase) { replacement = replacement.toLowerCase(); } // as we can't assume anything of 'replacement', we're URL encoding it return url.replace(placeholder, Url.encode(replacement)); }
public void cancel() { repLog.info("Replication [{}] to {} was canceled", IdGenerator.format(id), getURI()); canceledByReplication(); pool.pushWasCanceled(this); }
public void setCanceledWhileRunning() { repLog.info("Replication [{}] to {} was canceled while being executed", IdGenerator.format(id), getURI()); canceledWhileRunning.set(true); }
public void logRefUpdate(String project, Ref currRef, ObjectId newRefValue) { try (Repository repository = gitRepositoryManager.openRepository(new Project.NameKey(project))) { RevWalk walk = new RevWalk(repository); if (!ObjectId.zeroId().equals(newRefValue)) { RevCommit commit = walk.parseCommit(newRefValue); sharedRefDBLog.info(gson.toJson(new SharedRefLogEntry.UpdateRef( project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName(), CommonConverters.toGitPerson(commit.getCommitterIdent()), commit.getFullMessage()))); } else { sharedRefDBLog.info(gson.toJson(new SharedRefLogEntry.DeleteRef( project, currRef.getName(), currRef.getObjectId().getName()))); } } catch (IOException e) { logger.atSevere().withCause(e).log( "Cannot log sharedRefDB interaction for ref %s on project %s", currRef.getName(), project); } }
String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } public static class DeleteProject extends SharedRefLogEntry { public String refName; public String oldId; DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } }
private int getInt(PluginConfig cfg, String name, int defaultValue) { try { return cfg.getInt(name, defaultValue); } catch (IllegalArgumentException e) { log.error(String.format("invalid value for %s; using default value %d", name, defaultValue)); return defaultValue; } } replicateAllOnPluginStart = config.getBoolean("gerrit", "replicateOnStartup", true); defaultForceUpdate = config.getBoolean("gerrit", "defaultForceUpdate", false); sshCommandTimeout = (int) ConfigUtil.getTimeUnit(config, "gerrit", null, "sshCommandTimeout", 30, SECONDS); sshConnectionTimeout = (int) SECONDS.toMillis(ConfigUtil.getTimeUnit(config, "gerrit", null, "sshConnectionTimeout", 120, SECONDS)); ImmutableList.Builder<Destination> dest = ImmutableList.builder(); for (RemoteConfig c : allRemotes(config)) { if (c.getURIs().isEmpty()) { continue; } for (RefSpec ref : c.getPushRefSpecs()) { if (ref.getDestination() == null) { ref.setDestination(ref.getSource()); } } if (c.getPushRefSpecs().isEmpty()) { c.addPushRefSpec( new RefSpec() .setSourceDestination("refs/*", "refs/*") .setForceUpdate(defaultForceUpdate) ); } }
private ImmutableSet<String> parseRequestTypes(String traceId) { return ImmutableSet.copyOf(cfg.getStringList("tracing", traceId, "requestType")); } private ImmutableSet<Account.Id> parseAccounts(String traceId) { ImmutableSet.Builder<Account.Id> accountIds = ImmutableSet.builder(); String[] accounts = cfg.getStringList("tracing", traceId, "account"); for (String account : accounts) { Optional<Account.Id> accountId = Account.Id.tryParse(account); if (!accountId.isPresent()) { throw new IllegalArgumentException( String.format("Invalid tracing config ('tracing.%s.account = %s'): invalid account ID", traceId, account)); } accountIds.add(accountId.get()); } return accountIds.build(); } private ImmutableSet<Pattern> parseProjectPatterns(String traceId) { ImmutableSet.Builder<Pattern> projectPatterns = ImmutableSet.builder(); String[] projectPatternRegExs = cfg.getStringList("tracing", traceId, "projectPattern"); for (String projectPatternRegEx : projectPatternRegExs) { try { Pattern pattern = Pattern.compile(projectPatternRegEx); projectPatterns.add(pattern); } catch (PatternSyntaxException e) { throw new IllegalArgumentException( String.format("Invalid tracing config ('tracing.%s.projectPattern = %s'): invalid regex", traceId, projectPatternRegEx)); } } return projectPatterns.build(); }
boolean matches(RequestInfo requestInfo) { if (requestTypes().stream().noneMatch(type -> type.equalsIgnoreCase(requestInfo.requestType()))) { return false; } if (!accountIds().isEmpty()) { try { if (accountIds().stream().noneMatch(id -> id.equals(requestInfo.callingUser().getAccountId()))) { return false; } } catch (UnsupportedOperationException e) { // calling user is not logged in return false; } } if (!projectPatterns().isEmpty()) { if (!requestInfo.project().isPresent()) { // request is not for a project return false; } if (projectPatterns().stream().noneMatch(p -> p.matcher(requestInfo.project().get().get()).matches())) { return false; } } return true; }
/** Java API to interact with single {@code Check}s. */ public interface CheckApi { /** Returns a {@link CheckInfo} for the scoped resource with the given options. */ CheckInfo get(ListChecksOption... options) throws RestApiException; /** Updates a check and returns the {@link CheckInfo} for the updated resource. */ CheckInfo update(CheckInput input) throws RestApiException; /** Reruns the check and returns the {@link CheckInfo} for the updated check. Input ignores "state". */ CheckInfo rerun(CheckInput input) throws RestApiException; /** * A default implementation which allows source compatibility when adding new methods to the * interface. */ class NotImplemented implements CheckApi { @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo update(CheckInput input) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo rerun(CheckInput input) throws RestApiException { throw new NotImplementedException(); } } }
try (MetaDataUpdate md = metaDataUpdateUser.create(rsrc.getNameKey())) { ProjectConfig config = ProjectConfig.read(md); setAccess.validateChanges(config, removals, additions); setAccess.applyChanges(config, removals, additions); try { setAccess.setParentName(identifiedUser.get(), config, rsrc.getNameKey(), newParentProjectName, false); } catch (AuthException e) { throw new IllegalStateException(e); } md.setMessage("Review access change"); md.setInsertChangeId(true); Change.Id changeId = new Change.Id(seq.nextChangeId()); RevCommit commit = config.commitToNewRef(md, new PatchSet.Id(changeId, Change.INITIAL_PATCH_SET_ID).toRefName()); try (ObjectInserter objInserter = md.getRepository().newObjectInserter(); ObjectReader objReader = objInserter.newReader(); RevWalk rw = new RevWalk(objReader); BatchUpdate bu = updateFactory.create(db.get(), config.getProject().getNameKey(), projectControl.getUser(),
import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.ConfigInvalidException; @Singleton public class RerunCheck implements RestModifyView<CheckResource, CheckInput> { private final PostCheck postCheck; @Inject RerunCheck(PostCheck postCheck) { this.postCheck = postCheck; } @Override public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().get(); } else if (!checkResource.getCheckerUuid().get().equals(input.checkerUuid)) { throw new BadRequestException( String.format( "checker UUID in input must either be null or the same as on the resource:\n" + "input: %s\n" + "resource: %s", input.checkerUuid, checkResource.getCheckerUuid().get())); } return postCheck.apply(checkResource, input); } }
import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckInput; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.testing.TestTimeUtil; import com.google.inject.Inject; import java.sql.Timestamp; import java.time.Instant; import java.util.concurrent.TimeUnit; import org.junit.After; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void testRerunCheck() { // Test code goes here } }
import com.google.gerrit.testing.TestTimeUtil; import com.google.inject.Inject; import java.sql.Timestamp; import java.time.Instant; import java.util.concurrent.TimeUnit; import org.junit.After; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; // Test code continues... } }
public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } }
@Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void rerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); }
CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); @Test public void rerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); }
Fixed Code: ```java PermissionBackend permissionBackend; ExternalIds externalIds; @ServerInitiated Provider<AccountsUpdate> accountsUpdateProvider; SshKeyCache sshKeyCache; Realm realm; public MyClass(Self self, PermissionBackend permissionBackend, ExternalIds externalIds, @ServerInitiated Provider<AccountsUpdate> accountsUpdateProvider, SshKeyCache sshKeyCache, Realm realm) { this.self = self; this.permissionBackend = permissionBackend; this.externalIds = externalIds; this.accountsUpdateProvider = accountsUpdateProvider; this.sshKeyCache = sshKeyCache; this.realm = realm; } @Override public String apply(AccountResource rsrc, UsernameInput input) throws RestApiException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } if (!realm.allowsEdit(AccountFieldName.USER_NAME)) { throw new MethodNotAllowedException("realm does not allow editing username"); } Account.Id accountId = rsrc.getUser().getAccountId(); if (!externalIds.byAccount(accountId, SCHEME_USERNAME).isEmpty()) { throw new MethodNotAllowedException("Username cannot be changed."); } // rest of the code } ```
public String apply(AccountResource rsrc, UsernameInput input) throws AuthException, MethodNotAllowedException, UnprocessableEntityException, ResourceConflictException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } if (!realm.allowsEdit(AccountFieldName.USER_NAME)) { throw new MethodNotAllowedException("realm does not allow editing username"); } if (input == null) { input = new UsernameInput(); } Account.Id accountId = rsrc.getUser().getAccountId(); if (!externalIds.byAccount(accountId, SCHEME_USERNAME).isEmpty()) { throw new MethodNotAllowedException("Username cannot be changed."); } if (Strings.isNullOrEmpty(input.username)) { return input.username; } if (!ExternalId.isValidUsername(input.username)) { throw new UnprocessableEntityException("Invalid username."); } // Rest of the code... }
@Nullable public Timestamp finished; /** Timestamp of when this check was created. */ public Timestamp created; /** Timestamp of when this check was last updated. */ public Timestamp updated; /** Name of the checker that produced this check. */ public String checkerName; /** Status of the checker that produced this check. */ public CheckerStatus checkerStatus; /** Blocking conditions that apply to this check. */ public Set<BlockingCondition> blocking; /** Description of the checker that produced this check */ public String description; @Override public boolean equals(Object o) { if (!(o instanceof CheckInfo)) { return false; } CheckInfo other = (CheckInfo) o; return Objects.equals(other.repository, repository) && Objects.equals(other.changeNumber, changeNumber) && Objects.equals(other.patchSetId, patchSetId) && Objects.equals(other.checkerUuid, checkerUuid) && Objects.equals(other.state, state) && Objects.equals(other.message, message) && Objects.equals(other.url, url) && Objects.equals(other.started, started) && Objects.equals(other.finished, finished) && Objects.equals(other.created, created) && Objects.equals(other.updated, updated) && Objects.equals(other.checkerName, checkerName) && Objects.equals(other.checkerStatus, checkerStatus) && Objects.equals(other.blocking, blocking) && Objects.equals(other.description, description); }
String name = paths[i].replaceAll("\\*", ".*"); //$NON-NLS-1$ //$NON-NLS-2$ for (int relativeQuark : quarks) { try { for (int quark : fStateSystem.getSubAttributes(relativeQuark, false, name)) { subQuarks.add(quark); } } catch (AttributeNotFoundException e) { /** Nothing to do */ } } quarks = subQuarks; i++; } return quarks; } public XmlXYViewer(@Nullable Composite parent, XmlViewInfo viewInfo) { super(parent, Messages.XmlXYViewer_DefaultViewerTitle, Messages.XmlXYViewer_DefaultXAxis, Messages.XmlXYViewer_DefaultYAxis); fViewInfo = viewInfo; } @Override protected void updateData(long start, long end, int nb, @Nullable IProgressMonitor monitor) { ITmfXmlStateAttribute display = fDisplay; ITmfXmlStateAttribute seriesName = fSeriesName; OrmException, IOException, ConfigInvalidException { if (input == null) { input = new AccountInput(); } if (input.username != null && !username.equals(input.username)) { throw new BadRequestException("username must match URL"); } if (!username.matches(Account.USER_NAME_PATTERN)) { throw new BadRequestException("Username '" + username + "' must comply with [" + USER_NAME_PATTERN + "] pattern."); } Set<AccountGroup.Id> groups = parseGroups(input.groups); Account.Id id = new Account.Id(db.nextAccountId()); ExternalId extUser = ExternalId.createUsername(username, id, input.httpPassword); if (db.accountExternalIds().get(extUser.key().asAccountExternalIdKey()) != null) { throw new ResourceConflictException("username '" + username + "' already exists"); } if (input.email != null) { if (db.accountExternalIds() .get(ExternalId.Key.create(SCHEME_MAILTO, input.email).asAccountExternalIdKey()) != null) { throw new ResourceConflictException("email '" + input.email + "' already exists"); } } Account account = new Account(id, TimeUtil.nowTs()); account.setFullName(input.name); account.setPreferredEmail(input.email); account.setUserName(username); account.setActive(true); account.setExternalIds(ImmutableList.of(extUser)); account.setGroups(groups
} if (options.contains(FillOptions.STATUS)) { info.status = account.getStatus(); } if (options.contains(FillOptions.AVATARS)) { AvatarProvider ap = avatar.get(); if (ap != null) { info.avatars = new ArrayList<>(); IdentifiedUser user = userFactory.create(account.getId()); addAvatar(ap, info, user, AvatarInfo.DEFAULT_SIZE); if (!info.avatars.isEmpty()) { addAvatar(ap, info, user, 56); addAvatar(ap, info, user, 100); addAvatar(ap, info, user, 120); } } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.NotSupportedException; import org.eclipse.jgit.errors.TransportException; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; public interface TransportFactory { Transport open(Repository local, URIish uri) throws NotSupportedException, TransportException; }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.NotSupportedException; import org.eclipse.jgit.errors.TransportException; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; public class TransportFactoryImpl implements TransportFactory { @Override public Transport open(Repository git, URIish uri) throws NotSupportedException, TransportException { return Transport.open(git, uri); } }
import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.transport.FetchConnection; import org.eclipse.jgit.transport.PushConnection; import org.eclipse.jgit.transport.PushResult; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.RemoteRefUpdate; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; import org.eclipse.jgit.util.FS; import org.junit.Before; import org.junit.Test; public class PushOneTest { private GitRepositoryManager gitRepositoryManagerMock; private Repository repositoryMock; private PermissionBackend permissionBackendMock; private PermissionBackend.WithUser withUserMock; private PermissionBackend.ForProject forProjectMock; private Destination destinationMock; private RemoteConfig remoteConfigMock; private RefSpec refSpecMock; private CredentialsFactory credentialsFactory; private PerThreadRequestScope.Scoper threadRequestScoperMock; private ReplicationQueue replicationQueueMock; private IdGenerator idGeneratorMock; private ReplicationStateListeners replicationStateListenersMock; private ReplicationMetrics replicationMetricsMock; private Timer1.Context timerContextMock; private ProjectCache projectCacheMock; private RunwayStatus statusMock; private TransportFactory transportFactoryMock; private Transport transportMock; private FetchConnection fetchConnection; private PushConnection pushConnection; private ProjectState projectStateMock; }
verify(transportMock); } private PushOne createPushOne(DynamicItem<ReplicationPushFilter> replicationPushFilter) { PushOne push = new PushOne( gitRepositoryManagerMock, permissionBackendMock, destinationMock, remoteConfigMock, credentialsFactory, threadRequestScoperMock, replicationQueueMock, idGeneratorMock, replicationStateListenersMock, replicationMetricsMock, projectCacheMock, transportFactoryMock, projectNameKey, urish); push.setReplicationPushFilter(replicationPushFilter); return push; } private void waitUntilFinished() throws InterruptedException { while (!isCallFinished.get()) { Thread.sleep(100); } } private void setupProjectCacheMock() throws IOException { projectCacheMock = createNiceMock(ProjectCache.class); expect(projectCacheMock.checkedGet(projectNameKey)).andReturn(projectStateMock); } private void setupTransportMock() throws NotSupportedException, TransportException { transportMock = createNiceMock(Transport.class); expect(transportMock.openFetch()).andReturn(fetchConnection); transportFactoryMock = createNiceMock(TransportFactory.class); expect(transportFactoryMock.open(repositoryMock, urish)).andReturn(transportMock).anyTimes(); } private void setupReplicationMetricsMock() { replicationMetricsMock = createNiceMock(ReplicationMetrics.class); }
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.client.admin; import com.google.gerrit.client.Gerrit; import com.google.gerrit.client.ui.Hyperlink; import com.google.gerrit.reviewdb.client.Project; import com.google.gwt.http.client.URL; abstract class PaginatedProjectScreen extends ProjectScreen { protected int pageSize; protected String match; protected int start; public PaginatedProjectScreen(Project.NameKey toShow) { super(toShow); pageSize = Gerrit.getUserPreferences().changesPerPage(); } protected void parseToken(String token) { for (String kvPair : token.split("[,;&/?]")) { String[] kv = kvPair.split("=", 2); if (kv.length != 2 || kv[0].isEmpty()) { continue; } if ("filter".equals(kv[0])) { match = URL.decodeQueryString(kv[1]); } } } } class PluginUtils { public static String getGerritPluginName(File srcFile) { String fileName = srcFile.getName(); if (isJarPlugin(fileName)) { JarFile jarFile = new JarFile(srcFile); try { return jarFile.getManifest().getMainAttributes().getValue("Gerrit-PluginName"); } finally { jarFile.close(); } } if (isJsPlugin(fileName)) { return fileName.substring(0, fileName.length() - 3); } return null; } public static Multimap<String, File> asMultimap(List<File> plugins) throws IOException { Multimap<String, File> map = LinkedHashMultimap.create(); for (File srcFile : plugins) { map.put(Objects.firstNonNull(getGerritPluginName(srcFile), nameOf(srcFile)), srcFile); } return map; } private static boolean isJarPlugin(String name) { return isPlugin(name, "jar"); } private static boolean isJsPlugin(String name) { return isPlugin(name, "js"); } private static boolean isPlugin(String name, String extension) { return name.toLowerCase().endsWith("." + extension);
private boolean compareField(Object obj, Object expectedObj) { return obj != null ? obj.equals(expectedObj) : expectedObj == null; }
public GitPerson committer; public String comment; UpdateRef(String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } public static class DeleteProject extends SharedRefLogEntry { public String refName; public String oldId; DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } }
public String comment; public UpdateRef(String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } public static class DeleteProject extends SharedRefLogEntry { public String refName; public String oldId; DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } }
// limitations under the License. package com.google.gerrit.plugins.checks.api; import com.google.gerrit.exceptions.StorageException; import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.ConfigInvalidException; @Singleton public class RerunCheck implements RestModifyView<CheckResource, CheckInput> { private final PostCheck postCheck; @Inject RerunCheck(PostCheck postCheck) { this.postCheck = postCheck; } @Override public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().get(); } else if (!checkResource.getCheckerUuid().get().equals(input.checkerUuid)) { throw new BadRequestException("Invalid checker UUID"); } return postCheck.apply(checkResource, input); } }
import org.eclipse.jgit.diff.DiffEntry; import org.eclipse.jgit.diff.DiffFormatter; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectReader; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.util.io.DisabledOutputStream; public class ExternalIdCacheLoader extends CacheLoader<ObjectId, AllExternalIds> { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final int MAX_HISTORY_LOOKBACK = 10; private static final int MAX_DIFFERENTIAL_CHANGES = 100; public ExternalIdCacheLoader() { } @Override public AllExternalIds load(ObjectId key) throws Exception { try (Repository repo = openRepository()) { RevWalk walk = new RevWalk(repo); RevCommit commit = walk.parseCommit(key); walk.markStart(commit); AllExternalIds externalIds = new AllExternalIds(); for (RevCommit revCommit : walk) { if (externalIds.isFull()) { break; } externalIds.updateFromCommit(revCommit); } if (!externalIds.isFull()) { externalIds.updateFromFullReload(repo); } return externalIds; } } private Repository openRepository() throws IOException { // Open the repository // ... } }
import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.util.io.DisabledOutputStream; public class ExternalIdCacheLoader extends CacheLoader<ObjectId, AllExternalIds> { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final int MAX_HISTORY_LOOKBACK = 10; private static final int MAX_DIFF_UPDATES = 50; private final ExternalIdReader externalIdReader; private final Provider<Cache<ObjectId, AllExternalIds>> externalIdCache; private final GitRepositoryManager gitRepositoryManager; private final AllUsersName allUsersName; private final Counter1<Boolean> reloadCounter; private final Timer0 reloadDifferential; }
import new Description("Total number of external ID cache reloads from Git.") .setRate() .setUnit("updates"), Field.ofBoolean("partial", Metadata.Builder::partial).build()); this.reloadDifferential = metricMaker.newTimer( "notedb/external_id_partial_read_latency", new Description("Latency for generating a new external ID cache state from a prior state.") .setCumulative() .setUnit(Units.MILLISECONDS)); this.enablePartialReloads = config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", true); @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log("Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } // We failed to load the requested value from both the in-memory cache (hence, this loader was } Refactored Code: import new Description("Total number of external ID cache reloads from Git.") .setRate() .setUnit("updates"); Field<Boolean> partialField = Field.ofBoolean("partial", Metadata.Builder::partial).build(); this.reloadDifferential = metricMaker.newTimer( "notedb/external_id_partial_read_latency", new Description("Latency for generating a new external ID cache state from a prior state.") .setCumulative() .setUnit(Units.MILLISECONDS)); this.enablePartialReloads = config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", true); @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log("Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } // We failed to load the requested value from both the in-memory cache (hence, this loader was }
import com.googlesource.gerrit.plugins.renameproject.monitor.ProgressMonitor; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.List; import org.kohsuke.args4j.Argument; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @CommandMetaData(name = "rename", description = "Rename project") public final class RenameCommand extends SshCommand { @Argument(index = 0, required = true, metaVar = "OLDPROJECT", usage = "project to rename") private String existingProjectName; @Argument(index = 1, required = true, metaVar = "NEWNAME", usage = "new name for the project") private String newProjectName; private static final Logger log = LoggerFactory.getLogger(RenameCommand.class); private final RenameProject renameProject; private final ProjectCache projectCache; private final Provider<CurrentUser> self; @Inject protected RenameCommand(RenameProject renameProject, ProjectCache projectCache, Provider<CurrentUser> self) { this.renameProject = renameProject; this.projectCache = projectCache; this.self = self; } @Override public void run() throws UnloggedFailure, Failure, Exception { ProgressMonitor monitor = new ProgressMonitor(); try { renameProject.rename(existingProjectName, newProjectName, monitor); } catch (IOException e) { log.error("Failed to rename project", e); throw new UnloggedFailure(1, "Failed to rename project"); } projectCache.evict(existingProjectName); projectCache.evict(newProjectName); log.info("Project renamed successfully"); } }
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); public abstract Builder setStarted(@Nullable Timestamp started); public abstract Builder setFinished(@Nullable Timestamp finished); public abstract CheckUpdate build(); }
import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.transport.BundleWriter; import org.eclipse.jgit.transport.ReceiveCommand; import org.kohsuke.args4j.Option; import java.io.ByteArrayOutputStream; import java.io.IOException; import java.io.OutputStream; import java.util.Collection; import java.util.Set; @Singleton public class PreviewSubmit implements RestReadView<RevisionResource> { private final Provider<ReviewDb> dbProvider; private final Provider<MergeOp> mergeOpProvider; private final AllowedFormats allowedFormats; private String format; @Option(name = "--format") public void setFormat(String f) { this.format = f; } @Inject PreviewSubmit(Provider<ReviewDb> dbProvider, Provider<MergeOp> mergeOpProvider, AllowedFormats allowedFormats) { this.dbProvider = dbProvider; this.mergeOpProvider = mergeOpProvider; this.allowedFormats = allowedFormats; } @Override public BinaryResult apply(RevisionResource rsrc) throws RestApiException { if (Strings.isNullOrEmpty(format)) { // Review: Should this be configurable? } // Rest of the code } } public LazyArrayListStore() { fUniqueId = TraceCompassLogUtils.traceObjectCreation(LOGGER, Level.FINE, this); } // Rest of the code // Rest of the code private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final int MAX_HISTORY_LOOKBACK = 10; private static final int MAX_DIFF_UPDATES = 50; private final ExternalIdReader externalIdReader; private final Provider<Cache<ObjectId, AllExternalIds>> externalIdCache; private final GitRepositoryManager gitRepositoryManager; private final AllUsersName allUsersName; private final Counter1<Boolean> reloadCounter; private final Timer0 reloadDifferential; private final boolean enablePartialReloads; @Inject ExternalIdCacheLoader(GitRepositoryManager gitRepositoryManager, AllUsersName allUsersName, ExternalIdReader externalIdReader, @Named(ExternalIdCacheImpl.CACHE_NAME) Provider<Cache<ObjectId, AllExternalIds>> externalIdCache, MetricMaker metricMaker) { this.gitRepositoryManager = gitRepositoryManager; this.allUsersName = allUsersName; this.externalIdReader = externalIdReader; this.externalIdCache = externalIdCache; this.reloadCounter = metricMaker
try (Repository repo = gitRepositoryManager.openRepository(allUsersName)) { long start = System.nanoTime(); Ref extId = repo.exactRef(RefNames.REFS_EXTERNAL_IDS); if (extId == null) { logger.atInfo().log(RefNames.REFS_EXTERNAL_IDS + " not initialized, falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } try (RevWalk rw = new RevWalk(repo)) { RevCommit currentCommit = rw.parseCommit(extId.getObjectId()); rw.markStart(currentCommit); RevCommit parentWithCacheValue = null; AllExternalIds oldExternalIds = null; for (int i = 0; i < MAX_HISTORY_LOOKBACK; i++) { parentWithCacheValue = rw.next(); oldExternalIds = externalIdCache.get().getIfPresent(parentWithCacheValue.getId()); if (oldExternalIds != null) { break; } if (parentWithCacheValue.getParentCount() != 1) { logger.atWarning().log("External IDs cache not found in parent commit history."); return reloadAllExternalIdsAndCachePersistently(notesRev); } } if (oldExternalIds == null) { logger.atWarning().log("External IDs cache not found in commit history."); return reloadAllExternalIdsAndCachePersistently(notesRev); } return oldExternalIds; } }
logger.atInfo().log(RefNames.REFS_EXTERNAL_IDS + " not initialized, falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); RevWalk rw = new RevWalk(repo); RevCommit currentCommit = rw.parseCommit(extId.getObjectId()); rw.markStart(currentCommit); RevCommit parentWithCacheValue = null; AllExternalIds oldExternalIds = null; for (int i = 0; i < MAX_HISTORY_LOOKBACK; i++) { parentWithCacheValue = rw.next(); oldExternalIds = externalIdCache.get().getIfPresent(parentWithCacheValue.getId()); if (oldExternalIds != null) { break; } if (parentWithCacheValue.getParentCount() != 1) { logger.atWarning().log("Unable to find an old ExternalId cache state because %s doesn't have exactly one parent, falling back to full reload", parentWithCacheValue); return reloadAllExternalIdsAndCachePersistently(notesRev); } } if (oldExternalIds == null) { logger.atWarning().log("Unable to find an old ExternalId cache state, falling back to full reload"); return reloadAllExternalIdsAndCachePersistently(notesRev); }
nameToBlob.getValue()); } catch (ConfigInvalidException | RuntimeException e) { logger.atSevere().withCause(e).log( "Ignoring invalid external ID note %s", nameToBlob.getKey().name()); continue; } byAccount.put(parsedExternalId.accountId(), parsedExternalId); if (parsedExternalId.email() != null) { byEmail.put(parsedExternalId.email(), parsedExternalId); } reloadCounter.increment(true); reloadDifferential.start(); return new AutoValue_AllExternalIds(byAccount.build(), byEmail.build()); } } private static ObjectId fileNameToObjectId(String path) { int lastSlash = path.lastIndexOf('/'); return ObjectId.fromString(lastSlash > 0 ? path.substring(lastSlash) : path); } private AllExternalIds reloadAllExternalIdsAndCachePersistently(ObjectId notesRev) throws IOException, ConfigInvalidException { try (TraceTimer ignored = TraceContext.newTimer("Loading external IDs from scratch")) { long start = System.nanoTime(); Map<Account.Id, ExternalId> byAccount = new HashMap<>(); Map<String, ExternalId> byEmail = new HashMap<>(); for (Map.Entry<ExternalId.Key, ObjectId> nameToBlob : externalIdNotes.getNoteMap(notesRev).entrySet()) { ExternalId parsedExternalId; try { parsedExternalId = ExternalId.parse(nameToBlob.getKey().name(), nameToBlob.getValue()); } catch (ConfigInvalidException | RuntimeException e) { logger.atSevere().withCause(e).log( "Ignoring invalid external ID note %s", nameToBlob.getKey().name()); continue; } byAccount.put(parsedExternalId.accountId(), parsedExternalId); if (parsedExternalId.email() != null) { byEmail.put(parsedExternalId.email(), parsedExternalId); } } reloadCounter.increment(true); reloadDifferential.start(); return new AutoValue_AllExternalIds(byAccount.build(), byEmail.build()); } }
private static ObjectId fileNameToObjectId(String path) { int lastSlash = path.lastIndexOf('/'); return ObjectId.fromString(path.replaceAll("/", "")); }
private AllExternalIds reloadAllExternalIdsAndCachePersistently(ObjectId notesRev) throws IOException, ConfigInvalidException { try (TraceTimer ignored = TraceContext.newTimer("Loading external IDs from scratch", Metadata.builder().revision(notesRev.name()).build())) { ImmutableSet<ExternalId> externalIds = externalIdReader.all(notesRev); externalIds.forEach(ExternalId::checkThatBlobIdIsSet); AllExternalIds allExternalIds = AllExternalIds.create(externalIds); externalIdCache.get().put(notesRev, allExternalIds); reloadCounter.increment(false); return allExternalIds; } }
public abstract Optional<String> groupUuid(); public abstract Optional<Integer> httpStatus(); public abstract Optional<String> indexName(); public abstract Optional<Integer> indexVersion(); public abstract Optional<String> methodName(); public abstract Optional<Boolean> multiple(); public abstract Optional<Boolean> partial(); public abstract Optional<String> noteDbFilePath(); public abstract Optional<String> noteDbRefName(); public abstract Optional<String> noteDbSequenceType(); public abstract Optional<String> noteDbTable(); public abstract Optional<String> patchSetId();
package com.google.gerrit.server.config; import com.google.inject.Inject; import com.google.inject.Singleton; import org.eclipse.jgit.lib.Config; @Singleton public class ThreadSettingsConfig { private final int sshdThreads; private final int httpdMaxThreads; private final int sshdBatchThreads; private final int databasePoolLimit; @Inject ThreadSettingsConfig(@GerritServerConfig Config cfg) { int cores = Runtime.getRuntime().availableProcessors(); sshdThreads = cfg.getInt("sshd", "threads", Math.min(4, 2 * cores)); httpdMaxThreads = cfg.getInt("httpd", "maxThreads", 25); int defaultDatabasePoolLimit = sshdThreads + httpdMaxThreads + 2; databasePoolLimit = cfg.getInt("database", "poolLimit", defaultDatabasePoolLimit); sshdBatchThreads = cores == 1 ? 1 : 2; } public int getDatabasePoolLimit() { return databasePoolLimit; } public int getHttpdMaxThreads() { return httpdMaxThreads; } public int getSshdThreads() { return sshdThreads; } public int getSshdBatchTreads() { return sshdBatchThreads; } }
import org.eclipse.jgit.lib.RefUpdate.Result; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.lib.RepositoryCache.FileKey; import org.eclipse.jgit.util.FS; public class AccountsOnInit { private final InitFlags flags; private final SitePaths site; private final String allUsers; @Inject public AccountsOnInit(InitFlags flags, SitePaths site, AllUsersNameOnInitProvider allUsers) { this.flags = flags; this.site = site; this.allUsers = allUsers.get(); } public Account insert(Account.Builder account) throws IOException { File path = getPath(); if (path != null) { try (Repository repo = new FileRepository(path); ObjectInserter oi = repo.newObjectInserter()) { PersonIdent ident = new PersonIdent(new GerritPersonIdentProvider(flags.cfg).get(), account.registeredOn()); Config accountConfig = new Config(); AccountProperties.writeToAccountConfig( InternalAccountUpdate.builder() .setActive(account.isActive()) .setFullName(account.fullName()) .setPreferredEmail(account.preferredEmail()) .setStatus(account.status()) .build(), accountConfig, oi, ident); Account.Id accountId = account.id(); FileKey fileKey = FileKey.exact(path, FS.DETECTED); try (RepositoryCache.FileKeyRepositoryCache repoCache = new RepositoryCache.FileKeyRepositoryCache(fileKey, repo)) { AccountConfig accountCfg = new AccountConfig(accountId, repo); accountCfg.setAccountConfig(accountConfig); accountCfg.commit(ident, oi); } return account.build(); } } return null; } }
AllUsersName allUsersName = new AllUsersName(AllUsersNameProvider.DEFAULT); Account.Builder account = Account.builder(Account.id(1), TimeUtil.nowTs()); String metaId = "0e39795bb25dc914118224995c53c5c36923a461"; account.setMetaId(metaId); List<String> values = toStrings(AccountField.REF_STATE.get(AccountState.forAccount(account.build()))); assertThat(values).hasSize(1); String expectedValue = allUsersName.get() + ":" + RefNames.refsUsers(Account.id(1)) + ":" + metaId; assertThat(Iterables.getOnlyElement(values)).isEqualTo(expectedValue); @Test public void externalIdStateFieldValues() throws Exception { Account.Id id = Account.id(1); Account account = Account.create(id, TimeUtil.nowTs()); ExternalId extId1 = ExternalId.create( ExternalId.Key.create(ExternalId.SCHEME_MAILTO, "foo.bar@example.com"), id, "foo.bar@example.com", null, ObjectId.fromString("1b9a0cf038ea38a0ab08617c39aa8e28413a27ca") ); ExternalId extId2 = ExternalId.create( ExternalId.Key.create(ExternalId.SCHEME_USERNAME, "foo"), id, "foo", null, ObjectId.fromString("1b9a0cf038ea38a0ab08617c39aa8e28413a27cb") ); ExternalId extId3 = ExternalId.create( ExternalId.Key.create(ExternalId.SCHEME_USERNAME, "bar"), id, "bar", null, ObjectId.fromString("1b9a0cf038ea38a0ab08617c39aa8e28413a27cc") ); account.setExternalIds(ImmutableList.of(extId1, extId2, extId3)); List<String> values = toStrings(AccountField.REF_STATE.get(AccountState.forAccount(account))); assertThat(values).containsExactly( "externalId:" + extId1.key().get(), "externalId:" + extId2.key().get(), "externalId:" + extId3.key().get() ); }
@CommandMetaData(name = "rename", description = "Rename project") public final class RenameCommand extends SshCommand { @Argument(index = 0, required = true, metaVar = "OLDPROJECT", usage = "project to rename") private String projectControl; @Argument(index = 1, required = true, metaVar = "NEWNAME", usage = "new name for the project") private String newProjectName; private static final Logger log = LoggerFactory.getLogger(RenameCommand.class); private final RenameProject renameProject; private final Provider<ProjectCache> projectCache; private final Provider<CurrentUser> self; @Inject protected RenameCommand(RenameProject renameProject, Provider<ProjectCache> projectCache, Provider<CurrentUser> self) { this.renameProject = renameProject; this.projectCache = projectCache; this.self = self; } @Override public void run() throws Exception { try { RenameProject.Input input = new RenameProject.Input(); input.name = newProjectName; ProjectResource rsrc = new ProjectResource(projectCache.get().get(new Project.NameKey(projectControl)), self.get()); renameProject.apply(rsrc, input); } catch (ResourceNotFoundException e) { throw new UnloggedFailure(1, "project \"" + projectControl + "\" not found"); } } }
&& Objects.equals(other.checkerUuid, checkerUuid) && Objects.equals(other.state, state) && Objects.equals(other.message, message) && Objects.equals(other.url, url) && Objects.equals(other.started, started) && Objects.equals(other.finished, finished) && Objects.equals(other.created, created) && Objects.equals(other.updated, updated) && Objects.equals(other.checkerName, checkerName) && Objects.equals(other.checkerStatus, checkerStatus) && Objects.equals(other.blocking, blocking) && Objects.equals(other.description, description);
public abstract Optional<Timestamp> started(); public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** * Set the time the check started. Time can be reset to "null" if passed new Timestamp(0). */ public abstract Builder setStarted(Timestamp started); /** * Set the time the check finished. Time can be reset to "null" if passed new Timestamp(0). */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } }
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** * Set the time the check started. Time can be reset to "null" if passed new Timestamp(0). */ public abstract Builder setStarted(Timestamp started); /** * Set the time the check finished. Time can be reset to "null" if passed new Timestamp(0). */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); }
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); public abstract Builder setStarted(Timestamp started); public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); }
String email = readEmail(sshKey); List<ExternalId> extIds = new ArrayList<>(2); extIds.add(ExternalId.createUsername(username, id, httpPassword)); if (email != null) { extIds.add(ExternalId.createEmail(id, email)); } externalIds.insert("Add external IDs for initial admin user", extIds); Account.Builder a = Account.builder(id, TimeUtil.nowTs()) .setFullName(name) .setPreferredEmail(email); Account persistedAccount = a.build(); accounts.insert(a); // Only two groups should exist at this point in time and hence iterating over all of them // is cheap. Optional<GroupReference> adminGroupReference = groupsOnInit .getAllGroupReferences() .filter(group -> group.getName().equals("Administrators")) .findAny(); if (!adminGroupReference.isPresent()) { throw new NoSuchGroupException("Administrators"); } GroupReference adminGroup = adminGroupReference.get(); groupsOnInit.addGroupMember(adminGroup.getUUID(), persistedAccount); if (sshKey != null) { // ... (remaining code) ... }
public String refactorCode(boolean requireChangeId, RevCommit revCommit, String currentChangeId) { String newCommitMessage = CommitMessageUtil.checkAndSanitizeCommitMessage(revCommit.getShortMessage()); List<String> changeIdFooters = revCommit.getFooterLines(FooterConstants.CHANGE_ID); if (!changeIdFooters.isEmpty() && !changeIdFooters.get(0).equals(currentChangeId)) { throw new ResourceConflictException("wrong Change-Id footer"); } if (revCommit.getFooterLines().isEmpty()) { newCommitMessage += "\n"; } if (requireChangeId && changeIdFooters.isEmpty()) { newCommitMessage += FooterConstants.CHANGE_ID.getName() + ": " + currentChangeId + "\n"; } else if (changeIdFooters.size() > 1) { throw new ResourceConflictException("multiple Change-Id footers"); } return newCommitMessage; }
import com.google.gerrit.server.checker.CheckerName; import com.google.gerrit.server.checker.CheckerUpdate; import com.google.gerrit.server.checker.CheckersUpdate; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.Inject; import com.google.inject.Provider; import java.io.IOException; import javax.inject.Singleton; import org.eclipse.jgit.errors.ConfigInvalidException; @Singleton public class UpdateChecker implements RestModifyView<CheckerResource, CheckerInput> { private final GlobalChecksConfig globalChecksConfig; private final PermissionBackend permissionBackend; private final Provider<CheckersUpdate> checkersUpdate; private final CheckerJson checkerJson; @Inject public UpdateChecker( GlobalChecksConfig globalChecksConfig, PermissionBackend permissionBackend, @UserInitiated Provider<CheckersUpdate> checkersUpdate, CheckerJson checkerJson) { this.globalChecksConfig = globalChecksConfig; this.permissionBackend = permissionBackend; this.checkersUpdate = checkersUpdate; this.checkerJson = checkerJson; } @Override public CheckerInfo apply( CheckerResource resource, CheckerInput input) throws RestApiException, PermissionBackendException, NoSuchCheckerException, IOException { // Implementation code here } }
private final Checks checks; private final Provider<ChecksUpdate> checksUpdate; private final CheckJson.Factory checkJsonFactory; @Inject RerunCheck(Provider<CurrentUser> self, PermissionBackend permissionBackend, AdministrateCheckersPermission permission, Checks checks, @UserInitiated Provider<ChecksUpdate> checksUpdate, CheckJson.Factory checkJsonFactory) { this.self = self; this.permissionBackend = permissionBackend; this.permission = permission; this.checks = checks; this.checksUpdate = checksUpdate; this.checkJsonFactory = checkJsonFactory; } @Override public CheckInfo apply(CheckResource checkResource, Input input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (!self.get().isIdentifiedUser()) { throw new AuthException("Authentication required"); } permissionBackend.currentUser().check(permission); if (checkResource.getRevisionResource().getEdit().isPresent()) { throw new ResourceConflictException("checks are not supported on a change edit"); } CheckKey key = CheckKey.create(checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getChange().get()); ChecksUpdate update = checksUpdate.get(); update.setCheckKey(key); update.setCheckState(CheckState.RUNNING); update.setCheckInput(input); checksUpdate.get().update(update); CheckJson checkJson = checkJsonFactory.create(checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getChange().get()); return checkJson.format(checks.getCheck(key)); }
import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.UnprocessableEntityException; import com.google.gerrit.plugins.checks.CheckKey; import com.google.gerrit.plugins.checks.CheckerUuid; import com.google.gerrit.plugins.checks.acceptance.AbstractCheckersTest; import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.inject.Inject; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); } }
import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.NOT_STARTED).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunNotExistingCheckThrowsError() throws Exception { assertThrows(Exception.class, () -> { checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); }); } }
@Test public void rerunNotExistingCheckThrowsError() throws Exception { assertThrows(UnprocessableEntityException.class, () -> checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun()); }
.add("repository", repository) .add("changeNumber", changeNumber) .add("patchSetId", patchSetId) .add("checkerUuid", checkerUuid) .add("state", state) .add("message", message) .add("url", url) .add("started", started) .add("finished", finished) .add("created", created) .add("updated", updated) .add("checkerName", checkerName) .add("checkerStatus", checkerStatus) .add("blocking", blocking) .add("description", checkerDescription) .toString();
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); public abstract Builder setStarted(Timestamp started); public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); public Builder setStartedToNull() { return setStarted(new Timestamp(0)); } public Builder setFinishedToNull() { return setFinished(new Timestamp(0)); } }
@Test public void testBuildAndMergeNormalFrameInMem() throws HyracksDataException { int tableSize = 101; int numFrames = 50; int frameSize = 256; int minDataSize = frameSize; int minRecordSize = 20; int maxRecordSize = 50; testBuildAndMerge(tableSize, numFrames, frameSize, minDataSize, minRecordSize, maxRecordSize, null); } @Test public void testBuildAndMergeNormalFrameSpill() throws HyracksDataException { int tableSize = 101; int numFrames = 50; int frameSize = 256; int minDataSize = frameSize * 4; int minRecordSize = 20; int maxRecordSize = 50; testBuildAndMerge(tableSize, numFrames, frameSize, minDataSize, minRecordSize, maxRecordSize, null); } @Test public void testBuildAndMergeBigObj() throws HyracksDataException { int tableSize = 101; int numFrames = 50; int frameSize = 256; int minDataSize = frameSize * 80; int minRecordSize = 20; int maxRecordSize = 50; testBuildAndMerge(tableSize, numFrames, frameSize, minDataSize, minRecordSize, maxRecordSize, null); } } for (int i = 0; i < splitRow.size(); ++i) { LiteralExpr expr = splitRow.get(i); ColumnDef colDef = pkColumnDefByName_.get(colNames_.get(i)); org.apache.impala.catalog.Type colType = colDef.getType(); Preconditions.checkState(KuduUtil.isSupportedKeyType(colType)); expr.analyze(analyzer); org.apache.impala.catalog.Type exprType = expr.getType(); if (exprType.isNull()) { throw new AnalysisException("Split values cannot be NULL. Split row: " + splitRowToString(splitRow)); } if (!org.apache.impala.catalog.Type.isImplicitlyCastable(exprType, colType, true)) { throw new AnalysisException(String.format("Split value %s (type: %s) is " + "not type compatible with column '%s' (type: %s).", expr.toSql(), exprType, colDef
Fixed Code: ```java import static com.google.common.truth.Truth.assertThat; public void emptyStringIsDeserializedToMagicTimestamp() { Timestamp timestamp = deserializer.deserialize(new JsonPrimitive(""), Timestamp.class, null); assertThat(timestamp).isEqualTo(TimeUtil.never()); } ```
private void queueSuccessMessages(List<CreateRequest> newChanges) { // adjacency list for commit => parent Map<String, String> adjList = new HashMap<>(); List<String> outOfOrderCommits = new ArrayList<>(); for (CreateRequest cr : newChanges) { String parent = cr.commit.getParentCount() < 1 ? start : cr.commit.getParent(0).name(); adjList.put(parent, cr.commit.name()); } for (ReplaceRequest rr : replaceByChange.values()) { try { RevCommit revCommit = receivePack.getRevWalk().parseCommit(rr.newCommitId); String parent = revCommit.getParentCount() < 1 ? start : revCommit.getParent(0).name(); adjList.put(parent, rr.newCommitId.name()); } catch (IOException e) { logger.atWarning().withCause(e).log("failed to parse commit %s for success message.", rr.newCommitId.name()); outOfOrderCommits.add(rr.newCommitId.name()); } } if (adjList.get(start) == null) { // Handle the case when the start commit is not found in the adjacency list } } private List<SubmitRecord> getSubmitRecords(ChangeData cd) { if (projectState == null || projectState.hasPrologRules()) { return Collections.emptyList(); } SubmitRecord submitRecord = new SubmitRecord(); submitRecord.status = SubmitRecord.Status.OK; List<LabelType> labelTypes; List<PatchSetApproval> approvals; try { labelTypes = cd.getLabelTypes().getLabelTypes(); approvals = cd.currentApprovals(); } catch (OrmException e) { log.error("Unable to fetch labels and approvals for change {}: {}", cd.getId(), e); submitRecord.errorMessage = "Unable to fetch labels and approvals for the change"; submitRecord.status = SubmitRecord.Status.RULE_ERROR; return Collections.singletonList(submitRecord); } submitRecord.labels = new ArrayList<>(labelTypes.size()); for (LabelType t : labelTypes) { LabelFunction labelFunction = t.getFunction(); if (labelFunction == null) { log.error("Unable to find the LabelFunction for label {}, change {}", t.getName(), cd.getId()); // Handle the case when the LabelFunction is not found } } // Process the submit records and
// from the cache. Extend the cache size by 1 to cover this case, but expire the extra // object after a short period of time, since it may be a potentially large amount of // memory. // When loading a new value because the primary data advanced, we want to leverage the old // cache state to recompute only what changed. This doesn't affect cache size though as // Guava calls the loader first and evicts later on. .maximumWeight(2) .expireFromMemoryAfterAccess(Duration.ofMinutes(5)) .loader(ExternalIdCacheLoader.class) .diskLimit(-1) .version(1) .keySerializer(ObjectIdCacheSerializer.INSTANCE) .valueSerializer(AllExternalIds.Serializer.INSTANCE); bind(ExternalIdCacheImpl.class); bind(ExternalIdCache.class).to(ExternalIdCacheImpl.class);
public HashtagsInput(Set<String> add, Set<String> remove) { this.add = add; this.remove = remove; } public HashtagsInput(Set<String> add) { this(add, new HashSet<>()); }
CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.NOT_STARTED).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertSuccessfulRerun(info); assertThat(info.updated).isGreaterThan(info.created); } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertSuccessfulRerun(info); assertThat(info.updated).isGreaterThan(info.created); } @Test public void rerunCheckNotExistingButBackfilled() throws Exception { CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertSuccessfulRerun(info); } @Test
private final String variant; private CommitSoyData csd; public LogSoyData(HttpServletRequest req, GitilesAccess access, String pretty) throws IOException { this.req = checkNotNull(req); this.view = checkNotNull(ViewFilter.getView(req)); checkNotNull(pretty); Config config = access.getConfig(); fields = config.getBoolean("logFormat", pretty, "verbose", false) ? VERBOSE_FIELDS : FIELDS; variant = firstNonNull(config.getString("logFormat", pretty, "variant"), pretty); } private static class LogSoyDataAppendable implements AdvisingAppendable { private final Writer writer; LogSoyDataAppendable(Writer writer) { this.writer = writer; } @Override public AdvisingAppendable append(CharSequence csq) throws IOException { writer.append(csq); return this; } @Override public AdvisingAppendable append(CharSequence csq, int start, int end) throws IOException { writer.append(csq, start, end); return this; } @Override public AdvisingAppendable append(char c) throws IOException { writer.append(c); return this; } @Override public void advise(Object advice) { if (advice instanceof SoyMsgBundle) { try { ((SoyMsgBundle) advice).writeExternal(writer); } catch (IOException e) { throw new RuntimeException(e); } } } }
// don't do something with the result, so just wrap it in a dummy method. } public void renderStreaming(Paginator paginator, @Nullable String revision, Renderer renderer, Writer writer, DateFormatter df, FooterBehavior footerBehavior) throws IOException { LogSoyDataAppendable out = new LogSoyDataAppendable(writer); swallowResult(renderer.newRenderer("gitiles.logEntriesHeader") .setData(toHeaderSoyData(paginator, revision)) .renderHtml(out)); SoySauce.Renderer entryRenderer = renderer.newRenderer("gitiles.logEntryWrapper"); boolean renderedEntries = false; for (RevCommit c : paginator) { swallowResult(entryRenderer.setData(toEntrySoyData(paginator, c, df)).renderHtml(out)); out.flush(); renderedEntries = true; } if (!renderedEntries) { swallowResult(renderer.newRenderer("gitiles.emptyLog").renderHtml(out)); } swallowResult(renderer.newRenderer("gitiles.logEntriesFooter") .setData(toFooterSoyData(paginator, revision, footerBehavior)) .renderHtml(out)); }
checkState(u != null, "Missing Soy template %s", soyFile); Hasher h = Hashing.murmur3_128().newHasher(); try (InputStream is = u.openStream(); OutputStream os = Funnels.asOutputStream(h)) { ByteStreams.copy(is, os); } catch (IOException e) { throw new IllegalStateException("Missing Soy template " + soyFile, e); } return h.hash(); public String renderHtml(String templateName, Map<String, ?> soyData) { return newRenderer(templateName).setData(soyData).renderHtml().get().toString(); } void render(HttpServletRequest req, HttpServletResponse res, String templateName, Map<String, ?> soyData) throws IOException { res.setContentType("text/html"); res.setCharacterEncoding("UTF-8"); byte[] data = newRenderer(templateName).setData(soyData).renderHtml().get().toString().getBytes(UTF_8); if (BaseServlet.acceptsGzipEncoding(req)) { res.addHeader(HttpHeaders.VARY, HttpHeaders.ACCEPT_ENCODING); } res.setContentLength(data.length); res.getOutputStream().write(data); }
```java o.write(tail); } SoySauce.Renderer newRenderer(String templateName) { ImmutableMap.Builder<String, Object> staticUrls = ImmutableMap.builder(); for (String key : STATIC_URL_GLOBALS.keySet()) { staticUrls.put( key.replaceFirst("^gitiles\\.", ""), LegacyConversions.riskilyAssumeTrustedResourceUrl(globals.get(key)) ); } return getSauce() .renderTemplate(templateName) .setIj(ImmutableMap.of("staticUrls", staticUrls.build())); } protected abstract SoySauce getSauce(); ```
config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", false); @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log("Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIds(notesRev); } // We didn't find the requested value in the cache, so we try to create it from a past value using minimal Git operations to reduce latency. // First, try to find the most recent state in the persistent cache. We check the last 10 states and if nothing is found, we load the value from scratch. // ... }
import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.OutputFormat; import com.google.gerrit.server.util.SystemLog; import com.google.inject.Inject; import com.google.inject.Singleton; import org.apache.log4j.Level; import org.apache.log4j.LogManager; import org.apache.log4j.Logger; import org.apache.log4j.spi.LoggingEvent; @Singleton class DeleteLog implements LifecycleListener { private static final String DELETE_LOG_NAME = "delete_log"; private static final Logger log = LogManager.getLogger(DELETE_LOG_NAME); public static String ACCOUNT_ID = "accountId"; public static String USER_NAME = "userName"; public static String PROJECT_NAME = "projectName"; public static String OPTIONS = "options"; public static String ERROR = "error"; private final SystemLog systemLog; private final ServerInformation serverInfo; private static boolean started; @Inject public DeleteLog(SystemLog systemLog, ServerInformation serverInfo) { this.systemLog = systemLog; this.serverInfo = serverInfo; } public void onDelete(IdentifiedUser user, Project.NameKey project, ...) { // implementation } } private void initNoteDb() { ui.message( "Use experimental NoteDb for change metadata?\n" + "NoteDb is not recommended for production servers." + "Please familiarize yourself with the documentation:\n" + "https://gerrit-review.googlesource.com/Documentation/dev-note-db.html\n" ); if (!ui.yesno(false, "Enable")) { return; } Config defaultConfig = ConfigNotesMigration.allEnabledConfig(); for (String name : defaultConfig.getNames(SECTION_NOTE_DB, CHANGES.key())) { noteDbChanges.set( name, defaultConfig.getString(SECTION_NOTE_DB, CHANGES.key(), name) ); } } /** * Scans the plugin for declared public annotated classes * * @param pluginName the plugin name * @param annotations annotations declared by the plugin classes * @return map of annotations and associated plugin classes found * @throws InvalidPluginException if the plugin is not valid or corrupted */ Map<Class<? extends Annotation>, Iterable<ExtensionMetaData>> scan( String pluginName, Iterable<Class<? extends Annotation>> annotations ) throws InvalidPluginException; /** * Return the plugin resource
private static AllExternalIds buildAllExternalIds(Repository repo, AllExternalIds oldExternalIds, Map<ObjectId, ObjectId> additions, Set<ObjectId> removals) throws IOException { ImmutableSetMultimap.Builder<Account.Id, ExternalId> byAccount = ImmutableSetMultimap.builder(); ImmutableSetMultimap.Builder<String, ExternalId> byEmail = ImmutableSetMultimap.builder(); // Copy over old ExternalIds but exclude deleted ones for (ExternalId externalId : oldExternalIds.byAccount().values()) { if (removals.contains(externalId.blobId())) { continue; } byAccount.put(externalId.accountId(), externalId); if (externalId.email() != null) { byEmail.put(externalId.email(), externalId); } } // Add new ExternalIds for (Map.Entry<ObjectId, ObjectId> entry : additions.entrySet()) { ExternalId externalId = ExternalId.create(entry.getKey(), entry.getValue()); byAccount.put(externalId.accountId(), externalId); if (externalId.email() != null) { byEmail.put(externalId.email(), externalId); } } return new AllExternalIds(byAccount.build(), byEmail.build()); }
import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.treewalk.TreeWalk; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.Mockito; import org.mockito.junit.MockitoJUnitRunner; @RunWith(MockitoJUnitRunner.class) public class ExternalIDCacheLoaderTest { private static AllUsersName ALL_USERS = AllUsersNameProvider.DEFAULT; @Mock Cache<ObjectId, AllExternalIds> externalIdCache; private ExternalIdCacheLoader loader; private GitRepositoryManager repoManager = new InMemoryRepositoryManager(); private ExternalIdReader externalIdReader; private ExternalIdReader externalIdReaderSpy; @Before public void setUp() throws Exception { repoManager.createRepository(ALL_USERS).close(); externalIdReader = new ExternalIdReader(repoManager, ALL_USERS, new DisabledMetricMaker()); externalIdReaderSpy = Mockito.spy(externalIdReader); loader = createLoader(true); } @Test public void worksOnSingleCommit() throws Exception { // Test code here } }
private final TypeAdapter<T> defaultEnumAdapter; public EnumTypeAdapter(TypeAdapter<T> defaultEnumAdapter) { this.defaultEnumAdapter = defaultEnumAdapter; } @Override public T read(JsonReader in) throws IOException { if (in.peek() == JsonToken.NULL) { in.nextNull(); return null; } T enumValue = defaultEnumAdapter.read(in); if (enumValue == null) { throw new JsonSyntaxException(String.format("Invalid value '%s' for enum %s", in.nextString(), defaultEnumAdapter.getClass().getSimpleName())); } return enumValue; } @Override public void write(JsonWriter out, T value) throws IOException { defaultEnumAdapter.write(out, value); }
public void emptyEnumValueIsRejectedOnParse() { try { gson.fromJson("{\"value\":\"\"}", TestData.class); fail("Expected JsonSyntaxException to be thrown"); } catch (JsonSyntaxException e) { // Log the exception logger.error("Failed to parse empty enum value", e); // Handle the exception based on the severity if (isCriticalError(e)) { // Trigger a fire drill and rollback triggerFireDrillAndRollback(); } else { // Log a warning and continue processing logger.warn("Empty enum value encountered, but not critical"); } } }
private void waitUntilFinished() throws InterruptedException { while (!isCallFinished.get()) { Thread.sleep(100); } }
/** * Deletes a child resource. * * The returned response usually does not have any value (status code 204 No Content). * If a value in the returned response is set, it is automatically converted to JSON unless it is a BinaryResult. * * Further properties like caching behavior (see CacheControl) can be optionally set on the returned response. * * Throwing a subclass of RestApiException results in a 4XX response to the client. For any other exception, the client will get a 500 Internal Server Error response. * * @param parentResource the parent resource of the resource that should be deleted * @param id the ID of the child resource that should be deleted * @param input the input after parsing from the request * @return the response to return to the client * @throws RestApiException if the resource deletion is rejected */ public Response deleteChildResource(ParentResource parentResource, String id, Input input) throws RestApiException { // implementation goes here }
/** * RestCollectionModifyViews this is usually {code 200 OK}, but other 2XX or 3XX status codes are * also possible (e.g. {code 201 Created} if a resource was created, {code 202 Accepted} if a * background task was scheduled, {@code 204 No Content} if no content is returned, {@code 302 * Found} for a redirect). * <p>Further properties like caching behavior (see {@link CacheControl}) can be optionally set on * the returned response. * <p>Throwing a subclass of {@link RestApiException} results in a 4XX response to the client. For * any other exception the client will get a {@code 500 Internal Server Error} response. * * @param parentResource the collection resource on which the modification is done * @return response to return to the client * @throws Exception the implementation of the view failed. The exception will be logged and HTTP * 500 Internal Server Error will be returned to the client. * @throws UnsupportedOperationException if the response type does not support this operation */
throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } Map<ProjectWatchKey, Set<NotifyType>> projectWatches = asMap(input); accountsUpdateProvider .get() .update( "Update Project Watches via API", rsrc.getUser().getAccountId(), u -> u.updateProjectWatches(projectWatches)); return Response.ok(getWatchedProjects.apply(rsrc).value()); } private Map<ProjectWatchKey, Set<NotifyType>> asMap(List<ProjectWatchInfo> input) throws RestApiException, IOException, PermissionBackendException { Map<ProjectWatchKey, Set<NotifyType>> m = new HashMap<>(); for (ProjectWatchInfo info : input) { if (info.project == null) { throw new BadRequestException("project name must be specified"); } ProjectWatchKey key = ProjectWatchKey.create(projectsCollection.parse(info.project).getNameKey(), info.filter); if (m.containsKey(key)) { throw new BadRequestException("duplicate project watch key"); } m.put(key, info.notify); } return m; }
public void notifyChanged(Notification notification) { super.notifyChanged(notification); if (notification.getFeature() == VTablePackage.eINSTANCE.getTableDomainModelReference_ColumnDomainModelReferences()) { viewer.refresh(); parent.layout(); } if (VTableDomainModelReference.class.isInstance(notification.getNotifier())) { updateSetting(); viewer.refresh(); parent.layout(); } if (VTableControl.class.isInstance(notification.getNotifier()) && VTableDomainModelReference.class.isInstance(notification.getNewValue())) { updateSetting(); viewer.refresh(); parent.layout(); } } private static List<Rule> getRules(VElement renderable) { final HashMap<Class<? extends Rule>, Rule> rules = new HashMap<Class<? extends Rule>, Rule>(); for (final VAttachment attachment : renderable.getAttachments()) { if (Rule.class.isInstance(attachment)) { final Rule rule = (Rule) attachment; if (!rules.containsKey(rule.getClass())) { rules.put(rule.getClass(), rule); } } } return rules.values(); } List<SlotId> equivSlotIds = Lists.newArrayList(analyzer.getEquivSlots(slotId)); Iterator<SlotId> iter = equivSlotIds.iterator(); while (iter.hasNext()) { SlotId equivSlotId = iter.next(); if (equivSlotId.equals(slotId)) continue; TupleDescriptor tupleDesc = analyzer.getSlotDesc(equivSlotId).getParent(); if (tupleDesc.getTable() == null || !analyzer.hasValueTransfer(slotId, equivSlotId)) { continue; } List<SlotId> sids = slotsByTid.get(tupleDesc.getId()); if (sids == null) { sids = Lists.newArrayList(); slotsByTid.put(tupleDesc.getId(), sids); } sids.add(equivSlotId); } return slotsByTid; this.self = self; this.changes = changes; } @Override @SuppressWarnings("unchecked") public Response<List<ChangeInfo>> apply(AccountResource rsrc) throws BadRequestException, AuthException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { throw new AuthException("not allowed to list stars of another account"); } QueryChanges query = changes.list(); query.addQuery("has:stars"); return Response.ok((List<ChangeInfo>) query.apply(TopLevelResource.INSTANCE).value());
public Response<?> apply(ProjectResource rsrc, Input input) { Project.NameKey project = rsrc.getNameKey(); if (input.async) { return applyAsync(project, input); } return Response.ok(applySync(project, input)); }
private final String DEFAULT_DASHBOARD_MESSAGE = "Changed default dashboard to %s.\n"; public Response<DashboardInfo> setDefaultDashboard(ChangeResource rsrc, Input input) throws RestApiException { try { String msg = String.format(DEFAULT_DASHBOARD_MESSAGE, input.id); if (!msg.endsWith("\n")) { msg += "\n"; } md.setAuthor(rsrc.getUser().asIdentifiedUser()); md.setMessage(msg); config.commit(md); cache.evict(rsrc.getProjectState().getProject()); if (target != null) { DashboardInfo info = get.get().apply(target).value(); info.isDefault = true; return Response.ok(info); } return Response.none(); } catch (RepositoryNotFoundException notFound) { throw new ResourceNotFoundException(rsrc.getProjectState().getProject().getName()); } catch (ConfigInvalidException e) { throw new ResourceConflictException(String.format("invalid project.config: %s", e.getMessage())); } }
// limitations under the License. package com.google.gerrit.acceptance.testsuite.project; import static com.google.common.truth.Truth.assertThat; import static java.util.stream.Collectors.toList; import com.google.common.collect.ImmutableList; import com.google.gerrit.acceptance.AbstractDaemonTest; import com.google.gerrit.extensions.api.projects.BranchInfo; import com.google.gerrit.reviewdb.client.Project; import com.google.inject.Inject; import java.util.List; import org.junit.Test; public class ProjectOperationsImplTest extends AbstractDaemonTest { @Inject private ProjectOperations projectOperations; @Test public void defaultName() throws Exception { Project.NameKey name = projectOperations.newProject().create(); gApi.projects().name(name.get()); Project.NameKey name2 = projectOperations.newProject().create(); assertThat(name2).isNotEqualTo(name); } @Test public void specifiedName() throws Exception { String name = "somename"; Project.NameKey key = projectOperations.newProject().name(name).create(); assertThat(key.get()).isEqualTo(name); } @Test public void emptyCommit() throws Exception { // Test code here } } import org.eclipse.osee.orcs.data.ArtifactReadable; /** * @author Donald G. Dunne * @author David W. Miller */ @Path("program") public class ProgramResource extends AbstractConfigResource { @Context private UriInfo uriInfo; public void setUriInfo(UriInfo uriInfo) { this.uriInfo = uriInfo; } public ProgramResource(IAtsServer atsServer) { super(AtsArtifactTypes.Program, atsServer); } @GET @Path("{uuid}/insertion") @Produces(MediaType.APPLICATION_JSON) public Response getProgramInsertions(@PathParam("uuid") long uuid) throws Exception { ArtifactReadable programArt = atsServer.getArtifactByUuid(uuid); if (programArt == null) { throw new OseeCoreException("Given uuid not found"); } if (!programArt.getArtifactType().equals(AtsArtifactTypes.Program)) { throw new OseeCoreException("Given uuid not program type"); } // get the insertions related to the given program ResultSet<ArtifactReadable> results = programArt.getRelated(AtsRelationTypes.ProgramToInsertion_Insertion);
private void savePluginSections(Config rc, Set<AccountGroup.UUID> keepGroups) { unsetSection(rc, PLUGIN); List<String> existing = new ArrayList<>(rc.getSubsections(PLUGIN)); for (Map.Entry<String, Config> e : pluginConfigs.entrySet()) { String plugin = e.getKey(); Config pluginConfig = e.getValue(); for (String name : pluginConfig.getNames(PLUGIN, plugin)) { String value = pluginConfig.getString(PLUGIN, plugin, name); String groupName = GroupReference.extractGroupName(value); if (groupName != null) { GroupReference ref = groupsByName.get(groupName); if (ref != null && ref.getUUID() != null) { keepGroups.add(ref.getUUID()); pluginConfig.setString(PLUGIN, plugin, name, "group " + ref.getName()); } } rc.setStringList(PLUGIN, plugin, name, Arrays.asList(pluginConfig.getStringList(PLUGIN, plugin, name))); } } }
this.accountInfoFactory = infoFactory; this.projectCache = projectCache; this.prologRule = prologRule; @Override public Response<List<TestSubmitRuleInfo>> apply(RevisionResource rsrc, TestSubmitRuleInput input) throws AuthException, PermissionBackendException, BadRequestException { if (input == null) { input = new TestSubmitRuleInput(); } if (input.rule == null) { throw new BadRequestException("rule is required"); } if (!rules.isProjectRulesEnabled()) { throw new AuthException("project rules are disabled"); } input.filters = MoreObjects.firstNonNull(input.filters, filters); SubmitRuleOptions opts = SubmitRuleOptions.builder() .skipFilters(input.filters == Filters.SKIP) .rule(input.rule) .logErrors(false) .build(); ProjectState projectState = projectCache.get(rsrc.getProject()); if (projectState == null) { throw new BadRequestException("project not found"); } }
// http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.gerrit.extensions.registration.DynamicItem; import com.google.inject.AbstractModule; /** * Module for the Replication extension point. */ public class ReplicationExtensionPointModule extends AbstractModule { @Override protected void configure() { DynamicItem.itemOf(binder(), ReplicationPushFilter.class); } }
import org.junit.Test; import java.io.IOException; import java.util.List; import java.util.concurrent.TimeUnit; import java.util.stream.Collectors; import static org.easymock.EasyMock.*; import static org.junit.Assert.*; import static org.powermock.api.easymock.PowerMock.*; public class DialectEditorsOpeningWithFailingSessionOpeningTests extends SiriusTestCase { private IMemento memento; private IElementFactory elementFactory; private SessionOpeningFailureListener sessionOpeningFailureListener; private IEditorPart openedEditor; @Override protected void setUp() throws Exception { super.setUp(); closeWelcomePage(); } @Test public void shouldPushAllRefsWhenNoFiltersSetup() throws InterruptedException, IOException { List<RemoteRefUpdate> expectedUpdates = localRefs.values().stream() .map(ref -> { try { return new RemoteRefUpdate(repositoryMock, ref.getName(), ref.getObjectId(), "fooProject", false, "fooProject", null); } catch (IOException e) { throw new RuntimeException(e); } }) .collect(Collectors.toList()); PushResult pushResult = new PushResult(); expect(transportMock.push(anyObject(), compareRemoteRef(expectedUpdates))) .andReturn(pushResult) .once(); replay(transportMock); PushOne pushOne = createPushOne(replicationPushFilter); pushOne.addRef(PushOne.ALL_REFS); pushOne.run(); isCallFinished.await(10, TimeUnit.SECONDS); verify(transportMock); } }
throw new RuntimeException(e); }) .collect(Collectors.toList()); PushResult pushResult = new PushResult(); expect(transportMock.push(anyObject(), compareRemoteRef(expectedUpdates))) .andReturn(pushResult) .once(); replay(transportMock); PushOne pushOne = createPushOne(null); pushOne.addRef(PushOne.ALL_REFS); pushOne.run(); isCallFinished.await(10, TimeUnit.SECONDS); verify(transportMock); } @Test public void shouldNotApplyReplicationPushFilter() throws InterruptedException, IOException { DynamicItem<ReplicationPushFilter> replicationPushFilter = DynamicItem.itemOf( ReplicationPushFilter.class, new ReplicationPushFilter() { @Override public List<RemoteRefUpdate> filter( String projectName, List<RemoteRefUpdate> remoteUpdatesList) { return remoteUpdatesList; } }); // easymock way to check if method was never called expect(transportMock.push(anyObject(), anyObject())) .andThrow(new AssertionFailedError()) .anyTimes(); replay(transportMock); PushOne pushOne = createPushOne(replicationPushFilter); }
public List<RemoteRefUpdate> filter(String projectName, List<RemoteRefUpdate> remoteUpdatesList) { return Collections.emptyList(); }
private CommentFormatter createCommentFormatter() { return commentJson.get() .setFillAccounts(includeAuthorInfo()) .setFillPatchSet(true) .newCommentFormatter(); } throw new AuthException("Authentication required"); } return commentJson.get() .setFillAccounts(includeAuthorInfo()) .setFillPatchSet(true) .format(listComments(rsrc)); public List<CommentInfo> getComments(ChangeResource rsrc) throws AuthException, OrmException { if (requireAuthentication() && !rsrc.getUser().isIdentifiedUser()) { throw new AuthException("Authentication required"); } return createCommentFormatter().formatAsList(listComments(rsrc)); }
static final String MAX_CACHE_AGE = "maxCacheAge"; // seconds to stay in cache static final String MAX_CACHE_SIZE = "maxCacheSize"; // number of OwnersDb in cache static final String MIN_OWNER_VOTE_LEVEL = "minOwnerVoteLevel"; // default +1 static final String REPORT_SYNTAX_ERROR = "reportSyntaxError"; // only for tests // "alwaysShowButton" is obsolete, new UI design always shows the [Find Owners] button // Name of config parameters that can be defined in project.config or gerrit.confg: static final String OWNERS_FILE_NAME = "ownersFileName"; // config key for file name static final String REJECT_ERROR_IN_OWNERS = "rejectErrorInOwners"; // enable upload validator static final String OWNERS = "OWNERS"; // default OWNERS file name // Name of plugin and namespace. static final String PLUGIN_NAME = "find-owners"; static final String PROLOG_NAMESPACE = "find_owners"; private final PluginConfigFactory configFactory; // Each call to API entry point creates one new Config and parses gerrit.config.
String getOwnersFileName(Project project) { String defaultName = getDefaultOwnersFileName(); try { String name = getProjectConfig(project).getString(OWNERS_FILE_NAME, defaultName); if (name.trim().isEmpty()) { logger.atSevere().log("Project %s has empty %s", project, OWNERS_FILE_NAME); return defaultName; } return name; } catch (NoSuchProjectException e) { logger.atSevere().withCause(e).log("Exception in getOwnersFileName for %s", project.getName()); return defaultName; } }
public ImmutableSet<Account.Id> getAccountFor(String email) throws IOException { ImmutableSet<Account.Id> accounts = externalIds.byEmail(email) .stream() .map(ExternalId::accountId) .collect(toImmutableSet()); if (!accounts.isEmpty()) { return accounts; } return executeIndexQuery(() -> queryProvider.get().byPreferredEmail(email) .stream() .map(a -> a.getAccount().id()) .collect(toImmutableSet())); }
package com.google.gerrit.server.account; import static com.google.common.collect.ImmutableList.toImmutableList; import static com.google.common.collect.ImmutableSet.toImmutableSet; import com.google.common.base.Throwables; import com.google.common.collect.ImmutableSet; import com.google.common.collect.ImmutableSetMultimap; import com.google.common.collect.MultimapBuilder; import com.google.common.collect.SetMultimap; import com.google.gerrit.exceptions.StorageException; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.server.account.externalids.ExternalId; import com.google.gerrit.server.account.externalids.ExternalIds; import com.google.gerrit.server.query.account.InternalAccountQuery; import com.google.gerrit.server.update.RetryHelper; import com.google.gerrit.server.update.RetryHelper.Action; import com.google.gerrit.server.update.RetryHelper.ActionType; import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.Singleton; import java.io.IOException; import java.util.Arrays; import java.util.List; /** * Class to access accounts by email. */ @Singleton public class Emails { private final ExternalIds externalIds; private final Provider<InternalAccountQuery> accountQueryProvider; private final RetryHelper retryHelper; @Inject public Emails(ExternalIds externalIds, Provider<InternalAccountQuery> accountQueryProvider, RetryHelper retryHelper) { this.externalIds = externalIds; this.accountQueryProvider = accountQueryProvider; this.retryHelper = retryHelper; } public ImmutableSet<Account.Id> getAccountFor(String email) throws IOException { try { return retryHelper.execute(ActionType.ACCOUNTS_BY_EMAIL, new Action<ImmutableSet<Account.Id>>() { @Override public ImmutableSet<Account.Id> execute() throws IOException { return doGetAccountFor(email); } }); } catch (StorageException e) { Throwables.throwIfInstanceOf(e.getCause(), IOException.class); throw new IOException(e); } } private ImmutableSet<Account.Id> doGetAccountFor(String email) throws IOException { SetMultimap<String, Account.Id> byEmail = MultimapBuilder.hashKeys().hashSetValues().build(); ImmutableSetMultimap.Builder<Account.Id, ExternalId.Key> byAccount = ImmutableSetMultimap.builder(); externalIds.byEmail(email).forEach(externalId -> { byEmail.put(email,
// http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.extensions.common.GitPerson; public class SharedRefLogEntry { public enum Type { UPDATE_REF, DELETE_REF, DELETE_PROJECT } public String projectName; public Type type; public static class UpdateRef extends SharedRefLogEntry { public String refName; public String oldId; public String newId; public GitPerson committer; public String comment; UpdateRef(String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } } }
public SharedRefDatabaseWrapper(DynamicItem<SharedRefDatabase> sharedRefDatabase, SharedRefLogger sharedRefLogger) { this.sharedRefDb = sharedRefDatabase.get(); this.sharedRefLogger = sharedRefLogger; }
public SharedRefDatabaseWrapper(DynamicItem<SharedRefDatabase> sharedRefDatabase, SharedRefLogger sharedRefLogger) { this.sharedRefDatabase = sharedRefDatabase; this.sharedRefLogger = sharedRefLogger; } // In runtime, use sharedRefDatabase.get() to access the actual SharedRefDatabase instance.
logger.atFiner().log("Create new OwnersDb, key=%s", key); return new OwnersDb(permissionBackend, projectState, accountCache, emails, key, repoManager, config, changeData, branch, files); } try { logger.atFiner().log("Get from cache %s, key=%s, cache size=%d", dbCache, key, dbCache.size()); logger.atFine().log("FindOwnersCacheStats: " + dbCache.stats()); return dbCache.get(key, new Callable<OwnersDb>() { @Override public OwnersDb call() { logger.atFiner().log("Create new OwnersDb, key=%s", key); return new OwnersDb(permissionBackend, projectState, accountCache, emails, key, repoManager, config, changeData, branch, files); } }); } catch (ExecutionException e) { logger.atSevere().withCause(e).log("Error getting OwnersDb from cache: " + e.getMessage()); throw new RuntimeException("Error getting OwnersDb from cache", e); }
.create(); update(rev); ProjectConfig cfg = read(rev); cfg.getAccountsSection().setSameGroupVisibility(ImmutableList.of()); rev = commit(cfg); assertThat(text(rev, "project.config")) .isEqualTo("[commentlink \"bugzilla\"]\n\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n"); } @Test public void contributorSectionIsUnsetIfNoPermissionsAreSet() throws Exception { RevCommit rev = tr.commit() .add("project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[contributor-agreement \"Individual\"]\n" + " accepted = group Developers\n" + " accepted = group Staff\n") .create(); update(rev); ProjectConfig cfg = read(rev); ContributorAgreement section = cfg.getContributorAgreement("Individual");
.create(); update(rev); ProjectConfig cfg = read(rev); ContributorAgreement section = cfg.getContributorAgreement("Individual"); section.setAccepted(ImmutableList.of()); rev = commit(cfg); assertThat(text(rev, "project.config")) .isEqualTo( "[commentlink \"bugzilla\"]\n\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n"); } @Test public void notifySectionIsUnsetIfNoPermissionsAreSet() throws Exception { RevCommit rev = tr.commit() .add( "project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[notify \"name\"]\n" + " email = example@example.com\n") .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getNotifyConfigs().clear(); rev = commit(cfg);
@Test public void commentLinkSectionIsUnsetIfNoPermissionsAreSet() throws Exception { RevCommit rev = tr.commit() .add("project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[notify \"name\"]\n" + " email = example@example.com\n") .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getCommentLinkSections().clear(); rev = commit(cfg); }
@NoHttpd public class NoUnresolvedCommentsRuleIT extends LightweightPluginDaemonTest { private static final String FILENAME = "my.file"; @Before public void enableRuleBeforeTest() throws Exception { enableRule(true); } @Test public void blocksWithUnresolvedComments() throws Exception { ReviewInput.CommentInput comment = newFileComment(); comment.unresolved = true; PushOneCommit.Result r = createChangeWithComment(comment); Optional<SubmitRecord> submitRecords = evaluate(r.getChange()); assertThat(submitRecords).isPresent(); SubmitRecord result = submitRecords.get(); assertThat(result.status).isEqualTo(SubmitRecord.Status.NOT_READY); assertThat(result.labels).isNull(); assertThat(result.requirements).hasSize(1); } @Test public void doesNotBlockWithNoComments() throws Exception { PushOneCommit.Result r = createChange(); Optional<SubmitRecord> submitRecords = evaluate(r.getChange()); assertThat(submitRecords).isPresent(); SubmitRecord result = submitRecords.get(); assertThat(result.status).isEqualTo(SubmitRecord.Status.OK); assertThat(result.labels).isNull(); assertThat(result.requirements).isNull(); } }
package com.google.gerrit.server.rules; import com.google.gerrit.common.data.SubmitRecord; import com.google.gerrit.extensions.annotations.ExtensionPoint; import com.google.gerrit.server.query.change.ChangeData; import java.util.Optional; /** * Allows plugins to decide whether a change is ready to be submitted or not. * * <p>For a given {@link ChangeData}, each plugin is called and returns a {@link Optional} of {@link SubmitRecord}. * This collection can be empty, or contain one or several values. * * <p>A Change can only be submitted if all the plugins give their consent. * * <p>Each {@link SubmitRecord} represents a decision made by the plugin. If the plugin rejects a * change, it should hold valuable information to help the end user understand and correct the * blocking points. * * <p>It should be noted that each plugin can handle rules inheritance. * * <p>This interface should be used to write pre-submit validation rules. This includes both simple */ @ExtensionPoint public interface SubmitRule { /** * Evaluates the submit rule for the given change. * * @param changeData the change data * @return an optional submit record */ Optional<SubmitRecord> evaluate(ChangeData changeData); }
import java.util.Map; import java.util.Optional; import org.eclipse.jgit.internal.storage.dfs.InMemoryRepository; import org.eclipse.jgit.junit.TestRepository; import org.junit.Test; @NoHttpd public class IgnoreSelfApprovalRuleIT extends AbstractDaemonTest { @Inject private IgnoreSelfApprovalRule rule; @Test public void blocksWhenUploaderIsOnlyApprover() throws Exception { enableRule("Code-Review", true); PushOneCommit.Result r = createChange(); approve(r.getChangeId()); Optional<SubmitRecord> submitRecord = rule.evaluate(r.getChange()); assertThat(submitRecord.isPresent()).isTrue(); SubmitRecord result = submitRecord.get(); assertThat(result.status).isEqualTo(SubmitRecord.Status.NOT_READY); assertThat(result.labels).isNotEmpty(); assertThat(result.requirements) .containsExactly( SubmitRequirement.builder() .setFallbackText("Approval from non-uploader required") .setType("non_uploader_approval") .build()); } @Test public void allowsSubmissionWhenChangeHasNonUploaderApproval() throws Exception { enableRule("Code-Review", true); // Create change as user } }
import org.eclipse.jgit.api.errors.GitAPIException; import org.junit.Test; import java.io.IOException; import java.util.List; public class GetRelatedIT extends AbstractDaemonTest { @Inject private ChangeEditUtil editUtil; @Inject private ChangeEditModifier editModifier; @Test public void getRelatedNoResult() throws GitAPIException, IOException, Exception { PushOneCommit push = pushFactory.create(db, admin.getIdent()); PatchSet.Id ps = push.to(git, "refs/for/master").getPatchSetId(); List<ChangeAndCommit> related = getRelated(ps); assertThat(related).isEmpty(); } @Test public void getRelatedLinear() throws GitAPIException, IOException, Exception { add(git, "a.txt", "1"); Commit c1 = createCommit(git, admin.getIdent(), "subject: 1"); add(git, "b.txt", "2"); Commit c2 = createCommit(git, admin.getIdent(), "subject: 2"); pushHead(git, "refs/for/master", false); for (Commit c : ImmutableList.of(c2, c1)) { // code logic here } } @Test public void allowsSubmissionWhenChangeHasNonUploaderApproval() throws Exception { enableRule("Code-Review", true); TestRepository<InMemoryRepository> userTestRepo = cloneProject(project, user); PushOneCommit push = pushFactory.create(user.newIdent(), userTestRepo); PushOneCommit.Result r = push.to("refs/for/master"); approve(r.getChangeId()); Optional<SubmitRecord> submitRecords = rule.evaluate(r.getChange()); assertThat(submitRecords).isEmpty(); } @Test public void doesNothingByDefault() throws Exception { enableRule("Code-Review", false); PushOneCommit.Result r = createChange(); approve(r.getChangeId()); Optional<SubmitRecord> submitRecords = rule.evaluate(r.getChange()); assertThat(submitRecords).isEmpty(); } private void enableRule(String labelName, boolean newState) throws Exception { try (ProjectConfigUpdate u = updateProject(project)) { Map<String, LabelType> localLabelSections = u.getConfig().getLabelSections(); // code logic here } } }
public void convertsPrologToSubmitRecord() { PrologRuleEvaluator evaluator = makeEvaluator(); StructureTerm verifiedLabel = makeLabel("Verified", "may"); StructureTerm labels = new StructureTerm("label", verifiedLabel); List<Term> terms = ImmutableList.of(makeTerm("ok", labels)); Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); assertThat(record).isPresent(); }
terms.add(makeTerm("ok", makeLabels(label2))); terms.add(makeTerm("not_ready", makeLabels(label3))); Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); SubmitRecord expectedRecord = new SubmitRecord(); expectedRecord.status = SubmitRecord.Status.OK; expectedRecord.labels = new ArrayList<>(); expectedRecord.labels.add(submitRecordLabel2); expectedRecord.labels.add(submitRecordLabel3); assertThat(record).isPresent(); assertThat(record.get()).isEqualTo(expectedRecord);
terms.add(makeTerm("ok", makeLabels(label2))); terms.add(makeTerm("not_ready", makeLabels(label3))); Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); SubmitRecord expectedRecord = new SubmitRecord(); expectedRecord.status = SubmitRecord.Status.OK; expectedRecord.labels = new ArrayList<>(); expectedRecord.labels.add(submitRecordLabel2); expectedRecord.labels.add(submitRecordLabel3); assertThat(record).isPresent(); assertThat(record.get()).isEqualTo(expectedRecord);
protected void configure() { if (config.getSharedRefDb().isEnabled()) { DynamicSet.bind(binder(), ProjectDeletedListener.class) .to(ProjectDeletedSharedDbCleanup.class); } install(new ValidationModule(config)); }
protected void configure() { bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getZookeeperConfig().buildCurator()); bind(ZkConnectionConfig.class) .toInstance(new ZkConnectionConfig(cfg.getZookeeperConfig().buildCasRetryPolicy(), cfg.getZookeeperConfig().getZkInterProcessLockTimeOut())); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ProjectDeletedSharedDbCleanup.class); }
metadataBuilder.addPluginMetadata( PluginMetadata.create(PUBLISHER_SUCCESS_COUNTER, fieldValue) ) .description("Broker message published count") .build(); this.brokerPublisherFailureCounter = metricMaker.newCounter( "multi_site/broker/broker_message_publisher_failure_counter", new Description("Number of messages failed to publish by the broker publisher") .setRate() .setUnit("errors"), Field.ofString( PUBLISHER_FAILURE_COUNTER, (metadataBuilder, fieldValue) -> metadataBuilder.addPluginMetadata( PluginMetadata.create(PUBLISHER_FAILURE_COUNTER, fieldValue) ) ) .description("Broker failed to publish message count") .build() );
new Description("Number of messages failed to publish by the broker publisher") .setRate() .setUnit("errors"), Field.ofString(PUBLISHER_FAILURE_COUNTER, metadataMapper(PUBLISHER_FAILURE_COUNTER)) .description("Broker failed to publish message count") .build()); public void incrementBrokerPublishedMessage() { brokerPublisherSuccessCounter.increment(PUBLISHER_SUCCESS_COUNTER); } public void incrementBrokerFailedToPublishMessage() { brokerPublisherFailureCounter.increment(PUBLISHER_FAILURE_COUNTER); } private BiConsumer<Metadata.Builder, String> metadataMapper(String metadataKey) { return (metadataBuilder, fieldValue) -> metadataBuilder.addPluginMetadata(PluginMetadata.create(metadataKey, fieldValue)); }
"Kafka consumer subscribing to topic [%s] for event family [%s]", topic, getEventFamily()); consumer.subscribe(Collections.singleton(topic)); while (!closed.get()) { ConsumerRecords<byte[], byte[]> consumerRecords = consumer.poll(Duration.ofMillis(configuration.kafkaSubscriber().getPollingInterval())); consumerRecords.forEach(this::processRecord); } } catch (WakeupException e) { // Ignore exception if closing if (!closed.get()) { throw e; } } catch (Exception e) { subscriberMetrics.incrementSubscriberFailedToPollMessages(); throw e; } finally { consumer.close(); }
eventRouter.route(event.getEventBody(gson)); subscriberMetrics.incrementSubscriberConsumedMessage(); } catch (IOException e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (PermissionBackendException | OrmException e) { logger.atSevere().withCause(e).log( "Cannot handle message %s: [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (Exception e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", new String(consumerRecord.value(), UTF_8)); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); }
public IndexEventSubscriber(KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, IndexEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gsonProvider, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super(configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gsonProvider, instanceId, oneOffCtx, msgLog, subscriberMetrics); }
public KafkaCacheEvictionEventSubscriber(KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, StreamEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gsonProvider, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super(configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gsonProvider, instanceId, oneOffCtx, msgLog, subscriberMetrics); }
public ProjectUpdateEventSubscriber(KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, ProjectListUpdateRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gson, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super(configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gson, instanceId, oneOffCtx, msgLog, subscriberMetrics); }
public StreamEventSubscriber(KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, StreamEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gson, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super(configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gson, instanceId, oneOffCtx, msgLog, subscriberMetrics); }
private String replaceInUrl(String placeholder, String url, String replacement, boolean lowerCase) { if (url == null || replacement == null || !url.contains(placeholder)) { return url; } if (lowerCase) { replacement = replacement.toLowerCase(); } return url.replace(placeholder, Url.encode(replacement)); }
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.broker; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public interface BrokerSession { boolean isOpen(); void connect(); void disconnect(); boolean publishEvent(EventFamily eventFamily, String payload); boolean publishEventToTopic(String topic, String payload); }
CheckUpdate.Builder builder = CheckUpdate.builder(); builder.setState(CheckState.NOT_STARTED) .unsetFinished() .unsetStarted() .setMessage("") .setUrl(""); Check updatedCheck; if (!check.isPresent()) { Checker checker = checkers.getChecker(checkerUuid) .orElseThrow(() -> new ResourceNotFoundException(String.format("checker %s not found", checkerUuid))); updatedCheck = Check.newBackfilledCheck( checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getPatchSet(), checker); } else { updatedCheck = checksUpdate.get().updateCheck(key, builder.build()); } return checkJsonFactory.noOptions().format(updatedCheck); }
CheckUpdate.Builder builder = CheckUpdate.builder(); builder.setState(CheckState.NOT_STARTED) .unsetFinished() .unsetStarted() .setMessage("") .setUrl(""); Check updatedCheck; if (!check.isPresent()) { Checker checker = checkers.getChecker(checkerUuid) .orElseThrow(() -> new ResourceNotFoundException(String.format("checker %s not found", checkerUuid))); updatedCheck = Check.newBackfilledCheck( checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getPatchSet(), checker ); } else { updatedCheck = checksUpdate.get().updateCheck(key, builder.build()); } return checkJsonFactory.noOptions().format(updatedCheck);
Fixed Code: ``` assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); assertThat(info.updated).isGreaterThan(info.created); } @Test public void rerunCheckNotExistingButBackfilled() throws Exception { CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunExistingCheckWithCheckerNotAppliedToChange() throws Exception { Project.NameKey otherProject = createProjectOverAPI("other", null, true, null); checkerOperations.checker(checkKey.checkerUuid()).forUpdate().repository(otherProject).update(); checkOperations.newCheck(checkKey).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunNonExistingCheckWithCheckerNotAppliedToChange() throws Exception { Project.NameKey otherProject = createProjectOverAPI("other", null, true, null); checkerOperations.checker(checkKey.checkerUuid()).forUpdate().repository(otherProject).update(); assertThrows(ResourceNotFoundException.class, () -> { checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); }); } ```
// // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.inject.Inject; import com.google.inject.Singleton; import java.util.Optional; import org.eclipse.jgit.transport.URIish; /** * Factory for creating AdminApi instances. */ public interface AdminApiFactory { Optional<AdminApi> create(URIish uri); @Singleton static class DefaultAdminApiFactory implements AdminApiFactory { protected final SshHelper sshHelper; @Inject public DefaultAdminApiFactory(SshHelper sshHelper) { this.sshHelper = sshHelper; } @Override public Optional<AdminApi> create(URIish uri) { if (isGerrit(uri)) { return Optional.of(new GerritSshApi(sshHelper, uri)); } else if (!uri.isRemote()) { return Optional.of(new LocalFS(uri)); } return Optional.empty(); } /** * Checks if the given URIish is a Gerrit URI. * * @param uri the URIish to check * @return true if the URIish is a Gerrit URI, false otherwise */ private boolean isGerrit(URIish uri) { // implementation goes here } } }
if (destRef == null) { throw new ResourceConflictException("Can't rebase onto tip of branch " + destRefKey.get() + "; branch doesn't exist"); } return destRef.getObjectId(); Base base = rebaseUtil.parseBase(rsrc, str); if (base == null) { throw new ResourceConflictException("Base revision is missing from the destination branch: " + str); } PatchSet.Id baseId = base.patchSet().getId(); if (change.getId().equals(baseId.getParentKey())) { throw new ResourceConflictException("Cannot rebase change onto itself"); } permissionBackend .user(rsrc.getUser()) .database(dbProvider) .change(base.notes()) .check(ChangePermission.READ); Change baseChange = base.notes().getChange(); if (!baseChange.getProject().equals(change.getProject())) { throw new ResourceConflictException("Base change is in wrong project: " + baseChange.getProject()); } else if (!baseChange.getDest().equals(change.getDest())) { throw new ResourceConflictException("Base change is in wrong destination branch: " + baseChange.getDest()); }
package com.googlesource.gerrit.plugins.multisite.kafka; import com.google.gerrit.server.events.Event; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.broker.BrokerApi; import com.googlesource.gerrit.plugins.multisite.broker.kafka.BrokerPublisher; import com.googlesource.gerrit.plugins.multisite.consumer.SourceAwareEventWrapper; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventTopic; import com.googlesource.gerrit.plugins.multisite.kafka.consumer.KafkaEventSubscriber; import java.util.function.Consumer; public class KafkaBrokerApi implements BrokerApi { private final BrokerPublisher publisher; private final KafkaEventSubscriber subscriber; @Inject public KafkaBrokerApi(BrokerPublisher publisher, KafkaEventSubscriber subscriber) { this.publisher = publisher; this.subscriber = subscriber; } @Override public boolean send(String topic, Event event) { return publisher.publish(topic, event); } @Override public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { subscriber.subscribe(EventTopic.of(topic), eventConsumer); } }
public void receiveAsync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { subscriber.subscribe(EventTopic.of(topic), eventConsumer); }
} listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } install(new BrokerModule()); DynamicItem.bind(binder(), BrokerApi.class).to(KafkaBrokerApi.class); install(kafkaForwardedEventRouterModule); install(kafkaBrokerForwarderModule); install(new ValidationModule(config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); bind(Gson.class) .annotatedWith(BrokerGson.class) .toProvider(GsonProvider.class) .in(Singleton.class);
public void receiveAsync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { apiDelegate.get().receiveAsync(topic, eventConsumer); }
public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { KafkaEventSubscriber subscriber = subscriberProvider.get(); synchronized (subscribers) { subscribers.add(subscriber); } subscriber.subscribe(EventTopic.of(topic), eventConsumer); }
import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.config.SitePaths; import com.google.gerrit.server.util.ManualRequestContext; import com.google.gerrit.server.util.OneOffRequestContext; import com.google.gerrit.server.util.RequestContext; import com.google.gerrit.testing.ConfigSuite; import com.google.inject.Injector; import com.google.inject.Module; import com.google.inject.Provider; import java.io.File; import java.io.IOException; import java.util.Arrays; import java.util.Collections; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.StoredConfig; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.eclipse.jgit.util.SystemReader; import org.junit.Rule; import org.junit.rules.RuleChain; import org.junit.rules.TemporaryFolder; import org.junit.rules.TestRule; import org.junit.runner.Description; import org.junit.runner.RunWith; import org.junit.runners.model.Statement; @RunWith(ConfigSuite.class) @UseLocalDisk public abstract class StandaloneSiteTest { // code goes here }
return new FileBasedConfig(parent, new File(tempDir, "user.config"), FS.detect()); } @Override public FileBasedConfig openSystemConfig(Config parent, FS fs) { return new FileBasedConfig(parent, new File(tempDir, "system.config"), FS.detect()); } @Override public long getCurrentTime() { return oldSystemReader.getCurrentTime(); } @Override public int getTimezone(long when) { return oldSystemReader.getTimezone(when); } @Override public StoredConfig getUserConfig() throws IOException, ConfigInvalidException { return oldSystemReader.getUserConfig(); } @Override public StoredConfig getSystemConfig() throws IOException, ConfigInvalidException { return oldSystemReader.getSystemConfig(); }
private final Map<URIish, PushOne> pending = new HashMap<>(); private final Map<URIish, PushOne> inFlight = new HashMap<>(); private final PushOne.Factory opFactory; private final GitRepositoryManager gitManager; private final PermissionBackend permissionBackend; private final Provider<CurrentUser> userProvider; private final ProjectCache projectCache; private volatile ScheduledExecutorService pool; private final PerThreadRequestScope.Scoper threadScoper; private final DestinationConfiguration config; private final DynamicItem<EventDispatcher> eventDispatcher; private final ReplicationTasksStorage replicationTasksStorage; protected enum RetryReason { TRANSPORT_ERROR, COLLISION, REPOSITORY_MISSING; } public static class QueueInfo { public final Map<URIish, PushOne> pending; public final Map<URIish, PushOne> inFlight; public QueueInfo(Map<URIish, PushOne> pending, Map<URIish, PushOne> inFlight) { this.pending = ImmutableMap.copyOf(pending); this.inFlight = ImmutableMap.copyOf(inFlight); } } @Inject protected Destination( Injector injector, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, ScheduledExecutorService pool, PerThreadRequestScope.Scoper threadScoper, DestinationConfiguration config, DynamicItem<EventDispatcher> eventDispatcher, ReplicationTasksStorage replicationTasksStorage) { this.opFactory = injector.getInstance(PushOne.Factory.class); this.gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.pool = pool; this.threadScoper = threadScoper; this.config = config; this.eventDispatcher = eventDispatcher; this.replicationTasksStorage = replicationTasksStorage; }
protected Destination(Injector injector, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, GroupBackend groupBackend, ReplicationStateListeners stateLog, GroupIncludeCache groupIncludeCache, DynamicItem<EventDispatcher> eventDispatcher, ReplicationTasksStorage rts, @Assisted DestinationConfiguration cfg) { this.eventDispatcher = eventDispatcher; gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.stateLog = stateLog; this.eventsStorage = rts; config = cfg; CurrentUser remoteUser; if (!cfg.getAuthGroupNames().isEmpty()) { ImmutableSet.Builder<AccountGroup.UUID> builder = ImmutableSet.builder(); for (String name : cfg.getAuthGroupNames()) { GroupReference g = GroupBackends.findExactSuggestion(groupBackend, name); if (g != null) { builder.add(g.getUUID()); addRecursiveParents(g.getUUID(), builder, groupIncludeCache); } else {
return; } } } synchronized (stateLock) { PushOne e = getPendingPush(uri); if (e == null) { e = opFactory.create(project, uri); addRef(e, ref); e.addState(ref, state); @SuppressWarnings("unused") ScheduledFuture<?> ignored = pool.schedule(e, now ? 0 : config.getDelay(), TimeUnit.SECONDS); pending.put(uri, e); eventsStorage.persist(project.get(), ref, e.getURI(), getRemoteConfigName()); } else if (!e.getRefs().contains(ref)) { addRef(e, ref); e.addState(ref, state); } state.increasePushTaskCount(project.get(), ref); repLog.info("scheduled {}:{} => {} to run after {}s", project, ref, e, config.getDelay()); }
void notifyFinished(PushOne op) { synchronized (stateLock) { inFlight.remove(op.getURI()); if (!op.wasCanceled()) { for (String ref : op.getRefs()) { if (!refHasPendingPush(op.getURI(), ref)) { eventsStorage.delete(op.getProjectNameKey().get(), ref, op.getURI(), getRemoteConfigName()); } } } } }
String key = "${name}"; int n = in.indexOf(key); if (0 <= n) { return in.substring(0, n) + name + in.substring(n + key.length()); } if (keyIsOptional) { return in; } return null; } private final WorkQueue workQueue; private final DynamicItem<EventDispatcher> dispatcher; private final ReplicationConfig config; private final AdminApiFactory adminApiFactory; private final ReplicationState.Factory replicationStateFactory; private final ReplicationTasksStorage replicationTasksStorage; private volatile boolean running; private volatile boolean replaying; @Inject ReplicationQueue(WorkQueue wq, AdminApiFactory aaf, ReplicationConfig rc, DynamicItem<EventDispatcher> dis, ReplicationStateListeners sl, ReplicationState.Factory rsf, ReplicationTasksStorage es) { workQueue = wq; dispatcher = dis; config = rc; stateLog = sl; adminApiFactory = aaf; replicationStateFactory = rsf; replicationTasksStorage = es; } @Override public void start() { if (!running) { config.startup(workQueue); running = true; } }
return in; } return null; } private final WorkQueue workQueue; private final DynamicItem<EventDispatcher> dispatcher; private final ReplicationConfig config; private final AdminApiFactory adminApiFactory; private final ReplicationState.Factory replicationStateFactory; private final ReplicationTasksStorage eventsStorage; private volatile boolean running; private volatile boolean replaying; @Inject ReplicationQueue(WorkQueue wq, AdminApiFactory aaf, ReplicationConfig rc, DynamicItem<EventDispatcher> dis, ReplicationStateListeners sl, ReplicationState.Factory rsf, ReplicationTasksStorage storage) { workQueue = wq; dispatcher = dis; config = rc; stateLog = sl; adminApiFactory = aaf; replicationStateFactory = rsf; eventsStorage = storage; } @Override public void start() { if (!running) { config.startup(workQueue); running = true; firePendingEvents(); } } @Override public void stop() { running = false; int discarded = config.shutdown(); if (discarded > 0) { log.warn("Discarded {} replication tasks during shutdown", discarded); } }
private void firePendingEvents() { try { Set<String> eventsReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate e : eventsStorage.list()) { String eventKey = String.format("%s:%s", e.project, e.ref); if (!eventsReplayed.contains(eventKey)) { repLog.info("Firing pending event {}", eventKey); onGitReferenceUpdated(e.project, e.ref); eventsReplayed.add(eventKey); } } } finally { replaying = false; } }
import java.util.List; import java.util.Map; import java.util.Set; class ReplayInlineCommentsStep { interface Factory { ReplayInlineCommentsStep create(Change change, ChangeInfo changeInfo, GerritApi api, boolean resume); } private static final Logger log = LoggerFactory.getLogger(ReplayInlineCommentsStep.class); private final AccountUtil accountUtil; private final ReviewDb db; private final IdentifiedUser.GenericFactory genericUserFactory; private final ChangeControl.GenericFactory changeControlFactory; private final ChangeUpdate.Factory updateFactory; private final CommentsUtil commentsUtil; private final PatchListCache patchListCache; private final PatchSetUtil psUtil; private final String serverId; private final Change change; private final ChangeInfo changeInfo; private final GerritApi api; private final boolean resume; @Inject public ReplayInlineCommentsStep(AccountUtil accountUtil, ReviewDb db, IdentifiedUser.GenericFactory genericUserFactory, ChangeControl.GenericFactory changeControlFactory, ChangeUpdate.Factory updateFactory, CommentsUtil commentsUtil, PatchListCache patchListCache, PatchSetUtil psUtil, @GerritServerId String serverId, @Assisted Change change, @Assisted ChangeInfo changeInfo, @Assisted GerritApi api, @Assisted boolean resume) { this.accountUtil = accountUtil; this.db = db; this.genericUserFactory = genericUserFactory; this.changeControlFactory = changeControlFactory; this.updateFactory = updateFactory; this.commentsUtil = commentsUtil; this.patchListCache = patchListCache; this.psUtil = psUtil; this.serverId = serverId; this.change = change; this.changeInfo = changeInfo; this.api = api; this.resume = resume; } }
void notifyFinished(PushOne op) { synchronized (stateLock) { inFlight.remove(op.getURI()); if (!op.wasCanceled()) { for (String ref : op.getRefs()) { if (!refHasPendingPush(op.getURI(), ref)) { replicationTasksStorage.delete(op.getProjectNameKey().get(), ref, op.getURI(), getRemoteConfigName()); } } } } }
public void delete(String project, String ref, URIish uri, String remote) { ReplicateRefUpdate r = new ReplicateRefUpdate(); r.project = project; r.ref = ref; r.uri = uri.toASCIIString(); r.remote = remote; String eventJson = GSON.toJson(r) + "\n"; String eventKey = sha1(eventJson).name(); try { logger.atFiner().log("DELETE %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); } }
public void delete(String project, String ref, URIish uri, String remote) { ReplicateRefUpdate r = new ReplicateRefUpdate(); r.project = project; r.ref = ref; r.uri = uri.toASCIIString(); r.remote = remote; String eventJson = GSON.toJson(r) + "\n"; String eventKey = sha1(eventJson).name(); try { logger.atFiner().log("DELETE %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); } }
if (!running) { stateLog.warn("Replication plugin did not finish startup before event", state); return; } Project.NameKey project = new Project.NameKey(projectName); for (Destination cfg : config.getDestinations(FilterType.ALL)) { if (cfg.wouldPushProject(project) && cfg.wouldPushRef(refName)) { for (URIish uri : cfg.getURIs(project, null)) { replicationTasksStorage.persist(projectName, refName, uri, cfg.getRemoteConfigName()); cfg.schedule(project, refName, uri, state); } } } state.markAllPushTasksScheduled();
private void firePendingTasks() { try { Set<String> tasksReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate t : replicationTasksStorage.list()) { String taskKey = String.format("%s:%s", t.project, t.ref); if (!tasksReplayed.contains(taskKey)) { repLog.info("Firing pending task {}", taskKey); onGitReferenceUpdated(t.project, t.ref); tasksReplayed.add(taskKey); } } } finally { replaying = false; } }
private void firePendingEvents() { try { Set<String> tasksReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate t : replicationTasksStorage.list()) { String taskKey = String.format("%s:%s", t.project, t.ref); if (!tasksReplayed.contains(taskKey)) { repLog.info("Firing pending task {}", taskKey); onGitReferenceUpdated(t.project, t.ref); tasksReplayed.add(taskKey); } } } finally { replaying = false; } }
public String persist(ReplicateRefUpdate replicateRefUpdate) { String json = GSON.toJson(replicateRefUpdate) + "\n"; String eventKey = sha1(json).name(); Path file = refUpdates().resolve(eventKey); if (Files.exists(file)) { return eventKey; } try { logger.atFine().log("CREATE %s:%s => %s", replicateRefUpdate.project, replicateRefUpdate.ref, replicateRefUpdate.uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().log("Couldn't persist event %s", json, e); } return eventKey; }
String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path file = refUpdates().resolve(eventKey); if (Files.exists(file)) { return eventKey; } try { logger.atFine().log("CREATE %s:%s => %s", project, ref, uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey;
import com.google.common.collect.HashBasedTable; import com.google.common.collect.Table; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import java.util.concurrent.CountDownLatch; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; import org.eclipse.jgit.transport.RemoteRefUpdate; import org.eclipse.jgit.transport.URIish; import org.slf4j.Logger; public class ReplicationState { private static final Logger repLog = ReplicationQueue.repLog; public interface Factory { ReplicationState create(PushResultProcessing processing); } private boolean allScheduled; private final EventsStorage eventsStorage; private final PushResultProcessing pushResultProcessing; private final Lock countingLock = new ReentrantLock(); private final CountDownLatch allPushTasksFinished = new CountDownLatch(1); private static class RefReplicationStatus { private final String project; private final String ref; private int nodesToReplicateCount; private int replicatedNodesCount; RefReplicationStatus(String project, String ref) { this.project = project; this.ref = ref; } public boolean allDone() { // implementation } } } private String getOutgoingConnectorKind() { TaskRepository repository = getOutgoingRepository(); if (repository != null) { return repository.getConnectorKind(); } else if (task != null) { return task.getConnectorKind(); } } private static final String DATA_UNIT_DIR = "/data/unit/refresh/roundedCorner/"; private static final String SEMANTIC_RESOURCE_FILENAME = "VP-2700.ecore"; private static final String SESSION_RESOURCE_FILENAME = "VP-2700.aird"; private static final String MODELER_RESOURCE_FILENAME = "VP-2700.odesign"; private static final String REPRESENTATION_INSTANCE_NAME = "new VP-2700_Diagram"; private static final String REPRESENTATION_NAME = "VP-2700_Diagram"; private List<SWTBotGefEditPart> dNodeContainerEditPartBots; private Resource modelerResource; private List<ContainerMapping> containerMappings; private void initializeContainerStyleDescriptions() { ResourceSet resourceSet = new ResourceSetImpl(); Viewpoint viewpoint = localSession.getOpenedSession().getSelectedViewpoints(false).iterator().next(); URI modelerResourceURI = viewpoint.e
import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.junit.Test; @UseLocalDisk @TestPlugin(name = "replication", sysModule = "com.googlesource.gerrit.plugins.replication.ReplicationModule") public class ReplicationIT extends LightweightPluginDaemonTest { private static final int TEST_REPLICATION_DELAY = 2; private static final Duration TEST_TIMEMOUT = Duration.ofSeconds(TEST_REPLICATION_DELAY * 10); @Inject private SitePaths sitePaths; private Path pluginDataDir; private Path gitPath; private Path storagePath; private FileBasedConfig config; @Override public void setUpTestPlugin() throws Exception { config = new FileBasedConfig(sitePaths.etc_dir.resolve("replication.config").toFile(), FS.DETECTED); config.save(); gitPath = sitePaths.site_path.resolve("git"); super.setUpTestPlugin(); pluginDataDir = plugin.getSysInjector().getInstance(Key.get(Path.class, PluginData.class)); storagePath = pluginDataDir.resolve("ref-updates"); } @Test public void testReplication() { // Test code goes here } }
import static java.util.stream.Collectors.toList; e.printStackTrace(); return null; } private void setReplicationDestination(String remoteName, String replicaSuffix, int replicationDelay) throws IOException { setReplicationDestination(remoteName, Arrays.asList(replicaSuffix), replicationDelay); } private void setReplicationDestination(String remoteName, List<String> replicaSuffixes, int replicationDelay) throws IOException { List<String> replicaUrls = replicaSuffixes.stream() .map(suffix -> gitPath.resolve("${name}" + suffix + ".git").toString()) .collect(toList()); config.setStringList("remote", remoteName, "url", replicaUrls); config.setInt("remote", remoteName, "replicationDelay", replicationDelay); config.save(); reloadConfig(); } private void waitUntil(Supplier<Boolean> waitCondition) throws InterruptedException { Stopwatch stopwatch = Stopwatch.createStarted(); while (!waitCondition.get() && stopwatch.elapsed().compareTo(TEST_TIMEMOUT) < 0) { TimeUnit.SECONDS.sleep(1); } } private void reloadConfig() { plugin.getSysInjector().getInstance(AutoReloadConfigDecorator.class).forceReload(); }
private static class RefReplicationStatus { private final String project; private final String ref; private int nodesToReplicateCount; private int replicatedNodesCount; RefReplicationStatus(String project, String ref) { this.project = project; this.ref = ref; } public boolean allDone() { return replicatedNodesCount == nodesToReplicateCount; } } private final Table<String, String, RefReplicationStatus> statusByProjectRef; private int totalPushTasksCount; private int finishedPushTasksCount; @AssistedInject ReplicationState(@Assisted PushResultProcessing processing) { pushResultProcessing = processing; statusByProjectRef = HashBasedTable.create(); } public void increasePushTaskCount(String project, String ref) { countingLock.lock(); try { getRefStatus(project, ref).nodesToReplicateCount++; totalPushTasksCount++; } finally { countingLock.unlock(); } } public boolean hasPushTask() { return totalPushTasksCount != 0; } public void notifyRefReplicated(String project, String ref, URIish uri, RefPushResult status, @Nullable Throwable error) { countingLock.lock(); try { RefReplicationStatus refStatus = getRefStatus(project, ref); refStatus.replicatedNodesCount++; finishedPushTasksCount++; if (refStatus.allDone()) { statusByProjectRef.remove(project, ref); } } finally { countingLock.unlock(); } pushResultProcessing.processPushResult(project, ref, uri, status, error); }
super(retryHelper); this.opFactory = opFactory; this.editUtil = editUtil; @Override protected Response<Object> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException, IOException { if (!isChangeDeletable(rsrc)) { throw new MethodNotAllowedException("delete not permitted"); } rsrc.permissions().check(ChangePermission.DELETE); Optional<ChangeEdit> edit = editUtil.byChange(rsrc.getNotes(), rsrc.getUser()); try (BatchUpdate bu = updateFactory.create(rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) { Change.Id id = rsrc.getChange().getId(); bu.addOp(id, opFactory.create(id)); if (edit.isPresent()) { bu.addOp(id, new BatchUpdateOp() { @Override public boolean updateChange(ChangeContext ctx) throws Exception { editUtil.delete(edit.get()); return true; } }); } bu.execute(); } return Response.none(); } @Override
public Optional<Change> getUpdatedChange() { return Optional.ofNullable(updatedChange); }
Project.NameKey key = new Project.NameKey(projectName); try (Repository repository = repoManager.openRepository(key)) { RepositoryCache.close(repository); } cleanCache(key); FileUtils.deleteDirectory(gitDirectory); projectCache.remove(key); sendProjectDeletedEvent(projectName); return true; } catch (IOException e) { LOG.error("Cannot clean-up output Git directory " + gitDirectory); return false; } private void cleanCache(Project.NameKey key) throws IOException { Repository repository = repoManager.openRepository(key); repository.close(); RepositoryCache.close(repository); } private void sendProjectDeletedEvent(String projectName) { ProjectDeletedListener.Event event = new ProjectDeletedListener.Event() { @Override public String getProjectName() { return projectName; } @Override public NotifyHandling getNotify() { return NotifyHandling.NONE; } }; for (ProjectDeletedListener l : deletedListeners) { try { l.onProjectDeleted(event); } catch (RuntimeException e) { LOG.warn("Failure in ProjectDeletedListener", e); } } }
public boolean rollback() { File gitDirectory = destinationDirectory; if (!gitDirectory.exists()) { return false; } try { String projectName = organisation + "/" + repository; Project.NameKey key = new Project.NameKey(projectName); cleanJGitCache(key); FileUtils.deleteDirectory(gitDirectory); projectCache.remove(key); sendProjectDeletedEvent(projectName); return true; } catch (IOException e) { LOG.error("Cannot clean-up output Git directory " + gitDirectory); return false; } }
private static final String CAP_BOOLEAN_FALSE = "false"; private final IObjectPool<IARecordBuilder, ATypeTag> recordBuilderPool = new ListObjectPool<>(new RecordBuilderFactory()); private final IObjectPool<IAsterixListBuilder, ATypeTag> listBuilderPool = new ListObjectPool<>(new ListBuilderFactory()); private final IObjectPool<IMutableValueStorage, ATypeTag> abvsBuilderPool = new ListObjectPool<>(new AbvsBuilderFactory()); private ARecordType recordType; private SAXParserFactory capMessageSAXParserFactory; private SAXParser capMessageSAXParser; private ComplexBuilder complexBuilder; private ArrayList<ComplexBuilder> builderList; private ListElementHandler listElementHandler; private CAPMessageHandler capMessageHandler; private HashMap<String, Integer> listElementNames; private SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd'T'hh:mm:ss"); public CAPMessageParser(ARecordType recordType) throws HyracksDataException { this.recordType = recordType; bufferList = new ArrayList<>(); rbList = new ArrayList<>(); listElementNames = new HashMap<>(); fieldNameBuffer = getTempBuffer(); }
public void configureServlets() { for (String p : POLYGERRIT_INDEX_PATHS) { if (!options.enableGwtUi() || !p.equals("/")) { filter(p).through(XsrfCookieFilter.class); } } filter("/*").through(PolyGerritFilter.class); }
public ReplicateRefUpdate(String project, String ref, URIish uri, String remote) { this.project = project; this.ref = ref; this.uri = uri.toASCIIString(); this.remote = remote; }
public String persist(ReplicateRefUpdate r) { String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path path = refUpdates().resolve(eventKey); if (Files.exists(path)) { return eventKey; } try { logger.atFine().log("CREATE %s (%s)", path, r); Files.write(path, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey; }
public String persist(ReplicateRefUpdate r) { String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path path = refUpdates().resolve(eventKey); if (Files.exists(path)) { return eventKey; } try { logger.atFine().log("CREATE %s (%s)", path, r.toString()); Files.write(path, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey; }
public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); Path file = refUpdates().resolve(taskKey); try { logger.atFine().log("DELETE %s (%s)", file, r); Files.delete(file); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); } }
public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); Path path = refUpdates().resolve(taskKey); try { logger.atFine().log("DELETE %s (%s)", path, r); Files.delete(refUpdates().resolve(taskKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); } }
public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); Path path = refUpdates().resolve(taskKey); try { logger.atFine().log("DELETE %s (%s)", path, r); Files.delete(path); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); } }
package com.google.gerrit.pgm; import static com.google.common.base.MoreObjects.firstNonNull; import static java.nio.charset.StandardCharsets.UTF_8; import static java.util.stream.Collectors.joining; import static java.util.stream.Collectors.toList; import com.google.common.collect.ImmutableList; import com.google.gerrit.extensions.config.FactoryModule; import com.google.gerrit.lifecycle.LifecycleManager; import com.google.gerrit.pgm.util.BatchProgramModule; import com.google.gerrit.pgm.util.RuntimeShutdown; import com.google.gerrit.pgm.util.SiteProgram; import com.google.gerrit.reviewdb.client.Change; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.change.ChangeResource; import com.google.gerrit.server.git.GarbageCollection; import com.google.gerrit.server.index.DummyIndexModule; import com.google.gerrit.server.index.change.ChangeSchemaDefinitions; import com.google.gerrit.server.notedb.rebuild.GcAllUsers; import com.google.gerrit.server.notedb.rebuild.NoteDbMigrator; import com.google.gerrit.server.plugins.PluginGuiceEnvironment; import com.google.inject.Inject; import com.google.inject.Injector; import com.google.inject.Provider; import java.io.OutputStreamWriter; public class Main { public static void main(String[] args) throws Exception { Injector injector = createInjector(); try { SiteProgram program = injector.getInstance(SiteProgram.class); program.run(); } finally { LifecycleManager lifecycle = injector.getInstance(LifecycleManager.class); lifecycle.stop(); } } private static Injector createInjector() { return Guice.createInjector( new FactoryModule(), new BatchProgramModule(), new DummyIndexModule(ChangeSchemaDefinitions.INSTANCE), new PluginGuiceEnvironment(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(),
} return fileConfig; }); } return ofInstance(config); } public static class Kafka { private final Map<EventTopic, String> eventTopics; private final String bootstrapServers; Kafka(Supplier<Config> config) { this.bootstrapServers = getString( config, KAFKA_SECTION, null, "bootstrapServers", DEFAULT_KAFKA_BOOTSTRAP_SERVERS); this.eventTopics = new HashMap<>(); for (EventTopic eventTopic : EventTopic.values()) { String topicConfigKey = eventTopic.topicAliasKey(); eventTopics.put( eventTopic, getString(config, KAFKA_SECTION, null, topicConfigKey, eventTopic.topic())); } } public String getTopicAlias(EventTopic topic) { return eventTopics.get(topic); } public String getBootstrapServers() { return bootstrapServers; } private static String getString( Supplier<Config> cfg, String section, String subsection, String name, String defaultValue) { String value = cfg.get().getString(section, subsection, name); if (!Strings.isNullOrEmpty(value)) { return value; } return defaultValue; }
reloadConfig(); waitForEmptyTasks(); Project.NameKey targetProject = createProject("projectreplica"); String newBranch = "refs/heads/mybranch"; String master = "refs/heads/master"; BranchInput input = new BranchInput(); input.revision = master; gApi.projects().name(project.get()).branch(newBranch).create(input); assertThat(listReplicationTasks("refs/heads/(mybranch|master)")).hasSize(2); try (Repository repo = repoManager.openRepository(targetProject); Repository sourceRepo = repoManager.openRepository(project)) { waitUntil(() -> checkedGetRef(repo, newBranch) != null); Ref masterRef = getRef(sourceRepo, master); Ref targetBranchRef = getRef(repo, newBranch); assertThat(targetBranchRef).isNotNull(); assertThat(targetBranchRef.getObjectId()).isEqualTo(masterRef.getObjectId()); } } @Test public void shouldReplicateNewBranchToTwoRemotes() throws Exception { Project.NameKey targetProject1 = createProject("projectreplica1"); Project.NameKey targetProject2 = createProject("projectreplica2"); }
Change updatedChange = op.merge(change, submitter, true, input, false); if (updatedChange.isMerged()) { return change; } String errorMessage = String.format("change %s unexpectedly had status %s after submit attempt", updatedChange.getId(), updatedChange.getStatus()); logger.atWarning().log(errorMessage); throw new RestApiException(errorMessage);
config.save(); super.setUpTestPlugin(); pluginDataDir = plugin.getSysInjector().getInstance(Key.get(Path.class, PluginData.class)); storagePath = pluginDataDir.resolve("ref-updates"); @Test public void shouldReplicateNewProject() throws Exception { setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Project.NameKey sourceProject = createProject("foo"); assertThat(listReplicationTasks("refs/meta/config")).hasSize(1); waitUntil(() -> gitPath.resolve(sourceProject + "replica.git").toFile().isDirectory()); ProjectInfo replicaProject = gApi.projects().name(sourceProject + "replica").get(); assertThat(replicaProject).isNotNull(); } @Test public void shouldReplicateNewChangeRef() throws Exception { Project.NameKey targetProject = createProject("projectreplica"); setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Result pushResult = createChange(); RevCommit sourceCommit = pushResult.getCommit(); }
@Test public void shouldReplicateNewProject() throws Exception { setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Project.NameKey sourceProject = createProject("foo"); assertThat(listReplicationTasks("refs/meta/config")).hasSize(1); waitUntil(() -> projectExists(new Project.NameKey(sourceProject + "replica.git"))); ProjectInfo replicaProject = gApi.projects().name(sourceProject + "replica").get(); assertThat(replicaProject).isNotNull(); } @Test public void shouldReplicateNewChangeRef() throws Exception { Project.NameKey targetProject = createProject("projectreplica"); setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Result pushResult = createChange(); RevCommit sourceCommit = pushResult.getCommit(); String sourceRef = pushResult.getPatchSet().getRefName(); assertThat(listReplicationTasks("refs/changes/\\d*/\\d*/\\d*")).hasSize(1); try (Repository repo = repoManager.openRepository(targetProject)) { // ... } }
private static final String CONFIG_FILE_PATH = "/data/local/tmp/"; private static final String CLOUD_PROPERTY_FILE = "cloud.properties"; private static boolean s_mIsCbInvoked = CALLBACK_NOT_INVOKED; private enum CloudAuth { SIGNUP, SIGNIN, SIGNOUT }; private enum LogLevel { INFO, ERROR, DEBUG }; private static Properties s_mProps; private static String s_mFilePath; private static String s_mFileName; private static File s_mFile; public static CloudAuth s_mMethodName; public static String s_mCloudUid; public static String s_mCloudAccessToken; public static String s_mAuthCode; public static String s_mErrorMessage; public static void init(String fileDir) { s_mProps = new Properties(); ReadConfigPropFile.readConfigFile(CONFIG_FILE_PATH); s_mFile = new File(fileDir + CLOUD_PROPERTY_FILE); if (!s_mFile.exists()) { getAuthCode(); } } private static void getAuthCode() { Log.d(TAG, "getAuthCode IN"); GetAuthCode getContent = new GetAuthCode(); try { // code implementation } catch (Exception e) { // exception handling } }
public class OcAccountManagerHelper implements OcAccountManager.OnPostListener, IConfiguration { private static final String TAG = "OcAccountManagerHelper"; private static final String CONFIG_FILE_PATH = "/data/local/tmp/"; private static final String CLOUD_PROPERTY_FILE = "cloud.properties"; private static boolean s_mIsCbInvoked = CALLBACK_NOT_INVOKED; private enum CloudAuth { SIGNUP, SIGNIN, SIGNOUT }; private enum LogLevel { INFO, ERROR, DEBUG }; private static Properties s_mProps; private static String s_mFilePath; private static String s_mFileName; private static File s_mFile; public static CloudAuth s_mMethodName; public static String s_mCloudUid; public static String s_mCloudAccesstoken; public static String s_mAuthCode; public static String s_mErrorMessage; public static String s_CloudUid; public static String s_CloudAccesstoken; public static String authCode; public static String mErrorMessage; public static void init(String fileDir) { s_mProps = new Properties(); ReadConfigPropFile.readConfigFile(CONFIG_FILE_PATH); s_mFile = new File(fileDir + CLOUD_PROPERTY_FILE); if (!s_mFile.exists()) { getAuthCode(); } } private static void getAuthCode() { Log.d(TAG, "getAuthCode IN"); GetAuthCode getContent = new GetAuthCode(); try { OcAccountManagerHelper.authCode = getContent.execute().get(); // Rest of the code } catch (Exception e) { Log.e(TAG, "getAuthCode: Exception occurred: " + e.getMessage()); } } }
private static final String START_PRE_CONFIG_SERVER_01 = "./iotivity_pm_server " + PRECONFIG_SERVER_UNOWNED_CBOR_01 + " 3"; private static final String START_RE_SERVER = "./iotivity_re_server"; private static final String PROVISION_DB_FILE = "./Pdm.db"; private static final String DEVICE_PROP_CBOR_FILE = "./device_properties.dat"; private TestBroadCast mTestBroadCast; protected RIHelperCommon(IoTivityTc iotivityTcObj) { s_helperContext = iotivityTcObj.getInstrumentation().getTargetContext(); s_filePath = s_helperContext.getFilesDir().getPath(); s_sqLPath = s_helperContext.getFilesDir().getAbsolutePath().replace(FILES, DATABASES) + File.separator; mTestBroadCast = new TestBroadCast(s_helperContext); } public boolean configClientServerPlatform() { PlatformConfig cfg = new PlatformConfig(s_helperContext, ServiceType.IN_PROC, ModeType.CLIENT_SERVER, "0.0.0.0", 0, QualityOfService.HIGH); OcPlatform.Configure(cfg); }
package org.iotivity.testcase; import android.util.Log; public class IoTivityLog { public static void v(String tag, String format) { Log.v(tag, format); } public static void d(String tag, String format) { Log.d(tag, format); } public static void i(String tag, String format) { Log.i(tag, format); } public static void w(String tag, String format) { Log.w(tag, format); } public static void e(String tag, String format) { Log.e(tag, format); } }
package org.iotivity.testcase; import java.util.logging.Logger; public class IoTivityLog { public static void v(String tag, String format) { System.out.println(tag + " : " + format); } public static void d(String tag, String format) { System.out.println(tag + " : " + format); } public static void i(String tag, String format) { System.out.println(tag + " : " + format); } public static void w(String tag, String format) { System.out.println(tag + " : " + format); } public static void e(String tag, String format) { System.out.println(tag + " : " + format); } }
public void testConfigureServerInProc_SRC_P() { try { PlatformConfig cfg = new PlatformConfig(ServiceType.IN_PROC, ModeType.SERVER, "0.0.0.0", 0, QualityOfService.HIGH); OcPlatform.Configure(cfg); } catch (Exception e) { e.printStackTrace(); fail("Exception occurred"); } }
import org.iotivity.base.QualityOfService; import org.iotivity.base.RequestHandlerFlag; import org.iotivity.base.RequestType; import org.iotivity.base.ResourceProperty; import org.iotivity.base.ServiceType; import org.iotivity.base.OcRepresentation; import org.iotivity.base.OcResource; import org.iotivity.base.OcResource.OnObserveListener; import org.iotivity.base.OcResourceHandle; import org.iotivity.testcase.IoTivityLog; import org.iotivity.testcase.IoTivityTc; import org.iotivity.test.ri.common.RIHelperCommon; public class RIHelper extends RIHelperCommon implements IRIConstants { private static RIHelper s_riHelperInstance = null; private final String LOG_TAG = this.getClass().getSimpleName(); private OcResourceHandle m_resourceHandle = null; public EnumSet<ResourceProperty> m_resourceProperty; public static final String TEMPERATURE_RESOURCE_QUERY = OcPlatform.WELL_KNOWN_QUERY + "?rt=" + RESOURCE_TYPE_TEMPERATURE; private OcRepresentation m_representation = null; public int m_temp; public int m_hour; public static boolean s_isServerOk; public static String s_errorMsg; }
Map<String, String> queryParamsMap, OnPostListener onPostListener, QualityOfService qualityOfService) @test_data 1. resourceUri "/test/ri/android/temperature" 2. resourceTypeName "oic.r.temperature" 3. resourceInterface DEFAULT_INTERFACE 4. entityHandler entity handler 5. resourcePropertySet indicates property of the resource 6. representation representation to set 7. queryParamsMap map with query paramter and value 8. onPostListener event handler 9. qualityOfService High @pre_condition Configure platform for client server mode @procedure 1. Perform registerResource() API 2. Perform findResource() API with resource type in query 3. Check if callback is called 4. Check if temperature resource is found 5. Perform post() API(with qos) on the found temperature resource 6. Check if server can get the post request and send response correctly
public void onReceive(Context context, Intent intent) { Log.d(TAG, "BroadcastReceiver Invoked"); Log.d(TAG, "Recieved Braodcasted MSG : " + intent.getStringExtra("key")); if (mTcpClient != null) { mTcpClient.sendMessage(intent.getStringExtra("key")); } else { Log.e(TAG, "TCP Client is not initialized"); } }
(byte) 0x66, (byte) 0x11, (byte) 0xa5, (byte) 0x84, (byte) 0x99, (byte) 0x8d, (byte) 0x0d, (byte) 0xbd, (byte) 0xb1, (byte) 0x54, (byte) 0xbb, (byte) 0xc5, (byte) 0x4f, (byte) 0xed, (byte) 0x86, (byte) 0x9a, (byte) 0x66, (byte) 0x11 }; PMConstants.mErrorMessage = PMConstants.EMPTY_STRING; mPMHelper.clearAll(); mPMHelper.stopServers(); mPMHelper.startSecuredServer(mPMHelper.START_JUSTWORKS_SERVER_01); mPMHelper.startSecuredServer(mPMHelper.START_JUSTWORKS_SERVER_02); PMHelper.delay(5); mPMHelper.copyCborFromAsset(PMConstants.OIC_CLIENT_CBOR_DB_FILE); mPMHelper.configClientServerPlatform(PMConstants.OIC_CLIENT_CBOR_DB_FILE); mPMHelper.initOICStack(PMHelper.s_sqLPath, PMConstants.OIC_SQL_DB_FILE); } protected void tearDown() throws Exception { mPMHelper.stopServers(); mPMHelper.clearAll(); super.tearDown(); }
public static final String OIC_JWSERVER_CBOR_DB_FILE_2 = "oic_svr_db_server.dat"; public static final String OIC_DP_CLIENT_CBOR_DB_FILE = "oic_svr_db_client_directpairing.dat"; public static final String OIC_CLOUD_CLIENT = "cloud.dat"; public static final String OIC_SQL_DB_FILE = "Pdm.db"; public static final String OIC_MOT_SQL_DB_FILE = "MOT_Pdm.db"; public static final String SERVER_SQL_DB_FILE = "ServerPdm.db"; public static final String CERT_SERIAL_ONE = "1"; public static final String DEFAULT_ROWNER_ID = "61646d69-6e44-6576-6963-655555494430"; public static final String DEFAULT_RESOURCES = "*"; public static final String HREF_RESOURCES_1A = "/a/device1a"; public static final String HREF_RESOURCES_1B = "/a/device1b"; public static final String HREF_RESOURCES_2A = "/a/device2a"; public static final String HREF_RESOURCES_2B = "/a/device2b";
try { m_resource.put(m_rep, qpMap, onPut); } catch (Exception e) { e.printStackTrace(); fail("Exception occurred"); }
protected void initModel(String projectName, String modelName, Bundle bundle) throws CoreException, IOException { project = ProjectUtils.createProject(projectName); diModelFile = PapyrusProjectUtils.copyPapyrusModel(project, bundle, getSourcePath(), modelName); } protected String getSourcePath() { return "models/"; } protected Bundle getBundle() { return Activator.getDefault().getBundle(); } public ICellEditor getICellEditor(Table table, Object axisElement, ITableAxisElementProvider elementProvider) { super.getICellEditor(table, axisElement, elementProvider); AbstractPapyrusStyledTextCellEditor editor = new UMLReferenceTextWithCompletionCellEditor(table, axisElement, elementProvider); AbstractOpenDialogCellEditorButtonAction openDialog = getCellEditorWithDialogToOpen(axisElement, elementProvider); editor.setOpenDialogCellEditorButtonAction(openDialog); openDialog.setText("..."); //$NON-NLS-1$ openDialog.setTooltipText(Messages.UMLReferenceCellEditorConfiguration_OpenDialogToChooseTheValue); return editor; } public void apply(String value) { if (!label.isDisposed() && !(label.getText() != null && label.getText().equals(value))) { label.setText(Objects.firstNonNull(value, "")); //$NON-NLS-1$ EEFWidgetStyle style = getWidgetStyle(); List<EEFConditionalStyle> conditionalStyles = getWidgetConditionalStyles(); if (conditionalStyles != null && !conditionalStyles.isEmpty()) { style = getConditionalStyle(conditionalStyles); } if (style != null) { setLabelFontStyle(style); } } } public void testConfigureServerNon_SRC_P() { try { PlatformConfig cfg = new PlatformConfig(ServiceType.IN_PROC, ModeType.SERVER, "0.0.0.0", 0, QualityOfService.LOW); OcPlatform.Configure(cfg); } catch (Exception e) { e.printStackTrace(); fail("Exception occured"); } }
String DEVICE_TYPE_AC = "AirCondition"; String RESOURCE_URI_TEMPERATURE = "/test/ri/android/temperature"; String RESOURCE_TYPE_TEMPERATURE = "oic.r.temperature"; String RESOURCE_URI_LIGHT = "/a/light"; String RESOURCE_TYPE_LIGHT = "core.light"; String RESOURCE_URI_FAN = "/a/fan"; String RESOURCE_TYPE_FAN = "core.fan"; String HOST = "coap://192.168.1.2:5000"; int INT_ZERO = 0; int INT_ONE = 1; int INT_TWO = 2; int INT_MINUS_ONE = -1; int CALLBACK_WAIT_DEFAULT = 5; int CALLBACK_WAIT_MAX = 10; int CALLBACK_WAIT_MIN = 1; int SUCCESS_RESPONSE = 0; int COAP_RESPONSE_CODE_SUCCESS = 205; int COAP_RESPONSE_CODE_CREATED = 201; int COAP_RESPONSE_CODE_DELETED = 202;
public static RIHelper getInstance(IoTivityTc iotivityTcObj) { new OcRepresentation(); Lock mutex = new ReentrantLock(); if (s_mRiHelperInstance == null) { mutex.lock(); if (s_mRiHelperInstance == null) { IoTivityLog.i("RIHelper", "Inside Helper"); s_mRiHelperInstance = new RIHelper(iotivityTcObj); } mutex.unlock(); } return s_mRiHelperInstance; }
* //****************************************************************** * // Copyright 2018 Intel Corporation All Rights Reserved. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import org.iotivity.base.OcException;
//***************************************************************************** // Copyright 2018 Intel Corporation All Rights Reserved. // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. //***************************************************************************** package org.iotivity.base.examples; import org.iotivity.base.OcException;
Fixed Code: * //****************************************************************** * // Copyright 2018 Intel Corporation All Rights Reserved. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import android.graphics.Bitmap;
Fixed Code: ```java //****************************************************************** // Copyright 2016-2018 Intel Corporation All Rights Reserved. // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. // //****************************************************************** package org.iotivity.base.examples; import org.iotivity.base.OcException; ``` Note: The fixed code assumes that the copyright year should be updated to the current year (2018).
public class MediaControl extends Service { public static final String OIC_TYPE_MEDIA_CONTROL = "oic.r.media.control"; public static final String OCF_OIC_URI_PREFIX_MEDIA_CONTROL = "/ocf/media-control/"; public static final String UPNP_OIC_URI_PREFIX_MEDIA_CONTROL = "/upnp/media-control/"; public static final String STATE_KEY = "playState"; public static final boolean DEFAULT_STATE = false; public static final String SPEED_KEY = "mediaSpeed"; public static final double DEFAULT_SPEED = 1.0; public static final String LOCATION_KEY = "mediaLocation"; public static final String DEFAULT_LOCATION = "0"; public static final String LAST_ACTION_KEY = "lastAction"; public static final String DEFAULT_LAST_ACTION = "stop"; public static final String ACTIONS_KEY = "actions"; private boolean mPlayState; }
Refactored Code: ***************************************************************************** * Copyright (c) 2016-2018 Intel Corporation. All Rights Reserved. * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package org.iotivity.base.examples; import android.app.Activity;
package org.iotivity.base.examples; import org.iotivity.base.OcException; import org.iotivity.base.OcPlatform; import org.iotivity.base.PayloadType; public class Light { static public final String RESOURCE_TYPE = "oic.d.light"; static public final String DEVICE_RESOURCE_TYPE = "oic.wk.d"; private Switch switchRes; private Brightness brightnessRes; private String deviceName; public Light(String name, String uuid, boolean powerOn, int brightness, LightControlPanel ui) { deviceName = name; switchRes = new Switch(uuid); switchRes.setValue(powerOn); switchRes.addObserver(ui); ui.addObserver(switchRes); OcfLightServer.msg("Created switch resource: " + switchRes); brightnessRes = new Brightness(uuid); brightnessRes.setBrightness(brightness); brightnessRes.addObserver(ui); ui.addObserver(brightnessRes); } }
public void updateBrightness(boolean powerOn, int brightness) { setBrightness(brightness); notifyObservers(null); }
public void testUri() { OCResource r = new OCResource(); assertNotNull(r); r.setUri("/foo/bar"); assertEquals("/foo/bar", r.getUri()); } @Test public void testTypes() { OCResource r = new OCResource(); assertNotNull(r); //TODO properly encode/decode the OCResource oc_string_array_t types. //r.setTypes(value); // failure purposely done till the setTypes/getProperties methods are updated with non SWIG type values. fail("Not yet implemented"); } @Test public void testInterfaces() { OCResource r = new OCResource(); assertNotNull(r); r.setInterfaces(OCInterfaceMask.RW); assertEquals(OCInterfaceMask.RW, r.getInterfaces()); } @Test public void testDefaultInterface() { OCResource r = new OCResource(); assertNotNull(r); r.setDefaultInterface(OCInterfaceMask.BASELINE); assertEquals(OCInterfaceMask.BASELINE, r.getDefaultInterface()); } @Test public void testProperties(){ OCResource r = new OCResource(); assertNotNull(r); }
} else if (response.getCode() == OCStatus.OC_STATUS_CREATED) { System.out.println("\tPUT response: CREATED"); } else { System.out.println("\tPUT response code " + response.getCode().toString() + "(" + response.getCode() + ")"); } ObserveLightResponseHandler observerLight = new ObserveLightResponseHandler(); OCMain.doObserve(Light.server_uri, Light.server, null, OCQos.LOW_QOS, observerLight); System.out.println("Sent OBSERVE request");
private void eventLoop() { while (!quit) { long nextEvent = OCMain.mainPoll(); lock.lock(); try { if (nextEvent == 0) { cv.await(); } else { long timeToWait = nextEvent - OCClock.clockTime(); cv.awaitNanos(timeToWait); } } catch (InterruptedException e) { Log.d(TAG, e.getMessage()); } finally { lock.unlock(); } } }
public int initialize() { Log.d(TAG, "inside MyInitHandler.initialize()"); int ret = OCMain.initPlatform("Android"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "Kishen's Android Phone", "ocf.1.0.0", "ocf.res.1.0.0"); return ret; }
public void testValueObject() { OCMain.repNewBuffer(1024); CborEncoder root = OCMain.repBeginRootObject(); assertEquals(0, OCMain.repGetCborErrno()); CborEncoder myObject = OCMain.repOpenObject(root, "my_object"); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetInt(myObject, "a", 1); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetBoolean(myObject, "b", false); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetTextString(myObject, "c", "three"); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repCloseObject(root, myObject); OCMain.repEndRootObject(); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetPool(new OCMemoryBuffer()); OCRepresentation rep = OCMain.repGetOCRepresentaionFromRootObject(); assertNotNull(rep); OCValue v = new OCValue(); assertNotNull(v); }
public int initialize() { System.out.println("inside ObtInitHandler.initialize()"); int ret = OCMain.initPlatform("OCF"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "OBT", "ocf.1.0.0", "ocf.res.1.0.0"); return ret; }
System.out.println("################################################"); System.out.println("\nSelect option: "); } private static void discoverUnownedDevices() { System.out.println("Discovering un-owned devices"); appSyncLock.lock(); if (OCObt.discoverUnownedDevices(unownedDeviceHandler) < 0) { System.err.println("ERROR discovering un-owned Devices."); } appSyncLock.unlock(); } private static void discoverOwnedDevices() { appSyncLock.lock(); if (OCObt.discoverOwnedDevices(ownedDeviceHandler) > 0) { System.err.println("ERROR discovering owned Devices."); } appSyncLock.unlock(); } public static void main(String[] args) { quit = false; mainThread = Thread.currentThread(); Runtime.getRuntime().addShutdownHook(shutdownHook); String osName = System.getProperty("os.name"); boolean isLinux = (osName != null) && osName.toLowerCase().contains("linux"); System.out.println("OS Name = " + osName + ", isLinux = " + isLinux); String creds_path = "./onboarding_tool_creds/";
break; case 3: OCObt.aceResourceSetWc(res, OCAceWildcard.OC_ACE_WC_ALL_NON_DISCOVERABLE); break; default: break; } } System.out.print("Enter number of resource types [0-None]: "); c = scanner.nextInt(); if (c > 0 && c <= MAX_NUM_RT) { OCObt.aceResoruceSetNumRt(res, c); int j = 0; while (j < c) { System.out.print("Enter resource type : " + (j + 1)); String rt = scanner.next(); if (rt.length() > 127) { rt = rt.substring(0, 127); } OCObt.aceResoruceBindRt(res, rt); j++; } } System.out.print("Enter number of interfaces [0-None] : "); c = scanner.nextInt(); if (c > 0 && c <= 7) { int j = 0; while (j < c) { int k; System.out.println("\n[1]: oic.if.baseline");
public int initialize() { System.out.println("inside ObtInitHandler.initialize()"); int ret = OCMain.initPlatform("OCF"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "OBT", "ocf.1.0.0", "ocf.res.1.0.0"); return ret; }
public void handler(OCUuid uuid, int status, Object userData) { ObtMain.ownedDevices.remove(uuid); if (status >= 0) { System.out.println("\nSuccessfully performed hard RESET to device " + OCUuidUtil.uuidToString(uuid)); } else { System.out.println("\nERROR performing hard RESET to device " + OCUuidUtil.uuidToString(uuid)); } }
private void eventLoop() { while (!quit) { long nextEvent = OCMain.mainPoll(); lock.lock(); try { if (nextEvent == 0) { cv.await(); } else { long now = OCClock.clockTime(); long timeToWait = (NANOS_PER_SECOND / OCClock.clockSeconds()) * (nextEvent - now); cv.awaitNanos(timeToWait); } } catch (InterruptedException e) { Log.d(TAG, e.getMessage()); } finally { lock.unlock(); } } }
public void handler(OCRequest request, int interfaces) { Log.d(TAG, "inside Put Light Request Handler"); new PostLightRequestHandler(activity).handler(request, interfaces, userData); }
private Light light; OCMain.resourceSetRequestHandler(resource, OCMethod.OC_POST, new PostLightRequestHandler(activity, light)); OCMain.addResource(resource); @Override public void requestEntry() { Log.d(TAG, "inside MyInitHandler.requestEntry()"); } @Override public void signalEventLoop() { Log.d(TAG, "inside MyInitHandler.signalEventLoop()"); activity.lock.lock(); try { activity.cv.signalAll(); } finally { activity.lock.unlock(); } }
String creds_path = "./simpleserver_creds/"; java.io.File directory = new java.io.File(creds_path); if (!directory.exists()) { directory.mkdir(); } System.out.println("Storage Config PATH : " + directory.getPath()); if (0 != OCStorage.storageConfig(directory.getPath())) { System.err.println("Failed to setup Storage Config."); } OcUtils.setFactoryPresetsHandler(new FactoryPresetsHandler()); MyInitHandler handler = new MyInitHandler(platform); platform.systemInit(handler); try { Thread.sleep(Long.MAX_VALUE); } catch (InterruptedException e) { System.err.println(e); } System.exit(0);
if (!directory.exists()) { directory.mkdir(); } System.out.println("Storage Config PATH : " + directory.getPath()); if (0 != OCStorage.storageConfig(directory.getPath())) { System.err.println("Failed to setup Storage Config."); } OcUtils.setFactoryPresetsHandler(new FactoryPresetsHandler()); MyInitHandler handler = new MyInitHandler(platform); platform.systemInit(handler); try { Thread.sleep(Long.MAX_VALUE); } catch (InterruptedException e) { System.err.println(e); } System.exit(0);
public void getOwnedDeviceNameResponseHandler(OCClientResponse response) { OCRepresentation rep = response.getPayload(); String deviceName = null; String deviceId = null; while (rep != null) { switch (rep.getType()) { case OC_REP_STRING: if ("n".equals(rep.getName())) { deviceName = rep.getValue().getString(); } if ("di".equals(rep.getName())) { deviceId = rep.getValue().getString(); } break; default: break; } rep = rep.getNext(); } if (deviceId != null) { ObtMain.ownedDevices.add(new OCFDeviceInfo(OCUuidUtil.stringToUuid(deviceId), deviceName)); } }
public void handler(OCClientResponse response) { System.out.println("Get Unowned Device Name Handler:"); OCRepresentation rep = response.getPayload(); String n = null; String di = null; while (rep != null) { switch (rep.getType()) { case OC_REP_STRING: if ("n".equals(rep.getName())) { n = rep.getValue().getString(); } if ("di".equals(rep.getName())) { di = rep.getValue().getString(); } break; default: break; } rep = rep.getNext(); } if (di != null) { ObtMain.unownedDevices.add(new OCFDeviceInfo(OCUuidUtil.stringToUuid(di), n)); } }
public class IntraLineDiffKey implements Serializable { public static final long serialVersionUID = 5L; private transient Whitespace whitespace; private transient ObjectId aId; private transient ObjectId bId; public IntraLineDiffKey(ObjectId aId, ObjectId bId, Whitespace whitespace) { this.aId = aId; this.bId = bId; this.whitespace = whitespace; } public ObjectId getBlobA() { return aId; } public ObjectId getBlobB() { return bId; } public Whitespace getWhitespace() { return whitespace; } @Override public int hashCode() { int h = 0; h = h * 31 + aId.hashCode(); h = h * 31 + bId.hashCode(); h = h * 31 + whitespace.hashCode(); return h; } @Override public boolean equals(final Object o) { if (o instanceof IntraLineDiffKey) { final IntraLineDiffKey k = (IntraLineDiffKey) o; return aId.equals(k.aId) && bId.equals(k.bId) && whitespace.equals(k.whitespace); } return false; } } // ... public class MyClass { // ... public boolean isRebaseTransparent() { return isRebaseTransparent; } // ... public boolean getBoolean() throws OcCborException { Boolean returnValue = getValue().getBool(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean"); } // ... }
return long not Long see comment on getBoolean bellow. public Long getLong() throws OcCborException { Long returnValue = getValue().getInteger(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get long"); }
public Boolean getBoolean() throws OcCborException { Boolean returnValue = getValue().getBool(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean"); } public Long getLong() throws OcCborException { Long returnValue = getValue().getInteger(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get long"); } public double getDouble() throws OcCborException { double returnValue = getValue().getDouble(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get double"); } public String getString() throws OcCborException { String returnValue = getValue().getString(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get string"); } public OCArray getArray() throws OcCborException { OCArray returnValue = getValue().getArray(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get array"); }
OCRepresentation nativeRep = getValue().getObject(); if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object"); public OcRepresentation getObjectArray() throws OcCborException { OCRepresentation nativeRep = getValue().getObjectArray(); if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object array"); } public OCValue getValue() throws OcCborException { OCValue returnValue = nativeRepresentation.getValue(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get value"); } public Boolean getBoolean(String key) throws OcCborException { Boolean returnValue = OCRep.getBoolean(nativeRepresentation, key); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); }
if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object array"); } public OCValue getValue() throws OcCborException { OCRep.clearCborErrno(); OCValue returnValue = nativeRepresentation.getValue(); if (returnValue != null && OCRep.getCborErrno() == 0) { return returnValue; } throw new OcCborException("Failed to get value"); } public boolean getBoolean(String key) throws OcCborException { OCRep.clearCborErrno(); boolean returnValue = OCRep.getBoolean(nativeRepresentation, key); if (returnValue && OCRep.getCborErrno() == 0) { return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); } public Long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); Long returnValue = OCRep.getLong(nativeRepresentation, key); if (returnValue != null && OCRep.getCborErrno() == 0) { return returnValue; } throw new OcCborException("Failed to get long for key " + key); }
return long not Long see comments on getBoolean Fixed Code: return long not Long see comments on getBoolean public long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); long returnValue = OCRep.getLong(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get long for key " + key); }
return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); } public Long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); Long returnValue = OCRep.getLong(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get long for key " + key); } public Double getDouble(String key) throws OcCborException { OCRep.clearCborErrno(); Double returnValue = OCRep.getDouble(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get double for key " + key); } public String getString(String key) throws OcCborException { OCRep.clearCborErrno(); String returnValue = OCRep.getString(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; }
static public OcRepresentation createOcRepresentaionFromRoot() throws OcCborException { OCRep.clearCborErrno(); OCRepresentation nativeRep = OCRep.getOCRepresentaionFromRootObject(); if (null != nativeRep && OCRep.getCborErrno() == 0) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to create OcRepresentation from root object"); }
case R.id.radio_recovery: mRebootMode = 2; Settings.System.putInt(mContext.getContentResolver(), Settings.System.STATUS_BAR_LAST_NOTIFICATION_STYLE, mRebootMode); mTileMode = 2; refreshState(); break; case R.id.radio_bootloader: mRebootMode = 3; Settings.System.putInt(mContext.getContentResolver(), Settings.System.STATUS_BAR_LAST_NOTIFICATION_STYLE, mRebootMode); mTileMode = 2; refreshState(); break; default: refreshState(); break;
public void update() { int showNavBar = Settings.System.getIntForUser(mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_SHOW, -1, mCurrentUserId); int qsQuickPulldownValue = Settings.System.getInt(mContext.getContentResolver(), Settings.System.STATUS_BAR_QUICK_QS_PULLDOWN, 0); if (showNavBar != -1) { boolean showNavBarBool = showNavBar == 1; if (showNavBarBool != mShowNavBar) { updateNavigationBar(); } } mRecentsStyle = Settings.System.getIntForUser(mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_RECENTS, 0, mCurrentUserId); mOmniSwitchRecents = mRecentsStyle == 1; mLongPressOnAppSwitchBehavior = Settings.System.getIntForUser(mContext.getContentResolver(), Settings.System.BUTTON_LONG_PRESS_RECENTS, 0, mCurrentUserId); if (mStatusBarWindow != null) { mStatusBarWindow.updateSettings(); } if (mNavigationBar != null) { mNavigationBar.setRecentsOptions(mRecentsStyle, mLongPressOnAppSwitchBehavior); } if (mStatusBarWindowManager != null) { // rest of the code } }
public void update() { int showNavBar = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_SHOW, -1, mCurrentUserId ); int qsQuickPulldownValue = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.STATUS_BAR_QUICK_QS_PULLDOWN, 0, UserHandle.USER_CURRENT ); if (showNavBar != -1) { boolean showNavBarBool = showNavBar == 1; if (showNavBarBool != mShowNavBar) { updateNavigationBar(); } } mRecentsStyle = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_RECENTS, 0, mCurrentUserId ); mOmniSwitchRecents = mRecentsStyle == 1; mLongPressOnAppSwitchBehavior = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.BUTTON_LONG_PRESS_RECENTS, 0, mCurrentUserId ); if (mStatusBarWindow != null) { mStatusBarWindow.updateSettings(); } if (mNavigationBar != null) { mNavigationBar.setRecentsOptions(mRecentsStyle, mLongPressOnAppSwitchBehavior); } }
public void onBindViewHolder(PreferenceViewHolder holder) { super.onBindViewHolder(holder); LinearLayout linearLayout = (LinearLayout) holder.findViewById(R.id.selected_apps); if (linearLayout.getChildCount() > 0) { linearLayout.removeAllViews(); } for (String value : mValues) { try { ImageView v = new ImageView(mContext); ComponentName componentName = ComponentName.unflattenFromString(value); Drawable icon = mPm.getActivityIcon(componentName); v.setImageDrawable(icon); v.setPadding(0, 0, 15, 0); v.setScaleType(ImageView.ScaleType.CENTER_CROP); linearLayout.addView(v); } catch (PackageManager.NameNotFoundException e) { Log.e(TAG, "Set app icon", e); } } }
public void onKeyguardShowingChanged() { mShowIndicator = Settings.Secure.getIntForUser(mContext.getContentResolver(), Settings.Secure.LOCK_HIDE_INDICATOR_DISPLAY, 0, UserHandle.USER_CURRENT) == 0; updateLeftAffordance(); updateRightAffordance(); inflateCameraPreview(); mIndicationController.setVisibleOverwrite(mShowIndicator); }
private void updateSettings() { int mQsBackGroundAlpha = Settings.System.getIntForUser(getContext().getContentResolver(), Settings.System.QS_PANEL_BG_ALPHA, 255, UserHandle.USER_CURRENT); mQsBackGround.setAlpha(mQsBackGroundAlpha); setBackground(mQsBackGround); }
mMusicActive.setOnPreferenceChangeListener(this); mAutorun = (SwitchPreference) findPreference(EVENT_AUTORUN_SINGLE); mAutorun.setChecked(getPrefs().getBoolean(EventServiceSettings.EVENT_AUTORUN_SINGLE, true)); mAutorun.setOnPreferenceChangeListener(this); mChooserTimeout = (SeekBarPreference) findPreference(APP_CHOOSER_TIMEOUT); mChooserTimeout.setValue(getPrefs().getInt(EventServiceSettings.APP_CHOOSER_TIMEOUT, 15)); mChooserTimeout.setOnPreferenceChangeListener(this); boolean locationDisabled = Settings.Secure.getInt(getActivity().getContentResolver(), Settings.Secure.LOCATION_MODE, -1) == 0; mDisableWifi = (SeekBarPreference) findPreference(DISABLE_WIFI_THRESHOLD); mDisableWifi.setValue(getPrefs().getInt(EventServiceSettings.DISABLE_WIFI_THRESHOLD, 0)); mDisableWifi.setOnPreferenceChangeListener(this); mDisableWifi.setEnabled(!locationDisabled); homeWifi = findPreference(HOME_WIFI_PREFERENCE_SCREEN); homeWifi.setEnabled(!locationDisabled); workWifi = findPreference(WORK_WIFI_PREFERENCE_SCREEN); workWifi.setEnabled(!locationDisabled); if (locationDisabled) { mDisableWifi.setSummary(R.string.wifi_location_disabled); homeWifi.setSummary(R.string.wifi_location_disabled); }
public void onReceive(Context context, Intent intent) { String action = intent.getAction(); mWakeLock.acquire(); try { if (DEBUG) Log.d(TAG, "onReceive " + action); boolean disableIfMusicActive = getPrefs(context).getBoolean("media_player_music_active", false); boolean autoRun = getPrefs(context).getBoolean("media_player_autorun_single", true); boolean closeApp = getPrefs(context).getBoolean("media_player_disconnect_headset_or_a2dp", false); switch (action) { case BluetoothAdapter.ACTION_STATE_CHANGED: if (intent.getIntExtra(BluetoothAdapter.EXTRA_STATE, -1) == BluetoothAdapter.STATE_OFF) { mA2DPConnected = false; } break; case BluetoothA2dp.ACTION_CONNECTION_STATE_CHANGED: int state = intent.getIntExtra(BluetoothProfile.EXTRA_STATE, BluetoothProfile.STATE_CONNECTED); if (state == BluetoothProfile.STATE_CONNECTED && !mA2DPConnected) { mA2DPConnected = true; if (DEBUG) Log.d(TAG, "BluetoothProfile.STATE_CONNECTED = true"); } break; // other cases... } } finally { mWakeLock.release(); } }
private static final int KEY_MASK_BACK = 0x02; private static final int KEY_MASK_MENU = 0x04; private static final int KEY_MASK_ASSIST = 0x08; private static final int KEY_MASK_APP_SWITCH = 0x10; private CheckBoxPreference mVolumeWake; private CheckBoxPreference mSwapVolumeButtons; private SwitchPreference mEnableCustomBindings; private ListPreference mBackPressAction; private ListPreference mBackLongPressAction; private ListPreference mHomePressAction; private ListPreference mHomeLongPressAction; private ListPreference mHomeDoubleTapAction; private CheckBoxPreference mHomeAnswerCall; private ListPreference mMenuPressAction; private ListPreference mMenuLongPressAction; private ListPreference mAssistPressAction; private ListPreference mAssistLongPressAction; private ListPreference mAppSwitchPressAction; private ListPreference mAppSwitchLongPressAction; private Map<String, Integer> mKeySettings = new HashMap<String, Integer>();
mGestureButtonHandler.sendEmptyMessageDelayed(MSG_SEND_SWITCH_KEY, (long) GESTURE_KEY_DISTANCE_TIMEOUT); } } mLastX = rawX; mLastY = rawY; break; } else if (mLongClick && mPreparedKeycode == 3) { mGestureButtonHandler.removeMessages(MSG_SEND_SWITCH_KEY); mGestureButtonHandler.sendEmptyMessageDelayed(MSG_SEND_SWITCH_KEY, (long) GESTURE_KEY_DISTANCE_TIMEOUT); mPreparedKeycode = 0; mLongClick = false; } break; case 3: break; default: break; } }
/** * The animation property used for the icon when its isolation ends. * This animates the translation back to the right position. */ private static final AnimationProperties UNISOLATION_PROPERTY = new AnimationProperties() { private AnimationFilter mAnimationFilter = new AnimationFilter().animateX(); @Override public AnimationFilter getAnimationFilter() { return mAnimationFilter; } }.setDuration(CONTENT_FADE_DURATION); private int MAX_VISIBLE_ICONS_WHEN_DARK = 5; private int MAX_STATIC_ICONS = 4; private static final int MAX_DOTS = 1; private boolean mIsStaticLayout = true; private final HashMap<View, IconState> mIconStates = new HashMap<>(); private int mDotPadding; private int mMaxVisibleIconsWhenDark; private int mMaxStaticIcons; private int mStaticDotRadius; private int mStaticDotDiameter; private int mOverflowWidth; private int mActualLayoutWidth = NO_VALUE; private float mActualPaddingEnd = NO_VALUE; private float mActualPaddingStart = NO_VALUE; private boolean mDark;
private static final AnimationProperties UNISOLATION_PROPERTY = new AnimationProperties() { private AnimationFilter mAnimationFilter = new AnimationFilter().animateX(); @Override public AnimationFilter getAnimationFilter() { return mAnimationFilter; } }.setDuration(CONTENT_FADE_DURATION); public final int MAX_VISIBLE_ICONS_WHEN_DARK; public final int MAX_STATIC_ICONS; private static final int MAX_DOTS = 1; private boolean mIsStaticLayout = true; private final HashMap<View, IconState> mIconStates = new HashMap<>(); private int mDotPadding; private int mStaticDotRadius; private int mStaticDotDiameter; private int mOverflowWidth; private int mActualLayoutWidth = NO_VALUE; private float mActualPaddingEnd = NO_VALUE; private float mActualPaddingStart = NO_VALUE; private boolean mDark; private boolean mChangingViewPositions; private int mAddAnimationStartIndex = -1; private void initDimens() { MAX_VISIBLE_ICONS_WHEN_DARK = getResources().getInteger(R.integer.config_maxVisibleNotificationIconsWhenDark); MAX_STATIC_ICONS = getResources().getInteger(R.integer.config_maxVisibleNotificationIcons); }
private void initDimens() { public final int MAX_VISIBLE_ICONS_WHEN_DARK = getResources().getInteger(R.integer.config_maxVisibleNotificationIconsWhenDark); public final int MAX_STATIC_ICONS = getResources().getInteger(R.integer.config_maxVisibleNotificationIcons); private static final int MAX_DOTS = 1; }
toastText = com.android.internal.R.string.volume_dialog_ringer_guidance_silent_no_media; break; case VOLUME_HUSH_VIBRATE: effect = VibrationEffect.get(VibrationEffect.EFFECT_HEAVY_CLICK); ringerMode = AudioManager.RINGER_MODE_VIBRATE; toastText = com.android.internal.R.string.volume_dialog_ringer_guidance_vibrate; break; } maybeVibrate(effect); setRingerModeInternal(ringerMode, reason); Toast.makeText(ActivityThread.currentActivityThread().getSystemUiContext(), toastText, Toast.LENGTH_SHORT).show();
boolean result = false; try { logger.info("provisionONT begin"); AddOntMessage request = AddOntMessage.newBuilder() .setCLLI(clli) .setPortNumber(portNumber) .setSlotNumber(slotNumber) .setOntNumber(ontNumber) .setSerialNumber(serialNumber) .build(); AddOntReturn response = blockingStub.provisionOnt(request); result = response.getSuccess(); logger.info("provisionONT with device id : {} success : {}", serialNumber, result); } catch (RuntimeException e) { logger.log(Level.WARNING, "provisionONT RPC failed", e); } return result;
private static final Logger logger = Logger.getLogger(AbstractOLTServer.class.getName()); @Override public void echo(EchoMessage request, StreamObserver<EchoReplyMessage> responseObserver) { } @Override public void createChassis(AddChassisMessage request, StreamObserver<AddChassisReturn> responseObserver) { AddChassisReturn response = AddChassisReturn.newBuilder() .setDeviceID(request.getCLLI()) .build(); responseObserver.onNext(response); responseObserver.onCompleted(); logger.info("createChassis with clli : {}", request.getCLLI()); } @Override public void createOLTChassis(AddOLTChassisMessage request, StreamObserver<AddOLTChassisReturn> responseObserver) { AddOLTChassisReturn response = AddOLTChassisReturn.newBuilder() .setDeviceID(UUID.randomUUID().toString()) .setChassisDeviceID(request.getCLLI()) .build(); responseObserver.onNext(response); responseObserver.onCompleted(); logger.info("createOLTChassis with clli : {}", request.getCLLI()); } @Override public void provisionOnt(AddOntMessage request, StreamObserver<AddOntReturn> responseObserver) { AddOntReturn response = AddOntReturn.newBuilder() .setSuccess(true) .build(); responseObserver.onNext(response); responseObserver.onCompleted(); }
public void removeSubscriber(ConnectPoint port) { AccessDeviceData olt = oltData.get(port.deviceId()); if (olt == null) { log.warn("No data found for OLT device {}", port.deviceId()); return; } VlanId subscriberVlan = subscribers.remove(port); if (subscriberVlan == null) { log.warn("Unknown subscriber at location {}", port); return; } if (enableDhcpIgmpOnProvisioning) { processDhcpFilteringObjectives(olt.deviceId(), port.port(), false); } unprovisionSubscriber(olt.deviceId(), olt.uplink(), port.port(), subscriberVlan, olt.vlan(), olt.defaultVlan()); if (enableDhcpIgmpOnProvisioning) { processIgmpFilteringObjectives(olt.deviceId(), port.port(), false); } }
public void testPopulateExtendedModules() { XmlAnalysisModuleSource source = new XmlAnalysisModuleSource(); Iterable<IAnalysisModuleHelper> modules = source.getAnalysisModules(); assertNull("Module not present", findModule(modules, MY_MODULE)); /* use the valid extended XML test file */ File testXmlFile = TmfXmlTestFiles.VALID_FILE_EXTENDED.getFile(); if ((testXmlFile == null) || !testXmlFile.exists()) { fail("XML test file does not exist"); } XmlUtils.addXmlFile(testXmlFile); XmlAnalysisModuleSource.notifyModuleChange(); modules = source.getAnalysisModules(); assertTrue("Modules available from source", modules.iterator().hasNext()); assertNotNull("'My' module present", findModule(modules, MY_MODULE)); assertNotNull("'abc' module present", findModule(modules, ABC_MODULE)); } if (!(type_.isDecimal() && t1.isDecimal())) castChild(1, type_); t0 = getChild(0).getType(); t1 = getChild(1).getType(); // Use MATH_MOD function operator for floating-point modulo. // TODO remove this when we have operators implemented using the UDF interface // and we can resolve this just using function overloading. if ((t0.isFloatingPointType() || t1.isFloatingPointType()) && op_ == ArithmeticExpr.Operator.MOD) { fnName = "fmod"; } fn_ = getBuiltinFunction(analyzer, fnName, collectChildReturnTypes(), CompareMode.IS_IDENTICAL); if (fn_ == null) { Preconditions.checkState(false, String.format("No match " + "for '%s' with operand types %s and %s", toSql(), t0, t1)); } Preconditions.checkState(type_.matchesType(fn_.getReturnType())); @Override case 13: return "API 13: Android 3.2 (Honeycomb)"; case 14: return "API 14: Android 4.0 (IceCreamSandwich)"; case 15: return "API 15: Android 4.0.3 (IceCreamSandwich)"; case 16: return "API 16: Android 4.1 (Jelly Bean)"; case 17: return "API 17: Android 4.2 (Jelly Bean)"; // If you add more versions here, also update #getBuildCodes and #H
import org.polarsys.capella.core.model.handler.command.CapellaResourceHelper; /** * An {@link ECrossReferenceAdapter} that only takes capella resources into account. */ public class CapellaECrossReferenceAdapter extends SiriusCrossReferenceAdapter { class CapellaInverseCrossReferencer extends InverseCrossReferencer { private static final long serialVersionUID = -3473829340961544993L; @Override protected void addProxy(EObject proxy, EObject context) { // Do nothing to avoid keeping EObjects turn into proxies during the whole application life. } @Override protected boolean resolve() { return CapellaECrossReferenceAdapter.this.resolve(); } } WeakReference<EditingDomain> _editingDomain; public CapellaECrossReferenceAdapter(EditingDomain editingDomain, Session session, ResourceSet set) { super(set, (DAnalysisSessionImpl) session); _editingDomain = new WeakReference<EditingDomain>(editingDomain); } /** * Adapt all references of specified object against the inverse cross referencer. */ public void adaptAll(Notifier notifier) { if (notifier instanceof EObject) { EObject eObject = (EObject) notifier; if (CapellaResourceHelper.isCapellaResource(eObject.eResource())) { eObject.eAdapters().add(this); for (EObject content : eObject.eContents()) { adaptAll(content); } } } } }
private static final String MIGRATED_FITLER_EXT = ".filter"; private static final String FRAGMENT_SEPARATOR = "\\@"; private static final String FILTER_SEPARATOR = "\\'"; private static final String FRAGMENT_FILTER_KEY = "filters"; private static final String PLUGIN_TYPE = "plugin"; private static final String VALID_PLUGIN = "org.polarsys.capella.core.sirius.analysis"; private static final String DESCRIPTION_TYPE = "description"; private Map<DiagramDescription, Set<String>> validFilterNames; private Map<String, String> filterNameExceptions; public FilterMigrationContribution() { validFilterNames = new HashMap<>(); filterNameExceptions = new HashMap<>(); filterNameExceptions.put("ShowEIExchangeContext", "show.ei.exchange.context.filter"); filterNameExceptions.put("CEParam", "show.ce.param.filter"); filterNameExceptions.put("CEEIParam", "show.ce.ei.param.filter"); filterNameExceptions.put("ShowFEExchangeContex", "show.fe.exchange.context.filter"); filterNameExceptions.put("ShowCEExchangeContext", "show.ce.exchange.context.filter"); } @Override public void initialize() { filterNameExceptions = new HashMap<>(); filterNameExceptions.put("ShowEIExchangeContext", "show.ei.exchange.context.filter"); filterNameExceptions.put("CEParam", "show.ce.param.filter"); filterNameExceptions.put("CEEIParam", "show.ce.ei.param.filter"); filterNameExceptions.put("ShowFEExchangeContex", "show.fe.exchange.context.filter"); filterNameExceptions.put("ShowCEExchangeContext", "show.ce.exchange.context.filter"); } public static String getValidFilterNameCandidate(String filterName) { return filterNameExceptions.get(filterName); }
import org.polarsys.capella.core.model.helpers.BlockArchitectureExt; import org.polarsys.capella.core.model.helpers.ComponentExt; import org.polarsys.capella.core.ui.properties.fields.AbstractSemanticField; import org.polarsys.capella.core.ui.properties.fields.MultipleSemanticField; public abstract class ComponentSection extends GeneralizableElementSection { private boolean showIsHuman; private boolean showIsActor; private boolean showImplementedInterfaces; private boolean showUsedInterfaces; private boolean showAllocatedFunctions; protected IsHumanPropertiesCheckbox isHumanCheckbox; protected IsActorPropertiesCheckbox isActorCheckbox; private MultipleSemanticField implementedInterfaces; private MultipleSemanticField usedInterfaces; protected MultipleSemanticField allocatedFunctions; public ComponentSection() { this(true, true, true, true, true, true, true); } public ComponentSection(boolean showImplementedInterfaces, boolean showUsedInterfaces, boolean showAllocatedFunctions, boolean showSuperTypes, boolean showIsAbstract) { this.showImplementedInterfaces = showImplementedInterfaces; this.showUsedInterfaces = showUsedInterfaces; this.showAllocatedFunctions = showAllocatedFunctions; this.showSuperTypes = showSuperTypes; this.showIsAbstract = showIsAbstract; } }
if (null != propertiesCheckbox) { propertiesCheckbox.setEnabled(component.isActor()); } if (null != isHumanCheckbox) { isHumanCheckbox.loadData(component); boolean isOperationalEntity = block instanceof OperationalAnalysis && !component.isActor(); boolean isSystem = component == block.getSystem(); boolean isComposite = ComponentExt.isComposite(component); if (isHumanCheckbox.isEnabled() && (isOperationalEntity || isSystem || isComposite)) { isHumanCheckbox.setEnabled(false); } } if (null != isActorCheckbox) { isActorCheckbox.loadData(component); boolean isSystemAnalysis = block instanceof SystemAnalysis; boolean isSAComponent = component.isInSA(); boolean isActorWithoutContainer = component.isActor() && !component.canHaveComponent(); boolean isComponentWithoutActor = component.isComponent() && !component.canHaveActor(); if (isActorCheckbox.isEnabled() && (isSAComponent || isSystemAnalysis || isActorWithoutContainer || isComponentWithoutActor)) { isActorCheckbox.setEnabled(false); } }
boolean condition1 = block instanceof SystemAnalysis; boolean condition2 = component == block.getSystem(); boolean condition3 = component.isActor() && !ComponentExt.canCreateABComponent(component.eContainer()); boolean condition4 = !component.isActor() && !ComponentExt.canCreateABActor(component.eContainer()); if (isActorCheckbox.isEnabled() && (condition1 || condition2 || condition3 || condition4)) { isActorCheckbox.setEnabled(false); } if (null != implementedInterfaces) { implementedInterfaces.loadData(component, CsPackage.Literals.COMPONENT__OWNED_INTERFACE_IMPLEMENTATIONS); } if (null != usedInterfaces) { usedInterfaces.loadData(component, CsPackage.Literals.COMPONENT__OWNED_INTERFACE_USES); } if (null != allocatedFunctions) { allocatedFunctions.loadData(component, FaPackage.Literals.ABSTRACT_FUNCTIONAL_BLOCK__OWNED_FUNCTIONAL_ALLOCATION); }
/***************************************************************************** * Copyright (c) 2006, 2018 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util.pattern.helper; import java.util.ArrayList; import java.util.Collection; import org.polarsys.capella.core.data.fa.FunctionalExchange; import org.polarsys.capella.core.data.oa.CommunicationMean; import org.polarsys.capella.core.data.oa.Entity; import org.polarsys.capella.common.data.modellingcore.AbstractInformationFlow; import org.polarsys.capella.common.data.modellingcore.InformationsExchanger; import org.polarsys.capella.docgen.util.CapellaServices; import org.polarsys.capella.docgen.util.StringUtil; public class CapellaEntityHelper { public static Collection<String> getIncomingCommunicationMeansLines(Entity entity, String projectName, String outputFolder) { Collection<String> ret = new ArrayList<String>(); // implementation here return ret; } }
/***************************************************************************** * Copyright (c) 2006, 2019 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.Iterator; import java.util.List; import java.util.Set; import org.eclipse.emf.common.util.EList; import org.eclipse.emf.ecore.EObject; import org.polarsys.capella.core.data.cs.Component; import org.polarsys.capella.core.data.cs.Interface; import org.polarsys.capella.core.data.fa.AbstractFunction; import org.polarsys.capella.core.data.fa.ComponentExchange; import org.polarsys.capella.core.data.fa.ComponentExchangeEnd; import org.polarsys.capella.core.data.fa.ComponentExchangeKind; import org.polarsys.capella.core.data.fa.ComponentPort; import org.polarsys.capella.core.data.fa.FunctionalExchange;
/***************************************************************************** * Copyright (c) 2006, 2018 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util.pattern.helper; import java.util.ArrayList; import java.util.Collection; import java.util.HashMap; import java.util.Map; import org.polarsys.capella.common.data.modellingcore.ModelElement; import org.polarsys.capella.core.data.cs.Interface; import org.polarsys.capella.core.data.fa.ComponentExchange; import org.polarsys.capella.core.data.fa.ComponentExchangeKind; import org.polarsys.capella.core.data.fa.ComponentPort; import org.polarsys.capella.core.data.information.ExchangeItem; import org.polarsys.capella.docgen.util.CapellaServices; import org.polarsys.capella.docgen.util.StringUtil; public class CapellaComponentPortHelper { 	/** 	 * Get the provided interfaces of a ComponentPort as html 	 * 	 * @param port 	 * the ComponentPort 	 * @return the provided interfaces as html 	 */ 	public static String getProvidedInterfaces(ComponentPort port) { 		Collection<Interface> providedInterfaces = new ArrayList<Interface>(); 		for (ComponentExchange exchange : port.getOutgoingComponentExchangeRealizations()) { 			if (exchange.getKind() == ComponentExchangeKind.PROVIDES) { 				providedInterfaces.add(exchange.getInterface()); 			} 		} 		return StringUtil.join(providedInterfaces, ", ", new StringUtil.Function<Interface>() { 			public String apply(Interface input) { 				return CapellaServices.getService().getHyperlinkFromElement(input); 			} 		}); 	} 	/** 	 * Get the required interfaces of a ComponentPort as html 	 * 	 * @param port 	 * the ComponentPort 	 * @return the required interfaces as html 	 */ 	public static String getRequiredInterfaces(ComponentPort port) { 		Collection<Interface> requiredInterfaces = new ArrayList<Interface>(); 		for (ComponentExchange exchange : port.getIncomingComponentExchangeRealizations()) { 			if (exchange.getKind() == ComponentExchangeKind.RE
EList<EObject> objects = new BasicEList<EObject>(); objects.add(repTarget); if (repTarget instanceof Part) { objects.addAll(resolveReferencedElements(((Part) repTarget).getAbstractType())); } if (repTarget instanceof InstanceRole) { objects.addAll(resolveReferencedElements(((InstanceRole) repTarget).getRepresentedInstance())); } if (repTarget instanceof StateFragment) { objects.addAll(resolveReferencedElements(((StateFragment) repTarget).getRelatedAbstractFunction())); } return objects; public static Collection<DDiagram> getAllInterestedRepresentationsFor(EObject semanticElement) { <<<<<<< HEAD Scrutinize all EOI (element of interest: See {@link org.polarsys.capella.core.diagram.helpers.naming.DAnnotationSourceConstants.CAPELLA_ELEMENT_OF_INTEREST}) annotation of all representation descriptors to find all representations which are interested by the semantic element @param semanticElement to find all representation interested by it @return a collection of representations interested by semantic element. If there are no representation, empty collection is returned >>>>>>> }

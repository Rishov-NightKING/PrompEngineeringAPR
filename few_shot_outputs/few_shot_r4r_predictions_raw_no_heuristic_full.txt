import java.util.ArrayList; public class WifiConnectivityHelper { private static final String TAG = "WifiConnectivityHelper"; private final WifiNative mWifiNative; private boolean mFirmwareRoamingSupported = false; private static final int DEFAULT_MAX_NUM_BLACKLIST_BSSID = -1; private static final int DEFAULT_MAX_NUM_WHITELIST_SSID = -1; WifiConnectivityHelper(WifiNative wifiNative) { mWifiNative = wifiNative; } public void getFirmwareRoamingInfo() { int fwFeatureSet = mWifiNative.getSupportedFeatureSet(); Log.d(TAG, "Firmware supported feature set: " + Integer.toHexString(fwFeatureSet)); mFirmwareRoamingSupported = (fwFeatureSet & WIFI_FEATURE_CONTROL_ROAMING) > 0; } }
/** @hide */ public static final int WIFI_FEATURE_MKEEP_ALIVE = 0x100000; // Wifi mkeep_alive /** @hide */ public static final int WIFI_FEATURE_CONFIG_NDO = 0x200000; // ND offload configure /** @hide */ public static final int WIFI_FEATURE_TRANSMIT_POWER = 0x400000; // Capture Tx transmit power levels /** @hide */ public static final int WIFI_FEATURE_CONTROL_ROAMING = 0x800000; // Enable/Disable firmware roaming /** @hide */ public static final int WIFI_FEATURE_IE_WHITELIST = 0x1000000; // Probe IE white listing /** @hide */ public static final int WIFI_FEATURE_SCAN_RAND = 0x2000000; // Support MAC & Probe Sequence Number randomization private int getSupportedFeatures() { try { return mService.getSupportedFeatures(); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } private boolean isFeatureSupported(int feature) { return (getSupportedFeatures() & feature) == feature; } public void verifyFirmwareRoamingCapabilityWithSuccessfulNativeCall() { mWifiConnectivityHelper.getFirmwareRoamingInfo(); assertTrue(mWifiConnectivityHelper.isFirmwareRoamingSupported()); assertEquals(MAX_BSSID_BLACKLIST_SIZE, mWifiConnectivityHelper.getMaxNumBlacklistBssid()); assertEquals(MAX_SSID_WHITELIST_SIZE, mWifiConnectivityHelper.getMaxNumWhitelistSsid()); } public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { Log.e(TAG, "Firmware roaming is not supported"); return -1; } } mMaxNumWhitelistSsid = -1; if (mFirmwareRoamingSupported) { WifiNative.RoamingCapabilities roamingCap = new WifiNative.RoamingCapabilities(); if (mWifiNative.getRoamingCapabilities(roamingCap)) { mMaxNumBlacklistBssid = roamingCap.maxBlacklistSize; mMaxNumWhitelistSsid = roamingCap.maxWhitelistSize; Log.d(TAG, "Firmware roaming capabilities: max num blacklist bssid=" + mMaxNumBlacklistBssid + " max num whitelist ssid=" + mMaxNumWhitelistSsid);
Buggy Code: ```java mMaxNumWhitelistSsid = roamingCap.maxWhitelistSize; Log.d(TAG, "Firmware roaming capabilities: max num blacklist bssid=" + mMaxNumBlacklistBssid + " max num whitelist ssid=" + mMaxNumWhitelistSsid); } else { Log.e(TAG, "Failed to get firmware roaming capabilities"); } } public boolean isFirmwareRoamingSupported() { return mFirmwareRoamingSupported; } public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { Log.e(TAG, "Firmware roaming is not supported"); return -1; } } public int getMaxNumWhitelistSsid() { if (mFirmwareRoamingSupported) { return mMaxNumWhitelistSsid; } else { Log.e(TAG, "Firmware roaming is not supported"); return -1; } } ``` Review: - Add documentation for the `getMaxNumBlacklistBssid()` method to explain the return value. Refactored Code: ```java mMaxNumWhitelistSsid = roamingCap.maxWhitelistSize; Log.d(TAG, "Firmware roaming capabilities: max num blacklist bssid=" + mMaxNumBlacklistBssid + " max num whitelist ssid=" + mMaxNumWhitelistSsid); } else { Log.e(TAG, "Failed to get firmware roaming capabilities"); } } public boolean isFirmwareRoamingSupported() { return mFirmwareRoamingSupported; } /** * Return the maximum size of BSSID blacklist. * * @return The maximum size of BSSID blacklist if firmware roaming is supported, otherwise -1. */ public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { Log.e(TAG, "Firmware roaming is not supported"); return -1; } } public int getMaxNumWhitelistSsid() { if (mFirmwareRoamingSupported) { return mMaxNumWhitelistSsid; } else { Log.e(TAG, "Firmware roaming is not supported"); return -1; } } ```
public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } Log.e(TAG, "Firmware roaming is not supported"); return -1; }
public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { Log.e(TAG, "MaxNumBlacklistBssid invalid: Firmware roaming is not supported"); return -1; } }
public int getMaxNumWhitelistSsid() { if (mFirmwareRoamingSupported) { return mMaxNumWhitelistSsid; } Log.e(TAG, "Firmware roaming is not supported"); return -1; }
/** Sets up test. */ @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); setupWifiNative(); mWifiConnectivityHelper = new WifiConnectivityHelper(mWifiNative); } /** Cleans up test. */ @After public void cleanup() { validateMockitoUsage(); } private WifiConnectivityHelper mWifiConnectivityHelper; @Mock private WifiNative mWifiNative; @Captor ArgumentCaptor<WifiNative.RoamingConfig> mRoamingConfigCaptor; private int mFeatureSetValue; private static final String TAG = "WifiConnectivityHelper Unit Test"; private static final int MAX_BSSID_BLACKLIST_SIZE = 16; private static final int MAX_SSID_WHITELIST_SIZE = 8; private void setupWifiNative() { // Return firmware roaming feature as supported by default. when(mWifiNative.getSupportedFeatureSet()).thenReturn(WIFI_FEATURE_CONTROL_ROAMING); doAnswer(new AnswerWithArguments<Boolean>() { public boolean answer(WifiNative.RoamingCapabilities roamCap) throws Exception { roamCap.maxBlacklistSize = MAX_BSSID_BLACKLIST_SIZE; roamCap.maxWhitelistSize = MAX_SSID_WHITELIST_SIZE; return true; } }).when(mWifiNative).getRoamingCapabilities(any(WifiNative.RoamingCapabilities.class)); }
public void verifyFirmwareRoamingCapabilityWithFailureNativeCall() { doAnswer(new AnswerWithArguments() { public boolean answer(WifiNative.RoamingCapabilities roamCap) throws Exception { roamCap.maxBlacklistSize = -1; roamCap.maxWhitelistSize = -1; return false; } }).when(mWifiNative).getRoamingCapabilities(anyObject()); mWifiConnectivityHelper.getFirmwareRoamingInfo(); assertEquals(-1, mWifiConnectivityHelper.getMaxNumBlacklistBssid()); assertEquals(-1, mWifiConnectivityHelper.getMaxNumWhitelistSsid()); }
public void verifySetFirmwareRoamingConfigurationWithGoodInput() { mWifiConnectivityHelper.getFirmwareRoamingInfo(); ArrayList<String> blacklist = buildBssidBlacklist(MAX_BSSID_BLACKLIST_SIZE); ArrayList<String> whitelist = buildSsidWhitelist(MAX_SSID_WHITELIST_SIZE); assertTrue(mWifiConnectivityHelper.setFirmwareRoamingConfiguration(blacklist, whitelist)); }
protected String createNetworkSpecifierPassphrase(@Nullable PeerHandle peerHandle, @NonNull String passphrase) { if (passphrase == null || passphrase.length() == 0) { throw new IllegalArgumentException("Passphrase must not be null or empty"); } if (mTerminated) { Log.w(TAG, "createNetworkSpecifierPassphrase: called on terminated session"); return null; } WifiAwareManager mgr = mMgr.get(); if (mgr == null) { Log.w(TAG, "createNetworkSpecifierPassphrase: called post GC on WifiAwareManager"); return null; } int role = this instanceof SubscribeDiscoverySession ? WifiAwareManager.WIFI_AWARE_DATA_PATH_ROLE_INITIATOR : WifiAwareManager.WIFI_AWARE_DATA_PATH_ROLE_RESPONDER; return mgr.createNetworkSpecifier(mClientId, role, mSessionId, peerHandle, null, passphrase); }
* Copyright (C) 2017 The Android Open Source Project * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * http://www.apache.org/licenses/LICENSE-2.0 * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. import java.lang.reflect.Method; public class Main { // Workaround for b/18051191. class InnerClass {} public static void main(String[] args) throws Exception { Class<?> c = Class.forName("IrreducibleLoop"); Method m = c.getMethod("simpleLoop", int.class); Object[] arguments = { 42 }; System.out.println(m.invoke(null, arguments)); } }
boolean waitForCallback(int callback) { synchronized (mLocalLock) { Iterator<Integer> it = mCallbackQueue.iterator(); while (it.hasNext()) { if (it.next() == callback) { it.remove(); return true; } } mCurrentWaitForCallback = callback; mBlocker = new CountDownLatch(1); } try { return mBlocker.await(WAIT_FOR_AWARE_CHANGE_SECS, TimeUnit.SECONDS); } catch (InterruptedException e) { return false; } }
boolean hasCallbackAlreadyHappened(int callback) { synchronized (mLocalLock) { return mCallbackQueue.contains(callback); } }
public void testSubscribeDiscoverySuccess() { if (!TestUtils.shouldTestWifiAware(getContext())) { return; } final String serviceName = "ValidName"; WifiAwareSession session = attachAndGetSession(); SubscribeConfig subscribeConfig = new SubscribeConfig.Builder().setServiceName(serviceName).build(); DiscoverySessionCallbackTest discoveryCb = new DiscoverySessionCallbackTest(); session.subscribe(subscribeConfig, discoveryCb, null); assertTrue(discoveryCb.waitForCallback(DiscoverySessionCallbackTest.ON_SUBSCRIBE_STARTED)); SubscribeDiscoverySession discoverySession = discoveryCb.getSubscribeDiscoverySession(); assertNotNull(discoverySession); subscribeConfig = new SubscribeConfig.Builder().setServiceName(serviceName).setServiceSpecificInfo("extras".getBytes()).build(); discoverySession.updateSubscribe(subscribeConfig); assertTrue(discoveryCb.waitForCallback(DiscoverySessionCallbackTest.ON_SESSION_CONFIG_UPDATED)); assertFalse(discoveryCb.hasCallbackAlreadyHappened(DiscoverySessionCallbackTest.ON_SESSION_TERMINATED)); discoverySession.destroy(); }
assertTrue("Incorrect longitude: " + longitude, Math.abs(longitude - LONGITUDE) <= TOLERANCE); retriever.release(); return true; } private void checkOutputExist() { assertTrue(mOutFile.exists()); assertTrue(mOutFile.length() > 0); assertTrue(mOutFile.delete()); } public void testRecorderVideo() throws Exception { if (!hasCamera()) { return; } mCamera = Camera.open(0); setSupportedResolution(mCamera); mCamera.release(); mCamera = null; mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.CAMERA); mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.DEFAULT); mMediaRecorder.setOutputFile(OUTPUT_PATH2); mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.DEFAULT); mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setVideoSize(mVideoWidth, mVideoHeight); FileOutputStream fos = new FileOutputStream(OUTPUT_PATH2); FileDescriptor fd = fos.getFD(); mMediaRecorder.setOutputFile(fd); long maxFileSize = MAX_FILE_SIZE * 10; recordMedia(maxFileSize, mOutFile2); }
protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.list_7); mPhone = (TextView) findViewById(R.id.phone); getListView().setOnItemSelectedListener(this); // Get a cursor with all people Cursor c = getContentResolver().query(ContactsContract.Contacts.CONTENT_URI, PEOPLE_PROJECTION, null, null, null); startManagingCursor(c); mColumnHasPhoneNumber = c.getColumnIndex(ContactsContract.Contacts.HAS_PHONE_NUMBER); mColumnContactId = c.getColumnIndex(ContactsContract.Contacts._ID); ListAdapter adapter = new SimpleCursorAdapter(this, android.R.layout.simple_list_item_1, c, new String[] {ContactsContract.Contacts.DISPLAY_NAME}, new int[] {android.R.id.text1}); setListAdapter(adapter); } public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); // Query for people Cursor groupCursor = managedQuery(Contacts.CONTENT_URI, PEOPLE_PROJECTION, null, null, null); mContactIdColumnIndex = groupCursor.getColumnIndexOrThrow(ContactsContract.Contacts._ID); mAdapter = new MyExpandableListAdapter(groupCursor, this, android.R.layout.simple_expandable_list_item_1, android.R.layout.simple_expandable_list_item_1, new String[] {ContactsContract.Contacts.DISPLAY_NAME}, new int[] {android.R.id.text1}, new String[] {ContactsContract.CommonDataKinds.Phone.NUMBER}, new int[] {android.R.id.text1}); setListAdapter(mAdapter); } protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.list_7); mPhone = (TextView) findViewById(R.id.phone); getListView().setOnItemSelectedListener(this); // Get a cursor with all people Cursor c = getContentResolver().query(ContactsContract.Contacts.CONTENT_URI, PEOPLE_PROJECTION, null, null, null); startManagingCursor(c); ListAdapter adapter = new SimpleCursorAdapter(this, android.R.layout.simple_list_item_1, c, new String[] {ContactsContract.Contacts.DISPLAY_NAME}, new int[] {android.R.id.text1}); setListAdapter(adapter); } assertNotNull(durationStr); return Integer.parseInt(durationStr); } public void testSetMaxFileSize() throws Exception { testSetMaxFileSize(512 * 1024, 50 * 1024
private void checkType(int columnIndex, Type expectedType) { ColumnSchema columnSchema = schema.getColumnByIndex(columnIndex); Type columnType = columnSchema.getType(); if (!columnType.equals(expectedType)) { throw new IllegalArgumentException("Column (name: " + columnSchema.getName() + ", index: " + columnIndex +") is of type " + columnType.getName() + " but was requested as a type " + expectedType.getName()); } } public Integer abs(Integer self) { return Integer.valueOf(Math.abs(self.intValue())); } public Integer floor(Double self) { return Integer.valueOf((int)Math.floor(self.doubleValue())); } public Integer floor(Integer self) { return self; } // Refuse to send SMS if we can't get the calling package name. Rlog.e(TAG, "Can't get calling app package name: refusing to send SMS"); tracker.onFailed(mContext, RESULT_ERROR_GENERIC_FAILURE, 0/*errorCode*/); return; // Get package info via packagemanager PackageInfo appInfo; try { appInfo = pm.getPackageInfoAsUser(packageNames[0], PackageManager.GET_SIGNATURES, mContext.getUserId()); } catch (PackageManager.NameNotFoundException e) { Rlog.e(TAG, "Can't get calling app package info: refusing to send SMS"); tracker.onFailed(mContext, RESULT_ERROR_GENERIC_FAILURE, 0/*errorCode*/); return; } if (checkDestination(tracker)) { // code here }
mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.DEFAULT); mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setVideoSize(mVideoWidth, mVideoHeight); FileOutputStream fos = new FileOutputStream(OUTPUT_PATH2); FileDescriptor fd = fos.getFD(); mMediaRecorder.setOutputFile(fd); long maxFileSize = MAX_FILE_SIZE * 10; recordMedia(maxFileSize, mOutFile2); assertFalse(checkLocationInFile(OUTPUT_PATH2)); fos.close(); mCamera.release(); mCamera = null; public void testRecordingAudioInRawFormats() throws Exception { int testsRun = 0; if (hasAmrNb()) { testsRun += testRecordAudioInRawFormat(MediaRecorder.OutputFormat.AMR_NB, MediaRecorder.AudioEncoder.AMR_NB); } if (hasAmrWb()) { testsRun += testRecordAudioInRawFormat(MediaRecorder.OutputFormat.AMR_WB, MediaRecorder.AudioEncoder.AMR_WB); } if (hasAac()) { testsRun += testRecordAudioInRawFormat(MediaRecorder.OutputFormat.AAC_ADTS, MediaRecorder.AudioEncoder.AAC); } }
mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setMaxFileSize(fileSize); mMediaRecorder.prepare(); mMediaRecorder.start(); // Recording a scene with moving objects would greatly help reduce // the time for waiting. if (!mMaxFileSizeCond.block(MAX_FILE_SIZE_TIMEOUT_MS)) { fail("timed out waiting for MEDIA_RECORDER_INFO_MAX_FILESIZE_REACHED"); } mMediaRecorder.stop(); checkOutputFileSize(OUTPUT_PATH, fileSize, tolerance); mCamera.release(); mCamera = null; } private void checkOutputFileSize(final String fileName, long fileSize, long tolerance) { assertTrue(mOutFile.exists()); assertEquals(fileSize, mOutFile.length(), tolerance); assertTrue(mOutFile.delete()); } public void testOnErrorListener() throws Exception { if (!hasMicrophone() || !hasAmrNb()) { MediaUtils.skipTest("no audio codecs or microphone"); return; } mMediaRecorder.setAudioSource(MediaRecorder.AudioSource.DEFAULT); mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP);
try { Camera camera = Camera.open(0); List<Camera.Size> previewSizes = camera.getParameters().getSupportedPreviewSizes(); width = previewSizes.get(0).width; height = previewSizes.get(0).height; for (Camera.Size size : previewSizes) { if (size.width < width || size.height < height) { width = size.width; height = size.height; } } camera.release(); } catch (Exception e) { width = VIDEO_WIDTH; height = VIDEO_HEIGHT; } if (camera != null) { camera.release(); } Log.v(TAG, String.format("Camera video size used for test %dx%d", width, height)); output.write("H263 video record- reset after prepare Stress test\n"); output.write("Total number of loops:" + NUMBER_OF_RECORDER_STRESS_LOOPS + "\n"); output.write("No of loop: "); Log.v(TAG, "Start preview"); for (int i = 0; i < NUMBER_OF_RECORDER_STRESS_LOOPS; i++) { runOnLooper(new Runnable() { @Override public void run() { // code to be executed } }); } private WorkspaceData(IDataPersistenceService service) { this.service = service; } public List<Destination> getDestinations(FilterType filterType) { Predicate<? super Destination> filter = null; switch (filterType) { case PROJECT_CREATION: filter = dest -> dest.isCreateMissingRepos(); break; case PROJECT_DELETION: filter = dest -> dest != null && !dest.isReplicateProjectDeletions(); break; case ALL: default: break; } return filter != null ? destinations.stream().filter(filter).collect(toList()) : destinations; } assertTrue("Incorrect longitude: " + longitude, Math.abs(longitude - LONGITUDE) <= TOLERANCE); retriever.release(); return true; private void checkOutputExist() { assertTrue(mOutFile.exists()); assertTrue(mOutFile.length() > 0); assertTrue(mOutFile.delete()); } public void testRecorderVideo() throws Exception { if (!hasCamera()) { return; } mCamera = Camera.open(0); setSupportedResolution(mCamera); mCamera.unlock(); mMediaRecorder.setCamera(mCamera); mMedia
|| regState == ServiceState.RIL_REG_STATE_DENIED) { rejectCode = Integer.parseInt(states[13]); } if (states.length > 14) { if (states[14] != null && states[14].length() > 0) { psc = (int)Long.parseLong(states[14], 16); } } } catch (NumberFormatException ex) { loge("error parsing RegistrationState: " + ex); } mGsmRoaming = regCodeIsRoaming(regState); mNewSS.setVoiceRegState(regCodeToServiceState(regState)); mNewSS.setRilVoiceRadioTechnology(type); mNewRejectCode = rejectCode; boolean isVoiceCapable = mPhone.getContext().getResources() .getBoolean(com.android.internal.R.bool.config_voice_capable); if ((regState == ServiceState.RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED || regState == ServiceState.RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED || regState == ServiceState.RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED
private int convertHalRegStateToServiceState(int regState) { switch (regState) { case RegState.NOT_REG_MT_NOT_SEARCHING_OP: return ServiceState.RIL_REG_STATE_NOT_REG; case RegState.REG_HOME: return ServiceState.RIL_REG_STATE_HOME; case RegState.NOT_REG_MT_SEARCHING_OP: return ServiceState.RIL_REG_STATE_SEARCHING; case RegState.REG_DENIED: return ServiceState.RIL_REG_STATE_DENIED; case RegState.UNKNOWN: return ServiceState.RIL_REG_STATE_UNKNOWN; case RegState.REG_ROAMING: return ServiceState.RIL_REG_STATE_ROAMING; case RegState.NOT_REG_MT_NOT_SEARCHING_OP_EM: return ServiceState.RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED; case RegState.NOT_REG_MT_SEARCHING_OP_EM: return ServiceState.RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED; case RegState.REG_DENIED_EM: return ServiceState.RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED; case RegState.UNKNOWN_EM: return ServiceState.RIL_REG_STATE_UNKNOWN_EMERGENCY_CALL_ENABLED; default: return ServiceState.REGISTRATION_STATE_NOT_REGISTERED_AND_NOT_SEARCHING; } }
if (DBG) { log("handlPollVoiceRegResultMessage: regState=" + registrationState + " radioTechnology=" + voiceRegStateResult.rat); } break; } case EVENT_POLL_STATE_GPRS: { DataRegStateResult dataRegStateResult = (DataRegStateResult) ar.result; int regState = convertHalRegStateToServiceState(dataRegStateResult.regState); int dataRegState = regCodeToServiceState(regState); int newDataRat = dataRegStateResult.rat; int oldDataRAT = mSS.getRilDataRadioTechnology(); mNewSS.setDataRegState(dataRegState); mNewSS.setRilDataRadioTechnology(newDataRat); if (mPhone.isPhoneTypeGsm()) { mNewReasonDataDenied = dataRegStateResult.reasonDataDenied; mNewMaxDataCalls = dataRegStateResult.maxDataCalls; mDataRoaming = regCodeIsRoaming(regState); if (DBG) { log("handlPollStateResultMessage: GsmSST setDataRegState=" + dataRegState + " regState=" + regState + " dataRadioTechnology=" + newDataRat); } } else if (mPhone.isPhoneTypeCdma()) { // code for CDMA } }
* <td>TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA</td> * <td>1&ndash;8</td> * <td>1&ndash;8</td> </tr> <tr class="deprecated"> <td>TLS_DHE_RSA_WITH_AES_128_CBC_SHA</td> <td>9&ndash;TBD</td> <td>9&ndash;TBD</td> </tr> <tr class="deprecated"> <td>TLS_DHE_RSA_WITH_AES_128_CBC_SHA256</td> <td>20&ndash;26+</td> <td></td> </tr> <tr class="deprecated"> <td>TLS_DHE_RSA_WITH_AES_128_GCM_SHA256</td> <td>20&ndash;TBD</td> <td>20&ndash;TBD</td> </tr> <tr class="deprecated"> <td>TLS_DHE_RSA_WITH_AES_256_CBC_SHA</td> <td>9&ndash;TBD</td> <td>20&ndash;TBD</td> </tr> <tr class="deprecated">
@Test public void testSocketConnectTimeout() throws Exception { // #connect(SocketAddress endpoint, int timeout) checkOperationTimesOut(() -> new Socket(), s -> s.connect(UNREACHABLE_ADDRESS, TIMEOUT_MILLIS)); // Setting SO_TIMEOUT should not affect connect timeout. checkOperationTimesOut(() -> new Socket(), s -> { s.setSoTimeout(TIMEOUT_MILLIS / 2); s.connect(UNREACHABLE_ADDRESS, TIMEOUT_MILLIS); }); } @Test public void testSocketIOStreamTimeout() throws Exception { // #read() try (ServerSocket ss = new ServerSocket(0)) { // The server socket will accept the connection without explicitly calling accept() due // to TCP backlog. checkOperationTimesOut(() -> new Socket(), s -> { s.connect(ss.getLocalSocketAddress()); s.setSoTimeout(TIMEOUT_MILLIS); s.getInputStream().read(); }); } } @Test public void testSocketWriteNeverTimeouts() throws Exception { // Test case implementation }
writeCompleted.countDown(); } catch (IOException ignored) { } finally { writeCompleted.countDown(); }); thread.start(); // Wait for the thread to start. assertTrue(threadStarted.await(500, TimeUnit.MILLISECONDS)); // Wait for TIMEOUT_MILLIS + slop. If write does not complete by then, we assume it has // blocked. boolean blocked = !writeCompleted.await((long) (TIMEOUT_MILLIS * 1.2f), TimeUnit.MILLISECONDS); assertTrue(blocked); // Make sure the writing thread completes after the socket is closed. sock.close(); assertTrue(writeCompleted.await(600, TimeUnit.MILLISECONDS)); } } @Test public void testServerSocketAcceptTimeout() throws Exception { // #accept() checkOperationTimesOut(() -> new ServerSocket(0), s -> { s.setSoTimeout(TIMEOUT_MILLIS); s.accept(); }); } @Test public void testServerSocketChannelAcceptTimeout() throws Exception { // #accept() checkOperationTimesOut(() -> ServerSocketChannel.open(), s -> {
/** @hide */ public static final int WIFI_FEATURE_MKEEP_ALIVE = 0x100000; // Wifi mkeep_alive /** @hide */ public static final int WIFI_FEATURE_CONFIG_NDO = 0x200000; // ND offload configure /** @hide */ public static final int WIFI_FEATURE_TRANSMIT_POWER = 0x400000; // Capture Tx transmit power levels /** @hide */ public static final int WIFI_FEATURE_CONTROL_ROAMING = 0x800000; // Enable/Disable firmware roaming /** @hide */ public static final int WIFI_FEATURE_IE_WHITELIST = 0x1000000; // Probe IE white listing /** @hide */ public static final int WIFI_FEATURE_SCAN_RAND = 0x2000000; // Support MAC & Probe Sequence Number randomization private int getSupportedFeatures() { try { return mService.getSupportedFeatures(); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } private boolean isFeatureSupported(int feature) { return (getSupportedFeatures() & feature) == feature; } public void verifyFirmwareRoamingCapabilityWithSuccessfulNativeCall() { mWifiConnectivityHelper.getFirmwareRoamingInfo(); assertTrue(mWifiConnectivityHelper.isFirmwareRoamingSupported()); assertEquals(MAX_BSSID_BLACKLIST_SIZE, mWifiConnectivityHelper.getMaxNumBlacklistBssid()); assertEquals(MAX_SSID_WHITELIST_SIZE, mWifiConnectivityHelper.getMaxNumWhitelistSsid()); } public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { Log.e(TAG, "Firmware roaming is not supported"); return -1; } } if (roamingCap.maxBlacklistSize < 0 || roamingCap.maxWhitelistSize < 0) { Log.e(TAG, "Invalid firmware roaming capabilities: max num blacklist bssid=" + roamingCap.maxBlacklistSize + " max num whitelist ssid=" + roamingCap.maxWhitelistSize); } else { mFirmwareRoamingSupported = true; mMaxNumBlacklistBssid = roamingCap.maxBlacklistSize;
public boolean setFirmwareRoamingConfiguration(ArrayList<String> blacklistBssids, ArrayList<String> whitelistSsids) { if (!mFirmwareRoamingSupported) { Log.e(TAG, "Firmware roaming is not supported"); return false; } if (blacklistBssids == null || whitelistSsids == null) { Log.e(TAG, "Invalid firmware roaming configuration settings"); return false; } int blacklistSize = blacklistBssids.size(); int whitelistSize = whitelistSsids.size(); if (blacklistSize > mMaxNumBlacklistBssid || whitelistSize > mMaxNumWhitelistSsid) { Log.e(TAG, "Invalid BSSID blacklist size " + blacklistSize + " SSID whitelist size " + whitelistSize + ". Max blacklist size: " + mMaxNumBlacklistBssid + ", max whitelist size: " + mMaxNumWhitelistSsid); return false; } WifiNative.RoamingConfig roamConfig = new WifiNative.RoamingConfig(); roamConfig.blacklistBssids = blacklistBssids; roamConfig.whitelistSsids = whitelistSsids; return mWifiNative.configureRoaming(roamConfig); }
Fixed Code: public boolean requestIcon(String bssid, String fileName) { if (bssid == null || fileName == null) { throw new IllegalArgumentException("BSSID and file name cannot be null."); } return mSupplicantStaIfaceHal.initiateHs20IconQuery(bssid, fileName); }
package com.android.server.wifi; import static org.junit.Assert.assertTrue; import static org.mockito.Mockito.mock; import android.os.Handler; import android.os.Message; import android.util.SparseArray; import java.util.HashMap; import java.util.Map; public class MockWifiMonitor extends WifiMonitor { private final Map<String, SparseArray<Handler>> mHandlerMap = new HashMap<>(); public MockWifiMonitor() { super(mock(WifiInjector.class)); } @Override public void registerHandler(String iface, int what, Handler handler) { SparseArray<Handler> ifaceHandlers = mHandlerMap.get(iface); if (ifaceHandlers == null) { ifaceHandlers = new SparseArray<>(); mHandlerMap.put(iface, ifaceHandlers); } ifaceHandlers.put(what, handler); } @Override public void startMonitoring() { // Do nothing } }
result.setResult(mISupplicantP2pIface.startWpsPinKeypad(groupIfName, pin)); } catch (RemoteException e) { Log.e(TAG, "ISupplicantP2pIface exception: " + e); supplicantServiceDiedHandler(); } return result.isSuccess(); } public String startWpsPinDisplay(String groupIfName, String bssid) { if (TextUtils.isEmpty(groupIfName) || TextUtils.isEmpty(bssid)) return null; synchronized (mLock) { if (!checkSupplicantP2pIfaceAndLogFailure("startWpsPinDisplay")) return null; if (groupIfName == null) { Log.e(TAG, "Group name required when requesting WPS KEYPAD."); return null; } byte[] macAddress = null; if (bssid != null) {
```java public WifiNative(String interfaceName, WifiVendorHal vendorHal, SupplicantStaIfaceHal staIfaceHal, SupplicantP2pIfaceHal p2pIfaceHal, WificondControl condControl) { mInterfaceName = interfaceName; mWifiVendorHal = vendorHal; mSupplicantStaIfaceHal = staIfaceHal; mSupplicantP2pIfaceHal = p2pIfaceHal; mWificondControl = condControl; } public String getInterfaceName() { return mInterfaceName; } public void enableVerboseLogging(int verbose) { mWificondControl.enableVerboseLogging(verbose > 0 ? true : false); mSupplicantStaIfaceHal.enableVerboseLogging(verbose > 0); mWifiVendorHal.enableVerboseLogging(verbose > 0); } /******************************************************** * Native Initialization/Deinitialization ********************************************************/ /** * Setup wifi native for Client mode operations. * * 1. Starts the Wifi HAL and configures it in client/STA mode. * 2. Setup Wificond to operate in client mode and retrieve the handle to use for client operations. */ ```
public boolean startFilteringMulticastV4Packets() { return mSupplicantStaIfaceHal.startRxFilter() && mSupplicantStaIfaceHal.removeRxFilter(SupplicantStaIfaceHal.RX_FILTER_TYPE_V4_MULTICAST) && mSupplicantStaIfaceHal.startRxFilter(); }
public boolean stopFilteringMulticastV4Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.addRxFilter(SupplicantStaIfaceHal.RX_FILTER_TYPE_V4_MULTICAST) && mSupplicantStaIfaceHal.stopRxFilter(); }
public boolean startFilteringMulticastV6Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.removeRxFilter(SupplicantStaIfaceHal.RX_FILTER_TYPE_V6_MULTICAST) && mSupplicantStaIfaceHal.startRxFilter(); }
public boolean stopFilteringMulticastV6Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.addRxFilter(SupplicantStaIfaceHal.RX_FILTER_TYPE_V6_MULTICAST) && mSupplicantStaIfaceHal.stopRxFilter(); }
public boolean setSerialNumber(String value) { return mSupplicantStaIfaceHal.setWpsSerialNumber(value); } public void setPowerSave(boolean enabled) { mSupplicantStaIfaceHal.setPowerSave(enabled); } /** * "sta" prioritizes STA connection over P2P and "p2p" prioritizes * P2P connection over STA */ public boolean setConcurrencyPriority(boolean isStaHigherPriority) { return mSupplicantStaIfaceHal.setConcurrencyPriority(isStaHigherPriority); } /** * WifiSupplicantControl methods. TODO: These should use HIDL soon. */ /** * Migrate all the configured networks from wpa_supplicant. * * @param configs Map of configuration key to configuration objects corresponding to all * the networks. * @param networkExtras Map of extra configuration parameters stored in wpa_supplicant.conf * @return Max priority of all the configs. */ public boolean migrateNetworksFromSupplicant(Map<String, WifiConfiguration> configs, SparseArray<Map<String, String>> networkExtras) { return mSupplicantStaIfaceHal.loadNetworks(configs, networkExtras); }
/** * Handler to notify the occurrence of various events during PNO scan. */ public interface PnoEventHandler { /** * Callback to notify when one of the shortlisted networks is found during PNO scan. * @param results List of Scan results received. */ void onPnoNetworkFound(ScanResult[] results); /** * Callback to notify when the PNO scan schedule fails. */ void onPnoScanFailed(); } public static final int WIFI_SCAN_RESULTS_AVAILABLE = 0; public static final int WIFI_SCAN_THRESHOLD_NUM_SCANS = 1; public static final int WIFI_SCAN_THRESHOLD_PERCENT = 2; public static final int WIFI_SCAN_FAILED = 3; public boolean startScan(ScanSettings settings, ScanEventHandler eventHandler) { return mWifiVendorHal.startScan(settings, eventHandler); } public void stopScan() { mWifiVendorHal.stopScan(); } public void pauseScan() { mWifiVendorHal.pauseScan(); }
public void setWifiLinkLayerStats(String iface, int enable) { // TODO: Remove calling code with bug ID. }
public boolean isGetChannelsForBandSupported() { return mWifiVendorHal.isGetChannelsForBandSupported(); }
void onWifiAlert(int errorCode, byte[] buffer); public boolean setLoggingEventHandler(WifiLoggerEventHandler handler) { return mWifiVendorHal.setLoggingEventHandler(handler); } public boolean startLoggingRingBuffer(int verboseLevel, int flags, int maxInterval, int minDataSize, String ringName){ return mWifiVendorHal.startLoggingRingBuffer( verboseLevel, flags, maxInterval, minDataSize, ringName); } public int getSupportedLoggerFeatureSet() { return mWifiVendorHal.getSupportedLoggerFeatureSet(); } public boolean resetLogHandler() { return mWifiVendorHal.resetLogHandler(); } public String getDriverVersion() { return mWifiVendorHal.getDriverVersion(); } public String getFirmwareVersion() { return mWifiVendorHal.getFirmwareVersion(); } public static class RingBufferStatus{ String name; int flag; int ringBufferId; int ringBufferByteSize; int verboseLevel; int writtenBytes; int readBytes; int writtenRecords; // Bit masks for interpreting |flag| public static final int HAS_BINARY_ENTRIES = (1 << 0); }
* @hide */ public static final String KEY_NOTIFY_INTERNATIONAL_CALL_ON_WFC_BOOL = "notify_international_call_on_wfc_bool"; /** * Offset to be reduced from rsrp threshold while calculating signal strength level. * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int"; /** * Threshold of EARFCN above which signal_strength_offset_int will be applied. * Unit of this value should be in MHz. * @hide */ public static final String KEY_SIGNAL_STRENGTH_FREQ_THRESHOD_INT = "signal_strength_freq_threshold_int"; /** The default value for every variable. */ private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true);
"notify_international_call_on_wfc_bool"; /** * Offset to be reduced from rsrp threshold while calculating signal strength level. * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int"; /** * Threshold of EARFCN above which signal_strength_offset_int will be applied. * Unit of this value should be in MHz. * @hide */ public static final String KEY_SIGNAL_STRENGTH_EAFCN_THRESHOLD_INT = "signal_strength_earfcn_threshold_int"; /** The default value for every variable. */ private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true); sDefaults.putBoolean(KEY_APN_EXPAND_BOOL, true); sDefaults.putBoolean(KEY_AUTO_RETRY_ENABLED_BOOL, false);
/** * Opens a logical channel to the ICC card. * * Input parameters equivalent to TS 27.007 AT+CCHO command. * * <p>Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param subId The subscription to use. * @param AID Application id. See ETSI 102.221 and 101.220. * @param p2 P2 parameter (described in ISO 7816-4). Default value: 0x00 * @return an IccOpenLogicalChannelResponse object. */ @Deprecated public IccOpenLogicalChannelResponse iccOpenLogicalChannel(int subId, String AID, byte p2) { return iccOpenLogicalChannel(getSubId(), AID, p2); } /** * Opens a logical channel to the ICC card. * * Input parameters equivalent to TS 27.007 AT+CCHO command. * * <p>Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param AID Application id. See ETSI 102.221 and 101.220. * @param p2 P2 parameter (described in ISO 7816-4). Default value: 0x00 * @return an IccOpenLogicalChannelResponse object. */ public IccOpenLogicalChannelResponse iccOpenLogicalChannel(String AID, byte p2) { return iccOpenLogicalChannel(getSubId(), AID, p2); }
package com.android.server.wifi.scanner; import android.content.Context; import android.net.wifi.WifiScanner; import android.os.Handler; import android.os.Looper; import android.os.Message; import android.util.Log; import com.android.server.wifi.Clock; import com.android.server.wifi.WifiNative; public class HalWifiScannerImpl extends WifiScannerImpl implements Handler.Callback { private static final String TAG = "HalWifiScannerImpl"; private static final boolean DBG = false; private final WifiNative mWifiNative; private final ChannelHelper mChannelHelper; private final WificondScannerImpl mWificondScannerDelegate; private final boolean mHalBasedPnoSupported; public HalWifiScannerImpl(Context context, WifiNative wifiNative, Looper looper, Clock clock) { mWifiNative = wifiNative; mChannelHelper = new HalChannelHelper(wifiNative); mWificondScannerDelegate = new WificondScannerImpl(context, wifiNative, looper, clock); mHalBasedPnoSupported = wifiNative.isHalBasedPnoSupported(); } }
private static final String R_ATTR = "R"; //$NON-NLS-1$ private static final String G_ATTR = "G"; //$NON-NLS-1$ private static final String B_ATTR = "B"; //$NON-NLS-1$ private static final String TICK_TAG = "TICK"; //$NON-NLS-1$ private static final String FILTER_TAG = "FILTER"; //$NON-NLS-1$ /** * Saves the given color settings to file. * * @param pathName A file name with path * @param colorSettings An array of color settings to save. */ public static void save(String pathName, ColorSetting[] colorSettings) { try { DocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder documentBuilder = documentBuilderFactory.newDocumentBuilder(); Document document = documentBuilder.newDocument(); Element rootElement = document.createElement(COLOR_SETTINGS_TAG); document.appendChild(rootElement); for (ColorSetting colorSetting : colorSettings) { Element colorSettingElement = document.createElement(COLOR_SETTING_TAG); // code to add color setting to the document } // code to save the document to file } catch (Exception e) { e.printStackTrace(); } } private static void waitForShadowProjectUpdated(String parentProjectName) { for (int i = 1; i < 5000 && (TmfProjectModelHelper.getShadowProject(parentProjectName).exists()); i *= 2) { delay(i); } } /** * Step for FirstRunWizard for selecting a color scheme. */ public class SelectThemeStep extends FirstRunWizardStep { private final CustomizeUIThemeStepPanel themePanel; private final ScopedStateStore.Key<Boolean> myKeyCustomInstall; public SelectThemeStep(@NotNull ScopedStateStore.Key<Boolean> keyCustomInstall) { super("Select UI Theme"); this.myKeyCustomInstall = keyCustomInstall; this.themePanel = new CustomizeUIThemeStepPanel(); } // code for the rest of the class } /** * WifiScanner implementation that takes advantage of the gscan HAL API * The gscan API is used to perform background scans and wificond is used for onehot scans. * @see com.android.server.wifi.scanner.WifiScannerImpl for more details on each method. */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler.Callback { private static final String TAG = "HalWifiScanner
public void describeTo(Description description) { description.appendText(toString()); }
String[] s; s = params.getCipherSuites(); if (s != null) { setEnabledCipherSuites(s); } s = params.getProtocols(); if (s != null) { setEnabledProtocols(s); } if (params.getNeedClientAuth()) { setNeedClientAuth(true); } else if (params.getWantClientAuth()) { setWantClientAuth(true); } else { setWantClientAuth(false); } @Override public String toString() { return "SSL" + super.toString(); }
public void receivedWnmFrame(WnmData data) { mHandler.notifyWnmFrameReceived(data); } public boolean queryPasspointIcon(long bssid, String fileName) { return mHandler.requestIcon(bssid, fileName); } public Map<Constants.ANQPElementType, ANQPElement> getANQPElements(ScanResult scanResult) { InformationElementUtil.Vsa vsa = InformationElementUtil.getHS2VendorSpecificIE(scanResult.informationElements); long bssid = Utils.parseMac(scanResult.BSSID); ANQPData anqpEntry = mAnqpCache.getEntry(ANQPNetworkKey.buildKey(bssid, vsa.anqpDomainID)); if (anqpEntry != null) { return anqpEntry.getElements(); } else { return new HashMap<>(); } }
public Map<Constants.ANQPElementType, ANQPElement> lookupANQPElements(ScanResult scanResult) { InformationElementUtil.Vsa vsa = InformationElementUtil.getHS2VendorSpecificIE(scanResult.informationElements); long bssid = Utils.parseMac(scanResult.BSSID); ANQPData anqpEntry = mAnqpCache.getEntry(ANQPNetworkKey.buildKey(scanResult.SSID, bssid, scanResult.hessid, vsa.anqpDomainID)); return anqpEntry != null ? anqpEntry.getElements() : Collections.emptyMap(); }
public void enter() { super.enter(); if (!mBluetoothRouteManager.isInbandRingingEnabled()) { setSpeakerphoneOn(false); } CallAudioState newState = new CallAudioState(mIsMuted, ROUTE_BLUETOOTH, mAvailableRoutes); setSystemAudioState(newState); updateInternalCallAudioState(); }
/** * Opens a logical channel to the ICC card. * * Input parameters equivalent to TS 27.007 AT+CCHO command. * * <p>Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param AID Application id. See ETSI 102.221 and 101.220. * @return an IccOpenLogicalChannelResponse object. * @deprecated Replaced by {@link #iccOpenLogicalChannel(String, byte)} */ @Deprecated public IccOpenLogicalChannelResponse iccOpenLogicalChannel(String AID) { return iccOpenLogicalChannel(getSubId(), AID, (byte) 0x00); } /** * Opens a logical channel to the ICC card. * * Input parameters equivalent to TS 27.007 AT+CCHO command. * * <p>Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param AID Application id. See ETSI 102.221 and 101.220. * @param p2 P2 parameter (described in ISO 7816-4). Default value: 0x00 * @return an IccOpenLogicalChannelResponse object. */ public IccOpenLogicalChannelResponse iccOpenLogicalChannel(String AID, byte p2) { return iccOpenLogicalChannel(getSubId(), AID, p2); }
private static LinkProperties getUniqueLocalConfig(byte[] ulp, String ifname) { LinkProperties lp = new LinkProperties(); lp.setInterfaceName(ifname); final IpPrefix local48 = getUniqueLocalPrefix(ulp, (short) 0, 48); lp.addRoute(new RouteInfo(local48, null, null)); // Use 16 bits of the hashCode of the interface name as the Subnet ID. final IpPrefix local64 = getUniqueLocalPrefix(ulp, (short) ifname.hashCode(), 64); lp.addLinkAddress(new LinkAddress(local64.getAddress(), 64)); return lp; }
private int mEvdoDbm; private int mEvdoEcio; private int mEvdoSnr; private int mLteSignalStrength; private int mLteRsrp; private int mLteRsrq; private int mLteRssnr; private int mLteCqi; private int mLteOffset; private int mTdScdmaRscp; private boolean isGsm; public static SignalStrength newFromBundle(Bundle m) { SignalStrength ret; ret = new SignalStrength(); ret.setFromNotifierBundle(m); return ret; }
public void setLteRsrpOffset(int lteRsrpOffset) { mLteRsrpOffset = lteRsrpOffset; }
int rssiIconLevel = SIGNAL_STRENGTH_NONE_OR_UNKNOWN, rsrpIconLevel = -1, snrIconLevel = -1; int[] threshRsrp = Resources.getSystem().getIntArray(com.android.internal.R.array.config_lteDbmThresholds); if (threshRsrp.length != 6) { Log.wtf(LOG_TAG, "getLteLevel - config_lteDbmThresholds has invalid num of elements." + " Cannot evaluate RSRP signal."); } else { if (mLteRsrp > threshRsrp[5]) { rsrpIconLevel = -1; } else if (mLteRsrp >= (threshRsrp[4] - mLteOffset)) { rsrpIconLevel = SIGNAL_STRENGTH_GREAT; } else if (mLteRsrp >= (threshRsrp[3] - mLteOffset)) { rsrpIconLevel = SIGNAL_STRENGTH_GOOD; } else if (mLteRsrp >= (threshRsrp[2] - mLteOffset)) { rsrpIconLevel = SIGNAL_STRENGTH_MODERATE; } else if (mLteRsrp >= (threshRsrp[1] - mLteOffset)) { rsrpIconLevel = SIGNAL_STRENGTH_POOR; } else if (mLteRsrp >= threshRsrp[0]) { rsrpIconLevel = SIGNAL_STRENGTH_NONE_OR_UNKNOWN; } }
"notify_international_call_on_wfc_bool"; public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int"; public static final String KEY_SIGNAL_STRENGTH_EARFCNS_LIST_STRING_ARRAY = "signal_strength_earfcn_threshold_int"; private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true); }
public int startWifiHotspot(WifiConfiguration cfg) { try { return mService.startLocalOnlyWifiHotspot(cfg); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } }
public void verifyGetFirmwareRoamingInfoIsCalledWhenWifiEnabled() { reset(mWifiConnectivityHelper); mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper).getFirmwareRoamingInfo(); }
// Set up current network configuration WifiConfiguration currentNetwork = generateWifiConfig(0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null); when(mWifiConfigManager.getConfiguredNetwork(anyInt())).thenReturn(currentNetwork); // Set WiFi to connected state mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_CONNECTED); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Verify that startRoamToNetwork is called with the correct parameters verify(mWifiStateMachine).startRoamToNetwork(anyInt(), anyObject());
public void noFrameworkRoamingIfFirmwareControlRoaming() { // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set WiFi to connected state mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_CONNECTED); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); verify(mWifiStateMachine, times(0)).startRoamToNetwork(anyInt(), anyObject()); }
import com.intellij.openapi.diagnostic.Logger; import com.intellij.openapi.progress.ProgressIndicator; import com.intellij.openapi.progress.Task; import com.intellij.openapi.ui.Messages; import org.jetbrains.annotations.NotNull; import java.io.IOException; import java.util.concurrent.atomic.AtomicReference; public class SampleImportAction extends AnAction { private static final Logger LOG = Logger.getInstance(SampleImportAction.class); @Override public void actionPerformed(AnActionEvent e) { final SamplesIndex samplesService; SamplesIndex.Builder myBuilder = new SamplesIndex.Builder(new NetHttpTransport(), new JacksonFactory(), null); samplesService = myBuilder.build(); final AtomicReference<SampleCollection> sampleList = new AtomicReference<SampleCollection>(null); new Task.Modal(null, GctBundle.message("sample.import.title"), false) { @Override public void run(@NotNull ProgressIndicator indicator) { try { sampleList.set(samplesService.list()); } catch (IOException e) { LOG.error("Failed to retrieve sample list", e); Messages.showErrorDialog("Failed to retrieve sample list", "Sample Import"); } } }.queue(); } }
scrollView.scrollIntoView(new UiSelector().text(QUERY_STRING)); selectedLocation = scrollView.getChildByText(new UiSelector() .className(TextView.class.getName()), QUERY_STRING); Assert.assertTrue(selectedLocation.exists()); selectedLocation.clickAndWaitForNewWindow(); // Verify the Query String is present after completing search. UiObject searchTextView = searchUiObject.getChild(new UiSelector() .className(TextView.class.getName())); Assert.assertTrue(searchTextView.getText().contains(QUERY_STRING)); } else { searchEditText = mDevice.findObject(new UiSelector().className(EditText.class.getName())); searchEditText.setText(QUERY_STRING); UiScrollable listViewSelector = new UiScrollable(new UiSelector().className(ListView.class.getName())); selectedLocation = listViewSelector.getChildByText(new UiSelector() .className(TextView.class.getName()), QUERY_STRING); selectedLocation.clickAndWaitForNewWindow(); // Verify the Query String is present after completing search. Assert.assertTrue(searchEditText.getText().contains(QUERY_STRING)); }
private static final String TAG = "CellBroadcastReceiver"; static final boolean DBG = false; public static final String CELLBROADCAST_START_CONFIG_ACTION = "android.cellbroadcastreceiver.START_CONFIG"; private static final String CURRENT_INTERVAL_DEFAULT = "current_interval_default"; public static final String ACTION_MARK_AS_READ = "com.google.android.clockwork.cmas.intent.action.MARK_AS_READ"; public static final String EXTRA_DELIVERY_TIME = "com.google.android.clockwork.cmas.intent.extra.ID"; @Override public void onReceive(Context context, Intent intent) { onReceiveWithPrivilege(context, intent, false); } protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) { if (DBG) { log("onReceive " + intent); } String action = intent.getAction(); final long deliveryTime = intent.getLongExtra(EXTRA_DELIVERY_TIME, -1); if (ACTION_MARK_AS_READ.equals(action)) { new CellBroadcastContentProvider.AsyncCellBroadcastTask(context.getContentResolver()); } }
protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) { if (DBG) log("onReceive " + intent); String action = intent.getAction(); final long deliveryTime = intent.getLongExtra(EXTRA_DELIVERY_TIME, -1); if (ACTION_MARK_AS_READ.equals(action)) { new CellBroadcastContentProvider.AsyncCellBroadcastTask(context.getContentResolver()) .execute(new CellBroadcastContentProvider.CellBroadcastOperation() { @Override public boolean execute(CellBroadcastContentProvider provider) { return provider.markBroadcastRead(CellBroadcasts.DELIVERY_TIME, deliveryTime); } }); } else if (TelephonyIntents.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED.equals(action) || CarrierConfigManager.ACTION_CARRIER_CONFIG_CHANGED.equals(action) || CELLBROADCAST_START_CONFIG_ACTION.equals(action)) { // Todo: Add the service state check once the new get service state API is done. // Do not rely on mServiceState as it gets reset to -1 time to time because // the process of CellBroadcastReceiver gets killed every time once the job is done. } }
protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) { if (DBG) log("onReceive " + intent); String action = intent.getAction(); final long deliveryTime = intent.getLongExtra(EXTRA_DELIVERY_TIME, -1); if (ACTION_MARK_AS_READ.equals(action)) { new CellBroadcastContentProvider.AsyncCellBroadcastTask(context.getContentResolver()) .execute(new CellBroadcastContentProvider.CellBroadcastOperation() { @Override public boolean execute(CellBroadcastContentProvider provider) { return provider.markBroadcastRead(CellBroadcasts.DELIVERY_TIME, deliveryTime); } }); } else if (TelephonyIntents.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED.equals(action) || CarrierConfigManager.ACTION_CARRIER_CONFIG_CHANGED.equals(action) || CELLBROADCAST_START_CONFIG_ACTION.equals(action)) { // Todo: Add the service state check once the new get service state API is done. // Do not rely on mServiceState as it gets reset to -1 time to time because // the process of CellBroadcastReceiver gets killed every time once the job is done. } }
/** Intent action to display alert dialog/notification, after verifying the alert is new. */ static final String SHOW_NEW_ALERT_ACTION = "cellbroadcastreceiver.SHOW_NEW_ALERT"; /** Use the same notification ID for non-emergency alerts. */ static final int NOTIFICATION_ID = 1; /** Sticky broadcast for latest area info broadcast received. */ static final String CB_AREA_INFO_RECEIVED_ACTION = "android.cellbroadcastreceiver.CB_AREA_INFO_RECEIVED"; /** Intent extra for passing an SmsCbMessage */ private static final String EXTRA_MESSAGE = "message"; /** Container for service category, serial number, location, body hash code, and ETWS primary/secondary information for duplication detection. */ private static final class MessageServiceCategoryAndScope { private final int mServiceCategory; private final int mSerialNumber; private final SmsCbLocation mLocation; private final int mBodyHash; private final boolean mIsEtwsPrimary; MessageServiceCategoryAndScope(int serviceCategory, int serialNumber, SmsCbLocation location, int bodyHash, boolean isEtwsPrimary) { mServiceCategory = serviceCategory; mSerialNumber = serialNumber; mLocation = location; mBodyHash = bodyHash; mIsEtwsPrimary = isEtwsPrimary; } }
ArrayList<CellBroadcastMessage> messageList, Context context, boolean fromSaveState) { int channelTitleId = CellBroadcastResources.getDialogTitleResource(context, message); CharSequence channelName = context.getText(channelTitleId); String messageBody = message.getMessageBody(); // Create intent to show the new messages when user selects the notification. Intent intent; if (context.getPackageManager().hasSystemFeature(PackageManager.FEATURE_WATCH)) { intent = createWearDeleteIntent(context, message.getDeliveryTime()); } else { intent = createDisplayMessageIntent(context, CellBroadcastAlertDialog.class, messageList); } intent.putExtra(CellBroadcastAlertDialog.FROM_NOTIFICATION_EXTRA, true); intent.putExtra(CellBroadcastAlertDialog.FROM_SAVE_STATE_NOTIFICATION_EXTRA, fromSaveState); PendingIntent pi; if (context.getPackageManager().hasSystemFeature(PackageManager.FEATURE_WATCH)) { pi = PendingIntent.getBroadcast(context, 0, intent, 0); } else { pi = PendingIntent.getActivity(context, NOTIFICATION_ID, intent, PendingIntent.FLAG_UPDATE_CURRENT); } // Build and show the notification. NotificationCompat.Builder builder = new NotificationCompat.Builder(context) .setSmallIcon(R.drawable.ic_warning) .setContentTitle(channelName) .setContentText(messageBody) .setStyle(new NotificationCompat.BigTextStyle().bigText(messageBody)) .setContentIntent(pi) .setAutoCancel(true) .setPriority(NotificationCompat.PRIORITY_HIGH); NotificationManagerCompat notificationManager = NotificationManagerCompat.from(context); notificationManager.notify(NOTIFICATION_ID, builder.build()); }
static Intent createMarkAsReadIntent(Context context, long deliveryTime) { Intent deleteIntent = new Intent(context, CellBroadcastReceiver.class); deleteIntent.setAction(CellBroadcastReceiver.ACTION_MARK_AS_READ); deleteIntent.putExtra(CellBroadcastReceiver.EXTRA_DELIVERY_TIME, deliveryTime); return deleteIntent; }
/** * @hide */ public class NetdService { private static final String TAG = NetdService.class.getSimpleName(); private static final String NETD_SERVICE_NAME = "netd"; private static final int BASE_TIMEOUT_MS = 100; private static final int MAX_TIMEOUT_MS = 1000; public static INetd getInstance() { final INetd netdInstance = INetd.Stub.asInterface( ServiceManager.getService(NETD_SERVICE_NAME)); if (netdInstance == null) { Log.w(TAG, "WARNING: returning null INetd instance."); } return netdInstance; } }
public static INetd get() { for (int i = 0; ; i++) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } final int timeoutMs = (i < (MAX_TIMEOUT_MS / BASE_TIMEOUT_MS)) ? (i * BASE_TIMEOUT_MS) : MAX_TIMEOUT_MS; try { Thread.sleep(timeoutMs); } catch (InterruptedException e) {} } }
public static INetd get() { int timeoutMs = BASE_TIMEOUT_MS; while (true) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } try { Thread.sleep(timeoutMs); } catch (InterruptedException e) {} timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); } }
void run(INetd netd) throws RemoteException; } /** * Blocks until an INetd instance is availabe, and retries until either * the command succeeds or a ServiceSpecificError is thrown. */
import android.os.RemoteException; import android.os.ServiceSpecificException; public interface INetdRunner { void run(INetd netd) throws RemoteException, ServiceSpecificException; } /** * Blocks until an INetd instance is available, and retries until either * the command succeeds or a ServiceSpecificError is thrown. */ public class NetdRunner implements INetdRunner { @Override public void run(INetd netd) throws RemoteException, ServiceSpecificException { // Implementation goes here } }
public static void run(NetdCommand cmd) { while (true) { try { INetd netd = get(); if (netd == null) { continue; } cmd.run(netd); return; } catch (RemoteException re) { } } }
public static void run(NetdCommand cmd) { while (true) { try { cmd.run(get()); return; } catch (RemoteException re) { logger.error("RemoteException occurred while running command", re); } } }
ResultUnit.BYTE); Stat.StatResult stat = Stat.getStat(mbps); getReportLog().printSummary("write throughput", stat.mAverage, ResultType.HIGHER_BETTER, ResultUnit.MBPS); @TimeoutReq(minutes = 80) public void testSingleSequentialUpdate() throws Exception { final long fileSize = FileUtil.getFileSizeExceedingMemory(getContext(), BUFFER_SIZE); if (fileSize == 0) { // not enough space, give up return; } final int NUMBER_REPETITION = 3; FileUtil.doSequentialUpdateTest(getContext(), DIR_SEQ_UPDATE, getReportLog(), fileSize, BUFFER_SIZE, NUMBER_REPETITION); } @TimeoutReq(minutes = 30) public void testSingleSequentialRead() throws Exception { final long fileSize = FileUtil.getFileSizeExceedingMemory(getContext(), BUFFER_SIZE); if (fileSize == 0) { // not enough space, give up return; } long start = System.currentTimeMillis(); final File file = FileUtil.createNewFilledFile(getContext(), DIR_SEQ_RD, fileSize); long finish = System.currentTimeMillis(); }
private void updateSavedNetworkSelectionStatus() { List<WifiConfiguration> savedNetworks = mWifiConfigManager.getSavedNetworks(); if (savedNetworks.size() == 0) { localLog("No saved networks."); return; } StringBuffer sbuf = new StringBuffer("Saved Networks List: \n"); for (WifiConfiguration network : savedNetworks) { if (network.isPasspoint()) { continue; } WifiConfiguration.NetworkSelectionStatus status = network.getNetworkSelectionStatus(); mWifiConfigManager.tryEnableNetwork(network.networkId); mWifiConfigManager.clearNetworkCandidateScanResult(network.networkId); } }
List<WifiConfiguration> associatedConfigurations = null; WifiConfiguration associatedConfiguration = mWifiConfigManager.getSavedNetworkForScanDetailAndCache(scanDetail); if (associatedConfiguration == null) { continue; } else { associatedConfigurations = new ArrayList<>(Arrays.asList(associatedConfiguration)); } for (WifiConfiguration network : associatedConfigurations) { if (network.isPasspoint()) { continue; } WifiConfiguration.NetworkSelectionStatus status = network.getNetworkSelectionStatus(); status.setSeenInLastQualifiedNetworkSelection(true); if (!status.isNetworkEnabled()) { continue; } else if (network.BSSID != null && !network.BSSID.equals("any") && !network.BSSID.equals(scanResult.BSSID)) { // App has specified the only BSSID to connect for this // configuration. So only the matching ScanResult can be a candidate. } }
protected static final String AM_NO_HOME_SCREEN = "am no-home-screen"; private static final String AM_RESIZE_DOCKED_STACK = "am stack resize-docked-stack "; private static final String AM_MOVE_TASK = "am stack movetask "; private static final String AM_SUPPORTS_SPLIT_SCREEN_MULTIWINDOW = "am supports-split-screen-multiwindow"; private static final String INPUT_KEYEVENT_HOME = "input keyevent 3"; protected ITestDevice mDevice; private HashSet<String> mAvailableFeatures; protected static String getAmStartCmd(final String activityName) { return "am start -n " + getActivityComponentName(activityName); } protected static String getAmStartCmdOverHome(final String activityName) { return "am start --activity-task-on-home -n " + getActivityComponentName(activityName); } static String getActivityComponentName(final String activityName) { return "com.example.package/" + activityName; }
public int startLocalOnlyWifiHotspot(WifiConfiguration cfg) { if (mMode == Mode.LOCAL_HOTSPOT) { if (VDBG) { Log.e(TAG, "Attempt to startLocalOnlyWifiHotspot absent corresponding stop."); } return ConnectivityManager.TETHER_ERROR_SERVICE_UNAVAIL; } mMode = Mode.LOCAL_HOTSPOT; return setWifiTethering(cfg, true); }
public int startLocalOnlyWifiHotspot(WifiConfiguration cfg) { if (mMode == Mode.LOCAL_HOTSPOT) { if (VDBG) { Log.e(TAG, "Local hotspot already started"); } return ConnectivityManager.TETHER_ERROR_SERVICE_UNAVAIL; } mMode = Mode.LOCAL_HOTSPOT; return setWifiTethering(cfg, true); }
public void stopLocalOnlyWifiHotspot() { if (mMode != Mode.LOCAL_HOTSPOT) { Log.e(TAG, "Local hotspot not running. Attempt to stopLocalOnlyWifiHotspot absent corresponding start."); return; } setWifiTethering(null, false); }
protected boolean turnOffMasterTetherSettings() { if (!stopIpServices()) { transitionTo(mStopTetheringErrorState); return false; } if (mMode == Mode.TETHERING) { try { mNMService.setIpForwardingEnabled(false); } catch (Exception e) { transitionTo(mSetIpForwardingDisabledErrorState); return false; } } // Reset to tethering mode (default mode). mMode = Mode.TETHERING; transitionTo(mInitialState); return true; }
import java.util.Random; public class IPv6TetheringCoordinator { private static final String TAG = IPv6TetheringCoordinator.class.getSimpleName(); private static final boolean DBG = false; private static final boolean VDBG = false; private static class Downstream { public final TetherInterfaceStateMachine tism; public final short subnetId; Downstream(TetherInterfaceStateMachine tism, short subnetId) { this.tism = tism; this.subnetId = subnetId; } } private final ArrayList<TetherInterfaceStateMachine> mNotifyList; private final LinkedList<Downstream> mActiveDownstreams; private short mNextSubnetId; private byte[] mUniqueLocalPrefix; private NetworkState mUpstreamNetworkState; public IPv6TetheringCoordinator(ArrayList<TetherInterfaceStateMachine> notifyList) { mNotifyList = notifyList; mActiveDownstreams = new LinkedList<>(); } }
public class IPv6TetheringCoordinator { private static final String TAG = IPv6TetheringCoordinator.class.getSimpleName(); private static final boolean DBG = false; private static final boolean VDBG = false; private final ArrayList<TetherInterfaceStateMachine> mNotifyList; private final LinkedList<TetherInterfaceStateMachine> mActiveDownstreams; private short mNextSubnetId; private byte[] mUniqueLocalPrefix; private NetworkState mUpstreamNetworkState; public IPv6TetheringCoordinator(ArrayList<TetherInterfaceStateMachine> notifyList) { mNotifyList = notifyList; mActiveDownstreams = new LinkedList<>(); mNextSubnetId = 0; } public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { mActiveDownstreams.add(downstream); } } private TetherInterfaceStateMachine findDownstream(TetherInterfaceStateMachine downstream) { for (TetherInterfaceStateMachine stateMachine : mActiveDownstreams) { if (stateMachine.equals(downstream)) { return stateMachine; } } return null; } }
public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { mActiveDownstreams.offer(new DownstreamState(downstream, mNextSubnetId++)); updateIPv6TetheringInterfaces(); } }
private static byte[] generateUniqueLocalPrefix() { final byte[] ulp = new byte[6]; (new Random()).nextBytes(ulp); final byte[] in6addr = Arrays.copyOf(ulp, NetworkConstants.IPV6_ADDR_LEN); in6addr[0] = (byte) 0xfd; return in6addr; }
ActivityReceiverFilter appEndReceiver = new ActivityReceiverFilter(ACTIVITY_EXIT_ACTION); ActivityReceiverFilter timeReceiver = new ActivityReceiverFilter(ACTIVITY_TIME_TRACK_INFO); mContext.startActivity(intent, options.toBundle()); assertEquals(RESULT_PASS, appEndReceiver.waitForActivity()); appEndReceiver.close(); if (!noHomeScreen()) { assertEquals(RESULT_TIMEOUT, timeReceiver.waitForActivity()); assertTrue(timeReceiver.mTimeUsed == 0); } else { assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); } final Intent dummyIntent = new Intent(context, MockApplicationActivity.class); dummyIntent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); final Activity activity = mInstrumentation.startActivitySync(dummyIntent);
private CdmaSubscriptionSourceManager mCdmaSSM; public static final String INVALID_MCC = "000"; public static final String DEFAULT_MNC = "00"; private HbpcdUtils mHbpcdUtils = null; private String mRegistrationDeniedReason; private String mCurrentCarrier = null; private ArrayList<Pair<Integer, Integer>> mEarfcnPairListForRsrpBoost = null; private int mLteRsrpBoost = 0; private final Object mLteRsrpBoostLock = new Object(); public ServiceStateTracker(GsmCdmaPhone phone, CommandsInterface ci) { mPhone = phone; mCi = ci; mRatRatcheter = new RatRatcheter(mPhone); mVoiceCapable = mPhone.getContext().getResources().getBoolean(com.android.internal.R.bool.config_voice_capable); }
private ArrayList<Pair<Integer, Integer>> mEarfcnPairListForRsrpBoost = null; private int mLteRsrpBoost = 0; private final Object mLteRsrpBoostLock = new Object(); public ServiceStateTracker(GsmCdmaPhone phone, CommandsInterface ci) { mPhone = phone; mCi = ci; mRatRatcheter = new RatRatcheter(mPhone); mVoiceCapable = mPhone.getContext().getResources().getBoolean(com.android.internal.R.bool.config_voice_capable); mUiccController = UiccController.getInstance(); mUiccController.registerForIccChanged(this, EVENT_ICC_CHANGED, null); mCi.setOnSignalStrengthUpdate(this, EVENT_SIGNAL_STRENGTH_UPDATE, null); mCi.registerForCellInfoList(this, EVENT_UNSOL_CELL_INFO_LIST, null); mSubscriptionController = SubscriptionController.getInstance(); }
private void updateLteEarfcnBoost(ServiceState serviceState) { int dataRegStateResult = serviceState.getDataRegState(); int newDataRat = serviceState.getDataNetworkType(); if (ServiceState.isLte(dataRegStateResult) && ServiceState.isCdma(newDataRat)) { mCi.getSignalStrength(obtainMessage(EVENT_GET_SIGNAL_STRENGTH)); } mNewSS.setDataRoaming(regCodeIsRoaming(regState)); if (DBG) { log("handlPollStateResultMessage: CdmaLteSST setDataRegState=" + dataRegState + " regState=" + regState + " dataRadioTechnology=" + newDataRat); } updateLteEarfcnBoost(getLteEarfcn(dataRegStateResult)); } private void handlePollStateOperator(String[] opNames) { if (mPhone.isPhoneTypeGsm()) { if (opNames != null && opNames.length >= 3) { String brandOverride = mUiccController.getUiccCard(getPhoneId()) != null ? mUiccController.getUiccCard(getPhoneId()).getOperatorBrandOverride() : null; if (brandOverride != null) { // handle brand override } else { // handle normal operator names } } } else { // handle CDMA operator names } }
private static final int LTE_EARFCN_NOT_FOUND = -1; private void updateLteEarfcnBoost(int lteEarfcn) { synchronized (mLteRsrpBoostLock) { if (lteEarfcn != LTE_EARFCN_NOT_FOUND && containsEarfcnInEarfcnRange(mEarfcnPairListForRsrpBoost, lteEarfcn)) { mNewSS.setLteEarfcnRsrpBoost(mLteRsrpBoost); } else { mNewSS.setLteEarfcnRsrpBoost(0); } } }
public void methodName() { if (condition1 && condition2 && mRingingCall.getState() == ImsPhoneCall.State.IDLE) { mForegroundCall.detach(mPendingMO); removeConnection(mPendingMO); mPendingMO.finalize(); mPendingMO = null; mPhone.initiateSilentRedial(); return; } else { mPendingMO = null; int cause = getDisconnectCauseFromReasonInfo(reasonInfo); ImsPhoneConnection conn = findConnection(imsCall); if (conn != null) { conn.setPreciseDisconnectCause(getPreciseDisconnectCauseFromReasonInfo(reasonInfo)); } processCallStateChange(imsCall, ImsPhoneCall.State.DISCONNECTED, cause); } mMetrics.writeOnImsCallStartFailed(mPhone.getPhoneId(), imsCall.getCallSession(), reasonInfo); }
private int mPreciseDisconnectCause = 0; //***** Event Constants private static final int EVENT_DTMF_DONE = 1; private static final int EVENT_PAUSE_DONE = 2; private static final int EVENT_NEXT_POST_DIAL = 3; private static final int EVENT_WAKE_LOCK_TIMEOUT = 4; private static final int EVENT_DTMF_DELAY_DONE = 5; //***** Constants private static final int PAUSE_DELAY_MILLIS = 3 * 1000; private static final int WAKE_LOCK_TIMEOUT_MILLIS = 60 * 1000; //***** Inner Classes class MyHandler extends Handler { // handler implementation }
public static final int CDMA_PREEMPTED = 1007; public static final int CDMA_NOT_EMERGENCY = 1008; public static final int CDMA_ACCESS_BLOCKED = 1009; public static final int ILLEGAL_ARGUMENT = 1200; public static final int ILLEGAL_STATE = 1201; public static final int INTERNAL_ERROR = 1202; public static final int IMS_SERVICE_DOWN = 1203; public static final int NO_PENDING_CALL = 1204; public static final int POWER_OFF = 1205; public static final int LOW_BATTERY = 1206;
public static final int CDMA_PREEMPTED = 1007; public static final int CDMA_NOT_EMERGENCY = 1008; public static final int CDMA_ACCESS_BLOCKED = 1009; public static final int ILLEGAL_ARGUMENT = 1200; public static final int ILLEGAL_STATE = 1201; public static final int INTERNAL_ERROR = 1202; public static final int IMS_SERVICE_DOWN = 1203; public static final int NO_PENDING_CALL = 1204; public static final int POWER_OFF = 1205; public static final int LOW_BATTERY = 1206;
public static final int CDMA_ACCESS_BLOCKED = 1009; public static final int ILLEGAL_ARGUMENT = 1200; public static final int ILLEGAL_STATE = 1201; public static final int INTERNAL_ERROR = 1202; public static final int IMS_SERVICE_DOWN = 1203; public static final int NO_PENDING_CALL = 1204; public static final int POWER_OFF = 1205; public static final int LOW_BATTERY = 1206; public static final int NETWORK_NO_SERVICE = 1207;
public static final int ILLEGAL_ARGUMENT = 1200; public static final int ILLEGAL_STATE = 1201; public static final int INTERNAL_ERROR = 1202; public static final int IMS_SERVICE_DOWN = 1203; public static final int NO_PENDING_CALL = 1204; public static final int POWER_OFF = 1205; public static final int LOW_BATTERY = 1206; public static final int NETWORK_NO_SERVICE = 1207; public static final int NETWORK_NO_LTE_COVERAGE = 1208; public static final int NETWORK_ROAMING = 1209;
/** Service unavailable; by located in roaming area */ public static final int NETWORK_ROAMING = 1209; /** Service unavailable; by IP changed */ public static final int NETWORK_IP_CHANGED = 1210; /** Service unavailable; other */ public static final int SERVICE_UNAVAILABLE = 1211; /* Service unavailable; IMS connection is lost (IMS is not registered) */ public static final int NOT_REGISTERED = 1212; /** Max call exceeded */ public static final int MAX_LOCAL_CALLS_EXCEEDED = 1213; /** Call decline */ public static final int LOCAL_CALL_DECLINE = 1214; /** SRVCC is in progress */ public static final int VCC_ON_PROGRESSING = 1215; /** Resource reservation is failed (QoS precondition) */ public static final int RESOURCE_RESERVATION_FAILED = 1216; /** Retry CS call; VoLTE service can't be provided by the network or remote end * Resolve the extra code(EXTRA_CODE_CALL_RETRY_*) if the below code is set */
public static INetd get(int maxTimeoutMs) { int timeoutMs = BASE_TIMEOUT_MS; while (true) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } if (maxTimeoutMs == 0) { break; } timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); if (maxTimeoutMs > 0) { timeoutMs = Math.min(timeoutMs, maxTimeoutMs); } try { Thread.sleep(timeoutMs); } catch (InterruptedException e) { // If this occurs we can lose track of some time slept. } if (maxTimeoutMs > 0) { maxTimeoutMs -= timeoutMs; } } return null; }
public static INetd get(int maxTimeoutMs) { int timeoutMs = BASE_TIMEOUT_MS; while (true) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } if (maxTimeoutMs == 0) { break; } timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); if (maxTimeoutMs > 0) { timeoutMs = Math.min(timeoutMs, maxTimeoutMs); } try { Thread.sleep(timeoutMs); } catch (InterruptedException e) { // If this occurs we can lose track of some time slept. } if (maxTimeoutMs > 0) { maxTimeoutMs -= timeoutMs; } } return null; }
public static INetd get(int maxTimeoutMs) { int timeoutMs = BASE_TIMEOUT_MS; while (true) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } if (maxTimeoutMs == 0) { break; } // No netdInstance was received; sleep and retry. timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); if (maxTimeoutMs > 0) { timeoutMs = Math.min(timeoutMs, maxTimeoutMs); } try { Thread.sleep(timeoutMs); } catch (InterruptedException e) { // If this occurs we can lose track of some time slept. } if (maxTimeoutMs > 0) { maxTimeoutMs -= timeoutMs; } } return null; }
public static void run(NetdCommand cmd) { while (true) { try { cmd.run(get()); return; } catch (RemoteException re) { Log.e(TAG, "Error communicating with netd: " + re); } } }
private AuthenticatorHelper mAuthenticatorHelper; private BluetoothAdapter mBtAdapter; private ConnectivityListener mConnectivityListener; private boolean mInputSettingNeeded; private Preference mDeveloperPref; private PreferenceGroup mAccessoriesGroup; private PreferenceGroup mAccountsGroup; private Preference mAddAccessory; private Preference mNetworkPref; private Preference mSoundsPref; private final BroadcastReceiver mBCMReceiver = new BroadcastReceiver() { @Override public void onReceive(Context context, Intent intent) { updateAccessories(); } }; private final BroadcastReceiver mBtConnectionReceiver = new BluetoothConnectionsManager(); public static MainFragment newInstance() { return new MainFragment(); } @Override public void onCreate(Bundle savedInstanceState) { mAuthenticatorHelper = new AuthenticatorHelper(getContext(), new UserHandle(UserHandle.myUserId()), new AuthenticatorHelper.OnAccountsUpdateListener() { @Override public void onAccountsUpdate(UserHandle userHandle) { updateAccounts(); } }); mBtAdapter = BluetoothAdapter.getDefaultAdapter(); mConnectivityListener = new ConnectivityListener(getContext(), new ConnectivityListener.Listener() { @Override public void onConnectivityChanged(boolean isConnected) { updateConnectivity(isConnected); } }); mInputSettingNeeded = false; mDeveloperPref = findPreference(KEY_DEVELOPER_OPTIONS); mAccessoriesGroup = (PreferenceGroup) findPreference(KEY_ACCESSORIES); mAccountsGroup = (PreferenceGroup) findPreference(KEY_ACCOUNTS); mAddAccessory = findPreference(KEY_ADD_ACCESSORY); mNetworkPref = findPreference(KEY_NETWORK); mSoundsPref = findPreference(KEY_SOUNDS); } @Override public void onResume() { super.onResume(); getActivity().registerReceiver(mBCMReceiver, new IntentFilter(BluetoothManager.ACTION_CONNECTION_STATE_CHANGED)); getActivity().registerReceiver(mBtConnectionReceiver, new IntentFilter(BluetoothAdapter.ACTION_CONNECTION_STATE_CHANGED)); mConnectivityListener.startListening(); updateAccessories(); updateAccounts(); updateConnectivity(mConnectivityListener.isConnected()); } @Override public void onPause() { super.onPause(); getActivity().unregisterReceiver(mBCMReceiver); getActivity().unregisterReceiver(mBtConnectionReceiver); mConnectivityListener.stopListening(); } private void updateAccessories() { // Update accessories list } private void updateAccounts() { // Update accounts list } private void updateConnectivity(boolean isConnected) { // Update connectivity status
public void onStart() { super.onStart(); mAuthenticatorHelper.listenToAccountUpdates(); IntentFilter btChangeFilter = new IntentFilter(); btChangeFilter.addAction(BluetoothDevice.ACTION_ACL_CONNECTED); btChangeFilter.addAction(BluetoothDevice.ACTION_ACL_DISCONNECTED); btChangeFilter.addAction(BluetoothAdapter.ACTION_STATE_CHANGED); getContext().registerReceiver(mBBCMReceiver, btChangeFilter); }
List<X509Certificate> certPathList) throws GeneralSecurityException { if (debug != null) { debug.println("ForwardBuilder.verifyCert(SN: " + Debug.toHexString(cert.getSerialNumber()) + "\n Issuer: " + cert.getIssuerX500Principal() + ")" + "\n Subject: " + cert.getSubjectX500Principal() + ")"); } ForwardState currState = (ForwardState) currentState; currState.untrustedChecker.check(cert, Collections.<String>emptySet()); if (certPathList != null) { for (X509Certificate cpListCert : certPathList) { if (cert.equals(cpListCert)) { if (debug != null) { debug.println("loop detected!!"); } throw new CertPathValidatorException("loop detected"); } } } // rest of the code }
public void testScreenLayout() throws Exception { int expectedScreenLayout = computeScreenLayout(); int expectedSize = expectedScreenLayout & Configuration.SCREENLAYOUT_SIZE_MASK; int expectedLong = expectedScreenLayout & Configuration.SCREENLAYOUT_LONG_MASK; // Check that all four orientations report the same configuration value. for (int i = 0; i < ORIENTATIONS.length; i++) { Activity activity = startOrientationActivity(ORIENTATIONS[i]); if (activity.isInMultiWindowMode()) { // activity.setRequestedOrientation has no effect in multiwindow mode. teardown(); return; } Configuration mConfig = activity.getResources().getConfiguration(); int actualSize = mConfig.screenLayout & Configuration.SCREENLAYOUT_SIZE_MASK; int actualLong = mConfig.screenLayout & Configuration.SCREENLAYOUT_LONG_MASK; assertEquals("Expected screen size value of " + expectedSize + " but got " + actualSize + " for orientation " + ORIENTATIONS[i], expectedSize, actualSize); assertEquals("Expected screen long value of " + expectedLong + " but got " + actualLong, expectedLong, actualLong); } assertNoErrors(); }
public void testCompare() { assertTrue(PhoneNumberUtils.compare(null, null)); assertTrue(PhoneNumberUtils.compare("2023458246", "2023458246")); assertFalse(PhoneNumberUtils.compare("2023458246", "6503458246")); assertTrue(PhoneNumberUtils.compare("2023458246", "202-345-8246")); assertTrue(PhoneNumberUtils.compare("2023458246", "+12023458246")); assertTrue(PhoneNumberUtils.compare("2023458246", "+812023458246")); assertTrue(PhoneNumberUtils.compare("2023458246", "+1(202)345-8246")); }
public void testFormatNumberToE164() { assertNull(PhoneNumberUtils.formatNumber("invalid#", "US")); assertEquals("+12023458246", PhoneNumberUtils.formatNumberToE164("(202)345-8246", "US")); assertEquals("+812023458246", PhoneNumberUtils.formatNumberToE164("202-345-8246", "JP")); assertEquals("+18004664114", PhoneNumberUtils.formatNumberToE164("800-GOOG-114", "US")); }
int connectionState = mStateMachine.getConnectionState(device); if (connectionState != BluetoothProfile.STATE_CONNECTED && connectionState != BluetoothProfile.STATE_CONNECTING) { return false; } mStateMachine.sendMessage(HeadsetStateMachine.DISCONNECT, device); return true; } public List<BluetoothDevice> getConnectedDevices() { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getConnectedDevices(); } public BluetoothDevice getCurrentDevice() { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getCurrentDevice(); } private List<BluetoothDevice> getDevicesMatchingConnectionStates(int[] states) { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getDevicesMatchingConnectionStates(states); } public int getConnectionState(BluetoothDevice device) { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getConnectionState(device); } public boolean setPriority(BluetoothDevice device, int priority) { enforceCallingOrSelfPermission(BLUETOOTH_ADMIN_PERM, "Need BLUETOOTH_ADMIN permission"); Settings.Global.putInt(getContentResolver(),
private void processSlcConnected(BluetoothDevice device) { if (mPhoneProxy != null) { try { mPhoneProxy.queryPhoneState(); } catch (RemoteException e) { Log.e(TAG, Log.getStackTraceString(new Throwable())); } } else { Log.e(TAG, "Handsfree phone proxy null for query phone state"); } }
} return BluetoothProfile.STATE_DISCONNECTED; } else { Log.e(TAG, "Bad currentState: " + currentState); return BluetoothProfile.STATE_DISCONNECTED; } } List<BluetoothDevice> getConnectedDevices() { List<BluetoothDevice> devices = new ArrayList<BluetoothDevice>(); synchronized (this) { for (int i = 0; i < mConnectedDevicesList.size(); i++) devices.add(mConnectedDevicesList.get(i)); } return devices; } BluetoothDevice getCurrentDevice() { return mCurrentDevice; } boolean isAudioOn() { return (getCurrentState() == mAudioOn); } boolean isAudioConnected(BluetoothDevice device) { synchronized (this) { /* Additional check for audio state included for the case when PhoneApp queries Bluetooth Audio state, before we receive the close event from the stack for the sco disconnect issued in AudioOn state. This was causing a mismatch in the Incall screen UI. */ if (getCurrentState() == mAudioOn && mCurrentDevice.equals(device)
public void exit() { mWifiConfigManager.loadFromStore(); // Enable this network and disable other networks }
public void exit() { mWifiConfigManager.loadFromStore(); // transition to exit state }
protected boolean hasLog(String str) throws DeviceNotAvailableException { String logs = getDevice().executeAdbCommand("logcat", "-v", "brief", "-d", mService + ":I", "*:S"); return logs.contains(str); } private void clearLogcat() throws DeviceNotAvailableException { getDevice().executeAdbCommand("logcat", "-c"); } protected boolean supportedHardware() throws DeviceNotAvailableException { String features = getDevice().executeShellCommand("pm list features"); return !features.contains("android.hardware.type.television") && !features.contains("android.hardware.type.watch"); }
HandlerThread thread = new HandlerThread("BluetoothAdvertiseManager"); thread.start(); mHandler = new Handler(thread.getLooper()); void cleanup() { logd("cleanup()"); cleanupNative(); mAdvertisers.clear(); sTempRegistrationId = -1; if (mHandler != null) { // Shut down the thread mHandler.removeCallbacksAndMessages(null); Looper looper = mHandler.getLooper(); if (looper != null) { looper.quit(); } mHandler = null; } } class AdvertiserBag { /* When id is negative, the registration is ongoing. When the registration finishes, id * becomes equal to advertiser_id */ public Integer id; public AdvertisingSetDeathRecipient deathRecipient; public IAdvertisingSetCallback callback; AdvertiserBag(Integer id, AdvertisingSetDeathRecipient deathRecipient, IAdvertisingSetCallback callback) { this.id = id; this.deathRecipient = deathRecipient; this.callback = callback; } } IBinder toBinder(IAdvertisingSetCallback e) { return ((IInterface) e).asBinder(); } class AdvertisingSetDeathRecipient implements IBinder.DeathRecipient { // Implementation details }
import android.os.ParcelFileDescriptor; import android.os.Process; import android.os.SystemClock; import android.telecom.PhoneAccount; import android.telecom.PhoneAccountHandle; import android.telecom.TelecomManager; import junit.framework.TestCase; import java.io.BufferedReader; import java.io.FileInputStream; import java.io.InputStream; import java.io.InputStreamReader; import java.nio.charset.StandardCharsets; import java.util.ArrayList; import java.util.Optional; import java.util.concurrent.CountDownLatch; import java.util.concurrent.TimeUnit; import java.util.function.Predicate; import java.util.stream.Collectors; public class TestUtils { static final String TAG = "TelecomCTSTests"; static final boolean HAS_TELECOM = Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP; static final long WAIT_FOR_STATE_CHANGE_TIMEOUT_MS = 10000; static final long WAIT_FOR_CALL_ADDED_TIMEOUT_S = 15; static final long WAIT_FOR_STATE_CHANGE_TIMEOUT_CALLBACK = 50; // Non-final to allow modification by tests not in this package (e.g. permission-related // tests in the Telecom2 test package. }
private int getEffectiveLimit(Predicate<ChangeData> p) { List<Integer> possibleLimits = new ArrayList<>(4); possibleLimits.add(getBackendSupportedLimit()); possibleLimits.add(getPermittedLimit()); if (limitFromCaller > 0) { possibleLimits.add(limitFromCaller); } Integer limitFromPredicate = LimitPredicate.getLimit(FIELD_LIMIT, p); if (limitFromPredicate != null) { possibleLimits.add(limitFromPredicate); } return Ordering.natural().min(possibleLimits); } public int chooseRunningDeviceStep(String[] deviceNames) { JRadioButtonFixture chooseRunningDeviceRadioButton = new JRadioButtonFixture(robot, findRadioButtonByText("Choose a running device")); chooseRunningDeviceRadioButton.requireEnabled(); chooseRunningDeviceRadioButton.requireVisible(); chooseRunningDeviceRadioButton.click(); JBTable deviceTable = robot.finder().findByType(target, JBTable.class); assertNotNull(deviceTable); JTableFixture deviceTableFixture = new JTableFixture(robot, deviceTable); int deviceColumnIndex = deviceTable.getColumn("Device").getModelIndex(); int compatibleColumnIndex = deviceTable.getColumn("Compatible").getModelIndex(); ArrayList<Integer> rowsToSelect = new ArrayList<Integer>(deviceTable.getRowCount()); HashSet<String> deviceNameHashes = new HashSet<String>(Arrays.asList(deviceNames)); for (int i = 0; i < deviceTable.getRowCount(); ++i) { IDevice device = (IDevice)deviceTable.getModel().getValueAt(i, deviceColumnIndex); ThreeState launchCompatibility = ((LaunchCompatibility)deviceTable.getModel().getValueAt(i, compatibleColumnIndex)).isCompatible(); } public static void findAndSetPlatformSources(@NotNull IAndroidTarget target, @NotNull SdkModificator sdkModificator) { File sources = findPlatformSources(target); if (sources != null) { VirtualFile virtualFile = VfsUtil.findFileByIoFile(sources, true); if (virtualFile != null) { for (VirtualFile file : sdkModificator.getRoots(OrderRootType.SOURCES)) { if (file.equals(virtualFile)) { return; } } } } } // Avoid unnecessary work on spurious updates. if (Objects.equals(mLastIPv6LinkProperties, v6only)) { return; } RaParams params = null; if (v6only
public static final int IPV6_HEADER_LEN = 40; public static final int IPV6_PROTOCOL_OFFSET = 6; public static final int IPV6_SRC_ADDR_OFFSET = 8; public static final int IPV6_DST_ADDR_OFFSET = 24; public static final int IPV6_ADDR_LEN = 16; public static final int RFC7421_PREFIX_LENGTH = 64; public static final int ICMPV6_HEADER_MIN_LEN = 4; public static final int ICMPV6_ROUTER_SOLICITATION = 133; public static final int ICMPV6_ROUTER_ADVERTISEMENT = 134; public static final int ICMPV6_NEIGHBOR_SOLICITATION = 135; public static final int ICMPV6_NEIGHBOR_ADVERTISEMENT = 136; public static final int ICMPV6_ND_OPTION_MIN_LENGTH = 8;
private boolean startIPv6() { try { enableInterfaceIpv6PrivacyExtensions(); setInterfaceIpv6RaRtInfoMaxPlen(NetworkConstants.RFC7421_IPV6_PREFIX_LENGTH); mNwService.enableIpv6(mInterfaceName); } catch (IllegalStateException | RemoteException | ServiceSpecificException e) { logError("Unable to change interface settings: %s", e); return false; } return true; }
package com.android.server.connectivity.tethering; import android.net.INetd; import android.net.IpPrefix; import android.net.LinkAddress; import android.net.LinkProperties; import android.net.NetworkCapabilities; import android.net.NetworkState; import android.net.RouteInfo; import android.net.ip.RouterAdvertisementDaemon; import android.net.ip.RouterAdvertisementDaemon.RaParams; import android.net.util.NetdService; import static android.net.util.NetworkConstants.RFC7421_PREFIX_LENGTH; import android.os.INetworkManagementService; import android.os.ServiceSpecificException; import android.os.RemoteException; import android.util.Log; import android.util.Slog; import java.net.Inet6Address; import java.net.InetAddress; import java.net.NetworkInterface; import java.net.SocketException; import java.net.UnknownHostException; import java.util.ArrayList; import java.util.HashSet; import java.util.Objects; /** * @hide */ public class IPv6TetheringInterfaceServices { private static final String TAG = IPv6TetheringInterfaceServices.class.getSimpleName(); }
import android.net.apf.ApfFilter; import android.net.DhcpResults; import android.net.INetd; import android.net.InterfaceConfiguration; import android.net.LinkAddress; import android.net.LinkProperties; import android.net.LinkProperties.ProvisioningChange; import android.net.ProxyInfo; import android.net.RouteInfo; import android.net.StaticIpConfiguration; import android.net.dhcp.DhcpClient; import android.net.metrics.IpConnectivityLog; import android.net.metrics.IpManagerEvent; import android.net.util.MultinetworkPolicyTracker; import android.net.util.NetdService; import static android.net.util.NetworkConstants.RFC7421_PREFIX_LENGTH; import android.os.INetworkManagementService; import android.os.Message; import android.os.RemoteException; import android.os.ServiceManager; import android.os.ServiceSpecificException; import android.os.SystemClock; import android.system.OsConstants; import android.text.TextUtils; import android.util.LocalLog; import android.util.Log; import android.util.SparseArray; import com.android.internal.annotations.VisibleForTesting; import com.android.internal.util.IndentingPrintWriter; import com.android.internal.util.IState; import com.android.internal.util.State; import com.android.internal.util.StateMachine; import com.android.server.net.NetlinkTracker; import java.io.FileDescriptor;
protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); final int dialogType = getIntent().getIntExtra(DIALOG_TYPE_KEY, INVALID_PICK); switch (dialogType) { case DATA_PICK: case CALLS_PICK: case SMS_PICK: createDialog(this, dialogType).show(); break; case PREFERRED_PICK: displayPreferredDialog(getIntent().getIntExtra(PREFERRED_SIM, 0)); break; default: throw new IllegalArgumentException("Invalid dialog type " + dialogType + " sent."); } }
{"12345", "12345", "12345"}, {"12345", "67890", "67890"}, {"12345*00000", "12345", "12345*00000"}, {"12345*00000", "67890", "67890"}, {"12345*00000", "12345*00000", "12345*00000"}, {"12345;11111*00000", "12345", "12345"}, {"12345*00000;11111", "12345", "12345*00000"}, {"18412345*00000", "18412345", "18412345*00000"}, {"+8112345*00000", "+8112345", "+8112345*00000"}}; for (String[] testAddress : testAddressMappingSet) { mConnectionUT = new ImsPhoneConnection(mImsPhone, testAddress[0], mImsCT, mForeGroundCall, false); doReturn(testAddress[1]).when(mImsCallProfile).getCallExtra(eq(ImsCallProfile.EXTRA_OI)); mConnectionUT.updateAddressDisplay(mImsCall); assertEquals(testAddress[2], mConnectionUT.getAddress()); }
public static final int PROPERTY_IS_DOWNGRADED_CONFERENCE = 1<<6; public static final int PROPERTY_SELF_MANAGED = 1<<7; public static final int PROPERTY_IS_RTT = 1 << 8; public static final String EXTRA_LAST_FORWARDED_NUMBER = "android.telecom.extra.LAST_FORWARDED_NUMBER";
private static final int STACK_EVENT = 101; private static final int DIALING_OUT_TIMEOUT = 102; private static final int START_VR_TIMEOUT = 103; private static final int CLCC_RSP_TIMEOUT = 104; private static final int CONNECT_TIMEOUT = 201; private static final int DIALING_OUT_TIMEOUT_VALUE = 10000; private static final int START_VR_TIMEOUT_VALUE = 5000; private static final int CLCC_RSP_TIMEOUT_VALUE = 5000; private int max_hf_connections = 1; private static final int NBS_CODEC = 1; private static final int WBS_CODEC = 2; private static final Map<String, Integer> VENDOR_SPECIFIC_AT_COMMAND_COMPANY_ID; private HashMap<BluetoothDevice, HashMap> mHeadsetAudioParam = new HashMap<BluetoothDevice, HashMap>(); private HashMap<BluetoothDevice, Integer> mHeadsetBrsf = new HashMap<BluetoothDevice, Integer>();
import android.preference.PreferenceManager; import android.provider.Telephony; import android.provider.Telephony.CellBroadcasts; import android.telephony.CarrierConfigManager; import android.telephony.cdma.CdmaSmsCbProgramData; import android.util.Log; import com.android.internal.telephony.TelephonyIntents; import com.android.internal.telephony.cdma.sms.SmsEnvelope; public class CellBroadcastReceiver extends BroadcastReceiver { private static final String TAG = "CellBroadcastReceiver"; static final boolean DBG = false; // STOPSHIP: change to false before ship public static final String CELLBROADCAST_START_CONFIG_ACTION = "com.android.cellbroadcastreceiver.START_CONFIG"; private static final String CURRENT_INTERVAL_DEFAULT = "current_interval_default"; public static final String ACTION_MARK_AS_READ = "com.android.cellbroadcastreceiver.intent.action.MARK_AS_READ"; public static final String EXTRA_DELIVERY_TIME = "com.android.cellbroadcastreceiver.intent.extra.ID"; @Override public void onReceive(Context context, Intent intent) { onReceiveWithPrivilege(context, intent, false); } protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) { // Implementation } }
public boolean processMessage(Message message) { logStateAndMessage(message, this); switch (message.what) { case WifiMonitor.WPS_SUCCESS_EVENT: // Ignore intermediate success, wait for full connection break; case WifiMonitor.NETWORK_CONNECTION_EVENT: if (loadNetworksFromSupplicantAfterWps()) { replyToMessage(mSourceMessage, WifiManager.WPS_COMPLETED); mWifiConnectivityManager.forceConnectivityScan(); } else { replyToMessage(mSourceMessage, WifiManager.WPS_FAILED, WifiManager.ERROR); } mSourceMessage.recycle(); mSourceMessage = null; deferMessage(message); transitionTo(mDisconnectedState); break; case WifiMonitor.WPS_OVERLAP_EVENT: replyToMessage(mSourceMessage, WifiManager.WPS_FAILED, WifiManager.WPS_OVERLAP_ERROR); mSourceMessage.recycle(); mSourceMessage = null; transitionTo(mDisconnectedState); break; case WifiMonitor.WPS_FAIL_EVENT: // Arg1 has the reason for the failure if ((message.arg1 != WifiManager.ERROR) || (message.arg2 != 0)) { replyToMessage(mSourceMessage, WifiManager.WPS_FAILED, message.arg1); } mSourceMessage.recycle(); mSourceMessage = null; transitionTo(mDisconnectedState); break; } }
public boolean connect(Call call) { if (mIsConnected) { Log.addEvent(call, LogUtils.Events.INFO, "Already connected, ignoring request."); return true; } if (call.isSelfManaged() && !mInCallServiceInfo.isSelfManagedCallsSupported()) { return false; } Intent intent = new Intent(InCallService.SERVICE_INTERFACE); intent.setComponent(mInCallServiceInfo.getComponentName()); if (call != null && !call.isIncoming() && !call.isExternalCall()) { intent.putExtra(TelecomManager.EXTRA_OUTGOING_CALL_EXTRAS, call.getIntentExtras()); intent.putExtra(TelecomManager.EXTRA_PHONE_ACCOUNT_HANDLE, call.getTargetPhoneAccount()); } Log.i(this, "Attempting to bind to InCall %s, with %s", mInCallServiceInfo, intent); mIsConnected = true; if (!mContext.bindServiceAsUser(intent, mServiceConnection, Context.BIND_AUTO_CREATE | Context.BIND_FOREGROUND_SERVICE, UserHandle.CURRENT)) { Log.w(this, "Failed to connect."); mIsConnected = false; } return mIsConnected; }
public CallerInfoAsyncQuery startQuery(int token, Context context, String number, CallerInfoAsyncQuery.OnQueryCompleteListener listener, Object cookie) { Log.i(TelecomSystem.getInstance(), "CallerInfoAsyncQuery.startQuery number=%s cookie=%s", Log.pii(number), cookie); return CallerInfoAsyncQuery.startQuery(token, context, number, listener, cookie); }
public class IncomingCallNotifier extends CallsManagerListenerBase { public interface IncomingCallNotifierFactory { IncomingCallNotifier make(Context context, CallsManagerProxy mCallsManagerProxy); } public interface CallsManagerProxy { boolean hasCallsForOtherPhoneAccount(PhoneAccountHandle phoneAccountHandle); } private static final int NOTIFICATION_INCOMING_CALL = 2; public final Call.ListenerBase mCallListener = new Call.ListenerBase() { @Override public void onCallerInfoChanged(Call call) { if (mIncomingCall != call) { return; } showIncomingCallNotification(mIncomingCall); } }; private final Context mContext; private final NotificationManager mNotificationManager; private final Set<Call> mCalls = new ArraySet<>(); private CallsManagerProxy mCallsManagerProxy; private Call mIncomingCall; public IncomingCallNotifier(Context context) { mContext = context; mNotificationManager = (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE); } public void setCallsManagerProxy(CallsManagerProxy callsManagerProxy) { mCallsManagerProxy = callsManagerProxy; } public void onIncomingCall(Call call) { mCalls.add(call); if (mIncomingCall == null) { mIncomingCall = call; call.addListener(mCallListener); showIncomingCallNotification(call); } } public void onCallRemoved(Call call) { mCalls.remove(call); if (mIncomingCall == call) { mIncomingCall.removeListener(mCallListener); mIncomingCall = null; mNotificationManager.cancel(NOTIFICATION_INCOMING_CALL); if (!mCalls.isEmpty()) { Call nextCall = mCalls.iterator().next(); mIncomingCall = nextCall; nextCall.addListener(mCallListener); showIncomingCallNotification(nextCall); } } } private void showIncomingCallNotification(Call call) { // Show the incoming call notification } }
public boolean isConnected() { return sc.isConnected(); } public boolean isBound() { return sc.localAddress() != null; } public boolean isClosed() { return !sc.isOpen(); } public boolean isInputShutdown() { return !sc.isInputOpen(); } public boolean isOutputShutdown() { return !sc.isOutputOpen(); } @Override public FileDescriptor getFileDescriptor$() { return sc.getFD(); }
package libcore.java.nio.file.spi; import org.junit.Test; import java.nio.file.Paths; import java.nio.file.spi.FileTypeDetector; import static org.junit.Assert.assertEquals; public class FileTypeDetectorTest { @Test public void test_probeFileType() throws Exception { FileTypeDetector defaultFileTypeDetector = sun.nio.fs.DefaultFileTypeDetector.create(); assertEquals("text/plain", defaultFileTypeDetector.probeContentType(Paths.get("file.txt"))); assertEquals("text/x-java", defaultFileTypeDetector.probeContentType(Paths.get("file.java"))); } }
import java.io.FileOutputStream; import java.io.FilenameFilter; import java.io.IOException; import java.io.PrintWriter; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.List; /** * CarrierConfigLoader binds to privileged carrier apps to fetch carrier config overlays. */ public class CarrierConfigLoader extends ICarrierConfigLoader.Stub { private static final String LOG_TAG = "CarrierConfigLoader"; private final String mCarrierConfigPackage; private static CarrierConfigLoader sInstance; private Context mContext; private PersistableBundle[] mConfigFromDefaultApp; private PersistableBundle[] mConfigFromCarrierApp; private CarrierServiceConnection[] mServiceConnection; public CarrierConfigLoader(String carrierConfigPackage) { mCarrierConfigPackage = carrierConfigPackage; } public static CarrierConfigLoader getInstance() { if (sInstance == null) { sInstance = new CarrierConfigLoader("default"); } return sInstance; } public void setContext(Context context) { mContext = context; } public void loadConfigs() { // Load carrier configs from default app mConfigFromDefaultApp = loadConfigsFromDefaultApp(); // Load carrier configs from privileged carrier config app mConfigFromCarrierApp = loadConfigsFromCarrierApp(); } private PersistableBundle[] loadConfigsFromDefaultApp() { // Implementation here } private PersistableBundle[] loadConfigsFromCarrierApp() { // Implementation here } // Other methods and classes }
enforceTetherAccessPermission(); return mTethering.getTetheredIfaces(); } @Override public String[] getTetheringErroredIfaces() { enforceTetherAccessPermission(); return mTethering.getErroredIfaces(); } @Override public String[] getTetheredDhcpRanges() { enforceConnectivityInternalPermission(); return mTethering.getTetheredDhcpRanges(); } @Override public boolean isTetheringSupported() { enforceTetherAccessPermission(); int defaultVal = (SystemProperties.get("ro.tether.denied").equals("true") ? 0 : 1); boolean tetherEnabledInSettings = (Settings.Global.getInt(mContext.getContentResolver(), Settings.Global.TETHER_SUPPORTED, defaultVal) != 0) && !mUserManager.hasUserRestriction(UserManager.DISALLOW_CONFIG_TETHERING); return tetherEnabledInSettings && mUserManager.isAdminUser() && mTethering.hasTetherableConfiguration(); } @Override public void startTethering(int type, ResultReceiver receiver, boolean showProvisioningUi) {
private boolean updateBssidBlacklist(String bssid, boolean enable, int reasonCode) { if (enable) { return mBssidBlacklist.remove(bssid) != null; } else { BssidBlacklistStatus status = mBssidBlacklist.get(bssid); if (status == null) { // First time for this BSSID status = new BssidBlacklistStatus(); mBssidBlacklist.put(bssid, status); } status.blacklistedTimeStamp = mClock.getElapsedSinceBootMillis(); status.counter++; if (!status.isBlacklisted) { if (status.counter >= BSSID_BLACKLIST_THRESHOLD || reasonCode == REASON_CODE_AP_UNABLE_TO_HANDLE_NEW_STA) { status.isBlacklisted = true; return true; } } return false; } }
when(mClock.getElapsedSinceBootMillis()).thenReturn(SystemClock.elapsedRealtime() + WifiConnectivityManager.BSSID_BLACKLIST_EXPIRE_TIME_MS); mWifiConnectivityManager.forceConnectivityScan(); assertFalse(mWifiConnectivityManager.isBssidDisabled(bssid)); } /** * When WifiConnectivityManager is on and Wifi client mode is enabled, framework * queries firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability. * * Expected behavior: WifiConnectivityManager#setWifiEnabled calls into * WifiConnectivityHelper#getFirmwareRoamingInfo */ @Test public void verifyGetFirmwareRoamingInfoIsCalledWhenEnableWiFiAndWcmOn() { reset(mWifiConnectivityHelper); // WifiConnectivityManager is on by default mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper).getFirmwareRoamingInfo(); } /** * When WifiConnectivityManager is off, verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode. * * Expected behavior: WifiConnectivityManager#setWifiEnabled does not call into * WifiConnectivityHelper#getFirmwareRoamingIinfo */ @Test public void verifyGetFirmwareRoamingInfoIsNotCalledWhenEnableWiFiAndWcmOff() { reset(mWifiConnectivityHelper); mWifiConnectivityManager.setWifiEnabled(false); verify(mWifiConnectivityHelper, never()).getFirmwareRoamingInfo(); }
reset(mWifiConnectivityHelper); mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper).getFirmwareRoamingInfo(); } /** * When WifiConnectivityManager is off, verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode. * * Expected behavior: WifiConnectivityManager#setWifiEnabled does not call into * WifiConnectivityHelper#getFirmwareRoamingInfo */ @Test public void verifyGetFirmwareRoamingInfoIsNotCalledWhenEnableWiFiAndWcmOff() { reset(mWifiConnectivityHelper); mWifiConnectivityManager.enable(false); mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper, times(0)).getFirmwareRoamingInfo(); } /* * Firmware supports controlled roaming. * Connect to a network from the DISCONNECTED state. * * Expected behavior: WifiConnectivityManager calls * WifiStateMachine.startConnectToNetwork() with the * expected candidate network ID, and the BSSID value should be * 'any' since firmware controls the roaming. */ @Test
public void useAnyBssidForConnectionIfFirmwareControlsRoaming() { when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); mWifiConnectivityManager.handleScreenStateChanged(true); mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork(CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY); }
public void noFrameworkRoamingIfConnectedAndFirmwareRoamingSupported() { WifiConfiguration currentNetwork = generateWifiConfig(0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null); when(mWifiConfigManager.getConfiguredNetwork(anyInt())).thenReturn(currentNetwork); when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_CONNECTED); mWifiConnectivityManager.handleScreenStateChanged(true); verify(mWifiStateMachine, times(0)).startRoamToNetwork(anyInt(), anyObject()); }
private void refreshBssidBlacklist() { boolean updated = false; Iterator<BssidBlacklistStatus> iter = mBssidBlacklist.values().iterator(); Long currentTimeStamp = mClock.getElapsedSinceBootMillis(); while (iter.hasNext()) { BssidBlacklistStatus status = iter.next(); if (status.isBlacklisted && ((currentTimeStamp - status.blacklistedTimeStamp) >= BSSID_BLACKLIST_EXPIRE_TIME_MS)) { iter.remove(); updated = true; } } if (updated && mConnectivityHelper.isFirmwareRoamingSupported()) { updateFirmwareBssidBlacklist(); } }
// network(same SSID & security type) as the currently connected one. // This might save a disconnection triggered by network switch when // the score of the currently connected BSSID is lower than a network // with a different SSID, but within the currently connected network // there is a BSSID better than the currently connected BSSID. // This is under the assumption that firmware will roam the device // to that better BSSID. score += mSameBssidAward; sbuf.append(" Firmware roaming same BSSID bonus: ").append(mSameBssidAward).append(","); // When firmware roaming is supported, the same BSSID award is already // applied above, skip it. if (!mConnectivityHelper.isFirmwareRoamingSupported()) { // Same BSSID award. if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward).append(","); } } // Security award.
static boolean matchOnSP(String xmlSP, CarrierIdentifier id) { boolean matchFound = false; String currentSP = id.getSpn(); if (SPN_EMPTY_MATCH.equalsIgnoreCase(xmlSP)) { if (TextUtils.isEmpty(currentSP)) { matchFound = true; } } else if (currentSP != null) { Pattern spPattern = Pattern.compile(xmlSP); Matcher matcher = spPattern.matcher(currentSP); matchFound = matcher.matches(); } return matchFound; } public void run() { return this.editingContextAdapter.performModelChange(() -> { String actionExpression = action.getActionExpression(); EAttribute eAttribute = EefPackage.Literals.EEF_TOOLBAR_ACTION__ACTION_EXPRESSION; Map<String, Object> variables = new HashMap<String, Object>(); variables.putAll(EEFGroupController.this.variableManager.getVariables()); EvalFactory.of(EEFGroupController.this.interpreter, variables).logIfBlank(eAttribute).call(actionExpression); }); } package org.midonet.cluster.services.discovery; import com.fasterxml.jackson.annotation.JsonRootName; /** * Test class for service discovery details in java. * Java descriptions require, at least, the @JsonRootName annotation, * and a default constructor without parameters. * Methods 'equals' and 'hashCode' must be overwritten. */ @JsonRootName("details") public class TestJavaServiceDetails { private String description = ""; public TestJavaServiceDetails(String desc) { description = (desc == null)? "" : desc; } public TestJavaServiceDetails() { this(""); } public void setDescription(String desc) { description = (desc == null)? "" : desc; } // Methods 'equals' and 'hashCode' should be added here } data[0] = new StructCapUserData(data[0].effective, data[0].permitted, data[0].permitted); data[1] = new StructCapUserData(data[1].effective, data[1].permitted, data[1].permitted); Os.capset(header, data); for (int i = 0; i < 64; i++) { int dataIndex = i / 32; int bitShift = i % 32; if ((data[dataIndex].inheritable & (1 << bitShift)) != 0) { try { Os.prctl(Os
/** * This is supposed to be from Telephony service. * otherwise we think it is from other applications. * @return Returns true if the country code passed in is acceptable. */ public synchronized boolean setCountryCode(String countryCode) { if (DBG) Log.d(TAG, "Receive set country code request: " + countryCode); // Empty country code. if (TextUtils.isEmpty(countryCode)) { if (DBG) Log.d(TAG, "Received empty country code, reset to default country code"); mTelephonyCountryCode = null; } else { mTelephonyCountryCode = countryCode.toUpperCase(); } // If wpa_supplicant is ready we set the country code now, otherwise it will be // set once wpa_supplicant is ready. if (mReady) { updateCountryCode(); } return true; } /** * Method to get the Country Code that was sent to wpa_supplicant. * * @return Returns the local copy of the Country Code that was sent to the driver upon * setReadyForChange(true). */
package android.system; public final class OsConstants { private OsConstants() { } public static int CAP_TO_INDEX(int x) { return x >> 5; } public static int CAP_TO_MASK(int x) { return 1 << (x & 31); } public static boolean S_ISBLK(int mode) { return (mode & S_IFMT) == S_IFBLK; } }
refreshBssidBlacklist(); if (mStateMachine.isLinkDebouncing() || mStateMachine.isSupplicantTransientState()) { localLog(listenerName + " onResults: No network selection because linkDebouncing is " + mStateMachine.isLinkDebouncing() + " and supplicantTransient is " + mStateMachine.isSupplicantTransientState()); return false; } localLog(listenerName + " onResults: start network selection"); WifiConfiguration candidate = mNetworkSelector.selectNetwork(scanDetails, buildBssidBlacklist(), mWifiInfo, mStateMachine.isConnected(), mStateMachine.isDisconnected(), mUntrustedConnectionAllowed); mWifiLastResortWatchdog.updateAvailableNetworks(mNetworkSelector.getFilteredScanDetails()); mWifiMetrics.countScanResults(scanDetails); if (candidate != null) { localLog(listenerName + ": WNS candidate-" + candidate.SSID); connectToNetwork(candidate); return true; } else { return false; }
public void useAnyBssidForConnectionIfFirmwareControlsRoaming() { // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_DISCONNECTED); // Verify that startConnectToNetwork is called with candidate network ID and SUPPLICANT_BSSID_ANY verify(mWifiStateMachine).startConnectToNetwork(CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY); }
private void localLog(String log) { if (mLocalLog != null) { mLocalLog.log(log); } }
private void updateEverything() { BatteryInfo info = BatteryInfo.getBatteryInfo(getContext(), mBatteryBroadcast, mStats, SystemClock.elapsedRealtime() * 1000); final View view = getView(); if (mShowCellSignal) { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser, mPhoneParser); } else { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser); } ((TextView) view.findViewById(R.id.charge)).setText(info.batteryPercentString); ((TextView) view.findViewById(R.id.estimation)).setText(info.remainingLabel); bindData(mChargingParser, R.string.battery_stats_charging_label, R.id.charging_group); bindData(mScreenOn, R.string.battery_stats_screen_on_label, R.id.screen_on_group); bindData(mGpsParser, R.string.battery_stats_gps_on_label, R.id.gps_group); }
SystemClock.elapsedRealtime() * 1000); final View view = getView(); if (mShowCellSignal) { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser, mPhoneParser); } else { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser); } ((TextView) view.findViewById(R.id.charge)).setText(info.batteryPercentString); ((TextView) view.findViewById(R.id.estimation)).setText(info.remainingLabel); bindData(mChargingParser, R.string.battery_stats_charging_label, R.id.charging_group); bindData(mScreenOn, R.string.battery_stats_screen_on_label, R.id.screen_on_group); bindData(mGpsParser, R.string.battery_stats_gps_on_label, R.id.gps_group); bindData(mFlashlightParser, R.string.battery_stats_flashlight_on_label, R.id.flashlight_group);
bindData(mFlashlightParser, R.string.battery_stats_flashlight_on_label, R.id.flashlight_group); bindData(mCameraParser, R.string.battery_stats_camera_on_label, R.id.camera_group); bindData(mWifiParser, R.string.battery_stats_wifi_running_label, R.id.wifi_group); bindData(mCpuParser, R.string.battery_stats_wake_lock_label, R.id.cpu_group); if (mShowCellSignal) { bindData(mPhoneParser, R.string.battery_stats_phone_signal_label, R.id.cell_network_group); } else { view.findViewById(R.id.cell_network_group).setVisibility(View.GONE); }
// Wait until it finishes and end the receiver then. assertEquals(RESULT_PASS, appEndReceiver.waitForActivity()); appEndReceiver.close(); if (!noHomeScreen()) { // At this time the timerReceiver should not fire, even though the activity has shut // down, because we are back to the home screen. assertEquals(RESULT_TIMEOUT, timeReceiver.waitForActivity()); assertTrue(timeReceiver.mTimeUsed == 0); } else { assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); } // Issuing now another activity will trigger the timing information release. final Intent dummyIntent = new Intent(context, MockApplicationActivity.class); dummyIntent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); final Activity activity = mInstrumentation.startActivitySync(dummyIntent); // Wait until it finishes and end the receiver then. assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); timeReceiver.close(); assertTrue(timeReceiver.mTimeUsed != 0); } /** * Verify that the TimeTrackingAPI works properly when switching away from the monitored task. */
public class SubscriptionController extends ISub.Stub { static final String LOG_TAG = "SubscriptionController"; static final boolean DBG = true; static final boolean VDBG = false; static final int MAX_LOCAL_LOG_LINES = 500; // TODO: Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog(MAX_LOCAL_LOG_LINES); static class ScLocalLog { private LinkedList<String> mLog; private final int mMaxLines; ScLocalLog(int maxLines) { mMaxLines = maxLines; mLog = new LinkedList<>(); } synchronized void log(String msg) { if (mMaxLines > 0) { if (mLog.size() >= mMaxLines) { mLog.removeFirst(); } mLog.addLast(msg); } } synchronized void dump(PrintWriter pw) { for (String line : mLog) { pw.println(line); } } } // Rest of the code... }
import java.io.PrintWriter; import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.Iterator; import java.util.LinkedList; import java.util.List; import java.util.Map; import java.util.Map.Entry; import java.util.Set; import java.util.concurrent.ConcurrentHashMap; /** * SubscriptionController to provide an inter-process communication to * access Sms in Icc. * * Any setters which take subId, slotId or phoneId as a parameter will throw an exception if the * parameter equals the corresponding INVALID_XXX_ID or DEFAULT_XXX_ID. * * All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID. Ie calling * getPhoneId(DEFAULT_SUB_ID) will return the same as getPhoneId(getDefaultSubId()). * * Finally, any getters which perform the mapping between subscriptions, slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID. All other getters * will fail and return the appropriate error value. Ie calling getSlotId(INVALID_SUBSCRIPTION_ID) */
* All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID. Ie calling getPhoneId(DEFAULT_SUB_ID) will return the same as getPhoneId(getDefaultSubId()). * Finally, any getters which perform the mapping between subscriptions, slots and phones will return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID. All other getters will fail and return the appropriate error value. Ie calling getSlotId(INVALID_SUBSCRIPTION_ID) will return INVALID_SLOT_ID and calling getSubInfoForSubscriber(INVALID_SUBSCRIPTION_ID) will return null. */ public class SubscriptionController extends ISub.Stub { static final String LOG_TAG = "SubscriptionController"; static final boolean DBG = true; static final boolean VDBG = false; static final int MAX_LOCAL_LOG_LINES = 500; // TODO: Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog(MAX_LOCAL_LOG_LINES); /** * Copied from android.util.LocalLog with flush() adding flush and line number */ public class ScLocalLog { // implementation details } // Rest of the code }
} } /** * @return the maximum number of subscriptions this device will support at any one time. */ @Override public int getActiveSubInfoCountMax() { return mTelephonyManager.getSimCount(); } /** * Add a new SubInfoRecord to subinfo database if needed * @param iccId the IccId of the SIM card * @param slotId the slot which the SIM is inserted * @return 0 if success, < 0 on error. */ @Override public int addSubInfoRecord(String iccId, int slotId) { enforceModifyPhoneState("addSubInfoRecord"); final long identity = Binder.clearCallingIdentity(); try { if (iccId == null) {
public int addSubInfoRecord(String iccId, int slotId) { enforceModifyPhoneState("addSubInfoRecord"); final long identity = Binder.clearCallingIdentity(); try { if (iccId == null) { return -1; } ContentResolver resolver = mContext.getContentResolver(); Cursor cursor = resolver.query(SubscriptionManager.CONTENT_URI, new String[]{SubscriptionManager.UNIQUE_KEY_SUBSCRIPTION_ID, SubscriptionManager.SIM_SLOT_INDEX, SubscriptionManager.NAME_SOURCE}, SubscriptionManager.ICC_ID + "=?", new String[]{iccId}, null); int color = getUnusedColor(mContext.getOpPackageName()); boolean setDisplayName = false; try { if (cursor == null || !cursor.moveToFirst()) { setDisplayName = true; ContentValues value = new ContentValues(); value.put(SubscriptionManager.ICC_ID, iccId); value.put(SubscriptionManager.SIM_SLOT_INDEX, slotId); value.put(SubscriptionManager.NAME_SOURCE, SubscriptionManager.NAME_SOURCE_DEFAULT_SOURCE); resolver.insert(SubscriptionManager.CONTENT_URI, value); } } finally { if (cursor != null) { cursor.close(); } } if (setDisplayName) { setDisplayName(iccId, slotId, color); } return 0; } finally { Binder.restoreCallingIdentity(identity); } }
public int addSubInfoRecord(String iccId, int slotId) { if (DBG) { logdl("[addSubInfoRecord]+ iccId:" + SubscriptionInfo.givePrintableIccid(iccId) + " slotId:" + slotId); } enforceModifyPhoneState("addSubInfoRecord"); final long identity = Binder.clearCallingIdentity(); try { if (iccId == null) { if (DBG) { logdl("[addSubInfoRecord]- null iccId"); } return -1; } ContentResolver resolver = mContext.getContentResolver(); Cursor cursor = resolver.query(SubscriptionManager.CONTENT_URI, new String[]{SubscriptionManager.UNIQUE_KEY_SUBSCRIPTION_ID, SubscriptionManager.SIM_SLOT_INDEX, SubscriptionManager.NAME_SOURCE}, SubscriptionManager.ICC_ID + "=?", new String[]{iccId}, null); int color = getUnusedColor(mContext.getOpPackageName()); boolean setDisplayName = false; try { if (cursor == null || !cursor.moveToFirst()) { setDisplayName = true; ContentValues value = new ContentValues(); value.put(SubscriptionManager.ICC_ID, iccId); value.put(SubscriptionManager.COLOR, color); value.put(SubscriptionManager.SIM_SLOT_INDEX, slotId); resolver.insert(SubscriptionManager.CONTENT_URI, value); } } finally { if (cursor != null) { cursor.close(); } } if (setDisplayName) { setDisplayName(iccId, slotId); } return 0; } finally { Binder.restoreCallingIdentity(identity); } }
import com.android.internal.telephony.Phone; import com.android.internal.telephony.PhoneConstants; import com.android.internal.telephony.SubscriptionController; import com.android.internal.telephony.TelephonyIntents; import java.io.FileDescriptor; import java.io.PrintWriter; import java.util.concurrent.atomic.AtomicInteger; import java.util.List; // must extend SubscriptionController as some people use it directly within-process public class SubscriptionControllerMock extends SubscriptionController { final AtomicInteger mDefaultDataSubId = new AtomicInteger(INVALID_SUBSCRIPTION_ID); final ITelephonyRegistry.Stub mTelephonyRegistry; final int[][] mSlotIdxToSubId; public static SubscriptionController init(Phone phone) { throw new RuntimeException("not implemented"); } public static SubscriptionController init(Context c, CommandsInterface[] ci) { throw new RuntimeException("not implemented"); } public static SubscriptionController getInstance() { throw new RuntimeException("not implemented"); } public SubscriptionControllerMock(Context c, ITelephonyRegistry.Stub tr, int phoneCount) { super(c); mTelephonyRegistry = tr; mSlotIdxToSubId = new int[phoneCount][]; } }
public SubscriptionInfo getActiveSubscriptionInfo(int slotIndex, String cp) { throw new RuntimeException("not implemented"); }
private boolean isInvalidSlotId(int slotIdx) { if (slotIdx < 0 || slotIdx >= mSlotIdxToSubId.length) return true; return false; }
public int[] getSubId(int slotIdx) { if (isInvalidSlotId(slotIdx)) { return null; } return mSlotIdxToSubId[slotIdx]; }
public void setSlotSubId(int slotIndex, int subId) { if (isInvalidSlotId(slotIndex)) { throw new RuntimeException("Invalid slot specified: " + slotIndex); } if (mSlotIndexToSubId[slotIndex][0] != subId) { mSlotIndexToSubId[slotIndex][0] = subId; try { mTelephonyRegistry.notifySubscriptionInfoChanged(); } catch (RemoteException e) { // handle exception } } }
public SubscriptionInfo getActiveSubscriptionInfoBySlotIndex(int slotIdx, String callingPackage) { if (!canReadPhoneState(callingPackage, "getActiveSubscriptionInfoBySlotIndex")) { return null; } final long identity = Binder.clearCallingIdentity(); try { List<SubscriptionInfo> subList = getActiveSubscriptionInfoList(mContext.getOpPackageName()); if (subList != null) { for (SubscriptionInfo si : subList) { if (si.getSimSlotIndex() == slotIdx) { return si; } } } } finally { Binder.restoreCallingIdentity(identity); } return null; }
public int[] getSubId(int slotIdx) { if (VDBG) printStackTrace("[getSubId]+ slotIdx=" + slotIdx); if (slotIdx == SubscriptionManager.DEFAULT_SIM_SLOT_INDEX) { slotIdx = getSlotId(getDefaultSubId()); if (VDBG) logd("[getSubId] map default slotIdx=" + slotIdx); } if (!SubscriptionManager.isValidSlotId(slotIdx)) { if (DBG) logd("[getSubId]- invalid slotIdx=" + slotIdx); return null; } int size = sSlotIdxToSubId.size(); // ... }
private int[] getDummySubIds(int slotIdx) { int numSubs = getActiveSubInfoCountMax(); if (numSubs > 0) { int[] dummyValues = new int[numSubs]; for (int i = 0; i < numSubs; i++) { dummyValues[i] = SubscriptionManager.DUMMY_SUBSCRIPTION_ID_BASE - slotIdx; } return dummyValues; } else { return null; } }
private void checkType(int columnIndex, Type expectedType) { ColumnSchema columnSchema = schema.getColumnByIndex(columnIndex); Type columnType = columnSchema.getType(); if (!columnType.equals(expectedType)) { throw new IllegalArgumentException("Column (name: " + columnSchema.getName() + ", index: " + columnIndex +") is of type " + columnType.getName() + " but was requested as a type " + expectedType.getName()); } } public Integer abs(Integer self) { return Integer.valueOf(Math.abs(self.intValue())); } public Integer floor(Double self) { return Integer.valueOf((int)Math.floor(self.doubleValue())); } public Integer floor(Integer self) { return self; } pw.println(" defaultDataPhoneId=" + SubscriptionManager.from(mContext).getDefaultDataPhoneId()); pw.println(" defaultVoicePhoneId=" + SubscriptionManager.getDefaultVoicePhoneId()); pw.println(" defaultSmsPhoneId=" + SubscriptionManager.from(mContext).getDefaultSmsPhoneId()); pw.flush(); for (Entry<Integer, Integer> entry : sSlotIdxToSubId.entrySet()) { pw.println(" sSlotIdxToSubId[" + entry.getKey() + "]: subId=" + entry.getValue()); } pw.flush(); pw.println("++++++++++++++++++++++++++++++++"); List<SubscriptionInfo> sirl = getActiveSubscriptionInfoList(mContext.getOpPackageName()); if (sirl != null) { pw.println(" ActiveSubInfoList:"); for (SubscriptionInfo entry : sirl) { pw.println(" " + entry.toString()); } } else { pw.println(" ActiveSubInfoList: is null"); } pw.flush(); pw.println("++++++++++++++++++++++++++++++++"); sirl = getAllSubInfoList(mContext.getOpPackageName()); if (sirl != null) { // code continues... }
import com.android.internal.telephony.Phone; import com.android.internal.telephony.PhoneConstants; import com.android.internal.telephony.SubscriptionController; import com.android.internal.telephony.TelephonyIntents; import java.io.FileDescriptor; import java.io.PrintWriter; import java.util.concurrent.atomic.AtomicInteger; import java.util.List; public class SubscriptionControllerMock extends SubscriptionController { final AtomicInteger mDefaultDataSubId = new AtomicInteger(INVALID_SUBSCRIPTION_ID); final ITelephonyRegistry.Stub mTelephonyRegistry; final int[][] mSlotIdxToSubId; public static SubscriptionController init(Phone phone) { throw new RuntimeException("not implemented"); } public static SubscriptionController init(Context c, CommandsInterface[] ci) { throw new RuntimeException("not implemented"); } public static SubscriptionController getInstance() { throw new RuntimeException("not implemented"); } public SubscriptionControllerMock(Context c, ITelephonyRegistry.Stub tr, int phoneCount) { super(c); mTelephonyRegistry = tr; mSlotIdxToSubId = new int[phoneCount][]; } }
public SubscriptionInfo getActiveSubscriptionInfoForSimSlotIndex(int slotIdx, String cp){ throw new RuntimeException("not implemented"); }
private boolean isInvalidSlotId(int slotIdx) { if (slotIdx < 0 || slotIdx >= mSlotIdxToSubId.length) return true; return false; }
public void setSlotSubId(int slotIndex, int subId) { if (isInvalidSlotId(slotIndex)) { throw new RuntimeException("Invalid slot specified: " + slotIndex); } if (mSlotIndexToSubId[slotIndex][0] != subId) { mSlotIndexToSubId[slotIndex][0] = subId; try { mTelephonyRegistry.notifySubscriptionInfoChanged(); } catch (RemoteException ex) { // Handle RemoteException } } }
private static String getEtwsPrimaryMessage(Context context, int category) { Resources r = context.getResources(); switch (category) { case ETWS_WARNING_TYPE_EARTHQUAKE: return r.getString(R.string.etws_primary_default_message_earthquake); case ETWS_WARNING_TYPE_TSUNAMI: return r.getString(R.string.etws_primary_default_message_tsunami); case ETWS_WARNING_TYPE_EARTHQUAKE_AND_TSUNAMI: return r.getString(R.string.etws_primary_default_message_earthquake_and_tsunami); case ETWS_WARNING_TYPE_TEST_MESSAGE: return r.getString(R.string.etws_primary_default_message_test); case ETWS_WARNING_TYPE_OTHER_EMERGENCY: return r.getString(R.string.etws_primary_default_message_others); default: return ""; } }
public boolean isNetworkRoaming(int subId) { final int phoneId = getPhoneId(subId); if (phoneId < 0) { return false; } return TelephonyManager.getDefault().isNetworkRoaming(subId); } public int getSimState(int slotIndex) { return TelephonyManager.getDefault().getSimState(slotIndex); }
ServiceStateTable.DATA_OPERATOR_NUMERIC, ServiceStateTable.IS_MANUAL_NETWORK_SELECTION, ServiceStateTable.RIL_VOICE_RADIO_TECHNOLOGY, ServiceStateTable.RIL_DATA_RADIO_TECHNOLOGY, ServiceStateTable.CSS_INDICATOR, ServiceStateTable.NETWORK_ID, ServiceStateTable.SYSTEM_ID, ServiceStateTable.CDMA_ROAMING_INDICATOR, ServiceStateTable.CDMA_DEFAULT_ROAMING_INDICATOR, ServiceStateTable.CDMA_ERI_ICON_INDEX, ServiceStateTable.CDMA_ERI_ICON_MODE, ServiceStateTable.IS_EMERGENCY_ONLY, ServiceStateTable.IS_DATA_ROAMING_FROM_REGISTRATION, ServiceStateTable.IS_USING_CARRIER_AGGREGATION, }; @Override public boolean onCreate() { return true; } @Override public Uri insert(Uri uri, ContentValues values) { throw new RuntimeException("Not supported"); } @Override public int delete(Uri uri, String selection, String[] selectionArgs) { throw new RuntimeException("Not supported"); } @Override public int update(Uri uri, ContentValues values, String selection, String[] selectionArgs) { throw new RuntimeException("Not supported"); } @Override public String getType(Uri uri) { if (ServiceStateTable.CONTENT_URI.equals(uri)) { return ServiceStateTable.CONTENT_TYPE; } return null; }
super.okPressed(); broker.post(TOPIC_USER_REQUESTS_SEND, queue); } @Override protected void cancelPressed() { super.cancelPressed(); broker.post(TOPIC_USER_REQUESTS_CLEAR_QUEUE, queue); } private final class CommentToProviderActivationConverter extends Converter { private INeedinfoProviderDescriptor provider; private CommentToProviderActivationConverter(INeedinfoProviderDescriptor provider) { super(String.class, Boolean.class); this.provider = provider; } @Override public Object convert(Object fromObject) { String comment = (String) fromObject; if (comment != null) { int informationStart = comment.indexOf(MessageFormat.format(INFORMATION_START, provider.getHumanReadableDescription())); if (informationStart != -1) { int informationEnd = comment.indexOf(MessageFormat.format(INFORMATION_END, provider.getHumanReadableName()), informationStart); if (informationStart != -1 && informationEnd != -1) { return true; } } } return false; } } private final class ProviderActivationToCommentConverter extends Converter { private INeedinfoProviderDescriptor provider; private ProviderActivationToCommentConverter(INeedinfoProviderDescriptor provider) { super(Boolean.class, String.class); this.provider = provider; } @Override public Object convert(Object fromObject) { boolean activation = (boolean) fromObject; if (activation) { return MessageFormat.format(INFORMATION_START, provider.getHumanReadableDescription()) + " " + MessageFormat.format(INFORMATION_END, provider.getHumanReadableName()); } return null; } } new TaskId(getActivityId(), partition)); state.open(ctx); } @Override public void nextFrame(ByteBuffer buffer) throws HyracksDataException { state.appendFrame(buffer); } @Override public void fail() throws HyracksDataException { } @Override public void close() throws HyracksDataException { state.close(); state.writeOut(writer, new VSizeFrame(ctx)); } @Override public void flush() throws HyracksDataException { // flush() on any materializing operator is a no op } FileReference file = ctx.getJobletContext().createManagedWorkspaceFile(ExternalSortRunGenerator.class.getSimpleName()); return new RunFileWriter(file, ctx.getIOManager()); } @Override protected IFrameWriter getFlushableFrameWriter(RunFileWriter writer) throws HyracksData
public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri.parse("content://service-state/"); public static final String CONTENT_TYPE = "vnd.android.cursor.dir/service_state"; public static Uri getUriForSubId(String field, int subId) { // Used to push and receive updates to a field in the ServiceState for a given subId return Uri.withAppendedPath(CONTENT_URI, field + "/" + subId); } }
CMAS_RESPONSE_TYPE, CMAS_SEVERITY, CMAS_URGENCY, CMAS_CERTAINTY }; } public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri.parse("content://service-state/"); public static final String CONTENT_TYPE = "vnd.android.cursor.dir/service_state"; public static Uri getUriForSubId(String field, int subId) { return CONTENT_URI.buildUpon().appendEncodedPath(String.valueOf(subId)) .appendEncodedPath(field).build(); }
public static Uri getUriForSubId(String field, int subId) { if (field == null) { return CONTENT_URI.buildUpon().appendEncodedPath(String.valueOf(subId)).build(); } else { return CONTENT_URI.buildUpon().appendEncodedPath(String.valueOf(subId)) .appendEncodedPath(field).build(); } }
+ something.getClass().getName() + " to byte array!"); } } public AdvertiseData buildAdvData(JSONObject params) throws Exception { AdvertiseData.Builder builder = new AdvertiseData.Builder(); Iterator<String> keys = params.keys(); while (keys.hasNext()) { String key = keys.next(); if (key.startsWith("manufacturerData")) { JSONArray manuf = params.getJSONArray(key); int manufId = manuf.getInt(0); byte[] data = somethingToByteArray(manuf.get(1)); builder.addManufacturerData(manufId, data); } else if (key.startsWith("serviceData")) { JSONArray serDat = params.getJSONArray(key); ParcelUuid uuid = ParcelUuid.fromString(serDat.getString(0)); byte[] data = somethingToByteArray(serDat.get(1)); builder.addServiceData(uuid, data); } else if (key.startsWith("serviceUuid")) {
private void updateData(@NonNull TimeQueryFilter filters, IProgressMonitor monitor) { if (fXYDataProvider == null) { TraceCompassLogUtils.traceInstant(LOGGER, Level.WARNING, "Data provider for this viewer is not available"); //$NON-NLS-1$ return; } boolean isComplete = false; do { TmfModelResponse<ITmfXyModel> response = fXYDataProvider.fetchXY(filters, monitor); ITmfXyModel model = response.getModel(); if (!(model instanceof ITmfCommonXAxisModel)) { Activator.getDefault().logError("The model is of the wrong type: " + model); //$NON-NLS-1$ } extractXYModelAndUpdateViewModel((ITmfCommonXAxisModel) model); updateDisplay(); ITmfResponse.Status status = response.getStatus(); if (status == ITmfResponse.Status.COMPLETED) { /* Model is complete, no need to request again the data provider */ isComplete = true; } else if (status == ITmfResponse.Status.FAILED || status == ITmfResponse.Status.CANCELLED) { /* Error occurred, log and return */ Activator.getDefault().logError("Error occurred while fetching XY data: " + response.getStatus().toString()); //$NON-NLS-1$ return; } } while (!isComplete); }
public PeriodicAdvertisingParameters buildPeriodicParameters(JSONObject params) throws Exception { PeriodicAdvertisingParameters.Builder builder = new PeriodicAdvertisingParameters.Builder(); Iterator<String> keys = params.keys(); while (keys.hasNext()) { String key = keys.next(); if (key.equals("enable")) { builder.setEnable(params.getBoolean(key)); } else if (key.equals("includeTxPower")) { builder.setIncludeTxPower(params.getBoolean(key)); } else if (key.equals("interval")) { builder.setInterval(params.getInt(key)); } else { throw new IllegalArgumentException( "Unknown PeriodicAdvertisingParameters field " + key); } } return builder.build(); } /** * Starts ble advertising * * @throws Exception */ @Rpc(description = "Starts ble advertisement") public void bleAdvSetStartAdvertisingSet( @RpcParameter(name = "params") JSONObject parametersJson, @RpcParameter(name = "data") JSONObject dataJson, @RpcParameter(name = "scanResponse") JSONObject scanResponseJson, @RpcParameter(name = "periodicParameters") JSONObject periodicParametersJson, // rest of the code }
public void useAnyBssidForConnectionIfFirmwareControlsRoaming() { when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); mWifiConnectivityManager.handleScreenStateChanged(true); mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork(CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY); }
private int readHighTagNumber() throws BerDataValueFormatException { int b; int result = 0; do { if (!mBuf.hasRemaining()) { throw new BerDataValueFormatException("Truncated tag number"); } b = mBuf.get(); result <<= 7; result += b & 0x7f; if (result < 0) { throw new BerDataValueFormatException("Tag number too large"); } } while ((b & 0x80) != 0); return result; } private int readShortFormLength(int firstLengthByte) throws BerDataValueFormatException { return firstLengthByte & 0x7f; } private int readLongFormLength(int firstLengthByte) throws BerDataValueFormatException { int byteCount = firstLengthByte & 0x7f; // Rest of the code }
"Truncated indefinite-length contents: " + bytesRead + " bytes read"); } int b = mBuf.get(); bytesRead++; if (bytesRead < 0) { throw new BerDataValueFormatException("Indefinite-length contents too long"); } if (b == 0) { if (prevZeroByte) { // End of contents reached -- we've read the value and its terminator 0x00 0x00 return bytesRead - 2; } prevZeroByte = true; continue; } else { prevZeroByte = false; } } } }
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.rs.rsov.test; import android.content.Context; import android.renderscript.Allocation; import android.renderscript.Element; import android.renderscript.RenderScript; import android.renderscript.Type; import android.util.Log; public class UT_global_query extends UnitTest { protected UT_global_query(RSoVTestCore rstc, Context ctx) { super(rstc, "global_query", ctx); } }
req.channelRequestType = channelRequestType; req.channel = channel; req.ifaceName = interfaceName; req.securityRequired = !((pmk == null || pmk.length == 0) && (passphrase == null || passphrase.length() == 0)); if (req.securityRequired) { req.cipherType = getStrongestCipherSuiteType(capabilities.supportedCipherSuites); if (pmk != null && pmk.length != 0) { convertByteArrayToArrayList(pmk, req.pmk); } else { convertByteArrayToArrayList(passphrase.getBytes(), req.passphrase); } } try { WifiStatus status = iface.initiateDataPathRequest(transactionId, req); if (status.code == WifiStatusCode.SUCCESS) { return true; } else { Log.e(TAG, "initiateDataPath: error: " + statusString(status)); return false; } } catch (RemoteException e) { Log.e(TAG, "initiateDataPath: exception: " + e); return false; }
public boolean setWfdEnable(boolean enable) { return mSupplicantP2pIfaceHal.enableWfd(enable); } /** * Set Wifi Display device info. * * @param hex WFD device info as described in section 5.1.2 of WFD technical * specification v1.0.0. * @return true, if operation was successful. */ public boolean setWfdDeviceInfo(String hex) { return mSupplicantP2pIfaceHal.setWfdDeviceInfo(hex); } /** * Initiate a P2P service discovery indefinitely. * * @return boolean value indicating whether operation was successful. */ public boolean p2pFind() { return p2pFind(0); } /** * Initiate a P2P service discovery with a (optional) timeout. * * @param timeout Max time to be spent is performing discovery. * Set to 0 to indefinitely continue discovery until an explicit * |stopFind| is sent. * @return boolean value indicating whether operation was successful. */ public boolean p2pFind(int timeout) { // implementation }
import java.io.IOException; import java.util.Map; import java.util.concurrent.atomic.AtomicReference; public class ToyVpnService extends VpnService implements Handler.Callback, ToyVpnConnection.Listener { private static final String TAG = ToyVpnService.class.getSimpleName(); public static final String ACTION_CONNECT = "com.example.android.toyvpn.START"; public static final String ACTION_DISCONNECT = "com.example.android.toyvpn.STOP"; private Handler mHandler; private SparseArray<Thread> mThreads = new SparseArray<>(); private int mNextConnectionId = 1; private AtomicReference<ParcelFileDescriptor> mTunnelInterface = new AtomicReference<>(); private PendingIntent mConfigureIntent; @Override public void onCreate() { // The handler is only used to show messages. if (mHandler == null) { mHandler = new Handler(this); } // Create the intent to "configure" the connection (just start ToyVpnClient). mConfigureIntent = PendingIntent.getActivity(this, 0, new Intent(this, ToyVpnClient.class), PendingIntent.FLAG_UPDATE_CURRENT); } @Override // Rest of the code... }
public int onStartCommand(Intent intent, int flags, int startId) { switch (intent.getAction()) { case ACTION_DISCONNECT: disconnect(); break; case ACTION_CONNECT: connect(); break; default: log.w("unknown action " + intent.getAction()); break; } return START_STICKY; }
public boolean handleMessage(Message message) { if (message != null) { int messageId = message.what; Toast.makeText(this, messageId, Toast.LENGTH_SHORT).show(); if (messageId != R.string.disconnected) { updateForegroundNotification(messageId); } } return true; }
} final ParcelFileDescriptor oldInterface = mTunnelInterface.getAndSet(tunInterface); if (oldInterface != null) { try { Log.i(TAG, "Closing interface: " + oldInterface); oldInterface.close(); } catch (IOException e){ Log.e(TAG, "Closing interface failed", e); } } } @Override public void onDisconnect(int connectionId) { synchronized (this) { mThreads.remove(connectionId); } } @Override public void onRevoke() { disconnect(); } private void connect() { synchronized (this) { // Become a foreground service. Background services can be VPN services too, but they can // be killed by background check before getting a chance to receive onRevoke(). updateForegroundNotification(R.string.connecting); mHandler.sendEmptyMessage(R.string.connecting); final SharedPreferences prefs = getSharedPreferences(ToyVpnClient.Prefs.NAME, MODE_PRIVATE); final ToyVpnConnection connection; try { // Extract information from the shared preferences. connection = new ToyVpnConnection(this, this, mNextConnectionId, prefs.getString(ToyVpnClient.Prefs.SERVER_ADDRESS, ""), ... } catch (Exception e) { ... } } }
import org.junit.After; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.ArgumentCaptor; import org.mockito.Mock; import org.mockito.MockitoAnnotations; import static android.Manifest.permission.MODIFY_PHONE_STATE; import static android.Manifest.permission.READ_PHONE_STATE; import static com.android.internal.telephony.ims.ImsResolver.SERVICE_INTERFACE; import static junit.framework.Assert.assertEquals; import static junit.framework.Assert.assertNotNull; import static junit.framework.Assert.assertNull; import static junit.framework.Assert.fail; import static org.mockito.Matchers.any; import static org.mockito.Matchers.anyInt; import static org.mockito.Matchers.anyString; import static org.mockito.Matchers.eq; import static org.mockito.Matchers.nullable; import static org.mockito.Mockito.doThrow; import static org.mockito.Mockito.never; import static org.mockito.Mockito.times; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.when; @RunWith(AndroidJUnit4.class) public class ImsServiceTest { private static final int TEST_SLOT_0 = 0; private static final int TEST_SLOT_1 = 1; }
// Mock the HeadsetService when(mockServiceFactory.getHeadsetService()).thenReturn(mockHeadsetService); when(mockHeadsetService.getPriority(device)).thenReturn(BluetoothProfile.PRIORITY_UNDEFINED); // Mock the A2DP service when(mockServiceFactory.getA2dpService()).thenReturn(mockA2dpService); when(mockA2dpService.getPriority(device)).thenReturn(BluetoothProfile.PRIORITY_UNDEFINED); // Mock the looper when(mockAdapterService.getMainLooper()).thenReturn(mHandlerThread.getLooper()); // Tell the AdapterService that it is a mock (see isMock documentation) when(mockAdapterService.isMock()).thenReturn(true); PhonePolicy phonePolicy = new PhonePolicy(mockAdapterService, mockServiceFactory); // Get the broadcast receiver to inject events BroadcastReceiver injector = phonePolicy.getBroadcastReceiver(); // Inject an event for UUIDs updated for a remote device with only HFP enabled Intent intent = new Intent(BluetoothDevice.ACTION_UUID); intent.putExtra(BluetoothDevice.EXTRA_DEVICE, device); ParcelUuid[] uuids = new ParcelUuid[2]; uuids[0] = BluetoothUuid.Handsfree; uuids[1] = BluetoothUuid.AudioSink;
import com.android.internal.telephony.MmiCode; import com.android.internal.telephony.Phone; import com.android.internal.telephony.PhoneConstants; import java.util.List; public class MMIDialogActivity extends Activity { private Dialog mMMIDialog; private Handler mHandler; private CallManager mCM = PhoneGlobals.getInstance().getCallManager(); private Phone mPhone = PhoneGlobals.getPhone(); @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); Intent intent = getIntent(); int subId = intent.getIntExtra(PhoneConstants.SUBSCRIPTION_KEY, SubscriptionManager.DEFAULT_SUBSCRIPTION_ID); mPhone = PhoneGlobals.getPhone(subId); mHandler = new Handler() { @Override public void handleMessage(Message msg) { switch (msg.what) { case PhoneGlobals.MMI_COMPLETE: onMMIComplete((MmiCode) ((AsyncResult) msg.obj).result); break; case PhoneGlobals.MMI_CANCEL: onMMICancel(); break; default: break; } } }; } private void onMMIComplete(MmiCode code) { // implementation } private void onMMICancel() { // implementation } }
// Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork(CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY); @Test public void useAnyBssidToConnectWhenFirmwareRoamingOnAndConfigHasBssidSpecified() { // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set up the candidate configuration such that it has a BSSID specified. WifiConfiguration candidate = generateWifiConfig(0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null); }
Refactored Code: ```java anyBoolean(), anyBoolean())).thenReturn(candidate); mWifiConnectivityManager.handleScreenStateChanged(true); mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork(CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY); } @Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified() { mWifiConnectivityManager.handleScreenStateChanged(true); mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine, atLeastOnce()).startConnectToNetwork(CANDIDATE_NETWORK_ID, CANDIDATE_BSSID); } ``` Note: Removed the commented lines and extra spaces.
public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified() { mWifiConnectivityManager.handleScreenStateChanged(true); mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine, times(1)).startConnectToNetwork(CANDIDATE_NETWORK_ID, CANDIDATE_BSSID); }
@Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified() { // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine, atLeastOnce()).startConnectToNetwork(CANDIDATE_NETWORK_ID, CANDIDATE_BSSID); } @Test public void useConfigSpecifiedBssidToConnectionWhenFirmwareRoamingOff() { // Set up the candidate configuration such that it has a BSSID specified. WifiConfiguration candidate = generateWifiConfig(0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null); candidate.BSSID = CANDIDATE_BSSID; // config specified ScanResult candidateScanResult = new ScanResult(); }
candidateScanResult.SSID = CANDIDATE_SSID; candidateScanResult.BSSID = CANDIDATE_BSSID; candidate.getNetworkSelectionStatus().setCandidate(candidateScanResult); when(mWifiNS.selectNetwork(anyObject(), anyObject(), anyObject(), anyBoolean(), anyBoolean(), anyBoolean())).thenReturn(candidate); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged(WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork(CANDIDATE_NETWORK_ID, CANDIDATE_BSSID);
public synchronized void setLockdown(boolean lockdown) { enforceControlPermissionOrInternalCaller(); if (mAlwaysOn) { setAlwaysOnPackage(null, false); } setVpnForcedLocked(lockdown); mLockdown = lockdown; }
public synchronized void setLockdownEnabled(boolean lockdown) { enforceControlPermissionOrInternalCaller(); if (mAlwaysOn && lockdown) { setAlwaysOnPackage(null, false); } setVpnForcedLocked(lockdown); mLockdown = lockdown; } public void setAlwaysOnPackage(String packageName, boolean lockdown) { // implementation } public void setVpnForcedLocked(boolean lockdown) { // implementation }
private void setVpnForcedLocked(boolean enforce) { List<String> exemptedPackages = null; if (isNullOrLegacyVpn(mPackage)) { setVpnForcedWithExemptionsLocked(enforce, exemptedPackages); } else { exemptedPackages = Collections.singletonList(mPackage); setVpnForcedWithExemptionsLocked(enforce, exemptedPackages); } }
private void setVpnForcedWithExemptionsLocked(boolean enforce, @Nullable List<String> exemptedPackages) { final Set<UidRange> removedRanges = new ArraySet<>(mBlockedUsers); final Set<UidRange> addedRanges; if (enforce) { addedRanges = createUserAndRestrictedProfilesRanges(mUserHandle, /* allowedApplications */ null, /* disallowedApplications */ exemptedPackages); removedRanges.removeAll(addedRanges); addedRanges.removeAll(mBlockedUsers); } else { addedRanges = Collections.emptySet(); } setAllowOnlyVpnForUids(false, removedRanges); setAllowOnlyVpnForUids(true, addedRanges); }
protected TaskConfigFactory(GitRepositoryManager gitMgr) { this.allProjects = new AllProjectsName("All-Projects"); this.gitMgr = gitMgr; } private void setVpnForcedWithExemptionsLocked(boolean enforce, @Nullable List<String> exemptedPackages) { final Set<UidRange> removedRanges = new ArraySet<>(mBlockedUsers); final Set<UidRange> addedRanges; if (enforce) { addedRanges = createUserAndRestrictedProfilesRanges(mUserHandle, null, exemptedPackages); removedRanges.removeAll(addedRanges); addedRanges.removeAll(mBlockedUsers); } else { addedRanges = Collections.emptySet(); } setAllowOnlyVpnForUids(false, removedRanges); setAllowOnlyVpnForUids(true, addedRanges); }
Fixed Code: ```java public interface TypeVariable<D extends GenericDeclaration> extends Type { /** * Returns an array of {@code Type} objects representing the * upper bound(s) of this type variable. Note that if no upper bound is * explicitly declared, the upper bound is {@code Object}. * * <p>For each upper bound B: * <ul> * <li>if B is a parameterized type or a type variable, it is created, * (see {@link java.lang.reflect.ParameterizedType ParameterizedType} for the * details of the creation process for parameterized types). * <li>Otherwise, B is resolved. * </ul> * * @return an array of {@code Type} objects representing the upper bound(s) * of this type variable * @throws TypeNotPresentException if any of the bounds refers to a * non-existent type declaration * @throws MalformedParameterizedTypeException if any of the bounds refer * to a parameterized type that cannot be instantiated for any reason * @since 1.8 */ Type[] getBounds(); /** * Returns the {@code GenericDeclaration} object representing the * generic declaration declared this type variable. * * @return the generic declaration declared for this type variable. * @since 1.5 */ D getGenericDeclaration(); /** * Returns the name of this type variable, as it occurs in the source code. * * @return the name of this type variable * @since 1.8 */ String getName(); /** * Returns an array of {@code AnnotatedType} objects that represent the use * of types to specify superinterfaces and superclasses of the entity * represented by this type variable. The order of the objects in the array * corresponds to the order of the bounds in the declaration of the type * variable. * * @return an array of objects representing the upper bounds of the type * variable * @since 1.8 */ AnnotatedType[] getAnnotatedBounds(); } ``` Review: Removed AnnotatedElement due to excluded support for runtime type annotations.
@VisibleForTesting public void setWifiHandlerLogForTest(WifiLog log) { mClientHandler.setWifiLog(log); } public void checkAndStartWifi() { if (mFrameworkFacade.inStorageManagerCryptKeeperBounce()) { Log.d(TAG, "Device still encrypted. Need to restart SystemServer. Do not start wifi."); return; } boolean wifiEnabled = mSettingsStore.isWifiToggleEnabled(); Slog.i(TAG, "WifiService starting up with Wi-Fi " + (wifiEnabled ? "enabled" : "disabled")); registerForScanModeChange(); }
public void testWifiControllerDoesNotStartWhenDeviceTriggerResetMainAtBoot() { when(mPropertyService.get(eq("vold.decrypt"), anyString())).thenReturn("trigger_reset_main"); when(mSettingsStore.isWifiToggleEnabled()).thenReturn(false); mWifiServiceImpl.checkAndStartWifi(); verify(mWifiController, never()).start(); }
public void testWifiControllerStartsWhenDeviceIsDecryptedAtBootWithWifiDisabled() { when(mPropertyService.get(eq("vold.decrypt"), anyString())).thenReturn(""); when(mSettingsStore.isWifiToggleEnabled()).thenReturn(false); mWifiServiceImpl.checkAndStartWifi(); verify(mWifiController).start(); verify(mWifiController, never()).sendMessage(CMD_WIFI_TOGGLED); }
public void testWifiFullyStartsWhenDeviceIsDecryptedAtBootWithWifiEnabled() { when(mPropertyService.get(eq("vold.decrypt"), anyString())).thenReturn(""); when(mSettingsStore.handleWifiToggled(true)).thenReturn(true); when(mSettingsStore.isWifiToggleEnabled()).thenReturn(true); when(mWifiStateMachine.syncGetWifiState()).thenReturn(WIFI_STATE_DISABLED); mWifiServiceImpl.checkAndStartWifi(); verify(mWifiController).start(); verify(mWifiController).sendMessage(CMD_WIFI_TOGGLED); }
public static final int SUP_DISCONNECTION_EVENT = BASE + 2; /* Network connection completed */ public static final int NETWORK_CONNECTION_EVENT = BASE + 3; /* Network disconnection completed */ public static final int NETWORK_DISCONNECTION_EVENT = BASE + 4; /* Scan results are available */ public static final int SCAN_RESULTS_EVENT = BASE + 5; /* Scheduled scan results are available */ public static final int SCHED_SCAN_RESULTS_EVENT = BASE + 6; /* Supplicate state changed */ public static final int SUPPLICANT_STATE_CHANGE_EVENT = BASE + 7; /* Password failure and EAP authentication failure */ public static final int AUTHENTICATION_FAILURE_EVENT = BASE + 8; /* WPS success detected */ public static final int WPS_SUCCESS_EVENT = BASE + 9; /* WPS failure detected */ public static final int WPS_FAIL_EVENT = BASE + 10; /* WPS overlap detected */ public static final int WPS_OVERLAP_EVENT = BASE + 11; /* WPS timeout detected */
public void onPnoNetworkFound() { Log.d(TAG, "Pno scan result event"); mWifiMonitor.broadcastPnoScanResultEvent(mClientInterfaceName); }
android.provider.Settings.Global.SETUP_PREPAID_DATA_SERVICE_URL)); if (!isLteOnCdma || missingDataServiceUrl) { prefSet.removePreference(mLteDataServicePref); } else { android.util.Log.d(LOG_TAG, "keep ltePref"); } if (!(ImsManager.isVolteEnabledByPlatform(getActivity()) && ImsManager.isVolteProvisionedOnDevice(getActivity())) || carrierConfig.getBoolean(CarrierConfigManager.KEY_HIDE_ENHANCED_4G_LTE_BOOL)) { Preference pref = prefSet.findPreference(BUTTON_4G_LTE_KEY); if (pref != null) { prefSet.removePreference(pref); } } ActionBar actionBar = getActivity().getActionBar(); if (actionBar != null) { actionBar.setDisplayHomeAsUpEnabled(true); } // Enable link to CMAS app settings depending on the value in config.xml.
if (!isLteOnCdma || missingDataServiceUrl) { prefSet.removePreference(mLteDataServicePref); } else { android.util.Log.d(LOG_TAG, "keep ltePref"); } // Hide enhanced 4G LTE mode settings when either it is not supported by platform or // 'KEY_HIDE_ENHANCED_4G_LTE_BOOL' is true. if (!(ImsManager.isVolteEnabledByPlatform(getActivity()) && ImsManager.isVolteProvisionedOnDevice(getActivity())) || carrierConfig.getBoolean(CarrierConfigManager.KEY_HIDE_ENHANCED_4G_LTE_BOOL)) { Preference pref = prefSet.findPreference(BUTTON_4G_LTE_KEY); if (pref != null) { prefSet.removePreference(pref); } } ActionBar actionBar = getActivity().getActionBar(); if (actionBar != null) { // android.R.id.home will be triggered in onOptionsItemSelected() actionBar.setDisplayHomeAsUpEnabled(true); } // Enable link to CMAS app settings depending on the value in config.xml. final boolean isCellBroadcastAppLinkEnabled = getActivity().getResources().getBoolean(R.bool.config_cellBroadcastAppLinks);
if (obj == null) return false; if (getClass() != obj.getClass()) return false; Transition other = (Transition) obj; return Objects.equals(from, other.from) && Objects.equals(event, other.event) && Objects.equals(to, other.to); } @Override public String toString() { return "Transition " + from + " --(" + event + ")--> " + to; } private final Set<Transition> transitions = new LinkedHashSet<>(); private final Map<ActivationState, Map<EventType, Transition>> transitionMap = new HashMap<>(); private final ActivationState inactiveState; protected ActivationLifeCycle(ActivationState inactiveState) { Preconditions.checkArgument(inactiveState != null, "Inactive state cannot be null"); this.inactiveState = inactiveState; } /** * Returns the state in the life cycle that is defined as the next state * from the given current state in response to the given event. *
Handler handler = new Handler(Looper.getMainLooper()); manager.requestNetwork(request, callback, handler); // Callback is already registered, reregistration should fail. Class<IllegalArgumentException> wantException = IllegalArgumentException.class; expectThrowable(() -> manager.requestNetwork(request, callback), wantException); manager.unregisterNetworkCallback(callback); // Service release request and sends back notification Message releaseMsg = makeMessage(request, ConnectivityManager.CALLBACK_RELEASED); handler.sendMessage(releaseMsg); Thread.sleep(1000); // replace by waitForIdle() // Unregistering the callback should make it registrable again. manager.requestNetwork(request, callback); static Message makeMessage(NetworkRequest req, int messageType) { Bundle bundle = new Bundle(); bundle.putParcelable(NetworkRequest.class.getSimpleName(), req); Message msg = Message.obtain(); msg.what = messageType; msg.setData(bundle); return msg; } static NetworkRequest makeRequest(int requestId) { NetworkRequest request = new NetworkRequest.Builder().clearCapabilities().build(); return new NetworkRequest(request.networkCapabilities, ConnectivityManager.TYPE_NONE, requestId, NetworkRequest.Type.NONE); }
if (maxBlacklistSize <= 0) { Log.wtf(TAG, "Invalid max BSSID blacklist size: " + maxBlacklistSize); return; } ArrayList<String> blacklistedBssids = new ArrayList<String>(buildBssidBlacklist()); int blacklistSize = blacklistedBssids.size(); if (blacklistSize > maxBlacklistSize) { Log.wtf(TAG, "Attempt to write " + blacklistSize + " blacklisted BSSIDs, max size is " + maxBlacklistSize); blacklistedBssids = new ArrayList<String>(blacklistedBssids.subList(0, maxBlacklistSize)); } localLog("Trim down BSSID blacklist size from " + blacklistSize + " to " + blacklistedBssids.size()); if (!mConnectivityHelper.setFirmwareRoamingConfiguration(blacklistedBssids, new ArrayList<String>())) { localLog("Failed to set firmware roaming configuration."); }
private void start() { mConnectivityHelper.clearFirmwareRoamingInfo(); mConnectivityHelper.getFirmwareRoamingInfo(); startConnectivityScan(SCAN_IMMEDIATELY); }
public void setWifiEnabled(boolean enable) { localLog("Set WiFi " + (enable ? "enabled" : "disabled")); mWifiEnabled = enable; checkRunningState(); } private void checkRunningState() { if (mWifiEnabled && mWifiConnectivityManagerEnabled) { localLog("starting up WifiConnectivityManager"); start(); } else { localLog("stopping WifiConnectivitymanager"); stop(); } }
private void localLog(String log) { if (mLocalLog != null) { mLocalLog.log(log); } }
sbuf.append(" Same network the current one bonus: ").append(mSameNetworkAward).append(","); if (mConnectivityHelper.isFirmwareRoamingSupported() && currentBssid != null && !currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Firmware roaming equivalent BSSID bonus: ").append(mSameBssidAward).append(","); } if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward).append(","); } if (!WifiConfigurationUtil.isConfigForOpenNetwork(network)) { score += mSecurityAward; sbuf.append(" Secure network bonus: ").append(mSecurityAward).append(","); }
if (mConnectivityHelper.isFirmwareRoamingSupported() && currentBssid != null && !currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Firmware roaming equivalent BSSID bonus: ").append(mSameBssidAward).append(","); } if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward).append(","); } if (!WifiConfigurationUtil.isConfigForOpenNetwork(network)) { score += mSecurityAward; sbuf.append(" Secure network bonus: ").append(mSecurityAward).append(","); } if (network.numNoInternetAccessReports > 0 && !network.validatedInternetAccess) { score -= mNoInternetPenalty; sbuf.append(" No internet penalty: -").append(mNoInternetPenalty).append(","); } sbuf.append(" ## Total score: ").append(score).append("\n"); return score;
if (mConnectivityHelper.isFirmwareRoamingSupported() && currentBssid != null && !currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Firmware roaming equivalent BSSID bonus: ").append(mSameBssidAward).append(","); } if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward).append(","); } if (!WifiConfigurationUtil.isConfigForOpenNetwork(network)) { score += mSecurityAward; sbuf.append(" Secure network bonus: ").append(mSecurityAward).append(","); } if (network.numNoInternetAccessReports > 0 && !network.validatedInternetAccess) { score -= mNoInternetPenalty; sbuf.append(" No internet penalty: -").append(mNoInternetPenalty).append(","); } sbuf.append(" ## Total score: ").append(score).append("\n"); return score;
public void testCTSSyscallBlocked() { if (CpuFeatures.isArm64Cpu()) { testAllowed(98); testBlocked(99); testBlocked(100); } else if (CpuFeatures.isArmCpu()) { testBlocked(7); testAllowed(8); testBlocked(9); } else if (CpuFeatures.isX86_64Cpu()) { testBlocked(31); testAllowed(32); testBlocked(33); } else if (CpuFeatures.isX86Cpu()) { testBlocked(7); testAllowed(8); testBlocked(9); } else if (CpuFeatures.isMips64Cpu()) { testBlocked(5030); testAllowed(5031); testBlocked(5032); } else if (CpuFeatures.isMipsCpu()) { testBlocked(4032); testAllowed(4033); testBlocked(4034); } else { fail("Unsupported OS"); } }
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.security.cts; import android.test.AndroidTestCase; import com.android.compatibility.common.util.CpuFeatures; import junit.framework.TestCase; /** * Verify that the seccomp policy is enforced */ public class SeccompTest extends AndroidTestCase { static { System.loadLibrary("ctssecurity_jni"); } public void testCTSSyscallBlocked() { if (CpuFeatures.isArm64Cpu()) { // Test code here } } }
mPhone.notifyOtaspChanged(ServiceStateTracker.OTASP_SIM_UNPROVISIONED); // Tear down all metered apns cleanUpAllConnections(true, Phone.REASON_CARRIER_ACTION_DISABLE_METERED_APN); } else { teardownRestrictedMeteredConnections(); setupDataOnConnectableApns(Phone.REASON_DATA_ENABLED); } } private void onSimNotReady() { if (DBG) log("onSimNotReady"); // Clear auto attach as modem is expected to do a new attach once SIM is ready mAutoAttachOnCreation.set(false); cleanUpAllConnections(true, Phone.REASON_SIM_NOT_READY); mAllApnSettings = null; mAutoAttachOnCreationConfig = false; } private void onSetDependencyMet(String apnType, boolean met) { // don't allow users to tweak hipri to work around default dependency not met if (PhoneConstants.APN_TYPE_HIPRI.equals(apnType)) return; ApnContext apnContext = mApnContexts.get(apnType); if (apnContext == null) { loge("onSetDependencyMet: ApnContext not found in onSetDependencyMet(" + apnType + ", " + met + ")");
public void onChange(boolean selfChange) { mUserWantsSuspendOpt.set(Settings.Global.getInt(mContext.getContentResolver(), Settings.Global.WIFI_SUSPEND_OPTIMIZATIONS_ENABLED, 1) == 1); }
mSapProxy = getSapProxy(); } void notifyShutdown() { if (DEBUG) Log.i(TAG, "notifyShutdown()"); synchronized (this) { if (mSapProxy != null) sendShutdownMessage(); } } public void shutdown() { if (DEBUG) Log.i(TAG, "shutdown()"); synchronized (this) { if (mSapProxy != null) { mSapProxy = null; } } }
return null; WifiConfiguration[] configs = new WifiConfiguration[ssids.length]; for (int index = 0; index < ssids.length; index++) { int networkId = index; for (int k = 0; k < index; k++) { if (ssids[index].equals(ssids[k]) && (securities[index] == securities[k])) { networkId = k; break; } } configs[index] = generateWifiConfig(networkId, 0, ssids[index], false, true, null, null, securities[index]); } return configs;
private QualityOfService qos = QualityOfService.LOW; LinearLayout serverLayout; LinearLayout clientLayout; TextView resourceText; TextView actionLog; TextView resultLog; ToggleButton qosToggle; Button registerButton; Button getButton; Button putButton; Button largeButton; Button discoverIPButton; Button discoverBTButton; Button discoverLEButton; Button discoverTCPButton; Button discoverNFCButton; private String mLargeData; private boolean mState; private long mStartTime; private long mEndTime; private final double MILLI_PER_SEC = 1000.0; @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); mActivity = getActivity(); mContext = mActivity.getBaseContext(); } View.OnClickListener getButtonListener() { return new View.OnClickListener() { @Override public void onClick(View view) { if (foundResource != null) { mStartTime = System.currentTimeMillis(); sendGetToFoundResource(Common.STATE_GET); } else { // handle case when foundResource is null } } }; } colorSuggestor = new PrimaryDarkColorSuggestor(primaryColor); myColorPicker.setRecentColors(colorSuggestor.suggestColor()); } else if (attributeName.equals(ACCENT_MATERIAL)) { ResourceResolver resourceResolver = model.getSelectedStyle().getConfiguration().getResourceResolver(); ResourceValue rv = model.getSelectedStyle().getItemResourceValue(PRIMARY_MATERIAL); Color primaryColor = ResourceHelper.resolveColor(resourceResolver, rv); colorSuggestor = new AccentColorSuggestor(primaryColor); myColorPicker.setRecentColors(colorSuggestor.suggestColor()); } } if (color != null) { myContentPanel.setSelectedIndex(2); doSelection = false; } myValidator = ResourceNameValidator.create(false, AppResourceRepository.getAppResources(module, true), ResourceType.COLOR); if (doSelection && value.startsWith("@")) { value = StringUtil.replace(value, "+", ""); int index = value.indexOf('/'); if (index != -1) { ResourcePanel panel; String type; String name = value.substring(index + 1); if (value.startsWith(ANDROID)) { // handle case when value starts with ANDROID } } } String exceptionSignature = getExpectedExceptionSignature(fromNative); ReplyPacket replyPacket = debuggeeWrapper.vmMirror.setException(exceptionSignature, isCatch, isUncatch); int requestID = replyPacket.getNextValueAs
public class MacroSubstitutionNamingStrategy implements TestCaseNamingStrategy { private static final String MACRO_PATTERN = "\\{[^\\}]{0,50}\\}"; private static final Pattern MACRO_SPLIT_PATTERN = Pattern.compile(String.format("(?=%s)|(?<=%s)", MACRO_PATTERN, MACRO_PATTERN)); private static final String MACRO_START = "{"; private static final String MACRO_END = "}"; static final String DEFAULT_TEMPLATE = "{method}[{index}]"; private TestMethod method; public MacroSubstitutionNamingStrategy(TestMethod testMethod) { this.method = testMethod; } @Override public String getTestCaseName(int parametersIndex, Object parameters) { TestCaseName testCaseName = method.getAnnotation(TestCaseName.class); String template = getTemplate(testCaseName); String builtName = buildNameByTemplate(template, parametersIndex, parameters); return builtName; } private String getTemplate(TestCaseName testCaseName) { if (testCaseName != null) { return testCaseName.value(); } else { return DEFAULT_TEMPLATE; } } private String buildNameByTemplate(String template, int parametersIndex, Object parameters) { String[] parts = MACRO_SPLIT_PATTERN.split(template); StringBuilder builder = new StringBuilder(); for (String part : parts) { if (part.startsWith(MACRO_START) && part.endsWith(MACRO_END)) { String macro = part.substring(1, part.length() - 1); String value = getMacroValue(macro, parametersIndex, parameters); builder.append(value); } else { builder.append(part); } } return builder.toString(); } private String getMacroValue(String macro, int parametersIndex, Object parameters) { // Handle different macros here if (macro.equals("method")) { return method.getName(); } else if (macro.equals("index")) { return String.valueOf(parametersIndex); } else { return ""; } } }
import org.mockito.MockitoAnnotations; import org.mockito.stubbing.Answer; import java.net.InetAddress; import java.util.ArrayList; import java.util.Arrays; import java.util.List; import java.util.Random; /** * Unit tests for {@link com.android.server.wifi.WifiVendorHal}. */ public class WifiVendorHalTest { WifiVendorHal mWifiVendorHal; private WifiStatus mWifiStatusSuccess; private WifiStatus mWifiStatusFailure; WifiLog mWifiLog; @Mock private HalDeviceManager mHalDeviceManager; @Mock private Looper mLooper; @Mock private WifiVendorHal.HalDeviceManagerStatusListener mHalDeviceManagerStatusCallbacks; @Mock private IWifiApIface mIWifiApIface; @Mock private IWifiChip mIWifiChip; @Mock private IWifiStaIface mIWifiStaIface; @Mock private IWifiRttController mIWifiRttController; private IWifiStaIfaceEventCallback mIWifiStaIfaceEventCallback; private IWifiChipEventCallback mIWifiChipEventCallback; @Mock private WifiNative.VendorHalDeathEventHandler mVendorHalDeathHandler; /** * Identity function to supply a type to its argument, which is a lambda */ public void setUp() { MockitoAnnotations.initMocks(this); } }
Buggy Code: ```java public Collection<SubscribeSection> getInheritedSubscribeSections(Branch.NameKey branch) { Collection<SubscribeSection> ret = new ArrayList<>(); for (ProjectState s : tree()) { ret.addAll(s.getConfig().getSubscribeSections(branch)); } return ret; } ``` Fixed Code: ```java public Collection<SubscribeSection> getInheritedSubscribeSections(Branch.NameKey branch) { Collection<SubscribeSection> ret = new ArrayList<>(); for (ProjectState s : tree()) { ret.addAll(s.getConfig().getSubscribeSections(branch)); } return ret; } ``` Buggy Code: ```java LOG.info("running query " + query); if (query.isEmpty()) { throw new IllegalStateException("Cannot plan empty query in line: " + testCase.getStartingLineNum()); } TQueryCtx queryCtx = TestUtils.createQueryContext(dbName, System.getProperty("user.name")); queryCtx.client_request.query_options = options; // Test single node plan, scan range locations, and column lineage. TExecRequest singleNodeExecRequest = testPlan(testCase, Section.PLAN, queryCtx, ignoreExplainHeader, errorLog, actualOutput); validateTableIds(singleNodeExecRequest); checkScanRangeLocations(testCase, singleNodeExecRequest, errorLog, actualOutput); checkColumnLineage(testCase, singleNodeExecRequest, errorLog, actualOutput); checkLimitCardinality(query, singleNodeExecRequest, errorLog); // Test distributed plan. testPlan(testCase, Section.DISTRIBUTEDPLAN, queryCtx, ignoreExplainHeader, errorLog, actualOutput); // test parallel plans testPlan(testCase, Section.PARALLELPLANS, queryCtx, ignoreExplainHeader, errorLog, actualOutput); } /** * Validate that all tables in the descriptor table of 'request' have a unique id and ``` Fixed Code: ```java LOG.info("running query " + query); if (query.isEmpty()) { throw new IllegalStateException("Cannot plan empty query in line: " + testCase.getStartingLineNum()); } TQueryCtx queryCtx = TestUtils.createQueryContext(dbName, System.getProperty("user.name")); queryCtx.client_request.query_options = options; // Test single node plan, scan range locations, and column lineage. TExecRequest singleNodeExecRequest = testPlan(testCase, Section.PLAN, queryCtx, ignoreExplain
sendMessage(CMD_DISCONNECT); break; case WifiManager.CONNECT_NETWORK: netId = message.arg1; config = (WifiConfiguration) message.obj; mWifiConnectionStatistics.numWifiManagerJoinAttempt++; if (config != null) { result = mWifiConfigManager.addOrUpdateNetwork(config, message.sendingUid); if (!result.isSuccess()) { loge("CONNECT_NETWORK adding/updating config=" + config + " failed"); messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL; replyToMessage(message, WifiManager.CONNECT_NETWORK_FAILED, WifiManager.ERROR); break; } netId = result.getNetworkId(); } if (!connectToUserSelectNetwork(netId, message.sendingUid))
netId = message.arg1; config = (WifiConfiguration) message.obj; mWifiConnectionStatistics.numWifiManagerJoinAttempt++; // New network addition. if (config != null) { result = mWifiConfigManager.addOrUpdateNetwork(config, message.sendingUid); if (!result.isSuccess()) { loge("CONNECT_NETWORK adding/updating config=" + config + " failed"); messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL; replyToMessage(message, WifiManager.CONNECT_NETWORK_FAILED, WifiManager.ERROR); break; } netId = result.getNetworkId(); } if (!connectToUserSelectNetwork(netId, message.sendingUid)) { messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL; replyToMessage(message, WifiManager.CONNECT_NETWORK_FAILED, WifiManager.ERROR); break; }
newNetwork || WifiConfigurationUtil.hasCredentialChanged(existingInternalConfig, newInternalConfig); boolean hasIpChanged = newNetwork || WifiConfigurationUtil.hasIpChanged(existingInternalConfig, newInternalConfig); boolean hasProxyChanged = newNetwork || WifiConfigurationUtil.hasProxyChanged(existingInternalConfig, newInternalConfig); if (hasCredentialChanged) { newInternalConfig.getNetworkSelectionStatus().setHasEverConnected(false); } mConfiguredNetworks.put(newInternalConfig); if (mDeletedEphemeralSSIDs.remove(config.SSID)) { if (mVerboseLoggingEnabled) { Log.v(TAG, "Removed from ephemeral blacklist: " + config.SSID); } } mBackupManagerProxy.notifyDataChanged(); NetworkUpdateResult result = new NetworkUpdateResult(hasIpChanged, hasProxyChanged, hasCredentialChanged); result.setIsNewNetwork(newNetwork);
public ISap getSapProxy() { if (mSapProxy != null) { return mSapProxy; } try { mSapProxy = ISap.getService(SOCKET_NAME_RIL_BT); if (mSapProxy != null) { mSapProxy.linkToDeath(mSapProxyDeathRecipient, mSapProxyCookie.incrementAndGet()); mSapProxy.setCallback(mSapCallback); } else { Log.e(TAG, "getSapProxy: mSapProxy == null"); } } catch (RemoteException | RuntimeException e) { mSapProxy = null; Log.e(TAG, "getSapProxy: exception: " + e); } if (mSapProxy == null) { // if service is not up, treat it like death notification to try to get service again mSapServerMsgHandler.sendMessageDelayed( mSapServerMsgHandler.obtainMessage(SapServer.SAP_PROXY_DEAD, mSapProxyCookie.get()), SapServer.ISAP_GET_SERVICE_DELAY_MILLIS); } return mSapProxy; }
" mtu=" + mtu + " status=" + status); if (!address.equals(mDevice.getAddress())) { return; } try { mCallback.onMtuChanged(BluetoothGatt.this, mtu, status); } catch (Exception ex) { Log.w(TAG, "Unhandled exception in callback", ex); } } /** * Callback invoked when the given connection is updated * @hide */ public void onConnectionParametersUpdated(String address, int interval, int latency, int timeout, int status) { if (DBG) Log.d(TAG, "onConnectionUpdated() - Device=" + address + " interval=" + interval + " latency=" + latency + " timeout=" + timeout + " status=" + status); if (!address.equals(mDevice.getAddress())) { return; } try { mCallback.onConnectionUpdated(BluetoothGatt.this, interval, latency, timeout, status); } catch (Exception ex) { Log.w(TAG, "Unhandled exception in callback", ex); } } };
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.server; import static android.Manifest.permission.DUMP; import static android.Manifest.permission.SHUTDOWN; import android.content.Context; import android.net.IIpSecService; import android.net.INetd; import android.os.Binder; import android.os.Handler; import android.os.Process; import android.os.RemoteException; import android.os.ServiceManager; import android.util.Log; import java.io.FileDescriptor; import java.io.PrintWriter;
import java.util.concurrent.CountDownLatch; /** @hide */ public class IpSecService extends IIpSecService.Stub implements Watchdog.Monitor { private static final String TAG = "IpSecService"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_TAG = "NetdConnector"; private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; /** connector object for communicating with netd */ private final NativeDaemonConnector mConnector; private final Handler mFgHandler; private INetd mNetdService; private final Thread mThread; private CountDownLatch mConnectedSignal = new CountDownLatch(1); /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; // make sure this is on the same looper as our NativeDaemonConnector for sync purposes mFgHandler = new Handler(FgThread.get().getLooper()); mConnector = new NativeDaemonConnector(this, socket, 10, NETD_TAG, 160, null); mThread = new Thread(mConnector, NETD_TAG); } }
private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_TAG = "NetdConnector"; private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; /** connector object for communicating with netd */ private final NativeDaemonConnector mConnector; private final Handler mFgHandler; private INetd mNetdService; private final Thread mThread; private CountDownLatch mConnectedSignal = new CountDownLatch(1); /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; // make sure this is on the same looper as our NativeDaemonConnector for sync purposes mFgHandler = new Handler(FgThread.get().getLooper()); mConnector = new NativeDaemonConnector( new NetdCallbackReceiver(), socket, 10, NETD_TAG, 160, null /*wakelock*/, FgThread.get().getLooper()); }
public void systemReady() { if (DBG) { final long start = System.currentTimeMillis(); prepareNativeDaemon(); final long delta = System.currentTimeMillis() - start; Log.d(TAG, "Prepared in " + delta + "ms"); return; } else { prepareNativeDaemon(); } }
private void connectNativeNetdService() { mNetdService = INetd.Stub.asInterface(ServiceManager.getService(NETD_SERVICE_NAME)); if (!isNetdAlive()) { Log.wtf(TAG, "Can't connect to NativeNetdService " + NETD_SERVICE_NAME); } }
assertEquals(RESULT_PASS, appEndReceiver.waitForActivity()); appEndReceiver.close(); if (!noHomeScreen()) { assertEquals(RESULT_TIMEOUT, timeReceiver.waitForActivity()); assertTrue(timeReceiver.mTimeUsed == 0); } else { assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); } final Intent dummyIntent = new Intent(context, MockApplicationActivity.class); dummyIntent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK);
public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { mActiveDownstreams.offer(new Downstream(downstream, mNextSubnetId)); mNextSubnetId = Math.max(0, mNextSubnetId + 1); updateIPv6TetheringInterfaces(); } }
// (which extends it). SYSTEM_SERVICE_NAMES.put(android.text.ClipboardManager.class, Context.CLIPBOARD_SERVICE); registerService(Context.CONNECTIVITY_SERVICE, ConnectivityManager.class, new StaticApplicationContextServiceFetcher<ConnectivityManager>() { @Override public ConnectivityManager createService(Context context) { IBinder b = ServiceManager.getService(Context.CONNECTIVITY_SERVICE); IConnectivityManager service = IConnectivityManager.Stub.asInterface(b); return new ConnectivityManager(context, service); } }); registerService(Context.IPSEC_SERVICE, IpSecManager.class, new StaticApplicationContextServiceFetcher<IpSecManager>() { @Override public IpSecManager createService(Context context) { IBinder b = ServiceManager.getService(Context.IPSEC_SERVICE); IIpSecService service = IIpSecService.Stub.asInterface(b); return new IpSecManager(context, service); } }); registerService(Context.COUNTRY_DETECTOR, CountryDetector.class, new StaticServiceFetcher<CountryDetector>() { @Override public CountryDetector createService() { IBinder b = ServiceManager.getService(Context.COUNTRY_DETECTOR); return new CountryDetector(ICountryDetector.Stub.asInterface(b)); } }); registerService(Context.DEVICE_POLICY_SERVICE, DevicePolicyManager.class, new StaticServiceFetcher<DevicePolicyManager>() { @Override public DevicePolicyManager createService() { return new DevicePolicyManager(); } });
public IpSecManager createService(Context context) { IBinder b = ServiceManager.getService(Context.IPSEC_SERVICE); IIpSecService service = IIpSecService.Stub.asInterface(b); return new IpSecManager(context, service); }
import android.os.RemoteException; import android.util.Log; import android.util.Slog; import java.io.FileDescriptor; import java.io.PrintWriter; /** @hide */ public class IpSecService extends IIpSecService.Stub { private static final String TAG = "IpSecService"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 1000; //ms /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; } static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); service.connectNativeNetdService(); return service; } public static IpSecService create(Context context) throws InterruptedException { synchronized (IpSecService.class) { final IpSecService service = new IpSecService(context, null); service.connectNativeNetdService(); return service; } } }
import android.util.Slog; import java.io.FileDescriptor; import java.io.PrintWriter; public class IpSecService extends IIpSecService.Stub { private static final String TAG = "IpSecService"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_SERVICE_NAME = "netd"; private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 1000; //ms private IpSecService(Context context, String socket) { mContext = context; } static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); service.connectNativeNetdService(); return service; } public static IpSecService create(Context context) throws InterruptedException { return create(context, NETD_SERVICE_NAME); } }
protected Vpn(Looper looper, Context context, INetworkManagementService netService, int userHandle, SystemServices systemServices) { mContext = context; mNetd = netService; mUserHandle = userHandle; mLooper = looper; mSystemServices = systemServices; mPackage = VpnConfig.LEGACY_VPN; mOwnerUID = getAppUid(mPackage, mUserHandle); loadAlwaysOnPackage(); try { netService.registerObserver(mObserver); } catch (RemoteException e) { Log.wtf(TAG, "Problem registering observer", e); } mNetworkInfo = new NetworkInfo(ConnectivityManager.TYPE_VPN, 0, NETWORKTYPE, ""); // TODO: Copy metered attribute and bandwidths from physical transport, b/16207332 mNetworkCapabilities = new NetworkCapabilities(); mNetworkCapabilities.addTransportType(NetworkCapabilities.TRANSPORT_VPN); mNetworkCapabilities.removeCapability(NetworkCapabilities.NET_CAPABILITY_NOT_VPN); }
package com.example.android.toyvpn; import android.app.Activity; import android.content.Intent; import android.content.SharedPreferences; import android.net.VpnService; import android.os.Bundle; import android.widget.TextView; public class ToyVpnClient extends Activity { public interface Prefs { String NAME = "connection"; String SERVER_ADDRESS = "server.address"; String SERVER_PORT = "server.port"; String SHARED_SECRET = "shared.secret"; } @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.form); final TextView serverAddress = findViewById(R.id.address); final TextView serverPort = findViewById(R.id.port); final TextView sharedSecret = findViewById(R.id.secret); } }
private static final long IDLE_INTERVAL_MS = TimeUnit.MILLISECONDS.toMillis(100); private static final int MAX_HANDSHAKE_ATTEMPTS = 50; private final VpnService mService; private final int mConnectionId; private final String mServerName; private final int mServerPort; private final byte[] mSharedSecret; private PendingIntent mConfigureIntent; private OnEstablishListener mOnEstablishListener; public ToyVpnConnection(final VpnService service, final int connectionId, final String serverName, final int serverPort, final byte[] sharedSecret) { mService = service; mConnectionId = connectionId; mServerName = serverName; mServerPort = serverPort; mSharedSecret = sharedSecret; }
} catch (Exception e) { Log.e(getTag(), "Connection failed, exiting", e); } private boolean run(SocketAddress server) throws Exception { ParcelFileDescriptor iface = null; boolean connected = false; // Create a DatagramChannel as the VPN tunnel. try (DatagramChannel tunnel = DatagramChannel.open()) { // Protect the tunnel before connecting to avoid loopback. if (!mService.protect(tunnel.socket())) { throw new IllegalStateException("Cannot protect the tunnel for"); } // Connect to the server. tunnel.connect(server); // For simplicity, we use the same thread for both reading and writing. // Here we put the tunnel into non-blocking mode. tunnel.configureBlocking(false); // Authenticate and configure the virtual network interface. iface = handshake(tunnel); // Now we are connected. Set the flag. connected = true; // Packets to be sent are queued in this input stream. FileInputStream in = new FileInputStream(iface.getFileDescriptor()); }
public void sendDataToTunnel(SocketChannel tunnel, ByteBuffer packet) throws IOException, InterruptedException { packet.position(0); tunnel.write(packet); packet.clear(); for (int i = 0; i < MAX_HANDSHAKE_ATTEMPTS; ++i) { Thread.sleep(IDLE_INTERVAL_MS); int length = tunnel.read(packet); if (length > 0 && packet.get(0) == 0) { return configure(new String(packet.array(), 1, length - 1).trim()); } } throw new IllegalStateException("Timed out"); } private ParcelFileDescriptor configure(String parameters) throws Exception { VpnService.Builder builder = mService.new Builder(); for (String parameter : parameters.split(" ")) { String[] fields = parameter.split(","); switch (fields[0].charAt(0)) { case 'm': builder.setMtu(Short.parseShort(fields[1])); break; case 'a': builder.addAddress(fields[1], Integer.parseInt(fields[2])); break; // add other cases for configuring the builder } } // configure other settings and return the ParcelFileDescriptor }
packet.position(0); tunnel.write(packet); packet.clear(); // Wait for the parameters within a limited time. for (int i = 0; i < MAX_HANDSHAKE_ATTEMPTS; ++i) { Thread.sleep(IDLE_INTERVAL_MS); // Normally we should not receive random packets. int length = tunnel.read(packet); if (length > 0 && packet.get(0) == 0) { return configure(new String(packet.array(), 1, length - 1, "UTF-8").trim()); } } throw new IllegalStateException("Timed out"); } private ParcelFileDescriptor configure(String parameters) throws Exception { // Configure a builder while parsing the parameters. VpnService.Builder builder = mService.new Builder(); for (String parameter : parameters.split(" ")) { String[] fields = parameter.split(","); try { switch (fields[0].charAt(0)) { case 'm': builder.setMtu(Short.parseShort(fields[1])); break; case 'a': builder.addAddress(fields[1], Integer.parseInt(fields[2])); break; case 'r': builder.addRoute(fields[1], Integer.parseInt(fields[2])); break; case 'd': builder.addDnsServer(fields[1]); break; case 's': builder.setSession(fields[1]); break; default: throw new IllegalArgumentException("Unknown parameter: " + fields[0]); } } catch (NumberFormatException e) { throw new IllegalArgumentException("Bad parameter: " + parameter); } } return builder.establish(); }
private void setConnectingThread(final Thread thread) { final Thread oldThread = mConnectingThread.getAndSet(thread); if (oldThread != null) { try { oldThread.interrupt(); } catch (Throwable t) { Log.e(TAG, "Interrupting thread", t); } } }
private void setConnection(final Connection connection) { final Connection oldConnection = mConnection.getAndSet(connection); if (oldConnection != null) { try { oldConnection.first.interrupt(); oldConnection.second.close(); } catch (Exception e) { Log.e(TAG, "Interrupting thread", e); } } }
public static int inlineMonomorphic(Main a) { if (a == null) { return 42; } int i = 0; while (i < 100) { i += a.getValue(); } return i; } public static int inlinePolymorphic(Main a) { return a.getValue(); } public int getValue() { return value; }
mNetworkFactory = new WifiNetworkFactory(getHandler().getLooper(), mContext, NETWORKTYPE, mNetworkCapabilitiesFilter); mNetworkFactory.setScoreFilter(60); mNetworkFactory.register(); mUntrustedNetworkFactory = new UntrustedWifiNetworkFactory(getHandler().getLooper(), mContext, NETWORKTYPE_UNTRUSTED, mNetworkCapabilitiesFilter); mUntrustedNetworkFactory.setScoreFilter(Integer.MAX_VALUE); mUntrustedNetworkFactory.register(); /** * WifiStateMachine needs to enable/disable other services when wifi is in client mode. This * method allows WifiStateMachine to get these additional system services. * * At this time, this method is used to setup variables for P2P service and Wifi Aware. */ private void getAdditionalWifiServiceInterfaces() { // First set up Wifi Direct if (mP2pSupported) { IBinder s1 = mFacade.getService(Context.WIFI_P2P_SERVICE); WifiP2pServiceImpl wifiP2pServiceImpl =
public void close() throws IOException { if (closed) { return; } closed = true; try { obuffer = cipher.doFinal(); } catch (IllegalBlockSizeException | BadPaddingException e) { obuffer = null; throw new IOException(e); } try { flush(); } catch (IOException ignored) {} out.close(); }
setAndBroadcastNetworkSetTime(mSavedTime + (currTime - mSavedAtTime)); } private void revertToNitzTimeZone() { if (Settings.Global.getInt(mCr, Settings.Global.AUTO_TIME_ZONE, 0) == 0) { return; } String tmpLog = "Reverting to NITZ TimeZone: tz=" + mSavedTimeZone; if (DBG) log(tmpLog); mTimeZoneLog.log(tmpLog); if (mSavedTimeZone != null) { setAndBroadcastNetworkSetTimeZone(mSavedTimeZone); } } @VisibleForTesting public void setNotification(int notifyType) { if (DBG) log("setNotification: create notification " + notifyType); boolean isSetNotification = mPhone.getContext().getResources().getBoolean(com.android.internal.R.bool.config_user_notification_of_restrictied_mobile_access); }
public void setNotification(int notifyType) { if (DBG) log("setNotification: create notification " + notifyType); boolean isSetNotification = mPhone.getContext().getResources().getBoolean(com.android.internal.R.bool.config_user_notification_of_restrictied_mobile_access); if (!isSetNotification) { if (DBG) log("Ignore all the notifications"); return; } Context context = mPhone.getContext(); CarrierConfigManager configManager = (CarrierConfigManager) context.getSystemService(Context.CARRIER_CONFIG_SERVICE); if (configManager != null) { PersistableBundle bundle = configManager.getConfig(); if (bundle != null) { boolean disableVoiceBarringNotification = bundle.getBoolean(CarrierConfigManager.KEY_DISABLE_VOICE_BARRING_NOTIFICATION_BOOL, false); if (disableVoiceBarringNotification && (notifyType == CS_ENABLED || notifyType == CS_NORMAL_ENABLED || notifyType == CS_EMERGENCY_ENABLED)) { if (DBG) log("Voice/emergency call barred notification disabled"); return; } } } CharSequence details = ""; // rest of the code }
public void clearBlacklistForForcedConnection(int netId) { localLog("clearBlacklistForForcedConnection: netId=" + netId); clearConnectionAttemptTimeStamps(); clearBssidBlacklist(); }
long timeStamp = clock.getElapsedSinceBootMillis(); for (int index = 0; index < ssids.length; index++) { ScanDetail scanDetail = new ScanDetail(WifiSsid.createFromAsciiEncoded(ssids[index]), bssids[index], caps[index], levels[index], freqs[index], timeStamp, 0); scanDetailList.add(scanDetail); } return scanDetailList; } /** * Generate an array of {@link android.net.wifi.WifiConfiguration} based on the caller * supplied network SSID and security information. * * @param ssids an array of SSIDs * @param securities an array of the network's security setting * @return the constructed array of {@link android.net.wifi.WifiConfiguration} */ public static WifiConfiguration[] generateWifiConfigurations(String[] ssids, int[] securities) { if (ssids == null || securities == null || ssids.length != securities.length || ssids.length == 0) { return null; } Map<String, Integer> netIdMap = new HashMap<>(); int netId = 0;
private void readConfiguration() { String configEntry = cfgFactory.getFromGerritConfig(CHARSET_VALIDATOR) .getString("branch_regex", "^[a-z0-9_\\-/]+$"); if (regexpPattern == null || regexpPattern.hashCode() != configEntry.hashCode()) { okCharPattern = Pattern.compile(configEntry); regexpPattern = configEntry; } rejectReasonBranch = cfgFactory.getFromGerritConfig(CHARSET_VALIDATOR) .getString("branch_reject_reason", "Sorry, your branch is not valid."); rejectReasonCharset = cfgFactory.getFromGerritConfig(CHARSET_VALIDATOR) .getString("charset_reject_reason", "Sorry, your commit has non UTF8 content."); internalErrorMessage = cfgFactory.getFromGerritConfig(CHARSET_VALIDATOR) .getString("internal_error_message", "CharSetValidator failed to validate your commit."); fastUtf8Check = cfgFactory.getFromGerritConfig(CHARSET_VALIDATOR) .getBoolean("fast_utf8_check", true); validateUtf8 = cfgFactory.getFromGerritConfig(CHARSET_VALIDATOR) .getBoolean("validate_utf8", true); PluginConfig cfg = cfgFactory.getFromProjectConfig(); } throw new ResourceConflictException("change is " + status(change)); } else if (change.getStatus() == Change.Status.DRAFT) { throw new ResourceConflictException("draft changes cannot be abandoned"); } final AtomicReference<Change> updatedChange = new AtomicReference<>(); ChangeUpdate update; bu.addChangeOp(new ChangeOp(control) { @Override public void call(ReviewDb db, ChangeUpdate update) throws Exception { updatedChange.set(db.changes().atomicUpdate(change.getId(), new AtomicUpdate<Change>() { @Override public Change update(Change change) { if (change.getStatus().isOpen()) { change.setStatus(Change.Status.ABANDONED); ChangeUtil.updated(change); return change; } return null; } })); if (c == null) { throw new ResourceConflictException("change is " + status(db.changes().get(req.getChange().getId()))); } ChangeMessage message; //TODO(yyonas): atomic update was not propagated } }); public void cleanup() { db.close(); } @Test public void messagesNotReturned
MAXIMUM_POOL_SIZE, KEEP_ALIVE_SECONDS, TimeUnit.SECONDS, workQueue); for (int i = 1; i < mPackages.size(); i++) { final AppPrefLoader loader = new AppPrefLoader(); loader.executeOnExecutor(executor, mPackages.valueAt(i)); } } else { removePreference(KEY_APP_LIST); } } else { final Context context = getActivity(); UidDetail uidDetail = new UidDetailProvider(context).getUidDetail(mAppItem.key, true); mIcon = uidDetail.icon; mLabel = uidDetail.label; mPackageName = context.getPackageName(); removePreference(KEY_UNRESTRICTED_DATA); removePreference(KEY_APP_SETTINGS); removePreference(KEY_RESTRICT_BACKGROUND); removePreference(KEY_APP_LIST); }
private void setConnectingThread(final Thread thread) { final Thread oldThread = mConnectingThread.getAndSet(thread); if (oldThread != null) { try { oldThread.interrupt(); } catch (SecurityException e) { Log.e(TAG, "Interrupting thread", e); } } }
*/ @HasKeyId @Name("BoostLockedRegionPriorityFeature") @Description("Feature turning on BoostLockedRegionPriorityFeature") public final class BoostLockedRegionPriorityFeature implements Feature { @Nonnull public static final BooleanPropertyId ENABLE = BooleanPropertyId.create( "jack.transformations.boost-locked-region-priority", "Boost priority of threads acquiring certain locks") .addCategory(Private.class) .addDefaultValue(Boolean.FALSE) .addCategory(DumpInLibrary.class); @Nonnull public static final PropertyId<String> BOOST_LOCK_CLASSNAME = PropertyId.create( "jack.transformations.boost-locked-region-priority.classname", "The class signatures where acquiring it as a lock should boost a thread's prioirty", new ClassNameCodec()) .requiredIf(BoostLockedRegionPriorityFeature.ENABLE.getValue().isTrue()) .addCategory(Private.class) .addCategory(DumpInLibrary.class); @Nonnull public static final PropertyId<List<MethodNameValue>> BOOST_LOCK_REQUEST_METHOD = PropertyId.create( "jack.transformations.boost-locked-region-priority.request", "Static methods in the specified classes that can boost a thread's prioirty", new ListCodec<>(new MethodNameValueCodec())) .requiredIf(BoostLockedRegionPriorityFeature.ENABLE.getValue().isTrue()) .addCategory(Private.class) .addCategory(DumpInLibrary.class);
Jack.getSession().getReporter().report(Severity.FATAL, new BadBoostLockedRegionPriorityConfigurationException(prop, e)); Jack.getSession().abortEventually(); return null; } @Override public void run(@Nonnull JMethod method) { if (method.isNative() || method.isAbstract() || !filter.accept(this.getClass(), method)) { return; } if (lockClass == null || requestClass == null || resetClass == null || requestMethodId == null || resetMethodId == null) { return; } TransformationRequest tr = new TransformationRequest(method); Visitor visitor = new Visitor(method, tr); visitor.accept(method); tr.commit(); } private class Visitor extends JVisitor { @Nonnull private final JMethod method; @Nonnull private final TransformationRequest tr; public Visitor(@Nonnull JMethod method, @Nonnull TransformationRequest tr) { this.method = method; this.tr = tr; } @Override public void endVisit(@Nonnull JLock jLock) { assert lockClass != null; int lockIndex = -1; // rest of the code } }
public static boolean deepEquals(Object lft, Object rgt) { if (lft == rgt) { return true; } if (lft == null || rgt == null) { return false; } Class<?> lftClazz = lft.getClass(); Class<?> rgtClazz = rgt.getClass(); if (lftClazz != rgtClazz) { return false; } if (lftClazz.isArray()) { Class<?> lftElementType = lftClazz.getComponentType(); if (lftElementType != rgtClazz.getComponentType()) { return false; } if (lftElementType.isPrimitive()) { if (lftElementType == boolean.class) { return Arrays.equals((boolean[]) lft, (boolean[]) rgt); } else if (lftElementType == byte.class) { return Arrays.equals((byte[]) lft, (byte[]) rgt); } else if (lftElementType == char.class) { return Arrays.equals((char[]) lft, (char[]) rgt); } else if (lftElementType == short.class) { return Arrays.equals((short[]) lft, (short[]) rgt); } else if (lftElementType == int.class) { return Arrays.equals((int[]) lft, (int[]) rgt); } else if (lftElementType == long.class) { return Arrays.equals((long[]) lft, (long[]) rgt); } else if (lftElementType == float.class) { return Arrays.equals((float[]) lft, (float[]) rgt); } else if (lftElementType == double.class) { return Arrays.equals((double[]) lft, (double[]) rgt); } } else { Object[] lftArray = (Object[]) lft; Object[] rgtArray = (Object[]) rgt; if (lftArray.length != rgtArray.length) { return false; } for (int i = 0; i < lftArray.length; i++) { if (!deepEquals(lftArray[i], rgtArray[i])) { return false; } } return true; } } else if (lft instanceof List && rgt instanceof List) { List<?> lftList = (List<?>)
public static boolean deepEquals(Object lft, Object rgt) { if (lft == rgt) { return true; } if (lft == null || rgt == null) { return false; } Class<?> lftClazz = lft.getClass(); Class<?> rgtClazz = rgt.getClass(); if (lftClazz != rgtClazz) { return false; } if (lftClazz.isArray()) { Class<?> lftElementType = lftClazz.getComponentType(); if (lftElementType != rgtClazz.getComponentType()) { return false; } if (lftElementType.isPrimitive()) { if (lftElementType == boolean.class) { return Arrays.equals((boolean[]) lft, (boolean[]) rgt); } else if (lftElementType == byte.class) { return Arrays.equals((byte[]) lft, (byte[]) rgt); } else if (lftElementType == char.class) { return Arrays.equals((char[]) lft, (char[]) rgt); } else if (lftElementType == short.class) { return Arrays.equals((short[]) lft, (short[]) rgt); } else if (lftElementType == int.class) { return Arrays.equals((int[]) lft, (int[]) rgt); } else if (lftElementType == long.class) { return Arrays.equals((long[]) lft, (long[]) rgt); } else if (lftElementType == float.class) { return Arrays.equals((float[]) lft, (float[]) rgt); } else if (lftElementType == double.class) { return Arrays.equals((double[]) lft, (double[]) rgt); } } else { Object[] lftArray = (Object[]) lft; Object[] rgtArray = (Object[]) rgt; if (lftArray.length != rgtArray.length) { return false; } for (int i = 0; i < lftArray.length; i++) { if (!deepEquals(lftArray[i], rgtArray[i])) { return false; } } return true; } } else if (lft instanceof List && rgt instanceof List) { List<?> lftList = (List<?>)
* Two objects of HIDL types are considered equal if: * 1. Both null * 2. Both non-null, and of the same class, and: * 2.1 Both are primitive arrays / enum arrays, elements are equal using == check * 2.2 Both are object arrays, elements are checked recursively * 2.3 Both are Lists, elements are checked recursively * 2.4 (If both are collections other than lists or maps, undefined behavior) * 2.5 .equals return true */ public static boolean deepEquals(Object lft, Object rgt) { if (lft == rgt) { return true; } if (lft == null || rgt == null) { return false; } Class<?> lftClazz = lft.getClass(); Class<?> rgtClazz = rgt.getClass(); if (lftClazz != rgtClazz) { return false; } if (lftClazz.isArray()) { Class<?> lftElementType = lftClazz.getComponentType(); if (lftElementType != rgtClazz.getComponentType()) { return false; } // Rest of the code... } // Rest of the code... }
import java.io.File; import android.os.StrictMode; import dalvik.system.VMRuntime; String invokeWith = null; if ((app.info.flags & ApplicationInfo.FLAG_DEBUGGABLE) != 0) { String wrapperFileName = app.info.nativeLibraryDir + "/wrap.sh"; StrictMode.ThreadPolicy oldPolicy = StrictMode.allowThreadDiskReads(); try { if (new File(wrapperFileName).exists()) { invokeWith = "/system/bin/logwrapper " + wrapperFileName; } } finally { StrictMode.setThreadPolicy(oldPolicy); } } String requiredAbi = (abiOverride != null) ? abiOverride : app.info.primaryCpuAbi; if (requiredAbi == null) { requiredAbi = Build.SUPPORTED_ABIS[0]; } String instructionSet = null; if (app.info.primaryCpuAbi != null) { instructionSet = VMRuntime.getInstructionSet(app.info.primaryCpuAbi); } app.gids = gids; app.requiredAbi = requiredAbi; app.instructionSet = instructionSet; // Start the process. It will either succeed and return a result containing...
loge("setWfcSetting(): ", e); } } } public void setWfcSettingForSlot(boolean enabled) { int value = enabled ? 1 : 0; android.provider.Settings.Global.putInt(mContext.getContentResolver(), android.provider.Settings.Global.WFC_IMS_ENABLED, value); setWfcSettingInternalForSlot(enabled, getWfcModeForSlot()); } public void setWfcSettingInternalForSlot(boolean enabled, int wfcMode) { int imsFeatureValue = enabled ? ImsConfig.FeatureValueConstants.ON : ImsConfig.FeatureValueConstants.OFF; int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig.WfcModeFeatureValueConstants.CELLULAR_PREFERRED; try { ImsConfig config = getConfigInterface(); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI, TelephonyManager.NETWORK_TYPE_IWLAN, imsFeatureValue); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI_PREFERRED, TelephonyManager.NETWORK_TYPE_IWLAN, imsFeatureValue); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI_PREFERRED, ImsConfig.WfcModeFeatureValueConstants.WIFI_PREFERRED, imsWfcModeFeatureValue); } catch (ImsException e) { loge("setWfcSettingInternalForSlot(): ", e); } }
public void setWfcSettingForSlot(boolean enabled) { int value = enabled ? 1 : 0; android.provider.Settings.Global.putInt(mContext.getContentResolver(), android.provider.Settings.Global.WFC_IMS_ENABLED, value); setWfcSettingInternalForSlot(enabled, getWfcModeForSlot()); } public void setWfcSettingInternalForSlot(boolean enabled, int wfcMode) { int imsFeatureValue = enabled ? ImsConfig.FeatureValueConstants.ON : ImsConfig.FeatureValueConstants.OFF; int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig.WfcModeFeatureValueConstants.CELLULAR_PREFERRED; try { ImsConfig config = getConfigInterface(); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI, TelephonyManager.NETWORK_TYPE_IWLAN, imsFeatureValue); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI_PREFERRED, TelephonyManager.NETWORK_TYPE_IWLAN, imsFeatureValue); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI_PREFERRED, TelephonyManager.NETWORK_TYPE_LTE, imsFeatureValue); config.setWfcMode(ImsConfig.WfcModeFeatureValueConstants.CELLULAR_PREFERRED); config.setWfcMode(ImsConfig.WfcModeFeatureValueConstants.WIFI_PREFERRED); config.setWfcMode(imsWfcModeFeatureValue); } catch (ImsException e) { loge("setWfcSettingInternalForSlot(): ", e); } }
private void setWfcSettingInternalForSlot(boolean enabled, int wfcMode) { int imsFeatureValue = enabled ? ImsConfig.FeatureValueConstants.ON : ImsConfig.FeatureValueConstants.OFF; int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig.WfcModeFeatureValueConstants.CELLULAR_PREFERRED; try { ImsConfig config = getConfigInterface(); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI, TelephonyManager.NETWORK_TYPE_IWLAN, imsFeatureValue, mImsConfigListener); if (enabled) { log("setWfcSettingForSlot() : turnOnIms"); turnOnIms(); } else if (isTurnOffImsAllowedByPlatformForSlot() && (!isVolteEnabledByPlatformForSlot() || !isEnhanced4gLteModeSettingEnabledByUserForSlot())) { log("setWfcSettingForSlot() : imsServiceAllowTurnOff -> turnOffIms"); turnOffIms(); } setWfcModeInternalForSlot(imsWfcModeFeatureValue); } catch (ImsException e) { loge("setWfcSettingForSlot(): ", e); } }
/** * <h3>Developer Guides</h3> * <p>For more information about using Bluetooth, read the * <a href="{@docRoot}guide/topics/connectivity/bluetooth.html">Bluetooth</a> developer guide.</p> * </div> * * {@see BluetoothServerSocket} * {@see java.io.InputStream} * {@see java.io.OutputStream} */ public final class BluetoothSocket implements Closeable { private static final String TAG = "BluetoothSocket"; private static final boolean DBG = true; private static final boolean VDBG = Log.isLoggable(TAG, Log.VERBOSE); /** @hide */ public static final int MAX_RFCOMM_CHANNEL = 30; /*package*/ static final int MAX_L2CAP_PACKAGE_SIZE = 0xFFFF; /** RFCOMM socket */ public static final int TYPE_RFCOMM = 1; /** SCO socket */ public static final int TYPE_SCO = 2; /** L2CAP socket */ public static final int TYPE_L2CAP = 3; /*package*/ static final int EBADFD = 77; /*package*/ static final int EADDRINUSE = 98; }
public NetworkCapabilities setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier != null && Long.bitCount(mTransportTypes) != 1) { throw new IllegalStateException("Must have a single transport specified to use setNetworkSpecifier"); } if (mNetworkSpecifier != null) { throw new IllegalStateException("Network specifier already set"); } if (networkSpecifier != null && !(networkSpecifier instanceof Parcelable)) { throw new IllegalArgumentException("Network specifier must be parcelable"); } mNetworkSpecifier = networkSpecifier; return this; }
public boolean equals(Object o) { return o instanceof MatchAllNetworkSpecifier; }
public NetworkCapabilities setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier != null && Long.bitCount(mTransportTypes) != 1) { throw new IllegalStateException("Must have a single transport specified to use setNetworkSpecifier"); } if (networkSpecifier != null && !(networkSpecifier instanceof Parcelable)) { throw new IllegalArgumentException("Network specifier must be parcelable"); } mNetworkSpecifier = networkSpecifier; return this; }
private boolean satisfiedBySpecifier(NetworkCapabilities nc) { return mNetworkSpecifier == null || mNetworkSpecifier.satisfiedBy(nc.mNetworkSpecifier) || nc.mNetworkSpecifier instanceof MatchAllNetworkSpecifier; }
public LSMInvertedIndexDiskComponent(IInvertedIndex invIndex, BTree deletedKeysBTree, BloomFilter bloomFilter, ILSMComponentFilter filter) { super(invIndex.getMainIndex().getPageManager(), filter); this.invIndex = invIndex; this.deletedKeysBTree = deletedKeysBTree; this.bloomFilter = bloomFilter; } public void testCouchbaseBean() { final String key = "SpringCouchbase" + System.currentTimeMillis(); final String value = "Spring/Couchbase"; BeanFactory beanFactory = new ClassPathXmlApplicationContext("cbGenerate.xml"); CouchbaseClient c = beanFactory.getBean("couchbaseClient", CouchbaseClient.class); c.set(key, 0, value); assertEquals(value, c.get(key)); c.delete(key); c.shutdown(3, TimeUnit.SECONDS); } // override by higher priority values. // In the case of a platform with override values from the user, the skin value might // already be there, but it's ok. HashMap<String, String> finalHardwareValues = new HashMap<String, String>(); File targetHardwareFile = new File(target.getLocation(), AvdManager.HARDWARE_INI); if (targetHardwareFile.isFile()) { Map<String, String> targetHardwareConfig = ProjectProperties.parsePropertyFile(new FileWrapper(targetHardwareFile), log); if (targetHardwareConfig != null) { finalHardwareValues.putAll(targetHardwareConfig); values.putAll(targetHardwareConfig); } } // get the hardware properties for this skin File skinFolder = getSkinPath(skinName, target); File skinHardwareFile = new File(skinFolder, AvdManager.HARDWARE_INI); if (skinHardwareFile.isFile()) { Map<String, String> skinHardwareConfig = ProjectProperties.parsePropertyFile(new FileWrapper(skinHardwareFile), log); if (skinHardwareConfig != null) { finalHardwareValues.putAll(skinHardwareConfig); } } (mLinkUpBandwidthKbps * 11) + (mLinkDownBandwidthKbps * 13) + Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest
(mLinkUpBandwidthKbps * 11) + (mLinkDownBandwidthKbps * 13) + Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); dest.writeParcelable((Parcelable) mNetworkSpecifier, flags); dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); netCap.mNetworkSpecifier = in.readParcelable(null); netCap.mSignalStrength = in.readInt(); return netCap; } @Override
public StringNetworkSpecifier(String specifier) { Preconditions.checkArgument(!TextUtils.isEmpty(specifier), "Network specifier must not be empty"); this.specifier = specifier; }
public boolean satisfiedBy(NetworkSpecifier other) { if (other == null || !(other instanceof StringNetworkSpecifier)) { return false; } return specifier.equals(((StringNetworkSpecifier) other).specifier); }
package android.net; import android.os.Parcel; import android.os.Parcelable; import android.text.TextUtils; import java.util.Objects; /** @hide */ public final class StringNetworkSpecifier extends NetworkSpecifier implements Parcelable { public final String specifier; public StringNetworkSpecifier(String specifier) { if (TextUtils.isEmpty(specifier)) { throw new IllegalArgumentException("Network specifier must not be empty"); } this.specifier = specifier; } // Parcelable implementation public static final Creator<StringNetworkSpecifier> CREATOR = new Creator<StringNetworkSpecifier>() { @Override public StringNetworkSpecifier createFromParcel(Parcel in) { return new StringNetworkSpecifier(in.readString()); } @Override public StringNetworkSpecifier[] newArray(int size) { return new StringNetworkSpecifier[size]; } }; @Override public void writeToParcel(Parcel dest, int flags) { dest.writeString(specifier); } @Override public int describeContents() { return 0; } @Override public boolean satisfiedBy(NetworkSpecifier other) { if (other instanceof StringNetworkSpecifier) { StringNetworkSpecifier that = (StringNetworkSpecifier) other; return Objects.equals(specifier, that.specifier); } return false; } @Override public int hashCode() { return Objects.hash(specifier); } @Override public boolean equals(Object obj) { if (this == obj) { return true; } if (obj == null || getClass() != obj.getClass()) { return false; } StringNetworkSpecifier that = (StringNetworkSpecifier) obj; return Objects.equals(specifier, that.specifier); } }
public boolean satisfiedBy(NetworkSpecifier other) { if (other == null) { return true; } if (!(other instanceof StringNetworkSpecifier)) { return false; } return specifier.equals(((StringNetworkSpecifier) other).specifier); }
private IpSecService(Context context) { mContext = context; }
/** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; } static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); service.connectNativeNetdService(); return service; } public static IpSecService create(Context context) throws InterruptedException { return create(context, NETD_SERVICE_NAME); } public void systemReady() { if (isNetdAlive()) { Slog.d(TAG, "IpSecService is ready"); } else { Slog.wtf(TAG, "IpSecService not ready: failed to connect to NetD Native Service!"); } } private void connectNativeNetdService() { // Avoid blocking the system server to do this Thread t = new Thread(new Runnable() { @Override public void run() { synchronized (mLock) { try { if (!mNetdService.connect()) { Slog.e(TAG, "Failed to connect to NetD Native Service"); } } catch (RemoteException e) { Slog.e(TAG, "Failed to connect to NetD Native Service", e); } mLock.notifyAll(); } } }); t.start(); // Wait for the connection to be established synchronized (mLock) { mLock.wait(NETD_FETCH_TIMEOUT); } }
private static final String NETD_SERVICE_NAME = "netd"; private static final int NETD_FETCH_TIMEOUT = 5000; private Context mContext; private Object mLock = new Object(); private IpSecService(Context context, String socket) { mContext = context; } public static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); service.connectNativeNetdService(); return service; } public static IpSecService create(Context context) throws InterruptedException { return create(context, NETD_SERVICE_NAME); } public void systemReady() { if (isNetdAlive()) { Slog.d(TAG, "IpSecService is ready"); } else { Slog.wtf(TAG, "IpSecService not ready: failed to connect to NetD Native Service!"); } } private void connectNativeNetdService() { // Avoid blocking the system server to do this Thread t = new Thread(new Runnable() { @Override public void run() { synchronized (mLock) { NetdService.get(NETD_FETCH_TIMEOUT); } } }); t.start(); }
private final SparseArray<SpiRecord> mSpiRecords = new SparseArray<>(); private final SparseArray<TransformRecord> mTransformRecords = new SparseArray<>(); private void unlinkDeathRecipient() { if (mBinder != null) { mBinder.unlinkToDeath(this, 0); } } protected void releaseResources() {} protected void nullifyRecord() {} public void binderDied() { Log.w(TAG, "IpSecService.SpiRecord binderDied(" + mBinder + ")"); } private IpSecService(Context context) { mContext = context; } static IpSecService create(Context context) throws InterruptedException { final IpSecService service = new IpSecService(context); service.connectNativeNetdService(); return service; } public void systemReady() { if (isNetdAlive()) { Slog.d(TAG, "IpSecService is ready"); } else { // Handle the case when Netd is not alive } }
} catch (RemoteException e) { throw e.rethrowFromSystemServer(); } synchronized (mSpiRecords) { mSpiRecords.put(resourceId, new SpiRecord(resourceId, direction, localAddress, remoteAddress, spi, binder)); } Bundle retBundle = new Bundle(3); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_STATUS, IpSecManager.Status.OK); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_RESOURCE_ID, resourceId); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_SPI, spi); return null;
public Bundle createTransportModeTransform(IpSecConfig c, IBinder binder) { int resourceId = mNextTransformId.getAndIncrement(); for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { IpSecAlgorithm auth = c.getAuthentication(direction); IpSecAlgorithm crypt = c.getEncryption(direction); try { int result = getNetdInstance().ipSecAddSecurityAssociation( resourceId, c.getMode(), direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", (c.getNetwork() != null) ? c.getNetwork().getNetworkHandle() : 0, c.getSpi(direction), (auth != null) ? auth.getName() : "", (auth != null) ? auth.getKey() : null, (auth != null) ? auth.getTruncationLengthBits() : 0, (crypt != null) ? crypt.getName() : "", (crypt != null) ? crypt.getKey() : null, (crypt != null) ? crypt.getTruncationLengthBits() : 0); } catch (Exception e) { // Handle exception } } // Rest of the code }
public Bundle createTransportModeTransform(IpSecConfig c, IBinder binder) { int resourceId = mNextTransformId.getAndIncrement(); for (int direction : DIRECTIONS) { IpSecAlgorithm auth = c.getAuthentication(direction); IpSecAlgorithm crypt = c.getEncryption(direction); try { int result = getNetdInstance().ipSecAddSecurityAssociation( resourceId, c.getMode(), direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", (c.getNetwork() != null) ? c.getNetwork().getNetworkHandle() : 0, c.getSpi(direction), (auth != null) ? auth.getName() : "", (auth != null) ? auth.getKey() : null, (auth != null) ? auth.getTruncationLengthBits() : 0, (crypt != null) ? crypt.getName() : "", (crypt != null) ? crypt.getKey() : null, (crypt != null) ? crypt.getTruncationLengthBits() : 0); } catch (Exception e) { // Handle exception } } // Rest of the code } private static final int[] DIRECTIONS = {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN};
(auth != null) ? auth.getKey() : null, (auth != null) ? auth.getTruncationLengthBits() : 0, (crypt != null) ? crypt.getName() : "", (crypt != null) ? crypt.getKey() : null, (crypt != null) ? crypt.getTruncationLengthBits() : 0, c.getEncapType(), c.getEncapLocalPort(), c.getEncapRemotePort()); if (result != c.getSpi(direction)) { Bundle retBundle = new Bundle(2); retBundle.putInt(IpSecTransform.KEY_STATUS, IpSecManager.Status.SPI_UNAVAILABLE); retBundle.putInt(IpSecTransform.KEY_RESOURCE_ID, IpSecTransform.INVALID_SPI); return retBundle; } } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } synchronized (mTransformRecords) { mTransformRecords.put(resourceId, new TransformRecord(c, resourceId, binder)); }
(crypt != null) ? crypt.getKey() : null, (crypt != null) ? crypt.getTruncationLengthBits() : 0, c.getEncapType(), c.getEncapLocalPort(), c.getEncapRemotePort()); if (result != c.getSpi(direction)) { Bundle retBundle = new Bundle(2); retBundle.putInt(IpSecTransform.KEY_STATUS, IpSecManager.Status.SPI_UNAVAILABLE); retBundle.putInt(IpSecTransform.KEY_RESOURCE_ID, IpSecTransform.INVALID_SPI); return retBundle; } } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } synchronized (mTransformRecords) { mTransformRecords.put(resourceId, new TransformRecord(c, resourceId, binder)); } Bundle retBundle = new Bundle(2); retBundle.putInt(IpSecTransform.KEY_STATUS, IpSecManager.Status.OK); retBundle.putInt(IpSecTransform.KEY_RESOURCE_ID, resourceId); return retBundle;
public void deleteTransportModeTransform(int resourceId) { synchronized (mTransformRecords) { TransformRecord record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } mTransformRecords.remove(resourceId); record.releaseResources(); record.nullifyRecord(); } }
throw new CmlpDataSrcException("Please provide a predictor", 400); if (!(codeCloudAuthorization != null) && !(codeCloudAuthorization.isEmpty())) { throw new CmlpDataSrcException("Please provide CodeCloudAuthorization header", 400); } if (!(objCatalog.getPublisherUrl() != null) && objCatalog.getPublisherUrl().isEmpty()) { throw new CmlpDataSrcException("Please provide a publisher URL", 400); } try { log.info("RestCatalogServiceImpl::updateCatalog()::intiating update request."); String responseCatalogKey = aCatalogService.updateCatalog(user, authorization, codeCloudAuthorization, catalogKey, objCatalog); log.info("RestCatalogServiceImpl::updateCatalog()::update completed for key: " + responseCatalogKey); URI location = new URI(url + objCatalog.getCatalogKey()); } catch (Exception e) { log.error("Exception in RestCatalogServiceImpl:updateCatalog" + e.getMessage()); aResponseMessage.setCode(500); aResponseMessage.setMessage(e.getMessage()); return Response.status(Status.BAD_REQUEST).entity(aResponseMessage).build(); } String branchName = refName.startsWith("refs/heads/") ? refName.substring(11) : ""; ProjectBranchKey pbKey = new ProjectBranchKey(projectName, branchName); if (event.getNewObjectId().equals(ObjectId.zeroId().toString())) { log.info("Project: " + projectName + "\nrefName: " + refName); } else if (REFS_CONFIG.equals(refName)) { processProjectConfigChange(event); } else if (enabledManifestSource.containsKey(projectName) && enabledManifestSource.get(projectName).getBranches().contains(branchName)) { processManifestChange(event, projectName, branchName); } else if (subscribedRepos.containsRow(pbKey)) { Map<String, Map<String, Set<com.amd.gerrit.plugins.manifestsubscription.manifest.Project>>> destinations = subscribedRepos.row(pbKey); } record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } mTransformRecords.remove(resourceId); record.releaseResources(); record.nullifyRecord();
public void applyTransportModeTransform(ParcelFileDescriptor socket, int resourceId) { TransformRecord info; synchronized (mTransformRecords) { info = mTransformRecords.get(resourceId); if (info == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not active"); } if (info.pid != getCallingPid() || info.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may apply it!"); } } IpSecConfig c = info.getConfig(); try { for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { synchronized (mTransformRecords) { getNetdInstance().ipSecApplyTransportModeTransform( socket.getFileDescriptor(), resourceId, direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", c.getSpiResourceId(direction)); } } } catch (RemoteException | ServiceSpecificException e) { throw new IllegalStateException("Failed to communicate with IPsec service", e); } }
import static org.mockito.Mockito.atLeastOnce; import static org.mockito.Mockito.mock; import static org.mockito.Mockito.validateMockitoUsage; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.when; import android.content.Context; import android.net.wifi.WifiScanner.BssidInfo; import android.os.Handler; import android.os.Message; import android.os.test.TestLooper; import android.test.suitebuilder.annotation.SmallTest; import com.android.internal.util.test.BidirectionalAsyncChannelServer; import org.junit.After; import org.junit.Before; import org.junit.Test; import org.mockito.ArgumentCaptor; import org.mockito.Mock; import org.mockito.MockitoAnnotations; /** * Unit tests for {@link android.net.wifi.WifiScanner}. */ @SmallTest public class WifiScannerTest { @Mock private Context mContext; @Mock private IWifiScanner mService; private WifiScanner mWifiScanner; private TestLooper mLooper; private Handler mHandler; /** * Setup before tests. */ @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); mLooper = new TestLooper(); mHandler = mock(Handler.class); } }
mImsRegistered = (responseArray[0] == 1) ? true : false; } break; //GSM case EVENT_RADIO_AVAILABLE: //setPowerStateToDesired(); break; case EVENT_SIM_READY: mOnSubscriptionsChangedListener.mPreviousSubId.set(-1); pollState(); queueNextSignalStrengthPoll(); setNotification(CS_ENABLED); break; case EVENT_RADIO_STATE_CHANGED: case EVENT_PHONE_TYPE_SWITCHED: if(!mPhone.isPhoneTypeGsm() && mCi.getRadioState() == CommandsInterface.RadioState.RADIO_ON) { handleCdmaSubscriptionSource(mCdmaSSM.getCdmaSubscriptionSource()); queueNextSignalStrengthPoll(); } setPowerStateToDesired(); modemTriggeredPollState(); break;
public static final String KEY_BOOSTED_LTE_EARFCNS_STRING_ARRAY = "boosted_lte_earfcns_string_array"; public static final String KEY_DISABLE_VOICE_BARRING_NOTIFICATION_BOOL = "disable_voice_barring_notification_bool"; private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true); }
public class WifiManager { private static final String TAG = "WifiManager"; public static final int ERROR_AUTHENTICATING = 1; public static final int ERROR_AUTH_FAILURE_NONE = 0; public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; }
public class WifiManager { private static final String TAG = "WifiManager"; public static final int ERROR_AUTHENTICATING = 1; public static final int ERROR_AUTH_FAILURE_NONE = 0; public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; }
public static final int ERROR_AUTHENTICATING = 1; public static final int ERROR_AUTH_FAILURE_NONE = 0; public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3;
public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3; public static final String WIFI_SCAN_AVAILABLE = "wifi_scan_available"; public static final String EXTRA_SCAN_AVAILABLE = "scan_enabled";
(mLinkUpBandwidthKbps * 11) + (mLinkDownBandwidthKbps * 13) + Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); dest.writeParcelable((Parcelable) mNetworkSpecifier, 0); dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); netCap.mNetworkSpecifier = in.readParcelable(null); netCap.mSignalStrength = in.readInt(); return netCap; } @Override public NetworkCapabilities[] newArray(int size) { return new NetworkCapabilities[size]; } };
package android.net; public abstract class NetworkSpecifier { public abstract boolean satisfiedBy(NetworkSpecifier other); }
if (foregroundCall != null && foregroundCall != call && (foregroundCall.isActive() || foregroundCall.getState() == CallState.DIALING || foregroundCall.getState() == CallState.PULLING)) { if (!foregroundCall.getTargetPhoneAccount().equals(call.getTargetPhoneAccount()) && (call.isSelfManaged() != foregroundCall.isSelfManaged() || call.isSelfManaged())) { // The foreground call is from another connection service, and either: // 1. FG call's managed state doesn't match that of the incoming call. // E.g. Incoming is self-managed and FG is managed, or incoming is managed // and foreground is self-managed. // 2. The incoming call is self-managed. // E.g. The incoming call is Log.i(this, "Answering call from %s CS; disconnecting calls from %s CS.", foregroundCall.isSelfManaged() ? "selfMg" : "mg", } }
@Mock private Call mVideoCall; @Mock private Call mRingingCall; private IncomingCallNotifier mIncomingCallNotifier; private NotificationManager mNotificationManager; public void setUp() throws Exception { super.setUp(); mContext = mComponentContextFixture.getTestDouble().getApplicationContext(); ApplicationInfo info = new ApplicationInfo(); info.targetSdkVersion = Build.VERSION_CODES.N_MR1; doReturn(info).when(mContext).getApplicationInfo(); doReturn(null).when(mContext).getTheme(); mNotificationManager = (NotificationManager) mContext.getSystemService(Context.NOTIFICATION_SERVICE); mIncomingCallNotifier = new IncomingCallNotifier(mContext); mIncomingCallNotifier.setCallsManagerProxy(mCallsManagerProxy); when(mAudioCall.getVideoState()).thenReturn(VideoProfile.STATE_AUDIO_ONLY); when(mAudioCall.getTargetPhoneAccountLabel()).thenReturn("Bar"); when(mVideoCall.getVideoState()).thenReturn(VideoProfile.STATE_BIDIRECTIONAL); when(mVideoCall.getTargetPhoneAccountLabel()).thenReturn("Bar"); when(mRingingCall.isSelfManaged()).thenReturn(true); when(mRingingCall.isIncoming()).thenReturn(true); }
@Mock WifiTrafficPoller mWifiTrafficPoller; @Mock WifiStateMachine mWifiStateMachine; @Mock HandlerThread mHandlerThread; TestLooper mLooper; @Mock AsyncChannel mAsyncChannel; @Mock Resources mResources; @Mock FrameworkFacade mFrameworkFacade; @Mock WifiLockManager mLockManager; @Mock WifiMulticastLockManager mWifiMulticastLockManager; @Mock WifiLastResortWatchdog mWifiLastResortWatchdog; @Mock WifiBackupRestore mWifiBackupRestore; @Mock WifiMetrics mWifiMetrics; @Spy FakeWifiLog mLog; @Mock WifiPermissionsUtil mWifiPermissionsUtil; @Mock PropertyService mPropertyService; @Mock WifiSettingsStore mSettingsStore; @Mock ContentResolver mContentResolver; PowerManager mPowerManager; private class WifiAsyncChannelTester { private static final String TAG = "WifiAsyncChannelTester"; public static final int CHANNEL_STATE_FAILURE = -1; public static final int CHANNEL_STATE_DISCONNECTED = 0; public static final int CHANNEL_STATE_HALF_CONNECTED = 1; public static final int CHANNEL_STATE_FULLY_CONNECTED = 2; private int mState = CHANNEL_STATE_DISCONNECTED; private WifiAsyncChannel mChannel; private WifiLog mAsyncTestLog; }
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. package benchmarks.regression; import com.google.caliper.Param; public class StringReplaceAllBenchmark { // NOTE: These estimates of MOVEABLE / NON_MOVEABLE are based on a knowledge of // ART implementation details. They make a difference here because JNI calls related // to strings took different paths depending on whether the String in question was // moveable or not. enum StringLengths { EMPTY(""), SHORT("short"), MEDIUM("medium length string"), LONG("long string that is longer than the others"); private final String value; StringLengths(String value) { this.value = value; } public String getValue() { return value; } } @Param private StringLengths stringLength; private String input; public void setUp() { input = stringLength.getValue(); } public void timeReplaceAll(int reps) { for (int i = 0; i < reps; i++) { input.replaceAll(" ", "_"); } } }
private long size = 0; private Path tmpFile; public CleanFilter(Repository db, InputStream in, OutputStream out) throws IOException { super(in, out); lfsUtil = new LfsUtil(db.getDirectory().toPath().resolve("lfs")); Files.createDirectories(lfsUtil.getLfsTmpDir()); tmpFile = lfsUtil.createTmpFile(); this.out = out; } public org.apache.hadoop.hive.metastore.api.Table getMetaStoreTable() { return msTable_; } public void setMetaStoreTable(org.apache.hadoop.hive.metastore.api.Table msTbl) { msTable_ = msTbl; } public int getNumClusteringCols() { return numClusteringCols_; } public void setNumClusteringCols(int n) { Preconditions.checkState(RuntimeEnv.INSTANCE.isTestEnv()); numClusteringCols_ = n; } public long getNumRows() { return numRows_; } public ArrayType getType() { return type_; } @Override public long getCatalogVersion() { return catalogVersion_; } @Override public void setCatalogVersion(long catalogVersion) { catalogVersion_ = catalogVersion; } @Override public boolean isLoaded() { return true; } public static boolean isExternalTable() { // implementation } private final Map<Project.NameKey, ProjectState> all; private final ProjectCache projectCache; private final CapabilityControl.Factory capabilityControlFactory; private final ChangeControl.AssistedFactory changeControlFactory; private final PermissionCollection.Factory sectionSorter; private final InMemoryRepositoryManager repoManager; private final GroupControl.Factory controlFactory; private final GroupJson json; private final Provider<ListIncludedGroups> listIncludes; private final AllProjectsName allProjectsName = new AllProjectsName("All-Projects"); private final ProjectConfig allProjects; @SuppressWarnings("unchecked") public Util() { all = new HashMap<>(); repoManager = new InMemoryRepositoryManager(); try { Repository repo = repoManager.createRepository(allProjectsName); allProjects = new ProjectConfig(new Project.NameKey(allProjectsName.get())); allProjects.load(repo); allProjects.getLabelSections().put(CR.getName(), CR); add(allProjects); } catch (IOException | ConfigInvalidException e) { throw new RuntimeException(e); } projectCache = new ProjectCache() { @Override // implementation }; } public void start
/** * Creates a new advertising set. If operation succeed, device will start advertising. This * method returns immediately, the operation status is delivered through * {@code callback.onAdvertisingSetStarted()}. * * @param parameters advertising set parameters. * @param advertiseData Advertisement data to be broadcasted. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength}. If the advertisement is connectable, * three bytes will be appended with flags. * @param scanResponse Scan response associated with the advertisement data. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength} * @param periodicData Periodic advertising data. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength} * @param timeoutMillis Advertising time limit. May not exceed 180000 * @param callback Callback for advertising set. * @param handler thread upon which the callbacks will be invoked. */ public void startAdvertisingSet(AdvertisingSetParameters parameters, AdvertiseData advertiseData, AdvertiseData scanResponse, PeriodicAdvertisingParameters periodicParameters, long timeoutMillis, AdvertisingSetCallback callback, Handler handler) { // implementation goes here }
* by the system. */ public static final String ACTION_SUBINFO_RECORD_UPDATED = "android.intent.action.ACTION_SUBINFO_RECORD_UPDATED"; /** * Broadcast Action: The default subscription has changed. This has the following * extra values:</p> * <ul> * <li><em>subscription</em> - A int, the current default subscription.</li> * </ul> * @deprecated Use (@link SubscriptionManager.ACTION_DEFAULT_SUBSCRIPTION_CHANGED} */ @Deprecated public static final String ACTION_DEFAULT_SUBSCRIPTION_CHANGED = SubscriptionManager.ACTION_DEFAULT_SUBSCRIPTION_CHANGED; /** * Broadcast Action: The default data subscription has changed. This has the following * extra values:</p> * <ul> * <li><em>subscription</em> - A int, the current data default subscription.</li> * </ul> */ public static final String ACTION_DEFAULT_DATA_SUBSCRIPTION_CHANGED = "android.intent.action.ACTION_DEFAULT_DATA_SUBSCRIPTION_CHANGED"; /** * Broadcast Action: The default voice subscription has changed. This has the following */
Fixed Code: ```java public static final String ACTION_DEFAULT_VOICE_SUBSCRIPTION_CHANGED = "android.intent.action.ACTION_DEFAULT_VOICE_SUBSCRIPTION_CHANGED"; @Deprecated public static final String ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED = SubscriptionManager.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED; public static final String ACTION_PHONE_RADIO_ACCESS_FAMILY_CHANGED = "android.intent.action.PHONE_RADIO_ACCESS_FAMILY_CHANGED"; ```
Refactored Code: ```java } public void testChangeFontScaleNoRelaunch() throws Exception { // Should receive onConfigurationChanged() and no relaunch testChangeFontScale(NO_RELAUNCH_ACTIVITY_NAME, false); } private void testRotation(String activityName, int rotationStep, int numRelaunch, int numConfigChange) throws Exception { executeShellCommand(getAmStartCmd(activityName)); final String[] waitForActivitiesVisible = new String[] {activityName}; mAmWmState.computeState(mDevice, waitForActivitiesVisible); setDeviceRotation(4 - rotationStep); mAmWmState.computeState(mDevice, waitForActivitiesVisible); final int actualStackId = mAmWmState.getAmState().getTaskByActivityName(activityName).mStackId; final int displayId = mAmWmState.getAmState().getStackById(actualStackId).mDisplayId; final int newDeviceRotation = getDeviceRotation(displayId); if (newDeviceRotation == INVALID_DEVICE_ROTATION) { CLog.logAndDisplay(LogLevel.WARN, "Got an invalid device rotation value. " + "Continuing the test despite of that, but it is likely to fail."); } } ``` Note: The refactored code removes the unnecessary focus comments and adds a local variable for the device rotation value.
Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); if (mNetworkSpecifier != null && !NetworkSpecifier.isWhitelistedNetworkSpecifier( mNetworkSpecifier)) { throw new IllegalStateException("Invalid network specifier"); } dest.writeParcelable((Parcelable) mNetworkSpecifier, flags); dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); try { netCap.mNetworkSpecifier = in.readParcelable(null);
new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); try { netCap.mNetworkSpecifier = (NetworkSpecifier) in.readParcelable(null); } catch (BadParcelableException e) { Log.e(TAG, "BadParcelableException: e=" + e); netCap.mNetworkSpecifier = null; } netCap.mSignalStrength = in.readInt(); return netCap; } @Override public NetworkCapabilities[] newArray(int size) { return new NetworkCapabilities[size]; } }; @Override public String toString() { int[] types = getTransportTypes(); String transports = (types.length > 0) ? " Transports: " + transportNamesOf(types) : ""; types = getCapabilities(); String capabilities = (types.length > 0 ? " Capabilities: " : ""); }
@Override public void onPullExternalCall() { if ((getConnectionProperties() & Connection.PROPERTY_IS_EXTERNAL_CALL) != Connection.PROPERTY_IS_EXTERNAL_CALL) { Log.w(this, "onPullExternalCall - cannot pull non-external call"); return; } if (mOriginalConnection != null) { mOriginalConnection.pullExternalCall(); } } @Override public void onStartRtt(RttTextStream textStream) { Phone phone = getPhone(); if (phone instanceof ImsPhone) { ImsPhone imsPhone = (ImsPhone) phone; imsPhone.sendRttModifyRequest(textStream); } else { Log.w(this, "onStartRtt - not in IMS, so RTT cannot be enabled."); } } @Override public void onStopRtt() { // This is not supported by carriers/vendor yet. No-op for now. } @Override public void handleRttUpgradeResponse(RttTextStream textStream) { Phone phone = getPhone(); if (!(phone instanceof ImsPhone)) { // Handle non-IMS phone case } }
if (phone instanceof ImsPhone) { ImsPhone imsPhone = (ImsPhone) phone; imsPhone.sendRttModifyRequest(textStream); } else { Log.w(this, "onStartRtt - not in IMS, so RTT cannot be enabled."); } @Override public void onStopRtt() { // This is not supported by carriers/vendor yet. No-op for now. } @Override public void handleRttUpgradeResponse(RttTextStream textStream) { Phone phone = getPhone(); if (!(phone instanceof ImsPhone)) { Log.w(this, "handleRttUpgradeResponse - not in IMS, so RTT cannot be enabled."); return; } ImsPhone imsPhone = (ImsPhone) phone; imsPhone.sendRttModifyResponse(textStream); } public void performHold() { Log.v(this, "performHold"); // TODO: Can dialing calls be put on hold as well since they take up the // foreground call slot? if (Call.State.ACTIVE == mConnectionState) { Log.v(this, "Holding active call"); try { // Perform hold operation } catch (Exception e) { Log.e(this, "Error performing hold operation", e); } } }
/* Copyright (C) 2016 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net.wifi.aware; import android.net.NetworkSpecifier; import android.os.Parcel; import android.os.Parcelable; import java.util.Arrays; import java.util.Objects; /** * Network specifier object used to request a Wi-Fi Aware network. Apps do not create these objects * directly but obtain them using * {@link WifiAwareSession#createNetworkSpecifierOpen(int, byte[])} or * {@link WifiAwareSession#createNetworkSpecifierPassphrase(int, byte[], String)}. * * @hide */ public class NetworkSpecifier implements Parcelable { // ... rest of the code ... }
public boolean satisfiedBy(NetworkSpecifier other) { return equals(other); }
public static List<TimeZone> getTimeZonesWithUniqueOffsets(String country) { synchronized(sLastUniqueLockObj) { if ((country != null) && country.equals(sLastUniqueCountry)) { return sLastUniqueZoneOffsets; } } Collection<TimeZone> zones = getTimeZones(country); ArrayList<TimeZone> uniqueTimeZones = new ArrayList<>(); for (TimeZone zone : zones) { boolean found = false; for (int i = 0; i < uniqueTimeZones.size(); i++) { if (uniqueTimeZones.get(i).getRawOffset() == zone.getRawOffset()) { found = true; break; } } if (!found) { uniqueTimeZones.add(zone); } } return uniqueTimeZones; }
private static String getCounterLabel(int counterIndex) { switch (counterIndex) { case ON_POST_DIAL_WAIT: return "onPostDialWait"; case ON_CALL_EVENT: return "onCallEvent"; case ON_PULL_EXTERNAL_CALL: return "onPullExternalCall"; case ON_EXTRAS_CHANGED: return "onExtrasChanged"; case ON_START_RTT: return "onStartRtt"; case ON_RTT_REQUEST_RESPONSE: return "onRttRequestResponse"; case ON_STOP_RTT: return "onStopRtt"; default: return "Callback"; } }
public class MyClass { private int resourceId; public void setResourceId(int resourceId) { this.resourceId = resourceId; } public int getResourceId() { return resourceId; } public void stopKeepalive() { if (mKeepalive == null) { return; } mKeepalive.stop(); synchronized (mKeepaliveSyncLock) { if (mKeepaliveStatus == ConnectivityManager.PacketKeepalive.SUCCESS) { try { mKeepaliveSyncLock.wait(2000); } catch (InterruptedException e) { // Handle exception } } } } }
protected void releaseResources() { try { getNetdInstance().ipSecDeleteSecurityAssociation(mResourceId, mDirection, mLocalAddress, mRemoteAddress, mSpi); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw it as an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } }
INetd getNetdInstance() { final INetd netd = NetdService.getInstance(); if (netd == null) { throw new RemoteException("Failed to Get Netd Instance").rethrowFromSystemServer(); } return netd; }
} return netd; } boolean isNetdAlive() { synchronized (mLock) { final INetd netd = getNetdInstance(); if (netd == null) { return false; } try { return netd.isAlive(); } catch (RemoteException re) { return false; } } } @Override public Bundle reserveSecurityParameterIndex(int direction, String remoteAddress, int requestedSpi, IBinder binder) throws RemoteException { int resourceId = mNextResourceId.getAndIncrement(); int spi = IpSecManager.INVALID_SECURITY_PARAMETER_INDEX; String localAddress = ""; Bundle retBundle = new Bundle(3); try { spi = getNetdInstance().ipSecAllocateSpi(resourceId, direction, localAddress, remoteAddress, requestedSpi); Log.d(TAG, "Allocated SPI " + spi); retBundle.putInt(KEY_STATUS, IpSecManager.Status.OK); retBundle.putInt(KEY_RESOURCE_ID, resourceId); retBundle.putInt(KEY_SPI, spi);
@Override public Bundle createTransportModeTransform(IpSecConfig c, IBinder binder) throws RemoteException { int resourceId = mNextResourceId.getAndIncrement(); for (int direction : DIRECTIONS) { IpSecAlgorithm auth = c.getAuthentication(direction); IpSecAlgorithm crypt = c.getEncryption(direction); try { int result = getNetdInstance().ipSecAddSecurityAssociation( resourceId, c.getMode(), direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", c.getSpiResourceId(direction), (auth != null) ? auth.getName() : null, (auth != null) ? auth.getKey() : null, (crypt != null) ? crypt.getName() : null, (crypt != null) ? crypt.getKey() : null, c.getEncapType(), c.getEncapSocketResourceId(direction), c.getMarkResourceId(direction), binder); if (result != 0) { throw new RemoteException("ipSecAddSecurityAssociation returned " + result); } } catch (ServiceSpecificException e) { throw new RemoteException("Error configuring transform", e); } } return new Bundle(); }
@Override public void deleteTransportModeTransform(int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord record; record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } record.releaseResources(); mTransformRecords.remove(resourceId); } }
*/ @Override public void deleteTransportModeTransform(int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord record; // We want to non-destructively get so that we can check credentials before removing this record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != Binder.getCallingPid() || record.uid != Binder.getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional record.releaseResources(); mTransformRecords.remove(resourceId); record.nullifyRecord(); } } /** * Apply an active transport mode transform to a socket, which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override
if (record == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } record.releaseResources(); mTransformRecords.remove(resourceId); record.nullifyRecord(); } /** * Apply an active transport mode transform to a socket, which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override public void applyTransportModeTransform(ParcelFileDescriptor socket, int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord info; info = mTransformRecords.get(resourceId); // TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional info.releaseResources(); } }
// TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional record.releaseResources(); mTransformRecords.remove(resourceId); record.nullifyRecord(); } } /** * Apply an active transport mode transform to a socket, which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override public void applyTransportModeTransform(ParcelFileDescriptor socket, int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord info; // FIXME: this code should be factored out into a security check + getter info = mTransformRecords.get(resourceId); if (info == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not active"); } // TODO: make this a function. if (info.pid != getCallingPid() || info.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may apply it!"); } } }
@Override public void removeTransportModeTransform(ParcelFileDescriptor socket, int resourceId) throws RemoteException { try { getNetdInstance().ipSecRemoveTransportModeTransform(socket.getFileDescriptor()); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } } @Override protected void dump(FileDescriptor fd, PrintWriter pw, String[] args) { mContext.enforceCallingOrSelfPermission(DUMP, TAG); pw.println("IpSecService Log:"); pw.println("NetdNativeService Connection: " + (isNetdAlive() ? "alive" : "dead")); pw.println(); }
import org.apache.kudu.client.shaded.com.google.common.base.Preconditions; /** * Represents a literal timestamp. Its value is a 16-byte array that corresponds to a * raw BE TimestampValue, e.g., in a slot. In addition, it stores the string * representation of the timestamp value to avoid converting the raw bytes on the Java * side. Such a conversion could potentially be inconsistent with what the BE would * produce, so it's better to defer to a single source of truth (the BE implementation). * * Literal timestamps can currently only be created via constant folding. There is no * way to directly specify a literal timestamp from SQL. */ public class TimestampLiteral extends LiteralExpr { private final byte[] value_; private final String strValue_; public TimestampLiteral(byte[] value, String strValue) { Preconditions.checkState(value.length == Type.TIMESTAMP.getSlotSize()); value_ = value; strValue_ = strValue; type_ = Type.TIMESTAMP; } /** * Copy c'tor used in clone. */ }
out.writeParcelable(flow[IpSecTransform.DIRECTION_OUT].encryption, flags); out.writeParcelable(flow[IpSecTransform.DIRECTION_OUT].authentication, flags); out.writeInt(encapType); out.writeInt(encapLocalPort); out.writeInt(encapRemotePort); } IpSecConfig() { flow[IpSecTransform.DIRECTION_IN].spi = 0; flow[IpSecTransform.DIRECTION_OUT].spi = 0; nattKeepaliveInterval = 0; } private static InetAddress readInetAddressFromParcel(Parcel in) { String addrString = in.readString(); if (addrString == null) { return null; } try { return InetAddress.getByName(addrString); } catch (UnknownHostException e) { Log.wtf(TAG, "Invalid IpAddress " + addrString); return null; } } private IpSecConfig(Parcel in) { properties = in.readLong(); localAddress = readInetAddressFromParcel(in); remoteAddress = readInetAddressFromParcel(in); }
package android.net; import android.annotation.IntDef; import android.annotation.NonNull; import android.annotation.SystemApi; import android.content.Context; import android.os.Binder; import android.os.Bundle; import android.os.IBinder; import android.os.RemoteException; import android.os.ServiceManager; import android.util.Log; import com.android.internal.util.Preconditions; import dalvik.system.CloseGuard; import java.io.IOException; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.net.InetAddress; /** * This class represents an IpSecTransform, which encapsulates both properties and state of IPsec. */ package android.net; import android.annotation.IntDef; import android.annotation.NonNull; import android.annotation.SystemApi; import android.content.Context; import android.os.Binder; import android.os.Bundle; import android.os.IBinder; import android.os.RemoteException; import android.os.ServiceManager; import android.util.Log; import com.android.internal.util.Preconditions; import dalvik.system.CloseGuard; import java.io.IOException; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.net.InetAddress; /** * This class represents an IpSecTransform, which encapsulates both properties and state of IPsec. */
import java.net.InetAddress; import java.net.Socket; /** * This class contains methods for managing IPsec sessions, which will perform kernel-space * encryption and decryption of socket or Network traffic. * * <p>An IpSecManager may be obtained by calling {@link * android.content.Context#getSystemService(String) Context#getSystemService(String)} with {@link * android.content.Context#IPSEC_SERVICE Context#IPSEC_SERVICE} */ public final class IpSecManager { private static final String TAG = "IpSecManager"; /** @hide */ public interface Status { public static final int OK = 0; public static final int RESOURCE_UNAVAILABLE = 1; public static final int SPI_UNAVAILABLE = 2; } /** @hide */ public static final String KEY_STATUS = "status"; /** @hide */ public static final String KEY_RESOURCE_ID = "resourceId"; private IpSecManager() { // Private constructor to prevent instantiation } private static IIpSecService getIpSecService() { IBinder b = ServiceManager.getService(IPSEC_SERVICE); if (b == null) { throw new RemoteException("Failed to connect to IpSecService") .rethrowAsRuntimeException(); } return IIpSecService.Stub.asInterface(b); } private void checkResultStatus(int status) throws IOException, IpSecManager.ResourceUnavailableException, IpSecManager.SpiUnavailableException { switch (status) { case IpSecManager.Status.OK: return; case IpSecManager.Status.RESOURCE_UNAVAILABLE: throw new IpSecManager.ResourceUnavailableException( "Failed to allocate a new IpSecTransform"); case IpSecManager.Status.SPI_UNAVAILABLE: Log.wtf(TAG, "Attempting to use an SPI that was somehow not reserved"); // Fall through default: throw new IOException("Unknown status: " + status); } } }
mConfig = config; mResourceId = INVALID_RESOURCE_ID; private IIpSecService getIpSecService() { IBinder b = ServiceManager.getService(IPSEC_SERVICE); if (b == null) { throw new RemoteException("Failed to connect to IpSecService").rethrowAsRuntimeException(); } return IIpSecService.Stub.asInterface(b); } private void checkResultStatus(int status) throws IOException, IpSecManager.ResourceUnavailableException, IpSecManager.SpiUnavailableException { switch (status) { case IpSecManager.Status.OK: return; case IpSecManager.Status.RESOURCE_UNAVAILABLE: throw new IpSecManager.ResourceUnavailableException("Failed to allocate a new IpSecTransform"); case IpSecManager.Status.SPI_UNAVAILABLE: Log.wtf(TAG, "Attempting to use an SPI that was somehow not reserved"); // Fall through default: throw new IllegalStateException("Unknown status: " + status); } }
private void checkResultStatus(int status) throws IOException, IpSecManager.ResourceUnavailableException, IpSecManager.SpiUnavailableException { switch (status) { case IpSecManager.Status.OK: return; case IpSecManager.Status.RESOURCE_UNAVAILABLE: throw new IpSecManager.ResourceUnavailableException("Failed to allocate a new IpSecTransform"); case IpSecManager.Status.SPI_UNAVAILABLE: Log.wtf(TAG, "Attempting to use an SPI that was somehow not reserved"); // Fall through default: throw new IllegalStateException("Failed to Create a Transform with status code " + status); } }
private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_SERVICE_NAME = "netd"; private static final int[] DIRECTIONS = new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}; /** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms private AtomicInteger mNextTransformId = new AtomicInteger(0xFADED000); private abstract class ManagedResource implements IBinder.DeathRecipient { final int pid; final int uid; private IBinder mBinder; ManagedResource(IBinder binder) { super(); mBinder = binder; pid = getCallingPid(); uid = getCallingUid(); try { mBinder.linkToDeath(this, 0); } catch (RemoteException e) { binderDied(); } } /** * When this record is no longer needed for managing system resources this function should * unlink all references held by the record to allow efficient garbage collection. */ }
/** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms private AtomicInteger mNextTransformId = new AtomicInteger(0xFADED000); private abstract class ManagedResource implements IBinder.DeathRecipient { final int pid; final int uid; private IBinder mBinder; ManagedResource(IBinder binder) { super(); mBinder = binder; pid = Binder.getCallingPid(); uid = Binder.getCallingUid(); try { mBinder.linkToDeath(this, 0); } catch (RemoteException e) { binderDied(); } } /** * When this record is no longer needed for managing system resources this function should * unlink all references held by the record to allow efficient garbage collection. */ public final void release() { //Release all the underlying system resources first releaseResources(); if (mBinder != null) { mBinder.unlinkToDeath(this, 0); } mBinder = null; } }
protected void releaseResources() { for (int direction : DIRECTIONS) { try { getNetdInstance() .ipSecDeleteSecurityAssociation( mResourceId, direction, (mConfig.getLocalAddress() != null) ? mConfig.getLocalAddress().getHostAddress() : "", (mConfig.getRemoteAddress() != null) ? mConfig.getRemoteAddress().getHostAddress() : "", mConfig.getSpi(direction) ); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } }
mResourceId, direction, (mConfig.getLocalAddress() != null) ? mConfig.getLocalAddress().getHostAddress() : "", (mConfig.getRemoteAddress() != null) ? mConfig.getRemoteAddress().getHostAddress() : "", mConfig.getSpi(direction)); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } }
public IPageManager getPageManager() throws HyracksDataException { throw HyracksDataException.create(ErrorCode.LSM_INVERTED_INDEX_DOES_NOT_HAVE_PAGE_MANAGER); } public JobManager(CCConfig ccConfig, ClusterControllerService ccs, IResourceManager resourceManager) throws HyracksException { this.ccs = ccs; this.resourceManager = resourceManager; try { Constructor<?> jobQueueConstructor = this.getClass().getClassLoader().loadClass(ccConfig.jobQueueClassName) .getConstructor(IJobManager.class); jobQueue = (IJobQueue) jobQueueConstructor.newInstance(this); } catch (ClassNotFoundException | InstantiationException | IllegalAccessException | NoSuchMethodException | InvocationTargetException e) { throw HyracksException.create(ErrorCode.CLASS_LOADING_ISSUE, e, e.getMessage()); } activeRunMap = new HashMap<>(); runMapArchive = new LinkedHashMap<JobId, JobRun>() { private static final long serialVersionUID = 1L; @Override protected boolean removeEldestEntry(Map.Entry<JobId, JobRun> eldest) { return size() > ccConfig.jobHistorySize; } }; runMapHistory = new LinkedHashMap<JobId, List<Exception>>() { private static final long serialVersionUID = 1L; /** history size + 1 is for the case when history size = 0 */ }; } if (getDatasetType() == DatasetType.INTERNAL) { IActiveEntityEventsListener[] activeListeners = ActiveJobNotificationHandler.INSTANCE.getEventListeners(); for (IActiveEntityEventsListener listener : activeListeners) { if (listener.isEntityUsingDataset(dataverseName, datasetName)) { throw new CompilationException(ErrorCode.COMPILATION_CANT_DROP_ACTIVE_DATASET, ARecordType.toFullyQualifiedName(dataverseName, datasetName), listener.getEntityId().toString()); } } List<Index> indexes = MetadataManager.INSTANCE.getDatasetIndexes(mdTxnCtx.getValue(), dataverseName, datasetName); for (int j = 0; j < indexes.size(); j++) { if (indexes.get(j).isSecondaryIndex()) { jobsToExecute.add(IndexUtils.dropJob(indexes.get(j), metadataProvider, this)); } } Index primaryIndex = MetadataManager.INSTANCE.getIndex(mdTxnCtx.getValue(), dataverseName, datasetName, datasetName); jobsToExecute.add(Dataset
public void deleteTransportModeTransform(int resourceId) { synchronized (mTransformRecords) { TransformRecord record; record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } mTransformRecords.remove(resourceId); record.releaseResources(); record.nullifyRecord(); } }
record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } mTransformRecords.remove(resourceId); record.releaseResources(); record.nullifyRecord();
info = mTransformRecords.get(resourceId); if (info == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not active"); } if (info.pid != getCallingPid() || info.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may apply it!"); } IpSecConfig c = info.getConfig(); try { for (int direction : IpSecTransform.DIRECTIONS) { getNetdInstance() .ipSecApplyTransportModeTransform( socket.getFileDescriptor(), resourceId, direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", c.getSpi(direction) ); } } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception }
public final class BluetoothSocket implements Closeable { private static final String TAG = "BluetoothSocket"; private static final boolean DBG = true; private static final boolean VDBG = Log.isLoggable(TAG, Log.VERBOSE); public static final int MAX_RFCOMM_CHANNEL = 30; static final int MAX_L2CAP_PACKAGE_SIZE = 0xFFFF; public static final int TYPE_RFCOMM = 1; public static final int TYPE_SCO = 2; public static final int TYPE_L2CAP = 3; static final int EBADFD = 77; static final int EADDRINUSE = 98; }
/* Copyright (C) 2015 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net.cts; import android.content.Context; import android.net.ConnectivityManager; import android.net.IpSecAlgorithm; import android.net.IpSecManager; import android.net.IpSecTransform; import android.net.Network; import android.test.AndroidTestCase; import java.io.IOException; import java.net.DatagramPacket; import java.net.DatagramSocket; import java.net.InetAddress; import java.net.UnknownHostException;
public void testAllocSpi() { for (InetAddress addr : GOOGLE_DNS_LIST) { IpSecManager.SecurityParameterIndex randomSpi = null, droidSpi = null; try { randomSpi = mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_OUT, addr, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); assertTrue(randomSpi.getSpi() != IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); droidSpi = mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue(droidSpi.getSpi() == DROID_SPI); } catch (IpSecManager.ResourceUnavailableException | IpSecManager.SpiUnavailableException ru) { assertTrue(false); } // This *should* throw an SpiUnavailableException try { mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue(false); // we expect an exception in the above call } catch (IpSecManager.ResourceUnavailableException ru) { assertTrue(false); } catch (IpSecManager.SpiUnavailableException sp) { } randomSpi.close(); droidSpi.close(); } }
throws AuthException, BadRequestException, ResourceConflictException, Exception { try { ChangeSet cs = mergeSuperSet.completeChangeSet(dbProvider.get(), ChangeSet.create(resource.getChange())); json.addOptions(EnumSet.of(ListChangesOption.CURRENT_REVISION, ListChangesOption.CURRENT_COMMIT, ListChangesOption.DETAILED_LABELS, ListChangesOption.LABELS)); return json.format(cs.ids()); } catch (OrmException | IOException e) { log.error("Error on getting a ChangeSet", e); return Collections.emptyList(); } } throws AuthException, BadRequestException, ResourceConflictException, Exception { try { ChangeSet cs = mergeSuperSet.completeChangeSet(dbProvider.get(), ChangeSet.create(resource.getChange())); json.addOptions(EnumSet.of(ListChangesOption.CURRENT_REVISION, ListChangesOption.CURRENT_COMMIT, ListChangesOption.DETAILED_LABELS, ListChangesOption.LABELS)); return json.format(cs.ids()); } catch (OrmException | IOException e) { log.error("Error on getting a ChangeSet", e); throw e; } } public void test_NoClassDefFoundError_constructor_with_cause() { Class<NoClassDefFoundError> klass = NoClassDefFoundError.class; try { klass.getDeclaredConstructor(String.class, Throwable.class); } catch (Exception exc) { throw new RuntimeException(exc); } } public void test_NoClassDefFoundError_constructor_with_cause() { Class<NoClassDefFoundError> klass = NoClassDefFoundError.class; // This will succeed if the constructor is declared in NoClassDefFoundError. klass.getDeclaredConstructor(String.class, Throwable.class); } // a statestore heartbeat that contains the update. resp.getResult().setVersion(modifiedObjects.second.getCatalogVersion()); } else { // Invalidate the entire catalog if no table name is provided. Preconditions.checkArgument(!req.isIs_refresh()); catalog_.reset(); resp.result.setVersion(catalog_.getCatalogVersion()); } resp.getResult().setStatus(new TStatus(TStatusCode.OK, new ArrayList<String>())); return resp; } // a statestore heartbeat that contains the update. resp.getResult().setVersion(modifiedObjects.second.getCatalogVersion()); } else { // Invalidate the entire catalog if no table name is provided. Preconditions.checkArgument(!req.isIs_refresh()); catalog_.reset(); resp.result.setVersion(catalog_.
public void testCreateTransform() { InetAddress remote = InetAddress.getLoopbackAddress(); IpSecManager.SecurityParameterIndex outSpi = mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_OUT, remote, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); IpSecManager.SecurityParameterIndex inSpi = mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_IN, remote, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); IpSecTransform firstTransform = new IpSecTransform.Builder(mContext) .setSpi(IpSecTransform.DIRECTION_OUT, outSpi) .setEncryption(IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm(IpSecAlgorithm.ALGO_CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication(IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm(IpSecAlgorithm.ALGO_AUTH_HMAC_SHA256, AUTH_KEY, AUTH_KEY.length * 8)) .setSpi(IpSecTransform.DIRECTION_IN, inSpi) .setEncryption(IpSecTransform.DIRECTION_IN, new IpSecAlgorithm(IpSecAlgorithm.ALGO_CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication(IpSecTransform.DIRECTION_IN, new IpSecAlgorithm(IpSecAlgorithm.ALGO_AUTH_HMAC_SHA256, AUTH_KEY, AUTH_KEY.length * 8)) .build(); }
TimeZone biasMatch = null; for (int i = 0; i < candidates.size(); i++) { TimeZone match = candidates.get(i); if (!offsetMatchesAtTime(match, offsetSeconds, isDst, whenMillis)) { continue; } if (firstMatch == null) { firstMatch = match; if (bias == null) { // Terminate early if there is no bias. break; } } if (match.getID().equals(bias.getID())) { biasMatch = match; break; } } if (biasMatch != null) { return biasMatch; } else if (firstMatch != null) { return firstMatch; } else { return null; }
import java.nio.file.Path; import java.nio.file.SimpleFileVisitor; import java.nio.file.attribute.BasicFileAttributes; import java.util.Arrays; import java.util.HashMap; import java.util.HashSet; import java.util.List; import java.util.Map; import java.util.Set; import java.util.stream.Collectors; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertNull; import static org.junit.Assert.fail; public class TimeZoneFinderTest { private Path testDir; private static final int HOUR_MILLIS = 60 * 60 * 1000; private static final TimeZone NEW_YORK_TZ = TimeZone.getTimeZone("America/New_York"); private static final TimeZone LONDON_TZ = TimeZone.getTimeZone("Europe/London"); private static final TimeZone WHEN_NO_DST = TimeZone.getTimeZone("Europe/Paris"); private static final TimeZone WHEN_DST = TimeZone.getTimeZone("Europe/Madrid"); private static final Set<String> ZONES_WITH_DST = new HashSet<>(Arrays.asList( "America/Los_Angeles", "America/Denver", "America/Chicago", "America/New_York", "Europe/London", "Europe/Paris", "Europe/Madrid", "Asia/Tokyo", "Australia/Sydney" )); private static final Set<String> ZONES_WITHOUT_DST = new HashSet<>(Arrays.asList( "America/Phoenix", "America/Adak", "Pacific/Honolulu", "Pacific/Guam", "Pacific/Samoa", "Pacific/Midway", "Pacific/Niue", "Pacific/Pago_Pago", "Pacific/Tahiti", "Pacific/Marquesas", "Pacific/Gambier", "Pacific/Pitcairn", "Pacific/Galapagos", "Pacific/Easter", "Pacific/Fakaofo", "Pacific/Tongatapu", "Pacific/Apia", "Pacific/Kiritimati", "Pacific/Chatham", "Pacific/Auckland", "Pacific/Fiji", "Pacific/Noumea", "Pacific/Norfolk", "Pacific/Vanuatu", "Pacific/Wallis", "Pacific/Funafuti", "Pacific/Kwajalein", "Pacific/Majuro", "Pacific/Nauru", "Pacific/Tarawa", "Pacific/Wake", "Pacific/Yap", "Pacific/Chuuk", "Pacific/Pohnpei", "
@Test public void xmlParsing_emptyFile() throws Exception { checkThrowsParserException(""); } @Test public void xmlParsing_unexpectedRootElement() throws Exception { checkThrowsParserException("<foo></foo>\n"); } @Test public void xmlParsing_missingCountryZones() throws Exception { checkThrowsParserException("<timezones></timezones>\n"); } @Test public void xmlParsing_noCountriesOk() throws Exception { parse("<timezones>\n" + " <countryzones>\n" + " </countryzones>\n" + "</timezones>\n"); } @Test public void xmlParsing_unexpectedElementsIgnored() throws Exception { String unexpectedElement = "<unexpected-element>\n<a /></unexpected-element>\n"; TimeZoneFinder finder = parse("<timezones>\n" + " " + unexpectedElement + " <countryzones>\n" + " <country code=\"gb\">\n" + " <id>Europe/London</id>\n" + " </country>\n" + " </countryzones>\n" + "</timezones>\n"); }
@Test public void xmlParsing_unexpectedElementsIgnored() throws Exception { String unexpectedElement = "<unexpected-element>\n<a /></unexpected-element>\n"; TimeZoneFinder finder = parse("<timezones>\n" + unexpectedElement + " <countryzones>\n" + " <country code=\"gb\">\n" + " <id>Europe/London</id>\n" + " </country>\n" + " </countryzones>\n" + "</timezones>\n"); assertZonesEqual(zones("Europe/London"), finder.lookupTimeZonesByCountry("gb")); finder = parse("<timezones>\n" + " <countryzones>\n" + unexpectedElement + " </countryzones>\n" + "</timezones>\n"); assertZonesEqual(zones(), finder.lookupTimeZonesByCountry("gb")); }
mHandler.sendMessageDelayed(msg1, 1000); } break; case MSG_INCOMING_CONNECTION_RETRY: if (mBatchs.size() == 0) { Log.i(TAG, "Start Obex Server"); createServerSession(mPendingConnection); mIncomingRetries = 0; mPendingConnection = null; } else { if (mIncomingRetries == 20) { Log.w(TAG, "Retried 20 seconds, reject connection"); if (mServerSocket != null) { mServerSocket.prepareForNewConnect(); } try { mPendingConnection.close(); } catch (IOException e) { Log.e(TAG, "close tranport error"); } mIncomingRetries = 0; mPendingConnection = null; } else { Log.i(TAG, "OPP busy! Retry after 1 second"); mIncomingRetries = mIncomingRetries + 1; Message msg2 = Message.obtain(mHandler); msg2.what = MSG_INCOMING_CONNECTION_RETRY; mHandler.sendMessageDelayed(msg2, 1000); } } break;
protected void releaseResources() { for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { try { getNetdInstance() .ipSecDeleteSecurityAssociation( mResourceId, direction, (mConfig.getLocalAddress() != null) ? mConfig.getLocalAddress().getHostAddress() : "", (mConfig.getRemoteAddress() != null) ? mConfig.getRemoteAddress().getHostAddress() : "", mConfig.getSpi(direction) ); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw it as an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } }
protected void setUp() throws Exception { super.setUp(); mCM = (ConnectivityManager) getContext().getSystemService(Context.CONNECTIVITY_SERVICE); mISM = (IpSecManager) getContext().getSystemService(Context.IPSEC_SERVICE); } public void testAllocSpi() throws Exception { for (InetAddress addr : GOOGLE_DNS_LIST) { IpSecManager.SecurityParameterIndex randomSpi = null, droidSpi = null; randomSpi = mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_OUT, addr); assertTrue("Failed to receive a valid SPI", randomSpi.getSpi() != IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); droidSpi = mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue("Failed to allocate specified SPI, " + DROID_SPI, droidSpi.getSpi() == DROID_SPI); try { mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_IN, addr, DROID_SPI); fail("Expected SpiUnavailable exception"); } catch (SpiUnavailableException e) { // Expected exception } mISM.releaseSecurityParameterIndex(randomSpi); mISM.releaseSecurityParameterIndex(droidSpi); } }
private void testCreateTransform() throws Exception { InetAddress local = InetAddress.getLoopbackAddress(); IpSecManager.SecurityParameterIndex outSpi = mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_OUT, local); IpSecManager.SecurityParameterIndex inSpi = mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_IN, local, outSpi.getSpi()); IpSecTransform transform = new IpSecTransform.Builder(mContext) .setSpi(IpSecTransform.DIRECTION_OUT, outSpi) .setEncryption(IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm(IpSecAlgorithm.CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication(IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm(IpSecAlgorithm.AUTH_HMAC_SHA256)) .setSpi(IpSecTransform.DIRECTION_IN, inSpi) .setEncryption(IpSecTransform.DIRECTION_IN, new IpSecAlgorithm(IpSecAlgorithm.CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication(IpSecTransform.DIRECTION_IN, new IpSecAlgorithm(IpSecAlgorithm.AUTH_HMAC_SHA256)) .build(); transform.close(); mISM.releaseSecurityParameterIndex(outSpi); mISM.releaseSecurityParameterIndex(inSpi); }
if (length > 1) { String strippedSymbol = symbol.replaceAll("[\u200E\u200F\u061C]", ""); if (strippedSymbol.length() == 1) { return strippedSymbol.charAt(0); } } return fallback;
public NetworkCapabilities setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier != null && Long.bitCount(mTransportTypes) != 1) { throw new IllegalStateException("Must have a single transport specified to use setNetworkSpecifier"); } if (networkSpecifier != null && !(networkSpecifier instanceof Parcelable)) { throw new IllegalArgumentException("Network specifier must be parcelable"); } mNetworkSpecifier = networkSpecifier; return this; }
/** * Sets the optional bearer specific network specifier. * This has no meaning if a single transport is also not specified, so calling * this without a single transport set will generate an exception, as will * subsequently adding or removing transports after this is set. * </p> * * @param networkSpecifier A concrete, parcelable framework class that extends * NetworkSpecifier. * * @hide */ public Builder setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier instanceof MatchAllNetworkSpecifier) { return this; } return setNetworkSpecifier(new StringNetworkSpecifier(networkSpecifier.toString())); } /** * Sets the optional bearer specific network specifier. * This has no meaning if a single transport is also not specified, so calling * this without a single transport set will generate an exception, as will * subsequently adding or removing transports after this is set. * </p> * * @param networkSpecifier An {@code String} of opaque format used to specify the bearer * specific network specifier where the bearer has a choice of * networks. */ public Builder setNetworkSpecifier(String networkSpecifier) { return setNetworkSpecifier(new StringNetworkSpecifier(networkSpecifier)); }
public Builder setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier instanceof MatchAllNetworkSpecifier) { throw new IllegalArgumentException("NetworkRequests must not use MatchAllNetworkSpecifier"); } mNetworkCapabilities.setNetworkSpecifier(networkSpecifier); return this; }
package android.net; public abstract class NetworkSpecifier { public static boolean isWhitelistedNetworkSpecifier(NetworkSpecifier ns) { return ns instanceof MatchAllNetworkSpecifier || ns instanceof StringNetworkSpecifier; } public NetworkSpecifier() {} public abstract boolean satisfies(NetworkSpecifier other); }
public abstract class NetworkSpecifier { public static boolean isWhitelistedNetworkSpecifier(NetworkSpecifier ns) { return ns instanceof MatchAllNetworkSpecifier || ns instanceof StringNetworkSpecifier; } public NetworkSpecifier() {} public abstract boolean satisfiedBy(NetworkSpecifier other); }
|| wiFiEnabledState == WifiManager.WIFI_STATE_DISABLED) { if (startConsentUi(packageName, Binder.getCallingUid(), WifiManager.ACTION_REQUEST_ENABLE)) { return true; } } } else if (wiFiEnabledState == WifiManager.WIFI_STATE_ENABLING || wiFiEnabledState == WifiManager.WIFI_STATE_ENABLED) { if (startConsentUi(packageName, Binder.getCallingUid(), WifiManager.ACTION_REQUEST_DISABLE)) { return true; } } } mWifiController.obtainMessageAndSend(CMD_WIFI_TOGGLED); return true; } @Override public int getWifiEnabledState() { enforceAccessPermission(); mLog.trace("getWifiEnabledState uid=%").c(Binder.getCallingUid()).flush();
import org.eclipse.sirius.viewpoint.description.style.BasicLabelStyleDescription; import org.osgi.framework.Version; import com.google.common.collect.Lists; public class FontFormatMigrationParticipant extends AbstractMigrationParticipant { private static final String ITALIC = "italic"; private static final String BOLD = "bold"; private static final Version MIGRATION_VERSION = new Version("10.0.0.20150513"); @Override public Version getMigrationVersion() { return MIGRATION_VERSION; } @Override public Object getValue(EObject object, EStructuralFeature feature, Object value, String loadedVersion) { List<FontFormat> labelFormat = Lists.newArrayList(); if (object instanceof BasicLabelStyleDescription) { if (feature.getEType() == ViewpointPackage.Literals.FONT_FORMAT) { if (value instanceof String) { String oldFontFormat = (String) value; if (oldFontFormat.contains(ITALIC)) { FontFormatHelper.setFontFormat(labelFormat, FontFormat.ITALIC_LITERAL); } } } } } } public class ExprRewriter { private int numChanges_ = 0; private final List<ExprRewriteRule> rules_; public ExprRewriter(List<ExprRewriteRule> rules) { rules_ = rules; } public ExprRewriter(ExprRewriteRule rule) { rules_ = Lists.newArrayList(rule); } public Expr rewrite(Expr expr, Analyzer analyzer) throws AnalysisException { int initialNumChanges = numChanges_; int oldNumChanges; Expr rewrittenExpr = expr; do { oldNumChanges = numChanges_; for (ExprRewriteRule rule : rules_) { rewrittenExpr = applyRuleRepeatedly(rewrittenExpr, rule, analyzer); } } while (oldNumChanges != numChanges_); return rewrittenExpr; } } public class DecimalFormatSymbols implements Cloneable, Serializable { public DecimalFormatSymbols() { } }
public void testBluetoothDirWrite() { try { File file = new File("/data/misc/bluetooth/test.file"); assertTrue("File not created", file.createNewFile()); file.delete(); } catch (Exception e) { fail("Exception creating file /data/misc/bluetooth/test.file"); } }
assertEquals(TimeZoneDistroInstaller.INSTALL_SUCCESS, installer.stageInstallWithErrorCode(stagedDistro.getBytes())); assertInstallDistroStaged(stagedDistro); TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder(NEWER_RULES_VERSION, 1) .setTzLookupXml(null) .buildUnvalidated(); assertEquals(TimeZoneDistroInstaller.INSTALL_FAIL_BAD_DISTRO_STRUCTURE, installer.stageInstallWithErrorCode(incompleteDistro.getBytes())); assertInstallDistroStaged(stagedDistro); assertNoInstalledDistro(); public void testStageInstallWithErrorCode_badTzLookupFile() throws Exception { TimeZoneDistro stagedDistro = createValidTimeZoneDistro(NEW_RULES_VERSION, 1); assertEquals(TimeZoneDistroInstaller.INSTALL_SUCCESS, installer.stageInstallWithErrorCode(stagedDistro.getBytes())); assertInstallDistroStaged(stagedDistro); TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder(NEWER_RULES_VERSION, 1) .setTzLookupXml("<foo />") .buildUnvalidated(); assertEquals(TimeZoneDistroInstaller.INSTALL_FAIL_VALIDATION_ERROR, installer.stageInstallWithErrorCode(incompleteDistro.getBytes())); assertInstallDistroStaged(stagedDistro); }
/** * Attempts to strip RTL, LTR and Arabic letter markers from {@code symbol}. * If the string contains a single non-marker character (and any number of marker characters), * then that character is returned, otherwise {@code fallback} is returned. * As an implementation detail {@code fallback} is also returned when {@code symbol} contains * U+0000, which is tolerated, as that would indicate a considerable problem with the input. * @hide */ // VisibleForTesting public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length == 1) { char c = symbol.charAt(0); if (c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000') { return c; } } else if (length > 1) { char nonMarker = 0; for (char c : symbol.toCharArray()) { if (c != '\u200E' && c != '\u200F' && c != '\u061C') { if (nonMarker == 0) { nonMarker = c; } else if (nonMarker != c) { return fallback; } } } if (nonMarker != 0) { return nonMarker; } } return fallback; }
/** * Attempts to strip RTL, LTR and Arabic letter markers from {@code symbol}. * If the string contains a single non-marker character (and any number of marker characters), * then that character is returned, otherwise {@code fallback} is returned. * @hide */ // VisibleForTesting public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length == 1) { char c = symbol.charAt(0); if (c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000') { return c; } } else if (length > 1) { char nonMarker = 0; for (char c : symbol.toCharArray()) {
public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length == 1) { char c = symbol.charAt(0); if (c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000') { return c; } } else if (length > 1) { char nonMarker = 0; for (int i = 0; i < length; i++) { char c = symbol.charAt(i); if (c == '\u200E' || c == '\u200F' || c == '\u061C') { continue; } if (nonMarker != 0 || c == '\u0000') { // more than one non-marker character or U+0000 in the input string. return fallback; } nonMarker = c; } if (nonMarker != 0) { return nonMarker; } } return fallback; }
public static char maybeStripMarkers(final String symbol, final char fallback) { final int length = symbol.length(); if (length >= 1) { boolean sawNonMarker = false; char nonMarker = 0; for (int i = 0; i < length; i++) { char c = symbol.charAt(i); if (c == '\u200E' || c == '\u200F' || c == '\u061C') { continue; } if (sawNonMarker) { // More than one non-marker character. return fallback; } sawNonMarker = true; nonMarker = c; } if (sawNonMarker) { return nonMarker; } } return fallback; }
private final StateMachine mTetherMasterSM; private final OffloadController mOffloadController; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor; private volatile TetheringConfiguration mConfig; private String mCurrentUpstreamIface; private Notification.Builder mTetheredNotificationBuilder; private int mLastNotificationId; public enum Mode { IDLE, TETHERING, LOCAL_ONLY_HOTSPOT } private boolean mRndisEnabled; private boolean mUsbTetherRequested; private boolean mWifiTetherRequested; public Tethering(Context context, INetworkManagementService nmService, INetworkStatsService statsService, INetworkPolicyManager policyManager, Looper looper, MockableSystemProperties systemProperties) { mContext = context; mNMService = nmService; mStatsService = statsService; mPolicyManager = policyManager; mLooper = looper; mSystemProperties = systemProperties; }
public int tetherInterface(String iface, int mode) { TetherInterfaceStateMachine tetherState = mTetherStates.get(iface); if (tetherState == null) { Log.e(TAG, "Tried to Tether an unknown iface: " + iface + ", ignoring"); return ConnectivityManager.TETHER_ERROR_UNKNOWN_IFACE; } if (tetherState.lastState != IControlsTethering.STATE_AVAILABLE) { Log.e(TAG, "Tried to Tether an unavailable iface: " + iface + ", ignoring"); return ConnectivityManager.TETHER_ERROR_UNAVAIL_IFACE; } tetherState.stateMachine.sendMessage(TetherInterfaceStateMachine.CMD_TETHER_REQUESTED, mode); return ConnectivityManager.TETHER_ERROR_NO_ERROR; }
private final StateMachine mTetherMasterSM; private final OffloadController mOffloadController; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor; private volatile TetheringConfiguration mConfig; private String mCurrentUpstreamIface; private Notification.Builder mTetheredNotificationBuilder; private int mLastNotificationId; public enum Mode { IDLE, TETHERING, LOCAL_HOTSPOT; } private boolean mRndisEnabled; private boolean mUsbTetherRequested; private boolean mWifiTetherRequested; public Tethering(Context context, INetworkManagementService nmService, INetworkStatsService statsService, INetworkPolicyManager policyManager, Looper looper, MockableSystemProperties systemProperties) { mContext = context; mNMService = nmService; mStatsService = statsService; mPolicyManager = policyManager; mLooper = looper; mSystemProperties = systemProperties; }
public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { if (mActiveDownstreams.offer(new Downstream(downstream, mNextSubnetId))) { mNextSubnetId = (short) Math.max(0, mNextSubnetId + 1); } updateIPv6TetheringInterfaces(); } }
// Make a local copy, so we can modify it. final RaParams deprecated = new RaParams(deprecatedParams); // Remove any ULA DNS servers. removeULAs(deprecated.dnses); // Process newly deprecated information. mDeprecatedInfoTracker.putPrefixes(deprecated.prefixes); mDeprecatedInfoTracker.putDnses(deprecated.dnses); // Make a local copy, so we can modify it. final RaParams params = (newParams != null) ? new RaParams(newParams) : null; if (params != null) { // Remove any ULA DNS servers. removeULAs(params.dnses); // Process information that is no longer deprecated. mDeprecatedInfoTracker.removePrefixes(params.prefixes); mDeprecatedInfoTracker.removeDnses(params.dnses); } mRaParams = params; assembleRaLocked(); maybeNotifyMulticastTransmitter();
when(mResources.getStringArray(com.android.internal.R.array.config_mobile_hotspot_provision_app)) .thenReturn(new String[]{"malformedApp"}); assertTrue(!mTethering.isTetherProvisioningRequired()); private void sendWifiApStateChanged(int state) { final Intent intent = new Intent(WifiManager.WIFI_AP_STATE_CHANGED_ACTION); intent.putExtra(WifiManager.EXTRA_WIFI_AP_STATE, state); mServiceContext.sendStickyBroadcastAsUser(intent, UserHandle.ALL); } @Test public void workingWifiHotspot() throws Exception { when(mConnectivityManager.isTetheringSupported()).thenReturn(true); when(mWifiManager.setWifiApEnabled(any(WifiConfiguration.class), anyBoolean())) .thenReturn(true); mTethering.interfaceStatusChanged(mTestIfname, true); sendWifiApStateChanged(WifiManager.WIFI_AP_STATE_ENABLED); mLooper.dispatchAll(); verify(mNMService, times(1)).listInterfaces(); verify(mNMService, times(1)).getInterfaceConfig(mTestIfname); }
intent.putExtra(WifiManager.EXTRA_WIFI_AP_STATE, state); mServiceContext.sendStickyBroadcastAsUser(intent, UserHandle.ALL); } @Test public void workingWifiHotspot() throws Exception { when(mConnectivityManager.isTetheringSupported()).thenReturn(true); when(mWifiManager.setWifiApEnabled(any(WifiConfiguration.class), anyBoolean())) .thenReturn(true); // Emulate externally-visible WifiManager effects, causing the per-interface state machine starts up, and telling us that hotspot mode is to be started. mTethering.interfaceStatusChanged(mTestIfname, true); sendWifiApStateChanged(WifiManager.WIFI_AP_STATE_ENABLED); mLooper.dispatchAll(); verify(mNMService, times(1)).listInterfaces(); verify(mNMService, times(1)).getInterfaceConfig(mTestIfname); verify(mNMService, times(1)) .setInterfaceConfig(eq(mTestIfname), any(InterfaceConfiguration.class)); verify(mNMService, times(1)).tetherInterface(mTestIfname); verify(mNMService, times(1)).setIpForwardingEnabled(true); verify(mNMService, times(1)).startTethering(any(String[].class)); verifyNoMoreInteractions(mNMService); }
private void combineSpecifiers(NetworkCapabilities nc) { if (mNetworkSpecifier != null && !mNetworkSpecifier.equals(nc.getNetworkSpecifier())) { throw new IllegalStateException("Can't combine two networkSpecifiers"); } setNetworkSpecifier(nc.getNetworkSpecifier()); }
private void combineSpecifiers(NetworkCapabilities nc) { if (mNetworkSpecifier != null && !mNetworkSpecifier.equals(nc.getNetworkSpecifier())) { throw new IllegalStateException("Can't combine two networkSpecifiers"); } setNetworkSpecifier(nc.getNetworkSpecifier()); }
import com.android.sched.util.file.CannotChangePermissionException; import com.android.sched.util.file.CannotCreateFileException; import com.android.sched.util.file.Directory; import com.android.sched.util.file.FileAlreadyExistsException; import com.android.sched.util.file.FileOrDirectory; import com.android.sched.util.file.FileOrDirectory.ChangePermission; import com.android.sched.util.file.FileOrDirectory.Existence; import com.android.sched.util.file.FileOrDirectory.Permission; import com.android.sched.util.file.FileUtils; import com.android.sched.util.file.Files; import com.android.sched.util.file.InputJarFile; import com.android.sched.util.file.NoSuchFileException; import com.android.sched.util.file.NotDirectoryException; import com.android.sched.util.file.OutputZipFile.Compression; import com.android.sched.util.file.WriterFile; import com.android.sched.util.file.WrongPermissionException; import com.android.sched.util.location.FileLocation; import com.android.sched.util.location.NoLocation; import com.android.sched.util.location.StringLocation; import com.android.sched.util.log.LoggerFactory; import com.android.sched.util.log.TracerFactory; import com.android.sched.util.log.tracer.StatsTracerFtl; import com.android.sched.vfs.Container; public Range update(final double min, final double max, int length) { if (scale.isLogScaleEnabled() && (min <= 0 || max <= 0)) { throw new IllegalArgumentException("Range for log scale must be in positive range"); } final int maximumNumTicks = Math.min(MAX_TICKS, length / (scale.isHorizontal() ? TICKMINDIST_IN_PIXELS_X : TICKMINDIST_IN_PIXELS_Y) + 1); int numTicks = Math.max(3, maximumNumTicks); final TickFactory tf; if (scale instanceof AbstractScale) { AbstractScale aScale = (AbstractScale) scale; if (aScale.hasUserDefinedFormat()) { tf = new TickFactory(scale); } else if (aScale.isAutoFormat()) { tf = new TickFactory(TickFormatting.autoMode, scale); } else { String format = aScale.getFormatPattern(); if (format.contains("E")) { tf = new TickFactory(TickFormatting.useExponent, scale); } else { tf = new TickFactory(TickFormatting.autoMode, scale); }
NetworkCapabilities nc = new NetworkCapabilities(networkCapabilities); if (!ConnectivityManager.checkChangePermission(mContext)) { nc.addCapability(NET_CAPABILITY_FOREGROUND); } NetworkRequest networkRequest = new NetworkRequest(nc, TYPE_NONE, nextNetworkRequestId(), NetworkRequest.Type.LISTEN); NetworkRequestInfo nri = new NetworkRequestInfo(messenger, networkRequest, binder); mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_LISTENER, nri)); return networkRequest;
public void pendingListenForNetwork(NetworkCapabilities networkCapabilities, PendingIntent operation) { checkNotNull(operation, "PendingIntent cannot be null."); if (!hasWifiNetworkListenPermission(networkCapabilities)) { enforceAccessPermission(); } NetworkRequest networkRequest = new NetworkRequest( new NetworkCapabilities(networkCapabilities), TYPE_NONE, nextNetworkRequestId(), NetworkRequest.Type.LISTEN ); NetworkRequestInfo nri = new NetworkRequestInfo(networkRequest, operation); if (VDBG) { log("pendingListenForNetwork for " + nri); } mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_LISTENER, nri)); }
public void setNetworkSpecifier(NetworkSpecifier specifier) { if (specifier == null) { mNetworkCapabilities.setNetworkSpecifier(null); } else { mNetworkCapabilities.setNetworkSpecifier(specifier); } mNetworkAgent.sendNetworkCapabilities(mNetworkCapabilities); }
public void testNetworkSpecifier() { NetworkRequest rEmpty1 = newWifiRequestBuilder().build(); NetworkRequest rEmpty2 = newWifiRequestBuilder().setNetworkSpecifier((String) null).build(); NetworkRequest rEmpty3 = newWifiRequestBuilder().setNetworkSpecifier("").build(); NetworkRequest rEmpty4 = newWifiRequestBuilder().setNetworkSpecifier((NetworkSpecifier) null).build(); NetworkRequest rFoo = newWifiRequestBuilder().setNetworkSpecifier("foo").build(); NetworkRequest rBar = newWifiRequestBuilder().setNetworkSpecifier(new StringNetworkSpecifier("bar")).build(); TestNetworkCallback cEmpty1 = new TestNetworkCallback(); TestNetworkCallback cEmpty2 = new TestNetworkCallback(); TestNetworkCallback cEmpty3 = new TestNetworkCallback(); TestNetworkCallback cEmpty4 = new TestNetworkCallback(); TestNetworkCallback cFoo = new TestNetworkCallback(); TestNetworkCallback cBar = new TestNetworkCallback(); TestNetworkCallback[] emptyCallbacks = new TestNetworkCallback[] { cEmpty1, cEmpty2, cEmpty3 }; mCm.registerNetworkCallback(rEmpty1, cEmpty1); mCm.registerNetworkCallback(rEmpty2, cEmpty2); mCm.registerNetworkCallback(rEmpty3, cEmpty3); mCm.registerNetworkCallback(rEmpty4, cEmpty4); mCm.registerNetworkCallback(rFoo, cFoo); mCm.registerNetworkCallback(rBar, cBar); }
mCm.registerNetworkCallback(rEmpty3, cEmpty3); mCm.registerNetworkCallback(rEmpty4, cEmpty4); mCm.registerNetworkCallback(rFoo, cFoo); mCm.registerNetworkCallback(rBar, cBar); mWiFiNetworkAgent = new MockNetworkAgent(TRANSPORT_WIFI); mWiFiNetworkAgent.connect(false); cEmpty1.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty2.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty3.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty4.expectAvailableCallbacks(mWiFiNetworkAgent); assertNoCallbacks(cFoo, cBar); mWiFiNetworkAgent.setNetworkSpecifier("foo"); cFoo.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c : emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } cFoo.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); cFoo.assertNoCallback(); mWiFiNetworkAgent.setNetworkSpecifier("bar"); cFoo.expectCallback(CallbackState.LOST, mWiFiNetworkAgent); cBar.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c : emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); }
cEmpty2.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty3.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty4.expectAvailableCallbacks(mWiFiNetworkAgent); assertNoCallbacks(cFoo, cBar); mWiFiNetworkAgent.setNetworkSpecifier("foo"); cFoo.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c : emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } cFoo.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); cFoo.assertNoCallback(); mWiFiNetworkAgent.setNetworkSpecifier("bar"); cFoo.expectCallback(CallbackState.LOST, mWiFiNetworkAgent); cBar.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c : emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } cBar.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); cBar.assertNoCallback(); mWiFiNetworkAgent.setNetworkSpecifier(null); cBar.expectCallback(CallbackState.LOST, mWiFiNetworkAgent); for (TestNetworkCallback c : emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } assertNoCallbacks(cEmpty1, cEmpty2, cEmpty3, cFoo, cBar);
import org.bouncycastle.crypto.generators.BCrypt; import org.bouncycastle.util.Arrays; public class HashedPassword { private static final String ALGORITHM = "bcrypt"; private static SecureRandom secureRandom = new SecureRandom(); private static Base64 codec = new Base64(-1); public static HashedPassword decode(String encoded) { Preconditions.checkState(encoded.startsWith(ALGORITHM + ":")); String[] fields = encoded.split(":"); Preconditions.checkState(fields.length == 4); int cost = Integer.parseInt(fields[1]); return new HashedPassword(codec.decodeBase64(fields[3]), codec.decodeBase64(fields[2]), cost); } private static byte[] hashPassword(String password, byte[] salt, int cost) { byte pwBytes[] = password.getBytes(StandardCharsets.UTF_8); // hashing logic } } import org.apache.harmony.jpda.tests.share.JPDADebuggeeSynchronizer; public class BreakpointOnCatchTest extends JDWPEventTestCase { @Override protected String getDebuggeeClassName() { return BreakpointOnCatchDebuggee.class.getName(); } public void testBreakpointOnCatch() { logWriter.println("testBreakpointOnCatch started"); synchronizer.receiveMessage(JPDADebuggeeSynchronizer.SGNL_READY); long classID = getClassIDBySignature(getDebuggeeClassSignature()); long methodID = getMethodID(classID, BreakpointOnCatchDebuggee.BREAKPOINT_METHOD_NAME); logWriter.println("Install breakpoint in " + BreakpointOnCatchDebuggee.BREAKPOINT_METHOD_NAME); // breakpoint installation logic } } class ParcelableSpecifier extends NonParcelableSpecifier implements Parcelable { @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel p, int flags) { // parcel writing logic } } NetworkRequest.Builder builder; builder = new NetworkRequest.Builder().addTransportType(TRANSPORT_ETHERNET); try { builder.setNetworkSpecifier(new NonParcelableSpecifier()); Parcel parcelW = Parcel.obtain(); builder.build().writeToParcel(parcelW, 0); fail("Non-parcelable specifier did not throw exception"); } catch (Exception e) { // expected }
private int phoneIdForRequest(NetworkRequest netRequest) { NetworkSpecifier specifier = netRequest.networkCapabilities.getNetworkSpecifier(); int subId; if (specifier == null) { subId = mDefaultDataSubscription; } else if (specifier instanceof StringNetworkSpecifier) { try { subId = Integer.parseInt(((StringNetworkSpecifier) specifier).specifier); } catch (NumberFormatException e) { subId = INVALID_SUBSCRIPTION_ID; } } else { subId = INVALID_SUBSCRIPTION_ID; } int phoneId = INVALID_PHONE_INDEX; if (subId == INVALID_SUBSCRIPTION_ID) { return phoneId; } for (int i = 0; i < mNumPhones; i++) { if (mPhoneSubscriptions[i] == subId) { phoneId = i; break; } } return phoneId; }
package android.net; import android.net.wifi.aware.WifiAwareNetworkSpecifier; public abstract class NetworkSpecifier { public NetworkSpecifier() {} public abstract boolean satisfiedBy(NetworkSpecifier other); }
public void resize(int newSize) { int oldSize = mSize; mSize = newSize; ensureCapacity(mSize); if (newSize < oldSize) { Arrays.fill(mValues, newSize, oldSize, 0); } }
public void resize(int newSize) { int oldSize = mSize; mSize = newSize; ensureCapacity(mSize); if (newSize > oldSize) { Arrays.fill(mValues, oldSize, newSize, 0); } }
public void resize(int newSize) { // Throw on negative size if (newSize < 0) { throw new IllegalArgumentException("Size cannot be negative"); } int oldSize = mSize; mSize = newSize; ensureCapacity(mSize); if (newSize < oldSize) { Arrays.fill(mValues, newSize, oldSize, 0); } }
// limitations under the License. package com.google.gerrit.server.query.doc; import com.google.common.collect.Lists; import com.google.gerrit.extensions.restapi.RestReadView; import com.google.gerrit.extensions.restapi.TopLevelResource; import com.google.gerrit.server.query.QueryParseException; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import org.kohsuke.args4j.Option; import java.util.List; public class QueryDocs implements RestReadView<TopLevelResource> { private final DocQueryProcessor imp; public static class DocResult { public String title; public String url; public String content; } @Option(name = "--query", aliases = {"-q"}, metaVar = "QUERY", multiValued = true, usage = "Query string") private List<String> queries; @Inject QueryDocs(DocQueryProcessor imp) { this.imp = imp; } public void addQuery(String query) { if (queries == null) { queries = Lists.newArrayList(); } queries.add(query); } @Override public void apply(TopLevelResource resource) throws QueryParseException, OrmException { // Implementation of apply method } }
// changes network state. http://b/29964605 enforceMeteredApnPolicy(networkCapabilities); ensureRequestableCapabilities(networkCapabilities); if (timeoutMs < 0) { throw new IllegalArgumentException("Bad timeout specified"); } if (networkCapabilities.getNetworkSpecifier() instanceof MatchAllNetworkSpecifier) { throw new IllegalArgumentException("NetworkRequest with MatchAllNetworkSpecifier"); } if (networkCapabilities.getNetworkSpecifier() instanceof NetworkSpecifier.UidConsumer) { ((NetworkSpecifier.UidConsumer) networkCapabilities.getNetworkSpecifier()) .setRequestorUid(Binder.getCallingUid()); } NetworkRequest networkRequest = new NetworkRequest(networkCapabilities, legacyType, nextNetworkRequestId(), type); NetworkRequestInfo nri = new NetworkRequestInfo(messenger, networkRequest, binder); if (DBG) log("requestNetwork for " + nri); mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_REQUEST, nri)); if (timeoutMs > 0) { mHandler.sendMessageDelayed(mHandler.obtainMessage(EVENT_TIMEOUT_NETWORK_REQUEST, nri), timeoutMs); } return networkRequest;
public static void main(String[] args) { // Set up minint32, maxint32 and some others. int[] xi = new int[8]; xi[0] = 0x80000000; xi[1] = 0x7fffffff; xi[2] = -999; xi[3] = -13; xi[4] = -1; xi[5] = 0; xi[6] = 1; xi[7] = 999; doitInt(xi); expectEquals32(0x80000000, xi[0]); expectEquals32(0x7fffffff, xi[1]); expectEquals32(999, xi[2]); expectEquals32(13, xi[3]); expectEquals32(1, xi[4]); expectEquals32(0, xi[5]); expectEquals32(1, xi[6]); expectEquals32(999, xi[7]); // Set up minint64, maxint64 and some others. long[] xl = new long[8]; xl[0] = 0x8000000000000000L; xl[1] = 0x7fffffffffffffffL; xl[2] = -999; xl[3] = -13; xl[4] = -1; xl[5] = 0; xl[6] = 1; xl[7] = 999; }
@Test public void test_getFileStore_NPE() throws IOException { try { provider.getFileStore(null); fail(); } catch(SecurityException expected) { } }
} else { return false; } @Rpc(description = "request a network") public String connectivityRequestNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); networkRequest.networkCapabilities.setNetworkSpecifier(WifiAwareManagerFacade.getNetworkSpecifier(j)); } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; }
protected void bindZookeeperLockFactory() { ZookeeperLockFactory lockFactory = mock(ZookeeperLockFactory.class); InterProcessSemaphoreMutex lock = mock(InterProcessSemaphoreMutex.class); when(lockFactory.createShared(anyString())).thenReturn(lock); try { doReturn(true).when(lock).acquire(anyLong(), any(TimeUnit.class)); doNothing().when(lock).release(); } catch (Exception e) { throw new RuntimeException(e); } bind(ZookeeperLockFactory.class).toInstance(lockFactory); } public ZookeeperConnectionModule(Class<? extends ZkConnectionAwareWatcher> connWatcherImpl) { this.connWatcherImpl = connWatcherImpl; } Set<Change.Id> visibleChanges = visibleChanges(); Map<String, Ref> result = new HashMap<>(); List<Ref> deferredTags = new ArrayList<>(); for (Ref ref : refs.values()) { Change.Id changeId; Account.Id accountId; if (ref.getName().startsWith(RefNames.REFS_CACHE_AUTOMERGE)) { continue; } else if (showMetadata && ((currAccountId != null && RefNames.isRefsEditOf(ref.getLeaf().getName(), currAccountId)) || (RefNames.isRefsEdit(ref.getLeaf().getName()) && canViewMetadata))) { result.put(ref.getName(), ref); } else if ((changeId = Change.Id.fromRef(ref.getName())) != null) { // code omitted for brevity } } mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; @Rpc(description = "request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); networkRequest.networkCapabilities.setNetworkSpecifier(WifiAwareManagerFacade.getNetworkSpecifier(j)); } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; }
String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); networkRequest.networkCapabilities.setNetworkSpecifier(WifiAwareManagerFacade.getNetworkSpecifier(j)); } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "Stop listening for connectivity changes") public void connectivityStopTrackingConnectivityStateChange() { if (mTrackingConnectivityStateChange) { mTrackingConnectivityStateChange = false; mContext.unregisterReceiver(mConnectivityReceiver); } }
private static String networkTypeToString(int type) { String ret = "unknown"; switch (type) { case DATA_ACCESS_CDMA_IS95A: case DATA_ACCESS_CDMA_IS95B: case DATA_ACCESS_CDMA_1xRTT: ret = "CDMA"; break; case DATA_ACCESS_CDMA_EvDo_0: ret = "EVDO_0"; break; case DATA_ACCESS_CDMA_EvDo_A: ret = "EVDO_A"; break; default: if (DBG) { log("Unknown network type: " + type); } break; } return ret; } private void handleScoConnected(Message msg) { if (msg.arg1 == ScoSocket.STATE_CONNECTED && isHeadsetConnected() && mConnectedSco == null) { if (VDBG) log("Routing audio for outgoing SCO connection"); mConnectedSco = (ScoSocket) msg.obj; mAudioManager.setBluetoothScoOn(true); if (isCellularCallInProgress()) { broadcastAudioStateIntent(BluetoothHeadset.AUDIO_STATE_CONNECTED, mHeadset.getRemoteDevice()); } else if ((mHFScoState == HF_STATE_SCO_VIRTUALCALL_SETUP) || (mHFScoState == HF_STATE_SCO_VIRTUALCALL_TRANSFERRED)) { mHFScoState = HF_STATE_SCO_VIRTUALCALL_ACTIVE; broadcastVirtualCallStateIntent(BluetoothHeadset.VIRTUALCALL_STATE_CONNECTED); } if (DBG) log("mHandler: Updated mHFScoState:" + mHFScoState); } else if (msg.arg1 == ScoSocket.STATE_CONNECTED) { // Handle other cases } } @Rpc(description = "Request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); networkRequest.networkCapabilities.setNetworkSpecifier(WifiAwareManagerFacade.getNetworkSpecifier(j)); } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(network
public Uri insert(Uri uri, ContentValues values) { if (uri.isPathPrefixMatch(CONTENT_URI)) { // Parse the subId int subId = 0; try { subId = Integer.parseInt(uri.getLastPathSegment()); } catch (NumberFormatException e) { Log.d(TAG, "no subId provided, using default."); subId = getDefaultSubId(); } Log.d(TAG, "subId=" + subId); // create the new service state ServiceState newSS = new ServiceState(); newSS.setVoiceRegState(values.getAsInteger(VOICE_REG_STATE)); newSS.setDataRegState(values.getAsInteger(DATA_REG_STATE)); newSS.setVoiceOperatorName(values.getAsString(VOICE_OPERATOR_ALPHA_LONG), values.getAsString(VOICE_OPERATOR_ALPHA_SHORT), values.getAsString(VOICE_OPERATOR_NUMERIC)); newSS.setDataOperatorName(values.getAsString(DATA_OPERATOR_ALPHA_LONG), values.getAsString(DATA_OPERATOR_ALPHA_SHORT), values.getAsString(DATA_OPERATOR_NUMERIC)); newSS.setIsManualSelection(values.getAsBoolean(IS_MANUAL_NETWORK_SELECTION)); // TODO: Check if the insert operation requires a certain permission // TODO: Perform the insert operation // TODO: Return the inserted Uri } return null; }
private static byte getRandomNonZeroByte() { final byte random = (byte) (new Random()).nextInt(); return (random != 0) ? random : 0x1; }
protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.list_7); mPhone = (TextView) findViewById(R.id.phone); getListView().setOnItemSelectedListener(this); Cursor c = getContentResolver().query(ContactsContract.Contacts.CONTENT_URI, PEOPLE_PROJECTION, null, null, null); startManagingCursor(c); mColumnHasPhoneNumber = c.getColumnIndex(ContactsContract.Contacts.HAS_PHONE_NUMBER); mColumnContactId = c.getColumnIndex(ContactsContract.Contacts._ID); ListAdapter adapter = new SimpleCursorAdapter(this, android.R.layout.simple_list_item_1, c, new String[] {ContactsContract.Contacts.DISPLAY_NAME}, new int[] {android.R.id.text1}); setListAdapter(adapter); } public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); Cursor groupCursor = managedQuery(Contacts.CONTENT_URI, PEOPLE_PROJECTION, null, null, null); mContactIdColumnIndex = groupCursor.getColumnIndexOrThrow(ContactsContract.Contacts._ID); mAdapter = new MyExpandableListAdapter(groupCursor, this, android.R.layout.simple_expandable_list_item_1, android.R.layout.simple_expandable_list_item_1, new String[] {ContactsContract.Contacts.DISPLAY_NAME}, new int[] {android.R.id.text1}, new String[] {ContactsContract.CommonDataKinds.Phone.NUMBER}, new int[] {android.R.id.text1}); setListAdapter(mAdapter); } public boolean processMessage(Message message) { maybeLogMessage(this, message.what); boolean retValue = true; switch (message.what) { case CMD_TETHER_REQUESTED: final Mode mode; try { mode = (Mode) message.obj; } catch (ClassCastException e) { Log.e(TAG, "Invalid tethering interface mode given."); break; } Log.e(TAG, "CMD_TETHER_REQUESTED with mode " + mode + " when already operating in mode " + mMode); break; case CMD_TETHER_UNREQUESTED: transitionTo(mInitialState); if (DBG) Log.d(TAG, "Untethered (unrequested)" + mIfaceName); break; case CMD_INTERFACE_DOWN: transitionTo(mUnavailableState); if (DBG) Log.d(TAG, "Untethered (ifdown)" + mIfaceName); break;
public void testIntArray() { IntArray a = new IntArray(); a.resize(15); a.set(14, 30); verify(new int[]{1, 2, 0, 0, 0, 20, 10, 0, 0, 0, 0, 0, 0, 0, 30}, a); int[] backingArray = new int[]{1, 2, 3, 4}; a = IntArray.wrap(backingArray); a.set(0, 10); assertEquals(10, backingArray[0]); backingArray[1] = 20; backingArray[2] = 30; verify(backingArray, a); assertEquals(2, a.indexOf(30)); // Test shrinking and zeroing behavior a.resize(2); assertEquals(0, backingArray[2]); assertEquals(0, backingArray[3]); a.add(50); verify(new int[]{10, 20, 30, 4, 50}, a); } private void verify(int[] expected, IntArray actual) { assertEquals(expected.length, actual.size()); for (int i = 0; i < expected.length; i++) { assertEquals(expected[i], actual.get(i)); } }
Fixed Code: ```java a.resize(15); a.set(14, 30); verify(new long[]{1, 2, 0, 0, 0, 20, 10, 0, 0, 0, 0, 0, 0, 0, 30}, a); long[] backingArray = new long[]{1, 2, 3, 4}; a = LongArray.wrap(backingArray); a.set(0, 10); assertEquals(10, backingArray[0]); backingArray[1] = 20; backingArray[2] = 30; verify(backingArray, a); assertEquals(2, a.indexOf(30)); a.add(50); verify(new long[]{10, 20, 30, 4, 50}, a); ```
public SecurityParameterIndex reserveSecurityParameterIndex(int direction, InetAddress remoteAddress) throws ResourceUnavailableException { try { return new SecurityParameterIndex(mService, direction, remoteAddress, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); } catch (SpiUnavailableException impossible) { return null; } }
public SecurityParameterIndex reserveSecurityParameterIndex(int direction, InetAddress remoteAddress) throws ResourceUnavailableException { try { return new SecurityParameterIndex(mService, direction, remoteAddress, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); } catch (SpiUnavailableException impossible) { throw new ResourceUnavailableException("No free SPIs"); } }
Refactor the Buggy Code: ```java } } if (hostName != null) { hostAddr = InetAddress.getByName(hostName); serverSocket = new ServerSocket(port, 0, hostAddr); } else { serverSocket = new ServerSocket(port); } InetAddress iAddress = null; if (hostName != null) { iAddress = serverSocket.getInetAddress(); } else { iAddress = InetAddress.getLoopbackAddress(); } address = iAddress.getHostName() + ":" + serverSocket.getLocalPort(); return address; } @Override public void stopListening() throws IOException { if (serverSocket != null) { serverSocket.close(); } } @Override public void acceptAndHandshake(int acceptTimeout, int handshakeTimeout) throws IOException { Socket socket = serverSocket.accept(); performHandshake(socket, handshakeTimeout); } ``` Refactored Code: ```java if (hostName != null) { hostAddr = InetAddress.getByName(hostName); serverSocket = new ServerSocket(port, 0, hostAddr); } else { serverSocket = new ServerSocket(port); } InetAddress iAddress = null; if (hostName != null) { iAddress = serverSocket.getInetAddress(); } else { iAddress = InetAddress.getLoopbackAddress(); } address = iAddress.getHostName() + ":" + serverSocket.getLocalPort(); return address; } @Override public void stopListening() throws IOException { if (serverSocket != null) { serverSocket.close(); } } @Override public void acceptAndHandshake(int acceptTimeout, int handshakeTimeout) throws IOException { Socket socket = serverSocket.accept(); performHandshake(socket, handshakeTimeout); } ```
expectEquals(8070450532247928832L, geoLongMulLastValue(2147483647L)); expectEquals(0L, geoLongMulLastValue(-2147483648L)); expectEquals(8070450532247928832L, geoLongMulLastValue(9223372036854775807L)); expectEquals(0L, geoLongMulLastValue(-9223372036854775808L)); float[] a = new float[16]; narrowingSubscript(a); for (int i = 0; i < 16; i++) { expectEquals(2.0f, a[i]); } int[] xx = new int[2]; int[] yy = new int[469]; reduc(); expectEquals(-469, xx[0]); expectEquals(-938, xx[1]); for (int i = 0; i < 469; i++) { expectEquals(2, yy[i]); } System.out.println("passed");
mSentSinceLastRecv = 0; putRecoveryAction(RecoveryAction.GET_DATA_CALL_LIST); } else { if (VDBG_STALL) log("updateDataStallInfo: NONE"); } } private boolean isPhoneStateIdle() { for (int i = 0; i < TelephonyManager.getDefault().getPhoneCount(); i++ ) { Phone phone = PhoneFactory.getPhone(i); if (phone != null && phone.getState() != PhoneConstants.State.IDLE) { log("isPhoneStateIdle: Voice call active on phone: " + i); return false; } } return true; } private void onDataStallAlarm(int tag) { if (mDataStallAlarmTag != tag) { if (DBG) { log("onDataStallAlarm: ignore, tag=" + tag + " expecting " + mDataStallAlarmTag); } return; } updateDataStallInfo(); int hangWatchdogTrigger = Settings.Global.getInt(mResolver, Settings.Global.PDP_WATCHDOG_TRIGGER_PACKET_COUNT, NUMBER_SENT_PACKETS_OF_HANG); boolean suspectedStall = DATA_STALL_NOT_SUSPECTED;
chosenIface = iface; break; } } } if (chosenIface == null) { Log.e(TAG, "could not find iface of type " + interfaceType); return; } final int result; switch (requestedState) { case IControlsTethering.STATE_UNAVAILABLE: case IControlsTethering.STATE_AVAILABLE: result = untether(chosenIface); break; case IControlsTethering.STATE_TETHERED: case IControlsTethering.STATE_LOCAL_HOTSPOT: result = tether(chosenIface, requestedState); break; default: result = -1; } if (result != ConnectivityManager.TETHER_ERROR_NO_ERROR) { Log.e(TAG, "unable start or stop tethering on iface " + chosenIface); return; }
// by sending CMD_CLEAR_ERROR if (error == ConnectivityManager.TETHER_ERROR_MASTER_ERROR) { mTetherMasterSM.sendMessage(TetherMasterSM.CMD_CLEAR_ERROR, who); } switch (state) { case IControlsTethering.STATE_UNAVAILABLE: case IControlsTethering.STATE_AVAILABLE: mUpstreamWantingIfaces.remove(iface); mTetherMasterSM.sendMessage(TetherMasterSM.CMD_TETHER_MODE_UNREQUESTED, who); break; case IControlsTethering.STATE_TETHERED: mUpstreamWantingIfaces.add(iface); mTetherMasterSM.sendMessage(TetherMasterSM.CMD_TETHER_MODE_REQUESTED, who); break; case IControlsTethering.STATE_LOCAL_HOTSPOT: mUpstreamWantingIfaces.remove(iface); mTetherMasterSM.sendMessage(TetherMasterSM.CMD_TETHER_MODE_REQUESTED, who); break; } sendTetherStateChangedBroadcast();
case CMD_START_TETHERING_ERROR: case CMD_STOP_TETHERING_ERROR: case CMD_SET_DNS_FORWARDERS_ERROR: mLastError = ConnectivityManager.TETHER_ERROR_MASTER_ERROR; transitionTo(mInitialState); break; default: return false; } return true; } class LocalHotspotState extends State { @Override public void enter() { if (DBG) Log.d(TAG, "Local hotspot " + mIfaceName); setInterfaceState(IControlsTethering.STATE_LOCAL_HOTSPOT); } @Override public void exit() { } @Override public boolean processMessage(Message message) { maybeLogMessage(this, message.what); switch (message.what) { case CMD_TETHER_REQUESTED: Log.e(TAG, "CMD_TETHER_REQUESTED while in local hotspot mode."); break; case CMD_TETHER_CONNECTION_CHANGED: // Ignored in local hotspot state. break; default: return false; } return true; } } class TetheredState extends State { @Override public void enter() { if (DBG) Log.d(TAG, "Tethered " + mIfaceName); }
private final Object mPublicSync; private final Context mContext; private final ArrayMap<String, TetherState> mTetherStates; private final BroadcastReceiver mStateReceiver; private final INetworkManagementService mNMService; private final INetworkStatsService mStatsService; private final INetworkPolicyManager mPolicyManager; private final Looper mLooper; private final MockableSystemProperties mSystemProperties; private final StateMachine mTetherMasterSM; private final OffloadController mOffloadController; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor; private final HashSet<String> mIfacesWantingUpstream; private volatile TetheringConfiguration mConfig; private String mCurrentUpstreamIface; private Notification.Builder mTetheredNotificationBuilder; private int mLastNotificationId; private boolean mRndisEnabled; private boolean mUsbTetherRequested; private boolean mWifiTetherRequested; public Tethering(Context context, INetworkManagementService nmService, INetworkStatsService statsService, INetworkPolicyManager policyManager, Looper looper, MockableSystemProperties systemProperties) { mPublicSync = new Object(); mContext = context; mTetherStates = new ArrayMap<>(); mStateReceiver = new BroadcastReceiver(); mNMService = nmService; mStatsService = statsService; mPolicyManager = policyManager; mLooper = looper; mSystemProperties = systemProperties; mTetherMasterSM = new StateMachine(); mOffloadController = new OffloadController(); mUpstreamNetworkMonitor = new UpstreamNetworkMonitor(); mIfacesWantingUpstream = new HashSet<>(); mConfig = new TetheringConfiguration(); mCurrentUpstreamIface = null; mTetheredNotificationBuilder = new Notification.Builder(); mLastNotificationId = 0; mRndisEnabled = false; mUsbTetherRequested = false; mWifiTetherRequested = false; }
if (error == ConnectivityManager.TETHER_ERROR_MASTER_ERROR) { mTetherMasterSM.sendMessage(TetherMasterSM.CMD_CLEAR_ERROR, who); } int which; switch (state) { case IControlsTethering.STATE_UNAVAILABLE: case IControlsTethering.STATE_AVAILABLE: which = TetherMasterSM.EVENT_IFACE_SERVING_STATE_INACTIVE; break; case IControlsTethering.STATE_TETHERED: case IControlsTethering.STATE_LOCAL_HOTSPOT: which = TetherMasterSM.EVENT_IFACE_SERVING_STATE_ACTIVE; break; default: Log.wtf(TAG, "Unknown interface state: " + state); return; } mTetherMasterSM.sendMessage(which, state, 0, who); sendTetherStateChangedBroadcast();
capabilities |= PhoneAccount.CAPABILITY_VIDEO_CALLING_RELIES_ON_PRESENCE; if (mIsVideoCapable && isCarrierEmergencyVideoCallsAllowed()) { capabilities |= PhoneAccount.CAPABILITY_EMERGENCY_VIDEO_CALLING; } mIsVideoPauseSupported = isCarrierVideoPauseSupported(); Bundle phoneAccountExtras = new Bundle(); if (isCarrierInstantLetteringSupported()) { capabilities |= PhoneAccount.CAPABILITY_CALL_SUBJECT; phoneAccountExtras = getPhoneAccountExtras(phoneAccountExtras); } phoneAccountExtras.putInt(PhoneAccount.EXTRA_SORT_ORDER, slotId); mIsMergeCallSupported = isCarrierMergeCallSupported(); mIsVideoConferencingSupported = isCarrierVideoConferencingSupported(); mIsMergeOfWifiCallsAllowedWhenVoWifiOff = isCarrierMergeOfWifiCallsAllowedWhenVoWifiOff(); if (isEmergency && mContext.getResources().getBoolean(R.bool.config_emergency_account_emergency_calls_only)) { capabilities |= PhoneAccount.CAPABILITY_EMERGENCY_CALLS_ONLY; } if (icon == null) { Resources res = mContext.getResources(); Drawable drawable = res.getDrawable(DEFAULT_SIM_ICON, null); }
for (Map.Entry<Class<? extends UnitTest>, Integer> entry : allUnitTests.entrySet()) { int testApiVersion = entry.getValue(); // Only add test if test API version is not greater than build API version. if (testApiVersion <= thisApiVersion) { validUnitTests.add(entry.getKey()); } } return validUnitTests; } @Parameter(0) public Class<? extends com.android.rs.unit_test.UnitTest> mTestClass; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); UnitTest test = mTestClass.getDeclaredConstructor(Context.class).newInstance(ctx); test.runTest(); Assert.assertTrue(test.getSuccess()); }
private static void allocateReachableObjects(ArrayList<MockClass> reachableObjs) { for (int i = 0; i < reachableObjNum; i++) { reachableObjs.add(new MockClass(true)); } }
private static void allocateUnreachableObjects() { for(int i = 0; i < unreachableObjNum; i++) { new MockClass(false); } }
private static void allocateUnreachableObjects() { for (int i = 0; i < unreachableObjNum; i++) { new MockClass(false); } }
private void checkType(int columnIndex, Type expectedType) { ColumnSchema columnSchema = schema.getColumnByIndex(columnIndex); Type columnType = columnSchema.getType(); if (!columnType.equals(expectedType)) { throw new IllegalArgumentException("Column (name: " + columnSchema.getName() + ", index: " + columnIndex +") is of type " + columnType.getName() + " but was requested as a type " + expectedType.getName()); } } public Integer abs(Integer self) { return Integer.valueOf(Math.abs(self.intValue())); } public Integer floor(Double self) { return Integer.valueOf((int)Math.floor(self.doubleValue())); } public Integer floor(Integer self) { return self; } if (!mBinaryTestProfilingLibraryPath.isEmpty()) { jsonObject.put(BINARY_TEST_PROFILING_LIBRARY_PATH, new JSONArray(mBinaryTestProfilingLibraryPath)); CLog.i("Added %s to the Json object", BINARY_TEST_PROFILING_LIBRARY_PATH); } if (mBinaryTestType.equals(BINARY_TEST_TYPE_HAL_HIDL_GTEST)) { CLog.i("Set flags to stop the framework and native servers for %s", BINARY_TEST_TYPE_HAL_HIDL_GTEST); mBinaryTestStopNativeServers = true; } if (mBinaryTestDisableFramework) { jsonObject.put(BINARY_TEST_DISABLE_FRAMEWORK, mBinaryTestDisableFramework); CLog.i("Added %s to the Json object", BINARY_TEST_DISABLE_FRAMEWORK); } if (mBinaryTestStopNativeServers) { jsonObject.put(BINARY_TEST_STOP_NATIVE_SERVERS, mBinaryTestStopNativeServers); CLog.i("Added %s to the Json object", BINARY_TEST_STOP_NATIVE_SERVERS); } if (!mHalHidlReplayTestTracePaths.isEmpty()) { jsonObject.put(HAL_HIDL_REPLAY_TEST_TRACE_PATHS, new JSONArray(mHalHidlReplayTestTracePaths)); }
import android.util.Log; import java.util.Arrays; import java.util.Objects; /** * Network specifier object used to request a Wi-Fi Aware network. Apps do not create these objects * directly but obtain them using * {@link WifiAwareSession#createNetworkSpecifierOpen(int, byte[])} or * {@link DiscoverySession#createNetworkSpecifierOpen(PeerHandle)} or their secure (Passphrase) * versions. * * @hide */ public final class WifiAwareNetworkSpecifier extends NetworkSpecifier implements Parcelable, NetworkSpecifier.UidContainer { /** * TYPE: in band, specific peer: role, client_id, session_id, peer_id, pmk/passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB = 0; /** * TYPE: in band, any peer: role, client_id, session_id, pmk/passphrase optional * [only permitted for RESPONDER] * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB_ANY_PEER = 1; /** * TYPE: out-of-band: role, client_id, peer_mac, pmk/passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_OOB = 2; /** * TYPE: out-of-band: role, client_id, pmk/passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_OOB_ANY_PEER = 3; /** * TYPE: out-of-band: role, client_id, pmk/passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_OOB_ANY_PEER_OOB = 4; private static final String TAG = "WifiAwareNetworkSpecifier"; private final int mType; private final int mRole; private final int mClientId; private final int mSessionId; private final byte[] mPeerMac; private final byte[] mPmk; private final String mPassphrase; private final int mUid; private WifiAwareNetworkSpecifier(int type, int role, int clientId, int sessionId, byte[] peerMac, byte[] pmk, String passphrase, int uid) { mType = type; mRole = role; mClientId = clientId; mSessionId = sessionId; mPeerMac = peerMac;
mMediaInterface.folderItemsRsp(bdaddr, AvrcpConstants.RSP_INV_RANGE, null); return; } result_items = checkIndexOutOfBounds(bdaddr, items, startItem, endItem); if (result_items == null) { Log.w(TAG, "result_items is null."); mMediaInterface.folderItemsRsp(bdaddr, AvrcpConstants.RSP_INV_RANGE, null); return; } FolderItemsData folderDataNative = new FolderItemsData(result_items.size()); ArrayList<String> attrArray = new ArrayList<String>(); ArrayList<Integer> attrId = new ArrayList<Integer>(); for (int itemIndex = 0; itemIndex < result_items.size(); itemIndex++) { long qid = result_items.get(itemIndex).getQueueId(); byte[] uid = ByteBuffer.allocate(AvrcpConstants.UID_SIZE).putLong(qid).array(); for (int idx = 0; idx < AvrcpConstants.UID_SIZE; idx++) { // process uid array } }
String value = null; int attribId = isAllAttribRequested ? (idx + 1) : folderItemsReqObj.mAttrIDs[idx]; if (attribId >= AvrcpConstants.ATTRID_TITLE && attribId <= AvrcpConstants.ATTRID_PLAY_TIME) { value = getAttrValue(attribId, result_items, itemIndex); if (value != null) { attrArray.add(value); attrId.add(attribId); attrCnt++; } } else { Log.w(TAG, "invalid attribute id is requested: " + attribId); } } folderDataNative.mAttributesNum[itemIndex] = attrCnt; } } if (folderItemsReqObj.mNumAttr != AvrcpConstants.NUM_ATTR_NONE) { folderDataNative.mAttrIds = new int[attrId.size()]; for (int attrIndex = 0; attrIndex < attrId.size(); attrIndex++) folderDataNative.mAttrIds[attrIndex] = attrId.get(attrIndex); }
if (oldLp != null && newLp.isIdenticalDnses(oldLp)) { return; // no updating necessary } Collection<InetAddress> dnses = newLp.getDnsServers(); if (DBG) { log("Setting DNS servers for network " + netId + " to " + dnses); } try { mNetd.setDnsConfigurationForNetwork(netId, NetworkUtils.makeStrings(dnses), newLp.getDomains()); } catch (Exception e) { loge("Exception in setDnsConfigurationForNetwork: " + e); } flushVmDnsCache();
public static final String CAPTIVE_PORTAL_FALLBACK_URL = "captive_portal_fallback_url"; public static final String CAPTIVE_PORTAL_OTHER_FALLBACK_URLS = "captive_portal_other_fallback_urls"; public static final String CAPTIVE_PORTAL_USE_HTTPS = "captive_portal_use_https";
private URL[] makeCaptivePortalFallbackUrls(Context context) { String firstUrl = getSetting(context, Settings.Global.CAPTIVE_PORTAL_FALLBACK_URL, DEFAULT_FALLBACK_URL); String joinedUrls = firstUrl + "," + getSetting(context, Settings.Global.CAPTIVE_PORTAL_OTHER_FALLBACK_URLS, DEFAULT_OTHER_FALLBACK_URLS); List<URL> urls = new ArrayList<>(); for (String s : joinedUrls.split(",")) { URL u = makeURL(s); if (u == null) { continue; } urls.add(u); } if (urls.isEmpty()) { Log.e(TAG, String.format("could not create any url from %s", joinedUrls)); } return urls.toArray(new URL[urls.size()]); }
import com.google.gerrit.reviewdb.client.Change; import com.google.gerrit.reviewdb.client.CommentRange; import com.google.gerrit.reviewdb.client.Patch; import com.google.gerrit.reviewdb.client.PatchLineComment; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.RevId; import com.google.gwtorm.client.Column; import java.sql.Timestamp; import java.util.ArrayList; import java.util.List; import javax.annotation.concurrent.Immutable; /** * Holds the raw data of a RevisionNote. * It is intended for (de)serialization to JSON only. */ class RevisionNoteData { static class Identity { int id; Identity(Account.Id id) { this.id = id.get(); } Account.Id export() { return new Account.Id(id); } } static class CommentKey { String uuid; PatchKey patchKey; CommentKey(PatchLineComment.Key k) { uuid = k.get(); patchKey = new PatchKey(k.getParentKey()); } PatchLineComment.Key export() { return new PatchLineComment.Key(patchKey.export(), uuid); } } } // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api; import com.google.gerrit.extensions.api.changes.Changes; import com.google.gerrit.extensions.api.projects.Projects; import com.google.gerrit.extensions.restapi.NotImplementedException; public interface GerritApi { public Changes changes(); public Projects projects(); /** * A default implementation which allows source compatibility when adding new methods to the interface. */ public class NotImplementedGerritApi implements GerritApi { @Override public Changes changes() { throw new NotImplementedException(); } @Override public Projects projects() { throw new NotImplementedException(); } } } // Android-changed: removed Value-Based paragraph. import java.util.function.Consumer; import java.util.function.Function; import java.util.function.Predicate; import java.util.function.Supplier; /** * A container object which may or may not contain a non-null value. * If a value is present, {@code isPresent()} will return {@code true} and * {@code get()} will return the value. * * <p>
public Builder setSecondaryPhy(int secondaryPhy) { if (secondaryPhy != BluetoothDevice.PHY_LE_1M && secondaryPhy != BluetoothDevice.PHY_LE_2M && secondaryPhy != BluetoothDevice.PHY_LE_CODED) { throw new IllegalArgumentException("bad secondaryPhy " + secondaryPhy); } this.secondaryPhy = secondaryPhy; return this; } public Builder setAdvertisingInterval(int interval) { if (interval < AdvertisingSetParameters.INTERVAL_LOW || interval > AdvertisingSetParameters.INTERVAL_HIGH) { throw new IllegalArgumentException("Invalid advertising interval: " + interval); } this.interval = interval; return this; }
private String getDisplayName(boolean daylightTime, int style, Locale locale) { // BEGIN Android-changed: implement using android.icu.text.TimeZoneNames TimeZoneNames.NameType nameType; switch (style) { case SHORT: nameType = daylightTime ? TimeZoneNames.NameType.SHORT_DAYLIGHT : TimeZoneNames.NameType.SHORT_STANDARD; break; case LONG: nameType = daylightTime ? TimeZoneNames.NameType.LONG_DAYLIGHT : TimeZoneNames.NameType.LONG_STANDARD; break; default: throw new IllegalArgumentException("Illegal style: " + style); } long now = System.currentTimeMillis(); String canonicalID = android.icu.util.TimeZone.getCanonicalID(getID()); if (canonicalID != null) { TimeZoneNames names = TimeZoneNames.getInstance(locale); String displayName = names.getDisplayName(canonicalID, nameType, now); if (displayName != null) { return displayName; } } // We get here if this is a custom timezone or ICU doesn't have name data for the specific // style and locale. int offsetMillis = getRawOffset(); // END Android-changed }
private static class TestCase { AccessCheckInput input; String project; int want; TestCase(String mail, String project, String ref, int want) { this.input = new AccessCheckInput(mail, ref); this.project = project; this.want = want; } } @Test public void accessible() throws Exception { List<TestCase> inputs = ImmutableList.of( new TestCase(user.email, normalProject.get(), null, 200), new TestCase(user.email, secretProject.get(), null, 403), new TestCase(user.email, secretRefProject.get(), "refs/heads/secret/master", 403), new TestCase(privilegedUser.email, secretRefProject.get(), "refs/heads/secret/master", 200), new TestCase(privilegedUser.email, normalProject.get(), null, 200), new TestCase(privilegedUser.email, secretProject.get(), null, 200) ); for (TestCase tc : inputs) { String in = newGson().toJson(tc.input); AccessCheckInfo info = null; try { // Perform access check } catch (Exception e) { // Handle exception } } } ReviewInput in = new ReviewInput(); in.onBehalfOf = user.id.toString(); in.label("Not-A-Label", 5); exception.expect(BadRequestException.class); exception.expectMessage("label \"Not-A-Label\" is not a configured label"); revision.review(in); @Test public void voteOnBehalfOfInvalidLabelIgnoredWithoutStrictLabels() throws Exception { allowCodeReviewOnBehalfOf(); PushOneCommit.Result r = createChange(); RevisionApi revision = gApi.changes().id(r.getChangeId()).current(); ReviewInput in = new ReviewInput(); in.onBehalfOf = user.id.toString(); in.label("Code-Review", 1); in.label("Not-A-Label", 5); revision.review(in); assertThat(gApi.changes().id(r.getChangeId()).get().labels).doesNotContainKey("Not-A-Label"); } @Test public void voteOnBehalfOfLabelNotPermitted() throws Exception { ProjectConfig cfg = projectCache.checkedGet(project).getConfig(); LabelType verified = Util.verified(); // Perform test } private static boolean isCorrelated(SelectStmt subqueryStmt) { if
boolean isRingerAudible = isVolumeOverZero && shouldRingForContact && isRingtonePresent; boolean shouldAcquireAudioFocus = (isVolumeOverZero && shouldRingForContact && isRingtonePresent) || (isHfpDeviceAttached && shouldRingForContact); boolean isTheaterModeOn = mSystemSettingsUtil.isTheaterModeOn(mContext); boolean letDialerHandleRinging = mInCallController.doesConnectedDialerSupportRinging(); boolean endEarly = isTheaterModeOn || letDialerHandleRinging; if (endEarly) { if (letDialerHandleRinging) { Log.addEvent(foregroundCall, LogUtils.Events.SKIP_RINGING); } return shouldAcquireAudioFocus; }
Log.addEvent(foregroundCall, LogUtils.Events.START_RINGER); if (isVolumeOverZero && shouldRingForContact && isRingtonePresent) { mRingtonePlayer.play(mRingtoneFactory, foregroundCall); } else { Log.i(this, "startRinging: skipping because ringer would not be audible."); } if (shouldVibrate(mContext, foregroundCall) && !mIsVibrating && shouldRingForContact) { mVibratingCall = foregroundCall; mVibrator.vibrate(VIBRATION_PATTERN, VIBRATION_PATTERN_REPEAT, VIBRATION_ATTRIBUTES); mIsVibrating = true; } else if (mIsVibrating) { Log.addEvent(foregroundCall, LogUtils.Events.SKIP_VIBRATION, "already vibrating"); } return shouldAcquireAudioFocus;
private URL nextFallbackUrl() { if (mCaptivePortalFallbackUrls.length == 0) { return null; } int seed = Math.abs(mNextFallbackUrl) % mCaptivePortalFallbackUrls.length; mNextFallbackUrl += new Random().nextInt(); // randomly change seed without memory. return mCaptivePortalFallbackUrls[seed]; }
private void testIsInCallFail() throws Exception { doThrow(new SecurityException()).when(mContext).enforceCallingOrSelfPermission(anyString(), any()); try { mTSIBinder.isInCall("blah"); fail("Should throw SecurityException"); } catch (SecurityException expected) { // desired result } verify(mFakeCallsManager, never()).hasOngoingCalls(); }
mGotCountryCode = false; pollStateDone(); break; default: pollingContext[0]++; cm.getOperator(obtainMessage(EVENT_POLL_STATE_OPERATOR_CDMA, pollingContext)); pollingContext[0]++; cm.getRegistrationState(obtainMessage(EVENT_POLL_STATE_REGISTRATION_CDMA, pollingContext)); pollingContext[0]++; cm.getNetworkSelectionMode(obtainMessage(EVENT_POLL_STATE_NETWORK_SELECTION_MODE_CDMA, pollingContext)); break; } private static String networkTypeToString(int type) { String ret = "unknown"; switch (type) { case DATA_ACCESS_CDMA_IS95A: case DATA_ACCESS_CDMA_IS95B: case DATA_ACCESS_CDMA_1xRTT: ret = "CDMA"; break; case DATA_ACCESS_CDMA_EvDo_0: ret = "EVDO_0"; break; } mIncomingSco = createScoSocket(); mIncomingSco.accept(); break; case SCO_CONNECTED: if (msg.arg1 == ScoSocket.STATE_CONNECTED && isHeadsetConnected() && mConnectedSco == null) { if (VDBG) log("Routing audio for outgoing SCO conection"); mConnectedSco = (ScoSocket)msg.obj; mAudioManager.setBluetoothScoOn(true); if (isCellularCallInProgress()) { broadcastAudioStateIntent(BluetoothHeadset.AUDIO_STATE_CONNECTED, mHeadset.getRemoteDevice()); } else if ((mHFScoState == HF_STATE_SCO_VIRTUALCALL_SETUP) || (mHFScoState == HF_STATE_SCO_VIRTUALCALL_TRANSFERRED)) { mHFScoState = HF_STATE_SCO_VIRTUALCALL_ACTIVE; broadcastVirtualCallStateIntent(BluetoothHeadset.VIRTUALCALL_STATE_CONNECTED); } if (DBG) log("mHandler: Updated mHFScoState:"+ mHFScoState); } else if (msg.arg1 == ScoSocket.STATE_CONNECTED) { assertTrue(mTSIBinder.isInManagedCall(DEFAULT_DIALER_PACKAGE)); @SmallTest public void testNotIsInManagedCall() throws Exception { when(mFakeCallsManager.hasOngoingManagedCalls()).thenReturn(false); assertFalse(mTSIBinder.isInManagedCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testIsInManagedCallFail() throws Exception { doThrow(new SecurityException()).when(mContext).enforceCallingOrSelfPermission(anyString(), any()); try { mTSIBinder.isInManagedCall("blah"); } catch (SecurityException e
public void test_SystemProperties() { Properties originalProperties = System.getProperties(); try { Properties testProperties = new Properties(); testProperties.put("testIncInt", "notInt"); System.setProperties(testProperties); assertNull("returned incorrect default Integer", Integer.getInteger("testIncInt")); assertEquals(new Integer(4), Integer.getInteger("testIncInt", 4)); assertEquals(new Integer(4), Integer.getInteger("testIncInt", new Integer(4))); } finally { System.setProperties(originalProperties); } } for (int i = 0; i <= 255; ++i) { s.setTrafficClass(i); int actual = s.getTrafficClass(); assertTrue(actual == i || (((i & ~INET_ECN_MASK) == (actual & ~INET_ECN_MASK)) && ((actual & INET_ECN_MASK) == 0))); } public void testReadAfterClose() throws Exception { MockServer server = new MockServer(); server.enqueue(new byte[]{5, 3}, 0); Socket socket = new Socket("localhost", server.port); InputStream in = socket.getInputStream(); assertEquals(5, in.read()); assertEquals(3, in.read()); assertEquals(-1, in.read()); assertEquals(-1, in.read()); socket.close(); in.close(); }
} } } } private void connectToAddress(InetAddress address, int port, int timeout) throws IOException { if (address.isAnyLocalAddress()) { doConnect(InetAddress.getLocalHost(), port, timeout); } else { doConnect(address, port, timeout); } } public void setOption(int opt, Object val) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } // Android-removed: alternative implementation /* boolean on = true; switch (opt) { // check type safety b4 going native. These should never * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). // case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) throw new SocketException("Bad parameter for option"); if (val instanceof Boolean) { // true only if disabling - enabling should be Integer on = false; } break; case SO_TIMEOUT: */ }
if (address.isAnyLocalAddress()) { doConnect(InetAddress.getLocalHost(), port, timeout); } else { doConnect(address, port, timeout); } public void setOption(int opt, Object val) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } boolean on = true; switch (opt) { case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) { throw new SocketException("Bad parameter for option"); } if (val instanceof Boolean) { on = false; } break; case SO_TIMEOUT: if (val == null || (!(val instanceof Integer))) { throw new SocketException("Bad parameter for SO_TIMEOUT"); } break; default: throw new SocketException("Unrecognized socket option"); } // Set the socket option try { socket.setOption(opt, val); } catch (SocketException e) { throw new SocketException("Error setting socket option: " + e.getMessage()); } }
} else { doConnect(address, port, timeout); } public void setOption(int opt, Object val) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } // Android-removed: alternative implementation /* boolean on = true; switch (opt) { // check type safety b4 going native. These should never * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). // <|startfocus|> // <|endfocus|> case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) { throw new SocketException("Bad parameter for option"); } if (val instanceof Boolean) { // true only if disabling - enabling should be Integer on = false; } break; case SO_TIMEOUT: if (val == null || (!(val instanceof Integer))) { throw new SocketException("Bad parameter for SO_TIMEOUT"); } int tmp = ((Integer) val).intValue(); if (tmp < 0) { throw new IllegalArgumentException("timeout < 0"); } // <|startfocus|> // <|endfocus|> break; default: throw new SocketException("Option not supported"); } // <|startfocus|> // <|endfocus|> }
} // Android-removed: alternative implementation /* boolean on = true; switch (opt) { // check type safety b4 going native. These should never * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). // case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) throw new SocketException("Bad parameter for option"); if (val instanceof Boolean) { // true only if disabling - enabling should be Integer on = false; } break; case SO_TIMEOUT: if (val == null || (!(val instanceof Integer))) throw new SocketException("Bad parameter for SO_TIMEOUT"); int tmp = ((Integer) val).intValue(); if (tmp < 0) throw new IllegalArgumentException("timeout < 0"); timeout = tmp; break; case IP_TOS: if (val == null || !(val instanceof Integer)) { throw new SocketException("bad argument for IP_TOS"); } */ boolean on = true; switch (opt) { // check type safety b4 going native. These should never fail, since only java.Socket* has access to PlainSocketImpl.setOption(). // case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) { throw new SocketException("Bad parameter for option"); } if (val instanceof Boolean) { // true if disabling - enabling should be Integer on = false; } break; case SO_TIMEOUT: if (val == null || (!(val instanceof Integer))) { throw new SocketException("Bad parameter for SO_TIMEOUT"); } int tmp = ((Integer) val).intValue(); if (tmp < 0) { throw new IllegalArgumentException("timeout < 0"); } timeout = tmp; break; case IP_TOS: if (val == null || !(val instanceof Integer)) { throw new SocketException("bad argument for IP_TOS"); } }
Refactored Code: ```java break; default: throw new SocketException("unrecognized TCP option: " + opt); } socketSetOption(opt, on, val); if (opt == SO_TIMEOUT) { timeout = (Integer) val; } socketSetOption(opt, val); public Object getOption(int opt) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } if (opt == SO_TIMEOUT) { return new Integer(timeout); } // Android-removed: alternative implementation /* int ret = 0; // The native socketGetOption() knows about 3 options. // The 32 bit value it returns will be interpreted according // to what we're asking. A return of -1 means it understands // the option but its turned off. It will raise a SocketException // if "opt" isn't one it understands. switch (opt) { case TCP_NODELAY: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_OOBINLINE: ... } */ } ``` Summary of Changes: - Removed the commented out code block that was marked as "Android-removed: alternative implementation".
throw new SocketException("unrecognized TCP option: " + opt); } socketSetOption(opt, on, val); if (opt == SO_TIMEOUT) { timeout = (Integer) val; } socketSetOption(opt, val); } public Object getOption(int opt) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } if (opt == SO_TIMEOUT) { return new Integer(timeout); } int ret = 0; switch (opt) { case TCP_NODELAY: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_OOBINLINE:
} if (opt == SO_TIMEOUT) { return new Integer(timeout); } int ret = 0; switch (opt) { case TCP_NODELAY: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_OOBINLINE: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_LINGER: ret = socketGetOption(opt, null); return (ret == -1) ? Boolean.FALSE : (Object)(new Integer(ret)); case SO_REUSEADDR: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_BINDADDR: InetAddressContainer in = new InetAddressContainer(); // ... break; default: throw new SocketException("Unknown socket option: " + opt); }
abstract void socketCreate(boolean isServer) throws IOException; abstract void socketConnect(InetAddress address, int port, int timeout) throws IOException; abstract void socketBind(InetAddress address, int port) throws IOException; abstract void socketListen(int count) throws IOException; abstract void socketAccept(SocketImpl s) throws IOException; abstract int socketAvailable() throws IOException; abstract void socketClose0(boolean useDeferredClose) throws IOException; abstract void socketShutdown(int howto) throws IOException; // Android-changed: Method signature changed. abstract void socketSetOption(int cmd, Object value) throws SocketException; abstract Object socketGetOption(int opt) throws SocketException; abstract void socketSendUrgentData(int data) throws IOException; public final static int SHUT_RD = 0; public final static int SHUT_WR = 1; }
public static void main(String[] args) { System.out.println(test()); }
public final void setPriority(int newPriority) { ThreadGroup g; checkAccess(); if (newPriority > MAX_PRIORITY || newPriority < MIN_PRIORITY) { throw new IllegalArgumentException("Priority out of range: " + newPriority); } if ((g = getThreadGroup()) != null) { if (newPriority > g.getMaxPriority()) { newPriority = g.getMaxPriority(); } synchronized (this) { this.priority = newPriority; if (isAlive()) { nativeSetPriority(newPriority); } } } } public final int getPriority() { return priority; }
private static void disableReporting() { if (doDisableReporting == null) { return; } try { doDisableReporting.invoke(null); } catch (Exception e) { throw new Error("Unable to disable reporting!"); } }
private static void ensureTestWatcherInitialized() { try { addToBootClassLoader(LISTENER_LOCATION); Class<?> testwatcher_class = Class.forName("art.test.TestWatcher", true, null); DoEnableReporting = testwatcher_class.getDeclaredMethod("EnableReporting"); DoDisableReporting = testwatcher_class.getDeclaredMethod("DisableReporting"); } catch (Exception e) { throw new Error("Exception while making testwatcher", e); } }
/// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecAdd loop:<<Loop>> outer_loop:none /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } } /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecSub loop:<<Loop>> outer_loop:none
Fixed Code: ```java public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } } public static void SimdMulSub(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] -= 12345 * array1[j]; } } ```
// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) // CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none // CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } } // CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) // CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none // CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none // CHECK-DAG: VecSub loop:<<Loop>> outer_loop:none // CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (after) // CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none
private void handleRadioProxyExceptionForRR(RILRequest rr, String methodName, Exception e) { if (rr != null && rr.result != null) { AsyncResult.forMessage(rr.result, null, CommandException.fromException(e)); rr.result.sendToTarget(); } } @Override public void setCarrierInfoForImsiEncryption(PublicKey publicKey, String keyIdentifier, Message result) { IRadio radioProxy = getRadioProxy(result); if (radioProxy != null) { android.hardware.radio.V1_1.IRadio radioProxy11 = android.hardware.radio.V1_1.IRadio.castFrom(radioProxy); if (radioProxy11 == null) { AsyncResult.forMessage(result, null, CommandException.fromRilErrno(REQUEST_NOT_SUPPORTED)); result.sendToTarget(); } else { RILRequest rr = obtainRequest(RIL_REQUEST_SET_CARRIER_INFO_IMSI_ENCRYPTION, result, mRILDefaultWorkSource); if (RILJ_LOGD) riljLog(rr.serialString() + "> " + requestToString(rr.mRequest)); try { radioProxy11.setCarrierInfoForImsiEncryption(rr.mSerial, publicKeyToArrayList(publicKey), keyIdentifier); } catch (RemoteException | RuntimeException e) { handleRadioProxyExceptionForRR(rr, "setCarrierInfoForImsiEncryption", e); } } } }
if (DBG) { log("reportNetworkConnectivity(" + nai.network.netId + ", " + hasConnectivity + ") by " + uid); } synchronized (nai) { // Validating a network that has not yet connected could result in a call to // rematchNetworkAndRequests() which is not meant to work on such networks. if (!nai.everConnected) { return; } if (isNetworkWithLinkPropertiesBlocked(nai.linkProperties, uid, false)) { return; } nai.networkMonitor.sendMessage(NetworkMonitor.CMD_FORCE_REEVALUATION, uid); }
if (items == null) { Log.i(TAG, "null queue from " + mediaController.getPackageName() + ", constructing current-item list"); MediaMetadata metadata = mediaController.getMetadata(); MediaSession.QueueItem current = getCurrentQueueItem(mediaController, 1); items = new ArrayList<MediaSession.QueueItem>(); items.add(current); return items; } mNowPlayingList = items; return items; private MediaSession.QueueItem getCurrentQueueItem(MediaController controller, long qid) { MediaMetadata metadata = controller.getMetadata(); if (metadata == null) { Log.w(TAG, "Controller has no metadata!? Making an empty one"); metadata = (new MediaMetadata.Builder()).build(); } MediaDescription.Builder bob = new MediaDescription.Builder(); // rest of the code }
if (mediaController == null) { Log.e(TAG, "mediaController = null, sending no available players response"); mMediaInterface.getItemAttrRsp(bdaddr, AvrcpConstants.RSP_NO_AVBL_PLAY, null); return; } // We don't have the cached list, fetch it from Media Controller items = mediaController.getQueue(); if (items == null) { mMediaInterface.getTotalNumOfItemsRsp(bdaddr, AvrcpConstants.RSP_NO_ERROR, 0, 1); } // Cache the response for later mNowPlayingList = items; mMediaInterface.getTotalNumOfItemsRsp(bdaddr, AvrcpConstants.RSP_NO_ERROR, 0, items.size());
if ((length == 10 || length == 26 || length == 58) && password.matches("[0-9A-Fa-f]*")) { wifiConfiguration.wepKeys[0] = password; } else if (length == 5 || length == 13 || length == 16) { wifiConfiguration.wepKeys[0] = '"' + password + '"'; } else { if (wifiSecurity == WifiSecurity.PSK && password.length() < FormPageDisplayer.PSK_MIN_LENGTH) { return; } wifiConfiguration.preSharedKey = password.matches("[0-9A-Fa-f]{64}") ? password : '"' + password + '"'; }
private void getNumSlots(APDU apdu) { p1p2Unused(apdu); prepareToSend(apdu, (short) 4); final byte buffer[] = apdu.getBuffer(); buffer[(short) 0] = 0; buffer[(short) 1] = 0; Util.setShort(buffer, (short) 2, mSlots.getNumSlots()); apdu.sendBytes((short) 0, (byte) 4); }
@Override public void onPullExternalCall() { if ((getConnectionProperties() & Connection.PROPERTY_IS_EXTERNAL_CALL) != Connection.PROPERTY_IS_EXTERNAL_CALL) { Log.w(this, "onPullExternalCall - cannot pull non-external call"); return; } if (mOriginalConnection != null) { mOriginalConnection.pullExternalCall(); } } @Override public void onStartRtt(RttTextStream textStream) { if (isImsConnection()) { ImsPhone imsPhone = (ImsPhone) getPhone(); imsPhone.sendRttModifyRequest(textStream); } else { Log.w(this, "onStartRtt - not in IMS, so RTT cannot be enabled."); } } @Override public void onStopRtt() { // This is not supported by carriers/vendor yet. No-op for now. } @Override public void handleRttUpgradeResponse(RttTextStream textStream) { if (!isImsConnection()) { Log.w(this, "handleRttUpgradeResponse - not in IMS, so RTT cannot be enabled."); return; } ImsPhone imsPhone = (ImsPhone) getPhone(); imsPhone.getForegroundCall().getImsCall().blahBlargStuff(textStream); }
private Attribute sourceDebugExtension(DirectClassFile cf, int offset, int length, ParseObserver observer) { ByteArray bytes = cf.getBytes().slice(offset, offset + length); CstString smapString = new CstString(bytes); Attribute result = new AttSourceDebugExtension(smapString); if (observer != null) { String decoded = smapString.getString(); observer.parsed(bytes, offset, length, "sourceDebugExtension: " + decoded); } return result; }
import com.android.dx.rop.cst.CstMethodRef; import com.android.dx.rop.cst.CstNat; import com.android.dx.rop.cst.CstType; import com.android.dx.rop.type.StdTypeList; import com.android.dx.rop.type.Type; import com.android.dx.rop.type.TypeList; import com.android.dx.util.Warning; import java.util.ArrayList; /*package*/ class AttributeTranslator { private AttributeTranslator() { // This space intentionally left blank. } public static TypeList getExceptions(Method method) { AttributeList attribs = method.getAttributes(); AttExceptions exceptions = (AttExceptions) attribs.findFirst(AttExceptions.ATTRIBUTE_NAME); if (exceptions == null) { return StdTypeList.EMPTY; } else { return exceptions.getExceptions(); } } }
public static long $opt$noinline$mulNeg(long left, long right) { if (doThrow) throw new Error(); return - (left * right); } public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } }
private static void throttle(byte[] bArray, short bOff, short failureCount) { short highWord = 0; short lowWord = 0; final short thirtySecondsInMilliseconds = 0x7530; // = 1000 * 30 if (failureCount == 0) { // 0s } else if (failureCount > 0 && failureCount <= 10) { if (failureCount % 5 == 0) { // 30s lowWord = thirtySecondsInMilliseconds; } else { // 0s } } else if (failureCount < 30) { // 30s lowWord = thirtySecondsInMilliseconds; } else if (failureCount < 140) { // 30 * (2^((x - 30)/10)) final short shift = (short) ((short) (failureCount - 30) / 10); highWord = (short) (thirtySecondsInMilliseconds >> (16 - shift)); lowWord = (short) (thirtySecondsInMilliseconds << shift); } else { // 1 day in ms = 1000 * 60 * 60 * 24 = 0x5265C00 highWord = 0x0526; } }
IpSecTransform.DIRECTION_IN, new IpSecAlgorithm(IpSecAlgorithm.CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication(IpSecTransform.DIRECTION_IN, new IpSecAlgorithm(IpSecAlgorithm.AUTH_HMAC_SHA256, AUTH_KEY, CRYPT_KEY.length * 8)) .buildTransportModeTransform(local); // Hack to ensure the socket doesn't block indefinitely on failure DatagramSocket localSocket = new DatagramSocket(8888); localSocket.setSoTimeout(500); FileDescriptor udpSocket = ParcelFileDescriptor.fromDatagramSocket(localSocket).getFileDescriptor(); mISM.applyTransportModeTransform(udpSocket, transform); byte[] data = new String("Best test data ever!").getBytes("UTF-8"); byte[] in = new byte[data.length]; Os.sendto(udpSocket, data, 0, data.length, 0, local, 8888); Os.read(udpSocket, in, 0, in.length); assertTrue("Encapsulated data did not match.", Arrays.equals(data, in)); mISM.removeTransportModeTransform(udpSocket, transform); Os.close(udpSocket); transform.close(); }
Refactored Code: ```java if (mEnableTerminal != null) { updateSwitchPreference(mEnableTerminal, context.getPackageManager().getApplicationEnabledSetting(TERMINAL_APP_PACKAGE) == PackageManager.COMPONENT_ENABLED_STATE_ENABLED); } updateSwitchPreference(mBugreportInPower, Settings.Secure.getInt(cr, Settings.Global.BUGREPORT_IN_POWER_MENU, 0) != 0); updateSwitchPreference(mKeepScreenOn, Settings.Global.getInt(cr, Settings.Global.STAY_ON_WHILE_PLUGGED_IN, 0) != 0); updateSwitchPreference(mBtHciSnoopLog, SystemProperties.getBoolean(BLUETOOTH_BTSNOOP_ENABLE_PROPERTY, false)); updateSwitchPreference(mDebugViewAttributes, Settings.Global.getInt(cr, Settings.Global.DEBUG_VIEW_ATTRIBUTES, 0) != 0); updateSwitchPreference(mForceAllowOnExternal, Settings.Global.getInt(cr, Settings.Global.FORCE_ALLOW_ON_EXTERNAL, 0) != 0); updateHdcpValues(); updatePasswordSummary(); updateDebuggerOptions(); updateMockLocation(); updateStrictModeVisualOptions(); updatePointerLocationOptions(); updateShowTouchesOptions(); updateFlingerOptions(); updateHardwareUiOptions(); updateMsaaOptions(); updateTrackFrameTimeOptions(); updateShowNonRectClipOptions(); updateShowHwScreenUpdatesOptions(); updateShowHwLayersUpdatesOptions(); updateDebugHwOverdrawOptions(); ``` Note: The code has been refactored to remove long lines.
// Check that this is a valid device address (i.e. not broadcast). if ((val[0] & 0x01) != 0) { // Invalid since this is a broadcast address. String addressString = Utils.getAddressStringFromByte(val); errorLog("Invalid device address=" + addressString + ". Ignore this address."); break; } mAddress = val; debugLog("Address is:" + Utils.getAddressStringFromByte(mAddress)); intent = new Intent(BluetoothAdapter.ACTION_BT_BD_ADDR_CHANGED); intent.putExtra(BluetoothAdapter.EXTRA_BT_BD_ADDR, Utils.getAddressStringFromByte(mAddress)); intent.addFlags(Intent.FLAG_RECEIVER_REGISTERED_ONLY_BEFORE_BOOT); mService.sendBroadcastAsUser(intent, UserHandle.ALL, mService.BLUETOOTH_PERM); break; case AbstractionLayer.BT_PROPERTY_CLASS_OF_DEVICE: mBluetoothClass = Utils.byteArrayToInt(val, 0); debugLog("BT Class:" + mBluetoothClass); break; case AbstractionLayer.BT_PROPERTY_ADAPTER_SCAN_MODE: int mode = Utils.byteArrayToInt(val, 0);
public static final String EXTRA_PREVIOUS_CONNECTION_STATE = "android.bluetooth.adapter.extra.PREVIOUS_CONNECTION_STATE"; public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; public static final String ACTION_BT_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"; public static final String EXTRA_BT_BD_ADDR = "android.bluetooth.adapter.extra.BT_BD_ADDR";
/** * Broadcast Action: The Bluetooth adapter state has changed in LE only mode. * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Broadcast Action: The notifies Bluetooth BD (mac) address updated event. * @hide */ public static final String ACTION_BT_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"; /** * Extra used by {@link #ACTION_BT_BD_ADDR_CHANGED} * This extra represents the BD Address. * @hide */ public static final String EXTRA_BT_BD_ADDR = "android.bluetooth.adapter.extra.BT_BD_ADDR"; /** * Broadcast Action: The notifies Bluetooth ACL connected event. * This will be used by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state is in STATE_BLE_ON. * This denotes GATT connection. * @hide */ public static final String ACTION_BT_ACL_CONNECTED = "android.bluetooth.adapter.action.BT_ACL_CONNECTED";
@SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; public static final String ACTION_BT_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"; public static final String EXTRA_BT_BD_ADDR = "android.bluetooth.adapter.extra.BT_BD_ADDR"; public static final String ACTION_ACL_CONNECTED_BLE = "android.bluetooth.adapter.action.ACL_CONNECTED_BLE";
/** * Broadcast Action: The notifies Bluetooth BD (mac) address updated event. * * @hide */ public static final String ACTION_BT_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"; /** * Extra used by {@link #ACTION_BT_BD_ADDR_CHANGED} * * This extra represents the BD Address. * * @hide */ public static final String EXTRA_BT_BD_ADDR = "android.bluetooth.adapter.extra.BT_BD_ADDR"; /** * Broadcast Action: The notifies Bluetooth ACL connected event. This will be * used by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state is STATE_BLE_ON. This denotes GATT connection * as Bluetooth LE is the only feature available in STATE_BLE_ON. * * This is counterpart of {@link BluetoothDevice#ACTION_ACL_CONNECTED} which * works in Bluetooth state STATE_ON * * @hide */ public static final String ACTION_BLE_ACL_CONNECTED = ...
String newName = intent.getStringExtra(BluetoothAdapter.EXTRA_LOCAL_NAME); if (DBG) Slog.d(TAG, "Bluetooth Adapter name changed to " + newName); if (newName != null) { storeNameAndAddress(newName, null); } else if (BluetoothAdapter.ACTION_BT_BD_ADDR_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BT_BD_ADDR); if (newAddress != null) { if (DBG) Slog.d(TAG, "Bluetooth Adapter BD Address changed to " + newAddress); storeNameAndAddress(null, newAddress); } else { if (DBG) Slog.e(TAG, "No Bluetooth Adapter BD Address parameter found"); } }
if (newName != null) { storeNameAndAddress(newName, null); } else if (BluetoothAdapter.ACTION_BT_BD_ADDR_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BT_BD_ADDR); if (newAddress != null) { if (DBG) Slog.d(TAG, "Bluetooth Adapter BD Address changed to " + newAddress); storeNameAndAddress(null, newAddress); } else { if (DBG) Slog.e(TAG, "No Bluetooth Adapter BD Address parameter found"); } }
public void testAospServiceContexts() throws Exception { /* obtain service_contexts file from running device */ deviceSvcFile = File.createTempFile("service_contexts", ".tmp"); deviceSvcFile.deleteOnExit(); mDevice.pullFile("/service_contexts", deviceSvcFile); /* retrieve the AOSP service_contexts file from jar */ aospSvcFile = copyResourceToTempFile("/general_service_contexts"); /* retrieve NMR1 AOSP service_contexts file from jar */ if (!isFileStartsWith(aospSvcFile, deviceSvcFile)) { aospSvcFile = copyResourceToTempFile("/ab3857191_service_contexts"); assertFileStartsWith(aospSvcFile, deviceSvcFile); } } /** * Tests that the file_contexts.bin file on the device is valid. * * @throws Exception */ @CddTest(requirement="9.7") public void testValidFileContexts() throws Exception { /* retrieve the checkfc executable from jar */ checkFc = copyResourceToTempFile("/checkfc"); checkFc.setExecutable(true); /* obtain file_contexts.bin file from running device */ // ... }
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package art; import java.util.Base64; public class Test985 { static class Transform { private void Start() { System.out.println("hello - private"); } private void Finish() { System.out.println("goodbye - private"); } public void sayHi(Runnable r) { System.out.println("Pre Start private method call"); Start(); r.run(); Finish(); } } public static void main(String[] args) { Transform t = new Transform(); t.sayHi(() -> System.out.println("Hello, world!")); } }
byte result = Consts.READ_WRONG_KEY; if (Util.arrayCompare(keyBuffer, keyOffset, mKey, (short) 0, Consts.SLOT_KEY_BYTES) == 0) { return Consts.READ_SUCCESS; } JCSystem.beginTransaction(); if (result == Consts.READ_WRONG_KEY) { if (mFailureCount != 0x7fff) { mFailureCount += 1; } if (throttle(sRemainingBackoff, (short) 0, mFailureCount)) { //mBackoffTimer.startTimer( // sRemainingBackoff, (short) 0, DSTimer.DST_POWEROFFMODE_FALLBACK); } Util.arrayCopyNonAtomic(sRemainingBackoff, (short) 0, outBuffer, outOffset, (byte) 4); } else { mFailureCount = 0; //mBackoffTimer.stopTimer(); Util.arrayCopyNonAtomic(mValue, (short) 0, outBuffer, outOffset, Consts.SLOT_VALUE_BYTES); } JCSystem.commitTransaction(); return result;
/// CHECK-NOT: InstanceFieldSet /// CHECK-NOT: ConstructorFence /// CHECK-NOT: InstanceFieldGet static double calcCircleArea(double radius) { return new Circle(radius).getArea(); } /// CHECK-START: double Main.calcEllipseArea(double, double) load_store_elimination (before) /// CHECK: NewInstance /// CHECK: InstanceFieldSet /* // TODO: The super constructor fence should not be eliminated already. // CHECK: ConstructorFence */ /// CHECK: InstanceFieldSet /// CHECK: ConstructorFence /// CHECK: InstanceFieldGet /// CHECK: InstanceFieldGet /// CHECK-START: double Main.calcEllipseArea(double, double) load_store_elimination (after) /// CHECK-NOT: NewInstance /// CHECK-NOT: InstanceFieldSet /// CHECK-NOT: ConstructorFence /// CHECK-NOT: InstanceFieldGet // Multiple constructor fences can accumulate through inheritance, make sure // they are all eliminated when the allocation is eliminated. static double calcEllipseArea(double vertex, double covertex) { return new Ellipse(vertex, covertex).getArea(); }
static double calcEllipseArea(double vertex, double covertex) { return new Ellipse(vertex, covertex).getArea(); } static double someResult; static double calcCircleAreaOrCircumference(double radius, boolean area_or_circumference) { CalcCircleAreaOrCircumference calc = new CalcCircleAreaOrCircumference( area_or_circumference ? CalcCircleAreaOrCircumference.TYPE_AREA : CalcCircleAreaOrCircumference.TYPE_CIRCUMFERENCE ); if (area_or_circumference) { // Area someResult = calc.calculateArea(radius); } else { // Circumference someResult = calc.calculateCircumference(radius); } return someResult; }
/// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecAdd loop:<<Loop>> outer_loop:none /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-NOT: VecMul /// CHECK-NOT: VecAdd /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } } /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none
* Copyright (C) 2017 The Android Open Source Project Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. package com.android.rs.test; import android.content.Context; import android.renderscript.Allocation; import android.renderscript.Element; import android.renderscript.RenderScript; import android.renderscript.RSIllegalArgumentException; import android.renderscript.ScriptIntrinsicBlur; import android.renderscript.Type; import android.util.Log; public class UT_blur_validation extends UnitTest { private static final int ARRAY_SIZE = 256; private static final String TAG = "ScriptIntrinsicBlur validation"; }
public void destroyResources() { pRS.finish(); input1D.destroy(); input2D.destroy(); output1D.destroy(); output2D.destroy(); scriptBlur.destroy(); pRS.destroy(); } public void testDestroy() { output2D.destroy(); scriptBlur.destroy(); pRS.destroy(); passTest(); } public void testFailDestroy() { pRS.finish(); input1D.destroy(); input2D.destroy(); output1D.destroy(); output2D.destroy(); scriptBlur.destroy(); pRS.destroy(); failTest(); } // Usage if (condition) { destroyResources(); testDestroy(); } else { Log.e(TAG, "setting 1d input does not trigger exception"); destroyResources(); testFailDestroy(); }
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package art; import java.lang.reflect.Method; import java.util.HashMap; public class Test986 { static { // NB This is called before any setup is done so we don't need to worry about getting bind // events. Main.bindAgentJNIForClass(Test986.class); } private static final HashMap<Method, String> SymbolMap = new HashMap<>(); }
private static TDescribeDbResult describeDbExtended(Db db) { TDescribeDbResult descResult = new TDescribeDbResult(); org.apache.hadoop.hive.metastore.api.Database msDb = db.getMetaStoreDb(); String ownerName = null; PrincipalType ownerType = null; Map<String, String> params = null; PrincipalPrivilegeSet privileges = null; if (msDb != null) { location = msDb.getLocationUri(); comment = msDb.getDescription(); ownerName = msDb.getOwnerName(); ownerType = msDb.getOwnerType(); params = msDb.getParameters(); privileges = msDb.getPrivileges(); } TColumnValue dbNameCol = new TColumnValue(); dbNameCol.setString_val(db.getName()); TColumnValue dbLocationCol = new TColumnValue(); dbLocationCol.setString_val(Objects.toString(location, "")); TColumnValue commentCol = new TColumnValue(); commentCol.setString_val(Objects.toString(comment, "")); descResult.results.add(dbNameCol); descResult.results.add(dbLocationCol); descResult.results.add(commentCol); return descResult; } if (revisionDelta != null) { Map<EStructuralFeature, CDOFeatureDelta> featureDeltas = revisionDelta.getFeatureDeltaMap(); featureDeltas.remove(featureDelta.getFeature()); if (featureDeltas.isEmpty()) { cleanRevisions.remove(object); revisionDeltas.remove(id); lastSavepoint.getDirtyObjects().remove(id); if (lastSavepoint.getReattachedObjects().containsKey(id)) { lastSavepoint.getReattachedObjects().remove(id); lastSavepoint.getDetachedObjects().remove(id); } lastSavepoint.getDirtyObjects().remove(id); object.cdoInternalSetRevision(cleanRevision); changeState(object, CDOState.CLEAN); } } if (revisionDeltas.isEmpty()) { transaction.setDirty(false); } CDOTransactionHandler1[] handlers = transaction.getTransactionHandlers1(); for (int i = 0; i < handlers.length; i++) { CDOTransactionHandler1 handler = handlers[i]; if (handler instanceof WithUndo) { WithUndo withUndo = (WithUndo) handler; withUndo.undoingObject(transaction, object, featureDelta); } } return result; import org.apache.hadoop.hbase.Cluster
protected BufferedWriter writer = new BufferedWriter(new FileWriter(sourceList.getAbsolutePath())); for (String f : files) { writer.write(f); writer.write('\n'); } writer.close(); commandLine.add('@' + sourceList.getAbsolutePath()); } @Override @Nonnull public AndroidToolchain setAndroidMinApiLevel(@Nonnull String minApiLevel) throws Exception { this.minApiLevel = minApiLevel; return this; } abstract boolean isDesugarEnabled();
public void run() { RenderScript pRS = RenderScript.create(mCtx); final int width = 100; final int height = 100; Allocation input1D = Allocation.createSized(pRS, Element.U8(pRS), width * height, Allocation.USAGE_SCRIPT); final Allocation output1D = Allocation.createTyped(pRS, input1D.getType()); Type.Builder typeBuilder = new Type.Builder(pRS, Element.U8(pRS)); typeBuilder.setX(width); typeBuilder.setY(height); Type ty = typeBuilder.create(); final Allocation input2D = Allocation.createTyped(pRS, ty); final Allocation output2D = Allocation.createTyped(pRS, ty); ScriptIntrinsicBlur scriptBlur = ScriptIntrinsicBlur.create(pRS, Element.U8(pRS)); scriptBlur.setRadius(25f); boolean failed = false; try { scriptBlur.setInput(input1D); } catch (RSIllegalArgumentException e) { scriptBlur.setInput(input2D); try { scriptBlur.forEach(output1D); } catch (RSIllegalArgumentException e1) { scriptBlur.forEach(output2D); } } }
package com.android.rs.test_compat; import android.content.Context; import android.content.res.Resources; import android.support.v8.renderscript.Allocation; import android.support.v8.renderscript.Element; import android.support.v8.renderscript.RenderScript; import android.support.v8.renderscript.RSIllegalArgumentException; import android.support.v8.renderscript.ScriptIntrinsicBlur; import android.support.v8.renderscript.Type; import android.util.Log; public class UT_blur_validation extends UnitTest { private static final String TAG = "ScriptIntrinsicBlur validation"; protected UT_blur_validation(RSTestCore rstc, Resources res, Context ctx) { super(rstc, TAG, ctx); } public void run() { RenderScript pRS = RenderScript.create(mCtx); final int width = 100; final int height = 100; Allocation input1D = Allocation.createSized(pRS, Element.U8(pRS), width * height, Allocation.USAGE_SCRIPT); final Allocation output1D = Allocation.createTyped(pRS, input1D.getType()); } }
public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action.equals(BluetoothDevice.ACTION_BOND_STATE_CHANGED)) { int bondState = intent.getIntExtra(BluetoothDevice.EXTRA_BOND_STATE, BluetoothDevice.ERROR); if ((bondState != BluetoothDevice.BOND_NONE) && (bondState != BluetoothDevice.BOND_BONDED)) { return; } } else if (action.equals(ACTION_DISMISS_PAIRING)) { Log.d(TAG, "Notification cancel for " + mDevice.getAddress() + " (" + mDevice.getName() + ")"); } else { int bondState = intent.getIntExtra(BluetoothDevice.EXTRA_BOND_STATE, BluetoothDevice.ERROR); Log.d(TAG, "Dismiss pairing for " + mDevice.getAddress() + " (" + mDevice.getName() + "), BondState: " + bondState); } stopForeground(true); stopSelf(); }
public void sendUssd(String ussdMessage) throws ImsException { logi("sendUssd :: ussdMessage=" + ussdMessage); synchronized(mLockObj) { if (mSession == null) { loge("sendUssd :: "); throw new ImsException("No call session", ImsReasonInfo.CODE_LOCAL_CALL_TERMINATED); } mSession.sendUssd(ussdMessage); } } public void sendRttMessage(String rttMessage) { } public void sendRttModifyRequest() { logi("sendRttModifyRequest"); synchronized(mLockObj) { if (mSession == null) { loge("sendRttModifyRequest::no session"); } if (mCallProfile.mMediaProfile.isRttCall()) { logi("sendRttModifyRequest::Already RTT call, ignoring."); return; } Parcel p = Parcel.obtain(); // Modify the ImsCallProfile to enable RTT ImsCallProfile modifiedProfile = new ImsCallProfile(mCallProfile); modifiedProfile.mMediaProfile.setRttCall(true); p.writeParcelable(modifiedProfile, 0); try { mSession.sendRttModifyRequest(p); } catch (RemoteException e) { loge("sendRttModifyRequest::RemoteException: " + e); } p.recycle(); } }
public static List<TimeZone> getUniqueOffsetTimeZones(String country) { synchronized (sLastUniqueLockObj) { if (country != null && country.equals(sLastUniqueCountry)) { if (DBG) { Log.d(TAG, "getUniqueOffsetTimeZones(" + country + "): return cached version"); } return sLastUniqueZoneOffsets; } } Collection<TimeZone> zones = getTimeZones(country); ArrayList<TimeZone> uniqueTimeZones = new ArrayList<>(); for (TimeZone zone : zones) { boolean found = false; for (int i = 0; i < uniqueTimeZones.size(); i++) { if (uniqueTimeZones.get(i).getRawOffset() == zone.getRawOffset()) { found = true; break; } } if (!found) { if (DBG) { Log.d(TAG, "getUniqueOffsetTimeZones: add unique offset=" + zone.getRawOffset()); } uniqueTimeZones.add(zone); } } synchronized (sLastUniqueLockObj) { sLastUniqueCountry = country; sLastUniqueZoneOffsets = uniqueTimeZones; } return uniqueTimeZones; }
return mgr.isVolteProvisioned(); } } return true; } public boolean isVolteProvisionedOnDeviceForSlot() { if (getBooleanCarrierConfigForSlot(CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) { return isVolteProvisioned(); } return true; } public static boolean isWfcProvisionedOnDevice(Context context) { if (getBooleanCarrierConfig(context, CarrierConfigManager.KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL)) { if (!isVolteProvisionedOnDevice(context)) { return false; } } if (getBooleanCarrierConfig(context, CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) { return true; } return false; }
mGotCountryCode = false; pollStateDone(); break; default: pollingContext[0]++; cm.getOperator(obtainMessage(EVENT_POLL_STATE_OPERATOR_CDMA, pollingContext)); pollingContext[0]++; cm.getRegistrationState(obtainMessage(EVENT_POLL_STATE_REGISTRATION_CDMA, pollingContext)); pollingContext[0]++; cm.getNetworkSelectionMode(obtainMessage(EVENT_POLL_STATE_NETWORK_SELECTION_MODE_CDMA, pollingContext)); break; } private static String networkTypeToString(int type) { String ret = "unknown"; switch (type) { case DATA_ACCESS_CDMA_IS95A: case DATA_ACCESS_CDMA_IS95B: case DATA_ACCESS_CDMA_1xRTT: ret = "CDMA"; break; case DATA_ACCESS_CDMA_EvDo_0: ret = "EVDO_0"; break; } mIncomingSco = createScoSocket(); mIncomingSco.accept(); break; case SCO_CONNECTED: if (msg.arg1 == ScoSocket.STATE_CONNECTED && isHeadsetConnected() && mConnectedSco == null) { if (VDBG) log("Routing audio for outgoing SCO conection"); mConnectedSco = (ScoSocket)msg.obj; mAudioManager.setBluetoothScoOn(true); if (isCellularCallInProgress()) { broadcastAudioStateIntent(BluetoothHeadset.AUDIO_STATE_CONNECTED, mHeadset.getRemoteDevice()); } else if ((mHFScoState == HF_STATE_SCO_VIRTUALCALL_SETUP) || (mHFScoState == HF_STATE_SCO_VIRTUALCALL_TRANSFERRED)) { mHFScoState = HF_STATE_SCO_VIRTUALCALL_ACTIVE; broadcastVirtualCallStateIntent(BluetoothHeadset.VIRTUALCALL_STATE_CONNECTED); } if (DBG) log("mHandler: Updated mHFScoState:"+ mHFScoState); } else if (msg.arg1 == ScoSocket.STATE_CONNECTED) { return false; } if (getBooleanCarrierConfig(context, CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) { ImsManager mgr = ImsManager.getInstance(context, SubscriptionManager.getDefaultVoicePhoneId()); if (mgr != null) { return mgr.isWfcProvisioned(); } } return true; } public boolean isWfcProvisionedOnDeviceForSlot() { if (getBooleanCarrierConfigForSlot(CarrierConfigManager.KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL)) { if (!isVolteProvision
private void sendTetherStateChangedBroadcast() { if (!getConnectivityManager().isTetheringSupported()) return; final ArrayList<String> availableList = new ArrayList<>(); final ArrayList<String> tetherList = new ArrayList<>(); final ArrayList<String> hotspotList = new ArrayList<>(); final ArrayList<String> erroredList = new ArrayList<>(); boolean wifiTethered = false; boolean usbTethered = false; boolean bluetoothTethered = false; final TetheringConfiguration cfg = mConfig; synchronized (mPublicSync) { for (int i = 0; i < mTetherStates.size(); i++) { TetherState tetherState = mTetherStates.valueAt(i); String iface = mTetherStates.keyAt(i); if (tetherState.lastError != ConnectivityManager.TETHER_ERROR_NO_ERROR) { erroredList.add(iface); } else if (tetherState.lastState == IControlsTethering.STATE_AVAILABLE) { availableList.add(iface); } else if (tetherState.lastState == IControlsTethering.STATE_LOCAL_HOTSPOT) { hotspotList.add(iface); } } } // Rest of the code... }
import android.telephony.CarrierConfigManager; import android.os.Message; import android.os.Messenger; import com.android.internal.util.AsyncChannel; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.MockitoAnnotations; import org.mockito.ArgumentCaptor; import java.util.List; @RunWith(AndroidJUnit4.class) @SmallTest public class NsdManagerTest { @Mock Context mContext; @Mock INsdManager mService; MockServiceHandler mServiceHandler; private static final long TIMEOUT_MS = 100; @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); mServiceHandler = spy(MockServiceHandler.make(mContext)); when(mService.getMessenger()).thenReturn(new Messenger(mServiceHandler)); } @Test public void testResolveService() { NsdManager manager = makeManager(); NsdServiceInfo request = new NsdServiceInfo("a name", "a type"); NsdServiceInfo reply = new NsdServiceInfo("resolved name", "resolved type"); NsdManager.ResolveListener listener = mock(NsdManager.ResolveListener.class); manager.resolveService(request, listener); } }
public void testResolveService() { NsdManager manager = makeManager(); NsdServiceInfo request = new NsdServiceInfo("a name", "a type"); NsdServiceInfo reply = new NsdServiceInfo("resolved name", "resolved type"); NsdManager.ResolveListener listener = mock(NsdManager.ResolveListener.class); manager.resolveService(request, listener); int key1 = verifyRequest(NsdManager.RESOLVE_SERVICE); int err = 33; sendResponse(NsdManager.RESOLVE_SERVICE_FAILED, err, key1, null); verify(listener, timeout(mTimeoutMs).times(1)).onResolveFailed(request, err); manager.resolveService(request, listener); int key2 = verifyRequest(NsdManager.RESOLVE_SERVICE); sendResponse(NsdManager.RESOLVE_SERVICE_SUCCEEDED, 0, key2, reply); verify(listener, timeout(mTimeoutMs).times(1)).onServiceResolved(reply); }
public static MockServiceHandler create(Context context) { HandlerThread t = new HandlerThread("mock-service-handler"); t.start(); return new MockServiceHandler(t.getLooper(), context); }
mConnected.countDown(); return; case AsyncChannel.CMD_CHANNEL_DISCONNECTED: Log.e(TAG, "Channel lost"); return; default: break; } final NsdServiceInfo ns = getNsdService(key); final Object listener = getListener(key); if (listener == null) { if (what != RESOLVE_SERVICE_SUCCEEDED || what != RESOLVE_SERVICE_FAILED || what != RESOLVE_SERVICE_TIMEOUT) { Log.d(TAG, "Stale key " + key); } return; } if (DBG) { Log.d(TAG, "received " + nameOf(what) + " for key " + key + ", service " + ns); } switch (what) { case DISCOVER_SERVICES_STARTED: String s = getNsdServiceInfoType((NsdServiceInfo) message.obj); ((DiscoveryListener) listener).onDiscoveryStarted(s); break; case DISCOVER_SERVICES_FAILED: removeListener(key); ((DiscoveryListener) listener).onStartDiscoveryFailed(getNsdServiceInfoType(ns), message.arg1); break; case SERVICE_FOUND:
public static final String EXTRA_PREVIOUS_CONNECTION_STATE = "android.bluetooth.adapter.extra.PREVIOUS_CONNECTION_STATE"; public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = "android.bluetooth.adapter.action.BLUETOOTH_ADDRESS_CHANGED";
"android.bluetooth.adapter.extra.PREVIOUS_CONNECTION_STATE"; /** * Broadcast Action: The Bluetooth adapter state has changed in LE only mode. * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter. * <p>Always contains the extra field {@link #EXTRA_BLUETOOTH_ADDRESS} containing the MAC address. * * Note: only system level processes are allowed to send this * defined broadcast. * * @hide */ public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = "android.bluetooth.adapter.action.BLUETOOTH_ADDRESS_CHANGED"; /** * Used as a String extra field in {@link #ACTION_BLUETOOTH_ADDRESS_CHANGED} intent to store the local * Bluetooth MAC address. * * @hide */ public static final String EXTRA_BLUETOOTH_ADDRESS = "android.bluetooth.adapter.extra.BLUETOOTH_ADDRESS";
/** * <p>Always contains the extra field {@link * #EXTRA_BLUETOOTH_ADDRESS} containing the MAC address. * * Note: only system level processes are allowed to send this defined broadcast. * * @hide */ public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = "android.bluetooth.adapter.action.BLUETOOTH_ADDRESS_CHANGED"; /** * Used as a String extra field in {@link * #ACTION_BLUETOOTH_ADDRESS_CHANGED} intent to store the local Bluetooth MAC address. * * @hide */ public static final String EXTRA_BLUETOOTH_ADDRESS = "android.bluetooth.adapter.extra.BLUETOOTH_ADDRESS"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be by BLE Always on enabled application to know the ACL_CONNECTED event when Bluetooth state in STATE_BLE_ON. This denotes GATT connection as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of {@link BluetoothDevice#ACTION_ACL_CONNECTED} which */
String newName = intent.getStringExtra(BluetoothAdapter.EXTRA_LOCAL_NAME); if (DBG) Slog.d(TAG, "Bluetooth Adapter name changed to " + newName); if (newName != null) { storeNameAndAddress(newName, null); } else if (BluetoothAdapter.ACTION_BLUETOOTH_ADDRESS_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BLUETOOTH_ADDRESS); if (newAddress != null) { if (DBG) Slog.d(TAG, "Bluetooth Adapter Address changed to " + newAddress); storeNameAndAddress(null, newAddress); } else { if (DBG) Slog.e(TAG, "No Bluetooth Adapter Address parameter found"); } }
if (newName != null) { storeNameAndAddress(newName, null); } else if (BluetoothAdapter.ACTION_BLUETOOTH_ADDRESS_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BLUETOOTH_ADDRESS); if (newAddress != null) { if (DBG) Slog.d(TAG, "Bluetooth Adapter MAC Address changed to " + newAddress); storeNameAndAddress(null, newAddress); } else { if (DBG) Slog.e(TAG, "No Bluetooth Adapter MAC Address parameter found"); } }
mErrorRecoveryRetryCounter = 0; mContentResolver = context.getContentResolver(); // Observe BLE scan only mode settings change. registerForBleScanModeChange(); mCallbacks = new RemoteCallbackList<IBluetoothManagerCallback>(); mStateChangeCallbacks = new RemoteCallbackList<IBluetoothStateChangeCallback>(); IntentFilter filter = new IntentFilter(BluetoothAdapter.ACTION_LOCAL_NAME_CHANGED); filter.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter); filter = new IntentFilter(BluetoothAdapter.ACTION_BLUETOOTH_ADDRESS_CHANGED); filter.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter); loadStoredNameAndAddress(); if (isBluetoothPersistedStateOn()) { if (DBG) Slog.d(TAG, "Startup: Bluetooth persisted state is ON."); mEnableExternal = true; } String airplaneModeRadios = Settings.Global.getString(mContentResolver, Settings.Global.AIRPLANE_MODE_RADIOS); if (airplaneModeRadios == null || airplaneModeRadios.contains(Settings.Global.RADIO_BLUETOOTH)) { mContentResolver.registerContentObserver( Settings.Global.getUriFor(Settings.Global.AIRPLANE_MODE_ON), true, mAirplaneModeObserver ); }
public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; public static final String ACTION_BT_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_ADDR_CHANGED"; public static final String EXTRA_BT_ADDR = "android.bluetooth.adapter.extra.BT_ADDR"; public static final String ACTION_ACL_CONNECTED = "android.bluetooth.adapter.action.ACL_CONNECTED";
private boolean findMinAbs(RenderScript RS, float[] inputArray, String testName, ReduceFindMinAbs reduction) { final long javaTimeStart = java.lang.System.currentTimeMillis(); final float javaResult = findMinAbs(inputArray); final long javaTimeEnd = java.lang.System.currentTimeMillis(); final long rsTimeStart = java.lang.System.currentTimeMillis(); Allocation inputAllocation = Allocation.createSized(RS, Element.F32(RS), inputArray.length); final long copyTimeStart = java.lang.System.currentTimeMillis(); inputAllocation.copyFrom(inputArray); final long kernelTimeStart = java.lang.System.currentTimeMillis(); } private boolean findMinMat(RenderScript RS, int seed, int[] inputSize, int matSize, Element matElement, ReduceFindMinMat reduction) { final int length = inputSize[0]; final int matSizeSquared = matSize * matSize; final float[] inputArray = createInputArrayFloat(matSizeSquared * length, seed); final long javaTimeStart = java.lang.System.currentTimeMillis(); final float[] javaResult = findMinMat(inputArray, matSize); final long javaTimeEnd = java.lang.System.currentTimeMillis(); } boolean run(RenderScript RS, ScriptC_reduce s, int seed, int[] size); } @Override public void onCreate() { } @Override public int onStartCommand(Intent intent, int flags, int startId) { if (intent == null) { Log.e(TAG, "Can't start: null intent!"); stopSelf(); return START_NOT_STICKY; } Resources res = getResources(); Notification.Builder builder = new Notification.Builder(this) .setSmallIcon(android.R.drawable.stat_sys_data_bluetooth) .setTicker(res.getString(R.string.bluetooth_notif_ticker)); PendingIntent pairIntent = PendingIntent.getActivity(this, 0,
public class MyClass { public boolean processLine(String line, ErrorParserManager eoParser) { Matcher matcher = pattern.matcher(line); if (!matcher.matches()) { return false; } IFile fileName = eoParser.findFileName(matcher.group(1)); if (fileName != null) { int lineNumber = Integer.parseInt(matcher.group(2)); String description = matcher.group(4); int severity = Severity.findSeverityCode(matcher.group(3)); ProblemMarkerInfo info = new ProblemMarkerInfo(fileName, lineNumber, description, severity, null); eoParser.addProblemMarker(info); return true; } return false; } } public class CASTSimpleDeclSpecifier extends CASTBaseDeclSpecifier implements ICASTSimpleDeclSpecifier { private int simpleType; private boolean isSigned; private boolean isUnsigned; private boolean isShort; private boolean isLong; private boolean longlong; private boolean complex; private boolean imaginary; private IASTExpression fDeclTypeExpression; @Override public CASTSimpleDeclSpecifier copy() { return copy(CopyStyle.withoutLocations); } @Override public CASTSimpleDeclSpecifier copy(CopyStyle style) { CASTSimpleDeclSpecifier copy = new CASTSimpleDeclSpecifier(); return copy(copy, style); } protected <T extends CASTSimpleDeclSpecifier> T copy(T copy, CopyStyle style) { CASTSimpleDeclSpecifier target = copy; // Copy properties from this to target target.simpleType = this.simpleType; target.isSigned = this.isSigned; target.isUnsigned = this.isUnsigned; target.isShort = this.isShort; target.isLong = this.isLong; target.longlong = this.longlong; target.complex = this.complex; target.imaginary = this.imaginary; target.fDeclTypeExpression = this.fDeclTypeExpression; return copy; } } public class MyClass { static ICPPASTFunctionDefinition createFunctionSignatureWithEmptyBody(IASTDeclSpecifier newDeclSpec, IASTFunctionDeclarator newFuncDecl, IASTFunctionDefinition oldDefinition) { ICPPASTFunctionDefinition newFunc = null; newFuncDecl = adjustParamNames(newFuncDecl, oldDefinition); if (oldDefinition instanceof ICPPASTFunctionWithTryBlock)
* Copyright (C) 2017 The Android Open Source Project Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. public class Main { public static void main(String[] args) { System.loadLibrary(args[0]); testGetFieldId(TestClass.class, "intField", "I"); testGetFieldId(TestClass.class, "intField", "int"); testGetFieldId(TestClass.class, "intField", "Lint;"); testGetFieldId(TestClass.class, "stringField", "I"); } }
<tr><td>Android (TBD)</td> <td><a href="http://site.icu-project.org/download/58">ICU 58.2</a></td> <td><a href="http://cldr.unicode.org/index/downloads/cldr-30">CLDR 30.0.3</a></td> <td><a href="http://www.unicode.org/versions/Unicode9.0.0/">Unicode 9.0</a></td></tr>
// Disable native bind notify for now to avoid infinite loops. setNativeBindNotify(false); String transSym = SymbolMap.getOrDefault(method, nativeSym); setNativeBindNotify(true); return transSym; } public static void doTest() throws Exception { Method say_hi_method = Transform.class.getDeclaredMethod("sayHi"); Transform.sayHi2(); setNativeTransform(say_hi_method, "NoReallySayGoodbye"); Transform.sayHi(); setNativeTransform(say_hi_method, "Java_art_Test986_00024Transform_sayHi2"); rebindTransformClass(); Transform.sayHi(); removeNativeTransform(say_hi_method); rebindTransformClass(); Transform.sayHi(); Main.bindAgentJNIForClass(Main.class); Main.bindAgentJNIForClass(Test986.class); } // Functions called from native code.
package com.android.internal.telephony; import android.content.Context; import android.content.Intent; import android.content.IntentFilter; import android.content.BroadcastReceiver; import com.android.internal.telephony.CallForwardInfo; import com.android.internal.telephony.gsm.CommandException; import com.android.internal.telephony.gsm.NetworkInfo; import com.android.internal.telephony.gsm.PDPContextState; import com.android.internal.telephony.IccUtils; import com.android.internal.telephony.gsm.SmsResponse; import com.android.internal.telephony.gsm.SuppServiceNotification; import android.os.Parcel; import java.io.IOException; import android.os.Message; import android.os.Handler; import android.net.LocalSocketAddress; import android.net.LocalSocket; import com.android.internal.os.HandlerThread; import android.os.HandlerInterface; import java.util.ArrayList; import java.util.Collections; import java.io.InputStream; import android.telephony.PhoneNumberUtils; import android.telephony.gsm.SmsManager; public class PhoneSubInfo { private Phone mPhone; private Context mContext; public PhoneSubInfo(Phone phone) { mPhone = phone; mContext = phone.getContext(); } } public class Main { public static void bindAgentJNIForClass(Class<?> cls) { // implementation } } public class Test986 { // implementation }
private void ensureValidNetworkSpecifier(NetworkSpecifier ns) { MatchAllNetworkSpecifier.checkNotMatchAllNetworkSpecifier(ns); if (ns != null) { ns.assertValidFromUid(Binder.getCallingUid()); } }
/* * Copyright (C) 2009 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net.cts; import static com.android.server.NetworkManagementSocketTagger.resetKernelUidStats; import java.net.ServerSocket; import android.net.TrafficStats; import android.os.Process; import android.test.AndroidTestCase; import android.util.Log; import android.net.LocalSocket; import java.io.File; import java.io.BufferedReader; import java.io.FileNotFoundException; import java.io.FileReader; import java.io.FileWriter; import static com.android.server.NetworkManagementSocketTagger.resetKernelUidStats; import java.net.ServerSocket; import android.net.TrafficStats; import android.os.Process; import android.test.AndroidTestCase; import android.util.Log; import android.net.LocalSocket; import java.io.File; import java.io.BufferedReader; import java.io.FileNotFoundException; import java.io.FileReader; import java.io.FileWriter;
String line; Pattern ctrlDataPattern = Pattern.compile(PATTERN); while((line = qtaguidReader.readLine()) != null) { Matcher refCountMatcher = ctrlDataPattern.matcher(line); if(refCountMatcher.matches()) { if (refCountMatcher.group(TAG_INDEX).contains(Long.toHexString(fullTag)) && refCountMatcher.group(UID_INDEX).contains(Integer.toString(uid))) { refcnt_res = Integer.parseInt(refCountMatcher.group(REFCNT_INDEX)); Log.d(TAG, "result refcnt:" + refcnt_res); break; } } } qtaguidReader.close(); } catch (FileNotFoundException e) { fail("Not able to access qtaguid/ctrl: "+e); } catch (IOException e) { fail("file read error"); } return refcnt_res;
if (refCountMatcher.group(TAG_INDEX).contains(Long.toHexString(fullTag)) && refCountMatcher.group(UID_INDEX).contains(Integer.toString(uid))) { refcnt_res = Integer.parseInt(refCountMatcher.group(REFCNT_INDEX)); Log.d(TAG, "result refcnt:" + refcnt_res); break; } } qtaguidReader.close(); } catch (FileNotFoundException e) { fail("Not able to access qtaguid/ctrl: "+e); } catch (IOException e) { fail("file read error"); throw e; } return refcnt_res;
public boolean imsIsEnhanced4gLteModeSettingEnabledByPlatform() { return mImsManager.isVolteEnabledByPlatformForSlot(); }
private static BufferedImage getSvgImage(@NotNull String path, StringBuilder errorLog) { String xmlFileContent = generateVectorXml(new File(path), errorLog); BufferedImage image = VdPreview.getPreviewFromVectorXml(SVG_PREVIEW_WIDTH, 0.0f, xmlFileContent, errorLog); if (image == null) { image = new BufferedImage(1, 1, BufferedImage.TYPE_INT_ARGB); errorLog.insert(0, ERROR_MESSAGE_EMPTY_PREVIEW_IMAGE + "\n"); } return image; } protected void configure() { cache(CACHE_NAME, String.class, ProjectState.class).loader(Loader.class); cache(CACHE_LIST, ListKey.class, new TypeLiteral<SortedSet<Project.NameKey>>() {}) .maximumWeight(1) .loader(Lister.class); bind(ProjectCacheImpl.class); bind(ProjectCache.class).to(ProjectCacheImpl.class); install(new LifecycleModule() { @Override protected void configure() { listener().to(ProjectCacheWarmer.class); listener().to(ProjectCacheClock.class); } }); } assertEquals(true, NetworkSecurityPolicy.isCleartextTrafficPermitted()); public void testCleartextTrafficPolicyWithFtpURLConnection() throws Exception { NetworkSecurityPolicy.setCleartextTrafficPermitted(true); byte[] serverReplyOnConnect = "220\r\n".getBytes("US-ASCII"); try (CapturingServerSocket server = new CapturingServerSocket(serverReplyOnConnect)) { URL url = new URL("ftp://localhost:" + server.getPort() + "/test.txt"); try { url.openConnection().getContent(); fail(); } catch (IOException expected) { } assertDataTransmittedByClient(server); } NetworkSecurityPolicy.setCleartextTrafficPermitted(false); try (CapturingServerSocket server = new CapturingServerSocket(serverReplyOnConnect)) { URL url = new URL("ftp://localhost:" + server.getPort() + "/test.txt"); try { url.openConnection().getContent(); fail(); } catch (IOException expected) { } } } /** * A utility class for handling unsigned integers and unsigned arithmetics, as well as sugar methods * for ByteBuffer. Useful for networking and packet manipulations. */ public final class BitUtils { private BitUtils() {} public static boolean maskedEquals(long a,
} try { Class<?> tc = Class.forName("TestClass"); Method test = tc.getDeclaredMethod("test"); test.invoke(null); System.out.println("UNREACHABLE!"); } catch (InvocationTargetException ite) { if (ite.getCause() instanceof InstantiationError) { System.out.println(ite.getCause().getClass().getName() + ": " + ite.getCause().getMessage()); } else { ite.printStackTrace(System.out); } } catch (Throwable t) { t.printStackTrace(System.out); }
protected int computeMillisInDay() { int millisInDay = 0; int hourOfDayStamp = stamp[HOUR_OF_DAY]; int hourStamp = Math.max(stamp[HOUR], stamp[AM_PM]); return findPreviousZoneTransitionTime(tz, upperOffset, mid, lower); }
protected int computeMillisInDay() { int millisInDay = 0; int hourOfDayStamp = stamp[HOUR_OF_DAY]; int hourStamp = Math.max(stamp[HOUR], stamp[AM_PM]); if (hourOfDayStamp >= 0) { millisInDay += fields[HOUR_OF_DAY]; } else if (hourStamp >= 0) { millisInDay += fields[HOUR] + (fields[AM_PM] * 12); } millisInDay *= 60; millisInDay += fields[MINUTE]; millisInDay *= 60; millisInDay += fields[SECOND]; millisInDay *= 1000; millisInDay += fields[MILLISECOND]; return millisInDay; }
private String verifiedProvider; private boolean verificationResult; public X509CertImpl() { } // BEGIN Android-added: Constructor to retain original encoded form in PKCS7. public X509CertImpl(byte[] certData) { // Implementation here } // END Android-added
import java.security.cert.CertificateException; import java.security.cert.X509Certificate; import java.security.cert.CertificateFactory; import java.io.ByteArrayInputStream; import java.io.IOException; public class X509CertImpl { private X509Certificate signedCert; public X509CertImpl(byte[] certData) throws CertificateException { try { CertificateFactory cf = CertificateFactory.getInstance("X.509"); signedCert = (X509Certificate) cf.generateCertificate(new ByteArrayInputStream(certData)); } catch (IOException e) { signedCert = null; throw new CertificateException("Unable to initialize, " + e, e); } } }
public void onRestoreInstanceState(Bundle savedInstanceState) { if (savedInstanceState != null) { super.onRestoreInstanceState(savedInstanceState); DialogState dialogState = mDialogState.valueOf(savedInstanceState.getString(DIALOG_STATE)); String msg = savedInstanceState.getString(DIALOG_MSG_STRING); updateDialog(dialogState, msg); if (dialogState == DialogState.WPS_START) { startWps(); } } } private void startWps() { WpsInfo wpsConfig = new WpsInfo(); wpsConfig.setup = mWpsSetup; mWifiManager.startWps(wpsConfig, mWpsListener); }
import java.util.Arrays; import java.nio.ByteBuffer; import javax.obex.ServerRequestHandler; import javax.obex.ResponseCodes; import javax.obex.ApplicationParameter; import javax.obex.Operation; import javax.obex.HeaderSet; public class BluetoothPbapObexServer extends ServerRequestHandler { private static final String TAG = "BluetoothPbapObexServer"; private static final boolean D = BluetoothPbapService.DEBUG; private static final boolean V = BluetoothPbapService.VERBOSE; private static final int UUID_LENGTH = 16; public static final int INVALID_VALUE_PARAMETER = -1; private static final int VCARD_NAME_SUFFIX_LENGTH = 5; private static final byte[] PBAP_TARGET = new byte[] { 0x79, 0x61, 0x35, (byte)0xf0, (byte)0xf0, (byte)0xc5, 0x11, (byte)0xd8, 0x09, 0x66, 0x08, 0x00, 0x20, 0x0c, (byte)0x9a, 0x66 }; }
public String getShortName() { return EndpointBundle.message("api.namespace.short.name"); } public static int getMaxHttpConnectionsPerHost() { return getSystemPropertyAndParseInt(MAX_HTTP_HOST_CONNECTIONS_PROPERTY, MAX_HTTP_HOST_CONNECTIONS_DEFAULT); } private final int handleAppParaForResponse(AppParamValue appParamValue, int size, HeaderSet reply, Operation op, String name) { byte[] misnum = new byte[1]; ApplicationParameter ap = new ApplicationParameter(); long folderVersionCounterbitMask = 0x0008; long databaseIdentifierBitMask = 0x0004; boolean needSendCallHistoryVersionCounters = false; if (isNameMatchTarget(name, MCH) || isNameMatchTarget(name, ICH) || isNameMatchTarget(name, OCH) || isNameMatchTarget(name, CCH)) { needSendCallHistoryVersionCounters = checkPbapFeatureSupport(folderVersionCounterbitMask); } boolean needSendPhonebookVersionCounters = false; if (isNameMatchTarget(name, PB)) { needSendPhonebookVersionCounters = checkPbapFeatureSupport(folderVersionCounterbitMask); } if (mNeedPhonebookSize) { // ... } } interface ComponentVersionReader { ComponentVersionReader GRADLE = new GradleVersionReader(); ComponentVersionReader ANDROID_GRADLE_PLUGIN = new AndroidGradlePluginVersionReader(); boolean appliesTo(@NotNull Module module); String getVersion(@NotNull Module module); }
boolean status = sdpManager.removeSdpRecord(mSdpHandle); Log.d(TAG, "RemoveSDPrecord returns " + status); mSdpHandle = -1; } mSdpHandle = SdpManager.getDefaultManager().createPbapPseRecord( "OBEX Phonebook Access Server", mServerSockets.getRfcommChannel(), mServerSockets.getL2capPsm(), SDP_PBAP_SERVER_VERSION, SDP_PBAP_SUPPORTED_REPOSITORIES, SDP_PBAP_SUPPORTED_FEATURES); // Here we might have changed crucial data, hence reset DB identifier updateDbIdentifier(); if (DEBUG) Log.d(TAG, "PBAP server with handle:" + mSdpHandle);
import android.bluetooth.BluetoothDevice; import android.content.Intent; import android.util.Log; intent.putExtra(BluetoothDevice.EXTRA_PACKAGE_NAME, getPackageName()); mIsWaitingAuthorization = true; sendOrderedBroadcast(intent, BLUETOOTH_ADMIN_PERM); if (VERBOSE) { Log.v(TAG, "waiting for authorization for connection from: " + sRemoteDeviceName); } mSessionStatusHandler.sendMessageDelayed(mSessionStatusHandler.obtainMessage(USER_TIMEOUT), USER_CONFIRM_TIMEOUT_VALUE); // We will continue the process when we receive BluetoothDevice.ACTION_CONNECTION_ACCESS_REPLY from Settings app. return true;
+ startPointId; String selection; if (typeSelection == null) { selection = recordSelection; } else { selection = "(" + typeSelection + ") AND (" + recordSelection + ")"; } if (V) Log.v(TAG, "Call log query selection is: " + selection); return composeCallLogsAndSendSelectedVCards(op, selection, vcardType21, needSendBody, pbSize, null, ignorefilter, filter, vcardselector, vcardselectorop, vcardselect); } final int composeAndSendPhonebookVcards(Operation op, final int startPoint, final int endPoint, final boolean vcardType21, String ownerVCard, int needSendBody, int pbSize, boolean ignorefilter, byte[] filter, byte[] vcardselector, String vcardselectorop, boolean vcardselect) { if (startPoint < 1 || startPoint > endPoint) { Log.e(TAG, "internal error: startPoint or endPoint is not correct."); return ResponseCodes.OBEX_HTTP_INTERNAL_ERROR; }
public String onValueReceived(String rawValue, int type, String label, boolean isPrimary) { String numberWithControlSequence = rawValue.replace(PhoneNumberUtils.PAUSE, 'p') .replace(PhoneNumberUtils.WAIT, 'w'); return numberWithControlSequence; }
public String onValueReceived(String rawValue, int type, String label, boolean isPrimary) { // 'p' and 'w' are the standard characters for pause and wait // (see RFC 3601) // so use those when exporting phone numbers via vCard. String numberWithControlSequence = rawValue.replace(PhoneNumberUtils.PAUSE, 'p') .replace(PhoneNumberUtils.WAIT, 'w'); return numberWithControlSequence; }
private boolean checkprop(String vcard, String prop) { String lines[] = vcard.split(SEPARATOR); boolean isPresent = false; for (String line : lines) { if (!Character.isWhitespace(line.charAt(0)) && !line.startsWith("=")) { String currentProp = line.split("[;:]")[0]; if (prop.equals(currentProp)) { Log.e(TAG, "bit.prop.equals current prop :" + prop); isPresent = true; return isPresent; } } } return isPresent; }
private boolean checkVcardSelector(String vcard, String vcardSelectorOp) { boolean selectedIn = true; for (PropertyMask bit : PropertyMask.values()) { if (checkBit(bit.pos, selector)) { if (vcardSelectorOp.equals("0")) { if (checkProp(vcard, bit.prop)) { selectedIn = true; break; } else { selectedIn = false; } } else if (vcardSelectorOp.equals("1")) { if (!checkProp(vcard, bit.prop)) { selectedIn = false; return selectedIn; } else { selectedIn = true; } } } } return selectedIn; }
private boolean checkVcardSelector(String vcard, String vcardSelectorOp) { boolean selectedIn = true; for (PropertyMask bit : PropertyMask.values()) { if (checkBit(bit.pos, selector)) { Log.e(TAG, "checking for prop :" + bit.prop); if (vcardSelectorOp.equals("0")) { if (checkProp(vcard, bit.prop)) { Log.e(TAG, "bit.prop.equals current prop :" + bit.prop); selectedIn = true; break; } else { selectedIn = false; } } else if (vcardSelectorOp.equals("1")) { if (!checkProp(vcard, bit.prop)) { Log.e(TAG, "bit.prop.notequals current prop" + bit.prop); selectedIn = false; return selectedIn; } else { selectedIn = true; } } } } return selectedIn; }
boolean status = sdpManager.removeSdpRecord(mSdpHandle); Log.d(TAG, "RemoveSDPrecord returns " + status); mSdpHandle = -1; mSdpHandle = SdpManager.getDefaultManager().createPbapPseRecord( "OBEX Phonebook Access Server", mServerSockets.getRfcommChannel(), mServerSockets.getL2capPsm(), SDP_PBAP_SERVER_VERSION, SDP_PBAP_SUPPORTED_REPOSITORIES, SDP_PBAP_SUPPORTED_FEATURES); getPbapDbParams(); if (DEBUG) { Log.d(TAG, "PBAP server with handle:" + mSdpHandle); }
private boolean initialize() { Log.d(TAG, "Start initialize()"); mPMCStatusLogger = new PMCStatusLogger(TAG + ".log", TAG); // Check if any Bluetooth devices are connected ArrayList<BluetoothDevice> results = new ArrayList<BluetoothDevice>(); Set<BluetoothDevice> bondedDevices = mBluetoothAdapter.getBondedDevices(); if (bondedDevices == null) { Log.e(TAG, "No device is connected"); return false; } for (BluetoothDevice bd : bondedDevices) { if (bd.isConnected()) { results.add(bd); } } if (results.isEmpty()) { Log.e(TAG, "No device is connected"); return false; } Log.d(TAG, "Finish initialize()"); return true; }
private boolean initialize() { Log.d(TAG, "Start initialize()"); mPMCStatusLogger = new PMCStatusLogger(TAG + ".log", TAG); // Check if any BT devices are connected ArrayList<BluetoothDevice> results = new ArrayList<BluetoothDevice>(); BluetoothDevice[] bondedDevices = mBluetoothAdapter.getBondedDevices(); if (bondedDevices != null) { for (BluetoothDevice bd : bondedDevices) { if (bd.isConnected()) { results.add(bd); } } } if (results.isEmpty()) { Log.e(TAG, "No device is connected"); return false; } Log.d(TAG, "Finish initialize()"); return true; }
boolean bluetoothOffMute = false; Bundle extras = intent.getExtras(); if (extras == null) { Log.e(TAG, "No parameters specified"); return; } // Always initialize() if (!initialize()) { mPMCStatusLogger.logStatus("initialize() Failed"); return; } // Check if it is baseline Bluetooth is on but not streaming if (extras.containsKey("BT_ON_NotPlay")) { Log.v(TAG, "NotPlay is specified for baseline case of only Bluetooth on"); // Do nothing further mPMCStatusLogger.logStatus("READY"); mPMCStatusLogger.logStatus("SUCCEED"); return; } if (!extras.containsKey("PlayTime")) { Log.e(TAG, "No Play Time specified"); return; } String playTimeStr = extras.getString("PlayTime"); Log.d(TAG, "Play Time = " + playTimeStr); int playTime = Integer.valueOf(playTimeStr); if (!extras.containsKey("MusicURL")) { Log.e(TAG, "No Music URL specified"); return; }
Log.e(TAG, "No Play Time specified"); return; } tmpStr = extras.getString("PlayTime"); Log.d(TAG, "Play Time = " + tmpStr); playTime = Integer.valueOf(tmpStr); if (!extras.containsKey("MusicURL")) { Log.e(TAG, "No Music URL specified"); return; } musicUrl = extras.getString("MusicURL"); Log.d(TAG, "Music URL = " + musicUrl); // playTime and musicUrl are necessary if (playTime == 0 || musicUrl.isEmpty() || musicUrl == null) { Log.d(TAG, "Invalid parameters"); return; } // Check if it is the baseline for BT off but streaming with speakers muted if (extras.containsKey("BT_OFF_Mute")) { Log.v(TAG, "Mute is specified for BT off baseline case"); bt_off_mute = true; } else { if (!extras.containsKey("CodecType")) { Log.e(TAG, "No Codec Type specified"); return; }
public void testClientsCanConnect() { NsdService service = makeService(); NsdManager client1 = connectClient(service); NsdManager client2 = connectClient(service); // TODO: disconnect client1 // TODO: disconnect client2 }
} public MockPrintStream(OutputStream os) { super(os); } @Override public void clearError() { super.clearError(); } @Override public void setError() { super.setError(); } } /** * {@link java.io.PrintStream#PrintStream(String)} */ public void test_Constructor_Ljava_lang_String() throws IOException { PrintStream os = new PrintStream(testFilePath); os.print(UNICODE_STRING); os.close(); assertFileContents(UNICODE_STRING.getBytes(), testFile); } /** * {@link java.io.PrintStream#PrintStream(String, String)} */ public void test_Constructor_Ljava_lang_String_Ljava_lang_String() throws Exception { // Test that a bogus charset is mentioned in the exception try { new PrintStream(testFilePath, "Bogus"); fail("Exception expected"); } catch (UnsupportedEncodingException e) { assertNotNull(e.getMessage()); } { PrintStream os = new PrintStream(testFilePath, Charset.defaultCharset().name()); os.print(UNICODE_STRING); os.close();
import org.apache.lucene.index.Term; import org.apache.lucene.search.Query; import org.apache.lucene.store.Directory; import java.io.IOException; /** * Writer that optionally flushes/commits after every write. */ public class AutoCommitWriter extends IndexWriter { private boolean autoCommit; AutoCommitWriter(Directory dir, IndexWriterConfig config) throws IOException { this(dir, config, false); } AutoCommitWriter(Directory dir, IndexWriterConfig config, boolean autoCommit) throws IOException { super(dir, config); setAutoCommit(autoCommit); } /** * This method will override Gerrit configuration index.name.commitWithin * until next Gerrit restart (or reconfiguration through this method). * * @param enable auto commit */ public void setAutoCommit(boolean enable) { this.autoCommit = enable; } @Override public void addDocument(Iterable<? extends IndexableField> doc) throws IOException { super.addDocument(doc); autoFlush(); } @Override public void addDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs) throws IOException { super.addDocuments(docs); autoFlush(); } @Override public void updateDocuments(Term delTerm, Iterable<? extends Iterable<? extends IndexableField>> docs) throws IOException { super.updateDocuments(delTerm, docs); } } package org.eclipse.mylyn.wikitext.asciidoc; import java.util.Map; import org.eclipse.mylyn.wikitext.parser.markup.MarkupLanguageConfiguration; /** * Extended configuration for the AsciiDoc markup language * * @author Jeremie Bresson * @since 3.0.0 */ public class AsciiDocMarkupLanguageConfiguration extends MarkupLanguageConfiguration { private Map<String, String> initialAttributes = Collections.emptyMap(); public Map<String, String> getInitialAttributes() { return initialAttributes; } public void setInitialAttributes(Map<String, String> initialAttributes) { this.initialAttributes = initialAttributes; } } // The count should be one for the first rule. verify(firstRule, times(1)).rewritePre(any(), any()); verify(secondRule, times(0)).rewritePre(any(), any()); verify(thirdRule, times(0)).rewritePre(any(), any()); // Case 3: a mixture of returning true/false. // Iteration1:
confirmConfiguration(); return; // Thread-unsafe access to mApfFilter but just used for debugging. final ApfFilter apfFilter = mApfFilter; final ProvisioningConfiguration provisioningConfig = mConfiguration; IndentingPrintWriter pw = new IndentingPrintWriter(writer, " "); pw.println(mTag + " APF dump:"); pw.increaseIndent(); if (apfFilter != null) { apfFilter.dump(pw); } else { pw.println("No active ApfFilter. Capabilities: " + Objects.toString(provisioningConfig.mApfCapabilities)); } pw.decreaseIndent(); pw.println(); pw.println(mTag + " current ProvisioningConfiguration:"); pw.increaseIndent(); pw.println((provisioningConfig != null) ? provisioningConfig : "N/A"); pw.decreaseIndent(); pw.println(); pw.println(mTag + " StateMachine dump:"); pw.increaseIndent(); mLocalLog.readOnlyLocalLog().dump(fd, pw, args); pw.decreaseIndent(); pw.println();
final ApfFilter apfFilter = mApfFilter; final ProvisioningConfiguration provisioningConfig = mConfiguration; IndentingPrintWriter pw = new IndentingPrintWriter(writer, " "); pw.println(mTag + " APF dump:"); pw.increaseIndent(); if (apfFilter != null) { apfFilter.dump(pw); } else { if (provisioningConfig != null) { pw.println("No active ApfFilter; provisioned capabilities: " + provisioningConfig.mApfCapabilities); } else { pw.println("N/A -- no ProvisioningConfiguration available"); } } pw.decreaseIndent(); pw.println(); pw.println(mTag + " current ProvisioningConfiguration:"); pw.increaseIndent(); pw.println((provisioningConfig != null) ? provisioningConfig : "N/A"); pw.decreaseIndent(); pw.println(); pw.println(mTag + " StateMachine dump:"); pw.increaseIndent(); mLocalLog.readOnlyLocalLog().dump(fd, pw, args); pw.decreaseIndent(); pw.println();
pw.increaseIndent(); if (apfFilter != null) { apfFilter.dump(pw); } else { if (provisioningConfig != null) { pw.println("No active ApfFilter; provisioned capabilities: " + provisioningConfig.mApfCapabilities); } else { pw.println("N/A -- no ProvisioningConfiguration available"); } } pw.decreaseIndent(); pw.println(); pw.println(mTag + " current ProvisioningConfiguration:"); pw.increaseIndent(); pw.println(Objects.toString(provisioningConfig, "N/A")); pw.decreaseIndent(); pw.println(); pw.println(mTag + " StateMachine dump:"); pw.increaseIndent(); mLocalLog.readOnlyLocalLog().dump(fd, pw, args); pw.decreaseIndent(); pw.println(); pw.println(mTag + " connectivity packet log:"); pw.println(); pw.println("Debug with python and scapy via:"); pw.println("shell$ python"); pw.println(">>> from scapy import all as scapy");
private int putListener(Object listener, NsdServiceInfo s) { checkListener(listener); final int key; synchronized (mMapLock) { int valueIndex = mListenerMap.indexOfValue(listener); checkArgument(valueIndex == -1, "listener already in use"); key = Math.abs(mListenerKey++); mListenerMap.put(key, listener); mServiceMap.put(key, s); } return key; }
import org.apache.impala.catalog.AggregateFunction; import org.apache.impala.catalog.Type; import org.apache.impala.common.AnalysisException; import org.apache.impala.common.InternalException; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import com.google.common.base.Objects; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** * Encapsulates all the information needed to compute a list of aggregate functions with * compatible grouping including their distributed execution. * A mix of distinct and non-distinct aggregation functions is allowed as long as all * distinct functions have the same distinct expressions. * * Execution is modeled as a tree of AggregateInfo objects which express the local and * merging aggregate computations. The tree structure looks as follows: * - for non-distinct aggregation: * - aggInfo: contains the original aggregation functions and grouping exprs * - aggInfo.mergeAggInfo: contains the merging aggregation functions (grouping * exprs are identical) * - for distinct aggregation (also see createDistinctAggInfo()): */ public NetlinkSocketAddress(int nlPortId) { this(nlPortId, 0); } protected String handleSetTestResultCmd(final String request) { String response = RESPONSE_OK; StringTokenizer tokenizer = new StringTokenizer(request, " "); String testName = ""; SensorTestResult result = SensorTestResult.FAIL; String message = ""; try { tokenizer.nextToken(); /* SET */ tokenizer.nextToken(); /* TEST */ tokenizer.nextToken(); /* RESULT */ testName = tokenizer.nextToken(); final String resultToken = tokenizer.nextToken(); if (resultToken.equals("PASS")) { result = SensorTestResult.PASS; ++mCountPassed; message = "Test PASSED"; String logMessage = ""; while (tokenizer.hasMoreTokens()) { logMessage += tokenizer.nextToken() + " "; } Log.i(TAG, logMessage); response = RESPONSE_OK; } else if (resultToken.equals("FAIL")) { result = SensorTestResult.FAIL; ++mCountFailed; message = "Test FAILED"; while (tokenizer.hasMoreTokens()) { message += " " + tokenizer.nextToken(); } response = RESPONSE_OK; } } catch (Exception e) { // Handle exception } return response; } public void onOwnAddressRead(AdvertisingSet advertisingSet, int addressType
public void run() { byte[] annotatedDexContent = Base64.getDecoder().decode(base64DexWithExtensionClass); InMemoryDexClassLoader classLoader = new InMemoryDexClassLoader(ByteBuffer.wrap(annotatedDexContent), ClassLoader.getSystemClassLoader()); Class<?> klass = null; try { klass = classLoader.loadClass(classWithSourceDebugExtension); } catch (ClassNotFoundException e) { logWriter.println("--> Debuggee: Could not find class " + classWithSourceDebugExtension); } synchronizer.sendMessage(JPDADebuggeeSynchronizer.SGNL_READY); logWriter.println("--> Debuggee: SourceDebugExtensionDebuggee..."); synchronizer.receiveMessage(JPDADebuggeeSynchronizer.SGNL_CONTINUE); }
import android.media.MediaDescription; import android.media.MediaMetadata; import android.media.AudioManager; import android.media.session.MediaSessionManager; import android.os.Bundle; import android.os.Looper; import android.test.AndroidTestCase; import android.util.Log; import java.nio.ByteBuffer; import java.util.List; import java.util.Arrays; import java.util.ArrayList; import static org.mockito.Mockito.isA; import static org.mockito.Mockito.anyInt; import static org.mockito.Mockito.mock; import static org.mockito.Mockito.when; public class AvrcpTest extends AndroidTestCase { @Override public void setUp() { if (Looper.myLooper() == null) Looper.prepare(); } public void testCanBuild() { Avrcp a = Avrcp.make(getContext()); } public void testFailedBrowseStart() { Context mockContext = mock(Context.class); AudioManager mockAudioManager = mock(AudioManager.class); PackageManager mockPackageManager = mock(PackageManager.class); when(mockAudioManager.getStreamMaxVolume(AudioManager.STREAM_MUSIC)).thenReturn(100); when(mockContext.getSystemService(Context.AUDIO_SERVICE)).thenReturn(mockAudioManager); } }
protected void setWifiConfigurationPassword(WifiConfiguration wifiConfiguration, WifiSecurity wifiSecurity, String password) { if (wifiSecurity == WifiSecurity.WEP) { int length = password.length(); if ((length == 10 || length == 26 || length == 58) && password.matches("[0-9A-Fa-f]*")) { wifiConfiguration.wepKeys[0] = password; } else if (length == 5 || length == 13 || length == 16) { wifiConfiguration.wepKeys[0] = '"' + password + '"'; } } else { if (wifiSecurity == WifiSecurity.PSK && password.length() < FormPageDisplayer.PSK_MIN_LENGTH) { return; } if (password.matches("[0-9A-Fa-f]{64}")) { wifiConfiguration.preSharedKey = password; } else { wifiConfiguration.preSharedKey = '"' + password + '"'; } } }
protected void setWifiConfigurationPassword(WifiConfiguration wifiConfiguration, WifiSecurity wifiSecurity, String password) { if (wifiSecurity == WifiSecurity.WEP) { int length = password.length(); if ((length == 10 || length == 26 || length == 58) && password.matches("[0-9A-Fa-f]*")) { wifiConfiguration.wepKeys[0] = password; } else if (length == 5 || length == 13 || length == 16) { wifiConfiguration.wepKeys[0] = '"' + password + '"'; } } else { if (wifiSecurity == WifiSecurity.PSK && password.length() < FormPageDisplayer.PSK_MIN_LENGTH) { return; } if (password.matches("[0-9A-Fa-f]{64}")) { wifiConfiguration.preSharedKey = password; } else { wifiConfiguration.preSharedKey = '"' + password + '"'; } } }
assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar5(0L, 5L, 7L)); assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar5(0xFFFFFFFF00000000L, 5L, 7L)); assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar6(0L, 5L, 7L)); assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar6(2L, 5L, 7L)); assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar6(-9000L, 5L, 7L));
protected SuggestionCursor getCurrentSuggestions() { if (mSearchActivityView.getSuggestions() == null) { return null; } return mSearchActivityView.getSuggestions().getResult(); }
// Make sure that core apps are optimized according to their own "reason". // If the core apps are not preopted in the B OTA, and REASON_AB_OTA is not speed // (by default is speed-profile) they will be interepreted/JITed. This in itself is // not a problem as we will end up doing profile guided compilation. However, some // core apps may be loaded by system server which doesn't JIT and we need to make // sure we don't interpret-only. int compilationReason = p.coreApp ? PackageManagerService.REASON_CORE_APP : PackageManagerService.REASON_AB_OTA; mDexoptCommands.addAll(generatePackageDexopts(p, compilationReason)); for (PackageParser.Package p : others) { // We assume here that there are no core apps left. if (p.coreApp) { throw new IllegalStateException("Found a core app that's not important"); } mDexoptCommands.addAll(generatePackageDexopts(p, PackageManagerService.REASON_FIRST_BOOT)); } completeSize = mDexoptCommands.size();
classLoader = getClassLoaderInitializedWithDexFile(); } else { classLoader = getClassLoaderInitializedWithClassFile(); } Class<?> klass = null; try { klass = classLoader.loadClass(classWithSourceDebugExtension); } catch (ClassNotFoundException e) { logWriter.println("--> Debuggee: Could not find class " + classWithSourceDebugExtension); } Object o = null; if (klass != null) { try { o = klass.getConstructor().newInstance(); } catch (Exception e) { logWriter.println("--> Debuggee: Failed to instantiate " + classWithSourceDebugExtension + ": " + e); } } synchronizer.sendMessage(JPDADebuggeeSynchronizer.SGNL_READY); logWriter.println("--> Debuggee: SourceDebugExtensionDebuggee..."); synchronizer.receiveMessage(JPDADebuggeeSynchronizer.SGNL_CONTINUE);
public static final String ACTION_DOWNLOAD_RESULT_INTERNAL = "android.telephony.mbms.action.DOWNLOAD_RESULT_INTERNAL"; public static final String ACTION_FILE_DESCRIPTOR_REQUEST = "android.telephony.mbms.action.FILE_DESCRIPTOR_REQUEST";
/** * Optional extras are: * - EXTRA_FD_COUNT (0 if not present) * - EXTRA_PAUSED_LIST (empty if not present) * * TODO: future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST = "android.telephony.mbms.ACTION_FILE_DESCRIPTOR_REQUEST"; /** * The MBMS middleware should send this when it wishes to signal that there may be orphaned * files in the app's filesystem. Mandatory extras are: * - EXTRA_TEMP_FILES_IN_USE * * TODO: future systemapi */ public static final String ACTION_CLEANUP = "android.telephony.mbms.ACTION_CLEANUP"; /** * Integer extra indicating the result code of the download. * * TODO: put in link to error list * TODO: future systemapi (here and all extras) */ public static final String EXTRA_RESULT = "android.telephony.mbms.EXTRA_RESULT"; /** * Extra containing the FileInfo for which the download result */ public static final String EXTRA_FILE_INFO = "android.telephony.mbms.EXTRA_FILE_INFO";
public static final String ACTION_FILE_DESCRIPTOR_REQUEST = "android.telephony.mbms.ACTION_FILE_DESCRIPTOR_REQUEST"; public static final String ACTION_CLEANUP = "android.telephony.mbms.ACTION_CLEANUP"; public static final String EXTRA_RESULT = "android.telephony.mbms.EXTRA_RESULT"; public static final String EXTRA_INFO = "android.telephony.mbms.EXTRA_INFO";
public static final String EXTRA_RESULT = "android.telephony.mbms.extra.RESULT";
public static final String EXTRA_PAUSED_LIST = "android.telephony.mbms.EXTRA_PAUSED_LIST";
public static final String EXTRA_PAUSED_LIST = "android.telephony.mbms.EXTRA_PAUSED_LIST";
public static final String EXTRA_TEMP_FILES_IN_USE = "android.telephony.mbms.EXTRA_TEMP_FILES_IN_USE"; public static final int RESULT_SUCCESSFUL = 1; public static final int RESULT_CANCELLED = 2; public static final int RESULT_EXPIRED = 3; private final Context mContext; private int mSubId = INVALID_SUBSCRIPTION_ID; private IMbmsDownloadService mService; private final IMbmsDownloadManagerListener mCallback; private final String mDownloadAppName; public MbmsDownloadManager(Context context, IMbmsDownloadManagerListener callback, String downloadAppName, int subId) { mContext = context; mCallback = callback; mDownloadAppName = downloadAppName; mSubId = subId; } /** * Create a new MbmsDownloadManager using the system default data subscription ID. * * Note that this call will bind a remote service and that may take a bit. This * may throw an Illegal ArgumentException or RemoteException. * * @hide */
private void validateFragmentContributions(IBuildEntry binIncludes) { try { Document doc = DocumentBuilderFactory.newInstance().newDocumentBuilder().parse(PDEProject.getPluginXml(fProject).getContents()); XPath xpath = XPathFactory.newInstance().newXPath(); NodeList list = (NodeList) xpath.evaluate("/plugin/extension[@point='org.eclipse.e4.workbench.model']/fragment/@uri", doc, XPathConstants.NODESET); for (int i = 0; i < list.getLength(); i++) { Node node = list.item(i); validateBinIncludes(binIncludes, node.getNodeValue()); } } catch (Exception e) { e.printStackTrace(); } } private void validateApplicationContributions(IBuildEntry binIncludes) { try { Document doc = DocumentBuilderFactory.newInstance().newDocumentBuilder().parse(PDEProject.getPluginXml(fProject).getContents()); XPath xpath = XPathFactory.newInstance().newXPath(); Node nodeProduct = (Node) xpath.evaluate("/plugin/extension[@point='org.eclipse.core.runtime.products']/product", doc, XPathConstants.NODE); if (nodeProduct != null) { Node attValue = (Node) xpath.evaluate("property[@name='applicationXMI']/@value", nodeProduct, XPathConstants.NODE); if (attValue != null) { if (attValue.getNodeValue().isEmpty()) { //Error: no URL defined but should already be reported. } else { validateBinIncludes(binIncludes, attValue.getNodeValue()); } } else { validateBinIncludes(binIncludes, "Application.e4xmi"); } } } catch (Exception e) { e.printStackTrace(); } } private IAtsTeamDefinition getTeamDefinition() { if (teamDef == null) { TeamDefinitionDialog ld = new TeamDefinitionDialog("Select Team", "Select Team"); ld.setInput(TeamDefinitions.getTeamReleaseableDefinitions(Active.Active)); int result = ld.open(); if (result == 0) { return (IAtsTeamDefinition) ld.getResult()[0]; } return null; } else { return teamDef; } } private MbmsDownloadManager(Context context, IMbmsDownloadManagerListener callback, String downloadAppName, int subId) { mContext = context; mCallback = callback; mDownloadAppName = downloadAppName; mSubId =
private MbmsStreamingManager(Context context, IMbmsStreamingManagerListener listener, String streamingAppName, int subId) { mContext = context; mAppName = streamingAppName; mCallbackToApp = listener; mSubId = subId; }
public MbmsStreamingManager(Context context, IMbmsStreamingManagerListener listener, String streamingAppName, int subscriptionId) { mContext = context; mAppName = streamingAppName; mCallbackToApp = listener; mSubId = subscriptionId; }
private final ReviewerState state; private final NotifyHandling notify; private final ListMultimap<RecipientType, Id> accountsToNotify; private final ApprovalsUtil approvalsUtil; private final PatchSetUtil psUtil; private final ReviewerAdded reviewerAdded; private final AccountCache accountCache; private final ChangeResource rsrc; private final AddReviewerSender.Factory addReviewerSenderFactory; private final NotesMigration migration; private final Provider<IdentifiedUser> user; private final Provider<ReviewDb> dbProvider; private final Collection<Address> addedCCsByEmail = new ArrayList<>(); private List<PatchSetApproval> addedReviewers = new ArrayList<>(); private Collection<Account.Id> addedCCs = new ArrayList<>(); private PatchSet patchSet; private Result opResult = null; @Inject PostReviewersOp(ApprovalsUtil approvalsUtil, PatchSetUtil psUtil, ReviewerAdded reviewerAdded, AccountCache accountCache, AddReviewerSender.Factory addReviewerSenderFactory, NotesMigration migration, Provider<IdentifiedUser> user, Provider<ReviewDb> dbProvider, @Assisted ChangeResource rsrc, @Assisted Map<Account.Id, ChangeControl> reviewers, @Assisted Collection<Address> reviewersByEmail) { this.state = rsrc.getReviewerState(); this.notify = rsrc.getNotifyHandling(); this.accountsToNotify = rsrc.getAccountsToNotify(); this.approvalsUtil = approvalsUtil; this.psUtil = psUtil; this.reviewerAdded = reviewerAdded; this.accountCache = accountCache; this.rsrc = rsrc; this.addReviewerSenderFactory = addReviewerSenderFactory; this.migration = migration; this.user = user; this.dbProvider = dbProvider; this.addedCCsByEmail.addAll(reviewersByEmail); this.addedReviewers.addAll(reviewers.values()); }
public static boolean contactsLoaded = false; private static ContactInfo contactInfo = new ContactInfo(); public static boolean hasFilter(byte[] filter) { return filter != null && filter.length > 0; } public static boolean isNameAndNumberOnly(byte[] filter) { // For vcard 2.0: VERSION,N,TEL is mandatory // For vcard 3.0, VERSION,N,FN,TEL is mandatory // So we only need to make sure that no other fields except optionally // NICKNAME is set // Check that an explicit filter is not set. If not, this means // return everything if (!hasFilter(filter)) { // implementation } } public class ContactInfo { private HashMap<String, ArrayList<String>> email = new HashMap<String, ArrayList<String>>(); private HashMap<String, ArrayList<String>> phone = new HashMap<String, ArrayList<String>>(); private HashMap<String, ArrayList<String>> address = new HashMap<String, ArrayList<String>>(); private HashMap<String, String> name = new HashMap<String, String>(); private HashSet<String> contactSet = new HashSet<String>(); // getters and setters for the above fields }
} public NetworkStats readNetworkStatsDetail(int limitUid, String[] limitIfaces, int limitTag, NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat // packets needs to be subtracted for the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust =
NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; synchronized (sStackedIfaces) { final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat // packets needs to be subtracted for the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). } } }
NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; synchronized (sStackedIfaces) { final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat // packets needs to be subtracted for the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). } } }
readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; synchronized (sStackedIfaces) { final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { // Adjust the stats for 464xlat traffic on the base interface // both for tx and rx traffic } } }
readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; synchronized (sStackedIfaces) { final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { // packet } } }
for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) { adjust.rxBytes -= (entry.rxBytes + entry.rxPackets * IPV4V6_HEADER_DELTA); adjust.txBytes -= (entry.txBytes + entry.txPackets * IPV4V6_HEADER_DELTA); adjust.rxPackets -= entry.rxPackets; adjust.txPackets -= entry.txPackets; } } stats.combineValues(adjust); for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry); }
adjust.rxPackets -= entry.rxPackets; adjust.txPackets -= entry.txPackets; // TODO: does Entry#operations need to be adjusted too ? stats.combineValues(adjust); // For 464xlat traffic, xt_qtaguid only counts the bytes of the inner IPv4 packet sent on // the stacked interface with prefix "v4-" and drops the IPv6 header size after unwrapping. // To account correctly for on-the-wire traffic, adds the 20 additional bytes difference // for all packets (http://b/12249687, http:/b/33681750). for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry); if (entry.iface != null && entry.iface.startsWith(CLATD_INTERFACE_PREFIX)) { entry.rxBytes = entry.rxPackets * IPV4V6_HEADER_DELTA; entry.txBytes = entry.txPackets * IPV4V6_HEADER_DELTA; entry.rxPackets = 0; entry.txPackets = 0; stats.combineValues(entry); } } return stats;
private static final String CLATD_INTEFACE_PREFIX = "v4-"; private final File mStatsXtIfaceAll; private final File mStatsXtIfaceFmt; private final File mStatsXtUid; // TODO: for testability, do not use a static variable. @GuardedBy("sStackedIfaces") private static final ArrayMap<String, String> sStackedIfaces = new ArrayMap<>(); public static void noteStackedIface(String stackedIface, String baseIface) { synchronized (sStackedIfaces) { if (baseIface != null) { sStackedIfaces.put(stackedIface, baseIface); } else { sStackedIfaces.remove(stackedIface); } } } public NetworkStatsFactory() { this(new File("/proc/")); } @VisibleForTesting public NetworkStatsFactory(File procRoot) {
// from root UID on the base interface. NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) { adjust.txBytes -= entry.txBytes; adjust.txPackets -= entry.txPackets; adjust.rxBytes -= entry.rxBytes; adjust.rxPackets -= entry.rxPackets; } } stats.combineValues(adjust); // Double sigh, all rx traffic on clat needs to be tweaked to // account for the dropped IPv6 header size post-unwrap. for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry); if (entry.iface != null && entry.iface.startsWith(CLATD_INTEFACE_PREFIX)) { // Delta between IPv4 header (20b) and IPv6 header (40b) entry.rxBytes = entry.rxPackets * 20; } }
private void sendNsdStateChangeBroadcast(boolean isEnabled) { final Intent intent = new Intent(NsdManager.ACTION_NSD_STATE_CHANGED); intent.addFlags(Intent.FLAG_RECEIVER_REGISTERED_ONLY_BEFORE_BOOT); intent.putExtra(NsdManager.EXTRA_NSD_STATE, isEnabled ? NsdManager.NSD_STATE_ENABLED : NsdManager.NSD_STATE_DISABLED); mContext.sendStickyBroadcastAsUser(intent, UserHandle.ALL); }
for (String key : bc.keySet()) { if (key.contains(" ")) { continue; } if (key.startsWith("Alg.Alias.")) { key = key.substring("Alg.Alias.".length()); } Provider.Service service = getService(bc, key); if (bcClasses.contains(service.getClassName())) { shouldBeOverriddenBcIds.add(key); } }
AVA(Reader in, Map<String, String> keywordMap) throws IOException { this(in, DEFAULT, keywordMap); } AVA(Reader in, int format) throws IOException { this(in, format, Collections.<String, String>emptyMap()); } AVA(Reader in, int format, Map<String, String> keywordMap) throws IOException { // implementation }
return s; } catch (IOException e) { throw new RuntimeException("AVA error: " + e, e); } } private static DerValue parseHexString(Reader in, int format) throws IOException { int c; ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte b = 0; int cNdx = 0; while (true) { c = in.read(); if (isTerminator(c, format)) { break; } if (c == ' ' || c == '\n') { do { if (c != ' ' && c != '\n') { throw new IOException("AVA parse, invalid hex digit: " + (char) c); } c = in.read(); } while (!isTerminator(c, format)); break; } int cVal = hexDigits.indexOf(Character.toUpperCase((char) c)); if (cVal == -1) { throw new IOException("AVA parse, invalid hex digit: " + (char) c); } if (cNdx % 2 == 0) { b = (byte) (cVal << 4); } else { b |= (byte) cVal; baos.write(b); } cNdx++; } return new DerValue(baos.toByteArray()); }
while (true) { c = in.read(); if (isTerminator(c, format)) { break; } if (c == ' ' || c == '\n') { do { if (c != ' ' && c != '\n') { throw new IOException("AVA parse, invalid hex digit: " + (char)c); } c = in.read(); } while (!isTerminator(c, format)); break; } int cVal = hexDigits.indexOf(Character.toUpperCase((char)c)); if (cVal == -1) { throw new IOException("AVA parse, invalid hex digit: " + (char)c); } if ((cNdx % 2) == 1) { b = (byte)((b * 16) + (byte)(cVal)); baos.write(b); } else { b = (byte)(cVal); } cNdx++; } // throw exception if no hex digits
temp.append(hexString); embeddedHex.clear(); do { c = in.read(); } while ((c == '\n') || (c == ' ')); if (c != -1) { throw new IOException("AVA had characters other than whitespace after terminating quote"); } // encode as PrintableString unless value contains non-PrintableString chars // Android-changed: Do not trim() DerValue strings. if (this.oid.equals((Object)PKCS9Attribute.EMAIL_ADDRESS_OID) || (this.oid.equals((Object)X500Name.DOMAIN_COMPONENT_OID) && PRESERVE_OLD_DC_ENCODING == false)) { // EmailAddress and DomainComponent must be IA5String return new DerValue(DerValue.tag_IA5String, temp.toString()); } else if (isPrintableString) { return new DerValue(temp.toString()); } else { return new DerValue(DerValue.tag_UTF8String, temp.toString()); }
public class AlgorithmId implements Serializable, DerEncoder { private static final long serialVersionUID = 7205873507486557157L; private ObjectIdentifier algid; private AlgorithmParameters algParams; private boolean constructedFromDer = true; public AlgorithmId(ObjectIdentifier algid) { this.algid = algid; } public ObjectIdentifier getAlgorithmId() { return algid; } public AlgorithmParameters getAlgorithmParameters() { return algParams; } public void setAlgorithmParameters(AlgorithmParameters algParams) { this.algParams = algParams; } public boolean isConstructedFromDer() { return constructedFromDer; } public void setConstructedFromDer(boolean constructedFromDer) { this.constructedFromDer = constructedFromDer; } @Override public void derEncode(OutputStream out) throws IOException { algid.derEncode(out); if (algParams != null) { byte[] encodedParams = algParams.getEncoded(); out.write(encodedParams); } } @Override public void derDecode(InputStream in) throws IOException { algid = new ObjectIdentifier(); algid.derDecode(in); if (in.available() > 0) { byte[] encodedParams = new byte[in.available()]; in.read(encodedParams); algParams = AlgorithmParameters.getInstance(algid.toString()); algParams.init(encodedParams); } } }
} catch (NoSuchAlgorithmException e) { algParams = null; return; } // Decode (parse) the parameters algParams.init(params.toByteArray()); } public final void encode(DerOutputStream out) throws IOException { derEncode(out); } public final void derEncode(DerOutputStream out) throws IOException { // Encode the algorithm parameters if (algParams != null) { algParams.encode(out); } } public final void derDecode(DerInputStream in) throws IOException { // Decode the algorithm parameters if (algParams != null) { algParams.decode(in); } } public final void decode(byte[] encodedParams) throws IOException { // Decode the algorithm parameters from the encoded byte array if (encodedParams != null) { DerInputStream in = new DerInputStream(encodedParams); derDecode(in); } } public final byte[] getEncoded() throws IOException { // Get the encoded byte array of the algorithm parameters DerOutputStream out = new DerOutputStream(); derEncode(out); return out.toByteArray(); }
private static final String OCSPNOCHECK = ROOT + "." + OCSPNoCheckExtension.NAME; private static final int NetscapeCertType_data[] = { 2, 16, 840, 1, 113730, 1, 1 }; /** Map ObjectIdentifier(oid) -> OIDInfo(info) */ private final static Map<ObjectIdentifier,OIDInfo> oidMap; /** Map String(friendly name) -> OIDInfo(info) */ private final static Map<String,OIDInfo> nameMap; // BEGIN Android-changed: Specify Class objects rather for oidMap rather than String literals + reflection static { oidMap = new HashMap<ObjectIdentifier,OIDInfo>(); nameMap = new HashMap<String,OIDInfo>(); addInternal(SUB_KEY_IDENTIFIER, PKIXExtensions.SubjectKey_Id, SubjectKeyIdentifierExtension.class); addInternal(KEY_USAGE, PKIXExtensions.KeyUsage_Id, KeyUsageExtension.class); addInternal(PRIVATE_KEY_USAGE, PKIXExtensions.PrivateKeyUsage_Id, PrivateKeyUsageExtension.class); addInternal(SUB_ALT_NAME, PKIXExtensions.SubjectAlternativeName_Id, SubjectAlternativeNameExtension.class); addInternal(ISSUER_ALT_NAME, PKIXExtensions.IssuerAlternativeName_Id, IssuerAlternativeNameExtension.class); addInternal(BASIC_CONSTRAINTS, PKIXExtensions.BasicConstraints_Id, BasicConstraintsExtension.class); addInternal(NAME_CONSTRAINTS, PKIXExtensions.NameConstraints_Id, NameConstraintsExtension.class); addInternal(POLICY_MAPPINGS, PKIXExtensions.PolicyMappings_Id, PolicyMappingsExtension.class); addInternal(POLICY_CONSTRAINTS, PKIXExtensions.PolicyConstraints_Id, PolicyConstraintsExtension.class); addInternal(INHIBIT_ANY_POLICY, PKIXExtensions.InhibitAnyPolicy_Id, InhibitAnyPolicyExtension.class); addInternal(CRL_DISTRIBUTION_POINTS, PKIXExtensions.CRLDistributionPoints_Id, CRLDistributionPointsExtension.class); addInternal(CERTIFICATE_POLICIES, PKIXExtensions.CertificatePolicies_Id, CertificatePoliciesExtension.class); addInternal(EXTENDED_KEY_USAGE, PKIXExtensions.ExtendedKeyUsage_Id, ExtendedKeyUsageExtension.class); addInternal(AUTHORITY_KEY_IDENTIFIER, PKIXExtensions.AuthorityKey_Id, AuthorityKeyIdentifierExtension.class); addInternal(OCSPNOCHECK, PKIXExtensions.OCSPNoCheck_Id, OCSPNoCheckExtension.class);
// limitations under the License. package net.codemirror.lib; import com.google.gwt.core.client.JavaScriptObject; /** * {line, ch} objects used within CodeMirror. */ public class LineCharacter extends JavaScriptObject { public static LineCharacter create(int line, int ch) { LineCharacter lineCh = createObject().cast(); return lineCh.setLine(line).setCh(ch); } private final native LineCharacter setLine(int line) /*-{ this.line = line; return this; }-*/; public final native LineCharacter setCh(int ch) /*-{ this['ch'] = ch; return this; }-*/; public final native int getLine() /*-{ return this.line; }-*/; public final native int getCh() /*-{ return this.ch; }-*/; protected LineCharacter() { } } private static boolean isWrapped(final SWTBot bot) { return bot.label(1).getText().equals("Wrapped search"); } // limitations under the License. package net.codemirror.lib; import com.google.gwt.core.client.JavaScriptObject; /** * {line, ch} objects used within CodeMirror. */ public class LineCharacter extends JavaScriptObject { public static LineCharacter create(int line, int ch) { LineCharacter lineCh = createObject().cast(); return lineCh.setLine(line).setCh(ch); } private final native LineCharacter setLine(int line) /*-{ this.line = line; return this; }-*/; public final native LineCharacter setCh(int ch) /*-{ this['ch'] = ch; return this; }-*/; public final native int getLine() /*-{ return this.line; }-*/; public final native int getCh() /*-{ return this.ch; }-*/; protected LineCharacter() { } } private static boolean isWrapped(final SWTBot bot) { return bot.label(1).getText().equals("Wrapped search"); } // limitations under the License. package org.eclipse.tracecompass.internal.analysis.os.linux.core.latency; import org.eclipse.jdt.annotation.NonNull; import org.eclipse.tracecompass.datastore.core.interval.IHTIntervalReader; import org.eclipse.tracecompass.datastore.core.serialization.ISafeByteBufferWriter; import org.eclipse.trace
protected DataSourceProvider(SitePaths site, @GerritServerConfig Config cfg, Context ctx, DataSourceType dst, SecureStore secureStore) { this.site = site; this.cfg = cfg; this.ctx = ctx; this.dst = dst; this.secureStore = secureStore; } load(absolutePath, VMStack.getCallingClassLoader()); void load(String absolutePath, ClassLoader loader) { if (absolutePath == null) { throw new NullPointerException("absolutePath == null"); } else { final File libFile = new File(absolutePath); if (!libFile.exists()) { throw new NullPointerException("absolutePath is not existing"); } else if (!libFile.canRead()) { throw new java.io.IOException("absolutePath is not readable"); } else if (!libFile.canExecute()) { throw new NullPointerException("absolutePath is not executable"); } } String error = doLoad(absolutePath, loader); if (error != null) { throw new UnsatisfiedLinkError(error); } } private AVAComparator() { // empty } static Comparator<AVA> getInstance() { return INSTANCE; } public int compare(AVA a1, AVA a2) { boolean a1Has2253 = a1.hasRFC2253Keyword(); boolean a2Has2253 = a2.hasRFC2253Keyword(); if (a1Has2253) { if (a2Has2253) { return a1.toRFC2253CanonicalString().compareTo(a2.toRFC2253CanonicalString()); } else { return -1; } } else { if (a2Has2253) { return 1; } else { int[] a1Oid = a1.getObjectIdentifier().toIntArray(); int[] a2Oid = a2.getObjectIdentifier().toIntArray(); int pos = 0; int len = (a1Oid.length > a2Oid.length) ? a2Oid.length : a1Oid.length; while (pos < len) { int diff = a1Oid[pos] - a2Oid[pos]; if (diff != 0) { return diff; } pos++; } return a1Oid.length - a2Oid.length; } } }
/* * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.nfc; import android.content.BroadcastReceiver; import android.content.Context; import android.content.Intent; import android.content.pm.PackageManager; /** * Boot completed receiver. used to disable the application if the device doesn't * support NFC when device boots. */ public class NfcBootCompletedReceiver extends BroadcastReceiver { @Override public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action == null) { return; } if (action.equals(Intent.ACTION_BOOT_COMPLETED)) { PackageManager pm = context.getPackageManager(); if (!pm.hasSystemFeature(PackageManager.FEATURE_NFC)) { pm.setApplicationEnabledSetting(context.getPackageName(), PackageManager.COMPONENT_ENABLED_STATE_DISABLED, 0); } } } }
+ (System.currentTimeMillis() - timestamp) + " ms"); } ContentValues updateValues = new ContentValues(); updateValues.put(BluetoothShare.CURRENT_BYTES, position); mContext.getContentResolver().update(contentUri, updateValues, null, null); } } catch (IOException e1) { Log.e(TAG, "Error when receiving file"); /* OBEX Abort packet received from remote device */ if (e1.getMessage().equals("Abort Received")) { status = BluetoothShare.STATUS_CANCELED; } else { status = BluetoothShare.STATUS_OBEX_DATA_ERROR; } else { status = BluetoothShare.STATUS_OBEX_DATA_ERROR; } error = true; } } if (mInterrupted) { if (D) Log.d(TAG, "receiving file interrupted by user."); status = BluetoothShare.STATUS_CANCELED; } else { if (position == fileInfo.mLength) { if (D) Log.d(TAG, "Receiving file completed for " + fileInfo.mFileName); status = BluetoothShare.STATUS_SUCCESS; } else { private boolean isRefsFor(String refName) { return refName.startsWith("refs/for/") || refName.equals("refs/*"); } public OsExecutionGraphProvider(ITmfTrace trace) { super(trace, "LTTng Kernel"); //$NON-NLS-1$ fSystem = new OsSystemModel(); IConfigurationElement[] config = Platform.getExtensionRegistry().getConfigurationElementsFor(TMF_GRAPH_HANDLER_ID); for (IConfigurationElement ce : config) { String elementName = ce.getName(); if (elementName.equals(HANDLER)) { IOsExecutionGraphHandlerBuilder builder; try { builder = (IOsExecutionGraphHandlerBuilder) ce.createExecutableExtension(ATTRIBUTE_CLASS); } catch (CoreException e1) { Activator.getDefault().logWarning("Error create execution graph handler builder", e1); //$NON-NLS-1$ continue; } String priorityStr = ce.getAttribute(ATTRIBUTE_PRIORITY); int priority = DEFAULT_PRIORITY; try { priority = Integer.valueOf(priorityStr); } catch (NumberFormatException e) { // Nothing to do, use default value } ITraceEventHandler handler = builder.createHandler(this, priority); registerHandler(handler); } } } public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action == null) { return; } if (Intent.ACTION_BOOT_COMPLETED
public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action == null) { return; } if (action.equals(Intent.ACTION_BOOT_COMPLETED)) { PackageManager pm = context.getPackageManager(); if (!pm.hasSystemFeature(PackageManager.FEATURE_NFC_ANY)) { pm.setApplicationEnabledSetting(context.getPackageName(), PackageManager.COMPONENT_ENABLED_STATE_DISABLED, 0); } } }
private NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) { adjust.rxBytes += entry.rxBytes; adjust.rxPackets += entry.rxPackets; adjust.txBytes += entry.txBytes; adjust.txPackets += entry.txPackets; } } adjust.rxBytes = -adjust.rxBytes; adjust.rxPackets = -adjust.rxPackets; adjust.txBytes = -adjust.txBytes; adjust.txPackets = -adjust.txPackets; stats.combineValues(adjust);
*/ public static native String getOsVersion(); /** * @return hardware id extracted from uname() native call */ public static native String getHardwareId(); /** * @return kernel version extracted from uname() native call */ public static native String getKernelVersion(); /** * @return sysprop ro.boot.avb_version */ public static native String getBootAvbVersion(); /** * @return sysprop ro.boot.vbmeta.avb_version */ public static native String getBootVbmetaAvbVersion();
private void setLightLocked(int color, int mode, int onMS, int offMS, int brightnessMode) { if (shouldBeInLowPersistenceMode()) { brightnessMode = BRIGHTNESS_MODE_LOW_PERSISTENCE; } else if (brightnessMode == BRIGHTNESS_MODE_LOW_PERSISTENCE) { brightnessMode = mLastBrightnessMode; } if (!mInitialized || color != mColor || mode != mMode || onMS != mOnMS || offMS != mOffMS || mBrightnessMode != brightnessMode) { if (DEBUG) Slog.v(TAG, "setLight #" + mId + ": color=#" + Integer.toHexString(color) + ": brightnessMode=" + brightnessMode); mInitialized = true; mLastColor = mColor; mColor = color; mMode = mode; mOnMS = onMS; mOffMS = offMS; mBrightnessMode = brightnessMode; Trace.traceBegin(Trace.TRACE_TAG_POWER, "setLight(" + mId + ", 0x" + Integer.toHexString(color) + ")"); try { // Code to set the light } finally { Trace.traceEnd(Trace.TRACE_TAG_POWER); } } }
private int putListener(Object listener, NsdServiceInfo s) { checkListener(listener); final int key; synchronized (mMapLock) { int valueIndex = mListenerMap.indexOfValue(listener); checkArgument(valueIndex == -1, "listener already in use"); key = Math.abs(mListenerKey++); mListenerMap.put(key, listener); mServiceMap.put(key, s); } return key; }
public int initialize(IMbmsStreamingManagerCallback listener, String appName, int subId) { String appKey = appName + subId; if (!mAppCallbacks.containsKey(appKey)) { mAppCallbacks.put(appKey, listener); } else { return MbmsInitializationException.ERROR_ALREADY_INITIALIZED; } return 0; }
@Override public boolean isTrue() throws UiObjectNotFoundException { return device.findObject(new UiSelector().resourceId(Res.GOOGLE_PLAY_INPUT_RES)).exists(); } }); if (inputTextFieldExists) { UiObject inputTextField = device.findObject(new UiSelector().resourceId(Res.GOOGLE_PLAY_INPUT_RES)); inputTextField.clearTextField(); inputTextField.setText(application); device.pressEnter(); } } /** * Selects an application listed in the Play Store. */ public static void selectFromGooglePlay(Instrumentation instrumentation, String appDescription) throws Exception { final UiDevice device = UiDevice.getInstance(instrumentation); final String playStore = "Play Store"; final String application = appDescription; boolean isListed = new Wait().until(new Wait.ExpectedCondition() { @Override public boolean isTrue() throws UiObjectNotFoundException { return device.findObject(new UiSelector().description(application)).exists(); } }); if (isListed) { device.findObject(new UiSelector().description(application)).clickAndWaitForNewWindow(); } }
public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests"; @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { int thisApiVersion = android.os.Build.VERSION.SDK_INT; if (thisApiVersion < 21) { Log.w(TAG, "API version is less than 21, no tests running"); } Context ctx = InstrumentationRegistry.getTargetContext(); List<UnitTest> validUnitTests = new ArrayList<>(); for (Class<? extends UnitTest> testClass : RSTests.getTestClassesForCurrentAPIVersion()) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); validUnitTests.add(test); } checkDuplicateNames(validUnitTests); return validUnitTests; } private static void checkDuplicateNames(List<UnitTest> tests) { // Throws RuntimeException if any tests have the same name } }
@RunWith(Parameterized.class) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests"; @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); Iterable<Class<? extends UnitTest>> unitTestClasses = RSUtils.getProperSubclasses(UnitTest.class); List<UnitTest> ret = new ArrayList<>(); for (Class<? extends UnitTest> testClass : unitTestClasses) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); ret.add(test); } return ret; } @Parameter(0) public UnitTest mTest; @Test @MediumTest public void testRSUnitTest() throws Exception { String thisDeviceName = android.os.Build.DEVICE; int thisApiVersion = android.os.Build.VERSION.SDK_INT; // Rest of the test code } }
public GoogleLoginActionButton(AnAction action, Presentation presentation, String place, @NotNull Dimension minimumSize) { super(action, presentation, place, minimumSize); boolean showLoginButton = Boolean.parseBoolean(System.getProperty(SHOW_LOGIN_BUTTON_PROPERTY)); if (!showLoginButton) { setVisible(false); return; } GoogleLogin.getInstance().setLoginMenuItemContribution(this); defaultIcon = IconLoader.getIcon(DEFAULT_AVATAR); updateUi(); } ... : in.range != null ? in.range.endLine : 0; comment = new PatchLineComment( new PatchLineComment.Key( new Patch.Key(ps.getId(), in.path), ChangeUtil.messageUUID(ctx.getDb()) ), line, ctx.getUser().getAccountId(), Url.decode(in.inReplyTo), ctx.getWhen() ); short side; if (in.side == Side.PARENT) { side = in.parent == null ? 0 : (short) -in.parent.shortValue(); } else { side = 1; } comment.setSide(side); comment.setMessage(in.message.trim()); comment.setRange(in.range); comment.setTag(in.tag); setCommentRevId(comment, patchListCache, ctx.getChange(), ps); plcUtil.putComments(ctx.getDb(), ctx.getUpdate(psId), Collections.singleton(comment)); ctx.bumpLastUpdatedOn(false); return true; } } ... private static DbsMetadata getDbsMetadata(Frontend fe, String catalogName, PatternMatcher schemaPatternMatcher, PatternMatcher tablePatternMatcher, PatternMatcher columnPatternMatcher, PatternMatcher fnPatternMatcher, User user) throws ImpalaException { DbsMetadata result = new DbsMetadata(); if (!isEmptyPattern(catalogName)) { return result; } for (Db db: fe.getDbs(schemaPatternMatcher, user)) { if (fnPatternMatcher != PatternMatcher.MATCHER_MATCH_NONE) { List<Function> fns = db.getFunctions(null, fnPatternMatcher); result.functions.add(fns); } else { List<String> tableList = Lists.newArrayList(); List<List<Column>> tablesColumnsList = Lists.newArrayList(); List<String> tableComments = Lists.newArrayList(); List<String> tableTypes = Lists.newArrayList(); ... } } return result; } ... @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception {
Buggy Code: kage libcore.util; import junit.framework.TestCase; import java.io.ByteArrayInputStream; import java.io.IOException; import java.io.InputStream; import java.nio.charset.StandardCharsets; import java.util.Random; import libcore.util.Base64; import libcore.util.Base64InputStream; public class Base64InputStreamTest extends TestCase { static final String lipsum = "Lorem ipsum dolor sit amet, consectetur adipiscing elit. " + "Quisque congue eleifend odio, eu ornare nulla facilisis eget. " + "Integer eget elit diam, sit amet laoreet nibh. Quisque enim " + "urna, pharetra vitae consequat eget, adipiscing eu ante. " + "Aliquam venenatis arcu nec nibh imperdiet tempor. In id dui " + "eget lorem aliquam rutrum vel vitae eros. In placerat ornare " + "pretium. Curabitur non fringilla mi. Fusce ultricies, turpis " + "eu ultrices suscipit, ligula nisi consectetur eros, dapibus " + "aliquet dui sapien a turpis. Donec ultricies varius ligula, " + Fixed Code: kage libcore.util; import junit.framework.TestCase; import java.io.ByteArrayInputStream; import java.io.IOException; import java.io.InputStream; import java.nio.charset.StandardCharsets; import java.util.Random; import libcore.util.Base64; import libcore.util.Base64InputStream; public class Base64InputStreamTest extends TestCase { static final String lipsum = "Lorem ipsum dolor sit amet, consectetur adipiscing elit. " + "Quisque congue eleifend odio, eu ornare nulla facilisis eget. " + "Integer eget elit diam, sit amet laoreet nibh. Quisque enim " + "urna, pharetra vitae consequat eget, adipiscing eu ante. " + "Aliquam venenatis arcu nec nibh imperdiet tempor. In id dui " + "eget lorem aliquam rutrum vel vitae eros. In placerat ornare " + "pretium. Curabitur non fringilla mi. Fusce ultricies, turpis " + "eu ultrices suscipit, ligula nisi consectetur eros, dapibus " + "aliquet dui sapien a turpis. Donec ultricies varius ligula, " + Buggy Code: private static Image getImage(IMarker marker
public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. * * Filters out any tests with API version greater than current API version. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { int thisApiVersion = android.os.Build.VERSION.SDK_INT; if (thisApiVersion < 19) { Log.w(TAG, "API version is less than 19, no tests running"); } Context ctx = InstrumentationRegistry.getTargetContext(); ArrayList<UnitTest> validUnitTests = new ArrayList<>(); for (Class<? extends UnitTest> testClass : RSTests.getTestClassesForCurrentAPIVersion()) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); validUnitTests.add(test); } checkDuplicateNames(validUnitTests); return validUnitTests; } /** * Throws RuntimeException if any tests have the same name. */ private static void checkDuplicateNames(List<UnitTest> tests) { // Implementation omitted } }
Context ctx = InstrumentationRegistry.getTargetContext(); ArrayList<UnitTest> validUnitTests = new ArrayList<>(); for (Class<? extends UnitTest> testClass : RSTests.getTestClassesForCurrentAPIVersion()) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); validUnitTests.add(test); } checkDuplicateNames(validUnitTests); return validUnitTests; } private static void checkDuplicateNames(List<UnitTest> tests) { Set<String> names = new HashSet<>(); for (UnitTest test : tests) { String name = test.toString(); if (names.contains(name)) { throw new RuntimeException("duplicate name: " + name); } names.add(name); } } @Parameter(0) public UnitTest mTest; @Test @MediumTest public void testRSUnitTest() throws Exception { String thisDeviceName = android.os.Build.DEVICE; int thisApiVersion = android.os.Build.VERSION.SDK_INT;
import com.android.rs.unittest.*; import java.util.ArrayList; /** * This class is auto-generated by frameworks/rs/tests/java_api/RSUnitTests/RSUnitTests.py. * To change unit tests version, please run the Python script above. */ public class RSTests { public static Iterable<Class<? extends UnitTest>> getTestClassesForCurrentAPIVersion() { int thisApiVersion = android.os.Build.VERSION.SDK_INT; ArrayList<Class<? extends UnitTest>> validClasses = new ArrayList<>(); if (thisApiVersion >= 21) { validClasses.add(UT_alloc.class); validClasses.add(UT_array_alloc.class); validClasses.add(UT_array_init.class); validClasses.add(UT_atomic.class); validClasses.add(UT_bitfield.class); validClasses.add(UT_bug_char.class); validClasses.add(UT_check_dims.class); validClasses.add(UT_clamp.class); validClasses.add(UT_clamp_relaxed.class); validClasses.add(UT_constant.class); validClasses.add(UT_convert.class); validClasses.add(UT_convert_relaxed.class); validClasses.add(UT_copy_test.class); validClasses.add(UT_element.class); validClasses.add(UT_foreach.class); validClasses.add(UT_foreach_bounds.class); validClasses.add(UT_foreach_relaxed.class); validClasses.add(UT_foreach_simple.class); validClasses.add(UT_foreach_simple_relaxed.class); validClasses.add(UT_foreach_stride.class); validClasses.add(UT_foreach_stride_relaxed.class); validClasses.add(UT_foreach_types.class); validClasses.add(UT_fp16.class); validClasses.add(UT_fp16_relaxed.class); validClasses.add(UT_fp32.class); validClasses.add(UT_fp32_relaxed.class); validClasses.add(UT_fp64.class); validClasses.add(UT_fp64_relaxed.class); validClasses.add(UT_global.class); validClasses.add(UT_global_relaxed.class); validClasses.add(UT_global_types.class); validClasses.add(UT_half.class); validClasses.add(UT_half_relaxed.class); validClasses.add(UT_image.class); validClasses.add(UT_image_relaxed.class); validClasses.add(UT_image_types.class); validClasses.add(UT_init.class); valid
import android.content.Context; import android.support.test.InstrumentationRegistry; import android.support.test.filters.MediumTest; import android.util.Log; import org.junit.Assert; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameter; import org.junit.runners.Parameterized.Parameters; @RunWith(Parameterized.class) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests"; @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { return RSUtils.getProperSubclasses(UnitTest.class); } @Parameter(0) public Class<? extends UnitTest> mTestClass; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); // Test implementation } }
import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameter; import org.junit.runners.Parameterized.Parameters; @RunWith(Parameterized.class) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests"; @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { return RSUtils.getProperSubclasses(UnitTest.class); } @Parameter(0) public Class<? extends UnitTest> mTestClass; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); UnitTest test = mTestClass.getDeclaredConstructor(Context.class).newInstance(ctx); test.runTest(); switch (test.getResult()) { case UT_NOT_STARTED: case UT_RUNNING: // Handle test result break; case UT_SUCCESS: // Handle test success break; case UT_FAILURE: // Handle test failure break; } } }
return RSUtils.getProperSubclasses(UnitTest.class); @Parameter(0) public Class<? extends UnitTest> mTestClass; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); UnitTest test = mTestClass.getDeclaredConstructor(Context.class).newInstance(ctx); test.runTest(); switch (test.getResult()) { case UT_NOT_STARTED: case UT_RUNNING: Log.w(TAG, "unexpected unit test result: " + test.getResult().toString()); break; } Assert.assertTrue(test.getSuccess()); }
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.rs.testforward; import com.android.rs.unittest.UnitTest; import android.content.Context; import android.support.test.InstrumentationRegistry; import dalvik.system.DexFile; import java.io.IOException; import java.util.ArrayList; import java.util.Enumeration; public class RSUtils { /** Returns a list of all proper subclasses of the input class */ public static ArrayList<Class<?>> getSubClasses(Class<?> parent) { ArrayList<Class<?>> classes = new ArrayList<Class<?>>(); Context context = InstrumentationRegistry.getContext(); String packageName = context.getPackageName(); try { DexFile dexFile = new DexFile(context.getPackageCodePath()); Enumeration<String> entries = dexFile.entries(); while (entries.hasMoreElements()) { String className = entries.nextElement(); try { Class<?> clazz = Class.forName(className); if (parent.isAssignableFrom(clazz)) { classes.add(clazz); } } catch (ClassNotFoundException e) { // Ignore } } } catch (IOException e) { // Ignore } return classes; } }
MetricsLogger.histogram(context, "ota_stashed_in_MiBs", bytesStashedInMiB); if (temperatureStart != -1) { MetricsLogger.histogram(context, "ota_temperature_start", temperatureStart); } if (temperatureEnd != -1) { MetricsLogger.histogram(context, "ota_temperature_end", temperatureEnd); } if (temperatureMax != -1) { MetricsLogger.histogram(context, "ota_temperature_max", temperatureMax); } if (errorCode != -1) { MetricsLogger.histogram(context, "ota_blockbased_error_code", timeTotal); } if (causeCode != -1) { MetricsLogger.histogram(context, "ota_blockbased_cause_code", timeTotal); } catch (IOException e) { Log.e(TAG, "Failed to read lines in last_install", e); }
} else if (line.startsWith("source_build")) { sourceVersion = scaled; } else if (line.startsWith("bytes_written")) { bytesWrittenInMiB = (bytesWrittenInMiB == -1) ? scaled : bytesWrittenInMiB + scaled; } else if (line.startsWith("bytes_stashed")) { bytesStashedInMiB = (bytesStashedInMiB == -1) ? scaled : bytesStashedInMiB + scaled; } else if (line.startsWith("temperatureStart")) { temperatureStart = scaled; } else if (line.startsWith("temperatureEnd")) { temperatureEnd = scaled; } else if (line.startsWith("temperatureMax")) { temperatureMax = scaled; } else if (line.startsWith("error")) { errorCode = scaled; } else if (line.startsWith("cause")) { causeCode = scaled; } // Don't report data to tron if corresponding entry isn't found in last_install. if (timeTotal != -1) {
void sendTrackChangeWithId(int trackChangedNT, MediaController mediaController) { if (DEBUG) Log.d(TAG, "sendTrackChangeWithId"); byte[] track; try { if (mediaController == null) { mMediaInterface.trackChangedRsp(trackChangedNT, AvrcpConstants.NO_TRACK_SELECTED); return; } String mediaId = mediaController.getMetadata().getDescription().getMediaId(); long qid = MediaSession.QueueItem.UNKNOWN_ID; List<MediaSession.QueueItem> items = mNowPlayingList; /* traverse now playing list for current playing item */ for (QueueItem item : items) { if (item.getDescription().getMediaId().equals(mediaId)) { qid = item.getQueueId(); if (DEBUG) Log.d(TAG, "sendTrackChangeWithId: Found matching qid= " + qid); break; } } /* for any item associated with NowPlaying, uid is queueId */ track = ByteBuffer.allocate(AvrcpConstants.UID_SIZE).putLong(qid).array(); } catch (NullPointerException e) { Log.w(TAG, "NullPointerException getting uid, sending no track selected"); } }
} else if (!isPlayerAlreadyAddressed(selectedId)) { // register new Media Controller Callback and update the current IDs if (!updateCurrentController(selectedId, mCurrBrowsePlayerID)) { status = AvrcpConstants.RSP_INTERNAL_ERR; Log.e(TAG, "register for new Address player failed: " + mCurrAddrPlayerID); } } else { MediaPlayerInfo info = getAddressedPlayerInfo(); Log.i(TAG, "addressed player " + info + " is already focused"); } if (DEBUG) { Log.d(TAG, "setAddressedPlayer for selectedId: " + selectedId + " , status: " + status); } // Sending address player response to remote setAddressedPlayerRspNative(bdaddr, status);
mUnbinding = false; mEnable = false; mState = BluetoothAdapter.STATE_OFF; mQuietEnableExternal = false; mEnableExternal = false; mAddress = null; mName = null; mErrorRecoveryRetryCounter = 0; mContentResolver = context.getContentResolver(); // Observe BLE scan only mode settings change. registerForBleScanModeChange(); mCallbacks = new RemoteCallbackList<IBluetoothManagerCallback>(); mStateChangeCallbacks = new RemoteCallbackList<IBluetoothStateChangeCallback>(); IntentFilter filter = new IntentFilter(BluetoothAdapter.ACTION_LOCAL_NAME_CHANGED); filter.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter); IntentFilter filter2 = new IntentFilter(BluetoothAdapter.ACTION_BD_ADDR_CHANGED); filter2.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter2); loadStoredNameAndAddress(); if (isBluetoothPersistedStateOn()) { if (DBG) Slog.d(TAG, "Startup: Bluetooth persisted state is ON."); mEnableExternal = true; } String airplaneModeRadios = Settings.Global.getString(mContentResolver, Settings.Global.AIRPLANE_MODE_RADIOS); if (airplaneModeRadios == null || airplaneModeRadios.contains(Settings.Global.RADIO_BLUETOOTH)) { handleAirplaneModeChange(); }
protected int adjustDexoptNeeded(int dexoptNeeded) { if (dexoptNeeded == DexFile.NO_DEXOPT_NEEDED) { return -DexFile.DEX2OAT_FOR_FILTER; } return dexoptNeeded; }
private static final int CRASH_LOG_MAX_SIZE = 100; private static final String REASON_AIRPLANE_MODE = "airplane mode"; private static final String REASON_RESTARTED = "automatic restart"; private static final String REASON_START_CRASH = "turn-on crash"; private static final String REASON_SYSTEM_BOOT = "system boot"; private static final String REASON_UNEXPECTED = "unexpected crash"; private static final String REASON_USER_SWITCH = "user switch"; private static final String REASON_SYSTEM_RESTORE = "restored user setting"; private static final int TIMEOUT_BIND_MS = 3000; private static final int SERVICE_RESTART_TIME_MS = 200; private static final int ERROR_RESTART_TIME_MS = 3000; private static final int USER_SWITCHED_TIME_MS = 200; private static final int ADD_PROXY_DELAY_MS = 100;
/// CHECK-DAG: <<Add:d\d+>> VecAdd [<<Load>>,<<Repl>>] /// CHECK-NOT: IntermediateAddress /// CHECK-DAG: VecStore [<<Array>>,<<Address1>>,<<Add>>] /// CHECK-START-ARM64: void Main.checkIntCase(int[]) disassembly (after) /// CHECK: IntermediateAddressIndex /// CHECK-NEXT: add w{{[0-9]+}}, w{{[0-9]+}}, w{{[0-9]+}}, lsl #2 public static void checkIntCase(int[] a) { for (int i = 0; i < 128; i++) { a[i] += 5; } } /// CHECK-START-ARM64: void Main.checkByteCase(byte[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: <<Array:l\d+>> ParameterValue /// CHECK-DAG: <<Const5:i\d+>> IntConstant 5 /// CHECK-DAG: <<Repl:d\d+>> VecReplicateScalar [<<Const5>>] // -------------- Loop /// CHECK-DAG: <<Index:i\d+>> Phi
/// CHECK-DAG: <<Add:d\d+>> VecAdd [<<Load>>,<<Repl>>] /// CHECK-NOT: IntermediateAddress /// CHECK-DAG: VecStore [<<Array>>,<<Address1>>,<<Add>>] /// CHECK-START-ARM64: void Main.checkByteCase(byte[]) disassembly (after) /// CHECK: IntermediateAddressIndex /// CHECK-NEXT: add w{{[0-9]+}}, w{{[0-9]+}}, #0x{{[0-9a-fA-F]+}} /// CHECK: VecLoad /// CHECK-NEXT: ldr q{{[0-9]+}}, [x{{[0-9]+}}, x{{[0-9]+}}] /// CHECK: VecStore /// CHECK-NEXT: str q{{[0-9]+}}, [x{{[0-9]+}}, x{{[0-9]+}}] public static void checkByteCase(byte[] a) { for (int i = 0; i < 128; i++) { a[i] += 5; } }
/// CHECK: <<Add:d\d+>> VecAdd [<<Load>>,<<Repl>>] /// CHECK-NOT: IntermediateAddress /// CHECK: VecStore [<<Array>>,<<Address1>>,<<Add>>] /// CHECK-START-ARM64: void Main.checkIntCase(int[]) disassembly (after) /// CHECK: IntermediateAddressIndex /// CHECK-NEXT: add w{{[0-9]+}}, w{{[0-9]+}}, w{{[0-9]+}}, lsl #{{[0-9]}} public static void checkIntCase(int[] a) { for (int i = 0; i < 128; i++) { a[i] += 5; } } /// CHECK-START-ARM64: void Main.checkByteCase(byte[]) instruction_simplifier_arm64 (before) /// CHECK: <<Array:l\d+>> ParameterValue /// CHECK: <<Const5:i\d+>> IntConstant 5 /// CHECK: <<Repl:d\d+>> VecReplicateScalar [<<Const5>>] // -------------- Loop /// CHECK: <<Index:i\d+>> Phi /// CHECK: If
public static void checkInt2Float(int[] a, float[] b) { for (int i = 0; i < 128; i++) { b[i] = (float)a[i]; } }
public static void checkInt2Float(int[] a, float[] b) { for (int i = 0; i < 128; i++) { b[i] = (float) a[i]; } }
public static int calcArraySum(int[] a, byte[] b, float[] c) { int sum = 0; for (int i = 0; i < 128; i++) { sum += a[i] + b[i] + (int)c[i]; } return sum; }
package java.awt.font; import java.io.InvalidObjectException; import java.text.AttributedCharacterIterator.Attribute; import java.util.Map; import java.util.HashMap; public class TextAttribute { // Android-removed: List of classes for use with attribute keys; "Summary of attributes" section. public static final Attribute FAMILY = new Attribute("family"); public static final Attribute WEIGHT = new Attribute("weight"); public static final Attribute WIDTH = new Attribute("width"); public static final Attribute POSTURE = new Attribute("posture"); public static final Attribute SIZE = new Attribute("size"); public static final Attribute TRANSFORM = new Attribute("transform"); public static final Attribute SUPERSCRIPT = new Attribute("superscript"); public static final Attribute FONT = new Attribute("font"); public static final Attribute CHAR_REPLACEMENT = new Attribute("char_replacement"); public static final Attribute FOREGROUND = new Attribute("foreground"); public static final Attribute BACKGROUND = new Attribute("background"); public static final Attribute UNDERLINE = new Attribute("underline"); public static final Attribute STRIKETHROUGH = new Attribute("strikethrough"); public static final Attribute RUN_DIRECTION = new Attribute("run_direction"); public static final Attribute BIDI_EMBEDDING = new Attribute("bidi_embedding"); public static final Attribute JUSTIFICATION = new Attribute("justification"); public static final Attribute INPUT_METHOD_HIGHLIGHT = new Attribute("input_method_highlight"); public static final Attribute INPUT_METHOD_UNDERLINE = new Attribute("input_method_underline"); public static final Attribute SWAP_COLORS = new Attribute("swap_colors"); public static final Attribute NUMERIC_SHAPING = new Attribute("numeric_shaping"); public static final Attribute KERNING = new Attribute("kerning"); public static final Attribute LIGATURES = new Attribute("ligatures"); public static final Attribute TRACKING = new Attribute("tracking"); public static final Attribute BASELINE_TRANSFORM = new Attribute("baseline_transform"); public static final Attribute BASELINE_OFFSET = new Attribute("baseline_offset"); public static final Attribute STRIKETHROUGH_POSITION = new Attribute("strikethrough_position"); public static final Attribute STRIKETHROUGH_THICKNESS = new Attribute("strikethrough_thickness"); public static final Attribute UNDERLINE_POSITION = new Attribute("underline_position"); public static final Attribute UNDERLINE_THICKNESS = new Attribute("underline_thickness"); public
private static void updateChildrenFonts(CTabFolder folder, Font font) { for (CTabItem item : folder.getItems()) { Font itemFont = item.getFont(); if (itemFont != null && !itemFont.equals(font)) { item.setFont(font); } } } private static Label createErrorLabel(Composite parent) { final Label label = new Label(parent, SWT.WRAP); Color color = new Color(parent.getDisplay(), 0xe7, 0x4c, 0x3c); label.setForeground(color); final FontDescriptor fd = FontDescriptor.createFrom(parent.getFont()); fd.setHeight(9); Font font = fd.createFont(parent.getDisplay()); label.setFont(font); label.addDisposeListener(e -> { color.dispose(); fd.destroyFont(font); }); return label; } myPropertiesTable.getDefaultRenderer(String.class))); myPropertiesTable.setDefaultRenderer(Integer.class, new DelegatingCellRenderer(myModule, myConfiguration, myPropertiesTable.getDefaultRenderer(Integer.class))); myPropertiesTable.setDefaultRenderer(Boolean.class, new DelegatingCellRenderer(myModule, myConfiguration, myPropertiesTable.getDefaultRenderer(Boolean.class))); myPropertiesTable.setDefaultRenderer(StyleWrapper.class, new DelegatingCellRenderer(myModule, myConfiguration, false, styleEditor)); myPropertiesTable.setDefaultRenderer(TableLabel.class, new DefaultTableCellRenderer() { @Override public Component getTableCellRendererComponent(JTable table, Object value, boolean isSelected, boolean hasFocus, int row, int column) { super.getTableCellRendererComponent(table, value, isSelected, hasFocus, row, column); this.setFont(labelFont); return this; } }); final ColorRendererEditor editor = new ColorRendererEditor(myModule, myConfiguration, myPropertiesTable); myPropertiesTable.setDefaultEditor(Color.class, editor);
public static final TextAttribute SIZE = new TextAttribute("size"); public static final TextAttribute TRANSFORM = new TextAttribute("transform", TransformAttribute.IDENTITY); /** * Attribute key for the transform of a font. Values are * instances of <b><code>TransformAttribute</code></b>. The * default value is <code>TransformAttribute.IDENTITY</code>. * * <p>The primary intent is to support scaling and skewing, though * other effects are possible.</p> * * <p>Some transforms will cause the baseline to be rotated and/or * shifted. The text and the baseline are transformed together so * that the text follows the new baseline. For example, with text * that is not present on Android.</p> */
public static final TextAttribute SUPERSCRIPT = new TextAttribute("superscript"); public static final Integer SUPERSCRIPT_SUPER = Integer.valueOf(1); public static final Integer SUPERSCRIPT_SUB = Integer.valueOf(-1); public static final String FONT = "font"; public static final String FAMILY = "family"; public static final String WEIGHT = "weight"; public static final String WIDTH = "width"; public static final String POSTURE = "posture"; public static final String SIZE = "size"; public static final String TRANSFORM = "transform"; public static final String SUPERSCRIPT = "superscript"; public static final String FONT_RENDER_CONTEXT = "font_render_context"; public static final String CHAR_REPLACEMENT = "char_replacement"; public static final String FOREGROUND = "foreground"; public static final String BACKGROUND = "background"; public static final String UNDERLINE = "underline"; public static final String STRIKETHROUGH = "strikethrough"; public static final String RUN_DIRECTION = "run_direction"; public static final String BIDI_EMBEDDING = "bidi_embedding"; public static final String JUSTIFICATION = "justification"; public static final String INPUT_METHOD_HIGHLIGHT = "input_method_highlight"; public static final String INPUT_METHOD_UNDERLINE = "input_method_underline"; public static final String SWAP_COLORS = "swap_colors"; public static final String NUMERIC_SHAPING = "numeric_shaping"; public static final String KERNING = "kerning"; public static final String LIGATURES = "ligatures"; public static final String TRACKING = "tracking"; public static final String BASELINE_TRANSFORM = "baseline_transform"; public static final String CUSTOM = "custom";
Fixed Code: ```java public static final Float JUSTIFICATION_FULL = Float.valueOf(1.0f); public static final Float JUSTIFICATION_NONE = Float.valueOf(0.0f); public static final TextAttribute INPUT_METHOD_HIGHLIGHT = new TextAttribute("input method highlight"); ```
mHandler.removeMessages(MESSAGE_RESTART_BLUETOOTH_SERVICE); if (mEnable && mBluetooth != null) { waitForOnOff(true, false); mEnable = false; handleDisable(); waitForOnOff(false, false); } else { mEnable = false; handleDisable(); } break; case MESSAGE_RESTORE_ON_SETTING: try { if ((msg.arg1 == RESTORE_SETTING_TO_OFF) && mEnable) { if (DBG) Slog.d(TAG, "Restore to disable Bluetooth"); disable(REASON_RESTORE_USER_SETTING, true); } else if ((msg.arg1 == RESTORE_SETTING_TO_ON) && !mEnable) { if (DBG) Slog.d(TAG, "Restore to enable Bluetooth"); enable(REASON_RESTORE_USER_SETTING); } } catch (RemoteException e) { Slog.e(TAG,"Unable to change Bluetooth On setting",e); } break; case MESSAGE_REGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.unregister(callback); break; }
} else { mEnable = false; handleDisable(); } break; case MESSAGE_RESTORE_ON_SETTING: try { if ((msg.arg1 == RESTORE_SETTING_TO_OFF) && mEnable) { if (DBG) Slog.d(TAG, "Restore to disable Bluetooth"); disable(REASON_RESTORE_USER_SETTING, true); } else if ((msg.arg1 == RESTORE_SETTING_TO_ON) && !mEnable) { if (DBG) Slog.d(TAG, "Restore to enable Bluetooth"); enable(REASON_RESTORE_USER_SETTING); } } catch (RemoteException e) { Slog.e(TAG,"Unable to change Bluetooth On setting",e); } break; case MESSAGE_REGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.unregister(callback); break; } case MESSAGE_REGISTER_STATE_CHANGE_CALLBACK: { IBluetoothStateChangeCallback callback = (IBluetoothStateChangeCallback) msg.obj; mStateChangeCallbacks.register(callback); break; }
private static final int MESSAGE_BLUETOOTH_STATE_CHANGE = 60; private static final int MESSAGE_TIMEOUT_BIND = 100; private static final int MESSAGE_TIMEOUT_UNBIND = 101; private static final int MESSAGE_GET_NAME_AND_ADDRESS = 200; private static final int MESSAGE_USER_SWITCHED = 300; private static final int MESSAGE_USER_UNLOCKED = 301; private static final int MESSAGE_ADD_PROXY_DELAYED = 400; private static final int MESSAGE_BIND_PROFILE_SERVICE = 401; private static final int MESSAGE_RESTORE_ON_SETTING = 500; private static final int RESTORE_SETTING_TO_ON = 1; private static final int RESTORE_SETTING_TO_OFF = 0; private static final int MAX_SAVE_RETRIES = 3; private static final int MAX_ERROR_RESTART_RETRIES = 6; private static final int BLUETOOTH_OFF = 0; private static final int BLUETOOTH_ON_BLUETOOTH = 1; // Bluetooth persisted setting is off private static final int RESTORE_USER_SETTING = 500; // Bluetooth persisted setting is on // and Airplane mode won't affect Bluetooth state at start up private static final int BLUETOOTH_ON_AIRPLANE_MODE = 1;
Intent.EXTRA_SETTING_NEW_VALUE); if (DBG) Slog.d(TAG, "ACTION_SETTING_RESTORED with BLUETOOTH_ON, prevValue=" + prevValue + ", newValue=" + newValue); if ((newValue != null) && (prevValue != null) && !prevValue.equals(newValue)) { Message msg = mHandler.obtainMessage(MESSAGE_RESTORE_ON_SETTING, newValue.equals("0") ? RESTORE_SETTING_TO_OFF : RESTORE_SETTING_TO_ON, 0); mHandler.sendMessage(msg); }
if ((msg.arg1 == RESTORE_SETTING_TO_OFF) && mEnable) { if (DBG) Slog.d(TAG, "Restore Bluetooth state to disabled"); disable(REASON_RESTORE_USER_SETTING, true); } else if ((msg.arg1 == RESTORE_SETTING_TO_ON) && !mEnable) { if (DBG) Slog.d(TAG, "Restore Bluetooth state to enabled"); enable(REASON_RESTORE_USER_SETTING); } } catch (RemoteException e) { Slog.e(TAG, "Unable to change Bluetooth On setting", e); } break; case MESSAGE_REGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.unregister(callback); break; } case MESSAGE_REGISTER_STATE_CHANGE_CALLBACK: { IBluetoothStateChangeCallback callback = (IBluetoothStateChangeCallback) msg.obj; mStateChangeCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_STATE_CHANGE_CALLBACK: { IBluetoothStateChangeCallback callback = (IBluetoothStateChangeCallback) msg.obj; mStateChangeCallbacks.unregister(callback); break; }
private boolean rebindBottomOpRef(ILogicalOperator currentOp, Mutable<ILogicalOperator> opRef, Mutable<ILogicalOperator> replacementOpRef) { int index = 0; for (Mutable<ILogicalOperator> childRef : currentOp.getInputs()) { if (childRef == opRef) { currentOp.getInputs().set(index, replacementOpRef); return true; } else { if (rebindBottomOpRef(childRef.getValue(), opRef, replacementOpRef)) { return true; } } ++index; } return false; } public class ServiceInfo implements Parcelable { final static int MAP_LIMIT = 50; final Map<Locale, String> names; final String className; final Locale locale; final String serviceId; final Date sessionStartTime; final Date sessionEndTime; public ServiceInfo(Map<Locale, String> newNames, String newClassName, Locale newLocale, String newServiceId, Date start, Date end) { names = newNames; className = newClassName; locale = newLocale; serviceId = newServiceId; sessionStartTime = start; sessionEndTime = end; } }
private void selectItemByText(@NotNull final JList list, @NotNull final String text) { final Integer selectedIndex = GuiActionRunner.execute(new GuiQuery<Integer>() { @Override protected Integer executeInEDT() throws Throwable { ListPopupModel listPopupModel = (ListPopupModel) list.getModel(); for (int i = 0; i < listPopupModel.getSize(); ++i) { PopupFactoryImpl.ActionItem actionItem = (PopupFactoryImpl.ActionItem) listPopupModel.get(i); if (actionItem.getText().equals(text)) { return i; } } return -1; } }); assertTrue(selectedIndex >= 0); GuiActionRunner.execute(new GuiTask() { @Override protected void executeInEDT() throws Throwable { list.setSelectedIndex(selectedIndex); } }); assertTrue(((PopupFactoryImpl.ActionItem) list.getSelectedValue()).getText().equals(text)); } @Override public int initialize(IMbmsStreamingManagerCallback listener, String appName, int subscriptionId) throws RemoteException { return 0; }
@Override public int initialize(IMbmsStreamingManagerCallback listener, String appName, int subscriptionId) throws RemoteException { return 0; } @Override public void registerStreamingServices(String appName, int subscriptionId, List<ServiceClass> serviceClasses) throws RemoteException { // Register serviceClasses of interest with the appName/subId key // Starts async fetching data on streaming services of matching classes to be reported // later via IMbmsStreamingManagerCallback.streamingServicesUpdated(List) // Note that subsequent calls with the same appName and subId will replace // the service class list. }
@Override public int initialize(IMbmsStreamingManagerCallback listener, String appName, int subscriptionId) throws RemoteException { return 0; } /** * Registers serviceClasses of interest with the appName/subId key. * Starts async fetching data on streaming services of matching classes to be reported * later via {@link IMbmsStreamingManagerCallback#streamingServicesUpdated(List)} * Note that subsequent calls with the same appName and subId will replace * the service class list. * * @param appName The package name of the calling app. * @param subscriptionId The subscription id for eMBMS * @param serviceClasses The service classes that the app wishes to get info on. The strings * may contain arbitrary data as negotiated between the app and the * carrier. */ @Override public int getStreamingServices(String appName, int subscriptionId, List<String> serviceClasses) throws MbmsException { return 0; } @Override public StreamingService startStreaming(String appName, int subId, int uid) throws MbmsException { return null; }
security.checkWrite(name); } } */ if (name == null) { throw new NullPointerException("file == null"); } if (file.isInvalid()) { throw new FileNotFoundException("Invalid file path"); } this.path = name; this.mode = imode; fd = IoBridge.open(file.getPath(), imode); if (syncMetadata) { try { fd.sync(); } catch (IOException e) { // Ignored } } guard.open("close"); } /** * Returns the opaque file descriptor object associated with this * stream. * * @return the file descriptor object associated with this stream. * @exception IOException if an I/O error occurs. * @see java.io.FileDescriptor */
private static String getNativePath(String packageName) { String nativePath = getApplicationInfo(packageName).nativeLibraryDir; if (nativePath == null) { throw new IllegalStateException("No native path found for " + packageName); } if (apkPath == null) { throw new IllegalStateException("No APK path found for " + packageName); } return apkPath; } private static List<String> convert(Collection<StyleWrapper> themesRaw) { List<String> themes = new ArrayList<String>(themesRaw.size()); for (ThemeEditorStyle theme : themesRaw) { themes.add(theme.getName()); } Collections.sort(themes); return themes; } private boolean hasExt(PackExt ext) { return (extensions & ext.getBit()) != 0; } // Case statement removed for brevity case EVENT_IFACE_SERVING_STATE_INACTIVE: { TetherInterfaceStateMachine who = (TetherInterfaceStateMachine) message.obj; if (VDBG) { Log.d(TAG, "Tether Mode unrequested by " + who); } handleInterfaceServingStateInactive(who); if (mNotifyList.isEmpty()) { turnOffMasterTetherSettings(); } else { if (DBG) { Log.d(TAG, "TetherModeAlive still has " + mNotifyList.size() + " live requests:"); for (TetherInterfaceStateMachine o : mNotifyList) { // Code inside the for loop } } } }
// Buggy Code private static int getSum21() { int k = 0; int sum = 0; for (int i = 0; i < 6; i++) { k++; sum += k; } return sum; } // Review: Ensure double induction does not "overshoot". private static int getIncr2(int[] arr) { for (int i = 0; i < 12; ) { arr[i++] = 30; arr[i++] = 29; } int sum = 0; for (int i = 0; i < 12; i++) { sum += arr[i]; } return sum; } // TODO: handle as closed/empty eventually? static int mainIndexReturnedN(int n) { int i; for (i = 0; i < n; i++); return i; }
// To account correctly for on-the-wire traffic, add the 20 additional bytes difference // for all packets (http://b/12249687, http:/b/33681750). for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry); if (entry.iface == null || !entry.iface.startsWith(CLATD_INTERFACE_PREFIX)) { continue; } synchronized (sStackedIfaces) { if (!sStackedIfaces.containsKey(entry.iface)) { continue; } } entry.rxBytes = entry.rxPackets * IPV4V6_HEADER_DELTA; entry.txBytes = entry.txPackets * IPV4V6_HEADER_DELTA; entry.rxPackets = 0; entry.txPackets = 0; stats.combineValues(entry); } return stats; private NetworkStats readNetworkStatsDetailInternal(int limitUid, String[] limitIfaces, int limitTag, NetworkStats lastStats) throws IOException { if (USE_NATIVE_PARSING) { final NetworkStats stats; if (lastStats != null) { stats = lastStats; stats.setElapsedRealtime(SystemClock.elapsedRealtime()); } else { stats = new NetworkStats(SystemClock.elapsedRealtime(), 0); } synchronized (sStackedIfaces) { // Native parsing implementation } return stats; } else { // Java parsing implementation } }
// base interface. For correct stats accounting on the base interface, every 464xlat // packets needs to be subtracted for the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); if (stackedIface.startsWith(CLATD_INTERFACE_PREFIX)) { NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) { adjust.rxBytes -= (entry.rxBytes + entry.rxPackets * IPV4V6_HEADER_DELTA); adjust.txBytes -= (entry.txBytes + entry.txPackets * IPV4V6_HEADER_DELTA); adjust.rxPackets -= entry.rxPackets; adjust.txPackets -= entry.txPackets; } } } }
assertStatsEntry(stats, "lo", 0, SET_DEFAULT, 0x0, 1288L, 1288L); NetworkStatsFactory.noteStackedIface("v4-wlan0", null); } public void testDoubleClatAccounting100MBDownload() throws Exception { // Downloading 100mb from an ipv4 only destination in a foreground activity long appRxBytesBefore = 328684029L; long appRxBytesAfter = 439237478L; assertEquals("App traffic should be ~100MB", 110553449, appRxBytesAfter - appRxBytesBefore); long rootRxBytesBefore = 1394011L; long rootRxBytesAfter = 1398634L; assertEquals("Root traffic should be ~0", 4623, rootRxBytesAfter - rootRxBytesBefore); NetworkStatsFactory.noteStackedIface("v4-wlan0", "wlan0"); NetworkStats stats; // Stats snapshot before the download stats = parseDetailedStats(R.raw.xt_qtaguid_with_clat_100mb_download_before); assertStatsEntry(stats, "v4-wlan0", 10106, SET_FOREGROUND, 0x0, appRxBytesBefore, 5199872L); assertStatsEntry(stats, "wlan0", 0, SET_DEFAULT, 0x0, rootRxBytesBefore, 647888L); }
public void testDoubleClatAccounting100MBDownload() throws Exception { // Downloading 100mb from an ipv4 only destination in a foreground activity long appRxBytesBefore = 328684029L; long appRxBytesAfter = 439237478L; assertEquals("App traffic should be ~100MB", 110553449, appRxBytesAfter - appRxBytesBefore); long rootRxBytesBefore = 1394011L; long rootRxBytesAfter = 1398634L; assertEquals("Root traffic should be ~0", 4623, rootRxBytesAfter - rootRxBytesBefore); NetworkStatsFactory.noteStackedIface("v4-wlan0", "wlan0"); NetworkStats stats; // Stats snapshot before the download stats = parseDetailedStats(R.raw.xt_qtaguid_with_clat_100mb_download_before); assertStatsEntry(stats, "v4-wlan0", 10106, SET_FOREGROUND, 0x0, appRxBytesBefore, 5199872L); assertStatsEntry(stats, "wlan0", 0, SET_DEFAULT, 0x0, rootRxBytesBefore, 647888L); // Stats snapshot after the download stats = parseDetailedStats(R.raw.xt_qtaguid_with_clat_100mb_download_after); }
public void onConnected() { Log.d(TAG, "BrowsablePlayerListBuilder: " + mCurrentPlayer.packageName + " OK"); mCurrentBrowser.disconnect(); mCurrentBrowser = null; mBrowsePlayerInfoList.add(mCurrentPlayer); MediaPlayerInfo info = getMediaPlayerInfo(mCurrentPlayer.packageName); MediaController controller = (info == null) ? null : info.getMediaController(); // Refresh the media player entry so it notices we can browse if (controller != null) { addMediaPlayerController(controller.getWrappedInstance()); } else { addMediaPlayerPackage(mCurrentPlayer.packageName); } mPlayersChanged = true; connectNextPlayer(); }
} shr32(); for (int i = 0; i < 128; i++) { expectEquals(0x3fffffff, a[i], "shr32"); } shr33(); for (int i = 0; i < 128; i++) { expectEquals(0x1fffffff, a[i], "shr33"); } shrMinus255(); for (int i = 0; i < 128; i++) { expectEquals(0x07ffffff, a[i], "shrMinus255"); } // Bit-wise not operator. not(); for (int i = 0; i < 128; i++) { expectEquals(0xf8000000, a[i], "not"); } // Done. System.out.println("passed");
} shr64(); for (int i = 0; i < 128; i++) { expectEquals(0x3fffffffffffffffL, a[i], "shr64"); } shr65(); for (int i = 0; i < 128; i++) { expectEquals(0x1fffffffffffffffL, a[i], "shr65"); } shrMinus254(); for (int i = 0; i < 128; i++) { expectEquals(0x07ffffffffffffffL, a[i], "shr65"); } // Bit-wise not operator. not(); for (int i = 0; i < 128; i++) { expectEquals(0xf800000000000000L, a[i], "not"); } // Done. System.out.println("passed");
@SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION) public static final String ACTION_REPORT = "android.bluetooth.input.profile.action.REPORT"; @SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION) public static final String ACTION_VIRTUAL_UNPLUG_STATUS = "android.bluetooth.input.profile.action.VIRTUAL_UNPLUG_STATUS"; @SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION) public static final String ACTION_IDLE_TIME_CHANGED = "codeaurora.bluetooth.input.profile.action.IDLE_TIME_CHANGED"; public static final int INPUT_DISCONNECT_FAILED_NOT_CONNECTED = 5000; public static final int INPUT_CONNECT_FAILED_ALREADY_CONNECTED = 5001; public static final int INPUT_CONNECT_FAILED_ATTEMPT_FAILED = 5002; public static final int INPUT_OPERATION_GENERIC_FAILURE = 5003;
public static final String EXTRA_REPORT = "android.bluetooth.BluetoothInputDevice.extra.REPORT"; public static final String EXTRA_STATUS = "android.bluetooth.BluetoothInputDevice.extra.STATUS"; public static final String EXTRA_VIRTUAL_UNPLUG_STATUS = "android.bluetooth.BluetoothInputDevice.extra.VIRTUAL_UNPLUG_STATUS"; public static final String EXTRA_IDLE_TIME = "codeaurora.bluetooth.BluetoothInputDevice.extra.IDLE_TIME"; private Context mContext; private ServiceListener mServiceListener; private BluetoothAdapter mAdapter; private IBluetoothInputDevice mService; final private IBluetoothStateChangeCallback mBluetoothStateChangeCallback = new IBluetoothStateChangeCallback.Stub() { public void onBluetoothStateChange(boolean up) { if (DBG) Log.d(TAG, "onBluetoothStateChange: up=" + up); if (!up) { if (VDBG) Log.d(TAG,"Unbinding service..."); synchronized (mConnection) { try { mService = null; mContext.unbindService(mConnection); // ... } catch (Exception e) { Log.e(TAG, "Unable to unbind service", e); } } } } };
import android.os.RemoteException; import android.telephony.SignalStrength; public boolean getEmergencyCallbackMode(int subId) { try { ITelephony telephony = getITelephony(); if (telephony == null) { return false; } return telephony.getEmergencyCallbackMode(subId); } catch (RemoteException e) { Log.e(TAG, "Error calling ITelephony#getEmergencyCallbackMode", e); } return false; } @Nullable public SignalStrength getSignalStrength() { try { ITelephony service = getITelephony(); if (service != null) { return service.getSignalStrength(getSubId(), getOpPackageName()); } } catch (RemoteException e) { Log.e(TAG, "Error calling ITelephony#getSignalStrength", e); } return null; }
public void testSourceDebugExtension001() { doTest("testSourceDebugExtension001", "Lorg/apache/harmony/jpda/tests/jdwp/Events/SourceDebugExtensionMockClass;", JDWPConstants.Error.NONE); } public void testSourceDebugExtension002() { doTest("testSourceDebugExtension001", "I", JDWPConstants.Error.ABSENT_INFORMATION); } public void testSourceDebugExtension003() { doTest("testSourceDebugExtension003", "[I", JDWPConstants.Error.ABSENT_INFORMATION); } public void testSourceDebugExtension004() { doTest("testSourceDebugExtension004", "[Ljava/lang/String;", JDWPConstants.Error.ABSENT_INFORMATION); } public void testSourceDebugExtension005() { doTest("testSourceDebugExtension005", "[[Ljava/lang/String;", JDWPConstants.Error.ABSENT_INFORMATION); }
defaultHostnameVerifier = (HostnameVerifier) Class.forName("com.android.okhttp.internal.tls.OkHostnameVerifier") .getField("INSTANCE").get(null); originalDefaultHostnameVerifierClass = defaultHostnameVerifier.getClass(); } catch (Exception e) { throw new AssertionError("Failed to obtain okhttp HostnameVerifier", e); } } protected HostnameVerifier hostnameVerifier; public void setDefaultHostnameVerifier(HostnameVerifier v) { if (v == null) { throw new IllegalArgumentException("HostnameVerifier parameter is null"); } this.hostnameVerifier = v; } public HostnameVerifier getDefaultHostnameVerifier() { return this.hostnameVerifier; }
private boolean isNetworkConnected() { if (ni == null || !ni.isConnected()) { if (LOGD) Log.d(TAG, "forceRefresh: no connectivity"); return false; } return true; }
private void onPollNetworkTime(int event) { final NetworkInfo netInfo = mConnManager == null ? null : mConnManager.getActiveNetworkInfo(); if (!isAutomaticTimeRequested() || !netInfo.isConnected()) return; mWakeLock.acquire(); try { onPollNetworkTimeUnderWakeLock(event); } finally { mWakeLock.release(); } }
private void onPollNetworkTime(int event) { if (!isAutomaticTimeRequested()) { return; } if (mConnManager == null) { return; } final NetworkInfo netInfo = mConnManager.getActiveNetworkInfo(); if (netInfo == null || !netInfo.isConnected()) { return; } mWakeLock.acquire(); try { onPollNetworkTimeUnderWakeLock(event); } finally { mWakeLock.release(); } }
static void call(ChangeInfo changeInfo, RevisionInfo revisionInfo) { if (ChangeGlue.onSubmitChange(changeInfo, revisionInfo)) { final Change.Id changeId = changeInfo.legacy_id(); int j = revisionInfo.commit().other(); boolean flag = (j == 1) ? false : true; if (revisionInfo.commit().otherBranchCommit().equalsIgnoreCase("different branch commit")) { boolean reply = Window.confirm("You are about to merge change from a different branch.\n " + "Do you want to continue ?"); if (reply == true) { ChangeApi.submit(changeId.get(), revisionInfo.name(), new GerritCallback<SubmitInfo>() { public void onSuccess(SubmitInfo result) { redisplay(); } public void onFailure(Throwable err) { if (SubmitFailureDialog.isConflict(err)) { new SubmitFailureDialog(err.getMessage()).center(); } else { super.onFailure(err); } redisplay(); } private void redisplay() { Gerrit.display(PageLinks.toChange(changeId)); } }); } else { // Do something else } } } } public static void log(String message, IStatus status) { if (message != null) { getDefault().getLog().log(StatusUtil.newStatus(IStatus.ERROR, message, null)); } getDefault().getLog().log(status); } import org.eclipse.jgit.treewalk.EmptyTreeIterator; import org.eclipse.jgit.treewalk.TreeWalk; import org.eclipse.jgit.treewalk.filter.TreeFilter; public class StageBuilder { private static final int SMALL_BATCH_SIZE = 5; private static final byte[] PEEL = { ' ', '^' }; private final String txnStage; private final String txnId; public StageBuilder(String txnStageNamespace, ObjectId txnId) { // Constructor implementation } } package javax.security.auth; public final class AuthPermission extends java.security.BasicPermission { public AuthPermission(String name) { super(""); } public AuthPermission(String name, String actions) { super("", ""); } }
public NetworkTimeUpdateService(Context context) { mContext = context; mTime = NtpTrustedTime.getInstance(context); mAlarmManager = (AlarmManager) mContext.getSystemService(Context.ALARM_SERVICE); mConnManager = (ConnectivityManager) mContext.getSystemService(Context.CONNECTIVITY_SERVICE); Intent pollIntent = new Intent(ACTION_POLL, null); mPendingPollIntent = PendingIntent.getBroadcast(mContext, POLL_REQUEST, pollIntent, 0); mPollingIntervalMs = mContext.getResources().getInteger(com.android.internal.R.integer.config_ntpPollingInterval); mPollingIntervalShorterMs = mContext.getResources().getInteger(com.android.internal.R.integer.config_ntpPollingIntervalShorter); mTryAgainTimesMax = mContext.getResources().getInteger(com.android.internal.R.integer.config_ntpRetry); mTimeErrorThresholdMs = mContext.getResources().getInteger(com.android.internal.R.integer.config_ntpThreshold); mWakeLock = ((PowerManager) context.getSystemService(Context.POWER_SERVICE)).newWakeLock(PowerManager.PARTIAL_WAKE_LOCK, TAG); }
final public class CreateBranchCommand extends SshCommand { @Option(name = "--revision", aliases = {"-r"}, metaVar = "REVISION", usage = "base revision of the new branch") private String revision; @Argument(index = 0, required = true, metaVar = "PROJECT", usage = "name of the project") private ProjectControl project; @Argument(index = 1, required = true, metaVar = "NAME", usage = "name of branch to be created") private String name; @Inject GerritApi gApi; @Override protected void run() throws UnloggedFailure, Failure, Exception { BranchInput in = new BranchInput(); in.revision = revision; gApi.projects().name(project.getProject().getNameKey().get()).branch(name).create(in); } } InetAddress inetAddress; String hostName; hostName = "" + (0xff & hostAddress) + "." + (0xff & (hostAddress >> 8)) + "." + (0xff & (hostAddress >> 16)) + "." + (0xff & (hostAddress >> 24)); try { inetAddress = InetAddress.getByName(hostName); } catch (UnknownHostException e) { return null; } return inetAddress; } /** * Add a default route through the specified gateway. * @param interfaceName interface on which the route should be added * @param gw the IP address of the gateway to which the route is desired, * @param prefixLength specifies default or host route, value=32/128 for IPv4/IPv6 * host route respectively and value=0 for default IPv4/IPv6 route to a gateway. * @return {@code true} on success, {@code false} on failure */ public static boolean addRoute(String interfaceName, InetAddress gw, int prefixLength) { String dstStr; // Rest of the code } private class MyHandler extends Handler { public MyHandler(Looper l) { super(l); } @Override public void handleMessage(Message msg) { switch (msg.what) { case EVENT_AUTO_TIME_CHANGED: case EVENT_POLL_NETWORK_TIME: case EVENT_NETWORK_CHANGED: onPollNetworkTime(msg.what); break; } } } private class NetworkTimeCallback extends ConnectivityManager.NetworkCallback { @Override public
import android.bluetooth.BluetoothDevice; import android.os.Handler; import android.os.Looper; import android.os.Message; import android.net.ConnectivityManager; import android.net.Network; import android.net.NetworkCapabilities; import android.content.Context; import android.database.ContentObserver; import java.util.ArrayList; import java.util.List; import java.util.UUID; public class BluetoothGattService implements Parcelable { public static final int SERVICE_TYPE_PRIMARY = 0; public static final int SERVICE_TYPE_SECONDARY = 1; protected BluetoothDevice mDevice; protected UUID mUuid; protected int mInstanceId; protected int mServiceType; protected List<BluetoothGattCharacteristic> mCharacteristics; protected List<BluetoothGattService> mIncludedServices; public BluetoothGattService(UUID uuid, int instanceId, int serviceType) { mUuid = uuid; mInstanceId = instanceId; mServiceType = serviceType; mCharacteristics = new ArrayList<>(); mIncludedServices = new ArrayList<>(); } public BluetoothDevice getDevice() { return mDevice; } public UUID getUuid() { return mUuid; } public int getInstanceId() { return mInstanceId; } public int getServiceType() { return mServiceType; } public List<BluetoothGattCharacteristic> getCharacteristics() { return mCharacteristics; } public List<BluetoothGattService> getIncludedServices() { return mIncludedServices; } public void addCharacteristic(BluetoothGattCharacteristic characteristic) { mCharacteristics.add(characteristic); } public void addIncludedService(BluetoothGattService includedService) { mIncludedServices.add(includedService); } // Parcelable implementation // ... private class MyHandler extends Handler { public MyHandler(Looper l) { super(l); } @Override public void handleMessage(Message msg) { switch (msg.what) { case EVENT_AUTO_TIME_CHANGED: case EVENT_POLL_NETWORK_TIME: case EVENT_NETWORK_CHANGED: onPollNetworkTime(msg.what); break; } } } private class NetworkCallback extends ConnectivityManager.NetworkCallback { @Override public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { if (networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED)) { mNetworkValidated = true; } else { mNetwork
public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { mNetworkValidated = networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED); }
private void onPollNetworkTime(int event) { final NetworkInfo netInfo = mConnManager == null ? null : mConnManager.getActiveNetworkInfo(); if (!isAutomaticTimeRequested() || netInfo == null || !netInfo.isConnected()) { return; } mWakeLock.acquire(); try { onPollNetworkTimeUnderWakeLock(event); } finally { mWakeLock.release(); } }
return; case INS_GET_LOCK: resp = sendLockData(apdu, p1, p2); if (resp != 0) { sendResponseCode(apdu, resp); } return; case INS_SET_LOCK: if (p1 >= (byte)locks.length) { sendResponseCode(apdu, (short)0x0100); return; } if (metadataLength == (short) 0) { resp = locks[p1].set(p2); sendResponseCode(apdu, resp); } else { resp = locks[p1].setWithMetadata(p2, metadata, (short) 0, metadataLength); metadataLength = (short)0; sendResponseCode(apdu, resp); } return; case INS_SET_PRODUCTION: if (globalState.setProduction(enable) == true) { resp = 0x0000; } else { resp = 0x0001; } sendResponseCode(apdu, resp); return; /* carrierLockTest() { testVector } */
import android.widget.TextView; import java.io.IOException; import java.net.HttpURLConnection; import java.net.MalformedURLException; import java.net.URL; import java.lang.InterruptedException; import java.lang.reflect.Field; import java.lang.reflect.Method; import java.util.Random; public class CaptivePortalLoginActivity extends Activity { private static final String TAG = CaptivePortalLoginActivity.class.getSimpleName(); private static final boolean DBG = true; private static final boolean NO_AUTOCLOSE = false; private static final int SOCKET_TIMEOUT_MS = 10000; private enum Result { DISMISSED, UNWANTED, WANTED_AS_IS }; private URL mUrl; private String mUserAgent; private Network mNetwork; private CaptivePortal mCaptivePortal; private NetworkCallback mNetworkCallback; private ConnectivityManager mCm; private boolean mLaunchBrowser = false; private MyWebViewClient mWebViewClient; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); mCm = ConnectivityManager.from(this); } private void deactivate() { // Code to deactivate } }
private void testForCaptivePortal() { if (NO_AUTOCLOSE) { return; } new Thread(new Runnable() { public void run() { try { Thread.sleep(1000); } catch (InterruptedException e) { } HttpURLConnection urlConnection = null; int httpResponseCode = 500; try { urlConnection = (HttpURLConnection) mNetwork.openConnection(mUrl); urlConnection.setInstanceFollowRedirects(false); urlConnection.setConnectTimeout(SOCKET_TIMEOUT_MS); urlConnection.setReadTimeout(SOCKET_TIMEOUT_MS); urlConnection.setUseCaches(false); if (mUserAgent != null) { urlConnection.setRequestProperty("User-Agent", mUserAgent); } String requestHeader = urlConnection.getRequestProperties().toString(); urlConnection.getInputStream(); httpResponseCode = urlConnection.getResponseCode(); if (DBG) { Log.d(TAG, "probe at " + mUrl + " returns " + httpResponseCode); } } catch (IOException e) { if (DBG) { Log.d(TAG, "IOException - portal probably not detected"); } } finally { if (urlConnection != null) { urlConnection.disconnect(); } done(httpResponseCode); } } }).start(); }
public void systemRunning() { registerForTelephonyIntents(); registerForAlarms(); HandlerThread thread = new HandlerThread(TAG); thread.start(); mHandler = new MyHandler(thread.getLooper()); mNetworkTimeUpdateCallback = new NetworkTimeUpdateCallback(); mCM.registerDefaultNetworkCallback(mNetworkTimeUpdateCallback, mHandler); mSettingsObserver = new SettingsObserver(mHandler, EVENT_AUTO_TIME_CHANGED); mSettingsObserver.observe(mContext); }
public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { mNetworkValidated = networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED); }
import android.net.Network; public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { mNetworkValidated = networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED); }
import android.net.NetworkCapabilities; public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { mNetworkValidated = networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED); }
private static void doitMax(byte[] x, byte[] y, byte[] z) { int min = Math.min(x.length, Math.min(y.length, z.length)); for (int i = 0; i < min; i++) { x[i] = (byte) Math.max(y[i], z[i]); } } public static void main(String[] args) { int total = 256 * 256; byte[] x = new byte[total]; byte[] y = new byte[total]; byte[] z = new byte[total]; doitMax(x, y, z); }
package android.telephony; import android.content.ComponentName; import android.content.Context; import android.content.Intent; import android.content.ServiceConnection; import android.content.pm.PackageManager; import android.content.pm.ResolveInfo; import android.os.DeadObjectException; import android.os.IBinder; import android.os.RemoteException; import android.telephony.mbms.IMbmsStreamingManagerCallback; import android.telephony.mbms.IStreamingServiceCallback; import android.telephony.mbms.MbmsException; import android.telephony.mbms.StreamingService; import android.telephony.mbms.StreamingServiceInfo; import android.telephony.mbms.vendor.IMbmsStreamingService; import android.util.Log; import java.util.LinkedList; import java.util.List; import java.util.concurrent.CountDownLatch; import java.util.concurrent.TimeUnit; import static android.telephony.SubscriptionManager.INVALID_SUBSCRIPTION_ID; /** @hide */ public class MbmsStreamingManager { private interface ServiceListener { void onServiceConnected(); void onServiceDisconnected(); } private static final String LOG_TAG = "MbmsStreamingManager"; }
package android.os; public class Build { public static class VERSION { public static final int SDK_INT = 17; public static final String SDK = "17"; } }
package android.os; public class Build { public static class VERSION { public static final int SDK_INT = 17; public static final String SDK = "17"; } }
import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.Random; import java.util.concurrent.CountDownLatch; import java.util.concurrent.Semaphore; import java.util.concurrent.TimeUnit; import static java.nio.charset.StandardCharsets.UTF_8; public class FtpURLConnectionTest extends TestCase { private static final String FILE_PATH = "test/file/for/FtpURLConnectionTest.txt"; private static final String VALID_USER = "user"; private static final String VALID_PASSWORD = "password"; private static final String SERVER_HOSTNAME = "localhost"; private static final String USER_HOME_DIR = "/home/user"; private FakeFtpServer fakeFtpServer; private UnixFakeFileSystem fileSystem; @Override public void setUp() throws Exception { super.setUp(); fakeFtpServer = new FakeFtpServer(); fakeFtpServer.setServerControlPort(0 /* allocate port number automatically */); fakeFtpServer.addUserAccount(new UserAccount(VALID_USER, VALID_PASSWORD, USER_HOME_DIR)); fileSystem = new UnixFakeFileSystem(); fakeFtpServer.setFileSystem(fileSystem); } }
int total = interesting.length * interesting.length; short[] x = new short[total]; short[] y = new short[total]; short[] z = new short[total]; int k = 0; for (int i = 0; i < interesting.length; i++) { for (int j = 0; j < interesting.length; j++) { x[k] = 0; y[k] = interesting[i]; z[k] = interesting[j]; k++; } } // And test. doitMin(x, y, z); for (int i = 0; i < total; i++) { short expected = (short) Math.min(y[i], z[i]); expectEquals(expected, x[i]); } doitMax(x, y, z); for (int i = 0; i < total; i++) { short expected = (short) Math.max(y[i], z[i]); expectEquals(expected, x[i]); } System.out.println("passed");
private void recordAndEmit(Category category, String msg) { final String entry = logLine(category.toString(), msg); mLocalLog.log(entry); if (Category.ERROR.equals(category)) { Log.e(mTag, entry); } else { Log.d(mTag, entry); } }
import android.content.Context; import android.content.ContextWrapper; import android.content.res.Resources; import android.support.test.filters.SmallTest; import android.support.test.runner.AndroidJUnit4; import android.telephony.TelephonyManager; import com.android.internal.util.test.BroadcastInterceptingContext; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.MockitoAnnotations; @RunWith(AndroidJUnit4.class) @SmallTest public class TetheringConfigurationTest { private static final String[] PROVISIONING_APP_NAME = {"some", "app"}; @Mock private Context mContext; @Mock private TelephonyManager mTelephonyManager; @Mock private Resources mResources; private Context mMockContext; private boolean mWithTelephonyManager; private class MockContext extends BroadcastInterceptingContext { MockContext(Context base) { super(base); } @Override public Resources getResources() { return mResources; } @Override public Object getSystemService(String name) { if (Context.TELEPHONY_SERVICE.equals(name)) { return mWithTelephonyManager ? mTelephonyManager : null; } return super.getSystemService(name); } } }
import android.telephony.TelephonyManager; import com.android.internal.util.test.BroadcastInterceptingContext; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.MockitoAnnotations; @RunWith(AndroidJUnit4.class) @SmallTest public class TetheringConfigurationTest { private static final String[] PROVISIONING_APP_NAME = {"some", "app"}; @Mock private Context mContext; @Mock private TelephonyManager mTelephonyManager; @Mock private Resources mResources; private Context mMockContext; private boolean mWithTelephonyManager; private class MockContext extends BroadcastInterceptingContext { MockContext(Context base) { super(base); } @Override public Resources getResources() { return mResources; } @Override public Object getSystemService(String name) { if (Context.TELEPHONY_SERVICE.equals(name)) { return mWithTelephonyManager ? mTelephonyManager : null; } return super.getSystemService(name); } } @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); } }
/** * Returns the full file path of the optimized dex file {@code fileName}. * The returned string is the full file name including path of optimized dex file, if it exists. * @param fileName The name of the dex file * @param instructionSet The instruction set * @return The full file path of the optimized dex file * @throws FileNotFoundException If the file is not found * @hide */ public static native String getDexFileStatus(String fileName, String instructionSet) throws FileNotFoundException; /** * Returns the full file path of the optimized dex file {@code fileName}. * The returned string is the full file name including path of optimized dex file, if it exists. * @param fileName The name of the dex file * @param instructionSet The instruction set * @return The full file path of the optimized dex file * @throws FileNotFoundException If the file is not found * @hide */ public static native String[] getDexFileOutputPath(String fileName, String instructionSet) throws FileNotFoundException; /** * Returns whether the given filter is a valid filter. * @param filter The filter to check * @return True if the filter is valid, false otherwise * @hide */ public native static boolean isValidCompilerFilter(String filter); /** * Returns whether the given filter is based on profiles. * @param filter The filter to check * @return True if the filter is based on profiles, false otherwise * @hide */ public native static boolean isProfileGuidedCompilerFilter(String filter); /** * Returns the version of the compiler filter that is not based on profiles. * @return The version of the compiler filter * @hide */ public native static int getNonProfileGuidedCompilerFilterVersion();
/** * Returns the full file path of the optimized dex file {@code fileName}. * The returned string is the full file name including path of optimized dex file, if it exists. * * @param fileName The name of the dex file. * @param instructionSet The instruction set of the device. * @return The full file path of the optimized dex file. * @throws FileNotFoundException If the optimized dex file is not found. */ public static native String[] getDexFileOutputPaths(String fileName, String instructionSet) throws FileNotFoundException; /** * Returns whether the given filter is a valid filter. * * @param filter The filter to check. * @return True if the filter is valid, false otherwise. */ public native static boolean isValidCompilerFilter(String filter); /** * Returns whether the given filter is based on profiles. * * @param filter The filter to check. * @return True if the filter is based on profiles, false otherwise. */ public native static boolean isProfileGuidedCompilerFilter(String filter); /** * Returns the version of the compiler filter that is not based on profiles. * If the input is not a valid filter, or the filter is already not based on profiles, * the input filter is returned. * * @param filter The filter to convert. * @return The version of the compiler filter that is not based on profiles. */ public native static String getNonProfileGuidedCompilerFilter(String filter);
// determine the ABI from either ApplicationInfo or Build String arch = "arm"; if (cameraInfo.primaryCpuAbi != null && VMRuntime.is64BitAbi(cameraInfo.primaryCpuAbi)) { arch = arch + "64"; } else { if (VMRuntime.is64BitAbi(Build.SUPPORTED_ABIS[0])) { arch = arch + "64"; } } // get the path to the odex or oat file String baseCodePath = cameraInfo.getBaseCodePath(); String[] optimizedCode = null; try { optimizedCode = DexFile.getDexFileOutputPath(baseCodePath, arch); } catch (IOException ioe) {} if (optimizedCode == null) { return true; } // not pinning the oat/odex is not a fatal error for (int i = 0; i < optimizedCode.length; i++) { pf = pinFile(optimizedCode[i], 0, 0, MAX_CAMERA_PIN_SIZE); if (pf != null) { mPinnedCameraFiles.add(pf); if (DEBUG) { Slog.i(TAG, "Pinned " + pf.mFilename); } } }
String baseCodePath = cameraInfo.getBaseCodePath(); String[] optimizedCode = null; try { optimizedCode = DexFile.getDexFileOutputPath(baseCodePath, arch); } catch (IOException ioe) {} if (optimizedCode == null) { return true; } for (String file : optimizedCode) { pf = pinFile(file, 0, 0, MAX_CAMERA_PIN_SIZE); if (pf != null) { mPinnedCameraFiles.add(pf); if (DEBUG) { Slog.i(TAG, "Pinned " + pf.mFilename); } } } return true;
String baseCodePath = cameraInfo.getBaseCodePath(); String[] optimizedCode = null; try { optimizedCode = DexFile.getDexFileOutputPath(baseCodePath, arch); } catch (IOException ioe) {} if (optimizedCode == null) { return true; } for (int i = 0; i < optimizedCode.length; i++) { pf = pinFile(optimizedCode[i], 0, 0, MAX_CAMERA_PIN_SIZE); if (pf != null) { mPinnedCameraFiles.add(pf); if (DEBUG) { Slog.i(TAG, "Pinned " + pf.mFilename); } } } return true;
packageIntentFilter.addAction(Intent.ACTION_PACKAGE_REMOVED); packageIntentFilter.addAction(Intent.ACTION_PACKAGE_ADDED); packageIntentFilter.addDataScheme("package"); context.registerReceiverAsUser(mReceiver, UserHandle.ALL, packageIntentFilter, null, null); IntentFilter bootIntentFilter = new IntentFilter(Intent.ACTION_BOOT_COMPLETED); context.registerReceiverAsUser(mReceiver, UserHandle.ALL, bootIntentFilter, null, null); IntentFilter userRemovedFilter = new IntentFilter(Intent.ACTION_USER_REMOVED); context.registerReceiver(mReceiver, userRemovedFilter); Uri defaultDialerSetting = Settings.Secure.getUriFor(Settings.Secure.DIALER_DEFAULT_APPLICATION); context.getContentResolver().registerContentObserver(defaultDialerSetting, false, mDefaultDialerObserver, UserHandle.USER_ALL);
public IPv6TetheringCoordinator(ArrayList<TetherInterfaceStateMachine> notifyList, SharedLog log) { mLog = log.forSubComponent(TAG); mNotifyList = notifyList; mActiveDownstreams = new LinkedList<>(); mUniqueLocalPrefix = generateUniqueLocalPrefix(); mNextSubnetId = 0; }
public void e(String msg) { recordAndEmit(Category.ERROR, msg); }
} public void dump(FileDescriptor fd, PrintWriter writer, String[] args) { mLocalLog.readOnlyLocalLog().dump(fd, writer, args); } public void error(Exception e) { recordAndEmit(Category.ERROR, e.toString()); } public void error(String msg) { recordAndEmit(Category.ERROR, msg); } public void event(String msg) { recordAndEmit(Category.EVENT, msg); } public void log(String msg) { recordAndEmit(Category.NONE, msg); } public void logAndEmit(String msg) { recordAndEmit(Category.NONE, msg); } public void mark(String msg) { record(Category.MARK, msg); } private void record(Category category, String msg) { mLocalLog.log(logLine(category, msg)); } private void recordAndEmit(Category category, String msg) { final String entry = logLine(category, msg); mLocalLog.log(entry); if (Category.ERROR.equals(category)) { Log.e(mTag, entry); } else { Log.d(mTag, entry); } }
phoneAccountHandle = extras.getParcelable(TelecomManager.EXTRA_PHONE_ACCOUNT_HANDLE); boolean isSelfManaged = phoneAccountHandle != null && isSelfManagedConnectionService(phoneAccountHandle); if (isSelfManaged) { mContext.enforceCallingOrSelfPermission(Manifest.permission.MANAGE_OWN_CALLS, "Self-managed ConnectionServices require MANAGE_OWN_CALLS permission."); if (!callingPackage.equals(phoneAccountHandle.getComponentName().getPackageName()) && !canCallPhone(callingPackage, "CALL_PHONE permission required to place calls.")) { throw new SecurityException("Self-managed ConnectionServices can only place calls through their own ConnectionService."); } } else if (!canCallPhone(callingPackage, "placeCall")) { throw new SecurityException("Package " + callingPackage + " is not allowed to place phone calls"); }
private String logLine(Category category, String msg) { final StringJoiner sj = new StringJoiner(" "); if (!isRootLogInstance()) { sj.add("[" + mComponent + "]"); } if (category != Category.NONE) { sj.add(category.toString()); } return sj.add(msg).toString(); }
public GatewayClient(String target, ClientConfig conf, ObjectMapper mapper, ResourceLoader loader) { super(target, conf, mapper, loader); } public MLPPeer ping(String peerId) { return handleResponse(PEER_PFX + FederationClient.PING_URI, new ParameterizedTypeReference<JsonResponse<MLPPeer>>(){}, peerId); } public List<MLPPeer> getPeers(String peerId) { // implementation }
} /** * Ask the peer about its peers. * * @param peerId The ID of the peer Acumos. * @return The list of the peer's peers. */ public List<MLPPeer> getPeers(String peerId) { return handleResponse(PEER_PFX + FederationClient.PEERS_URI, new ParameterizedTypeReference<JsonResponse<List<MLPPeer>>>(){}, peerId); } /** * Register with the peer. * * @param peerId The ID of the peer Acumos. * @return Information about the peer. */ public MLPPeer register(String peerId) { return handleResponse(PEER_PFX + FederationClient.REGISTER_URI, HttpMethod.POST, new ParameterizedTypeReference<JsonResponse<MLPPeer>>(){}, peerId); } /** * Ask the peer for a list of catalogs. * * @param peerId The ID of the peer Acumos. * @return The list of catalogs (enhanced with their sizes), the peer is willing to share. */ public List<MLPCatalog> getCatalogs(String peerId) { return handleResponse(PEER_PFX + FederationClient.CATALOGS_URI, new ParameterizedTypeReference<JsonResponse<List<MLPCatalog>>>(){}, peerId); }
@SpringBootApplication @EnableAutoConfiguration(exclude = { DataSourceAutoConfiguration.class, DataSourceTransactionManagerAutoConfiguration.class, HibernateJpaAutoConfiguration.class }) @EnableConfigurationProperties @ComponentScan(basePackages = "org.acumos.federation", useDefaultFilters = false, includeFilters = @ComponentScan.Filter(type=FilterType.ASSIGNABLE_TYPE, classes={org.acumos.federation.gateway.config.GatewayConfiguration.class, org.acumos.federation.gateway.config.AdapterConfiguration.class})) public class Application { private final static EELFLoggerDelegate logger = EELFLoggerDelegate.getLogger(Application.class); public static void main(String[] args) throws Exception { SpringApplicationBuilder gatewayBuilder = new SpringApplicationBuilder(Application.class) .bannerMode(Banner.Mode.OFF) .web(false); gatewayBuilder.child(FederationConfiguration.class) .bannerMode(Banner.Mode.OFF) .web(true) .run(args); gatewayBuilder.child(LocalConfiguration.class); } }
public MLPSolution createSolution(MLPSolution solution) { Set<MLPTag> tags = solution.getTags(); solution.setTags(Collections.emptySet()); solution = clients.getCDSClient().createSolution(solution); doTags(tags, solution.getSolutionId()); return solution; }
import com.github.dockerjava.api.DockerClient; import com.github.dockerjava.core.DefaultDockerClientConfig; import com.github.dockerjava.core.DockerClientBuilder; import org.acumos.cds.client.ICommonDataServiceRestClient; import org.acumos.cds.client.CommonDataServiceRestClientImpl; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.ClientBase; import org.acumos.federation.client.FederationClient; public class Clients { @Autowired private FederationConfig federation; @Autowired private ServiceConfig cdmsConfig; @Autowired private NexusConfig nexusConfig; @Autowired private DockerConfig dockerConfig; private ICommonDataServiceRestClient cdsClient; private NexusClient nexusClient; private DockerClient dockerClient; public FederationClient getFederationClient(String url) { return new FederationClient(url, federation); } public synchronized ICommonDataServiceRestClient getCDSClient() { if (cdsClient == null) { String url = cdmsConfig.getUrl(); ClientConfig cc = new ClientConfig(); cc.setCreds(cdmsConfig); cdsClient = new CommonDataServiceRestClientImpl(url, cc); } return cdsClient; } public synchronized NexusClient getNexusClient() { if (nexusClient == null) { nexusClient = new NexusClient(nexusConfig); } return nexusClient; } public synchronized DockerClient getDockerClient() { if (dockerClient == null) { DefaultDockerClientConfig config = DefaultDockerClientConfig.createDefaultConfigBuilder() .withDockerHost(dockerConfig.getHost()) .withDockerTlsVerify(dockerConfig.isTlsVerify()) .withDockerCertPath(dockerConfig.getCertPath()) .withDockerConfig(dockerConfig.getDockerConfig()) .build(); dockerClient = DockerClientBuilder.getInstance(config).build(); } return dockerClient; } }
public InputStream getArtifactContent(MLPArtifact artifact); /** * Set the URI for an artifact. * * @param solutionId The ID of the solution. * @param artifact The artifact to set the URI on. */ public void setArtifactUri(String solutionId, MLPArtifact artifact); /** * Put the content of an artifact. * * @param artifact The artifact to put. * @param tag The image tag in the input data. * @param is The data to put. */ public void putArtifactContent(MLPArtifact artifact, String tag, InputStream is); /** * Get the body of a document. * * @param document The document to retrieve. * @return An InputStream for reading the document's content. */ public InputStream getDocumentContent(MLPDocument document); /** * Set the URI for a document. * * @param solutionId The ID of the solution. * @param document The document to set the URI on. */ public void setDocumentUri(String solutionId, MLPDocument document);
package com.googlesource.gerrit.plugins.xdocs.formatter; import com.googlesource.gerrit.plugins.xdocs.ConfigSection; import java.io.IOException; import java.io.InputStream; public interface StreamFormatter extends Formatter { /** * Formats the given raw text as html. * * @param projectName the name of the project that contains the file to be formatted * @param revision the abbreviated revision from which the file is loaded * @param cfg the global configuration for this formatter * @param raw the raw stream * @return the content from the given stream formatted as html * @throws IOException thrown if the formatting fails */ public String format(String projectName, String revision, ConfigSection cfg, InputStream raw) throws IOException; } import org.eclipse.tracecompass.internal.provisional.tmf.chart.core.descriptor.IDataChartDescriptor; public class DescriptorsInformation { private final boolean fAreDescriptorsNumerical; private final boolean fAreDescriptorsDuration; private final boolean fAreDescriptorsTimestamp; public DescriptorsInformation(Collection<IDataChartDescriptor<?, ?>> descriptors) { DescriptorTypeVisitor visitor = new DescriptorTypeVisitor(); descriptors.forEach(desc -> desc.accept(visitor)); if (visitor.isEmpty()) { throw new IllegalArgumentException("No descriptor were given."); } if (visitor.isMixed()) { // Handle mixed descriptors } else { // Handle non-mixed descriptors } } } import com.google.common.collect.ImmutableSet; import com.google.common.base.Splitter; import java.util.Locale; import java.util.stream.Stream; public class SomeClass { public void someMethod() { assertThat(Splitter.on(", ").splitToList(allowMethods)) .named(ACCESS_CONTROL_ALLOW_METHODS) .containsExactly("GET", "HEAD", "POST", "PUT", "DELETE", "OPTIONS"); assertThat(allowHeaders) .named(ACCESS_CONTROL_ALLOW_HEADERS) .isNotNull(); assertThat(Splitter.on(", ").splitToList(allowHeaders)) .named(ACCESS_CONTROL_ALLOW_HEADERS) .containsExactlyElementsIn( Stream.of(AUTHORIZATION, CONTENT_TYPE, "X-Gerrit-Auth", "X-Requested-With") .map(s -> s.toLowerCase(Locale.US)) .collect(ImmutableSet.toImmutableSet())); // Handle other assertions } } public interface DocumentService { public InputStream getDocumentContent(
public void setBuffer(char[] buffer){ this.buffer = buffer; tokenBegin = bufpos = 0; containsEscapes = false; tokenBegin = -1; } import org.acumos.cds.domain.MLPSolutionRevision; import org.acumos.cds.domain.MLPArtifact; import org.acumos.cds.domain.MLPDocument; import org.acumos.federation.client.ClientBase; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.data.Artifact; import org.acumos.federation.client.data.Document; import org.acumos.federation.client.data.JsonResponse; import org.acumos.federation.client.data.SolutionRevision; @Controller @CrossOrigin public class FederationController { private static final Logger log = LoggerFactory.getLogger(FederationController.class); @Autowired private FederationConfig federation; @Autowired private WebSecurityConfigurerAdapter security; @Autowired private PeerService peerService; @Autowired private CatalogService catalogService; @Autowired private ContentService contentService; private UriTemplateHandler originBuilder; private String makeOrigin(String uri, Object... params) { if (originBuilder == null) { // code to build origin } // code to return origin } }
import org.acumos.cds.domain.MLPDocument; import org.acumos.federation.client.ClientBase; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.data.Artifact; import org.acumos.federation.client.data.Document; import org.acumos.federation.client.data.JsonResponse; import org.acumos.federation.client.data.SolutionRevision; @Controller @CrossOrigin public class FederationController { private static final Logger log = LoggerFactory.getLogger(FederationController.class); @Autowired private FederationConfig federation; @Autowired private WebSecurityConfigurerAdapter security; @Autowired private PeerService peerService; @Autowired private CatalogService catalogService; @Autowired private ContentService contentService; private UriTemplateHandler originBuilder; private String makeOrigin(String uri, Object... params) { if (originBuilder == null) { originBuilder = ClientBase.buildRestTemplate("https://" + ((Security)security).getSelf().getSubjectName() + ":" + federation.getServer().getPort(), new ClientConfig(), null, null).getUriTemplateHandler(); } } }
public JsonResponse<Void> badRequestError(HttpServletRequest request, HttpServletResponse response, BadRequestException badRequest) { log.error("Request {} failed {} {} {}", request.getRequestURI(), badRequest.getMessage(), badRequest.getCode(), badRequest); JsonResponse<Void> ret = new JsonResponse<>(); ret.setError(badRequest.getMessage()); response.setStatus(badRequest.getCode()); return ret; }
import org.acumos.cds.domain.MLPCatalog; import org.acumos.cds.domain.MLPSolution; import org.acumos.cds.domain.MLPPeer; import org.acumos.cds.domain.MLPPeerSubscription; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.GatewayClient; import org.acumos.federation.client.data.JsonResponse; @Controller @CrossOrigin @Secured(Security.ROLE_INTERNAL) @RequestMapping(GatewayClient.PEER_PFX) public class GatewayController { private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private Clients clients; @Autowired private PeerService peerService; @Autowired private PeerGateway peerGateway; @ApiOperation(value = "Invoked by local Acumos to get a list of catalogs available from a peer Acumos instance .", response = MLPCatalog.class, responseContainer = "List") @RequestMapping(value = FederationClient.CATALOGS_URI, method = RequestMethod.GET, produces = MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseBody public JsonResponse<List<MLPCatalog>> getCatalogs(HttpServletResponse response, @PathVariable("peerId") String peerId) { // code implementation } }
import org.springframework.security.config.http.SessionCreationPolicy; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.userdetails.User; import org.acumos.cds.domain.MLPPeer; import org.acumos.federation.client.config.TlsConfig; import org.acumos.federation.client.FederationClient; @Configuration @EnableWebSecurity public class GatewaySecurity extends WebSecurityConfigurerAdapter { public static final String ROLE_REGISTER = "ROLE_REGISTRATION"; public static final String ROLE_UNREGISTER = "ROLE_UNREGISTRATION"; public static final String ROLE_PEER = "ROLE_PEER"; public static final String ROLE_TRUSTED_PEER = "ROLE_TRUSTED_PEER"; // Rest of the code... }
if (alias == null) { Enumeration<String> aliases = ks.aliases(); while (aliases.hasMoreElements()) { alias = aliases.nextElement(); if (ks.entryInstanceOf(alias, KeyStore.PrivateKeyEntry.class)) { break; } } } try { myself = peerService.getSelf(getLdapNameField(new LdapName(((X509Certificate)ks.getCertificate(alias)).getSubjectX500Principal().getName()), "CN")); } catch (Exception e) { myself = new MLPPeer(); myself.setStatusCode(PSC_UNKNOWN); }
public void applyTo(TaskAttribute taskAttribute) { Assert.isNotNull(taskAttribute); TaskData taskData = taskAttribute.getTaskData(); TaskAttributeMapper mapper = taskData.getAttributeMapper(); taskAttribute.getMetaData().defaults().setType(TaskAttribute.TYPE_ATTACHMENT); if (getAttachmentId() != null) { mapper.setValue(taskAttribute, getAttachmentId()); } if (getAuthor() != null && getAuthor().getPersonId() != null) { TaskAttribute child = taskAttribute.createMappedAttribute(TaskAttribute.ATTACHMENT_AUTHOR); TaskAttributeMetaData defaults = child.getMetaData().defaults(); defaults.setType(TaskAttribute.TYPE_PERSON); defaults.setLabel("Attachment Author:"); mapper.setRepositoryPerson(child, getAuthor()); } if (getContentType() != null) { TaskAttribute child = taskAttribute.createMappedAttribute(TaskAttribute.ATTACHMENT_CONTENT_TYPE); TaskAttributeMetaData defaults = child.getMetaData().defaults(); defaults.setType(TaskAttribute.TYPE_SHORT_TEXT); defaults.setLabel("Content Type:"); mapper.setValue(child, getContentType()); } if (getCreationDate() != null) { // Rest of the code } }
logger.debug("JWT_TOKEN_HEADER_KEY : " + authToken); if (authToken != null) { authToken = authToken.replace(TOKEN_PASS_KEY, ""); logger.debug("TOKEN_PASS_KEY : " + authToken); JWTTokenVO jwtTokenVO = JwtTokenUtil.getUserToken(authToken, secretKey); if (jwtTokenVO != null && !(SecurityContextHolder.getContext().getAuthentication() instanceof AnonymousAuthenticationToken)) { //validate token if (validateToken(jwtTokenVO, secretKey)) { MLPUser mlpUser = userService.findUserByUsername(jwtTokenVO.getUserName()); //TODO : Need to implement role base authority UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken( new AuthenticatedUser(mlpUser), authToken, new ArrayList<>()); authentication.setDetails(new WebAuthenticationDetailsSource() .buildDetails(httpRequest)); SecurityContextHolder.getContext().setAuthentication(authentication); } } } chain.doFilter(request, response); logger.debug("doFilterInternal() End"); private boolean validateToken(JWTTokenVO jwtTokenVO, String secretKey) { logger.debug("validateToken() Begin"); }
package org.acumos.federation.client; import java.util.List; import org.acumos.cds.domain.MLPCatalog; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.config.TlsConfig; import org.acumos.federation.client.data.Catalog; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.GatewayClient; public class ClientDemo { private static final String peerApiUrl = "https://public.otheracumos.org:9084"; private static final String internalApiUrl = "https://federation-service:9011"; private static final String keystore = "keystore.jks"; private static final String keystorepass = "keystore_pass"; private static final String firstpeerid = "12345678-1234-1234-1234-1234567890ab"; private static final String secondpeerid = "cafebebe-cafe-bebe-cafe-bebecafebebe"; public static void main(String[] args) throws Exception { ClientConfig cconf = new ClientConfig(); TlsConfig tlsConfig = new TlsConfig(keystore, keystorepass); cconf.setTlsConfig(tlsConfig); cconf.setPeerApiUrl(peerApiUrl); cconf.setInternalApiUrl(internalApiUrl); FederationClient federationClient = new FederationClient(cconf); GatewayClient gatewayClient = federationClient.getGatewayClient(); List<Catalog> catalogs = gatewayClient.getCatalogs(); for (Catalog catalog : catalogs) { System.out.println("Catalog ID: " + catalog.getCatalogId()); System.out.println("Catalog Name: " + catalog.getCatalogName()); System.out.println("Catalog Description: " + catalog.getCatalogDescription()); System.out.println("Catalog Owner: " + catalog.getCatalogOwner()); System.out.println("Catalog Type: " + catalog.getCatalogType()); System.out.println("Catalog URL: " + catalog.getCatalogUrl()); System.out.println("Catalog Created: " + catalog.getCreated()); System.out.println("Catalog Modified: " + catalog.getModified()); System.out.println("Catalog Metadata: " + catalog.getMetadata()); System.out.println("Catalog Active: " + catalog.isActive()); System.out.println("Catalog Deleted: " + catalog.isDeleted()); System.out.println
private static final String keystorepass = "keystore_pass"; private static final String firstpeerid = "12345678-1234-1234-1234-1234567890ab"; private static final String secondpeerid = "cafebebe-cafe-bebe-cafe-bebecafebebe"; public static void main(String[] args) throws Exception { ClientConfig cconf = new ClientConfig(); cconf.setSsl(new TlsConfig()); cconf.getSsl().setKeyStore(keystore); cconf.getSsl().setKeyStorePassword(keystorepass); FederationClient fedclient = new FederationClient(peerApiUrl, cconf); System.out.println("Listing remote acumos catalogs using public E5 interface"); for (MLPCatalog mcat : fedclient.getCatalogs()) { System.out.println("Catalog " + mcat.getName() + " has " + ((Catalog) mcat).getSize() + " models"); } GatewayClient gwclient = new GatewayClient(internalApiUrl, cconf); System.out.println("Fetching first peer's catalogs from inside Acumos using private interface"); for (MLPCatalog mcat : gwclient.getCatalogs(firstpeerid)) { System.out.println("Catalog " + mcat.getName() + " has " + ((Catalog) mcat).getSize() + " models"); } }
import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(value = "/") public class PipeLineServiceController { private static final String PIPELINE_INPROGRESS = "IP"; private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired @Qualifier("InputValidationServiceImpl") private InputValidationService inputValidationService; @Autowired @Qualifier("PipeLineValidationServiceImpl") private PipeLineValidationService pipeLineValidationService; @Autowired @Qualifier("PipeLineServiceImpl") private PipeLineService pipeLineService; @Autowired private PipeLineCacheService pipelineCacheService; /** * Creates new independent Pipeline for a user. * @param authenticatedUserId */ @RequestMapping(value = "/createPipeline/{authenticatedUserId}", method = RequestMethod.POST) @ResponseBody public ResponseEntity<String> createPipeline(@PathVariable String authenticatedUserId, @RequestBody PipelineRequest pipelineRequest) { // Implementation code here } /** * Retrieves the status of a pipeline. * @param authenticatedUserId * @param pipelineId */ @RequestMapping(value = "/getPipelineStatus/{authenticatedUserId}/{pipelineId}", method = RequestMethod.GET) @ResponseBody public ResponseEntity<String> getPipelineStatus(@PathVariable String authenticatedUserId, @PathVariable String pipelineId) { // Implementation code here } /** * Updates the status of a pipeline. * @param authenticatedUserId * @param pipelineId * @param pipelineStatus */ @RequestMapping(value = "/updatePipelineStatus/{authenticatedUserId}/{pipelineId}/{pipelineStatus}", method = RequestMethod.PUT) @ResponseBody public ResponseEntity<String> updatePipelineStatus(@PathVariable String authenticatedUserId, @PathVariable String pipelineId, @PathVariable String pipelineStatus) { // Implementation code here } /** * Deletes a pipeline. * @param authenticatedUserId * @param pipelineId */ @RequestMapping(value = "/deletePipeline/{authenticatedUserId}/{pipelineId}", method = RequestMethod.DELETE) @ResponseBody public
import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class MyClass { private static final Logger logger = LoggerFactory.getLogger(MyClass.class); public void createPipeline(String pipelineName, String acumosLoginId) throws DuplicatePipeLineException { logger.debug("createPipeline() begin"); // Check if the pipeline already exists in NiFi and NiFi Registry boolean pipelineExists = checkPipelineExists(pipelineName, acumosLoginId); if (pipelineExists) { logger.debug("Skipping flow creation...flow {} already exists for user {} in NiFi Registry.", pipelineName, acumosLoginId); throw new DuplicatePipeLineException("Requested Pipeline Name: " + pipelineName + " already exists in both NiFi Server and NiFi Registry"); } // Create the pipeline in NiFi String flowURL = createPipelineInNiFi(pipelineName, acumosLoginId); logger.debug("NiFi createPipeline() end"); return flowURL; } public boolean checkifNifiPodRunning(String acumosLoginId) { boolean nifiPodRunning = false; logger.debug("checkifNifiPodRunning() begin"); nifiPodRunning = createNiFi.checkifNifiPodRunning(acumosLoginId); logger.debug("checkifNifiPodRunning() End"); return nifiPodRunning; } public String createNiFiInstance(String acumosLoginId) { logger.debug("createNiFiInstance() Begin"); String nifiURL = null; // Call the Kubernetes API to create a NiFi Instance try { nifiURL = createNiFi.createNiFiInstanceForUser(acumosLoginId); logger.debug("createNiFiInstance() End"); } catch (Exception e) { logger.error("Failed to create NiFi instance for user {}", acumosLoginId, e); } return nifiURL; } private boolean checkPipelineExists(String pipelineName, String acumosLoginId) { // Implementation to check if the pipeline exists in NiFi and NiFi Registry } private String createPipelineInNiFi(String pipelineName, String acumosLoginId) { // Implementation to create the pipeline in NiFi } }
public void clearCandidates() { fTraceTypes.clear(); fTraceFiles.clear(); } public String createNiFiInstance(String acumosLoginId) { logger.debug("createNiFiInstance() Begin"); String nifiURL = null; // Call the Kubernetes API to create a NiFi Instance try { nifiURL = createNiFi.createNiFiInstanceForUser(acumosLoginId); } catch (NiFiInstanceCreationException e) { logger.error("Exception occurred while creating NiFi Instance for User", e); throw new NiFiInstanceCreationException("Exception occurred while creating NiFi Instance for User"); } logger.debug("createNiFiInstance() End"); return nifiURL; }
package org.acumos.workbench.pipelineservice.service; import java.lang.invoke.MethodHandles; import org.acumos.workbench.common.vo.Pipeline; import org.acumos.workbench.pipelineservice.exception.DuplicateRequestException; import org.acumos.workbench.pipelineservice.util.MLWBRequestCache; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; @Service public class PipeLineCacheService { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private MLWBRequestCache requestCache; public void putCreateRequest(String requestId, Pipeline pipeline) { logger.debug("putCreateRequest() Begin "); Boolean exist = requestCache.checkIfCreateRequestExists(requestId, pipeline); if (exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addCreateRequest(requestId, pipeline); } logger.debug("putCreateRequest() End"); } public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } }
private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private MLWBRequestCache requestCache; public void putCreateRequest(String requestId, Pipeline pipeline) { logger.debug("putCreateRequest() Begin "); Boolean exist = requestCache.checkIfCreateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addCreateRequest(requestId, pipeline); } logger.debug("putCreateRequest() End"); } public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); }
/** * This method puts a create request into the request cache. * If the request already exists, it throws a DuplicateRequestException. * * @param requestId The ID of the request * @param pipeline The pipeline object */ public void putCreateRequest(String requestId, Pipeline pipeline) { logger.debug("putCreateRequest() Begin "); Boolean exist = requestCache.checkIfCreateRequestExists(requestId, pipeline); if (exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addCreateRequest(requestId, pipeline); } logger.debug("putCreateRequest() End"); } /** * This method removes a create request from the request cache. * * @param requestId The ID of the request * @param pipeline The pipeline object */ public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } /** * This method puts an update request into the request cache. * If the request already exists, it throws a DuplicateRequestException. * * @param requestId The ID of the request * @param pipeline The pipeline object */ public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if (exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); } /** * This method removes an update request from the request cache. * * @param requestId The ID of the request * @param pipeline The pipeline object */ public void removeUpdateRequest(String requestId, Pipeline pipeline) { requestCache.removeUpdateRequest(requestId); } */
/** * This method removes the create request from the request cache. * * @param requestId The ID of the create request. * @param pipeline The pipeline associated with the create request. */ public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } /** * This method puts the update request into the request cache. * * @param requestId The ID of the update request. * @param pipeline The pipeline associated with the update request. * @throws DuplicateRequestException If a duplicate request is found. */ public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if (exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); } /** * This method removes the update request from the request cache. * * @param requestId The ID of the update request. * @param pipeline The pipeline associated with the update request. */ public void removeUpdateRequest(String requestId, Pipeline pipeline) { requestCache.removeUpdateRequest(requestId); } /** * This method puts the delete request into the request cache. * * @param requestId The ID of the delete request. * @param pipelineId The ID of the pipeline associated with the delete request. * @throws DuplicateRequestException If a duplicate request is found. */ public void putDeleteRequest(String requestId, String pipelineId) { logger.debug("putDeleteRequest() Begin "); Boolean exist = requestCache.checkIfDeleteRequestExists(requestId, pipelineId); if (exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addDeleteRequest(requestId, pipelineId); } logger.debug("putDeleteRequest() End "); }
/** * This method puts an update request into the request cache. * If the request already exists, it throws a DuplicateRequestException. * * @param requestId The ID of the request * @param pipeline The pipeline object */ public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if (exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); } /** * This method removes an update request from the request cache. * * @param requestId The ID of the request * @param pipeline The pipeline object */ public void removeUpdateRequest(String requestId, Pipeline pipeline) { requestCache.removeUpdateRequest(requestId); } /** * This method puts a delete request into the request cache. * If the request already exists, it throws a DuplicateRequestException. * * @param requestId The ID of the request * @param pipelineId The ID of the pipeline */ public void putDeleteRequest(String requestId, String pipelineId) { logger.debug("putDeleteRequest() Begin "); Boolean exist = requestCache.checkIfDeleteRequestExists(requestId, pipelineId); if (exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addDeleteRequest(requestId, pipelineId); } logger.debug("putDeleteRequest() End "); } /** * This method removes a delete request from the request cache. * * @param requestId The ID of the request * @param pipelineId The ID of the pipeline */ public void removeDeleteRequest(String requestId, String pipelineId) { requestCache.removeDeleteRequest(requestId); }
@ApplicationScope @Component public class MLWBRequestCache implements Serializable { private static final long serialVersionUID = -4688732173089705360L; private Map<String, Pipeline> createRequests; private Map<String, Pipeline> updateRequests; private Map<String, String> deleteRequests; private Map<String, String> archiveRequests; public MLWBRequestCache() { createRequests = new HashMap<String, Pipeline>(); updateRequests = new HashMap<String, Pipeline>(); deleteRequests = new HashMap<String, String>(); archiveRequests = new HashMap<String, String>(); } public void addCreateRequest(String key, Pipeline value) { createRequests.put(key, value); } public void removeCreateRequest(String key) { createRequests.remove(key); } public Pipeline getCreateRequestByKey(String key) { if (createRequests.containsKey(key)) { return createRequests.get(key); } return null; } }
private Map<String, String> deleteRequests; private Map<String, String> archiveRequests; public MLWBRequestCache() { createRequests = new HashMap<String, Pipeline>(); updateRequests = new HashMap<String, Pipeline>(); deleteRequests = new HashMap<String, String>(); archiveRequests = new HashMap<String, String>(); } public void addCreateRequest(String key, Pipeline value) { createRequests.put(key, value); } public void removeCreateRequest(String key) { createRequests.remove(key); } public Pipeline getCreateRequestByKey(String key) { if (createRequests.containsKey(key)) { return createRequests.get(key); } return null; } /** * Check if request with given requestId or Pipeline already exists in the cache. * * @param key request Id * @param value Pipeline * @return boolean */ public boolean checkRequestExists(String key, Pipeline value) { return createRequests.containsKey(key) || createRequests.containsValue(value); }
List<Nodes> nodesList = new ArrayList<Nodes>(); nodesList.add(node); cdump.setNodes(nodesList); String nodeId = "123"; String userId = "123"; Resource resource1 = resourceLoader.getResource(PROTOBUF_TEMPLATE_NAME); when(resourceLoader.getResource("classpath:Protobuf_Template.txt")).thenReturn(resource1);
package org.eclipse.egit.ui.internal.rebase; import java.util.LinkedList; import java.util.List; import org.eclipse.egit.core.internal.rebase.RebaseInteractivePlan; import org.eclipse.jface.viewers.ITreeContentProvider; import org.eclipse.jface.viewers.Viewer; import org.eclipse.jgit.lib.RebaseTodoLine; public enum RebaseInteractivePlanContentProvider implements ITreeContentProvider { INSTANCE; private RebaseInteractivePlanContentProvider() { } public void dispose() { } public void inputChanged(Viewer viewer, Object oldInput, Object newInput) { } public Object[] getElements(Object inputElement) { if (inputElement instanceof RebaseInteractivePlan) { RebaseInteractivePlan plan = (RebaseInteractivePlan) inputElement; List<RebaseTodoLine> lines = plan.getLines(); return lines.toArray(); } return new Object[0]; } public Object[] getChildren(Object parentElement) { return new Object[0]; } public Object getParent(Object element) { return null; } public boolean hasChildren(Object element) { return false; } }
import com.google.common.collect.Lists; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.ApiKey; import springfox.documentation.service.AuthorizationScope; import springfox.documentation.service.Contact; import springfox.documentation.service.SecurityReference; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spi.service.contexts.SecurityContext; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; @Configuration @EnableSwagger2 public class SwaggerConfiguration { @Bean public Docket swaggerSpringfoxDocket() { Docket docket = new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .forCodeGeneration(true) .genericModelSubstitutes(ResponseEntity.class) .ignoredParameterTypes(Pageable.class) .ignoredParameterTypes(java.sql.Date.class) .directModelSubstitute(java.time.LocalDate.class, java.sql.Date.class) .directModelSubstitute(java.time.ZonedDateTime.class, Date.class) .directModelSubstitute(java.time.LocalDateTime.class, Date.class) .securityContexts(Lists.newArrayList(securityContext())); return docket; } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title("API Documentation") .description("API Documentation") .version("1.0") .contact(new Contact("Name", "URL", "email@example.com")) .build(); } private SecurityContext securityContext() { return SecurityContext.builder() .securityReferences(defaultAuth()) .forPaths(PathSelectors.any()) .build(); } private List<SecurityReference> defaultAuth() { AuthorizationScope authorizationScope = new AuthorizationScope("global", "accessEverything"); AuthorizationScope[] authorizationScopes = new AuthorizationScope[]{authorizationScope}; return Lists.newArrayList(new SecurityReference("apiKey", authorizationScopes)); } }
// Secure the endpoints with HTTP Basic authentication @Override protected void configure(HttpSecurity http) throws Exception { http .csrf().disable() .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() .antMatchers("/swagger-ui.html").permitAll() .anyRequest().authenticated() .and() .addFilterBefore(jwtAuthorizationFilterBean(), UsernamePasswordAuthenticationFilter.class); } @Bean public JWTAuthorizationFilter jwtAuthorizationFilterBean() throws Exception { JWTAuthorizationFilter jwtAuthorizationFilter = new JWTAuthorizationFilter(authenticationManagerBean(), conf.getJwtSecretKey(), cdsClient); return jwtAuthorizationFilter; }
package org.acumos.workbench.modelservice.service; import org.acumos.workbench.common.vo.Model; public interface ModelValidationService { public void validateInputData(String authenticatedUserId, Model model); }
/* * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.workbench.modelservice.service; import org.acumos.workbench.common.vo.Model; public interface ModelValidationService { public void validateInputData(String authenticatedUserId, Model model); }
* ===============LICENSE_START======================================================= * Acumos * =================================================================================== * Copyright (C) 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. * =================================================================================== * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.designstudio.toscagenerator.test; import java.io.File; import java.io.IOException; import java.lang.invoke.MethodHandles; import java.time.Instant; import java.util.ArrayList; import java.util.List; import org.acumos.cds.domain.MLPSolutionRevision; import org.acumos.designstudio.toscagenerator.ToscaGeneratorClient;
import org.junit.Rule; import org.junit.Test; import org.mockito.MockitoAnnotations; import org.mockito.junit.MockitoJUnit; import org.mockito.junit.MockitoRule; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class ToscaGeneratorClientTest { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Rule public MockitoRule mockitoRule = MockitoJUnit.rule(); @Before public void setUp() { MockitoAnnotations.initMocks(this); } @Test(expected = ServiceException.class) public void ToscaClientTest() { // Test code goes here } }
mlpRev.setModified(Instant.now()); mlpRev.setOnboarded(Instant.now()); mlpRev.setPublisher("techmdev"); mlpRev.setRevisionId("123"); mlpRev.setSolutionId("123"); mlpRev.setUserId("123"); mlpRev.setVerifiedLicense("Yes"); mlpRev.setVerifiedVulnerability("Yes"); mlpRev.setVersion("1"); List<MLPSolutionRevision> listMLPSolRev = new ArrayList<>(); listMLPSolRev.add(mlpRev); try { client.generateTOSCA("123", "123", "1", "123", protoFile, tagFile); } catch (AcumosException e) { logger.error("AcumosException occured while generating the TOSCA File"); }
/***************************************************************************** * Copyright (C) 2018 - 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. * * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. *****************************************************************************/ package org.acumos.csvdatabroker.vo; import static org.junit.Assert.assertTrue; import org.junit.Test; public class CSVdatabrokerVOTest { 	@Test 	public void csvdatabrokerVOTest() { 		DataBrokerMap dataBrokerMap = new DataBrokerMap(); 		dataBrokerMap.setScript("test"); 	} }
/***************************************************************************** * Copyright (C) 2018 - 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. * * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. *****************************************************************************/ package org.acumos.sqldatabroker.vo; import static org.junit.Assert.assertTrue; import java.util.ArrayList; import java.util.List; import org.acumos.sqldatabroker.exceptionhandler.ServiceException; import org.junit.Test; public class DataBrokerMapVOTest { 	@Test 	public void test() { 		// Add test cases here 	} }
/***************************************************************************** * Copyright (C) 2018 - 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. * * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. *****************************************************************************/ package org.acumos.csvdatabroker.vo; import static org.junit.Assert.assertTrue; import org.junit.Test; public class CSVdatabrokerVOTest { @Test public void csvdatabrokerVOTest() { DataBrokerMap dataBrokerMap = new DataBrokerMap(); dataBrokerMap.setScript("test"); } }
@RestController @RequestMapping(value = "/") public class ModelServiceController { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired @Qualifier("InputValidationServiceImpl") private InputValidationService inputValidationService; @Autowired @Qualifier("ModelValidationServiceImpl") private ModelValidationService modelValidationService; @Autowired @Qualifier("ModelServiceImpl") private ModelService modelService; @ApiOperation(value = "List all the Models belonging to a user") @RequestMapping(value = "/users/{authenticatedUserId}/models/", method = RequestMethod.GET) public ResponseEntity<?> listModels(HttpServletRequest request, @ApiParam(value = "Acumos User login Id", required = true) @PathVariable("authenticatedUserId") String authenticatedUserId) { logger.debug("listModels() Begin"); String authToken = getAuthJWTToken(request); // 1. Check if the Authenticated User Id is present or not inputValidationService.isValuePresent(ModelServiceConstants.MODEL_AUTHENTICATED_USER_ID, authenticatedUserId); // Rest of the code... } }
import org.acumos.workbench.common.vo.Version; import org.acumos.workbench.modelservice.exceptionhandling.ModelNotFoundException; import org.acumos.workbench.modelservice.util.ConfigurationProperties; import org.acumos.workbench.modelservice.util.ModelServiceProperties; import org.acumos.workbench.modelservice.util.ModelServiceUtil; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.slf4j.MDC; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Service; import org.springframework.web.client.RestClientResponseException; @Service("ModelServiceImpl") public class ModelServiceImpl implements ModelService { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private CommonDataServiceRestClientImpl cdsClient; @Autowired private ModelServiceProperties props; @Autowired private ConfigurationProperties confprops; @Autowired private ProjectServiceRestClientImpl psClient; @Override public List<Model> getModels(String authenticatedUserId, String projectId) { logger.debug("getModels() Begin"); List<Model> modelList = new ArrayList<Model>(); MLPUser mlpUser = getUserDetails(authenticatedUserId); // ... } }
Model model = getModelWithErrorStatus(ex); return new ResponseEntity<Model>(model, HttpStatus.NOT_FOUND); } @ExceptionHandler(AssociationException.class) public final ResponseEntity<?> handleAssociationException(AssociationException ex, WebRequest request) { Model model = getModelWithErrorStatus(ex); return new ResponseEntity<Model>(model, HttpStatus.NOT_FOUND); } @ExceptionHandler(ProjectModelAssociationNotFoundException.class)
public void isValuePresent(String fieldName, String value) throws ValueNotFoundException; public void validateModelInputJson(Model model) throws InvalidInputJSONException;
package org.acumos.workbench.modelservice.util; public class ModelServiceConstants { public static final String MODEL_AUTHENTICATED_USER_ID = "AuthenticatedUserId"; public static final String DELETED = "DELETED"; public static final String MODEL_IS_ACTIVE = "Model is Active"; public static final String CATALOGNAMES = "CATALOG_NAMES"; public static final String UNARCHIVE = "UA"; public static final String ARCHIVE = "A"; public static final String PROJECTID = "projectId"; public static final String ASSOCIATIONID = "ASSOCIATION_ID"; public static final String MODELTYPECODE = "MODEL_TYPE_CODE"; public static final String MODELPUBLISHSTATUS = "MODEL_PUBLISH_STATUS"; }
private List<String> getConnectedPortInputMsgNames(List<ProtobufServiceOperation> operations) { List<String> inputMessageNames = null; for (ProtobufServiceOperation o : operations) { inputMessageNames = o.getInputMessageNames(); } return inputMessageNames; }
// 1. Get the list of SolutionRevision for the solutionId. mlpSolutionRevisionList = getSolutionRevisionsList(solutionId); // 2. Match the version with the SolutionRevision and get the solutionRevisionId. if (null != mlpSolutionRevisionList && !mlpSolutionRevisionList.isEmpty()) { solutionRevisionId = mlpSolutionRevisionList.stream() .filter(mlp -> mlp.getVersion().equals(version)) .findFirst() .get() .getRevisionId(); logger.debug(EELFLoggerDelegator.debugLogger, "SolutionRevisonId for Version : {}", solutionRevisionId); } else { result = String.format(error, "501", "Failed to fetch the Solution Revision List"); } } catch (Exception e) { logger.error(EELFLoggerDelegator.errorLogger, "Error : Exception in fetchJsonTOSCA() : Failed to fetch the Solution Revision List", e); result = String.format(error, "501", "Failed to fetch the Solution Revision List for the version {}", version); } if (null != solutionRevisionId) { // continue with the code logic }
// add protobuf file addProtobufFile(protobufJarEntryName, tempJar); // add DavaVO.class file List<String> dataVOEntryList = addDataVOClasses(DataVOClassEntryName, tempJar); JarEntry entry = null; // Open the original jar jar = new JarFile(jarFile); // Loop through the jar entries and add them to the temp jar, // skipping the entry that was added to the temp jar already. for (Enumeration entries = jar.entries(); entries.hasMoreElements();) { // Get the next entry. entry = (JarEntry) entries.nextElement(); // If the entry has not been added already, add it. if (!entry.getName().equals(fieldMappingJarEntryName) && !dataVOEntryList.contains(entry.getName())) { // Get an input stream for the entry. InputStream entryStream = jar.getInputStream(entry); // Read the entry and write it to the temp jar. tempJar.putNextEntry(entry); while ((bytesRead = entryStream.read(buffer)) != -1) { // Write the bytes to the temp jar. tempJar.write(buffer, 0, bytesRead); } } }
curPartIdx++; if (curPartIdx <= endPartIdx) { boolean suitablePartFound = false; for (int i = curPartIdx; i <= endPartIdx; i++) { if (partitionCursors[i] == null || partitionCursors[i].size() < occurrenceThreshold) { continue; } suitablePartFound = true; curPartIdx = i; break; } if (!suitablePartFound) { isFinishedSearch = true; invListMerger.close(); finalSearchResult.finalizeWrite(); return true; } }
isSingleInvertedList = true; needToReadNewPart = true; } else { singleInvListCursor = null; isSingleInvertedList = false; needToReadNewPart = invListMerger.merge(partitionCursors[curPartIdx], occurrenceThreshold, numPrefixLists, finalSearchResult); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); } if (needToReadNewPart && isFinalPartIdx) { invListMerger.close(); finalSearchResult.finalizeWrite(); isFinishedSearch = true; return true; } else { isFinishedSearch = true; } return false; } public void setNumTokensBoundsInSearchKeys(short numTokensLowerBound, short numTokensUpperBound) {
needToReadNewPart = true; } else { singleInvListCursor = null; isSingleInvertedList = false; needToReadNewPart = invListMerger.merge(partitionCursors[curPartIdx], occurrenceThreshold, numPrefixLists, finalSearchResult); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); } if (needToReadNewPart && isFinalPartIdx) { invListMerger.close(); finalSearchResult.finalizeWrite(); isFinishedSearch = true; return true; } } else { isFinishedSearch = true; } return false; } public void setNumTokensBoundsInSearchKeys(short numTokensLowerBound, short numTokensUpperBound) {
searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); if (needToReadNewPart && isFinalPartIdx) { invListMerger.close(); finalSearchResult.finalizeWrite(); isFinishedSearch = true; return true; } else { isFinishedSearch = true; } return false; } public void setNumTokensBoundsInSearchKeys(short numTokensLowerBound, short numTokensUpperBound) { ShortPointable.setShort(lowerBoundTuple.getFieldData(0), lowerBoundTuple.getFieldStart(0), numTokensLowerBound); ShortPointable.setShort(upperBoundTuple.getFieldData(0), upperBoundTuple.getFieldStart(0), numTokensUpperBound); } public ITupleReference getPrefixSearchKey() { return searchKey; } public ITupleReference getFullLowSearchKey() { return fullLowSearchKey; }
singleInvListCursor.prepareLoadPages(); singleInvListCursor.loadPages(); isSingleInvertedList = true; isFinishedSearch = true; } else { finalSearchResult.reset(); isFinishedSearch = invListMerger.merge(invListCursors, occurrenceThreshold, numPrefixLists, finalSearchResult); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); } if (isFinishedSearch) { invListMerger.close(); finalSearchResult.finalizeWrite(); } resultCursor.open(null, searchPred);
@Override public boolean continueSearch() throws HyracksDataException { if (isFinishedSearch) { return true; } isFinishedSearch = invListMerger.continueMerge(); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); if (isFinishedSearch) { invListMerger.close(); finalSearchResult.finalizeWrite(); } return isFinishedSearch; }
public void upsert(ITupleReference tuple) throws HyracksDataException; public IIndexCursor createSearchCursor(boolean exclusive) throws HyracksDataException; public void search(IIndexCursor cursor, ISearchPredicate searchPred) throws HyracksDataException;
public boolean append(byte[] bytes, int offset, int length) { if (tupleDataEndOffset + length + TUPLE_COUNT_SIZE <= frameSize) { if (buffer == null) { LOGGER.info("buffer null"); } System.arraycopy(bytes, offset, buffer.array(), tupleDataEndOffset, length); tupleDataEndOffset += length; return true; } return false; }
invListTuple = invListCursor.getTuple(); if (!newSearchResult.append(invListTuple, 1)) { return false; } invListTidx++; if (invListCursor.hasNext()) { invListCursor.next(); } while (resultTidx < prevResultFrameTupleCount) { resultTuple.reset(prevCurrentBuffer.array(), resultFrameTupleAcc.getTupleStartOffset(resultTidx)); count = getCount(resultTuple); if (!newSearchResult.append(resultTuple, count)) { return false; } resultTidx++; checkPrevResultAndFetchNextFrame(prevSearchResult); } return finishMergingOneList(isFinalList, prevSearchResult, newSearchResult);
private static final Map<Integer, ReplicationRequestType> TYPES = new HashMap<>(); static { Stream.of(ReplicationRequestType.values()).forEach(type -> TYPES.put(type.ordinal(), type)); } public static ByteBuffer readRequest(SocketChannel socketChannel, ByteBuffer dataBuffer) throws IOException { NetworkingUtil.readBytes(socketChannel, dataBuffer, Integer.BYTES); final int requestSize = dataBuffer.getInt(); if (dataBuffer.capacity() < requestSize) { dataBuffer = ByteBuffer.allocate(requestSize); } NetworkingUtil.readBytes(socketChannel, dataBuffer, requestSize); return dataBuffer; } public static ReplicationRequestType getRequestType(SocketChannel socketChannel, ByteBuffer byteBuffer) throws IOException { NetworkingUtil.readBytes(socketChannel, byteBuffer, REPLICATION_REQUEST_TYPE_SIZE); return TYPES.get(byteBuffer.getInt()); } private static ByteBuffer getGoodbyeBuffer() { ByteBuffer bb = ByteBuffer.allocate(REPLICATION_REQUEST_TYPE_SIZE); bb.putInt(ReplicationRequestType.GOODBYE.ordinal()); bb.flip(); return bb; }
public static int getJobIdFromLogAckMessage(String msg) { return Integer.parseInt(msg.substring(msg.indexOf(JOB_REPLICATION_ACK) + 1)); }
ITupleReference highSearchKey = null; partSearcher.setNumTokensBoundsInSearchKeys(numTokensLowerBound, numTokensUpperBound); if (numTokensLowerBound < 0) { ctx.getBtreePred().setLowKeyComparator(ctx.getPrefixSearchCmp()); lowSearchKey = partSearcher.getPrefixSearchKey(); } else { ctx.getBtreePred().setLowKeyComparator(ctx.getSearchCmp()); lowSearchKey = partSearcher.getFullLowSearchKey(); } if (numTokensUpperBound < 0) { ctx.getBtreePred().setHighKeyComparator(ctx.getPrefixSearchCmp()); highSearchKey = partSearcher.getPrefixSearchKey(); } else { ctx.getBtreePred().setHighKeyComparator(ctx.getSearchCmp()); highSearchKey = partSearcher.getFullHighSearchKey(); } ctx.getBtreePred().setLowKey(lowSearchKey, true); ctx.getBtreePred().setHighKey(highSearchKey, true); ctx.getBtreeAccessor().search(ctx.getBtreeCursor(), ctx.getBtreePred()); boolean tokenExists = false; try { while (ctx.getBtreeCursor().hasNext()) { ctx.getBtreeCursor().next(); ITupleReference btreeTuple = ctx.getBtreeCursor().getTuple(); } } catch (Exception e) { // Handle exception } finally { ctx.getBtreeCursor().close(); }
protected void createAndOpenFile() throws HyracksDataException { if (isInMemoryOpMode) { // In-memory mode should not generate a file. return; } if (searchResultWriter == null) { FileReference file = ctx.getJobletContext().createManagedWorkspaceFile(FILE_PREFIX); searchResultWriter = new RunFileWriter(file, ctx.getIoManager()); searchResultWriter.open(); isFileOpened = true; } } // Deallocates the I/O buffer (one frame). This should be the last operation. protected void deallocateIOBuffer() throws HyracksDataException { if (ioBufferFrame != null) { bufferManager.releaseFrame(ioBuffer); buffers.clear(); ioBufferFrame = null; ioBuffer = null; } }
private boolean searchInBTreeCursors(int i, boolean includeMutableComponent) { if (i == 0 && includeMutableComponent) { btreeCursors[i].reset(); searchCallback.reconcile(predicate.getLowKey()); reconciled = true; btreeAccessors[0].search(btreeCursors[i], predicate); if (btreeCursors[i].hasNext()) { btreeCursors[i].next(); if (((ILSMTreeTupleReference) btreeCursors[i].getTuple()).isAntimatter()) { searchCallback.cancel(predicate.getLowKey()); btreeCursors[i].close(); return false; } else { frameTuple = btreeCursors[i].getTuple(); foundTuple = true; searchCallback.complete(predicate.getLowKey()); foundIn = i; return true; } } else { searchCallback.cancel(predicate.getLowKey()); btreeCursors[i].close(); } } else { frameTuple = btreeCursors[i].getTuple(); searchCallback.reconcile(frameTuple); searchCallback.complete(frameTuple); foundTuple = true; foundIn = i; return true; } return false; }
protected void appendToLogTail(ILogRecord logRecord) { syncAppendToLogTail(logRecord); if (waitForFlush(logRecord) && !logRecord.isFlushed()) { synchronized (logRecord) { while (!logRecord.isFlushed()) { try { logRecord.wait(); } catch (InterruptedException e) { // NOSONAR ensure txn survive at this stage // ignore interrupt Thread.currentThread().interrupt(); } } } } }
Refactored Code: ```java * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.common.replication; import java.util.HashMap; import java.util.Map; public class ReplicationStrategyFactory { private static final Map<String, Class<? extends IReplicationStrategy>> BUILT_IN_REPLICATION_STRATEGY = new HashMap<>(); static { BUILT_IN_REPLICATION_STRATEGY.put("no_replication", NoReplicationStrategy.class); BUILT_IN_REPLICATION_STRATEGY.put("all", AllDatasetsReplicationStrategy.class); BUILT_IN_REPLICATION_STRATEGY.put("metadata", MetadataOnlyReplicationStrategy.class); } private ReplicationStrategyFactory() { throw new AssertionError(); } public static IReplicationStrategy create(String name) { String strategyName = name.toLowerCase(); if (!BUILT_IN_REPLICATION_STRATEGY.containsKey(strategyName)) { throw new IllegalStateException("Couldn't find strategy with name: " + name); } Class<? extends IReplicationStrategy> clazz = BUILT_IN_REPLICATION_STRATEGY.get(strategyName); try { return clazz.getDeclaredConstructor().newInstance(); } catch (Exception e) { throw new IllegalStateException("Failed to create replication strategy: " + name, e); } } } ```
private int numActiveIOOps; public synchronized void declareActiveIOOperation() { numActiveIOOps++; } public synchronized void undeclareActiveIOOperation() { numActiveIOOps--; notifyAll(); } public synchronized Set<ILSMIndex> getDatasetIndexes() { Set<ILSMIndex> datasetIndexes = new HashSet<>(); for (IndexInfo iInfo : indexes.values()) { if (iInfo.isOpen()) { datasetIndexes.add(iInfo.getIndex()); } } return datasetIndexes; } @Override public int compareTo(DatasetInfo i) { if (isOpen() && !i.isOpen()) { return -1; } else if (!isOpen() && i.isOpen()) { return 1; } else { int referenceCountComparison = Integer.compare(referenceCount, i.referenceCount); if (referenceCountComparison != 0) { return referenceCountComparison; } else { return Long.compare(lastAccess, i.lastAccess); } } }
ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetLifecycle> openDatasets = new ArrayList<>(datasetLifecycles.values()); for (DatasetLifecycle dslc : openDatasets) { closeDataset(dslc.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { ArrayList<DatasetLifecycle> openDatasets = new ArrayList<>(datasetLifecycles.values()); for (DatasetLifecycle dslc : openDatasets) { if (dslc.getDatasetID() >= getFirstAvilableUserDatasetID()) { closeDataset(dslc.getDatasetInfo()); } } } @Override public synchronized void stop(boolean dumpState, OutputStream outputStream) throws IOException { if (stopped) { return; } if (dumpState) { dumpState(outputStream); } closeAllDatasets(); datasetLifecycles.clear(); }
synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); ArrayList<DatasetLifecycle> openDatasets = new ArrayList<>(datasetLifecycles.values()); for (DatasetLifecycle dslc : openDatasets) { closeDataset(dslc.getDatasetInfo()); } ArrayList<DatasetLifecycle> openDatasets = new ArrayList<>(datasetLifecycles.values()); for (DatasetLifecycle dslc : openDatasets) { if (dslc.getDatasetID() >= getFirstAvilableUserDatasetID()) { closeDataset(dslc.getDatasetInfo()); } } if (stopped) { return; } if (dumpState) { dumpState(outputStream); } closeAllDatasets(); datasetLifecycles.clear(); stopped = true;
protected void cleanupForAbort() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers.entrySet()) { AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); } }
protected void cleanupForAbort() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers.entrySet()) { AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); } }
protected void cleanupForAbort() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers.entrySet()) { AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); } }
protected void cleanupForAbort() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers.entrySet()) { AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); } }
protected void cleanupForAbort() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers.entrySet()) { AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); } }
Fixed Code: jobGenParams.writeToFuncArgs(secondaryIndexFuncArgs); List<LogicalVariable> secondaryIndexUnnestVars = new ArrayList<LogicalVariable>(); List<Object> secondaryIndexOutputTypes = new ArrayList<Object>(); appendSecondaryIndexOutputVars(dataset, recordType, metaRecordType, index, outputPrimaryKeysOnly, context, secondaryIndexUnnestVars); appendSecondaryIndexTypes(dataset, recordType, metaRecordType, index, outputPrimaryKeysOnly, secondaryIndexOutputTypes); IFunctionInfo secondaryIndexSearch = FunctionUtil.getFunctionInfo(AsterixBuiltinFunctions.INDEX_SEARCH); UnnestingFunctionCallExpression secondaryIndexSearchFunc = new UnnestingFunctionCallExpression(secondaryIndexSearch, secondaryIndexFuncArgs); secondaryIndexSearchFunc.setReturnsUniqueValues(true);
if (dsInfo.isDurable()) { synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null, logManager.getNodeId(), indexes.size()); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } while (!logRecord.isFlushed()) { try { logRecord.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } } for (ILSMIndex index : indexes) { AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) { // perform synchronous flush } }
synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null, logManager.getNodeId(), indexes.size()); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { logRecord.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } for (ILSMIndex index : indexes) { AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) { // TODO: This is not efficient since we flush the indexes sequentially. } }
try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) { closeDataset(dsr.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) { closeDataset(dsr.getDatasetInfo()); } }
try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) { closeDataset(dsr.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) { try { closeDataset(dsr.getDatasetInfo()); } catch (HyracksDataException e) { // handle exception } } }
// we will force all jobs to spill their cached entities to disk. // This could happen only when we have many jobs with small // number of records and none of them have job commit. freeJobsCachedEntities(txnId); jobId2WinnerEntitiesMap.put(txnId, jobEntityWinners); } else { jobEntityWinners = jobId2WinnerEntitiesMap.get(txnId); } jobEntityWinners.add(logRecord); @SuppressWarnings({"squid:MethodCyclomaticComplexity","squid:S134"}) private synchronized void startRecoveryRedoPhase(Set<Integer> partitions, ILogReader logReader, long lowWaterMarkLSN, Set<Long> winnerTxnSet) throws IOException, ACIDException { int redoCount = 0; long txnId = 0; long resourceId; long maxDiskLastLsn; long lsn = -1; ILSMIndex index = null; LocalResource localResource = null; DatasetLocalResource localResourceMetadata = null; boolean foundWinner = false; JobEntityCommits jobEntityWinners = null; IAppRuntimeContextProvider appRuntimeContext = txnSubsystem.getAsterixAppRuntimeContextProvider(); IDatasetLifecycleManager datasetLifecycleManager = appRuntimeContext.getDatasetLifecycleManager();
private void doWriteLogRecord(ByteBuffer buffer) { buffer.put(logSource); buffer.put(logType); buffer.putLong(txnId); switch (logType) { case LogType.ENTITY_COMMIT: writeEntityInfo(buffer); break; case LogType.UPDATE: writeEntityInfo(buffer); buffer.putLong(resourceId); buffer.putInt(logSize); buffer.putInt(newValueFieldCount); buffer.put(newOp); buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); if (oldValueSize > 0) { buffer.putInt(oldValueSize); buffer.putInt(oldValueFieldCount); writeTuple(buffer, oldValue, oldValueSize); } break; case LogType.FILTER: writeEntityInfoNoPK(buffer); buffer.putLong(resourceId); buffer.putInt(logSize); buffer.putInt(newValueFieldCount); buffer.put(newOp); buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); break; case LogType.FLUSH: buffer.putInt(datasetId); break; case LogType.MARKER: buffer.putInt(datasetId); buffer.putInt(resourcePartition); callback.before(buffer); buffer.putInt(logSize); break; } }
private void writeEntityInfo(ByteBuffer buffer) { buffer.putInt(resourcePartition); buffer.putInt(datasetId); buffer.putInt(PKHashValue); if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } buffer.putInt(PKValueSize); writePKValue(buffer); }
private void writeEntityInfo(ByteBuffer buffer) { buffer.putInt(resourcePartition); buffer.putInt(datasetId); buffer.putInt(PKHashValue); if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } buffer.putInt(PKValueSize); writePKValue(buffer); }
private void writeEntityResource(ByteBuffer buffer) { buffer.putInt(resourcePartition); buffer.putInt(datasetId); }
txnId = buffer.getLong(); switch (logType) { case LogType.FLUSH: if (buffer.remaining() < ILogRecord.DS_LEN) { return RecordReadStatus.TRUNCATED; } datasetId = buffer.getInt(); resourceId = 0l; // fall through case LogType.WAIT: computeAndSetLogSize(); break; case LogType.JOB_COMMIT: case LogType.ABORT: datasetId = -1; PKHashValue = -1; computeAndSetLogSize(); break; case LogType.ENTITY_COMMIT: if (readEntityInfo(buffer)) { computeAndSetLogSize(); } else { return RecordReadStatus.TRUNCATED; } break; case LogType.UPDATE: if (readEntityInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.FILTER: if (readEntityNoPKInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; }
if (readEntityInfo(buffer)) { computeAndSetLogSize(); } else { return RecordReadStatus.TRUNCATED; } break; case LogType.UPDATE: if (readEntityInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.FILTER: if (readEntityNoPKInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.MARKER: if (buffer.remaining() < DS_LEN + RS_PARTITION_LEN + PRVLSN_LEN + LOGRCD_SZ_LEN) { return RecordReadStatus.TRUNCATED; } datasetId = buffer.getInt(); resourcePartition = buffer.getInt(); prevMarkerLSN = buffer.getLong(); logSize = buffer.getInt(); int lenRemaining = logSize - MARKER_BASE_LOG_SIZE;
Buggy Code: computeAndSetLogSize(); } else { return RecordReadStatus.TRUNCATED; } break; case LogType.UPDATE: if (readEntityInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.FILTER: if (readEntityNoPKInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.MARKER: if (buffer.remaining() < DS_LEN + RS_PARTITION_LEN + PRVLSN_LEN + LOGRCD_SZ_LEN) { return RecordReadStatus.TRUNCATED; } datasetId = buffer.getInt(); resourcePartition = buffer.getInt(); prevMarkerLSN = buffer.getLong(); logSize = buffer.getInt(); int lenRemaining = logSize - MARKER_BASE_LOG_SIZE; if (buffer.remaining() < lenRemaining) { return RecordReadStatus.TRUNCATED; } Refactored Code: computeAndSetLogSize(); } else { return RecordReadStatus.TRUNCATED; } break; case LogType.UPDATE: if (readEntityInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.FILTER: if (readEntityNoPKInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.MARKER: if (buffer.remaining() < DS_LEN + RS_PARTITION_LEN + PRVLSN_LEN + LOGRCD_SZ_LEN) { return RecordReadStatus.TRUNCATED; } datasetId = buffer.getInt(); resourcePartition = buffer.getInt(); prevMarkerLSN = buffer.getLong(); logSize = buffer.getInt(); int lenRemaining
private boolean readEntityInfo(ByteBuffer buffer) { if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) { return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); PKHashValue = buffer.getInt(); PKValueSize = buffer.getInt(); if (buffer.remaining() < PKValueSize) { return false; } if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } PKValue = readPKValue(buffer); return true; }
private boolean readEntityInfo(ByteBuffer buffer) { if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) { return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); PKHashValue = buffer.getInt(); PKValueSize = buffer.getInt(); if (buffer.remaining() < PKValueSize) { return false; } if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } PKValue = readPKValue(buffer); return true; }
private boolean readEntityNoPKInfo(ByteBuffer buffer) { if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) { return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); return true; }
private boolean readEntityNoPKInfo(ByteBuffer buffer) { if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) { return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); return true; }
private boolean readEntityNoPKInfo(ByteBuffer buffer) { if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN + ENTITY_RESOURCE_LENGTH_LEN) { return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); return true; }
if (isDeleteOperation(tuple, numOfPrimaryKeys)) { abstractModCallback.setOp(Operation.DELETE); lsmAccessor.forceDelete(tuple); recordWasDeleted = true; } else { abstractModCallback.setOp(Operation.UPSERT); lsmAccessor.forceUpsert(tuple); recordWasInserted = true; } if (isFiltered && prevTuple != null) { lsmAccessor.updateFilter(prevTuple, true); } writeOutput(index, recordWasInserted, recordWasDeleted); } catch (Exception e) { throw HyracksDataException.create(e); } } @Override public void start() throws HyracksDataException { lsmAccessor.getCtx().setOperation(IndexOperation.UPSERT); } @Override public void finish() throws HyracksDataException { lsmAccessor.getCtx().setOperation(IndexOperation.UPSERT); } }; return modCallback; }
import org.apache.hyracks.storage.am.common.ophelpers.IndexOperation; public enum IndexOperation { CREATE, INSERT, DELETE, UPDATE, UPSERT, FILTER_MOD, SEARCH, DISKORDERSCAN, PHYSICALDELETE, NOOP, MERGE, FULL_MERGE, FLUSH, REPLICATE, DISK_COMPONENT_SCAN, DELETE_MEMORY_COMPONENT, DELETE_DISK_COMPONENTS }
public PhoneSubInfo(Phone phone) { mPhone = phone; mContext = phone.getContext(); } public void updateFilter(ITupleReference tuple, boolean callback) throws HyracksDataException { ctx.setOperation(IndexOperation.UPSERT); lsmHarness.updateFilter(ctx, tuple, callback); } public void batchOperate(FrameTupleAccessor accessor, FrameTupleReference tuple, IFrameTupleProcessor processor, IFrameOperationCallback frameOpCallback) throws HyracksDataException { lsmHarness.batchOperate(ctx, accessor, tuple, processor, frameOpCallback); } @Override public void scanDiskComponents(IIndexCursor cursor) throws HyracksDataException { ctx.setOperation(IndexOperation.DISK_COMPONENT_SCAN); lsmHarness.scanDiskComponents(ctx, cursor); } @Override public String toString() { return getClass().getSimpleName() + ':' + lsmHarness.toString(); }
} @Override public void found(ITupleReference before, ITupleReference after) throws HyracksDataException { if (isFoundNull) { Assert.assertEquals(null, before); } else { Assert.assertEquals(0, cmp.compare(AbstractModificationOperationCallbackTest.this.tuple, before)); } Assert.assertEquals(0, cmp.compare(AbstractModificationOperationCallbackTest.this.tuple, after)); } @Override public void after(ITupleReference tuple) throws HyracksDataException { Assert.assertEquals(0, cmp.compare(AbstractModificationOperationCallbackTest.this.tuple, tuple)); } }
// Do nothing. @Override public void before(ITupleReference tuple) { // Do nothing. } @Override public void found(ITupleReference before, ITupleReference after) { // Do nothing. } @Override public void cancel(ITupleReference tuple) { // Do nothing. } @Override public void complete(ITupleReference tuple) throws HyracksDataException { // Do nothing. } @Override public void after(ITupleReference tuple) throws HyracksDataException { // Do nothing. }
public void after(ITupleReference tuple) { // code implementation goes here }
IOptimizationContext context, Quadruple<Boolean, Boolean, Boolean, Boolean> indexOnlyPlanInfo) throws AlgebricksException { boolean isIndexOnlyPlan = false; boolean secondaryKeyFieldUsedAfterSelectOrJoinOp = indexOnlyPlanInfo.getSecond(); boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getFourth(); // rest of the code... }
boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getFourth(); List<IOptimizableFuncExpr> matchedFuncExprs = analysisCtx.getMatchedFuncExprs(); boolean noIndexOnlyPlanOption = getNoIndexOnlyOption(context); if (noIndexOnlyPlanOption) { indexOnlyPlanInfo.setFirst(isIndexOnlyPlan); return; } List<LogicalVariable> usedVarsInSelJoinOp = new ArrayList<>(); List<LogicalVariable> usedVarsInSelJoinOpTemp = new ArrayList<>(); // remaining code...
typeEnvironment); if (!matches) { matches = AccessMethodUtils.analyzeFuncExprArgsForTwoVars(funcExpr, analysisCtx); } return matches; return analyzeGetItemFuncExpr(funcExpr, assignsAndUnnests, analysisCtx); public boolean analyzeGetItemFuncExpr(AbstractFunctionCallExpression funcExpr, List<AbstractLogicalOperator> assignsAndUnnests, AccessMethodAnalysisContext analysisCtx) throws AlgebricksException { if (funcExpr.getFunctionIdentifier() != BuiltinFunctions.GET_ITEM) { return false; } ILogicalExpression arg1 = funcExpr.getArguments().get(0).getValue(); ILogicalExpression arg2 = funcExpr.getArguments().get(1).getValue(); if (arg2.getExpressionTag() != LogicalExpressionTag.CONSTANT) { return false; } if (arg1.getExpressionTag() != LogicalExpressionTag.VARIABLE) { return false; } // Rest of the code } OrderedListBuilder orderedList = (OrderedListBuilder) getOrderedListBuilder(); orderedList.reset(orderedListType); for (int iter1 = 0; iter1 < jArray.length(); iter1++) { itemBuffer.reset(); if (writeField(jArray.get(iter1), orderedListType.getItemType(), itemBuffer.getDataOutput())) { orderedList.addItem(itemBuffer); } } orderedList.write(output, true); private boolean writeFieldWithFieldType(Object fieldObj, IAType fieldType, DataOutput out) throws HyracksDataException { boolean writeResult = true; IAType chkFieldType; if (fieldType instanceof AUnionType) { chkFieldType = ((AUnionType) fieldType).getActualType(); } else { chkFieldType = fieldType; } if (chkFieldType != null) { switch (chkFieldType.getTypeTag()) { case STRING: out.write(fieldType.getTypeTag().serialize()); utf8Writer.writeUTF8(fieldObj.toString(), out); break; case INT64: out.write(fieldType.getTypeTag().serialize()); if (fieldObj instanceof Integer) { // Rest of the code } } } }
do { if (subTreeOp.getOperatorTag() == LogicalOperatorTag.SELECT) { subTreeOpRef = subTreeOp.getInputs().get(0); subTreeOp = (AbstractLogicalOperator) subTreeOpRef.getValue(); } if (subTreeOp.getOperatorTag() != LogicalOperatorTag.ASSIGN && subTreeOp.getOperatorTag() != LogicalOperatorTag.UNNEST) { result = initializeDataSource(subTreeOpRef); passedSource = true; if (!subTreeOp.getInputs().isEmpty()) { searchOpRef = subTreeOp.getInputs().get(0); subTreeOp = (AbstractLogicalOperator) searchOpRef.getValue(); } } while (subTreeOp.getOperatorTag() == LogicalOperatorTag.ASSIGN || subTreeOp.getOperatorTag() == LogicalOperatorTag.UNNEST) { if (!OperatorPropertiesUtil.isMovable(subTreeOp)) { return false; } else { getAssignsAndUnnestsRefs().add(subTreeOpRef); getAssignsAndUnnests().add(subTreeOp); } subTreeOpRef = subTreeOp.getInputs().get(0); subTreeOp = (AbstractLogicalOperator) subTreeOpRef.getValue(); } } while (true);
// object creation: should be relatively low btreeCursors = new ITreeIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; bloomFilters = new BloomFilter[numBTrees]; includeMutableComponent = false; for (int i = 0; i < numBTrees; i++) { ILSMComponent component = operationalComponents.get(i); BTree btree = (BTree) component.getIndex(); if (component.getType() == LSMComponentType.MEMORY) { includeMutableComponent = true; bloomFilters[i] = null; } else { bloomFilters[i] = ((LSMBTreeWithBloomFilterDiskComponent) component).getBloomFilter(); } if (btreeAccessors[i] == null) { btreeAccessors[i] = btree.createAccessor(NoOpIndexAccessParameters.INSTANCE); btreeCursors[i] = btreeAccessors[i].createPointCursor(false); } else { // re-use btreeAccessors[i].reset(btree, NoOpOperationCallback.INSTANCE, NoOpOperationCallback.INSTANCE); btreeCursors[i].close(); } } nextHasBeenCalled = false; foundTuple = false; } @Override public void next() throws HyracksDataException { nextHasBeenCalled = true; }
// object creation: should be relatively low btreeCursors = new ITreeIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; bloomFilters = new BloomFilter[numBTrees]; includeMutableComponent = false; for (int i = 0; i < numBTrees; i++) { ILSMComponent component = operationalComponents.get(i); BTree btree = (BTree) component.getIndex(); if (component.getType() == LSMComponentType.MEMORY) { includeMutableComponent = true; bloomFilters[i] = null; } else { bloomFilters[i] = ((LSMBTreeWithBloomFilterDiskComponent) component).getBloomFilter(); } if (btreeAccessors[i] == null) { btreeAccessors[i] = btree.createAccessor(NoOpIndexAccessParameters.INSTANCE); btreeCursors[i] = btreeAccessors[i].createPointCursor(false); } else { // re-use btreeAccessors[i].reset(btree, NoOpOperationCallback.INSTANCE, NoOpOperationCallback.INSTANCE); btreeCursors[i].close(); } } nextHasBeenCalled = false; foundTuple = false; } @Override public void next() throws HyracksDataException { nextHasBeenCalled = true; }
public int compare(ReferenceEntry tp1, ReferenceEntry tp2) { int[] tPointers1 = tp1.getTPointers(); int[] tPointers2 = tp2.getTPointers(); int cmp = NormalizedKeyUtils.compareNormalizeKeys(tPointers1, 0, tPointers2, 0, normalizedKeyLength); if (cmp != 0) { return cmp; } IFrameTupleAccessor fta1 = tp1.getAccessor(); IFrameTupleAccessor fta2 = tp2.getAccessor(); byte[] b1 = fta1.getBuffer().array(); byte[] b2 = fta2.getBuffer().array(); for (int f = 0; f < sortFields.length; ++f) { int c; try { c = comparators[f].compare(b1, tPointers1[2 * f + normalizedKeyLength], tPointers1[2 * f + normalizedKeyLength + 1], b2, tPointers2[2 * f + normalizedKeyLength], tPointers2[2 * f + normalizedKeyLength + 1]); if (c != 0) { return c; } } catch (HyracksDataException e) { // Handle exception } } return 0; }
private void closeDataset(DatasetInfo dsInfo) throws HyracksDataException { synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { Thread.currentThread().interrupt(); throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dataset : openDatasets) { closeDataset(dataset.getDatasetInfo()); } }
if (op2.getOperatorTag() == LogicalOperatorTag.DATASOURCESCAN) { DataSourceScanOperator scan = (DataSourceScanOperator) op2; int n = scan.getVariables().size(); LogicalVariable scanRecordVar = scan.getVariables().get(n - 1); IDataSource<DataSourceId> dataSource = (IDataSource<DataSourceId>) scan.getDataSource(); byte dsType = ((DataSource) dataSource).getDatasourceType(); if (dsType != DataSource.Type.INTERNAL_DATASET && dsType != DataSource.Type.EXTERNAL_DATASET) { return false; } DataSourceId asid = dataSource.getId(); MetadataProvider mp = (MetadataProvider) context.getMetadataProvider(); Dataset dataset = mp.findDataset(asid.getDataverseName(), asid.getDatasourceName()); if (dataset == null) { throw new AlgebricksException("Dataset " + asid.getDatasourceName() + " not found."); } if (dataset.getDatasetType() != DatasetType.INTERNAL) { setAsFinal(access, context, finalAnnot); return false; } String tName = dataset.getItemTypeName(); }
buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); if (oldValueSize > 0) { buffer.putInt(oldValueSize); buffer.putInt(oldValueFieldCount); writeTuple(buffer, oldValue, oldValueSize); } break; case LogType.FILTER: writeEntityResource(buffer); buffer.putLong(resourceId); buffer.putInt(logSize); buffer.putInt(newValueFieldCount); buffer.put(newOp); buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); break; case LogType.FLUSH: buffer.putInt(datasetId); break; case LogType.MARKER: buffer.putInt(datasetId); buffer.putInt(resourcePartition); callback.before(buffer); buffer.putInt(logSize); buffer.put(marker); break; default: // Do nothing
package org.apache.hyracks.storage.am.common.api; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.hyracks.storage.common.IModificationOperationCallback; public interface IExtendedModificationOperationCallback extends IModificationOperationCallback { void after(ITupleReference after) throws HyracksDataException; }
public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { return createAccessor(createOpContext((IExtendedModificationOperationCallback) iap.getModificationCallback(), iap.getSearchOperationCallback())); }
public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { return createAccessor(createOpContext(((IExtendedModificationOperationCallback) (iap.getModificationCallback())), iap.getSearchOperationCallback())); }
if (minTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); minTupleBytes = new byte[numBytes]; opCallback.after(tuple); logged = true; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); minTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, minTuple); if (c < 0) { if (!logged) { opCallback.after(tuple); logged = true; } int numBytes = tupleWriter.bytesRequired(tuple); if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); // ... rest of the code }
if (minTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); minTupleBytes = new byte[numBytes]; opCallback.after(tuple); logged = true; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); minTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, minTuple); if (c < 0) { if (!logged) { opCallback.after(tuple); logged = true; } int numBytes = tupleWriter.bytesRequired(tuple); if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); // rest of the code }
if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if (!logged) { opCallback.after(tuple); logged = true; } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if (!logged) { opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) { // resize maxTupleBytes if necessary } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); } }
minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if (!logged) { opCallback.after(tuple); logged = true; } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if (!logged) { opCallback.after(tuple); logged = true; } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) { maxTupleBytes = new byte[numBytes]; } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } }
int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if (!logged) { opCallback.after(tuple); logged = true; } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if (!logged) { opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) { maxTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); } else { tupleWriter.writeTuple(tuple, maxTupleBytes, 0); } ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } } } @Override public ITupleReference getMinTuple() { return minTuple; } @Override
import org.apache.hyracks.algebricks.core.algebra.metadata.IMetadataProvider; /** * This class is the type computer for not-missing function. * If the input type is not a union, we just return it. * If the input type is a union, * case 1: we return a new union without missing if the new union still has more than one types; * case 2: we return the non-missing item type in the original union if there are only missing and it in the original union. */ public class NotMissingTypeComputer implements IResultTypeComputer { public static final NotMissingTypeComputer INSTANCE = new NotMissingTypeComputer(); @Override public IAType computeType(ILogicalExpression expression, IVariableTypeEnvironment env, IMetadataProvider<?, ?> metadataProvider) throws AlgebricksException { AbstractFunctionCallExpression f = (AbstractFunctionCallExpression) expression; IAType type = (IAType) env.getType(f.getArguments().get(0).getValue()); if (type.getTypeTag() != ATypeTag.UNION) { // directly return the input type if it is not a union return type; } } } .createTuplePairComparator(ctx); final ITuplePairComparator nljComparatorBuild2Probe = tuplePairComparatorFactoryBuild2Probe.createTuplePairComparator(ctx); final IPredicateEvaluator predEvaluator = (predEvaluatorFactory == null ? null : predEvaluatorFactory.createPredicateEvaluator()); for (int i = 0; i < comparatorFactories.length; i++) { comparators[i] = comparatorFactories[i].createBinaryComparator(); } final IMissingWriter[] nonMatchWriter = isLeftOuter ? new IMissingWriter[nonMatchWriterFactories.length] : null; final ArrayTupleBuilder nullTupleBuild = isLeftOuter ? new ArrayTupleBuilder(buildRd.getFieldCount()) : null; if (isLeftOuter) { DataOutput out = nullTupleBuild.getDataOutput(); for (int i = 0; i < nonMatchWriterFactories.length; i++) { nonMatchWriter[i] = nonMatchWriterFactories[i].createMissingWriter(); nonMatchWriter[i].writeMissing(out); nullTupleBuild.addFieldEndOffset(); } } IOperatorNodePushable op = new AbstractUnaryInputUnaryOutputOperatorNodePushable() { private BuildAndPartitionTaskState state; private
public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { LSMRTreeOpContext opCtx = createOpContext((IExtendedModificationOperationCallback) iap.getModificationCallback(), iap.getSearchOperationCallback()); return new LSMTreeIndexAccessor(getHarness(), opCtx, cursorFactory); }
public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { LSMRTreeOpContext opCtx = createOpContext(((IExtendedModificationOperationCallback) (iap.getModificationCallback())), iap.getSearchOperationCallback()); return new LSMTreeIndexAccessor(getHarness(), opCtx, cursorFactory); }
public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { LSMRTreeOpContext opCtx = createOpContext((IExtendedModificationOperationCallback) iap.getModificationCallback(), iap.getSearchOperationCallback()); return new LSMTreeIndexAccessor(getHarness(), opCtx, cursorFactory); }
// may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker. flushAndWaitForIO(dsInfo, iInfo); } } private void closeDataset(DatasetInfo dsInfo) throws HyracksDataException { // First wait for any ongoing IO operations synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { // First wait for any ongoing IO operations for (DatasetInfo dsInfo : datasetInfos.values()) { synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } } // Close all datasets for (DatasetInfo dsInfo : datasetInfos.values()) { closeDataset(dsInfo); } }
// may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker. flushAndWaitForIO(dsInfo, iInfo); } } private void closeDataset(DatasetInfo dsInfo) throws HyracksDataException { // First wait for any ongoing IO operations synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { // First wait for any ongoing IO operations for (DatasetInfo dsInfo : datasetInfos.values()) { synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { Thread.currentThread().interrupt(); } } } } for (DatasetInfo dsInfo : datasetInfos.values()) { closeDataset(dsInfo); } }
} catch (HyracksDataException e) { datasetLifecycleManager.close(localResource.getPath()); throw e; } resourceId2MaxLSNMap.put(resourceId, maxDiskLastLsn); } else { maxDiskLastLsn = resourceId2MaxLSNMap.get(resourceId); } if (lsn >= maxDiskLastLsn) { redo(logRecord, datasetLifecycleManager); redoCount++; } break; case LogType.JOB_COMMIT: case LogType.ENTITY_COMMIT: case LogType.ABORT: case LogType.FLUSH: case LogType.WAIT: case LogType.MARKER: //do nothing break; default: throw new ACIDException("Unsupported LogType: " + logRecord.getLogType()); } logRecord = logReader.next(); } LOGGER.info("Logs REDO phase completed. Redo logs count: " + redoCount); } finally {
int numBytes = tupleWriter.bytesRequired(tuple); minTupleBytes = new byte[numBytes]; opCallback.after(tuple); logged = true; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); minTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, minTuple); if (c < 0) { if (!logged) { opCallback.after(tuple); logged = true; } int numBytes = tupleWriter.bytesRequired(tuple); if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; } tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple);
minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if (!logged) { opCallback.after(tuple); logged = true; } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if (!logged) { opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) { maxTupleBytes = new byte[numBytes]; } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } }
return pin(dpid, newPage, null); } @Override public ICachedPage pin(long dpid, boolean newPage, ILargePageHelper helper) throws HyracksDataException { if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { while (confiscatedPages.contains(c)) { throw new IllegalStateException(); } } } } finally { confiscateLock.unlock(); } } synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } }
return pin(dpid, newPage, null); } @Override public ICachedPage pin(long dpid, boolean newPage, ILargePageHelper helper) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { while (confiscatedPages.contains(c)) { throw new IllegalStateException(); } } } } finally { confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } }
return pin(dpid, newPage, null); } @Override public ICachedPage pin(long dpid, boolean newPage, ILargePageHelper helper) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { while (confiscatedPages.contains(c)) { throw new IllegalStateException(); } } } } finally { confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } }
return null; } }); } for(int i=0;i<bufferCacheNumPages;i++){ synchronized (readers[i]){ while(readers[i].getValue() == null){ readers[i].wait(); } } } final long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start < duration){ for(int i=0;i<bufferCacheNumPages;i++){ readers[i].getValue().interrupt(); } wait(25); } try { for (int i = 0; i < bufferCacheNumPages; i++) { futures[i].get(); } } finally { bufferCache.deleteFile(fileId); bufferCache.close(); } } @Test public void simpleOpenPinCloseTest() throws HyracksException { TestStorageManagerComponentHolder.init(PAGE_SIZE, NUM_PAGES, MAX_OPEN_FILES); IBufferCache bufferCache = TestStorageManagerComponentHolder.getBufferCache(ctx.getJobletContext().getServiceContext()); IIOManager ioManager = TestStorageManagerComponentHolder.getIOManager(); String fileName = getFileName(); FileReference file = ioManager.resolve(fileName);
this.btreePred = (RangePredicate) searchPred; btreeAccessor.search(btreeCursor, btreePred); openInvListRangeSearchCursor(); @Override public boolean hasNext() throws HyracksDataException { // No more results possible if (!isInvListCursorOpen) { return false; } if (invListRangeSearchCursor.hasNext()) { return true; } // The current inverted-list-range-search cursor is exhausted. if (isInvListCursorOpen) { invListRangeSearchCursor.close(); isInvListCursorOpen = false; } openInvListRangeSearchCursor(); return isInvListCursorOpen; } @Override public void next() throws HyracksDataException { invListRangeSearchCursor.next(); if (concatTuple.hasMaxTuples()) { concatTuple.removeLastTuple(); } concatTuple.addTuple(invListRangeSearchCursor.getTuple()); } @Override public void destroy() throws HyracksDataException { if (isInvListCursorOpen) { invListRangeSearchCursor.unloadPages(); invListRangeSearchCursor.destroy(); isInvListCursorOpen = false; } btreeCursor.destroy(); } @Override
// Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { while (confiscatedPages.contains(c)) { throw new IllegalStateException(); } } } } finally { confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } pageReplacementStrategy.notifyCachePageAccess(cPage); if (DEBUG) { pinnedPageOwner.put((CachedPage) cPage, Thread.currentThread().getStackTrace()); } cPage.setLargePageHelper(helper);
// Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { while (confiscatedPages.contains(c)) { throw new IllegalStateException(); } } } } finally { confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } pageReplacementStrategy.notifyCachePageAccess(cPage); if (DEBUG) { pinnedPageOwner.put((CachedPage) cPage, Thread.currentThread().getStackTrace()); } cPage.setLargePageHelper(helper);
// Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { while (confiscatedPages.contains(c)) { throw new IllegalStateException(); } } } } finally { confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } pageReplacementStrategy.notifyCachePageAccess(cPage); if (DEBUG) { pinnedPageOwner.put((CachedPage) cPage, Thread.currentThread().getStackTrace()); } cPage.setLargePageHelper(helper);
protected void doStop() { log.info("Stopping client"); wrkr.shutdownGracefully(); try { sock.channel().closeFuture().sync(); } catch (InterruptedException e) { log.warn("Client stop interrupted"); Thread.currentThread().interrupt(); } log.info("Client stopped"); notifyStopped(); } out.add(result); return out; } catch (IOException e) { throw new OrmException(e); } catch (ParseException e) { throw new OrmException(e); } protected Directory readIndexDirectory() throws IOException { Directory dir = new RAMDirectory(); byte[] buffer = new byte[4096]; InputStream index = QueryDocumentationFilter.class.getClassLoader().getResourceAsStream(INDEX_PATH); if (index == null) { log.warn("No index available"); return null; } ZipInputStream zip = new ZipInputStream(index); try { ZipEntry entry; while ((entry = zip.getNextEntry()) != null) { IndexOutput out = dir.createOutput(entry.getName(), null); int count; while ((count = zip.read(buffer)) != -1) { out.writeBytes(buffer, count); } out.close(); } } finally { zip.close(); } // We must NOT call dir.close() here, as DirectoryReader.open() expects an opened directory. return dir; } ((Interface2Builder) parentBuilder).setIpv4(readValue); } @Nonnull @Override public Ipv4Builder getBuilder(@Nonnull final InstanceIdentifier<Ipv4> id) { return new Ipv4Builder(); } @Override public void readCurrentAttributes(@Nonnull final InstanceIdentifier<Ipv4> id, @Nonnull final Ipv4Builder builder, @Nonnull final ReadContext ctx) throws ReadFailedException { LOG.warn("Operation not supported"); } pageReplacementStrategy.notifyCachePageAccess(cPage); return cPage; } cPage = cPage.next; } } finally { bucket.bucketLock.unlock(); } return cPage; } @Override public ICachedPage pin(long dpid, boolean newPage) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid); if (!newPage)
CachedPage cPage = findPage(dpid); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally { confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage); cPage.valid = true; } } } else { try { tryRead(cPage); } finally { if (!cPage.valid) { unpin(cPage); } } } return cPage;
package org.apache.hyracks.storage.common; import java.io.File; import java.text.SimpleDateFormat; import java.util.ArrayList; import java.util.Date; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Random; import java.util.concurrent.*; import java.util.concurrent.atomic.AtomicInteger; import org.apache.commons.lang3.mutable.Mutable; import org.apache.commons.lang3.mutable.MutableObject; import org.apache.hyracks.api.context.IHyracksTaskContext; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.api.exceptions.HyracksException; import org.apache.hyracks.api.io.FileReference; import org.apache.hyracks.api.io.IIOManager; import org.apache.hyracks.storage.common.buffercache.CachedPage; import org.apache.hyracks.storage.common.buffercache.IBufferCache; import org.apache.hyracks.storage.common.buffercache.ICachedPage; import org.apache.hyracks.storage.common.file.BufferedFileHandle; public class StorageUtils { private static final int MAX_OPEN_FILES = 100; private static final int MAX_OPEN_FILES_THRESHOLD = (int) (MAX_OPEN_FILES * 0.9); private static final int MAX_OPEN_FILES_WAIT_TIME = 100; private static final int MAX_OPEN_FILES_WAIT_ATTEMPTS = 10; private static final int MAX_OPEN_FILES_WAIT_BACKOFF = 10; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_ATTEMPTS = 10; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_THRESHOLD = 100; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_MAX = 1000; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_MAX_ATTEMPTS = 10; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_MAX_THRESHOLD = 1000; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_MAX_MAX = 10000; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_MAX_MAX_ATTEMPTS = 10; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_MAX_MAX_THRESHOLD = 10000; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_MAX_MAX_MAX = 100000; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_MAX_MAX_MAX_ATTEMPTS = 10; private static final int MAX_OPEN_FILES_WAIT_BACKOFF_MAX_MAX_MAX_THRESHOLD = 100000; private static final int MAX_OPEN_FILES_WAIT
private final IFrameWriter writer; private final MutableBoolean failed; public ForwardingFrameWriter(IFrameWriter writer) { this.writer = writer; this.failed = new MutableBoolean(false); } @Override public void setInputRecordDescriptor(int index, RecordDescriptor recordDescriptor) { // input is not accessed } @Override public void open() throws HyracksDataException { if (idx == 0) { writer.open(); } } @Override public void nextFrame(ByteBuffer buffer) throws HyracksDataException { writer.nextFrame(buffer); } @Override public void fail() throws HyracksDataException { boolean wasFailed = this.failed.getValue(); this.failed.setValue(true); if (!wasFailed) { writer.fail(); } } @Override public void close() throws HyracksDataException { if (idx == 0) { writer.close(); } }
int n = subplans.size(); AlgebricksPipeline[] result = new AlgebricksPipeline[n]; for (int i = 0; i < n; i++) { List<AlgebricksPipeline> subplanOps = subplans.get(i); if (subplanOps.size() != 1) { throw new AlgebricksException("Attempting to construct a nested plan with " + subplanOps.size() + " operator descriptors. Currently, nested plans can only consist in linear pipelines of Asterix micro operators."); } result[i] = subplanOps.get(0); } return result; } protected List<List<AlgebricksPipeline>> compileSubplansImpl(IOperatorSchema outerPlanSchema, AbstractOperatorWithNestedPlans npOp, IOperatorSchema opSchema, JobGenContext context) throws AlgebricksException { List<List<AlgebricksPipeline>> subplans = new ArrayList<>(npOp.getNestedPlans().size()); PlanCompiler pc = new PlanCompiler(context); for (ILogicalPlan p : npOp.getNestedPlans()) { subplans.add(buildPipelineWithProjection(p, outerPlanSchema, npOp, opSchema, pc)); } return subplans; }
context.getTypeEnvironment(op.getInputs().get(0).getValue()), inputSchemas[0], context); IMissingWriterFactory[] missingWriterFactories = new IMissingWriterFactory[np.get(0).getOutputWidth()]; for (int i = 0; i < missingWriterFactories.length; i++) { missingWriterFactories[i] = context.getMissingWriterFactory(); } RecordDescriptor recDesc = JobGenHelper.mkRecordDescriptor(context.getTypeEnvironment(op), opSchema, context); SubplanRuntimeFactory runtime = new SubplanRuntimeFactory(np, missingWriterFactories, inputRecordDesc, recDesc, null); builder.contributeMicroOperator(subplan, runtime, recDesc); ILogicalOperator src = op.getInputs().get(0).getValue(); builder.contributeGraphEdge(src, 0, op, 0); } @Override public boolean expensiveThanMaterialization() { return true; }
public void setInputRecordDescriptor(int index, RecordDescriptor recordDescriptor) { // TODO: Implement this method throw new UnsupportedOperationException("Not implemented yet"); }
return useConnectorPolicyForScheduling; } public void setUseConnectorPolicyForScheduling(boolean useConnectorPolicyForScheduling) { this.useConnectorPolicyForScheduling = useConnectorPolicyForScheduling; } public void setRequiredClusterCapacity(IClusterCapacity capacity) { this.requiredClusterCapacity = capacity; } public IClusterCapacity getRequiredClusterCapacity() { return requiredClusterCapacity; } public void setMetaOps(List<IOperatorDescriptor> metaOps) { this.metaOps = metaOps; } public List<IOperatorDescriptor> getMetaOps() { return metaOps; } private <K, V> void insertIntoIndexedMap(Map<K, List<V>> map, K key, int index, V value) { List<V> vList = map.computeIfAbsent(key, k -> new ArrayList<>()); extend(vList, index); vList.set(index, value); } @Override public String toString() { StringBuilder buffer = new StringBuilder(); opMap.forEach((key, value) -> { buffer.append(key.getId()).append(" : ").append(value.toString()).append("\n"); }); return buffer.toString(); }
* * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.ipc.impl; import org.apache.hyracks.ipc.api.IIPCEventListener; public class NoOpIPCEventListener implements IIPCEventListener { private NoOpIPCEventListener() { } public static final IIPCEventListener INSTANCE = new NoOpIPCEventListener(); }
return new BloomFilterBuilder(numElements, numHashes, numBitsPerElement); } public class BloomFilterBuilder implements IIndexBulkLoader { private final long[] hashes = BloomFilter.createHashArray(); private final long numElements; private final int numHashes; private final long numBits; private final int numPages; private final IFIFOPageQueue queue; private final ICachedPage[] pages; private ICachedPage metaDataPage = null; public BloomFilterBuilder(long numElements, int numHashes, int numBitsPerElement) throws HyracksDataException { if (!isActivated) { throw HyracksDataException.create(ErrorCode.CANNOT_CREATE_BLOOM_FILTER_BUILDER_FOR_INACTIVE_FILTER); } queue = bufferCache.createFIFOQueue(); this.numElements = numElements; this.numHashes = numHashes; numBits = this.numElements * numBitsPerElement; long tmp = (long) Math.ceil(numBits / (double) numBitsPerPage); if (tmp > Integer.MAX_VALUE) { throw HyracksDataException.create(ErrorCode.CANNOT_CREATE_BLOOM_FILTER_WITH_NUMBER_OF_PAGES, tmp); } numPages = (int) tmp; pages = new ICachedPage[numPages]; } }
import org.apache.hyracks.tests.util.NoOpOperatorDescriptor; import org.junit.Assert; import org.junit.Test; public class JobFailureTest extends AbstractMultiNCIntegrationTest { @Test public void failureOnCreatePushRuntime() throws Exception { JobId jobId = null; for (int i = 0; i < 20; i++) { JobSpecification spec = new JobSpecification(); JobId runJobId = runTest(spec, new ExceptionOnCreatePushRuntimeOperatorDescriptor(spec, 0, 1, new int[]{4}, true)); if (i == 0) { jobId = runJobId; waitForCompletion(jobId, ExceptionOnCreatePushRuntimeOperatorDescriptor.ERROR_MESSAGE); } } waitForCompletion(jobId, ExceptionOnCreatePushRuntimeOperatorDescriptor.ERROR_MESSAGE); for (int i = 0; i < 300; i++) { JobSpecification spec = new JobSpecification(); runTest(spec, new ExceptionOnCreatePushRuntimeOperatorDescriptor(spec, 0, 1, new int[] { 4 }, true)); } } }
Fixed Code: ```java package org.apache.asterix.api.http.server; import java.util.Map; import java.util.UUID; import java.util.concurrent.ConcurrentMap; import java.util.concurrent.TimeUnit; import java.util.concurrent.TimeoutException; import java.util.function.Function; import org.apache.asterix.algebra.base.ILangExtension; import org.apache.asterix.app.message.CancelQueryRequest; import org.apache.asterix.app.message.ExecuteStatementRequestMessage; import org.apache.asterix.app.message.ExecuteStatementResponseMessage; import org.apache.asterix.app.result.ResultReader; import org.apache.asterix.common.api.Duration; import org.apache.asterix.common.api.IApplicationContext; import org.apache.asterix.common.config.GlobalConfig; import org.apache.asterix.common.exceptions.ErrorCode; import org.apache.asterix.common.exceptions.ExceptionUtils; import org.apache.asterix.common.exceptions.RuntimeDataException; import org.apache.asterix.common.messaging.api.INCMessageBroker; import javax.xml.transform.Result; public class MyClass { // code here } ```
channel.abort(); } finally { channel.close(); resultState.readClose(); // if resultState has been exhausted, delete the result partition if (resultState.isExhausted()) { datasetPartitionManager.removePartition(resultState.getResultSetPartitionId().getJobId(), resultState.getResultSetPartitionId().getResultSetId(), resultState.getResultSetPartitionId().getPartition()); } } catch (HyracksDataException e) { LOGGER.error("unexpected failure in partition reader", e); } if (LOGGER.isInfoEnabled()) { LOGGER.info("result reading successful(" + resultState.getResultSetPartitionId() + ")"); }
package org.apache.asterix.translator; import java.util.Map; import org.apache.asterix.translator.IStatementExecutor.Stats; import org.apache.hyracks.api.dataset.IHyracksDataset; public interface IRequestParameters { IHyracksDataset getHyracksDataset(); ResultProperties getResultProperties(); Stats getStats(); IStatementExecutor.ResultMetadata getOutMetadata(); String getClientContextId(); Map<String, String> getOptionalParameters(); }
package org.apache.hyracks.storage.am.common.api; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.hyracks.storage.common.IIndexCursor; public interface ILSMIndexCursor extends IIndexCursor { ITupleReference getFilterMinTuple(); ITupleReference getFilterMaxTuple(); }
```java /* * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.common.api; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.hyracks.storage.common.IIndexCursor; public interface ILSMIndexCursor extends IIndexCursor { ITupleReference getFilterMinTuple(); ITupleReference getFilterMaxTuple(); } ```
AbstractLogicalOperator op2 = (AbstractLogicalOperator) opRef2.getValue(); if (op2.getOperatorTag() == LogicalOperatorTag.PROJECT || context.checkAndAddToAlreadyCompared(access, op2) && !(op2.getOperatorTag() == LogicalOperatorTag.SELECT && isAccessToIndexedField(access, context))) { return false; } Object annotation = op2.getAnnotations().get(IS_MOVABLE); if (annotation != null && !((Boolean) annotation)) { return false; } if (tryingToPushThroughSelectionWithSameDataSource(access, op2)) { return false; } if (testAndModifyRedundantOp(access, op2)) { propagateFieldAccessRec(opRef2, context, finalAnnot); return true; } List<LogicalVariable> usedInAccess = new LinkedList<>(); VariableUtilities.getUsedVariables(access, usedInAccess); List<LogicalVariable> produced2 = new LinkedList<>(); if (op2.getOperatorTag() == LogicalOperatorTag.GROUP) { VariableUtilities.getLiveVariables(op2, produced2); }
import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalOperator; import org.apache.hyracks.algebricks.core.algebra.base.LogicalVariable; import org.apache.hyracks.algebricks.core.algebra.properties.VariablePropagationPolicy; import org.apache.hyracks.algebricks.core.algebra.visitors.ILogicalExpressionReferenceTransform; import java.util.HashMap; import java.util.Map; public abstract class AbstractBinaryJoinOperator extends AbstractLogicalOperator { protected final Mutable<ILogicalExpression> condition; protected JoinKind joinKind; public Map<Integer, Integer> getPhaseToInput() { return phaseToInput; } protected Map<Integer,Integer> phaseToInput; public enum JoinKind { INNER, LEFT_OUTER } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition) { this.joinKind = joinKind; this.condition = condition; this.phaseToInput = new HashMap<>(); phaseToInput.put(0,1); phaseToInput.put(1,0); } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition, Mutable<ILogicalOperator> input1, Mutable<ILogicalOperator> input2) { this(joinKind, condition); this.input1 = input1; this.input2 = input2; } }
import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalOperator; import org.apache.hyracks.algebricks.core.algebra.base.LogicalVariable; import org.apache.hyracks.algebricks.core.algebra.properties.VariablePropagationPolicy; import org.apache.hyracks.algebricks.core.algebra.visitors.ILogicalExpressionReferenceTransform; public abstract class AbstractBinaryJoinOperator extends AbstractLogicalOperator { protected final Mutable<ILogicalExpression> condition; protected JoinKind joinKind; protected Map<Integer, Integer> phaseToInput; public enum JoinKind { INNER, LEFT_OUTER } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition) { this.joinKind = joinKind; this.condition = condition; this.phaseToInput = new HashMap<>(); phaseToInput.put(0, 1); phaseToInput.put(1, 0); } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition, Mutable<ILogicalOperator> input1, Mutable<ILogicalOperator> input2) { this(joinKind, condition); inputs.add(input1); inputs.add(input2); } public Map<Integer, Integer> getPhaseToInput() { return phaseToInput; } }
if (connection != null) { inp.put("input", connection.getLeft().getLeft().getOperatorId().toString()); } if (pleObject.size() > 0) { pcObject.set("location", pleObject); } if (pcObject.size() > 0) { op.set("partition-constraints", pcObject); } if (inp.size() > 0) { op.set("inputs", inp); } jopArray.add(op); }); jjob.set("operators", jopArray); ArrayNode jcArray = om.createArrayNode(); connMap.forEach((key, value) -> { ObjectNode conn = om.createObjectNode(); Pair<Pair<IOperatorDescriptor, Integer>, Pair<IOperatorDescriptor, Integer>> connection = connectorOpMap.get(key); if (connection != null) { conn.put("in-operator-id", connection.getLeft().getLeft().getOperatorId().toString()); conn.put("in-operator-port", connection.getLeft().getRight().intValue()); } // rest of the code });
} } return false; } /** * Executes the passed interruptible, retrying if the operation fails due to {@link ClosedByInterruptException}. * Once the interruptible completes, the current thread will be re-interrupted, if the original operation was * interrupted. */ public static void doIoUninterruptibly(ThrowingIOInterruptible interruptible) throws IOException { boolean interrupted = false; try { while (true) { try { interruptible.run(); break; } catch (ClosedByInterruptException e) { LOGGER.error("IO operation Interrupted. Retrying..", e); interrupted = true; Thread.interrupted(); } } } finally { if (interrupted) { Thread.currentThread().interrupt(); } } } @FunctionalInterface public interface Interruptible { void run() throws InterruptedException; } @FunctionalInterface public interface ThrowingInterruptible { void run() throws Exception; // NOSONAR } @FunctionalInterface public interface ThrowingIOInterruptible { void run() throws IOException; } }
import java.io.IOException; import java.nio.channels.ClosedByInterruptException; public class InterruptibleUtils { private static final Logger LOGGER = LoggerFactory.getLogger(InterruptibleUtils.class); public static void runInterruptible(Interruptible action) { boolean interrupted = false; try { while (true) { try { action.run(); break; } catch (ClosedByInterruptException e) { LOGGER.error("IO operation Interrupted. Retrying..", e); interrupted = true; Thread.interrupted(); } } } catch (InterruptedException e) { interrupted = true; } finally { if (interrupted) { Thread.currentThread().interrupt(); } } } @FunctionalInterface public interface Interruptible { void run() throws InterruptedException; } @FunctionalInterface public interface ThrowingInterruptible { void run() throws Exception; } @FunctionalInterface public interface ThrowingIOInterruptible { void run() throws IOException; } }
if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Substitute node joining : " + serviceContext.getNodeId()); } updateOnNodeJoin(); appContext.initialize(initialRun); MessagingProperties messagingProperties = ((IPropertiesProvider) appContext).getMessagingProperties(); messageBroker = new NCMessageBroker(controllerService, messagingProperties); serviceContext.setMessageBroker(messageBroker); MessagingChannelInterfaceFactory interfaceFactory = new MessagingChannelInterfaceFactory((NCMessageBroker) messageBroker, messagingProperties); serviceContext.setMessagingChannelInterfaceFactory(interfaceFactory); boolean replicationEnabled = ClusterProperties.INSTANCE.isReplicationEnabled(); boolean autoFailover = ClusterProperties.INSTANCE.isAutoFailoverEnabled(); if (initialRun) { LOGGER.info("System is being initialized. (first run)"); } else { IRecoveryManager recoveryMgr = appContext.getTransactionSubsystem().getRecoveryManager(); systemState = recoveryMgr.getSystemState(); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("System is in a state: " + systemState); } //do not attempt to perform remote recovery if this is a virtual NC if (autoFailover && !virtualNC) { // Perform remote recovery } }
if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Substitute node joining : " + serviceContext.getNodeId()); } updateOnNodeJoin(); appContext.initialize(initialRun); MessagingProperties messagingProperties = ((IPropertiesProvider) appContext).getMessagingProperties(); messageBroker = new NCMessageBroker(controllerService, messagingProperties); serviceContext.setMessageBroker(messageBroker); MessagingChannelInterfaceFactory interfaceFactory = new MessagingChannelInterfaceFactory((NCMessageBroker) messageBroker, messagingProperties); serviceContext.setMessagingChannelInterfaceFactory(interfaceFactory); boolean replicationEnabled = ClusterProperties.INSTANCE.isReplicationEnabled(); boolean autoFailover = ClusterProperties.INSTANCE.isAutoFailoverEnabled(); if (initialRun) { LOGGER.info("System is being initialized. (first run)"); } else { IRecoveryManager recoveryMgr = appContext.getTransactionSubsystem().getRecoveryManager(); systemState = recoveryMgr.getSystemState(); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("System is in a state: " + systemState); } //do not attempt to perform remote recovery if this is a virtual NC if (autoFailover && !virtualNC) { latestCheckpoint = recoveryMgr.getLatestCheckpoint(); } }
int n = subplans.size(); AlgebricksPipeline[] result = new AlgebricksPipeline[n]; for (int i = 0; i < n; i++) { List<AlgebricksPipeline> subplanOps = subplans.get(i); if (subplanOps.size() != 1) { throw new AlgebricksException("Attempting to construct a nested plan with " + subplanOps.size() + " operator descriptors. Currently, nested plans can only consist in linear pipelines."); } result[i] = subplanOps.get(0); } return result; } protected List<List<AlgebricksPipeline>> compileSubplansImpl(IOperatorSchema outerPlanSchema, AbstractOperatorWithNestedPlans npOp, IOperatorSchema opSchema, JobGenContext context) throws AlgebricksException { List<List<AlgebricksPipeline>> subplans = new ArrayList<>(npOp.getNestedPlans().size()); PlanCompiler pc = new PlanCompiler(context); for (ILogicalPlan p : npOp.getNestedPlans()) { subplans.add(buildPipelineWithProjection(p, outerPlanSchema, npOp, opSchema, pc)); } return subplans; }
opSchema.addAllVariables(topOpInSubplanScm); Map<OperatorDescriptorId, IOperatorDescriptor> opMap = nestedJob.getOperatorMap(); List<? extends IOperatorDescriptor> metaOps = nestedJob.getMetaOps(); if (opMap.size() != metaOps.size()) { for (IOperatorDescriptor opd : opMap.values()) { if (!(opd instanceof AlgebricksMetaOperatorDescriptor)) { throw new AlgebricksException("Can only generate jobs for pipelinable nested plans, not for " + opd.getClass().getName()); } } throw new IllegalStateException(); } List<AlgebricksPipeline> result = new ArrayList<>(metaOps.size()); for (IOperatorDescriptor opd : metaOps) { AlgebricksMetaOperatorDescriptor amod = (AlgebricksMetaOperatorDescriptor) opd; result.add(amod.getPipeline()); } return result;
Map<OperatorDescriptorId, IOperatorDescriptor> opMap = nestedJob.getOperatorMap(); List<? extends IOperatorDescriptor> metaOps = nestedJob.getMetaOps(); if (opMap.size() != metaOps.size()) { for (IOperatorDescriptor opd : opMap.values()) { if (!(opd instanceof AlgebricksMetaOperatorDescriptor)) { throw new AlgebricksException("Can only generate Hyracks jobs for pipelinable Asterix nested plans, not for " + opd.getClass().getName()); } } throw new IllegalStateException(); } List<AlgebricksPipeline> result = new ArrayList<>(metaOps.size()); for (IOperatorDescriptor opd : metaOps) { AlgebricksMetaOperatorDescriptor amod = (AlgebricksMetaOperatorDescriptor) opd; result.add(amod.getPipeline()); } return result;
final String message); public void raiseError(final String message) throws Exception; public void waitForUserAcknowledgement(final String message); public void appendText(String text); }; public final String TAG = "PowerTestApp"; private final static String RESPONSE_OK = "OK"; private final static String RESPONSE_ERR = "ERR"; public final static String SOCKET_NAME = "/android/cts/powertest"; private static final int BUFFER_SIZE = 4096; private byte[] mBuffer; private LocalServerSocket mServerSocket; private volatile boolean mStopThread; private final SensorManager mSensorManager; private final PowerManager mPowerManager; private final Context mContext; private final Listener mListener; private boolean mConnected = false; public PowerTestHostLink(Context context, final Listener listener) { Log.d(TAG, " +++ Begin of localSocketServer() +++ "); mListener = listener; mBuffer = new byte[BUFFER_SIZE]; mContext = context; try { mServerSocket = new LocalServerSocket(SOCKET_NAME);
RecordDescriptor pipelineLastRecordDescriptor = pipeline.getRecordDescriptors()[pipeline.getRecordDescriptors().length - 1]; RecordDescriptor outputRecordDescriptor; IFrameWriter outputWriter; if (i == 0) { // primary pipeline outputWriter = new TupleOuterProduct(pipelineLastRecordDescriptor, missingWriters); outputRecordDescriptor = SubplanRuntimeFactory.this.outputRecordDesc; } else { // secondary pipeline IPushRuntime outputPushRuntime = linkSecondaryPipeline(pipeline, pipelineAssemblers, i); if (outputPushRuntime == null) { throw new IllegalStateException(); } outputPushRuntime.setInputRecordDescriptor(0, pipelineLastRecordDescriptor); outputWriter = outputPushRuntime; outputRecordDescriptor = pipelineLastRecordDescriptor; } PipelineAssembler pa = new PipelineAssembler(pipeline, 1, 1, inputRecordDesc, outputRecordDescriptor); startOfPipelines[i] = (NestedTupleSourceRuntime) pa.assemblePipeline(outputWriter, ctx); pipelineAssemblers[i] = pa; } IPushRuntime linkSecondaryPipeline(AlgebricksPipeline pipeline, PipelineAssembler[] pipelineAssemblers, int pipelineAssemblersCount) { IPushRuntimeFactory[] outputRuntimeFactories = pipeline.getOutputRuntimeFactories();
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } int temp = n; if (temp > 0b11) { temp >>>= 2; log |= 2; } return log + (temp >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public static int log2Floor(int n) { assert n >= 1; int log = 0; if (n > 0xffff) { n >>>= 16; log = 16; } if (n > 0xff) { n >>>= 8; log |= 8; } if (n > 0xf) { n >>>= 4; log |= 4; } if (n > 0b11) { n >>>= 2; log |= 2; } return log + (n >>> 1); }
public Ini toIni(boolean includeDefaults) { Ini ini = new Ini(); (includeDefaults ? configurationMap : definedMap).forEach((option, value) -> { if (value != null) { ini.add(option.section().sectionName(), option.ini(), option.type().serializeToIni(value)); } }); getSections().forEach(section -> { ini.add(section.sectionName()); }); nodeSpecificMap.forEach((key, nodeValueMap) -> { String section = Section.NC.sectionName() + "/" + key; synchronized (nodeValueMap) { for (Map.Entry<IOption, Object> entry : nodeValueMap.entrySet()) { if (entry.getValue() != null) { final IOption option = entry.getKey(); ini.add(section, option.ini(), option.type().serializeToIni(entry.getValue())); } } } }); extensionOptions.forEach((extension, options) -> { options.forEach(option -> ini.add(extension, option.getKey(), option.getValue())); }); return ini; }
public void sendApplicationMessageToCC(byte[] data, DeploymentId deploymentId, String nodeId) throws Exception; public void registerResultPartitionLocation(JobId jobId, ResultSetId rsId, boolean orderedResult, boolean emptyResult, int partition, int nPartitions, NetworkAddress networkAddress) throws Exception; public void reportResultPartitionWriteCompletion(JobId jobId, ResultSetId rsId, int partition) throws Exception; public void reportResultPartitionFailure(JobId jobId, ResultSetId rsId, int partition, HyracksDataException cause) throws Exception; public void getNodeControllerInfos() throws Exception; public void notifyThreadDump(String nodeId, String requestId, String threadDumpJSON) throws Exception;
List<TaskAttemptDescriptor> taskDescriptors, Map<ConnectorDescriptorId, IConnectorPolicy> connectorPolicies, Set<JobFlag> flags, Map<String, byte[]> contextRuntTimeVarMap) throws Exception; public void abortTasks(JobId jobId, List<TaskAttemptId> tasks) throws Exception; public void cleanUpJoblet(JobId jobId, JobStatus status) throws Exception; public void reportPartitionAvailability(PartitionId pid, NetworkAddress networkAddress) throws Exception; public void deployBinary(DeploymentId deploymentId, List<URL> url) throws Exception; public void undeployBinary(DeploymentId deploymentId) throws Exception; public void distributeJob(JobId jobId, byte[] planBytes) throws Exception; public void destroyJob(JobId jobId) throws Exception; public void dumpState(String stateDumpId) throws Exception; public void shutdown(boolean terminateNCService) throws Exception; public void sendApplicationMessageToNC(byte[] data, DeploymentId deploymentId, String nodeId) throws Exception; public void takeThreadDump(String requestId) throws Exception;
throws HyracksDataException { this.ctx = ctx; this.treeIndexHelper = indexHelperFactory.create(ctx.getJobletContext().getServiceContext(), partition); this.searchCallbackFactory = searchCallbackFactory; } @Override public void initialize() throws HyracksDataException { treeIndexHelper.open(); try { try { writer.open(); FrameTupleAppender appender = new FrameTupleAppender(new VSizeFrame(ctx)); scan(appender); appender.write(writer, true); } catch (Throwable th) { writer.fail(); throw HyracksDataException.create(th); } finally { writer.close(); } } catch (Throwable th) { throw HyracksDataException.create(th); } } private void scan(FrameTupleAppender appender) throws IOException { ITreeIndex treeIndex = (ITreeIndex) treeIndexHelper.getIndexInstance(); LocalResource resource = treeIndexHelper.getResource(); ISearchOperationCallback searchCallback = searchCallbackFactory.createSearchOperationCallback(resource.getId(), ctx, null); IIndexAccessParameters iap = new IndexAccessParameters(NoOpOperationCallback.INSTANCE, searchCallback); ITreeIndexAccessor indexAccessor = (ITreeIndexAccessor) treeIndex.createAccessor(iap); try { // code for scanning the index and appending tuples to the appender } catch (IOException e) { throw e; } }
this.searchCallbackFactory = searchCallbackFactory; @Override public void initialize() throws HyracksDataException { treeIndexHelper.open(); try { try { writer.open(); FrameTupleAppender appender = new FrameTupleAppender(new VSizeFrame(ctx)); scan(appender); appender.write(writer, true); } catch (Throwable th) { writer.fail(); throw HyracksDataException.create(th); } finally { writer.close(); } } catch (Throwable th) { throw HyracksDataException.create(th); } } private void scan(FrameTupleAppender appender) throws IOException { ITreeIndex treeIndex = (ITreeIndex) treeIndexHelper.getIndexInstance(); LocalResource resource = treeIndexHelper.getResource(); ISearchOperationCallback searchCallback = searchCallbackFactory.createSearchOperationCallback(resource.getId(), ctx, null); IIndexAccessParameters iap = new IndexAccessParameters(NoOpOperationCallback.INSTANCE, searchCallback); ITreeIndexAccessor indexAccessor = (ITreeIndexAccessor) treeIndex.createAccessor(iap); try { doScan(treeIndex, indexAccessor, appender); } finally { indexAccessor.destroy(); } }
for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { filterTuples.add(mergeOp.getMergingComponents().get(i).getLSMComponentFilter().getMinTuple()); filterTuples.add(mergeOp.getMergingComponents().get(i).getLSMComponentFilter().getMaxTuple()); } getFilterManager().updateFilter(mergedComponent.getLSMComponentFilter(), filterTuples); getFilterManager().writeFilter(mergedComponent.getLSMComponentFilter(), mergedComponent.getMetadataHolder()); componentBulkLoader.end(); return mergedComponent; } @Override public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { return new LSMRTreeAccessor(getLsmHarness(), createOpContext(iap.getModificationCallback(), iap.getSearchOperationCallback()), buddyBTreeFields); } @Override public void modify(IIndexOperationContext ictx, ITupleReference tuple) throws HyracksDataException { LSMRTreeOpContext ctx = (LSMRTreeOpContext) ictx; if (ctx.getOperation() == IndexOperation.PHYSICALDELETE) { ctx.getRTree().delete(tuple); } else { ctx.getRTree().upsert(tuple); } }
public void resetNonIndexFieldsTuple(ITupleReference newValue) { tupleWithNonIndexFields.reset(newValue); } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; HyracksDataException failure = null; try { accessor.destroy(); } catch (HyracksDataException e) { failure = e; } finally { try { if (cursor != null) { cursor.destroy(); } } catch (Exception e) { throw HyracksDataException.suppress(failure, e); } } }
public void resetNonIndexFieldsTuple(ITupleReference newValue) { tupleWithNonIndexFields.reset(newValue); } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; HyracksDataException failure = null; try { accessor.destroy(); } catch (HyracksDataException e) { failure = e; } finally { try { if (cursor != null) { cursor.destroy(); } } catch (Exception e) { throw HyracksDataException.suppress(failure, e); } } }
builder.addField(diskTuple.getFieldData(i), diskTuple.getFieldStart(i), diskTuple.getFieldLength(i)); } @Override public ITupleReference doGetTuple() { return outputTuple; } @Override public void doDestroy() throws HyracksDataException { Throwable failure = null; if (lsmHarness != null) { if (rangeCursors != null) { for (int i = 0; i < rangeCursors.length; i++) { try { rangeCursors[i].destroy(); } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } } rangeCursors = null; } try { lsmHarness.endScanDiskComponents(opCtx); } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } } foundNext = false; if (failure != null) { throw HyracksDataException.create(failure); } } @Override protected void setPriorityQueueComparator() { if (pqCmp == null || cmp != pqCmp.getMultiComparator()) { pqCmp = new PriorityQueueScanComparator(cmp); } }
@Override public void doDestroy() throws HyracksDataException { Throwable failure = null; if (lsmHarness != null) { if (rangeCursors != null) { for (int i = 0; i < rangeCursors.length; i++) { try { rangeCursors[i].destroy(); } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } } rangeCursors = null; } try { lsmHarness.endScanDiskComponents(opCtx); } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } } foundNext = false; if (failure != null) { throw HyracksDataException.create(failure); } } @Override protected void setPriorityQueueComparator() { if (pqCmp == null || cmp != pqCmp.getMultiComparator()) { pqCmp = new PriorityQueueScanComparator(cmp); } } private class PriorityQueueScanComparator extends PriorityQueueComparator { public PriorityQueueScanComparator(MultiComparator cmp) { super(cmp); } @Override public int compare(FrameTupleAccessor accessor, int t1, int t2) { try { return super.compare(accessor, t1, t2); } catch (Exception e) { throw new HyracksDataException(e); } } }
package org.apache.hyracks.storage.am.lsm.common.util; import org.apache.hyracks.storage.am.common.api.IIndexOperationContext; import org.apache.hyracks.storage.common.IIndexAccessor; import org.apache.hyracks.storage.common.IIndexCursor; public class DestroyUtils { private DestroyUtils() { throw new AssertionError("This util class should not be initialized."); } public static <T extends IIndexOperationContext> Throwable destroy(T[] contexts) { Throwable failure = null; for (int i = 0; i < contexts.length; i++) { if (contexts[i] != null) { try { contexts[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexAccessor> Throwable destroy(T[] accessors) { Throwable failure = null; for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { try { accessors[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } }
package org.apache.hyracks.storage.am.lsm.common.util; import org.apache.hyracks.storage.am.common.api.IIndexOperationContext; import org.apache.hyracks.storage.common.IIndexAccessor; import org.apache.hyracks.storage.common.IIndexCursor; public class DestroyUtils { public static <T extends IIndexOperationContext> Throwable destroy(T[] contexts) { Throwable failure = null; for (int i = 0; i < contexts.length; i++) { if (contexts[i] != null) { try { contexts[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexAccessor> Throwable destroy(T[] accessors) { Throwable failure = null; for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { try { accessors[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } }
} catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } return failure; } public static <T extends IIndexAccessor> Throwable destroy(T[] accessors) { Throwable failure = null; for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { try { accessors[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexCursor> Throwable destroy(T[] cursors) { Throwable failure = null; for (int i = 0; i < cursors.length; i++) { if (cursors[i] != null) { try { cursors[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; }
} catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } return failure; } public static <T extends IIndexCursor> Throwable destroy(T[] cursors) { Throwable failure = null; for (int i = 0; i < cursors.length; i++) { if (cursors[i] != null) { try { cursors[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; }
boolean abort = true; try { try { ISearchPredicate rtreeSearchPred = new SearchPredicate(null, null); ILSMIndexOperationContext opCtx = ((LSMRTreeSortedCursor) cursor).getOpCtx(); search(opCtx, cursor, rtreeSearchPred); try { mergedComponent = createDiskComponent(componentFactory, mergeOp.getTarget(), mergeOp.getBTreeTarget(), mergeOp.getBloomFilterTarget(), true); if (mergeOp.getMergingComponents().get(mergeOp.getMergingComponents().size() - 1) != diskComponents.get(diskComponents.size() - 1)) { long numElements = 0L; for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { numElements += ((LSMRTreeDiskComponent) mergeOp.getMergingComponents().get(i)) .getRTree().getNumElements(); } if (numElements > 0) { mergeDeletedKeys(mergeOp.getMergingComponents(), mergeOp.getBTreeTarget(), mergeOp.getBloomFilterTarget()); } } abort = false; } catch (Throwable th) { throw th; } finally { if (abort) { mergedComponent.destroy(); } } } finally { lsmHarness.endSearch(opCtx); } } finally { cursor.close(); }
// In case we must keep the deleted-keys BTrees, then they must be merged *before* merging the r-trees so that // lsmHarness.endSearch() is called once when the r-trees have been merged. if (mergeOp.getMergingComponents().get(mergeOp.getMergingComponents().size() - 1) != diskComponents .get(diskComponents.size() - 1)) { // Keep the deleted tuples since the oldest disk component is not included in the merge operation long numElements = 0L; for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { numElements += ((LSMRTreeDiskComponent) mergeOp.getMergingComponents().get(i)) .getBloomFilter().getNumElements(); } componentBulkLoader = mergedComponent.createBulkLoader(1.0f, false, numElements, false, false, false); LSMRTreeDeletedKeysBTreeMergeCursor btreeCursor = new LSMRTreeDeletedKeysBTreeMergeCursor(opCtx); try { search(opCtx, btreeCursor, rtreeSearchPred); try { while (btreeCursor.hasNext()) { // Process deleted tuples } } finally { btreeCursor.close(); } } catch (Exception e) { // Handle exception } }
} doOpen(initialState, searchPred); state = State.OPENED; if (STORE_TRACES) { openCallStack = new Throwable().getStackTrace(); } } protected void doOpen(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { // Do nothing } @Override public final boolean hasNext() throws HyracksDataException { if (ENFORCE_NEXT_HAS_NEXT && state != State.OPENED) { throw new IllegalStateException("Cannot call hasNext() on a cursor in the state " + state); } return doHasNext(); } protected boolean doHasNext() throws HyracksDataException { return false; } @Override public final void next() throws HyracksDataException { if (ENFORCE_NEXT_HAS_NEXT && state != State.OPENED) { throw new IllegalStateException("Cannot call next() on a cursor in the state " + state); } doNext(); } protected void doNext() throws HyracksDataException { // Do nothing } @Override
if (state != State.OPENED) { throw new IllegalStateException("Cannot call hasNext() on a cursor in the state " + state); } return doHasNext(); } protected boolean doHasNext() throws HyracksDataException { return false; } @Override public final void next() throws HyracksDataException { if (ENFORCE_NEXT_HAS_NEXT && state != State.OPENED) { throw new IllegalStateException("Cannot call next() on a cursor in the state " + state); } doNext(); } protected void doNext() throws HyracksDataException { // Do nothing } @Override public final void destroy() throws HyracksDataException { if (ENFORCE_OPEN_CLOSE_DESTROY) { if (state == State.DESTROYED) { LOGGER.log(Level.WARN, "multiple cursor.destroy() call in " + Arrays.toString(new Throwable().getStackTrace())); return; } else if (state != State.CLOSED) { if (STORE_TRACES && openCallStack != null) { LOGGER.log(Level.WARN, "cursor.destroy() called without cursor.close() in " + Arrays.toString(openCallStack)); } close(); } state = State.DESTROYED; } }
private ByteBuffer buffer; private volatile long dpid; private int multiplier; private VirtualPage next; private AtomicInteger readCount = new AtomicInteger(0); private AtomicInteger writeCount = new AtomicInteger(0); public VirtualPage(ByteBuffer buffer, int pageSize) { this.buffer = buffer; this.pageSize = pageSize; latch = new ReentrantReadWriteLock(true); dpid = -1; next = null; }
public void acquireReadLatch() { latch.readLock().lock(); readCount.incrementAndGet(); }
ITreeIndexAccessor treeIndexAccessor = (ITreeIndexAccessor) indexAccessor; TreeIndexDiskOrderScanCursor diskOrderCursor = (TreeIndexDiskOrderScanCursor) treeIndexAccessor.createDiskOrderScanCursor(); try { treeIndexAccessor.diskOrderScan(diskOrderCursor); while (diskOrderCursor.hasNext()) { diskOrderCursor.next(); ITupleReference frameTuple = diskOrderCursor.getTuple(); if (LOGGER.isInfoEnabled()) { LOGGER.info(TupleUtils.printTuple(frameTuple, fieldSerdes)); } } } catch (UnsupportedOperationException e) { // Ignore exception because some indexes, e.g. the LSMRTree, don't support disk-order scan. if (LOGGER.isInfoEnabled()) { LOGGER.info("Ignoring disk-order scan since it's not supported."); } } catch (ClassCastException e) { // Ignore exception because IIndexAccessor sometimes isn't an ITreeIndexAccessor, e.g., for the LSMRTree. } finally { diskOrderCursor.close(); diskOrderCursor.destroy(); }
Class<?> c = Class.forName(className); ncAppEntryPoint = (INCApplicationEntryPoint) c.newInstance(); String[] args = ncConfig.appArgs == null ? new String[0] : ncConfig.appArgs.toArray(new String[ncConfig.appArgs.size()]); ncAppEntryPoint.start(appCtx, args); executor = Executors.newCachedThreadPool(appCtx.getThreadFactory()); } @Override public synchronized void stop() throws Exception { if (!shuttedDown) { LOGGER.log(Level.INFO, "Stopping NodeControllerService"); executor.shutdownNow(); if (!executor.awaitTermination(10, TimeUnit.SECONDS)) { LOGGER.log(Level.SEVERE, "Some jobs failed to exit, continuing with abnormal shutdown"); } partitionManager.close(); datasetPartitionManager.close(); netManager.stop(); datasetNetworkManager.stop(); if (messagingNetManager != null) { messagingNetManager.stop(); } queue.stop(); if (ncAppEntryPoint != null) { ncAppEntryPoint.stop(); } } // Stop heartbeat after NC has stopped to avoid false node failure detection }
CCNCFunctions.NodeRegistrationResult nrrf = (CCNCFunctions.NodeRegistrationResult) fn; setNodeRegistrationResult(nrrf.getNodeParameters(), nrrf.getException()); return; case GET_NODE_CONTROLLERS_INFO_RESPONSE: CCNCFunctions.GetNodeControllersInfoResponseFunction gncirf = (CCNCFunctions.GetNodeControllersInfoResponseFunction) fn; setNodeControllersInfo(gncirf.getNodeControllerInfos()); return; case DEPLOY_BINARY: CCNCFunctions.DeployBinaryFunction dbf = (CCNCFunctions.DeployBinaryFunction) fn; queue.schedule(new DeployBinaryWork(NodeControllerService.this, dbf.getDeploymentId(), dbf.getBinaryURLs())); return; @Deprecated case UNDEPLOY_BINARY: CCNCFunctions.UnDeployBinaryFunction ndbf = (CCNCFunctions.UnDeployBinaryFunction) fn; queue.schedule(new UnDeployBinaryWork(NodeControllerService.this, ndbf.getDeploymentId())); return; case STATE_DUMP_REQUEST: final CCNCFunctions.StateDumpRequestFunction dsrf = (StateDumpRequestFunction) fn; queue.schedule(new StateDumpWork(NodeControllerService.this, dsrf.getStateDumpId())); return; case SHUTDOWN_REQUEST: final CCNCFunctions.ShutdownRequestFunction sdrf = (CCNCFunctions.ShutdownRequestFunction) fn;
package org.apache.hyracks.api.job; import java.io.DataInput; import java.io.DataOutput; import java.io.IOException; import java.io.Serializable; import org.apache.hyracks.api.control.CcId; import org.apache.hyracks.api.exceptions.ErrorCode; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.api.io.IWritable; public final class JobId implements IWritable, Serializable, Comparable { public static final int CC_BITS = Short.SIZE; public static final int ID_BITS = Long.SIZE - CC_BITS; public static final long MAX_ID = (1L << ID_BITS) - 1; public static final JobId INVALID = null; private static final long serialVersionUID = 1L; private long id; private transient CcId ccId; public static JobId create(DataInput dis) throws IOException { JobId jobId = new JobId(); jobId.readFields(dis); return jobId; } private JobId() { } public JobId(long id) { this.id = id; } public long getId() { return id; } public CcId getCcId() { return ccId; } public void setCcId(CcId ccId) { this.ccId = ccId; } @Override public void writeFields(DataOutput output) throws HyracksDataException { try { output.writeLong(id); } catch (IOException e) { throw HyracksDataException.create(e); } } @Override public void readFields(DataInput input) throws HyracksDataException { try { id = input.readLong(); } catch (IOException e) { throw HyracksDataException.create(e); } } @Override public int compareTo(Object o) { if (o == null || !(o instanceof JobId)) { throw new IllegalArgumentException("Cannot compare JobId with non-JobId object"); } JobId other = (JobId) o; return Long.compare(id, other.id); } @Override public int hashCode() { return Long.hashCode(id); } @Override public boolean equals(Object obj) { if (this == obj) { return true; } if (obj == null ||
import java.io.DataOutput; import java.io.IOException; import java.io.Serializable; import org.apache.hyracks.api.control.CcId; import org.apache.hyracks.api.exceptions.ErrorCode; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.api.io.IWritable; public final class JobId implements IWritable, Serializable, Comparable { public static final int CC_BITS = Short.SIZE; public static final int ID_BITS = Long.SIZE - CC_BITS; public static final long MAX_ID = (1L << ID_BITS) - 1; public static final JobId INVALID = null; private static final long serialVersionUID = 1L; private long id; private transient CcId ccId; public static JobId create(DataInput dis) throws IOException { JobId jobId = new JobId(); jobId.readFields(dis); return jobId; } private JobId() { } public JobId(long id) { this.id = id; } public long getId() { return id; } public CcId getCcId() { return ccId; } }
ncAppEntryPoint.stop(); heartbeatTask.cancel(); LOGGER.log(Level.INFO, "Stopped NodeControllerService"); shuttedDown = true; } public String getId() { return id; } public ServerContext getServerContext() { return serverCtx; } public Map<JobId, Joblet> getJobletMap() { return jobletMap; } public Map<JobId, ActivityClusterGraph> getActivityClusterGraphMap() { return activityClusterGraphMap; } public NetworkManager getNetworkManager() { return netManager; } public DatasetNetworkManager getDatasetNetworkManager() { return datasetNetworkManager; } public PartitionManager getPartitionManager() { return partitionManager; } public IClusterController getClusterController() { return ccs; } public NodeParameters getNodeParameters() { return nodeParameters; } public ExecutorService getExecutorService() { return executor; } public NCConfig getConfiguration() { return configuration; }
static class DatasetInputChannelMonitor implements IInputChannelMonitor { private int availableFrames; private boolean eos; private boolean failed; DatasetInputChannelMonitor() { eos = false; failed = false; } @Override public synchronized void notifyFailure(IInputChannel channel) { failed = true; notifyAll(); } @Override public synchronized void notifyDataAvailability(IInputChannel channel, int nFrames) { availableFrames += nFrames; notifyAll(); } @Override public synchronized void notifyEndOfStream(IInputChannel channel) { eos = true; notifyAll(); } synchronized boolean failed() { return failed; } }
private static final boolean[] UNIQUE_META_FIELDS = null; private static final int[] KEY_INDEXES = { 0 }; private static final int[] KEY_INDICATORS = { Index.RECORD_INDICATOR }; private static final List<Integer> KEY_INDICATORS_LIST = Arrays.asList(new Integer[] { Index.RECORD_INDICATOR }); private static final int TOTAL_NUM_OF_RECORDS = 10000; private static final int RECORDS_PER_COMPONENT = 1000; private static final int DATASET_ID = 101; private static final int PARTITION_ID = 0; private static final String DATAVERSE_NAME = "TestDV"; private static final String DATASET_NAME = "TestDS"; private static final String DATA_TYPE_NAME = "DUMMY"; private static final String NODE_GROUP_NAME = "DEFAULT"; private static final Predicate<ILSMComponent> memoryComponentsPredicate = c -> c instanceof ILSMMemoryComponent; private static final StorageComponentProvider storageManager = new StorageComponentProvider(); private static TestNodeController nc; private static TestLsmBtree lsmBtree; private static NCAppRuntimeContext ncAppCtx; private static IDatasetLifecycleManager dsLifecycleMgr; private static Dataset dataset;
package org.apache.hyracks.storage.am.common.api; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.api.io.FileReference; public interface ILSMIOOperation { ILSMIOOperationCallback getCallback(); String getIndexIdentifier(); LSMIOOperationType getIOOpertionType(); Boolean call() throws HyracksDataException; FileReference getTarget(); ILSMIndexAccessor getAccessor(); LSMComponentFileReferences getComponentFiles(); }
private boolean isScan = false; public LSMBTreeCursorInitialState(ITreeIndexFrameFactory leafFrameFactory, MultiComparator cmp, MultiComparator bloomFilterCmp, ILSMHarness lsmHarness, ISearchPredicate predicate, ISearchOperationCallback searchCallback, List<ILSMComponent> operationalComponents) { this.leafFrameFactory = leafFrameFactory; this.cmp = cmp; this.bloomFilterCmp = bloomFilterCmp; this.lsmHarness = lsmHarness; this.searchCallback = searchCallback; this.predicate = predicate; this.operationalComponents = operationalComponents; }
btreeCursors[i] = btreeAccessors[i].createPointCursor(false); } else { btreeAccessors[i].reset(btree, NoOpOperationCallback.INSTANCE, NoOpOperationCallback.INSTANCE); btreeCursors[i].reset(); } } nextHasBeenCalled = false; foundTuple = false; } @Override public void next() throws HyracksDataException { nextHasBeenCalled = true; } @Override public void close() throws HyracksDataException { if (lsmHarness != null) { try { destroyCursors(); btreeCursors = null; } finally { lsmHarness.endSearch(opCtx); } } nextHasBeenCalled = false; foundTuple = false; } @Override public ITupleReference getTuple() { return frameTuple; } @Override public ITupleReference getFilterMinTuple() { ILSMComponentFilter filter = getFilter(); return filter == null ? null : filter.getMinTuple(); } @Override public ITupleReference getFilterMaxTuple() { ILSMComponentFilter filter = getFilter(); return filter == null ? null : filter.getMaxTuple(); }
private final LSMBTreeRangeSearchCursor rangeCursor; private ITreeIndexCursor currentCursor; public LSMBTreeSearchCursor(ILSMIndexOperationContext opCtx) { pointCursor = new LSMBTreePointSearchCursor(opCtx); rangeCursor = new LSMBTreeRangeSearchCursor(opCtx); } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMBTreeCursorInitialState lsmInitialState = (LSMBTreeCursorInitialState) initialState; RangePredicate btreePred = (RangePredicate) searchPred; currentCursor = btreePred.isPointPredicate(lsmInitialState.getOriginalKeyComparator()) ? pointCursor : rangeCursor; currentCursor.open(lsmInitialState, searchPred); } @Override public boolean hasNext() throws HyracksDataException { return currentCursor.hasNext(); } @Override public void next() throws HyracksDataException { currentCursor.next(); } @Override public void close() throws HyracksDataException { if (currentCursor != null) { currentCursor.close(); } currentCursor = null; } @Override public void reset() throws HyracksDataException { if (currentCursor != null) { currentCursor.reset(); } currentCursor = null; }
private List<Mutable<ILogicalOperator>> ixJoinOuterAdditionalDataSourceRefs = null; private List<DataSourceType> ixJoinOuterAdditionalDataSourceTypes = null; private List<Dataset> ixJoinOuterAdditionalDatasets = null; private List<ARecordType> ixJoinOuterAdditionalRecordTypes = null; public boolean initFromSubTree(Mutable<ILogicalOperator> subTreeOpRef) throws AlgebricksException { reset(); rootRef = subTreeOpRef; root = subTreeOpRef.getValue(); boolean passedSource = false; boolean result = false; Mutable<ILogicalOperator> searchOpRef = subTreeOpRef; AbstractLogicalOperator subTreeOp = (AbstractLogicalOperator) searchOpRef.getValue(); do { if (subTreeOp.getOperatorTag() == LogicalOperatorTag.SELECT) { searchOpRef = subTreeOp.getInputs().get(0); } else if (subTreeOp.getOperatorTag() == LogicalOperatorTag.DATASOURCESCAN) { if (passedSource) { return false; } passedSource = true; DataSourceScanOperator dataSourceScanOp = (DataSourceScanOperator) subTreeOp; dataSourceRef = searchOpRef; dataSourceType = dataSourceScanOp.getDataSource().getDatasourceType(); dataset = dataSourceScanOp.getDataSource().getDataset(); recordType = dataSourceScanOp.getDataSource().getSchema().getType(); } else if (subTreeOp.getOperatorTag() == LogicalOperatorTag.ASSIGN) { assignRef = searchOpRef; AssignOperator assignOp = (AssignOperator) subTreeOp; assignExpressions = assignOp.getExpressions(); } else if (subTreeOp.getOperatorTag() == LogicalOperatorTag.UNNEST) { unnestRef = searchOpRef; UnnestOperator unnestOp = (UnnestOperator) subTreeOp; unnestExpressions = unnestOp.getExpressions(); } else if (subTreeOp.getOperatorTag() == LogicalOperatorTag.INDEX_NESTED_LOOP_JOIN) { IndexNestedLoopJoinOperator joinOp = (IndexNestedLoopJoinOperator) subTreeOp; ixJoinOuterAdditionalDataSourceRefs = joinOp.getOuterAdditionalDataSourceRefs(); ixJoinOuterAdditionalDataSourceTypes = joinOp.getOuterAdditionalDataSourceTypes(); ixJoinOuterAdditionalDatasets = joinOp.getOuterAdditionalDatas
```java } } /** * Computes and returns the byte array for an integer value. */ public static byte[] computeByteArrayForIntValue(int value) throws AlgebricksException { ArrayBackedValueStorage castBuffer = new ArrayBackedValueStorage(); try { AInt32 val = new AInt32(value); SerializerDeserializerUtil.serializeTag(val, castBuffer.getDataOutput()); AInt32SerializerDeserializer.INSTANCE.serialize(val, castBuffer.getDataOutput()); } catch (HyracksDataException e) { throw CompilationException.create(ErrorCode.CANNOT_SERIALIZE_A_VALUE); } return castBuffer.getByteArray(); } } ```
private ITreeIndexAccessor[] btreeAccessors; private RTreeSearchCursor[] mutableRTreeCursors; private ITreeIndexCursor[] btreeCursors; private RangePredicate btreeRangePredicate; private boolean foundNext; private ITupleReference frameTuple; private int[] comparatorFields; private MultiComparator btreeCmp; private int currentCursor; private SearchPredicate rtreeSearchPredicate; private int numMutableComponents; private boolean open; protected ISearchOperationCallback searchCallback; private boolean resultOfsearchCallBackProceed = false; private ArrayTupleBuilder tupleBuilderForProceedResult; private ArrayTupleReference copyTuple = null; public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx) { this(opCtx, false); } public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx, boolean returnDeletedTuples) { super(opCtx, returnDeletedTuples); currentCursor = 0; } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = (LSMRTreeCursorInitialState) initialState; cmp = lsmInitialState.getHilbertCmp(); btreeCmp = lsmInitialState.getBTreeCmp(); lsmHarness = lsmInitialState.getLSMHarness(); }
private RTreeSearchCursor[] mutableRTreeCursors; private ITreeIndexCursor[] btreeCursors; private RangePredicate btreeRangePredicate; private boolean foundNext; private ITupleReference frameTuple; private int[] comparatorFields; private MultiComparator btreeCmp; private int currentCursor; private SearchPredicate rtreeSearchPredicate; private int numMutableComponents; private boolean open; protected ISearchOperationCallback searchCallback; private boolean resultOfsearchCallBackProceed = false; private int numberOfFieldFromIndex = 0; private ArrayTupleReference copyTuple = null; public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx) { this(opCtx, false); } public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx, boolean returnDeletedTuples) { super(opCtx, returnDeletedTuples); currentCursor = 0; } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = (LSMRTreeCursorInitialState) initialState; cmp = lsmInitialState.getHilbertCmp(); btreeCmp = lsmInitialState.getBTreeCmp(); lsmHarness = lsmInitialState.getLSMHarness(); }
private RTreeSearchCursor[] mutableRTreeCursors; private ITreeIndexCursor[] btreeCursors; private RangePredicate btreeRangePredicate; private boolean foundNext; private ITupleReference frameTuple; private int[] comparatorFields; private MultiComparator btreeCmp; private int currentCursor; private SearchPredicate rtreeSearchPredicate; private int numMutableComponents; private boolean open; protected ISearchOperationCallback searchCallback; private boolean resultOfsearchCallBackProceed = false; private int numberOfFieldFromIndex = 0; private ArrayTupleBuilder tupleBuilderForProceedResult; public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx) { this(opCtx, false); } public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx, boolean returnDeletedTuples) { super(opCtx, returnDeletedTuples); currentCursor = 0; } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = (LSMRTreeCursorInitialState) initialState; cmp = lsmInitialState.getHilbertCmp(); btreeCmp = lsmInitialState.getBTreeCmp(); lsmHarness = lsmInitialState.getLSMHarness(); }
public interface INcApplicationContext extends IApplicationContext { IIOManager getIoManager(); Executor getThreadExecutor(); ITransactionSubsystem getTransactionSubsystem(); void preStop() throws Exception; boolean isShuttingdown(); ILSMIOOperationScheduler getLSMIOScheduler(); ILSMMergePolicyFactory getMetadataMergePolicyFactory(); IBufferCache getBufferCache(); ILocalResourceRepository getLocalResourceRepository(); IDatasetLifecycleManager getDatasetLifecycleManager(); IDatasetMemoryManager getDatasetMemoryManager(); IResourceIdFactory getResourceIdFactory(); ILSMOperationTracker getPrimaryOperationTracker(int datasetID, int partition); void initialize(boolean initialRun) throws IOException, ACIDException, AlgebricksException; void setShuttingdown(boolean b); void deinitialize() throws HyracksDataException; double getBloomFilterFalsePositiveRate(); Object getActiveManager(); IReplicationManager getReplicationManager(); IReplicationChannel getReplicationChannel(); void exportMetadataNodeStub() throws RemoteException; void initializeMetadataNode() throws Exception; }
idGenerator.refresh(); if (dsInfo.isDurable()) { synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { logRecord.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } for (ILSMIndex index : indexes) { AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) { // TODO: This is not efficient since we flush the indexes sequentially. } }
idGenerator.refresh(); if (dsInfo.isDurable()) { synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { logRecord.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } for (ILSMIndex index : indexes) { AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) { // TODO: This is not efficient since we flush the indexes sequentially. index.getIOOperationCallback().flush(); } }
this.setMemoryAllocated(false); @Override public void touch() { super.touch(); setLastAccess(System.currentTimeMillis()); } @Override public void untouch() { super.untouch(); setLastAccess(System.currentTimeMillis()); } public synchronized void declareActiveIOOperation() { numActiveIOOps++; } public synchronized void undeclareActiveIOOperation() { numActiveIOOps--; //notify threads waiting on this dataset info notifyAll(); } public synchronized Set<ILSMIndex> getDatasetPartitionOpenIndexes(int partition) { Set<ILSMIndex> indexSet = new HashSet<>(); Set<IndexInfo> partitionIndexInfos = this.partitionIndexes.get(partition); if (partitionIndexInfos != null) { for (IndexInfo iInfo : partitionIndexInfos) { if (iInfo.isOpen()) { indexSet.add(iInfo.getIndex()); } } } return indexSet; } @Override public int compareTo(DatasetInfo i) { // sort by (isOpen, referenceCount, lastAccess) ascending, where true < false // // Example sort order: // -------------------
public String toString() { return "JID:[" + getCcId() + "]" + getIdOnly(); }
import java.util.Map; import java.util.Set; import org.apache.hyracks.api.application.ICCServiceContext; import org.apache.hyracks.api.application.IClusterLifecycleListener; import org.apache.hyracks.api.config.IApplicationConfig; import org.apache.hyracks.api.config.IOption; import org.apache.hyracks.api.context.ICCContext; import org.apache.hyracks.api.exceptions.HyracksException; import org.apache.hyracks.api.job.IJobLifecycleListener; import org.apache.hyracks.api.job.JobId; import org.apache.hyracks.api.job.JobSpecification; import org.apache.hyracks.api.job.JobStatus; import org.apache.hyracks.api.service.IControllerService; import org.apache.hyracks.control.cc.ClusterControllerService; import org.apache.hyracks.control.common.application.ServiceContext; import org.apache.hyracks.control.common.context.ServerContext; import org.apache.hyracks.control.common.utils.HyracksThreadFactory; import org.apache.hyracks.control.common.work.IResultCallback; public class CCServiceContext extends ServiceContext implements ICCServiceContext { private final ICCContext ccContext; protected final Set<String> initPendingNodeIds; protected final Set<String> deinitPendingNodeIds; protected IResultCallback<Object> initializationCallback; protected IResultCallback<Object> deinitializationCallback; }
indexOnlyPlanInfo.setFirst(false); return; boolean isIndexOnlyPlan = false; boolean secondaryKeyFieldUsedAfterSelectOrJoinOp = indexOnlyPlanInfo.getSecond(); boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getFourth(); // matched function expressions // remaining code...
boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getFourth(); List<IOptimizableFuncExpr> matchedFuncExprs = analysisCtx.getMatchedFuncExprs(); List<LogicalVariable> usedVarsInSelJoinOp = new ArrayList<>(); List<LogicalVariable> usedVarsInSelJoinOpTemp = new ArrayList<>(); List<LogicalVariable> liveVarsAfterSelJoinOp = new ArrayList<>(); List<LogicalVariable> dataScanPKRecordVars; List<LogicalVariable> dataScanPKVars = new ArrayList<>(); List<LogicalVariable> dataScanRecordVars = new ArrayList<>();
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) { return new IScalarEvaluatorFactory() { private static final long serialVersionUID = 1L; @Override @SuppressWarnings("unchecked") public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException { return new IScalarEvaluator() { private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private final DataOutput out = resultStorage.getDataOutput(); private final IPointable argPtr0 = new VoidPointable(); private final IScalarEvaluator eval0 = args[0].createScalarEvaluator(ctx); private final AMutableInt32 intRes = new AMutableInt32(0); @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { resultStorage.reset(); eval0.evaluate(tuple, argPtr0); try { byte[] bytes0 = argPtr0.getByteArray(); int offset0 = argPtr0.getStartOffset(); int len0 = argPtr0.getLength(); ATypeTag tag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes0[offset0]); if (tag != ATypeTag.GEOMETRY) { // Rest of the code } } catch (IOException e) { throw HyracksDataException.create(e); } } }; } }; }
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) { return new IScalarEvaluatorFactory() { private static final long serialVersionUID = 1L; @Override public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException { return new IScalarEvaluator() { private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private DataOutput out = resultStorage.getDataOutput(); private IPointable inputArg = new VoidPointable(); private IScalarEvaluator eval = args[0].createScalarEvaluator(ctx); @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { eval.evaluate(tuple, inputArg); byte[] data = inputArg.getByteArray(); int offset = inputArg.getStartOffset(); int len = inputArg.getLength(); if (data[offset] != ATypeTag.SERIALIZED_BINARY_TYPE_TAG) { throw new TypeMismatchException(BuiltinFunctions.ST_GEOM_FROM_WKB, 0, data[offset], ATypeTag.SERIALIZED_BINARY_TYPE_TAG); } try { out.writeByte(ATypeTag.SERIALIZED_GEOMETRY_TYPE_TAG); out.write(data, offset + 1, len - 1); result.set(resultStorage); } catch (IOException e) { throw HyracksDataException.create(e); } } }; } }; }
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) { return new IScalarEvaluatorFactory() { private static final long serialVersionUID = 1L; @Override public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException { return new IScalarEvaluator() { private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private DataOutput out = resultStorage.getDataOutput(); private IPointable inputArg = new VoidPointable(); private IScalarEvaluator eval = args[0].createScalarEvaluator(ctx); @Override @SuppressWarnings("unchecked") public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { eval.evaluate(tuple, inputArg); byte[] bytes = inputArg.getByteArray(); int offset = inputArg.getStartOffset(); int len = inputArg.getLength(); AOrderedListType type = new AOrderedListType(BuiltinType.AGEOMETRY, null); byte typeTag = inputArg.getByteArray()[inputArg.getStartOffset()]; ISerializerDeserializer serde; if (typeTag == ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG) { serde = new AOrderedListSerializerDeserializer(type); } // rest of the code... } }; } }; }
public int hashCode() { return Objects.hash(first, second, third, fourth); }
public boolean equals(Object o) { if (!(o instanceof Quadruple<?, ?, ?, ?>)) { return false; } Quadruple<?, ?, ?, ?> quadRuple = (Quadruple<?, ?, ?, ?>) o; return Objects.equals(first, quadRuple.first) && Objects.equals(second, quadRuple.second) && Objects.equals(third, quadRuple.third) && Objects.equals(fourth, quadRuple.fourth); }
public boolean hasNext() { return currentElementIx < numElements; }
package org.apache.hyracks.storage.common; import java.util.Arrays; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.logging.log4j.Level; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; public abstract class EnforcedIndexCursor implements IIndexCursor { enum State { CLOSED, OPENED, DESTROYED } private static final boolean STORE_TRACES = false; private static final boolean ENFORCE_NEXT_HAS_NEXT = true; private static final boolean ENFORCE_OPEN_CLOSE_DESTROY = true; private static final Logger LOGGER = LogManager.getLogger(); private State state = State.CLOSED; private StackTraceElement[] openCallStack; private StackTraceElement[] destroyCallStack; @Override public final void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { if (ENFORCE_OPEN_CLOSE_DESTROY && state != State.CLOSED) { throw new IllegalStateException("Cursor is not closed"); } state = State.OPENED; if (STORE_TRACES) { openCallStack = Thread.currentThread().getStackTrace(); } try { doOpen(initialState, searchPred); } catch (HyracksDataException e) { state = State.CLOSED; throw e; } } protected abstract void doOpen(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException; @Override public final boolean next() throws HyracksDataException { if (ENFORCE_NEXT_HAS_NEXT && state != State.OPENED) { throw new IllegalStateException("Cursor is not opened"); } return doNext(); } protected abstract boolean doNext() throws HyracksDataException; @Override public final void close() throws HyracksDataException { if (ENFORCE_OPEN_CLOSE_DESTROY && state != State.OPENED) { throw new IllegalStateException("Cursor is not opened"); } state = State.CLOSED; if (STORE_TRACES) { openCallStack = null; } doClose(); } protected abstract void doClose() throws HyracksDataException; @Override public final void destroy() throws HyracksDataException { if
private static final long serialVersionUID = 1L; private static final int METADATA_DATASET_ID = MetadataPrimaryIndexes.PROPERTIES_METADATA.getDatasetId(); private IDatasetLifecycleManager datasetLifecycleManager; private ITransactionSubsystem transactionSubsystem; private int metadataStoragePartition; private transient MetadataTupleTranslatorProvider tupleTranslatorProvider; private Map<ExtensionMetadataDatasetId, ExtensionMetadataDataset<?>> extensionDatasets; public static final MetadataNode INSTANCE = new MetadataNode(); private MetadataNode() { super(); } public void initialize(IAppRuntimeContext runtimeContext, MetadataTupleTranslatorProvider tupleTranslatorProvider, List<IMetadataExtension> metadataExtensions) { this.tupleTranslatorProvider = tupleTranslatorProvider; this.transactionSubsystem = runtimeContext.getTransactionSubsystem(); this.datasetLifecycleManager = runtimeContext.getDatasetLifecycleManager(); this.metadataStoragePartition = ((IPropertiesProvider) runtimeContext).getMetadataProperties() .getMetadataPartition().getPartitionId(); if (metadataExtensions != null) { extensionDatasets = new HashMap<>(); for (IMetadataExtension metadataExtension : metadataExtensions) { for (ExtensionMetadataDataset<?> extensionIndex : metadataExtension.getExtensionIndexes()) { // initialize extension datasets } } } }
import java.util.concurrent.atomic.AtomicLong; import java.util.function.Supplier; import org.apache.asterix.common.transactions.ILongBlockFactory; import org.apache.asterix.common.transactions.ITxnIdFactory; import org.apache.asterix.common.transactions.TxnId; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; /** * Represents a factory to generate unique transaction IDs. */ class CcTxnIdFactory implements ITxnIdFactory { private static final int TXN_BLOCK_SIZE = 10; private static final Logger LOGGER = LogManager.getLogger(); private final Supplier<ILongBlockFactory> blockFactorySupplier; private volatile Block block = new Block(0, 0); public CcTxnIdFactory(Supplier<ILongBlockFactory> blockFactorySupplier) { this.blockFactorySupplier = blockFactorySupplier; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { // retry } } } }
private static int TXN_BLOCK_SIZE = 10; private static final Logger LOGGER = LogManager.getLogger(); private final Supplier<ILongBlockFactory> blockFactorySupplier; private volatile Block block = new Block(0, 0); public CcTxnIdFactory(Supplier<ILongBlockFactory> blockFactorySupplier) { this.blockFactorySupplier = blockFactorySupplier; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { block = new Block(blockFactorySupplier.get().getBlock(TXN_BLOCK_SIZE), TXN_BLOCK_SIZE); } } } @Override public void ensureMinimumId(long id) throws AlgebricksException { blockFactorySupplier.get().ensureMinimum(id); } static class Block { private static final BlockExhaustedException BLOCK_EXHAUSTED_EXCEPTION = new BlockExhaustedException(); private final AtomicLong id; private final long start; private final long endExclusive; private Block(long start, long blockSize) { this.id = new AtomicLong(start); this.start = start; this.endExclusive = start + blockSize; } private long nextId() throws BlockExhaustedException { long currentId = id.getAndIncrement(); if (currentId >= endExclusive) { throw BLOCK_EXHAUSTED_EXCEPTION; } return currentId; } }
} @Override public ActiveManager getActiveManager() { return activeManager; } @Override public ReplicationProperties getReplicationProperties() { return replicationProperties; } @Override public IReplicationChannel getReplicationChannel() { return replicationChannel; } @Override public IReplicationManager getReplicationManager() { return replicationManager; } @Override public ILibraryManager getLibraryManager() { return libraryManager; } @Override public void initializeMetadata(boolean newUniverse) throws Exception { LOGGER.info("Bootstrapping metadata"); MetadataNode.INSTANCE.initialize(this, ncExtensionManager.getMetadataTupleTranslatorProvider(), ncExtensionManager.getMetadataExtensions()); //noinspection unchecked ConcurrentHashMap<CcId, IAsterixStateProxy> proxyMap = ((ConcurrentHashMap<CcId, IAsterixStateProxy>) getServiceContext().getDistributedState()); if (proxyMap == null) { throw new IllegalStateException("Metadata node cannot access distributed state"); } // This is a special case, we just give the metadataNode directly. // This way we can delay the registration of the metadataNode until // it is completely initialized.
private int indexOf(byte[] source, int sourceOffset, int sourceCount, byte[] target, int targetOffset, int targetCount, int fromIndex) { if (fromIndex >= sourceCount) { return targetCount == 0 ? sourceCount : -1; } int from = fromIndex; if (from < 0) { from = 0; } if (targetCount == 0) { return fromIndex; } byte first = target[targetOffset]; int max = sourceOffset + (sourceCount - targetCount); for (int i = sourceOffset + fromIndex; i <= max; i++) { if (source[i] != first) { while (++i <= max && source[i] != first) { ; } } if (i <= max) { int j = i + 1; int end = j + targetCount - 1; // Rest of the code } } // Rest of the code } public static IValueParserFactory[] getValueParserFactories(ARecordType recordType) { int n = recordType.getFieldTypes().length; IValueParserFactory[] fieldParserFactories = new IValueParserFactory[n]; for (int i = 0; i < n; i++) { ATypeTag tag = null; if (recordType.getFieldTypes()[i].getTypeTag() == ATypeTag.UNION) { AUnionType unionType = (AUnionType) recordType.getFieldTypes()[i]; if (!unionType.isNullableType()) { throw new NotImplementedException("Non-optional UNION type is not supported."); } tag = unionType.getActualType().getTypeTag(); } else { tag = recordType.getFieldTypes()[i].getTypeTag(); } if (tag == null) { throw new NotImplementedException("Failed to get the type information for field " + i + "."); } fieldParserFactories[i] = getParserFactory(tag); } return fieldParserFactories; } if (!typeTag.equals(ATypeTag.BOOLEAN)) { throw new AlgebricksException(AsterixBuiltinFunctions.EDIT_DISTANCE_STRING_IS_FILTERABLE.getName() + ": expects input type BOOLEAN as fourth argument, but got " + typeTag + "."); } boolean usePrePost = BooleanPointable.getBoolean
import java.io.File; import java.util.ArrayList; import java.util.Collections; import java.util.List; import javax.annotation.Nonnull; public class LambdaNoGroupingShrinkTests { private File PROGUARD_SHRINK_NOTHING = new File(AbstractTestTools.getTestRootDir("com.android.jack.java8.lambda.test044"), "shrink-nothing.flags"); private RuntimeTestInfo TEST001 = new RuntimeTestInfo(AbstractTestTools.getTestRootDir("com.android.jack.java8.lambda.test044"), "com.android.jack.java8.lambda.test044.jack.Tests"); @Test public void testLamba040_whole() throws Exception { File lib = makeLibrary(new File[]{}, TEST001.directory); test(TEST001.jUnit, lib); } @Test @Runtime public void testLamba040_ByLib() throws Exception { File lib2 = makeLibrary(new File[]{}, new File(TEST001.directory, "lib2")); File lib1 = makeLibrary(new File[]{lib2}, new File(TEST001.directory, "lib1")); File libJack = makeLibrary(new File[]{lib2, lib1}, new File(TEST001.directory, "jack")); test(TEST001.jUnit, lib2, lib1, libJack); } @Test public void ltestLamba040_ByTestClass() throws Exception { File libs = makeLibrary(new File[]{}, new File(TEST001.directory, "lib1"), new File(TEST001.directory, "lib2")); File b2 = makeLibrary(new File[]{libs}, new File(TEST001.directory, "jack/B2.java")); File b3 = makeLibrary(new File[]{libs}, new File(TEST001.directory, "jack/B3.java")); File test = makeLibrary(new File[]{libs, b2, b3}); } private static class NCMetadataManagerImpl extends MetadataManager { public NCMetadataManagerImpl(Collection<IAsterixStateProxy> proxies, IMetadataNode metadataNode) { super(proxies, metadataNode); } @Override public MetadataTransactionContext beginTransaction() throws RemoteException, ACIDException { TxnId txnId = new TxnId(metadataNode.reserveTxnIdBlock(1)); metadataNode.beginTransaction(txnId); return new MetadataTransactionContext(txnId); } } }
import java.util.concurrent.atomic.AtomicLong; import java.util.function.Supplier; import org.apache.asterix.common.transactions.ILongBlockFactory; import org.apache.asterix.common.transactions.ITxnIdFactory; import org.apache.asterix.common.transactions.TxnId; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; class CcTxnIdFactory implements ITxnIdFactory { private static int TXN_BLOCK_SIZE = 10; private static final Logger LOGGER = LogManager.getLogger(); private final Supplier<ILongBlockFactory> blockFactorySupplier; private volatile Block block = new Block(0, 0); public CcTxnIdFactory(Supplier<ILongBlockFactory> blockFactorySupplier) { this.blockFactorySupplier = blockFactorySupplier; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { // retry } } } }
@Override public synchronized void stop() throws Exception { if (!shuttedDown) { LOGGER.log(Level.INFO, "Stopping NodeControllerService"); executor.shutdownNow(); if (!executor.awaitTermination(10, TimeUnit.SECONDS)) { LOGGER.log(Level.SEVERE, "Some jobs failed to exit, continuing with abnormal shutdown"); } partitionManager.close(); datasetPartitionManager.close(); netManager.stop(); datasetNetworkManager.stop(); if (messagingNetManager != null) { messagingNetManager.stop(); } workQueue.stop(); ncAppEntryPoint.stop(); /* * Stop heartbeat after NC has stopped to avoid false node failure detection * on CC if an NC takes a long time to stop. */ heartbeatTask.cancel(); LOGGER.log(Level.INFO, "Stopped NodeControllerService"); shuttedDown = true; } } public String getId() { return id; } public ServerContext getServerContext() { return serverCtx; } public Map<JobId, Joblet> getJobletMap() { return jobletMap; }
public synchronized void stop() throws Exception { if (!shuttedDown) { LOGGER.log(Level.INFO, "Stopping NodeControllerService"); executor.shutdownNow(); if (!executor.awaitTermination(10, TimeUnit.SECONDS)) { LOGGER.log(Level.SEVERE, "Some jobs failed to exit, continuing with abnormal shutdown"); } partitionManager.close(); datasetPartitionManager.close(); netManager.stop(); datasetNetworkManager.stop(); if (messagingNetManager != null) { messagingNetManager.stop(); } workQueue.stop(); ncAppEntryPoint.stop(); heartbeatTask.cancel(); LOGGER.log(Level.INFO, "Stopped NodeControllerService"); shuttedDown = true; } } public String getId() { return id; } public ServerContext getServerContext() { return serverCtx; } public Map<JobId, Joblet> getJobletMap() { return jobletMap; }
// Scan diskInvertedIndexes ignoring the memoryInvertedIndex. // Create an inverted index instance. ILSMDiskComponent component = createDiskComponent(componentFactory, mergeOp.getTarget(), mergeOp.getDeletedKeysBTreeTarget(), mergeOp.getBloomFilterTarget(), true); ILSMDiskComponentBulkLoader componentBulkLoader; // In case we must keep the deleted-keys BTrees, then they must be merged *before* merging the inverted indexes // so that lsmHarness.endSearch() is called once when the inverted indexes have been merged. if (mergeOp.getMergingComponents().get(mergeOp.getMergingComponents().size() - 1) != diskComponents.get(diskComponents.size() - 1)) { // Keep the deleted tuples since the oldest disk component is not included in the merge operation LSMInvertedIndexDeletedKeysBTreeMergeCursor btreeCursor = new LSMInvertedIndexDeletedKeysBTreeMergeCursor(opCtx); try { long numElements = 0L; for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { numElements += ((LSMInvertedIndexDiskComponent) mergeOp.getMergingComponents().get(i)) .getBloomFilter().getNumElements(); } btreeCursor.open(mergeOp.getMergingComponents(), numElements); while (btreeCursor.hasNext()) { btreeCursor.next(); componentBulkLoader.delete(btreeCursor.getTuple()); } } finally { btreeCursor.close(); } }
private boolean isOpen; private final Map<Long, List<StackTraceElement[]>> callers = new HashMap<>(); public Info() { referenceCount = 0; isOpen = false; }
public void untouch() { long tid = Thread.currentThread().getId(); List<StackTraceElement[]> caller = callers.get(tid); if (caller == null || caller.isEmpty()) { throw new IllegalStateException("Untouch of an untouched resource by thread: " + tid); } caller.remove(caller.size() - 1); --referenceCount; }
public void touch() { long tid = Thread.currentThread().getId(); if (callers.containsKey(tid)) { LOGGER.log(Level.WARN, "\"Double touch of a resource by thread:" + tid + ". Previous call was from: " + Arrays.toString(callers.get(tid)) + ". This call is from: " + Arrays.toString(new Throwable().getStackTrace())); throw new IllegalStateException("Double touch of a resource by thread: " + tid); } callers.put(tid, new Throwable().getStackTrace()); ++referenceCount; }
package org.apache.hyracks.api.dataflow; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IDestroyable { void destroy() throws HyracksDataException; }
dest.add(context.newVar()); } } /** * Gets the primary key variables from the unnest-map or left-outer-unnest-map operator * that does a secondary index lookup. * The order: SK, PK, [Optional: the result of a TryLock on PK] */ public static List<LogicalVariable> getKeyVarsFromSecondaryUnnestMap(Dataset dataset, ARecordType recordType, ARecordType metaRecordType, ILogicalOperator unnestMapOp, Index index, KeyType keyType, boolean outputPrimaryKeysOnlyFromSIdxSearch) throws AlgebricksException { int numPrimaryKeys; int numSecondaryKeys = KeyFieldTypeUtil.getNumSecondaryKeys(index, recordType, metaRecordType); if (dataset.getDatasetType() == DatasetType.EXTERNAL) { numPrimaryKeys = IndexingConstants .getRIDSize(((ExternalDatasetDetails) dataset.getDatasetDetails()).getProperties()); } else { numPrimaryKeys = dataset.getPrimaryKeys().size(); } List<LogicalVariable> keyVars = new ArrayList<>(); List<LogicalVariable> sourceVars = ((AbstractUnnestMapOperator) unnestMapOp).getVariables(); // Assumption: the primary keys are located after the secondary key.
numPrimaryKeys = IndexingConstants.getRIDSize(((ExternalDatasetDetails) dataset.getDatasetDetails()).getProperties()); } else { numPrimaryKeys = dataset.getPrimaryKeys().size(); } List<LogicalVariable> keyVars = new ArrayList<>(); List<LogicalVariable> sourceVars = ((AbstractUnnestMapOperator) unnestMapOp).getVariables(); int start; int stop; if (outputPrimaryKeysOnlyFromSIdxSearch) { numSecondaryKeys = 0; } switch (keyType) { case 0: start = numSecondaryKeys; stop = numSecondaryKeys + numPrimaryKeys; break; case 1: start = 0; stop = numSecondaryKeys; break; case 2: start = numSecondaryKeys + numPrimaryKeys; stop = sourceVars.size(); break; default: throw new IllegalArgumentException("Invalid key type: " + keyType); }
switch (keyType) { case 0: // Fetches primary keys - the second position start = numSecondaryKeys; stop = numSecondaryKeys + numPrimaryKeys; break; case 1: // Fetches secondary keys - the first position start = 0; stop = numSecondaryKeys; break; case 2: // Fetches conditional splitter - the last position start = numSecondaryKeys + numPrimaryKeys; stop = sourceVars.size(); break; default: return Collections.emptyList(); } for (int i = start; i < stop; i++) { keyVars.add(sourceVars.get(i)); } return keyVars; } public static List<LogicalVariable> getPrimaryKeyVarsFromSecondaryUnnestMap(Dataset dataset, ILogicalOperator unnestMapOp) { int numPrimaryKeys; if (dataset.getDatasetType() == DatasetType.EXTERNAL) { numPrimaryKeys = IndexingConstants.getRIDSize(((ExternalDatasetDetails) dataset.getDatasetDetails()).getProperties()); } else { numPrimaryKeys = dataset.getPrimaryKeys().size(); } List<LogicalVariable> primaryKeyVars = new ArrayList<>(); primaryKeyVars.addAll(getKeyVars(unnestMapOp, numPrimaryKeys, numPrimaryKeys, numPrimaryKeys + 1)); return primaryKeyVars; }
// If the constant type and target type does not match, we may need to do a type conversion. if (constantValueTag != indexedFieldTypeTag && constantValue != null) { // To check whether the constant is REAL values, and target field is an INT type field. // In this case, we need to change the search parameter. Refer to the caller section for the detail. realTypeConvertedToIntegerType = isRealTypeConvertedToIntegerType(constantValueTag, indexedFieldTypeTag); if (realTypeConvertedToIntegerType) { // For the index on a closed-type field, // if a DOUBLE or FLOAT constant is converted to an INT type value, // we need to check a corner case where two real values are located // between an INT value. For example, the following query, // // for $emp in dataset empDataset // where $emp.age > double("2.3") and $emp.age < double("3.3") // return $emp.id; // // 1) it seems like this floor/ceil conversion is needed for index on closed-field // (as the comment below indicates). For other indexes relaxing condition from < to <= // would still work fine as before. So can we limit it to this case by changing this condition to // "realTypeConvertedToIntegerType && !index.isEnforced() && !index.isOverridingKeyFieldTypes()" // 2) The precision loss is also possible when converting a large BIGINT to FLOAT/DOUBLE. // I wonder whether we need to deal with this in the new code? } }
public void processMathFunction(TypeCastingMathFunctionType mathFunctionTypeForNumericTypeCasting) { switch (mathFunctionTypeForNumericTypeCasting) { case CEIL: replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.CEIL); break; case FLOOR: replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.FLOOR); break; case EQ: replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.FLOOR); replacedConstantValueForEQCase = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.CEIL); break; default: break; } if (mathFunctionTypeForNumericTypeCasting == TypeCastingMathFunctionType.NONE) { replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.NONE); } if (replacedConstantValue == null) { return new Triple<>(constantAtRuntimeExpression, null, false); } if (replacedConstantValueForEQCase == null) { throw new IllegalStateException("NEQ is not expected here."); } }
replacedConstantValueForEQCase = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.CEIL); break; else if (mathFunctionTypeForNumericTypeCasting == TypeCastingMathFunctionType.NONE) { replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.NONE); } else if (replacedConstantValue == null) { return new Triple<>(constantAtRuntimeExpression, null, false); } else if (replacedConstantValueForEQCase == null) { return new Triple<>(new ConstantExpression(replacedConstantValue), null, realTypeConvertedToIntegerType); } else { return new Triple<>(new ConstantExpression(replacedConstantValue), new ConstantExpression(replacedConstantValueForEQCase), realTypeConvertedToIntegerType); }
private final String nodeId; private final List<INCLifecycleTask> tasks; public RegistrationTasksResponseMessage(String nodeId, List<INCLifecycleTask> tasks) { this.nodeId = nodeId; this.tasks = tasks; } @Override public void handle(INcApplicationContext appCtx) throws HyracksDataException, InterruptedException { INCMessageBroker broker = (INCMessageBroker) appCtx.getServiceContext().getMessageBroker(); IControllerService cs = appCtx.getServiceContext().getControllerService(); cs.getExecutor().submit(() -> { boolean success = true; try { Throwable exception = null; try { for (INCLifecycleTask task : tasks) { if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Starting startup task: " + task); } task.perform(getCcId(), cs); if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Completed startup task: " + task); } } } catch (Throwable e) { LOGGER.log(Level.ERROR, "Failed during startup task", e); exception = e; } if (exception != null) { success = false; broker.sendApplicationMessageToCC(new RegistrationTasksResponseMessage(nodeId, tasks), nodeId); } } catch (Exception e) { LOGGER.log(Level.ERROR, "Failed to send registration tasks response message to CC", e); } }); }
class CachingTxnIdFactory implements ITxnIdFactory { private static final Logger LOGGER = LogManager.getLogger(); private final INcApplicationContext appCtx; private volatile Block block = new Block(0, 0); public CachingTxnIdFactory(INcApplicationContext appCtx) { this.appCtx = appCtx; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { LOGGER.info("block exhausted; obtaining new block from supplier"); TxnIdBlockRequestMessage.Block newBlock; try { newBlock = TxnIdBlockRequestMessage.send(appCtx); } catch (HyracksDataException e) { throw new AlgebricksException(e); } block = new Block(newBlock.getStartingId(), newBlock.getBlockSize()); } } } @Override public void ensureMinimumId(long id) throws AlgebricksException { throw new UnsupportedOperationException(); } @Override public long getIdBlock(int blockSize) { throw new UnsupportedOperationException(); } }
((ClusterControllerService) appCtx.getServiceContext().getControllerService()).getJobIdFactory() .setMaxJobId(maxJobId); public static void send(CcId ccId, NodeControllerService ncs) throws HyracksDataException { INcApplicationContext appContext = (INcApplicationContext) ncs.getApplicationContext(); long maxResourceId = Math.max(appContext.getLocalResourceRepository().maxId(), MetadataIndexImmutableProperties.FIRST_AVAILABLE_USER_DATASET_ID); long maxTxnId = Math.max(appContext.getMaxTxnId(), appContext.getTransactionSubsystem().getTransactionManager().getMaxTxnId()); long maxJobId = ncs.getMaxJobId(ccId); ReportLocalCountersMessage countersMessage = new ReportLocalCountersMessage(ncs.getId(), maxResourceId, maxTxnId, maxJobId); try { ((INCMessageBroker) ncs.getContext().getMessageBroker()).sendMessageToCC(ccId, countersMessage); } catch (Exception e) { LOGGER.log(Level.ERROR, "Unable to report local counters", e); throw HyracksDataException.create(e); } } @Override public String toString() { return ReportLocalCountersMessage.class.getSimpleName(); }
public static Throwable close(ITupleForwarder tupleForwarder, Throwable root) { if (tupleForwarder != null) { try { tupleForwarder.close(); } catch (Exception e) { try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", e); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, e); } } return root; }
public static Throwable close(ITupleForwarder tupleForwarder, Throwable root) { if (tupleForwarder != null) { try { tupleForwarder.close(); } catch (Throwable th) { root = ExceptionUtils.suppress(root, th); } } return root; }
@FunctionalInterface public interface IDestroyable { void destroy() throws HyracksDataException; }
package org.apache.hyracks.api.dataflow; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IDestroyable { void destroy() throws HyracksDataException; }
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Exception e) { try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", e); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, e); } } return root; }
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root; }
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root; }
public static Throwable close(List<IIndexDataflowHelper> indexHelpers, Throwable root) { for (int i = 0; i < indexHelpers.size(); i++) { root = close(indexHelpers, root); } return root; }
reusablePred.setHighKeyComparator(predicate.getHighKeyComparator()); includeMutableComponent = false; int numBTrees = operationalComponents.size(); if (rangeCursors == null) { rangeCursors = new IIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; } else if (rangeCursors.length != numBTrees) { Throwable failure = ExceptionUtils.suppress(DestroyUtils.destroy(btreeAccessors), DestroyUtils.destroy(rangeCursors)); if (failure != null) { throw HyracksDataException.create(failure); } rangeCursors = new IIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; } for (int i = 0; i < numBTrees; i++) { ILSMComponent component = operationalComponents.get(i); BTree btree; if (component.getType() == LSMComponentType.MEMORY) { includeMutableComponent = true; } btree = (BTree) component.getIndex(); if (btreeAccessors[i] == null) { btreeAccessors[i] = btree.createAccessor(NoOpIndexAccessParameters.INSTANCE); rangeCursors[i] = btreeAccessors[i].createSearchCursor(false); } }
try { indexHelper.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } try { // will definitely be called regardless of exceptions writer.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } if (closeException != null) { throw closeException; } @Override public void doFail() throws HyracksDataException { failed = true; writer.fail(); }
indexHelper.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } try { // will definitely be called regardless of exceptions writer.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } if (closeException != null) { throw closeException; } @Override public void doFail() throws HyracksDataException { failed = true; writer.fail(); }
} try { indexHelper.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } try { writer.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } if (closeException != null) { throw closeException; } @Override public void doFail() throws HyracksDataException { failed = true; writer.fail(); }
import org.apache.hyracks.data.std.primitive.VoidPointable; public class IntervalLogic implements Serializable { private static final long serialVersionUID = 1L; private final ComparisonHelper ch = new ComparisonHelper(); private final IPointable s1 = VoidPointable.FACTORY.createPointable(); private final IPointable e1 = VoidPointable.FACTORY.createPointable(); private final IPointable s2 = VoidPointable.FACTORY.createPointable(); private final IPointable e2 = VoidPointable.FACTORY.createPointable(); public boolean validateInterval(AIntervalPointable ip1) throws HyracksDataException { ip1.getStart(s1); ip1.getEnd(e1); return ch.compare(ip1.getTypeTag(), ip1.getTypeTag(), s1, e1) <= 0; } public boolean before(AIntervalPointable ip1, AIntervalPointable ip2) throws AsterixException { ip1.getEnd(e1); ip2.getStart(s2); // rest of the code... } } callback.afterFinalize(LSMOperationType.MERGE, null); return; } fullMergeIsRequested.set(false); lsmIndex.scheduleMerge(ctx, callback); } @Override public void merge(ILSMIndexOperationContext ctx, ILSMIOOperation operation) throws HyracksDataException, IndexException { if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Started a merge operation for index: " + lsmIndex + " ..."); } ILSMDiskComponent newComponent = null; try { newComponent = lsmIndex.merge(operation); operation.getCallback().afterOperation(LSMOperationType.MERGE, ctx.getComponentHolder(), newComponent); lsmIndex.markAsValid(newComponent); } catch (Throwable e) { e.printStackTrace(); throw e; } finally { exitComponents(ctx, LSMOperationType.MERGE, newComponent, false); operation.getCallback().afterFinalize(LSMOperationType.MERGE, newComponent); } if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Finished the merge operation for index: " + lsmIndex); } } @Override public void addBulkLoadedComponent(IDiskComponent c) throws HyracksDataException, IndexException { lsmIndex.markAsValid(c); } for (ExternalFile
public static Throwable close(ITupleForwarder tupleForwarder, Throwable root) { if (tupleForwarder != null) { try { tupleForwarder.close(); } catch (Throwable th) { try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root; }
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root; }
try { rangeCursors[i].destroy(); } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } rangeCursors = null; try { lsmHarness.endScanDiskComponents(opCtx); } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } foundNext = false; if (failure != null) { throw HyracksDataException.create(failure); } @Override protected void setPriorityQueueComparator() { if (pqCmp == null || cmp != pqCmp.getMultiComparator()) { pqCmp = new PriorityQueueScanComparator(cmp); } } private class PriorityQueueScanComparator extends PriorityQueueComparator { public PriorityQueueScanComparator(MultiComparator cmp) { super(cmp); } @Override public int compare(PriorityQueueElement elementA, PriorityQueueElement elementB) { int result; try { result = cmp.compare(elementA.getTuple(), elementB.getTuple()); if (result != 0) { return result; } } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } return 0; } }
```java package org.apache.asterix.test.base; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; import org.junit.rules.TestWatcher; import org.junit.runner.Description; /** * Traces method entry/exit to System.out (or supplied PrintStream). * To use, add the following to your test class: * * @Rule * public TestRule watcher = new TestMethodTracer(); * * @Rule * public TestRule watcher = new TestMethodTracer(System.err); */ public class TestMethodTracer extends TestWatcher { private static final Logger LOGGER = LogManager.getLogger(); @Override protected void starting(Description description) { LOGGER.info("### {} START", description.getMethodName()); } @Override protected void failed(Throwable e, Description description) { LOGGER.info("### {} FAILED ({})", description.getMethodName(), e.getClass().getName()); } @Override protected void succeeded(Description description) { LOGGER.info("### {} SUCCEEDED", description.getMethodName()); } } ```
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Exception e) { try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", e); } catch (Throwable ignore) { // Do nothing } root = ExceptionUtils.suppress(root, e); } } return root; }
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root; }
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root; }
public LSMBTreePointSearchCursor getInsertSearchCursor() { return insertSearchCursor; } public BTreeRangeSearchCursor getMemCursor() { return memCursor; } public LSMBTreeCursorInitialState getSearchInitialState() { return searchInitialState; } public MultiComparator getCmp() { return cmp; } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; Throwable failure = DestroyUtils.destroy(null, mutableBTreeAccessors); failure = DestroyUtils.destroy(failure, mutableBTreeOpCtxs); failure = DestroyUtils.destroy(insertSearchCursor, failure); failure = DestroyUtils.destroy(memCursor, failure); if (failure != null) { throw HyracksDataException.create(failure); } } }
public BTreeRangeSearchCursor getMemCursor() { return memCursor; } public LSMBTreeCursorInitialState getSearchInitialState() { return searchInitialState; } public MultiComparator getCmp() { return cmp; } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; Throwable failure = DestroyUtils.destroy(null, mutableBTreeAccessors); failure = DestroyUtils.destroy(failure, mutableBTreeOpCtxs); failure = DestroyUtils.destroy(insertSearchCursor, failure); failure = DestroyUtils.destroy(memCursor, failure); if (failure != null) { throw HyracksDataException.create(failure); } } }
return memCursor; } public LSMBTreeCursorInitialState getSearchInitialState() { return searchInitialState; } public MultiComparator getCmp() { return cmp; } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; Throwable failure = DestroyUtils.destroy(null, mutableBTreeAccessors); failure = DestroyUtils.destroy(failure, mutableBTreeOpCtxs); failure = DestroyUtils.destroy(insertSearchCursor, failure); failure = DestroyUtils.destroy(memCursor, failure); if (failure != null) { throw HyracksDataException.create(failure); } } }
} Function f = new Function(dataverse, getExternalFunctionFullName(libraryName, function.getName().trim()), args.size(), args, function.getReturnType().trim(), function.getDefinition().trim(), library.getLanguage().trim(), function.getFunctionType().trim(), null); MetadataManager.INSTANCE.addFunction(mdTxnCtx, f); if (LOGGER.isInfoEnabled()) { String functionName = getExternalFunctionFullName(libraryName, function.getName().trim()); LOGGER.info("Installed function: " + functionName); } } } if (LOGGER.isInfoEnabled()) { LOGGER.info("Installed functions in library :" + libraryName); } // Add adapters if (library.getLibraryAdapters() != null) { for (LibraryAdapter adapter : library.getLibraryAdapters().getLibraryAdapter()) { String adapterFactoryClass = adapter.getFactoryClass().trim(); String adapterName = getExternalFunctionFullName(libraryName, adapter.getName().trim()); AdapterIdentifier aid = new AdapterIdentifier(dataverse, adapterName); DatasourceAdapter dsa =
*Refactored Buggy Code:* ```java package org.apache.asterix.external.api; import org.apache.asterix.external.library.java.JTypeTag; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IFunctionHelper { public IJObject getArgument(int index); public IJObject getResultObject(); public void setResult(IJObject result) throws HyracksDataException; public boolean isValidResult(); public IJObject getObject(JTypeTag jtypeTag) throws HyracksDataException; public void reset(); public String getParameters(); } ```
import org.apache.hyracks.data.std.api.IDataOutputProvider; import org.apache.hyracks.data.std.api.IValueReference; public class JavaFunctionHelper implements IFunctionHelper { private final IExternalFunctionInfo finfo; private final IDataOutputProvider outputProvider; private final IJObject[] arguments; private IJObject resultHolder; private final IObjectPool<IJObject, IAType> objectPool = new ListObjectPool<>(JTypeObjectFactory.INSTANCE); private final JObjectPointableVisitor pointableVisitor; private final PointableAllocator pointableAllocator; private final Map<Integer, TypeInfo> poolTypeInfo; private final String parameters; private boolean isValidResult = false; public JavaFunctionHelper(IExternalFunctionInfo finfo, IDataOutputProvider outputProvider, String parameters) throws HyracksDataException { this.finfo = finfo; this.outputProvider = outputProvider; this.pointableVisitor = new JObjectPointableVisitor(); this.pointableAllocator = new PointableAllocator(); this.arguments = new IJObject[finfo.getArgumentList().size()]; int index = 0; for (IAType param : finfo.getArgumentList()) { this.arguments[index++] = objectPool.allocate(param); } this.resultHolder = objectPool.allocate(finfo.getReturnType()); this.parameters = parameters; } }
try { while (true) { pageCleanerPolicy.notifyCleanCycleStart(this); int curPage = 0; while (true) { synchronized (cachedPages) { if (curPage >= cachedPages.size()) { break; } CachedPage cPage = (CachedPage) cachedPages.get(curPage); if (cPage != null) { cleanPage(cPage, false); } } curPage++; } if (shutdownStart) { break; } pageCleanerPolicy.notifyCleanCycleFinish(this); } } catch (Exception e) { e.printStackTrace(); } finally { shutdownComplete = true; notifyAll(); } @Override public void close() { closed = true; fifoWriter.destroyQueue(); synchronized (cleanerThread) { cleanerThread.shutdownStart = true; cleanerThread.notifyAll(); while (!cleanerThread.shutdownComplete) { try { cleanerThread.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } synchronized (fileInfoMap) { try { // code here } catch (IOException e) { e.printStackTrace(); } } }
synchronized (cachedPages) { if (curPage >= cachedPages.size()) { break; } CachedPage cPage = (CachedPage) cachedPages.get(curPage); if (cPage != null) { cleanPage(cPage, false); } } curPage++; if (shutdownStart) { break; } pageCleanerPolicy.notifyCleanCycleFinish(this); } } catch (Exception e) { e.printStackTrace(); } finally { shutdownComplete = true; notifyAll(); } } @Override public void close() { closed = true; fifoWriter.destroyQueue(); synchronized (cleanerThread) { cleanerThread.shutdownStart = true; cleanerThread.notifyAll(); while (!cleanerThread.shutdownComplete) { try { cleanerThread.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } synchronized (fileInfoMap) { try { for (Map.Entry<Integer, BufferedFileHandle> entry : fileInfoMap.entrySet()) { // code to handle entry } } catch (Exception e) { e.printStackTrace(); } } }
public void close() { closed = true; fifoWriter.destroyQueue(); synchronized (cleanerThread) { cleanerThread.shutdownStart = true; cleanerThread.notifyAll(); while (!cleanerThread.shutdownComplete) { try { cleanerThread.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } synchronized (fileInfoMap) { try { for (Map.Entry<Integer, BufferedFileHandle> entry : fileInfoMap.entrySet()) { boolean fileHasBeenDeleted = entry.getValue().fileHasBeenDeleted(); sweepAndFlush(entry.getKey(), !fileHasBeenDeleted); if (!fileHasBeenDeleted) { ioManager.close(entry.getValue().getFileHandle()); } } } catch (HyracksDataException e) { e.printStackTrace(); } fileInfoMap.clear(); } }
/** * @author Loïc Prieur-Drevon * @since 3.0 */ public class UpdateTraceBoundsJob extends Job { private static final Logger LOGGER = TraceCompassLog.getLogger(UpdateTraceBoundsJob.class); private static final String BOUNDS_FILE_NAME = "bounds"; private final Queue<TmfTraceElement> fTraceBoundsToUpdate; /** * Constructor. * * @param name The name of the job * @param traceBoundsToUpdate Queue of TmfTraceElement to update */ public UpdateTraceBoundsJob(String name, Queue<TmfTraceElement> traceBoundsToUpdate) { super(name); fTraceBoundsToUpdate = traceBoundsToUpdate; } @Override public IStatus run(IProgressMonitor monitor) { SubMonitor subMonitor = SubMonitor.convert(monitor, fTraceBoundsToUpdate.size()); while (!fTraceBoundsToUpdate.isEmpty()) { subMonitor.setTaskName(getName()); if (subMonitor.isCanceled()) { return Status.CANCEL_STATUS; } TmfTraceElement tElement = fTraceBoundsToUpdate.poll(); ITmfTimestamp start = tElement.getStartTime(); // rest of the code } return Status.OK_STATUS; } } public void addDesignSpaceChangedListener(IDesignSpaceChangeHandler changeEvent) { // implementation } public void removeDesignSpaceChangedListener(IDesignSpaceChangeHandler changeEvent) { // implementation } CachedPage cPage = bucket.cachedPage; bucket.cachedPage = bucket.cachedPage.next; cPage.next = null; // rest of the code
isFinishedSearch = true; invListMerger.close(); finalSearchResult.finalizeWrite(); return true; return false; curPartIdx++; if (curPartIdx <= endPartIdx) { boolean suitablePartFound = false; for (int i = curPartIdx; i <= endPartIdx; i++) { if (partitionCursors[i] == null || partitionCursors[i].size() < occurrenceThreshold) { continue; } suitablePartFound = true; curPartIdx = i; break; } if (!suitablePartFound) { isFinishedSearch = true; invListMerger.close(); finalSearchResult.finalizeWrite(); return true; } numPrefixLists = searchModifier.getNumPrefixLists(occurrenceThreshold, partitionCursors[curPartIdx].size()); invListMerger.reset(); finalSearchResult.resetBuffer();
this.argTypes = argTypes; this.failOnArgTypeMismatch = failOnArgTypeMismatch; } @Override public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException { final IScalarEvaluator[] argEvals = new IScalarEvaluator[args.length]; final IPointable[] argPtrs = new IPointable[args.length]; for (int i = 0; i < args.length; i++) { argEvals[i] = args[i].createScalarEvaluator(ctx); argPtrs[i] = new VoidPointable(); } return new IScalarEvaluator() { final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); final DataOutput resultOutput = resultStorage.getDataOutput(); final ARecordVisitablePointable openRecordPointable = new ARecordVisitablePointable(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE); final ARecordVisitablePointable[] argVisitablePointables; final BitSet castRequired; final ACastVisitor castVisitor; final Triple<IVisitablePointable, IAType, Boolean> castVisitorArg; final RecordBuilder outRecordBuilder = new RecordBuilder(); final BinaryEntry keyEntry = new BinaryEntry(); final BinaryEntry valEntry = new BinaryEntry(); final BinaryHashMap fieldMap = new BinaryHashMap(); { argVisitablePointables = new ARecordVisitablePointable[args.length]; castRequired = new BitSet(args.length); castVisitor = new ACastVisitor(); castVisitorArg = new Triple<>(null, null, false); for (int i = 0; i < args.length; i++) { argVisitablePointables[i] = new ARecordVisitablePointable(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE); castRequired.set(i, false); } } @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { resultStorage.reset(); resultOutput.write(result.getByteArray(), result.getStartOffset(), result.getLength()); outRecordBuilder.reset(); fieldMap.clear(); keyEntry.reset(); valEntry.reset(); openRecordPointable.set(result.getByteArray(), result.getStartOffset(), result.getLength()); try { for (int i = 0; i < args.length; i++) { argPtrs
final BitSet castRequired; final ACastVisitor castVisitor; final Triple<IVisitablePointable, IAType, Boolean> castVisitorArg; final RecordBuilder outRecordBuilder = new RecordBuilder(); final BinaryEntry keyEntry = new BinaryEntry(); final BinaryEntry valEntry = new BinaryEntry(); final BinaryHashMap fieldMap = new BinaryHashMap(TABLE_SIZE, TABLE_FRAME_SIZE, outRecordBuilder.getFieldNameHashFunction(), outRecordBuilder.getFieldNameHashFunction(), outRecordBuilder.getFieldNameComparator()); outRecordBuilder.reset(openRecordPointable.getInputRecordType()); valEntry.set(new byte[0], 0, 0); int argCount = argEvals.length; ARecordVisitablePointable[] vp = new ARecordVisitablePointable[argCount]; BitSet cr = new BitSet(); ACastVisitor cv = null; Triple<IVisitablePointable, IAType, Boolean> ca = null; for (int i = 0; i < argCount; i++) { ARecordType argType = argTypes[i]; if (argType != null) { vp[i] = new ARecordVisitablePointable(argType); if (hasDerivedType(argType.getFieldTypes())) { cr.set(i); } } } castRequired = cr; castVisitor = cv; castVisitorArg = ca;
import org.apache.hyracks.algebricks.core.algebra.operators.logical.visitors.VariableUtilities; import org.apache.hyracks.algebricks.core.algebra.plan.ALogicalPlanImpl; import org.apache.hyracks.algebricks.core.algebra.util.OperatorPropertiesUtil; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.storage.am.lsm.invertedindex.tokenizers.DelimitedUTF8StringBinaryTokenizer; /** * Static helper functions for rewriting plans using indexes. */ public class AccessMethodUtils { enum SecondaryUnnestMapOutputVarType { PRIMARY_KEY, SECONDARY_KEY, CONDITIONAL_SPLIT_VAR } public static void appendPrimaryIndexTypes(Dataset dataset, IAType itemType, IAType metaItemType, List<Object> target) throws AlgebricksException { ARecordType recordType = (ARecordType) itemType; ARecordType metaRecordType = (ARecordType) metaItemType; target.addAll(KeyFieldTypeUtil.getPartitoningKeyTypes(dataset, recordType, metaRecordType)); target.add(itemType); if (dataset.hasMetaPart()) { target.add(metaItemType); } } }
switch (keyVarType) { case PRIMARY_KEY: start = numSecondaryKeys; stop = numSecondaryKeys + numPrimaryKeys; break; case SECONDARY_KEY: start = 0; stop = numSecondaryKeys; break; case CONDITIONAL_SPLIT_VAR: if (!abstractUnnestMapOp.getGenerateCallBackProceedResultVar()) { throw CompilationException.create(ErrorCode.CANNOT_GET_CONDITIONAL_SPLIT_KEY_VARIABLE); } start = numSecondaryKeys + numPrimaryKeys; stop = start + 1; break; default: return Collections.emptyList(); } for (int i = start; i < stop; i++) { keyVars.add(sourceVars.get(i)); } return keyVars; } public static List<LogicalVariable> getPrimaryKeyVarsFromPrimaryUnnestMap(Dataset dataset, ILogicalOperator unnestMapOp) { int numPrimaryKeys = dataset.getPrimaryKeys().size(); // rest of the code }
case UPDATE: case WRITE: case WRITE_RESULT: case INDEX_INSERT_DELETE_UPSERT: case INSERT_DELETE_UPSERT: case INTERSECT: return getOperatorRequiredMemory(operator, frameSize); case LEFT_OUTER_UNNEST_MAP: case UNNEST_MAP: long unnestMapMemorySize = frameSize; if (isInvertedIndexSearch((AbstractUnnestMapOperator) operator)) { unnestMapMemorySize = textSearchMemorySize; } return getOperatorRequiredMemory(operator, unnestMapMemorySize); case EXCHANGE: return getExchangeRequiredMemory((ExchangeOperator) operator); case GROUP: return getOperatorRequiredMemory(operator, groupByMemorySize); case ORDER: return getOperatorRequiredMemory(operator, sortMemorySize); case INNERJOIN: case LEFTOUTERJOIN: return getOperatorRequiredMemory(operator, joinMemorySize); default: throw new IllegalStateException("Unrecognized operator: " + operator.getOperatorTag());
public static Throwable destroy(Throwable root, IDestroyable... destroyables) { for (IDestroyable destroyable : destroyables) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } } return root; }
public static Throwable close(IFrameWriter writer, Throwable root) { if (writer != null) { try { writer.close(); } catch (Throwable th) { root = ExceptionUtils.suppress(root, th); } } return root; }
String[] getPaths(); ConcurrentMap<String, Object> ctx(); void handle(IServletRequest request, IServletResponse response); default IChannelCloseHandler getChannelCloseHandler() { return null; }
Collection<Task> tasks = joblet.getTaskMap().values(); for (Task task : tasks) { task.abort(); allTasks.add(task); } final JobId jobId = joblet.getJobId(); if (dpm != null) { dpm.abortReader(jobId); dpm.sweep(jobId); } ncs.getWorkQueue().schedule(new CleanupJobletWork(ncs, jobId, JobStatus.FAILURE)); for (int i = 0; i < allTasks.size(); i++) { allTasks.get(i).awaitCompletion(); }
import java.io.DataOutput; import java.io.IOException; import java.util.LinkedHashMap; import java.util.Map; public final class JRecord implements IJObject { private ARecordType recordType; private IJObject[] fields; private Map<String, IJObject> openFields; private RecordBuilder recordBuilder = new RecordBuilder(); private ArrayBackedValueStorage fieldName = new ArrayBackedValueStorage(); private ArrayBackedValueStorage fieldValue = new ArrayBackedValueStorage(); private AMutableString nameString = new AMutableString(""); private static final AStringSerializerDeserializer aStringSerDer = AStringSerializerDeserializer.INSTANCE; public JRecord(ARecordType recordType, IJObject[] fields) { this.recordType = recordType; this.fields = fields; this.openFields = new LinkedHashMap<>(); } public JRecord(ARecordType recordType, IJObject[] fields, LinkedHashMap<String, IJObject> openFields) { this(recordType, fields); this.openFields = openFields; } public void addField(String fieldName, IJObject fieldValue) throws HyracksDataException { int pos = getFieldPosByName(fieldName); if (pos >= 0) { // Add field logic } } private int getFieldPosByName(String fieldName) { // Get field position logic } }
public JRecord(ARecordType recordType, IJObject[] fields, Map<String, IJObject> openFields) { this(recordType, fields); this.openFields = openFields; }
import org.apache.hyracks.algebricks.runtime.base.IScalarEvaluator; import org.apache.hyracks.algebricks.runtime.base.IScalarEvaluatorFactory; import org.apache.hyracks.api.context.IHyracksTaskContext; import org.apache.hyracks.util.string.UTF8StringUtil; public class FullTextContainsDescriptor extends AbstractScalarFunctionDynamicDescriptor { private static final long serialVersionUID = 1L; public static final LinkedHashMap<String, ATypeTag> paramTypeMap = new LinkedHashMap<>(); public static final String SEARCH_MODE_OPTION = "mode"; public static final String DISJUNCTIVE_SEARCH_MODE_OPTION = "any"; public static final String CONJUNCTIVE_SEARCH_MODE_OPTION = "all"; static final byte[] searchModeOptionArray = UTF8StringUtil.writeStringToBytes(SEARCH_MODE_OPTION); static final byte[] disjunctiveFTSearchOptionArray = UTF8StringUtil.writeStringToBytes(DISJUNCTIVE_SEARCH_MODE_OPTION); static final byte[] conjunctiveFTSearchOptionArray = UTF8StringUtil.writeStringToBytes(CONJUNCTIVE_SEARCH_MODE_OPTION); static { paramTypeMap.put(SEARCH_MODE_OPTION, ATypeTag.STRING); } } public HashMap<Long, LocalResource> loadAndGetAllResources() throws HyracksDataException { //TODO During recovery, the memory usage currently is proportional to the number of resources available. //This could be fixed by traversing all resources on disk until the required resource is found. HashMap<Long, LocalResource> resourcesMap = new HashMap<Long, LocalResource>(); for (int i = 0; i < mountPoints.length; i++) { File storageRootDir = getStorageRootDirectoryIfExists(mountPoints[i], nodeId, i); if (storageRootDir == null) { continue; } //load all local resources. } return resourcesMap; } return new ARecord(mergedRecordType, mergedFields); @Override public void reset() throws HyracksDataException { if (openFields != null && !openFields.isEmpty()) { openFields.clear(); } if (fields != null) { for (IJObject field : fields) { if (field != null) { field.reset(); } } } } public void reset(IJObject[] fields, Map<String, IJObject> openFields) throws HyracksDataException { this.reset();
* * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { private JBuiltinType() { } public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() {
```java package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static final JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; @Override public abstract IAType getIAType(); } ``` ```java package org.apache.asterix.om.base; import org.apache.asterix.common.exceptions.AsterixException; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; import org.apache.asterix.om.visitors.IOMVisitor; import org.json.JSONException; import org.json.JSONObject; public final class ABoolean implements IAObject { public static final ABoolean TRUE = new ABoolean(true); public static final ABoolean FALSE = new ABoolean(false); private final Boolean bVal; private ABoolean(boolean b) { bVal = Boolean.valueOf(b); } public Boolean getBoolean() { return bVal; } public ABoolean valueOf(boolean b) { return b ? TRUE : FALSE; } @Override public IAType getType() { return BuiltinType.ABOOLEAN; } @Override public String toString() { return "ABoolean: {" + bVal + "}"; } public boolean equals(Object obj) { return obj == this; } @Override public int hashCode() { return super.hashCode(); } } ``` ```java package org.apache
package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static final JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; @Override public abstract IAType getIAType(); }
import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static final JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; @Override public abstract IAType getIAType(); }
package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static final JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; }
package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static final JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; }
package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; }
import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static final JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; }
import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static final JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; }
import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() {
public static final JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } };
public static final JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } };
public static JBuiltinType jBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType jByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType jCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType jDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType jDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType jDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType jDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } };
} }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } };
public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() {
```java } }; public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static final JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; ```
public static final JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static final JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static void resolveResultType(ILogicalExpression expr, IVariableTypeEnvironment env, ArgTypeChecker checker, ResultTypeGenerator resultTypeGenerator) throws AlgebricksException { // implementation goes here } } public class Tracer implements ITracer { protected static final Level TRACE_LOG_LEVEL = Level.INFO; protected final Logger traceLog; protected String[] categories; protected static final int pid = PidHelper.getPid(); public Tracer(String name, String[] categories) { this.traceLog = Logger.getLogger(Tracer.class.getName() + "@" + name); this.categories = categories; } public static final Tracer ALL = new Tracer("All", new String[] { "*" }); @Override public String toString() { return getName() + Arrays.toString(categories) + (isEnabled() ? "enabled" : "disabled"); } @Override public String getName() { return traceLog.getName(); } @Override
} }; public static final JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static final JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static final JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } };
public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static void resolveResultType(ILogicalExpression expr, IVariableTypeEnvironment env, ArgTypeChecker checker, ResultTypeGenerator resultTypeGenerator) throws AlgebricksException { // implementation goes here } } public class Tracer implements ITracer { protected static final Level TRACE_LOG_LEVEL = Level.INFO; protected final Logger traceLog; protected String[] categories; protected static final int pid = PidHelper.getPid(); public Tracer(String name, String[] categories) { this.traceLog = Logger.getLogger(Tracer.class.getName() + "@" + name); this.categories = categories; } public static final Tracer ALL = new Tracer("All", new String[] { "*" }); @Override public String toString() { return getName() + Arrays.toString(categories) + (isEnabled() ? "enabled" : "disabled"); } @Override public String getName() { return traceLog.getName(); } @Override
```java } }; public static final JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static final JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static final JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static final JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; ```
public static final JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static void resolveResultType(ILogicalExpression expr, IVariableTypeEnvironment env, ArgTypeChecker checker, ResultTypeGenerator resultTypeGenerator) throws AlgebricksException { // implementation goes here } } public class Tracer implements ITracer { protected static final Level TRACE_LOG_LEVEL = Level.INFO; protected final Logger traceLog; protected String[] categories; protected static final int pid = PidHelper.getPid(); public Tracer(String name, String[] categories) { this.traceLog = Logger.getLogger(Tracer.class.getName() + "@" + name); this.categories = categories; } public static final Tracer ALL = new Tracer("All", new String[] { "*" }); @Override public String toString() { return getName() + Arrays.toString(categories) + (isEnabled() ? "enabled" : "disabled"); } @Override public String getName() { return traceLog.getName(); } @Override
```java } }; public static final JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static final JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static final JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static final JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static final JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; ```
public static final JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static void resolveResultType(ILogicalExpression expr, IVariableTypeEnvironment env, ArgTypeChecker checker, ResultTypeGenerator resultTypeGenerator) throws AlgebricksException { // implementation goes here } } public class Tracer implements ITracer { protected static final Level TRACE_LOG_LEVEL = Level.INFO; protected final Logger traceLog; protected String[] categories; protected static final int pid = PidHelper.getPid(); public Tracer(String name, String[] categories) { this.traceLog = Logger.getLogger(Tracer.class.getName() + "@" + name); this.categories = categories; } public static final Tracer ALL = new Tracer("All", new String[] { "*" }); @Override public String toString() { return getName() + Arrays.toString(categories) + (isEnabled() ? "enabled" : "disabled"); } @Override public String getName() { return traceLog.getName(); } @Override
} }; public static final JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static final JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static final JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static final JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static final JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } };
public static final JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; }
} }; public static final JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static final JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static final JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static final JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static final JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static final JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } };
public static final JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static void resolveResultType(ILogicalExpression expr, IVariableTypeEnvironment env, ArgTypeChecker checker, ResultTypeGenerator resultTypeGenerator) throws AlgebricksException { // implementation goes here } } public class Tracer implements ITracer { protected static final Level TRACE_LOG_LEVEL = Level.INFO; protected final Logger traceLog; protected String[] categories; protected static final int pid = PidHelper.getPid(); public Tracer(String name, String[] categories) { this.traceLog = Logger.getLogger(Tracer.class.getName() + "@" + name); this.categories = categories; } public static final Tracer ALL = new Tracer("All", new String[] { "*" }); @Override public String toString() { return getName() + Arrays.toString(categories) + (isEnabled() ? "enabled" : "disabled"); } @Override public String getName() { return traceLog.getName(); } @Override
} }; public static final JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static final JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static final JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static final JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static final JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static final JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } };
public static final JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static final JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static final JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static void resolveResultType(ILogicalExpression expr, IVariableTypeEnvironment env, ArgTypeChecker checker, ResultTypeGenerator resultTypeGenerator) throws AlgebricksException { // implementation goes here } } public class Tracer implements ITracer { protected static final Level TRACE_LOG_LEVEL = Level.INFO; protected final Logger traceLog; protected String[] categories; protected static final int pid = PidHelper.getPid(); public Tracer(String name, String[] categories) { this.traceLog = Logger.getLogger(Tracer.class.getName() + "@" + name); this.categories = categories; } public static final Tracer ALL = new Tracer("All", new String[] { "*" }); @Override public String toString() { return getName() + Arrays.toString(categories) + (isEnabled() ? "enabled" : "disabled"); } @Override public String getName() { return traceLog.getName(); } @
} }; public static final JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static final JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static final JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static final JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static final JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } };
public static final JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static void resolveResultType(ILogicalExpression expr, IVariableTypeEnvironment env, ArgTypeChecker checker, ResultTypeGenerator resultTypeGenerator) throws AlgebricksException { // implementation goes here } } public class Tracer implements ITracer { protected static final Level TRACE_LOG_LEVEL = Level.INFO; protected final Logger traceLog; protected String[] categories; protected static final int pid = PidHelper.getPid(); public Tracer(String name, String[] categories) { this.traceLog = Logger.getLogger(Tracer.class.getName() + "@" + name); this.categories = categories; } public static final Tracer ALL = new Tracer("All", new String[] { "*" }); @Override public String toString() { return getName() + Arrays.toString(categories) + (isEnabled() ? "enabled" : "disabled"); } @Override public String getName() { return traceLog.getName(); } @
} }; public static final JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static final JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static final JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static final JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } };
} }; public static final JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static final JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static final JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static final JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static void resolveResultType(ILogicalExpression expr, IVariableTypeEnvironment env, ArgTypeChecker checker, ResultTypeGenerator resultTypeGenerator) throws AlgebricksException { // implementation goes here } } public class Tracer implements ITracer { protected static final Level TRACE_LOG_LEVEL = Level.INFO; protected final Logger traceLog; protected String[] categories; protected static final int pid = PidHelper.getPid(); public Tracer(String name, String[] categories) { this.traceLog = Logger.getLogger(Tracer.class.getName() + "@" + name); this.categories = categories; } public static final Tracer ALL = new Tracer("All", new String[] { "*" }); @Override public String toString() { return getName() + Arrays.toString(categories) + (isEnabled() ? "enabled" : "disabled"); } @Override public String getName() { return traceLog.getName(); } @
```java } }; public static final JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static final JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static final JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static final JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; ```
public static final JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static final JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; }
public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } };
public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, * the expression to consider. * @param env, * the type environment. * @param checker, * the argument type checker. * @param resultTypeGenerator, * the result type generator. */ public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; }
} }; public static final JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static final JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static final JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static final JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } };
public static final JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static final JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static final JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } };
} }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } };
```java } }; public static final JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static final JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static final JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static final JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; ```
public class MyClass { public static final JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static final JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static final JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static final JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
```java } }; public static final JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static final JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static final JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static final JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; ```
public static final JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static final JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static void resolveResultType(ILogicalExpression expr, IVariableTypeEnvironment env, ArgTypeChecker checker, ResultTypeGenerator resultTypeGenerator) throws AlgebricksException { // implementation goes here } } public class Tracer implements ITracer { protected static final Level TRACE_LOG_LEVEL = Level.INFO; protected final Logger traceLog; protected String[] categories; protected static final int pid = PidHelper.getPid(); public Tracer(String name, String[] categories) { this.traceLog = Logger.getLogger(Tracer.class.getName() + "@" + name); this.categories = categories; } public static final Tracer ALL = new Tracer("All", new String[] { "*" }); @Override public String toString() { return getName() + Arrays.toString(categories) + (isEnabled() ? "enabled" : "disabled"); } @Override public String getName() { return traceLog.getName(); } @
```java public static final JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; ```
public static final JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } };
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
```java public static final JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; ```
public class MyClass { public static final JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static final JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static final JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
import org.apache.asterix.om.types.IAType; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.AbstractFunctionCallExpression; import org.apache.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment; public class TypeComputeUtils { private static final byte CERTAIN = 1; private static final byte NULLABLE = 2; private static final byte MISSABLE = 4; private static final byte MISSING = 8; private static final byte NULL = 16; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes(int argIndex, IAType argType) throws AlgebricksException; } public static interface ResultTypeGenerator { public IAType getResultType(IAType... knownInputTypes); } private TypeComputeUtils() { } /** * Resolve the result type of an expression. * * @param expr, the expression to consider. * @param env, the type environment. * @param checker, the argument type checker. * @param resultTypeGenerator, the result type generator. */ public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
public static IValueParserFactory[] getValueParserFactories(ARecordType recordType) { int n = recordType.getFieldTypes().length; IValueParserFactory[] fieldParserFactories = new IValueParserFactory[n]; for (int i = 0; i < n; i++) { ATypeTag tag = null; if (recordType.getFieldTypes()[i].getTypeTag() == ATypeTag.UNION) { AUnionType unionType = (AUnionType) recordType.getFieldTypes()[i]; if (!unionType.isNullableType()) { throw new NotImplementedException("Non-optional UNION type is not supported."); } tag = unionType.getActualType().getTypeTag(); } else { tag = recordType.getFieldTypes()[i].getTypeTag(); } if (tag == null) { throw new NotImplementedException("Failed to get the type information for field " + i + "."); } fieldParserFactories[i] = getParserFactory(tag); } return fieldParserFactories; } if (!typeTag.equals(ATypeTag.BOOLEAN)) { throw new AlgebricksException(AsterixBuiltinFunctions.EDIT_DISTANCE_STRING_IS_FILTERABLE.getName() + ": expects input type BOOLEAN as fourth argument, but got " + typeTag + "."); } boolean usePrePost = BooleanPointable.getBoolean(usePrePostPtr.getByteArray(), usePrePostPtr.getStartOffset() + 1); long numGrams = usePrePost ? strLen + gramLen - 1 : strLen - gramLen + 1; long lowerBound = numGrams - edThresh * gramLen; try { if (lowerBound <= 0 || strLen == 0) { booleanSerde.serialize(ABoolean.FALSE, output); } else { booleanSerde.serialize(ABoolean.TRUE, output); } } catch (IOException e) { throw new AlgebricksException(e); } result.set(resultStorage); private int indexOf(byte[] source, int sourceOffset, int sourceCount, byte[] target, int targetOffset, int targetCount, int fromIndex) { if (fromIndex >= sourceCount) { return targetCount == 0 ? sourceCount : -1; } int from = fromIndex; if (from < 0) { from = 0; } if (targetCount ==
public JDate(int chrononTimeInDays) { super(new AMutableDate(chrononTimeInDays)); } public void setValue(int chrononTimeInDays) { ((AMutableDate) value).setValue(chrononTimeInDays); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.DATE.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } ADateSerializerDeserializer.INSTANCE.serialize(((AMutableDate) value), dataOutput); } @Override public void reset() { ((AMutableDate) value).setValue(0); } @Override public IAType getIAType() { return BuiltinType.ADATE; }
public JDateTime(long chrononTime) { super(new AMutableDateTime(chrononTime)); } public void setValue(long chrononTime) { ((AMutableDateTime) value).setValue(chrononTime); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.DATETIME.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } ADateTimeSerializerDeserializer.INSTANCE.serialize((AMutableDateTime) value, dataOutput); } @Override public void reset() { ((AMutableDateTime) value).setValue(0); } @Override public IAType getIAType() { return BuiltinType.ADATETIME; }
public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.DURATION.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } ADurationSerializerDeserializer.INSTANCE.serialize((AMutableDuration) value, dataOutput); } @Override public void reset() { ((AMutableDuration) value).setValue(0, 0); } @Override public IAType getIAType() { return BuiltinType.ADURATION; }
public long getIntervalEnd() { return ((AMutableInterval) value).getIntervalEnd(); } public short getIntervalType() { return ((AMutableInterval) value).getIntervalType(); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.INTERVAL.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } AIntervalSerializerDeserializer.INSTANCE.serialize((AMutableInterval) value, dataOutput); } @Override public void reset() throws HyracksDataException { ((AMutableInterval) value).setValue(0L, 0L, (byte) 0); } @Override public IAType getIAType() { return BuiltinType.AINTERVAL; }
public void setValue(APoint p1, APoint p2) { ((AMutableLine) value).setValue(p1, p2); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.LINE.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } ALineSerializerDeserializer.INSTANCE.serialize(((AMutableLine) value), dataOutput); } @Override public void reset() { ((AMutableLine) value).setValue(null, null); } @Override public IAType getIAType() { return BuiltinType.ALINE; }
public void reset() { // Method intentionally left empty }
public double getYValue() { return ((AMutablePoint3D) value).getY(); } public double getZValue() { return ((AMutablePoint3D) value).getZ(); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.POINT3D.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } APoint3DSerializerDeserializer.INSTANCE.serialize((AMutablePoint3D) value, dataOutput); } @Override public void reset() { ((AMutablePoint3D) value).setValue(0, 0, 0); } @Override public IAType getIAType() { return BuiltinType.APOINT3D; }
builder.appendString(String.valueOf(i)); break; } case BIGINT: { long l = AInt64SerializerDeserializer.getLong(serString, startOffset); builder.appendString(String.valueOf(l)); break; } case DOUBLE: { double d = ADoubleSerializerDeserializer.getDouble(serString, startOffset); if (Double.isNaN(d)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (d == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (d == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; } }
case DOUBLE: { double d = ADoubleSerializerDeserializer.getDouble(serString, startOffset); if (Double.isNaN(d)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (d == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (d == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; }
} else if (d == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; } case BOOLEAN: { boolean b = ABooleanSerializerDeserializer.getBoolean(serString, startOffset); builder.appendString(String.valueOf(b)); break; } // NotYetImplemented case CIRCLE: case DATE: case DATETIME: case LINE: case TIME: case DURATION: case YEARMONTHDURATION: case DAYTIMEDURATION: case INTERVAL: case ARRAY: case POINT:
builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; } case BOOLEAN: { boolean b = ABooleanSerializerDeserializer.getBoolean(serString, startOffset); builder.appendString(String.valueOf(b)); break; } // NotYetImplemented case CIRCLE: case DATE: case DATETIME: case LINE: case TIME: case DURATION: case YEARMONTHDURATION: case DAYTIMEDURATION: case INTERVAL: case ARRAY: case POINT: case POINT3D: case RECTANGLE: case POLYGON:
builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); // NOSONAR } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); // NOSONAR } else { builder.appendString(String.valueOf(f)); } break; }
} else if (d == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; } case BOOLEAN: { boolean b = ABooleanSerializerDeserializer.getBoolean(serString, startOffset); builder.appendString(String.valueOf(b)); break; } // NotYetImplemented case CIRCLE: case DATE: case DATETIME: case LINE: case TIME: case DURATION: case YEARMONTHDURATION: case DAYTIMEDURATION: case INTERVAL: case ARRAY: case POINT:
import org.apache.asterix.external.input.record.reader.factory.SemiStructuredRecordReaderFactory; import org.apache.asterix.external.input.stream.factory.LocalFSInputStreamProviderFactory; import org.apache.asterix.external.input.stream.factory.SocketInputStreamProviderFactory; import org.apache.asterix.external.util.ExternalDataConstants; import org.apache.asterix.external.util.ExternalDataUtils; public class DatasourceFactoryProvider { public static IExternalDataSourceFactory getExternalDataSourceFactory(Map<String, String> configuration) throws Exception { switch (ExternalDataUtils.getDataSourceType(configuration)) { case RECORDS: return DatasourceFactoryProvider.getRecordReaderFactory(configuration); case STREAM: return DatasourceFactoryProvider.getInputStreamFactory(configuration.get(ExternalDataConstants.KEY_STREAM), configuration); } String reader = configuration.get(ExternalDataConstants.KEY_READER); if (reader != null) { return DatasourceFactoryProvider.getRecordReaderFactory(configuration); } return null; } public static IInputStreamProviderFactory getInputStreamFactory(String stream, Map<String, String> configuration) throws Exception { IInputStreamProviderFactory streamFactory; if (ExternalDataUtils.isExternal(stream)) { String dataverse = ExternalDataUtils.getDataverse(configuration); streamFactory = ExternalDataUtils.createExternalInputStreamFactory(dataverse, stream); } else { // Handle non-external stream } return streamFactory; } } protected void updateData(long start, long end, int nb, IProgressMonitor monitor) { double[] xAxis = getXAxis(start, end, nb); if (xAxis.length == 1) { return; } try (ScopeLog log = new ScopeLog(LOGGER, Level.FINE, "CounterChartViewer#updateData")) { for (CounterTreeViewerEntry counterEntry : Iterables.filter(fEntries, CounterTreeViewerEntry.class)) { if (monitor.isCanceled()) { return; } double[] steps = new double[xAxis.length]; ITmfStateSystem ss = counterEntry.getStateSystem(); Integer quark = counterEntry.getQuark(); // Perform necessary operations } } } import org.apache.impala.catalog.Type; import org.apache.impala.common.AnalysisException; import org.apache.impala.common.ImpalaException; import org.apache.impala.common.InternalException; import org.apache.impala.common.RuntimeEnv; import org.apache
public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Exception e) { root = ExceptionUtils.suppress(root, e); } } return root; }
public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { root = ExceptionUtils.suppress(root, th); } } return root; }
public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { root = ExceptionUtils.suppress(root, th); } } return root; }
public void write(IFileHandle fHandle, long offset, ByteBuffer data) throws HyracksDataException { if (state != State.INITIAL) { throw new IllegalStateException("Can't request a read operation through a " + state + " request"); } state = State.WRITE_REQUESTED; this.fHandle = fHandle; this.offset = offset; this.data = data; queue(); } private void queue() throws HyracksDataException { try { submittedRequests.put(this); } catch (InterruptedException e) { throw HyracksDataException.create(e); } } @Override public void await() throws InterruptedException { synchronized (this) { while (state != State.OPERATION_FAILED && state != State.OPERATION_SUCCEEDED) { wait(); } } } synchronized void handle() { try { if (state == State.READ_REQUESTED) { read = ioManager.doSyncRead(fHandle, offset, data); } else if (state == State.WRITE_REQUESTED) { if (data != null) { // single buffer ioManager.doSyncWrite(fHandle, offset, data); } else { // multiple buffers ioManager.doSyncWrite(fHandle, offset, buffers); } } state = State.OPERATION_SUCCEEDED; } catch (Exception e) { state = State.OPERATION_FAILED; } synchronized (this) { notifyAll(); } }
read = ioManager.doSyncRead(fHandle, offset, data); } else if (state == State.WRITE_REQUESTED) { if (data != null) { // single buffer write write = ioManager.doSyncWrite(fHandle, offset, data); } else { // multiple buffers writes writes = ioManager.doSyncWrite(fHandle, offset, dataArray); } } else { throw new IllegalStateException("IO Request with state = " + state); } state = State.OPERATION_SUCCEEDED; try { // code block to be reviewed } catch (Exception e) { state = State.OPERATION_FAILED; failure = HyracksDataException.create(e); } notifyAll(); } public State getState() { return state; } void recycle() { reset(); freeRequests.offer(this); } public int getRead() { return read; } public int getWrite() { return write; } public long getWrites() { return writes; } @Override public void run() throws InterruptedException { await(); } public HyracksDataException getFailure() { return failure; }
public void run() { Thread.currentThread().setName(getClass().getSimpleName() + "-" + num); while (true) { IoRequest next; try { next = queue.take(); } catch (InterruptedException e) { LOGGER.log(Level.WARN, "Ignoring interrupt. IO threads should never be interrupted."); continue; } if (next == POISON_PILL) { LOGGER.log(Level.INFO, "Exiting"); InvokeUtil.doUninterruptibly(() -> queue.put(POISON_PILL)); if (Thread.interrupted()) { LOGGER.log(Level.ERROR, "Ignoring interrupt. IO threads should never be interrupted."); } break; } next.handle(); } }
public void run() { Thread.currentThread().setName(getClass().getSimpleName() + "-" + num); while (true) { IoRequest next; try { next = queue.take(); } catch (InterruptedException e) { LOGGER.log(Level.WARN, "Ignoring interrupt. IO threads should never be interrupted."); continue; } if (next == POISON_PILL) { LOGGER.log(Level.INFO, "Exiting"); InvokeUtil.doUninterruptibly(() -> queue.put(POISON_PILL)); Thread.currentThread().interrupt(); break; } next.handle(); } }
public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root; }
public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { root = ExceptionUtils.suppress(root, th); } } return root; }
import org.apache.hyracks.api.exceptions.HyracksDataException; public class FeedStreamDataFlowController extends AbstractFeedDataFlowController implements IStreamFlowController { private IStreamDataParser dataParser; private AInputStream stream; @Override public void start(IFrameWriter writer) throws HyracksDataException { try { initializeTupleForwarder(writer); while (true) { tb.reset(); if (!dataParser.parse(tb.getDataOutput())) { break; } tb.addFieldEndOffset(); tupleForwarder.addTuple(tb); } } catch (Exception e) { throw new HyracksDataException(e); } } @Override public boolean stop() throws Exception { if (stream.stop()) { stream.close(); return true; } return false; } @Override public boolean handleException(Throwable th) { boolean handled = true; try { handled &= stream.skipError(); if (handled) { handled &= dataParser.reset(stream); } } catch (Exception e) { th.addSuppressed(e); return false; } return handled; } }
@SuppressWarnings("unused") public void run() { Thread.currentThread().setName(getClass().getSimpleName() + "-" + num); while (true) { IoRequest next; try { next = queue.take(); } catch (InterruptedException e) { LOGGER.log(Level.WARN, "Ignoring interrupt. IO threads should never be interrupted."); continue; } if (next == POISON_PILL) { LOGGER.log(Level.INFO, "Exiting"); InvokeUtil.doUninterruptibly(() -> queue.put(POISON_PILL)); if (Thread.interrupted()) { LOGGER.log(Level.ERROR, "Ignoring interrupt. IO threads should never be interrupted."); } break; } next.handle(); } }
boolean finishConnect = false; try { finishConnect = channel.finishConnect(); } catch (IOException e) { key.cancel(); synchronized (connectionListener) { connectionListener.connectionFailure((InetSocketAddress) key.attachment(), e); } } if (finishConnect) { createConnection(key, channel); } } catch (Exception e) { LOGGER.error(() -> new ParameterizedMessage("Error in TCPEndpoint {}", localAddress), e); }
TestHelper.deleteExistingInstanceFiles(); String configPath = System.getProperty("user.dir") + File.separator + "src" + File.separator + "test" + File.separator + "resources" + File.separator + "cc.conf"; nc = new TestNodeController(configPath, false); nc.init(); ncAppCtx = nc.getAppRuntimeContext(); dsLifecycleMgr = ncAppCtx.getDatasetLifecycleManager(); @AfterClass public static void tearDown() throws Exception { nc.deInit(); TestHelper.deleteExistingInstanceFiles(); } @Before public void createIndex() throws Exception { PrimaryIndexInfo primaryIndexInfo = StorageTestUtils.createPrimaryIndex(nc, PARTITION); IndexDataflowHelperFactory iHelperFactory = new IndexDataflowHelperFactory(nc.getStorageManager(), primaryIndexInfo.getFileSplitProvider()); JobId jobId = nc.newJobId(); ctx = nc.createTestContext(jobId, PARTITION, false); indexDataflowHelper = iHelperFactory.create(ctx.getJobletContext().getServiceContext(), PARTITION); indexDataflowHelper.open(); lsmBtree = (TestLsmBtree) indexDataflowHelper.getIndexInstance(); }
public void testRollbackWhileNoOp() { try { // allow all operations StorageTestUtils.allowAllOps(lsmBtree); // ensure no disk component and memory component is empty Assert.assertEquals(0, lsmBtree.getDiskComponents().size()); Assert.assertFalse(lsmBtree.isMemoryComponentsAllocated()); MutableArrayValueReference key = new MutableArrayValueReference("FlushMetadataOnlyTestKey".getBytes()); MutableArrayValueReference value = new MutableArrayValueReference("FlushMetadataOnlyTestValue".getBytes()); indexDataflowHelper.open(); ILSMIndexAccessor accessor = lsmBtree.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.updateMeta(key, value); Assert.assertTrue(lsmBtree.isMemoryComponentsAllocated()); Assert.assertTrue(lsmBtree.getCurrentMemoryComponent().isModified()); indexDataflowHelper.close(); // flush synchronously StorageTestUtils.flush(dsLifecycleMgr, lsmBtree, false); // assert one disk component Assert.assertEquals(1, lsmBtree.getDiskComponents().size()); VoidPointable pointable = VoidPointable.FACTORY.createPointable(); ComponentUtils.get(lsmBtree, key, pointable); Assert.assertTrue(DataUtils.equals(pointable, value)); // ensure that we can search this component // ... } catch (Exception e) { // handle exception } }
public static boolean areEqual(IValueReference first, IValueReference second) { if (first.getLength() != second.getLength()) { return false; } return equalsInRange(first.getByteArray(), first.getStartOffset(), second.getByteArray(), second.getStartOffset(), first.getLength()); }
private static TestLsmBtree lsmBtree; private static NCAppRuntimeContext ncAppCtx; private static IDatasetLifecycleManager dsLifecycleMgr; private static IHyracksTaskContext ctx; private static IIndexDataflowHelper indexDataflowHelper; private static final int PARTITION = 0; @BeforeClass public static void setUp() throws Exception { TestHelper.deleteExistingInstanceFiles(); String configPath = FilePath.joinPath(System.getProperty("user.dir"), "src", "test", "resources", "cc.conf"); nc = new TestNodeController(configPath, false); nc.init(); ncAppCtx = nc.getAppRuntimeContext(); dsLifecycleMgr = ncAppCtx.getDatasetLifecycleManager(); } @AfterClass public static void tearDown() throws Exception { System.out.println("TearDown"); nc.deInit(); TestHelper.deleteExistingInstanceFiles(); } @Before public void createIndex() throws Exception { PrimaryIndexInfo primaryIndexInfo = StorageTestUtils.createPrimaryIndex(nc, PARTITION); IndexDataflowHelperFactory iHelperFactory = ... }
ncSection = ccini.add(sectionName); if (ncConfig.getString(NCConfig.Option.CLUSTER_ADDRESS) == null) { ncSection.put(NCConfig.Option.CLUSTER_ADDRESS.ini(), ccs.getCCConfig().getClusterPublicAddress()); ncSection.put(NCConfig.Option.CLUSTER_PORT.ini(), String.valueOf(ccs.getCCConfig().getClusterPublicPort())); } String ncJvmArgs = ncConfig.getString(NCConfig.Option.JVM_ARGS); if (ncJvmArgs == null || !ncJvmArgs.contains("-XX:MaxGCPauseMillis")) { String gcMaxPauseArg = "-XX:MaxGCPauseMillis=" + getGcMaxPauseMillis(); ncSection.put(NCConfig.Option.JVM_ARGS.ini(), ncJvmArgs == null ? gcMaxPauseArg : ncJvmArgs + " " + gcMaxPauseArg); }
public void run() { while (true) { try { if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Connecting NC service '" + ncId + "' at " + ncHost + ":" + ncPort); } Socket s = new Socket(ncHost, ncPort); ObjectOutputStream oos = new ObjectOutputStream(s.getOutputStream()); oos.writeUTF(NC_MAGIC_COOKIE); oos.writeUTF(serializeIni(ccs.getCCConfig().getIni())); oos.close(); break; // QQQ Should probably have an ACK here } catch (IOException e) { if (LOGGER.isLoggable(Level.WARNING)) { LOGGER.log(Level.WARNING, "Failed to contact NC service at " + ncHost + ":" + ncPort + "; will retry", e); } } try { Thread.sleep(5000); } catch (InterruptedException ignored) { // Just go 'round again } } } public void run() { while (true) { try { if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Connecting NC service '" + ncId + "' at " + ncHost + ":" + ncPort); } Socket s = new Socket(ncHost, ncPort); ObjectOutputStream oos = new ObjectOutputStream(s.getOutputStream()); oos.writeUTF(NC_MAGIC_COOKIE); oos.writeUTF(serializeIni(ccs.getCCConfig().getIni())); oos.close(); break; // QQQ Should probably have an ACK here } catch (IOException e) { if (LOGGER.isLoggable(Level.WARNING)) { LOGGER.log(Level.WARNING, "Failed to contact NC service at " + ncHost + ":" + ncPort + "; will retry", e); } } try { Thread.sleep(5000); } catch (InterruptedException ignored) { // Just go 'round again } } } public void run() { while (true) { try { if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Connecting NC service '" + ncId + "' at " + ncHost + ":" + ncPort); } Socket s = new Socket(ncHost, ncPort); ObjectOutputStream oos = new ObjectOutputStream(s.getOutputStream()); oos.writeUTF(NC_MAGIC_COOKIE); oos.writeUTF(serializeIni(ccs.getCCConfig().get
public List<String> getFunctionParameters(String dataverseName, String fullFunctionName) { return externalFunctionParameters.getOrDefault(dataverseName + "." + fullFunctionName, Collections.emptyList()); }
String functionReturnType = function.getReturnType().trim(); String functionDefinition = function.getDefinition().trim(); String functionLanguage = library.getLanguage().trim(); String functionType = function.getFunctionType().trim(); List<String> args = new ArrayList<>(); for (String arg : fargs) { args.add(arg); } FunctionSignature signature = new FunctionSignature(dataverse, getExternalFunctionFullName(libraryName, function.getName().trim()), args.size()); Function f = new Function(signature, args, functionReturnType, functionDefinition, functionLanguage, functionType, null); MetadataManager.INSTANCE.addFunction(mdTxnCtx, f); if (LOGGER.isInfoEnabled()) { LOGGER.info("Installed function: " + functionFullName); } } if (LOGGER.isInfoEnabled()) { LOGGER.info("Installed functions in library :" + libraryName); } // Add adapters if (library.getLibraryAdapters() != null) { for (LibraryAdapter adapter : library.getLibraryAdapters().getLibraryAdapter()) {
configManager.set(nodeId, NCConfig.Option.NCSERVICE_PORT, NCConfig.NCSERVICE_PORT_DISABLED); final INCApplication ncApplication = createNCApplication(); ConfigManager ncConfigManager; if (confFile == null) { ncConfigManager = new ConfigManager(); } else { ncConfigManager = new ConfigManager(new String[] { "-config-file", confFile }); } ncApplication.registerConfig(ncConfigManager); opts.forEach(opt -> ncConfigManager.set(nodeId, opt.getLeft(), opt.getRight())); nodeControllers.add(new NodeControllerService(fixupIODevices(createNCConfig(nodeId, ncConfigManager)), ncApplication)); opts.forEach(opt -> configManager.set(opt.getLeft(), opt.getRight())); cc.start(); // Starts ncs. nodeNames = ccConfig.getConfigManager().getNodeNames(); List<Thread> startupThreads = new ArrayList<>(); for (NodeControllerService nc : nodeControllers) { Thread ncStartThread = new Thread("IntegrationUtil-" + nc.getId()) { @Override public void run() { try { nc.start(); } catch (Exception e) { // Handle exception } } }; startupThreads.add(ncStartThread); ncStartThread.start(); }
private static final long MAX_WAIT_TIME = TimeUnit.MINUTES.toMillis(1); throws Exception { flushPartition(dslLifecycleMgr, lsmBtree, DATASET, async); } public static void flushPartition(IDatasetLifecycleManager dslLifecycleMgr, TestLsmBtree lsmBtree, Dataset dataset, boolean async) throws Exception { waitForOperations(lsmBtree); PrimaryIndexOperationTracker opTracker = (PrimaryIndexOperationTracker) lsmBtree.getOperationTracker(); opTracker.setFlushOnExit(true); opTracker.flushIfNeeded(); long before = System.currentTimeMillis(); while (opTracker.isFlushLogCreated()) { Thread.sleep(5); if (System.currentTimeMillis() - before > MAX_WAIT_TIME) { throw new IllegalStateException((System.currentTimeMillis() - before) + "ms passed without scheduling the flush operation"); } } if (!async) { DatasetInfo dsInfo = dslLifecycleMgr.getDatasetInfo(dataset.getDatasetId()); dsInfo.waitForIO(); } }
public void flushPartition(IDatasetLifecycleManager dslLifecycleMgr, TestLsmBtree lsmBtree, Dataset dataset, boolean async) throws Exception { waitForOperations(lsmBtree); PrimaryIndexOperationTracker opTracker = (PrimaryIndexOperationTracker) lsmBtree.getOperationTracker(); opTracker.setFlushOnExit(true); opTracker.flushIfNeeded(); long maxWaitTime = 60000L; // 1min long before = System.nanoTime(); while (opTracker.isFlushLogCreated()) { Thread.sleep(5); if (System.nanoTime() - before > maxWaitTime * 1000000) { throw new IllegalStateException((System.nanoTime() - before) + "ns passed without scheduling the flush operation"); } } if (!async) { DatasetInfo dsInfo = dslLifecycleMgr.getDatasetInfo(dataset.getDatasetId()); dsInfo.waitForIO(); } }
import org.apache.hyracks.api.dataflow.value.ISerializerDeserializer; import org.apache.hyracks.api.exceptions.HyracksDataException; import java.io.DataInput; import java.io.DataOutput; public class AMissingSerializerDeserializer implements ISerializerDeserializer<AMissing> { private static final long serialVersionUID = 1L; public static final AMissingSerializerDeserializer INSTANCE = new AMissingSerializerDeserializer(); private AMissingSerializerDeserializer() { } @Override public AMissing deserialize(DataInput in) throws HyracksDataException { return AMissing.MISSING; } @Override public void serialize(AMissing instance, DataOutput out) throws HyracksDataException { // A missing value only has a typetag in its serialized form. } } import org.apache.hyracks.api.dataflow.value.ISerializerDeserializer; import org.apache.hyracks.api.exceptions.HyracksDataException; import java.io.DataInput; import java.io.DataOutput; public class ANullSerializerDeserializer implements ISerializerDeserializer<IAObject> { private static final long serialVersionUID = 1L; public static final ANullSerializerDeserializer INSTANCE = new ANullSerializerDeserializer(); private ANullSerializerDeserializer() { } @Override public ANull deserialize(DataInput in) throws HyracksDataException { return ANull.NULL; } @Override public void serialize(IAObject instance, DataOutput out) throws HyracksDataException { // A null value only has a typetag in its serialized form. } } import org.apache.hyracks.algebricks.data.IPrinter; import org.apache.hyracks.algebricks.data.IPrinterFactory; import org.apache.hyracks.api.exceptions.HyracksDataException; import java.io.PrintStream; public class AObjectPrinterFactory implements IPrinterFactory { private static final long serialVersionUID = 1L; public static final AObjectPrinterFactory INSTANCE = new AObjectPrinterFactory(); @Override public IPrinter createPrinter() { return PRINTER; } } /** * This method is intentionally left empty as it is not needed for the operation. */ public void afterFinalize(ILSMIndexOperationContext opCtx) throws HyracksDataException { } public class StubIOOperationCallback implements ILSMIOOperationCallback { private ILSMIndexOperationContext opCtx = null;
public class StubIOOperationCallback implements ILSMIOOperationCallback { private ILSMIndexOperationContext opCtx = null; @Override public void beforeOperation(ILSMIndexOperationContext opCtx) throws HyracksDataException { // Not interested in this } @Override public void afterOperation(ILSMIndexOperationContext opCtx) throws HyracksDataException { this.opCtx = opCtx; } @Override public void afterFinalize(ILSMIndexOperationContext opCtx) throws HyracksDataException { // Redundant info from after } public List<ILSMDiskComponent> getLastOldComponents() { return opCtx.getComponentsToBeMerged(); } public ILSMDiskComponent getLastNewComponent() { return opCtx.getNewComponent(); } @Override public void recycled(ILSMMemoryComponent component, boolean componentSwitched) { // Not interested in this } @Override public void allocated(ILSMMemoryComponent component) { // Not interested in this } }
protected LSMRTreeOpContext createOpContext(IIndexAccessParameters iap) { return new LSMRTreeOpContext(this, memoryComponents, rtreeLeafFrameFactory, rtreeInteriorFrameFactory, btreeLeafFrameFactory, (IExtendedModificationOperationCallback) iap.getModificationCallback(), iap.getSearchOperationCallback(), getTreeFields(), getFilterFields(), getHarness(), comparatorFields, linearizerArray, getFilterCmpFactories(), tracer); }
package org.apache.asterix.external.api; import java.io.DataOutput; import org.apache.asterix.om.base.IAObject; import org.apache.asterix.om.types.IAType; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IJObject { IAType getIAType(); IAObject getIAObject(); void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException; void reset() throws HyracksDataException; }
super(); this.listType = new AOrderedListType(listItemType, null); } @Override public IAType getIAType() { return listType; } @Override public IAObject getIAObject() { AMutableOrderedList v = new AMutableOrderedList(listType); for (IJObject jObj : jObjects) { v.add(jObj.getIAObject()); } return v; } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { IAsterixListBuilder listBuilder = new UnorderedListBuilder(); listBuilder.reset(listType); ArrayBackedValueStorage fieldValue = new ArrayBackedValueStorage(); for (IJObject jObject : jObjects) { fieldValue.reset(); jObject.serialize(fieldValue.getDataOutput(), true); listBuilder.addItem(fieldValue); } listBuilder.write(dataOutput, writeTypeTag); } @Override public void reset() { jObjects.clear(); }
package org.apache.asterix.external.library.java.base; import org.apache.asterix.dataflow.data.nontagged.serde.ABooleanSerializerDeserializer; import org.apache.asterix.om.base.ABoolean; import org.apache.asterix.om.base.IAObject; import org.apache.asterix.om.types.ATypeTag; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; import org.apache.hyracks.api.exceptions.HyracksDataException; import java.io.DataOutput; public final class JBoolean extends JObject { private boolean value; public JBoolean(boolean value) { this.value = value; } public void setValue(boolean value) { this.value = value; } public boolean getValue() { return value; } @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } @Override public IAObject getIAObject() { return value ? ABoolean.TRUE : ABoolean.FALSE; } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { serializeTypeTag(writeTypeTag, dataOutput, ATypeTag.BOOLEAN); ABooleanSerializerDeserializer.INSTANCE.serialize(value, dataOutput); } }
public ARectangle getValue() { return (AMutableRectangle) value; }
public ITupleReference getSearchKey() { return MetadataNode.createTuple(signature.getNamespace(), signature.getName(), Integer.toString(signature.getArity())); }
adapterRuntimeManager = new AdapterRuntimeManager(ctx, feedId, adapter, writer, partition); ActiveRuntimeId runtimeId = new ActiveRuntimeId(feedId, FeedRuntimeType.INTAKE.toString(), partition); ingestionRuntime = new IngestionRuntime(feedId, runtimeId, adapterRuntimeManager, ctx); feedManager.registerRuntime(ingestionRuntime); writer.open(); TaskUtils.putInSharedMap(HyracksConstants.KEY_MESSAGE, new VSizeFrame(ctx), ctx); adapterRuntimeManager.start(); synchronized (adapterRuntimeManager) { while (!adapterRuntimeManager.isDone()) { adapterRuntimeManager.wait(); } } if (adapterRuntimeManager.isFailed()) { throw new HyracksDataException("Unable to ingest data"); } catch (Exception e) { /* * An Interrupted Exception is thrown if the Intake job cannot progress further due to failure of another node involved in the Hyracks job. * As the Intake job involves only the intake operator, the exception is indicative of a failure at the sibling intake operator location. * The surviving intake partitions must continue to live and receive data from the external source. */ }
public static void exit(int status) { if (exitThread.isAlive()) { LOGGER.warn("ignoring duplicate request to exit with status " + status + "; already exiting with status " + exitThread.status + "..."); } exitThread.setStatus(status); exitThread.start(); }
import org.apache.logging.log4j.Level; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; public class NCShutdownHook extends Thread { public static final int FAILED_TO_STARTUP_EXIT_CODE = 2; public static final int FAILED_TO_RECOVER_EXIT_CODE = 3; private static final Logger LOGGER = LogManager.getLogger(); private final NodeControllerService nodeControllerService; NCShutdownHook(NodeControllerService nodeControllerService) { super("ShutdownHook-" + nodeControllerService.getId()); this.nodeControllerService = nodeControllerService; } @Override public void run() { try { try { LOGGER.info("Shutdown hook called"); } catch (Throwable th) { //NOSONAR } LOGGER.log(Level.INFO, () -> "Thread dump at shutdown: " + ThreadDumpUtil.takeDumpString()); nodeControllerService.stop(); } catch (Throwable th) { LOGGER.error("Error occurred during shutdown", th); } } }
protected void cleanup() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers.entrySet()) { int pendingOps = partitionPendingOps.get(e.getKey()).intValue(); for (int i = 0; i < pendingOps; i++) { try { e.getValue().first.completeOperation(null, LSMOperationType.MODIFICATION, null, e.getValue().second); } catch (HyracksDataException ex) { throw new ACIDException(ex); } } } }
try { if (interrupted) { Thread.currentThread().interrupt(); } } finally { // Log timeout information if it reaches a log String timeoutMessage = "Timeout occurred after " + timeout + " " + unit.toString(); throw new TimeoutException(timeoutMessage); } public static void runWithTimeout(ThrowingAction action, BooleanSupplier stopCondition, long timeout, TimeUnit unit) throws Exception { long remainingTime = unit.toNanos(timeout); final long startTime = System.nanoTime(); while (!stopCondition.getAsBoolean()) { if (remainingTime <= 0) { throw new TimeoutException(); } action.run(); remainingTime -= System.nanoTime() - startTime; } }
public static IValueParserFactory[] getValueParserFactories(ARecordType recordType) { int n = recordType.getFieldTypes().length; IValueParserFactory[] fieldParserFactories = new IValueParserFactory[n]; for (int i = 0; i < n; i++) { ATypeTag tag = null; if (recordType.getFieldTypes()[i].getTypeTag() == ATypeTag.UNION) { AUnionType unionType = (AUnionType) recordType.getFieldTypes()[i]; if (!unionType.isNullableType()) { throw new NotImplementedException("Non-optional UNION type is not supported."); } tag = unionType.getActualType().getTypeTag(); } else { tag = recordType.getFieldTypes()[i].getTypeTag(); } if (tag == null) { throw new NotImplementedException("Failed to get the type information for field " + i + "."); } fieldParserFactories[i] = getParserFactory(tag); } return fieldParserFactories; } if (!typeTag.equals(ATypeTag.BOOLEAN)) { throw new AlgebricksException(AsterixBuiltinFunctions.EDIT_DISTANCE_STRING_IS_FILTERABLE.getName() + ": expects input type BOOLEAN as fourth argument, but got " + typeTag + "."); } boolean usePrePost = BooleanPointable.getBoolean(usePrePostPtr.getByteArray(), usePrePostPtr.getStartOffset() + 1); long numGrams = usePrePost ? strLen + gramLen - 1 : strLen - gramLen + 1; long lowerBound = numGrams - edThresh * gramLen; try { if (lowerBound <= 0 || strLen == 0) { booleanSerde.serialize(ABoolean.FALSE, output); } else { booleanSerde.serialize(ABoolean.TRUE, output); } } catch (IOException e) { throw new AlgebricksException(e); } result.set(resultStorage); private int indexOf(byte[] source, int sourceOffset, int sourceCount, byte[] target, int targetOffset, int targetCount, int fromIndex) { if (fromIndex >= sourceCount) { return targetCount == 0 ? sourceCount : -1; } int from = fromIndex; if (from < 0) { from = 0; } if (targetCount ==
utf8Writer = new UTF8StringWriter(); } public static IBinaryComparator createStringBinaryComparator() { return PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY).createBinaryComparator(); } public static int compareStringBinValues(IValueReference a, IValueReference b, IBinaryComparator comparator) throws HyracksDataException { return comparator.compare(a.getByteArray(), a.getStartOffset() + 1, a.getLength() - 1, b.getByteArray(), b.getStartOffset() + 1, b.getLength() - 1); } public static boolean isEqual(IValueReference a, IValueReference b, IBinaryComparator comparator) throws HyracksDataException { return (compareStringBinValues(a, b, comparator) == 0); } public static boolean byteArrayEqual(IValueReference valueRef1, IValueReference valueRef2) { return byteArrayEqual(valueRef1, valueRef2, 3); } public static boolean byteArrayEqual(IValueReference valueRef1, IValueReference valueRef2, int dataOffset) { if (valueRef1 == null || valueRef2 == null) { return false; } byte[] bytes1 = valueRef1.getByteArray(); byte[] bytes2 = valueRef2.getByteArray(); int startOffset1 = valueRef1.getStartOffset() + dataOffset; int startOffset2 = valueRef2.getStartOffset() + dataOffset; int length1 = valueRef1.getLength() - dataOffset; int length2 = valueRef2.getLength() - dataOffset; if (length1 != length2) { return false; } for (int i = 0; i < length1; i++) { if (bytes1[startOffset1 + i] != bytes2[startOffset2 + i]) { return false; } } return true; }
} IndexCursorUtils.open(btreeAccessors, btreeCursors, btreeRangePredicate); try { for (int i = 0; i < numberOfTrees; i++) { if (btreeCursors[i].hasNext()) { btreeCursors[i].next(); } else { depletedBtreeCursors[i] = true; } } } catch (Throwable th) { for (int i = 0; i < numberOfTrees; i++) { th = IndexCursorUtils.close(btreeCursors[i], th); } throw HyracksDataException.create(th); } }
public static Throwable close(IIndexCursor cursor, Throwable root) { if (cursor != null) { try { cursor.close(); } catch (Throwable th) { root = ExceptionUtils.suppress(root, th); } } return root; }
throws HyracksDataException { int opened = 0; try { for (int i = 0; i < cursors.length; i++) { if (accessors.get(i) != null) { accessors.get(i).search(cursors[i], pred); } opened++; } } catch (Throwable th) { for (int j = 0; j < opened; j++) { th = IndexCursorUtils.close(cursors[j], th); } throw HyracksDataException.create(th); } } public static void open(IIndexAccessor[] accessors, IIndexCursor[] cursors, ISearchPredicate pred) throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { for (int j = 0; j < opened; j++) { th = IndexCursorUtils.close(cursors[j], th); } throw HyracksDataException.create(th); } }
throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { for (int j = 0; j < opened; j++) { th = IndexCursorUtils.close(cursors[j], th); } throw HyracksDataException.create(th); } } public static Throwable close(IIndexCursor[] cursors, Throwable th) { for (int j = 0; j < cursors.length; j++) { th = IndexCursorUtils.close(cursors[j], th); } return th; }
public static Throwable close(IIndexCursor[] cursors, Throwable th) { for (int j = 0; j < cursors.length; j++) { th = IndexCursorUtils.close(cursors[j], th); } return th; }
ILSMOperationTracker getOperationTracker(); ILSMIOOperationScheduler getIOScheduler(); ILSMIOOperationCallback getIOOperationCallback(); List<ILSMDiskComponent> getDiskComponents(); boolean isPrimaryIndex(); void modify(IIndexOperationContext ictx, ITupleReference tuple) throws HyracksDataException; void search(ILSMIndexOperationContext ictx, IIndexCursor cursor, ISearchPredicate pred) throws HyracksDataException; public void scanDiskComponents(ILSMIndexOperationContext ctx, IIndexCursor cursor) throws HyracksDataException; void scheduleFlush(ILSMIndexOperationContext ctx, ILSMIOOperationCallback callback) throws HyracksDataException; ILSMDiskComponent flush(ILSMIOOperation operation) throws HyracksDataException; void scheduleMerge(ILSMIndexOperationContext ctx, ILSMIOOperationCallback callback) throws HyracksDataException; ILSMDiskComponent merge(ILSMIOOperation operation) throws HyracksDataException;
public static Throwable close(IIndexCursor cursor, Throwable root) { if (cursor != null) { try { cursor.close(); } catch (Throwable th) { root = ExceptionUtils.suppress(root, th); } } return root; }
IOperatorNodePushable operatorNodePushable = operatorNodePushables.get(activityIdInputIndex.getLeft()); return operatorNodePushable.getInputFrameWriter(activityIdInputIndex.getRight()); } @Override public String getDisplayName() { return "Super Activity " + parent.getActivityMap().values().toString(); } @FunctionalInterface interface OperatorNodePushableAction { void run(IOperatorNodePushable op) throws HyracksDataException; } @SuppressWarnings("unchecked") private void runInParallel(OperatorNodePushableAction action) throws HyracksDataException { Future<Void>[] tasks = new Future[operatorNodePushablesBFSOrder.size()]; Throwable[] failures = new Throwable[operatorNodePushablesBFSOrder.size()]; final Semaphore startSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); final Semaphore completeSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); int completed = 0; Throwable root = null; try { for (int i = 0; i < operatorNodePushablesBFSOrder.size(); i++) { final int current = i; tasks[i] = ctx.getExecutorService().submit(() -> { startSemaphore.release(); try { action.run(operatorNodePushablesBFSOrder.get(current)); } catch (Throwable th) { failures[current] = th; } finally { completeSemaphore.release(); } return null; }); } startSemaphore.acquire(); for (int i = 0; i < operatorNodePushablesBFSOrder.size(); i++) { completeSemaphore.acquire(); } for (int i = 0; i < operatorNodePushablesBFSOrder.size(); i++) { if (failures[i] != null) { if (root == null) { root = failures[i]; } else { root.addSuppressed(failures[i]); } } } if (root != null) { throw HyracksDataException.create(root); } } catch (InterruptedException e) { Thread.currentThread().interrupt(); throw HyracksDataException.create(e); } }
import java.lang.reflect.Method; public class Main { public static void main(String[] args) throws Exception { Class<?> c = Class.forName("TypePropagation"); Method m = c.getMethod("method", int[].class); int[] array = new int[7]; Object[] arguments = { array }; m.invoke(null, arguments); } } Iterator<Expression> iterator = node.astArguments().iterator(); Expression argument = null; for (Expression arg : iterator) { argument = arg; } if (argument == null) { return; } long value = getLongValue(context, argument); if (value < min) { String message = String.format("Value will be forced up to %d as of Android 5.1; " + "don't rely on this to be exact", min); context.report(ISSUE, argument, context.getLocation(argument), message); } provider = config.createExecutableExtension("class");//$NON-NLS-1$ if (provider instanceof ICommitMessageProvider) { providers.add((ICommitMessageProvider) provider); } else { Activator.logError(UIText.CommitDialog_WrongTypeOfCommitMessageProvider, null); } } catch (CoreException | InvalidRegistryObjectException e) { String contributorName; try { contributorName = config.getDeclaringExtension().getContributor().getName(); } catch (InvalidRegistryObjectException e1) { contributorName = ""; //$NON-NLS-1$ } Activator.logError(MessageFormat.format(UIText.CommitDialog_ErrorCreatingCommitMessageProvider, contributorName), e); } } return providers; } provider = config.createExecutableExtension("class");//$NON-NLS-1$ if (provider instanceof ICommitMessageProvider) { providers.add((ICommitMessageProvider) provider); } else { Activator.logError(UIText.CommitDialog_WrongTypeOfCommitMessageProvider, null); } } catch (CoreException | InvalidRegistryObjectException e) { String contributorName; try { contributorName = config.getDeclaringExtension().getContributor().getName(); } catch (InvalidRegistryObjectException e1) { contributorName = ""; //$NON-NLS-1$ } Activator.logError(MessageFormat.format(UIText.CommitDialog_ErrorCreatingCommitMessageProvider, contributorName), e); } } return providers; } @SuppressWarnings("unchecked") private void runInParallel(Operator
final Semaphore completeSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); int completed = 0; Throwable root = null; try { for (int i = 0; i < operatorNodePushablesBFSOrder.size(); i++) { final int current = i; tasks[i] = ctx.getExecutorService().submit(() -> { startSemaphore.release(); try { action.run(operatorNodePushablesBFSOrder.get(current)); } catch (Throwable th) { failures[current] = th; throw th; } finally { completeSemaphore.release(); } return null; }); } for (Future<Void> task : tasks) { task.get(); completed++; } } catch (ExecutionException e) { root = e.getCause(); completed++; } catch (Throwable e) { root = e; } if (root != null) { cancelTasks(tasks, startSemaphore, completeSemaphore); }
public boolean hasIncrementalStats() { TPartitionStats partStats = getPartitionStats(); return partStats != null && partStats.intermediate_col_stats != null; } public synchronized ClassLoader getClassLoader(ObjectId rulesId) { if (rulesId == null || rulesDir == null) { return null; } Reference<? extends ClassLoader> ref = classLoaderCache.get(rulesId); if (ref != null) { ClassLoader cl = ref.get(); if (cl != null) { return cl; } synchronized(lock) { referMap.remove(rulesId); } ref.enqueue(); } cleanMap(); if (rulesId == null || rulesDir == null) { return null; } File jarFile = new File(rulesDir, "rules-" + rulesId.getName() + ".jar"); if (!jarFile.isFile()) { return null; } ClassLoader defaultLoader = getClass().getClassLoader(); URL url; try { url = jarFile.toURI().toURL(); } catch (MalformedURLException e) { return null; } URL[] urls = new URL[]{url}; } public interface CheckpointManager { Checkpoint getLatest() throws ACIDException; void doSharpCheckpoint() throws HyracksDataException; long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void unlockLSN(long lsn); void lockLSN(long lsn); }
/** * Performs a sharp checkpoint. * * @throws HyracksDataException */ void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void unlockLSN(long lsn); void lockLSN(long lsn);
DataflowUtils.addTupleToFrame(tupleAppender, tuple, insertOp); lowWaterMarkLSN = recoveryManager.getMinFirstLSN(); currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN); } JobId jobId2 = nc.newJobId(); IHyracksTaskContext ctx2 = nc.createTestContext(jobId2, 0, false); nc.getTransactionManager().beginTransaction(nc.getTxnJobId(ctx2), new TransactionOptions(ITransactionManager.AtomicityLevel.ENTITY_LEVEL)); LSMInsertDeleteOperatorNodePushable insertOp2 = nc.getInsertPipeline(ctx2, dataset, KEY_TYPES, RECORD_TYPE, META_TYPE, null, KEY_INDEXES, KEY_INDICATOR_LIST, storageManager, null).getLeft(); insertOp2.open(); VSizeFrame frame2 = new VSizeFrame(ctx2);
RECORD_TYPE, META_TYPE, null, KEY_INDEXES, KEY_INDICATOR_LIST, storageManager, null).getLeft(); insertOp2.open(); VSizeFrame frame2 = new VSizeFrame(ctx2); FrameTupleAppender tupleAppender2 = new FrameTupleAppender(frame2); for (int i = 0; i < 4; i++) { long lastCkpoint = recoveryManager.getMinFirstLSN(); long lastFileId = logManager.getLogFileId(lastCkpoint); logger.debug("ckpoint: " + lastCkpoint); checkpointManager.tryCheckpoint(lowWaterMarkLSN); // Validate initialLowWaterMarkFileId was deleted for (Long fileId : logManager.getLogFileIds()) { Assert.assertNotEquals(initialLowWaterMarkFileId, fileId.longValue()); } while (currentLowWaterMarkLogFileId == lastFileId) { ITupleReference tuple = tupleGenerator.next(); DataflowUtils.addTupleToFrame(tupleAppender2, tuple, insertOp2); lowWaterMarkLSN = recoveryManager.getMinFirstLSN(); currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN); } }
void doSharpCheckpoint() throws HyracksDataException; long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void unlockLSN(long lsn); void lockLSN(long lsn);
private void touchLogFile(long fileId) { synchronized (txnLogFileId2ReaderCount) { if (txnLogFileId2ReaderCount.containsKey(fileId)) { txnLogFileId2ReaderCount.put(fileId, txnLogFileId2ReaderCount.get(fileId) + 1); } else { txnLogFileId2ReaderCount.put(fileId, 1); } } }
public void run() { while (true) { try { logRecord = flushLogsQ.take(); appendToLogTail(logRecord); } catch (ACIDException e) { e.printStackTrace(); } catch (InterruptedException e) { //ignore } } }
if (!checkpointDir.exists()) { if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Checkpoint directory " + checkpointDirPath + " didn't exist. Creating one"); } checkpointDir.mkdirs(); } lsnThreshold = checkpointProperties.getLsnThreshold(); pollFrequency = checkpointProperties.getPollFrequency(); // We must keep at least the latest checkpoint historyToKeep = checkpointProperties.getHistoryToKeep() == 0 ? 1 : checkpointProperties.getHistoryToKeep(); lockedLSNs = new HashMap<>();
if (checkpointSucceeded) { for (Long l : lockedLSNs.keySet()) { if (minFirstLSN > l) { return minFirstLSN; } } logManager.deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; @Override public void lockLSN(long lsn) { if (!lockedLSNs.containsKey(lsn)) { lockedLSNs.put(lsn, 1); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) + 1); } } @Override public void unlockLSN(long lsn) { if (!lockedLSNs.containsKey(lsn)) { return; } else { if (lockedLSNs.get(lsn) == 1) { lockedLSNs.remove(lsn); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) - 1); } } }
} } return minFirstLSN; } @Override public void lockLSN(long lsn) { synchronized (txnSubsystem.getLogManager()) { if (!lockedLSNs.containsKey(lsn)) { lockedLSNs.put(lsn, 1); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) + 1); } } } @Override public void unlockLSN(long lsn) { synchronized (txnSubsystem.getLogManager()) { if (!lockedLSNs.containsKey(lsn)) { return; } else { if (lockedLSNs.get(lsn) == 1) { lockedLSNs.remove(lsn); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) - 1); } } } } }
final IVisitablePointable vp1 = pa.allocateRecordValue(inRecType1); final IPointable argPtr0 = new VoidPointable(); final IPointable argPtr1 = new VoidPointable(); final IScalarEvaluator eval0 = args[0].createScalarEvaluator(ctx); final IScalarEvaluator eval1 = args[1].createScalarEvaluator(ctx); final List<RecordBuilder> rbStack = new ArrayList<>(); final ArrayBackedValueStorage tabvs = new ArrayBackedValueStorage(); final IBinaryComparator stringBinaryComparator = PointableHelper.createStringBinaryComparator(); return new IScalarEvaluator() { private final RuntimeRecordTypeInfo runtimeRecordTypeInfo = new RuntimeRecordTypeInfo(); private final DeepEqualAssessor deepEqualAssesor = new DeepEqualAssessor(); private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private DataOutput out = resultStorage.getDataOutput(); @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { resultStorage.reset(); eval0.evaluate(tuple, argPtr0); eval1.evaluate(tuple, argPtr1); vp0.set(argPtr0); vp1.set(argPtr1); // rest of the code } };
public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException { final PointableAllocator pa = new PointableAllocator(); final IVisitablePointable vp0 = pa.allocateRecordValue(inputRecType); final IVisitablePointable vp1 = pa.allocateListValue(inputListType); final IPointable inputArg0 = new VoidPointable(); final IPointable inputArg1 = new VoidPointable(); final IScalarEvaluator eval0 = inputRecordEvalFactory.createScalarEvaluator(ctx); final IScalarEvaluator eval1 = removeFieldPathsFactory.createScalarEvaluator(ctx); final IBinaryComparator stringBinaryComparator = PointableHelper.createStringBinaryComparator(); return new IScalarEvaluator() { private final RuntimeRecordTypeInfo runtimeRecordTypeInfo = new RuntimeRecordTypeInfo(); private final List<RecordBuilder> rbStack = new ArrayList<>(); private final ArrayBackedValueStorage tabvs = new ArrayBackedValueStorage(); private final Deque<IVisitablePointable> recordPath = new ArrayDeque<>(); private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private DataOutput out = resultStorage.getDataOutput(); @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { resultStorage.reset(); // rest of the code } }; }
IndexCursorUtils.open(btreeAccessors, btreeCursors, btreeRangePredicate); try { for (int i = 0; i < numberOfTrees; i++) { if (btreeCursors[i].hasNext()) { btreeCursors[i].next(); } else { depletedBtreeCursors[i] = true; } } } catch (Throwable th) { for (int i = 0; i < numberOfTrees; i++) { th = IndexCursorUtils.close(btreeCursors[i], th); } throw HyracksDataException.create(th); }
throws HyracksDataException { int opened = 0; try { for (int i = 0; i < cursors.length; i++) { if (accessors.get(i) != null) { accessors.get(i).search(cursors[i], pred); } opened++; } } catch (Throwable th) { for (int j = 0; j < opened; j++) { th = IndexCursorUtils.close(cursors[j], th); } throw HyracksDataException.create(th); } } public static void open(IIndexAccessor[] accessors, IIndexCursor[] cursors, ISearchPredicate pred) throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { for (int j = 0; j < opened; j++) { th = IndexCursorUtils.close(cursors[j], th); } throw HyracksDataException.create(th); } }
throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { for (int j = 0; j < opened; j++) { th = IndexCursorUtils.close(cursors[j], th); } throw HyracksDataException.create(th); } } public static Throwable close(IIndexCursor[] cursors, Throwable th) { for (int j = 0; j < cursors.length; j++) { th = IndexCursorUtils.close(cursors[j], th); } return th; }
initializationTasks.add(ctx.getExecutorService().submit(() -> { opAction.runAction(op, opIndex); return null; })); // Waits until all parallel actions to finish. for (Future<Void> initializationTask : initializationTasks) { initializationTask.get(); } } catch (Throwable th) { for (Future<Void> initializationTask : initializationTasks) { initializationTask.cancel(true); } throw new HyracksDataException(th); } }
public LogRecord next() { if (buffer.position() == endOffset) { return null; } RecordReadStatus status = logRecord.readLogRecord(buffer); if (status != RecordReadStatus.OK) { String logMessage = "Unexpected log read status: " + status + ". Read log: " + logRecord.getLogRecordForDisplay(); log.error(logMessage); throw new IllegalStateException(logMessage); } return logRecord; }
IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); capture(minFirstLSN, false); if (checkpointSucceeded) { txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; private synchronized long getMinSecuredLSN() { return securedLSNs.isEmpty() ? -1 : Collections.min(securedLSNs.values()); } @Override public synchronized void secure(TxnId id) throws HyracksDataException { securedLSNs.put(id, txnSubsystem.getRecoveryManager().getMinFirstLSN()); } @Override public synchronized void completed(TxnId id) { securedLSNs.remove(id); }
Checkpoint getLatest() throws ACIDException; void doSharpCheckpoint() throws HyracksDataException; long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void secure(TxnId id) throws HyracksDataException; void completed(TxnId id);
public abstract class AbstractCheckpointManager implements ICheckpointManager { private static final Logger LOGGER = LogManager.getLogger(); private static final String CHECKPOINT_FILENAME_PREFIX = "checkpoint_"; public static final long SHARP_CHECKPOINT_LSN = -1; private static final FilenameFilter filter = (File dir, String name) -> name.startsWith(CHECKPOINT_FILENAME_PREFIX); private final File checkpointDir; private final int historyToKeep; private final int lsnThreshold; private final int pollFrequency; private final Map<TxnId, Long> securedLSNs; protected final ITransactionSubsystem txnSubsystem; private CheckpointThread checkpointer; public AbstractCheckpointManager(ITransactionSubsystem txnSubsystem, CheckpointProperties checkpointProperties) { this.txnSubsystem = txnSubsystem; String checkpointDirPath = checkpointProperties.getCheckpointDirPath(); if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Checkpoint directory = " + checkpointDirPath); } if (!checkpointDirPath.endsWith(File.separator)) { checkpointDirPath += File.separator; } checkpointDir = new File(checkpointDirPath); // Create the checkpoint directory if missing if (!checkpointDir.exists()) { checkpointDir.mkdirs(); } historyToKeep = checkpointProperties.getHistoryToKeep(); lsnThreshold = checkpointProperties.getLsnThreshold(); pollFrequency = checkpointProperties.getPollFrequency(); securedLSNs = new ConcurrentHashMap<>(); } // Rest of the code... }
final long minSecuredLSN = txnSubsystem.getRecoveryManager().getMinFirstLSN(); boolean checkpointSucceeded = minSecuredLSN >= checkpointTargetLSN; if (!checkpointSucceeded) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); } capture(minSecuredLSN, false); if (checkpointSucceeded) { for (Long securedLSN : securedLSNs.values()) { if (minSecuredLSN >= securedLSN) { return minSecuredLSN; } } txnSubsystem.getLogManager().deleteOldLogFiles(minSecuredLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minSecuredLSN)); } return minSecuredLSN; } @Override public synchronized void secure(TxnId id) throws HyracksDataException { securedLSNs.put(id, txnSubsystem.getRecoveryManager().getMinFirstLSN()); } @Override public synchronized void completed(TxnId id) throws IllegalStateException { if (securedLSNs.containsKey(id)) { securedLSNs.remove(id); } else { throw new IllegalStateException(...); } }
public void abortTransaction(TxnId txnId) throws ACIDException { final ITransactionContext txnCtx = getTransactionContext(txnId); try { if (txnCtx.isWriteTxn()) { LogRecord logRecord = new LogRecord(); TransactionUtil.formJobTerminateLogRecord(txnCtx, logRecord, false); txnSubsystem.getLogManager().log(logRecord); txnSubsystem.getCheckpointManager().secure(txnId); txnSubsystem.getRecoveryManager().rollbackTransaction(txnCtx); txnCtx.setTxnState(ITransactionManager.ABORTED); } } catch (ACIDException | HyracksDataException e) { String msg = "Could not complete rollback! System is in an inconsistent state"; if (LOGGER.isErrorEnabled()) { LOGGER.log(Level.ERROR, msg, e); } throw new ACIDException(msg, e); } finally { txnCtx.complete(); txnSubsystem.getLockManager().releaseLocks(txnCtx); txnCtxRepository.remove(txnCtx.getTxnId()); txnSubsystem.getCheckpointManager().completed(txnId); } } public long getMaxTxnId() { return maxTxnId.get(); } public void start() { // implementation }
public abstract class AbstractCheckpointManager implements ICheckpointManager { private static final Logger LOGGER = LogManager.getLogger(); private static final String CHECKPOINT_FILENAME_PREFIX = "checkpoint_"; public static final long SHARP_CHECKPOINT_LSN = -1; private static final FilenameFilter filter = (File dir, String name) -> name.startsWith(CHECKPOINT_FILENAME_PREFIX); private final File checkpointDir; private final int historyToKeep; private final int lsnThreshold; private final int pollFrequency; private Map<TxnId, Long> securedLSNs; protected final ITransactionSubsystem txnSubsystem; private CheckpointThread checkpointer; public AbstractCheckpointManager(ITransactionSubsystem txnSubsystem, CheckpointProperties checkpointProperties) { this.txnSubsystem = txnSubsystem; String checkpointDirPath = checkpointProperties.getCheckpointDirPath(); if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Checkpoint directory = " + checkpointDirPath); } if (!checkpointDirPath.endsWith(File.separator)) { checkpointDirPath += File.separator; } checkpointDir = new File(checkpointDirPath); // Create the checkpoint directory if missing if (!checkpointDir.exists()) { checkpointDir.mkdirs(); } // Initialize other properties historyToKeep = checkpointProperties.getHistoryToKeep(); lsnThreshold = checkpointProperties.getLsnThreshold(); pollFrequency = checkpointProperties.getPollFrequency(); securedLSNs = new HashMap<>(); } }
for (DatasetResourceReference indexRef : partitionResources) { long remoteIndexMaxLSN = idxCheckpointMgrProvider.get(indexRef).getLowWatermark(); minRemoteLSN = Math.min(minRemoteLSN, remoteIndexMaxLSN); } } return minRemoteLSN; } @Override public synchronized void replayReplicaPartitionLogs(Set<Integer> partitions, boolean flush) throws HyracksDataException { //replay logs > minLSN that belong to these partitions final TxnId randomDummyTxnId = new TxnId(ThreadLocalRandom.current().nextInt(Integer.MIN_VALUE, -1)); try { checkpointManager.secure(randomDummyTxnId); long minLSN = getPartitionsMinLSN(partitions); long readableSmallestLSN = logMgr.getReadableSmallestLSN(); if (minLSN < readableSmallestLSN) { minLSN = readableSmallestLSN; } replayPartitionsLogs(partitions, logMgr.getLogReader(true), minLSN); if (flush) { appCtx.getDatasetLifecycleManager().flushAllDatasets(); } } catch (IOException | ACIDException e) { throw HyracksDataException.create(e); } finally { checkpointManager.completed(randomDummyTxnId); } } @Override
package com.android.internal.telephony; import android.content.Context; import android.content.Intent; import android.content.IntentFilter; import android.content.BroadcastReceiver; import com.android.internal.telephony.CallForwardInfo; import com.android.internal.telephony.gsm.CommandException; import com.android.internal.telephony.gsm.NetworkInfo; import com.android.internal.telephony.gsm.PDPContextState; import com.android.internal.telephony.IccUtils; import com.android.internal.telephony.gsm.SmsResponse; import com.android.internal.telephony.gsm.SuppServiceNotification; import android.os.Parcel; import java.io.IOException; import android.os.Message; import android.os.Handler; import android.net.LocalSocketAddress; import android.net.LocalSocket; import com.android.internal.os.HandlerThread; import android.os.HandlerInterface; import java.util.ArrayList; import java.util.Collections; import java.io.InputStream; import android.telephony.PhoneNumberUtils; import android.telephony.gsm.SmsManager; public class PhoneSubInfo { private Phone mPhone; private Context mContext; public PhoneSubInfo(Phone phone) { mPhone = phone; mContext = phone.getContext(); } } void doSharpCheckpoint() throws HyracksDataException; long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void secure(TxnId id) throws HyracksDataException; void completed(TxnId id);
long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void secure(TxnId id) throws HyracksDataException; void completed(TxnId id);
package org.apache.asterix.transaction.management.service.recovery; import java.io.BufferedWriter; import java.io.File; import java.io.FilenameFilter; import java.io.IOException; import java.io.OutputStream; import java.nio.channels.ClosedByInterruptException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import org.apache.asterix.common.exceptions.ACIDException; import org.apache.asterix.common.transactions.Checkpoint; import org.apache.asterix.common.transactions.CheckpointProperties; import org.apache.asterix.common.transactions.ICheckpointManager; import org.apache.asterix.common.transactions.ILogManager; import org.apache.asterix.common.transactions.ITransactionManager; import org.apache.asterix.common.transactions.ITransactionSubsystem; import org.apache.asterix.common.transactions.TxnId; import org.apache.asterix.common.utils.StorageConstants; import org.apache.hyracks.api.exceptions.HyracksDataException; public class RecoveryService { // TODO: Add code here }
@Override public synchronized long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException { LOGGER.info("Attempting soft checkpoint..."); final long minFirstLSN = txnSubsystem.getRecoveryManager().getMinFirstLSN(); final long minSecuredLSN = getMinSecuredLSN(); if (checkpointTargetLSN >= minSecuredLSN) { return minSecuredLSN; } boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN; if (!checkpointSucceeded) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); } capture(minFirstLSN, false); if (checkpointSucceeded) { txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("Soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; } private synchronized long getMinSecuredLSN() { // implementation omitted }
IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); capture(minFirstLSN, false); if (checkpointSucceeded) { txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; private synchronized long getMinSecuredLSN() { return securedLSNs.isEmpty() ? -1 : Collections.min(securedLSNs.values()); } @Override public synchronized void secure(TxnId id) throws HyracksDataException { securedLSNs.put(id, txnSubsystem.getRecoveryManager().getMinFirstLSN()); } @Override public synchronized void completed(TxnId id) { securedLSNs.remove(id); }
public void run() { Thread ct = Thread.currentThread(); String threadName = ct.getName(); if (!addPendingThread(ct)) { exceptions.add(new InterruptedException("Task " + getTaskAttemptId() + " was aborted!")); ExceptionUtils.setNodeIds(exceptions, ncs.getId()); ncs.getWorkQueue().schedule(new NotifyTaskFailureWork(ncs, this, exceptions)); return; } try { ct.setName(displayName + ":" + taskAttemptId + ":" + 0); try { operator.initialize(); if (collectors.length > 0) { final Semaphore sem = new Semaphore(collectors.length - 1); for (int i = 1; i < collectors.length; ++i) { final IPartitionCollector collector = collectors[i]; final IFrameWriter writer = operator.getInputFrameWriter(i); sem.acquire(); final int cIdx = i; executorService.execute(new Runnable() { @Override public void run() { try { collector.open(); writer.open(); while (collector.hasNext()) { writer.nextFrame(collector.nextFrame()); } } catch (Exception e) { exceptions.add(e); } finally { writer.close(); collector.close(); sem.release(); } } }); } } operator.start(); } catch (Exception e) { exceptions.add(e); } finally { operator.close(); } } catch (Exception e) { exceptions.add(e); } finally { ct.setName(threadName); removePendingThread(ct); } }
import java.nio.charset.Charset; import java.util.Arrays; import java.util.TimeZone; public class DateTimeFormatUtils { private static final byte[][] TIMEZONE_IDS; private static final int[] TIMEZONE_OFFSETS; private static final Charset ENCODING = Charset.forName("UTF-8"); static { String[] tzIds = TimeZone.getAvailableIDs(); int tzCount = tzIds.length; TIMEZONE_IDS = new byte[tzCount][]; TIMEZONE_OFFSETS = new int[tzCount]; for (int i = 0; i < tzCount; i++) { TIMEZONE_IDS[i] = encode(tzIds[i]); } Arrays.sort(TIMEZONE_IDS, byteArrayComparator); for (int i = 0; i < tzCount; i++) { String tzId; try { tzId = new String(TIMEZONE_IDS[i], ENCODING); } catch (UnsupportedEncodingException e) { throw new IllegalStateException(ENCODING, e); } TIMEZONE_OFFSETS[i] = TimeZone.getTimeZone(tzId).getRawOffset(); } } private static byte[] encode(String tzId) { // implementation of encode method } private static int byteArrayComparator(byte[] a, byte[] b) { // implementation of byteArrayComparator method } private DateTimeFormatUtils() { } public static DateTimeFormatUtils getInstance() { return INSTANCE; } private int parseFormatField(byte[] format, int formatStart, int formatLength, int formatPointer, char formatChar, int maxAllowedFormatCharCopied) { int formatCharCopies = 0; formatPointer++; formatCharCopies++; // implementation of parseFormatField method } }
&& data[dataStart + timezoneEndField] <= 'Z') || data[dataStart + timezoneEndField] == '/' || data[dataStart + timezoneEndField] == '_') { timezoneEndField++; } int searchIdx = binaryTimezoneIDSearch(data, dataStart + dataStringPointer, timezoneEndField - dataStringPointer); if (searchIdx >= 0) { timezone = TIMEZONE_OFFSETS[searchIdx]; } else { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException("Unexpected timezone string: " + decode(data, dataStart + dataStringPointer, dataStart + timezoneEndField)); } else { return false; } } dataStringPointer = timezoneEndField; timezoneExists = true; break; case AMPM: if (dataStringPointer + 1 < dataLength) { if (hour > 12 || hour <= 0) { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException("Hour " + hour + " cannot be a time for AM/PM."); } else { return false; } } char ampm = data[dataStart + dataStringPointer]; if (ampm == 'A' || ampm == 'a') { if (hour == 12) { hour = 0; } } else if (ampm == 'P' || ampm == 'p') { if (hour < 12) { hour += 12; } } else { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException("Invalid AM/PM indicator: " + ampm); } else { return false; } } dataStringPointer++; break; }
} else { return false; } if (byteArrayEqualToString(data, dataStart + dataStringPointer, 2, AM_BYTEARRAY)) { // do nothing } else if (byteArrayEqualToString(data, dataStart + dataStringPointer, 2, PM_BYTEARRAY)) { hour += 12; if (hour == 24) { hour = 0; } } else { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException("Unexpected string for AM/PM marker " + decode(data, dataStart + dataStringPointer, dataStart + dataStringPointer + 2)); } else { return false; } } dataStringPointer += 2; } else { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException("Cannot find valid AM/PM marker."); } else { return false; } } break; case SKIPPER: // just skip all continuous character and numbers
public long getWrites() { try { List<String> rows = getInfo(); long writes = extractRow(rows, 5); long cancelledWrites = extractRow(rows, 6); return writes - cancelledWrites; } catch (Exception e) { LOGGER.log(failureCount++ > 0 ? Level.DEBUG : Level.WARN, "Failure getting writes", e); return IOCounterDefault.IO_COUNTER_UNAVAILABLE; } }
"Input stream given to OnDiskInvertedIndex bulk load is not sorted."); } } // Remember last tuple by creating a copy. // TODO: This portion can be optimized by only copying the token when it changes, and using the last appended inverted-list element as a reference. lastTupleBuilder.reset(); for (int i = 0; i < tuple.getFieldCount(); i++) { lastTupleBuilder.addField(tuple.getFieldData(i), tuple.getFieldStart(i), tuple.getFieldLength(i)); } } @Override public void end() throws HyracksDataException { // The last tuple builder is empty if add() was never called. if (lastTupleBuilder.getSize() != 0) { createAndInsertBTreeTuple(); } btreeBulkloader.end(); if (currentPage != null) { queue.put(currentPage); } invListsMaxPageId = currentPageId; bufferCache.finishQueue(); } @Override public void abort() throws HyracksDataException { if (btreeBulkloader != null) { btreeBulkloader.abort(); } } } @Override
IRecordDescriptorProvider recordDescProvider, final int partition, int nPartitions) { final RecordDescriptor rd0 = recordDescProvider.getInputRecordDescriptor(hpaId, 0); final RecordDescriptor rd1 = recordDescProvider.getInputRecordDescriptor(getActivityId(), 0); final IBinaryComparator[] comparators = new IBinaryComparator[comparatorFactories.length]; for (int i = 0; i < comparatorFactories.length; ++i) { comparators[i] = comparatorFactories[i].createBinaryComparator(); } final IMissingWriter[] nullWriters1 = isLeftOuter ? new IMissingWriter[nonMatchWriterFactories.length] : null; if (isLeftOuter) { for (int i = 0; i < nonMatchWriterFactories.length; i++) { nullWriters1[i] = nonMatchWriterFactories[i].createMissingWriter(); } } final IPredicateEvaluator predEvaluator = (predEvaluatorFactory == null ? null : predEvaluatorFactory.createPredicateEvaluator()); IOperatorNodePushable op = new AbstractUnaryInputSinkOperatorNodePushable() { private HashBuildTaskState state; @Override public void open() throws HyracksDataException { ITuplePartitionComputer hpc0 = new FieldHashPartitionComputerFactory(keys0, hashFunctionFactories) // ... } // ... }; // ... } long fileSize = fileChannel.size(); if (LSMComponentJob != null) { ILSMComponent diskComponent = LSMComponentJob.getLSMIndexOperationContext().getComponentsToBeReplicated().get(0); long LSNByteOffset = AsterixLSMIndexUtil.getComponentFileLSNOffset((AbstractLSMIndex) LSMComponentJob.getLSMIndex(), diskComponent, filePath); asterixFileProperties.initialize(filePath, fileSize, nodeId, isLSMComponentFile, LSNByteOffset, remainingFiles == 0); } else { asterixFileProperties.initialize(filePath, fileSize, nodeId, isLSMComponentFile, IMetaDataPageManager.INVALID_LSN_OFFSET, remainingFiles == 0); } requestBuffer = ReplicationProtocol.writeFileReplicationRequest(requestBuffer, asterixFileProperties, ReplicationRequestType.REPLICATE_FILE); Iterator<Map.Entry<String, SocketChannel>> iterator = replicasSockets.entrySet().iterator(); while (iterator.hasNext()) {
public class OnDiskInvertedIndexAccessor implements IInvertedIndexAccessor { private final OnDiskInvertedIndex index; private final IInvertedIndexSearcher searcher; private final IIndexOperationContext opCtx = new OnDiskInvertedIndexOpContext(btree); public OnDiskInvertedIndexAccessor(OnDiskInvertedIndex index) throws HyracksDataException { this.index = index; this.searcher = new TOccurrenceSearcher(ctx, index); } protected OnDiskInvertedIndexAccessor(OnDiskInvertedIndex index, IInvertedIndexSearcher searcher) { this.index = index; this.searcher = searcher; } @Override public IIndexCursor createSearchCursor(boolean exclusive) { return new OnDiskInvertedIndexSearchCursor(searcher, index.getInvListTypeTraits().length); } @Override public void search(IIndexCursor cursor, ISearchPredicate searchPred) throws HyracksDataException { searcher.search((OnDiskInvertedIndexSearchCursor) cursor, (InvertedIndexSearchPredicate) searchPred, opCtx); } @Override public IInvertedListCursor createInvertedListCursor() { return index.createInvertedListCursor(); } @Override public void openInvertedListCursor(IInvertedListCursor listCursor, ITupleReference searchKey) throws HyracksDataException { index.openInvertedListCursor(listCursor, searchKey); } }
public void setKeyTuple(ITupleReference key) { boolean newToken = this.keyTuple == null; this.keyTuple = key; }
for (int i = 0; i < end; i++) { if (bloomFilters[i] != null && !bloomFilters[i].contains(keysOnlyTuple, hashes)) { continue; } deletedKeysBTreeAccessors.get(i).search(deletedKeysBTreeCursors[i], keySearchPred); try { if (deletedKeysBTreeCursors[i].hasNext()) { return true; } } finally { deletedKeysBTreeCursors[i].close(); } } return false; } @Override public void doClose() throws HyracksDataException { try { super.doClose(); } finally { if (deletedKeysBTreeCursors != null) { for (int i = 0; i < deletedKeysBTreeCursors.length; i++) { deletedKeysBTreeCursors[i].close(); } } } } @Override public void doDestroy() throws HyracksDataException { if (deletedKeysBTreeCursors != null) { for (int i = 0; i < deletedKeysBTreeCursors.length; i++) { deletedKeysBTreeCursors[i].close(); } } super.doClose(); }
import java.util.StringTokenizer; import android.content.Context; import android.hardware.Sensor; import android.hardware.SensorEvent; import android.hardware.SensorEventListener; import android.hardware.SensorManager; import android.os.Build; import android.os.Bundle; import android.os.Message; import android.os.PowerManager; import android.provider.Settings; import android.provider.Settings.Global; import android.provider.Settings.SettingNotFoundException; import android.util.Log; import android.view.View; import android.widget.TextView; import com.android.cts.verifier.sensors.BaseSensorTestActivity.SensorTestResult; public class PowerTestHostLink { public class PowerTestHostLink { } } import java.util.StringTokenizer; import android.content.Context; import android.hardware.Sensor; import android.hardware.SensorEvent; import android.hardware.SensorEventListener; import android.hardware.SensorManager; import android.os.Build; import android.os.Bundle; import android.os.Message; import android.os.PowerManager; import android.provider.Settings; import android.provider.Settings.Global; import android.provider.Settings.SettingNotFoundException; import android.util.Log; import android.view.View; import android.widget.TextView; import com.android.cts.verifier.sensors.BaseSensorTestActivity.SensorTestResult; public class PowerTestHostLink { public class PowerTestHostLink { } } IIndex invIndex = testCtx.getIndex(); if (LOGGER.isInfoEnabled()) { LOGGER.info("Validating index: " + invIndex); } // Validate index and compare against expected index. invIndex.validate(); if (invIndexType == InvertedIndexType.INMEMORY || invIndexType == InvertedIndexType.ONDISK) { // This comparison method exercises different features of these types of inverted indexes. LSMInvertedIndexTestUtils.compareActualAndExpectedIndexes(testCtx); } //LSMInvertedIndexTestUtils.compareActualAndExpectedIndexesRangeSearch(testCtx); if (invIndexType == InvertedIndexType.LSM || invIndexType == InvertedIndexType.PARTITIONED_LSM) { LSMInvertedIndex lsmIndex = (LSMInvertedIndex) invIndex; if (!lsmIndex.isMemoryComponentsAllocated() || lsmIndex.isCurrentMutableComponentEmpty()) { LSMInvertedIndexTestUtils.compareActualAndExpectedIndexesMergeSearch(testCtx); } } } protected void runTinySearchWorkload(LSMInvertedIndexTestContext testCtx, TupleGenerator tupleGen) throws IOException { for (IInverted
public boolean isSubFieldNullable(List<String> subFieldName) throws AlgebricksException { IAType subRecordType = getFieldType(subFieldName.get(0)); for (int i = 1; i < subFieldName.size(); i++) { if (subRecordType == null) { return true; } if (subRecordType.getTypeTag().equals(ATypeTag.UNION)) { if (NonTaggedFormatUtil.isOptional(subRecordType)) { return true; } subRecordType = ((AUnionType) subRecordType).getActualType(); if (subRecordType.getTypeTag() != ATypeTag.OBJECT) { throw new AsterixException("Field accessor is not defined for values of type " + subRecordType.getTypeTag()); } } subRecordType = ((ARecordType) subRecordType).getFieldType(subFieldName.get(i)); } return subRecordType == null || NonTaggedFormatUtil.isOptional(subRecordType); }
boolean changed = changeRec(expr, arg); if (!checkArgs(expr) || !expr.isFunctional()) { return new Pair<>(changed, expr); } // Skip Constant Folding for the record-related functions. if (FUNC_ID_SET_THAT_SHOULD_NOT_BE_APPLIED.contains(expr.getFunctionIdentifier())) { return new Pair<>(false, null); } try { if (expr.getFunctionIdentifier().equals(BuiltinFunctions.UNORDERED_LIST_CONSTRUCTOR) || expr.getFunctionIdentifier().equals(BuiltinFunctions.ORDERED_LIST_CONSTRUCTOR)) { AbstractCollectionType listType = (AbstractCollectionType) TypeCastUtils.getRequiredType(expr); if (listType != null && (listType.getItemType().getTypeTag() == ATypeTag.ANY || listType.getItemType() instanceof AbstractCollectionType)) { //case1: listType == null, could be a nested list inside a list<ANY> //case2: itemType = ANY //case3: itemType = a nested list
IScalarEvaluator eval = fact.createScalarEvaluator(null); eval.evaluate(null, p); Object t = _emptyTypeEnv.getType(expr); @SuppressWarnings("rawtypes") ISerializerDeserializer serde = jobGenCtx.getSerializerDeserializerProvider().getSerializerDeserializer(t); bbis.setByteBuffer(ByteBuffer.wrap(p.getByteArray(), p.getStartOffset(), p.getLength()), 0); IAObject o = null; try { o = (IAObject) serde.deserialize(dis); } catch (HyracksDataException | AlgebricksException e) { return new Pair<>(false, null); } return new Pair<>(true, new ConstantExpression(new AsterixConstantValue(o))); @Override public Pair<Boolean, ILogicalExpression> visitAggregateFunctionCallExpression(AggregateFunctionCallExpression expr, Void arg) throws AlgebricksException { boolean changed = changeRec(expr, arg); return new Pair<>(changed, expr); } @Override public Pair<Boolean, ILogicalExpression> visitStatefulFunctionCallExpression(StatefulFunctionCallExpression expr, Void arg) throws AlgebricksException { boolean changed = changeRec(expr, arg); return new Pair<>(changed, expr); }
empty-tuple-source -- |UNPARTITIONED| assign [$$29] <- [TRUE] -- |UNPARTITIONED| assign [$$26] <- [TRUE] -- |UNPARTITIONED| data-scan []<-[$$20, $$21, $$2] <- tpch:LineItems -- |UNPARTITIONED| */ public class InlineSubplanInputForNestedTupleSourceRule implements IAlgebraicRewriteRule { @Override public boolean rewritePre(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException { if (context.checkIfInDontApplySet(this, opRef.getValue())) { return false; } Pair<Boolean, LinkedHashMap<LogicalVariable, LogicalVariable>> result = rewriteSubplanOperator(opRef, context); return result.first; } private Pair<Boolean, LinkedHashMap<LogicalVariable, LogicalVariable>> rewriteSubplanOperator(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException { AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue(); Pair<Boolean, LinkedHashMap<LogicalVariable, LogicalVariable>> changedAndVarMap = traverseNonSubplanOperator(op, context); return changedAndVarMap; } }
translator.addVariableToMetaScope(new VarIdentifier("$$RIGHT_" + i), rightInputVarCopy); for (int j = 0; j < rightInputPKs.size(); j++) { rightInputVarCopy = copyVisitor.varCopy(rightInputPKs.get(j)); translator.addVariableToMetaScope(new VarIdentifier("$$RIGHTPK_" + i + "_" + j), rightInputVarCopy); } copyVisitor.updatePrimaryKeys(context); copyVisitor.reset(); counter.set(context.getVarCounter()); AQLPlusParser parser = new AQLPlusParser(new StringReader(aqlPlus)); parser.initScope(); parser.setVarCounter(counter); List<Clause> clauses; try { clauses = parser.Clauses(); } catch (ParseException e) { throw new AlgebricksException(e); } ILogicalPlan plan; try { plan = translator.translate(clauses); } catch (AsterixException e) { throw new AlgebricksException(e); } context.setVarCounter(counter.get());
@Test public void testCatalogdTableInvalidator() throws CatalogException, InterruptedException { Reference<Boolean> tblWasRemoved = new Reference<>(); Reference<Boolean> dbWasAdded = new Reference<>(); String dbName = "functional"; String tblName = "alltypes"; catalog_.invalidateTable(new TTableName(dbName, tblName), tblWasRemoved, dbWasAdded); MockTicker ticker = new MockTicker(); CatalogdTableInvalidator.TIME_SOURCE = ticker; catalog_.setCatalogdTableInvalidator( new CatalogdTableInvalidator(catalog_, /*unusedTableTtlSec=*/ 2, /*invalidateTablesOnMemoryPressure=*/false, /*oldGenFullThreshold=*/ 0.6, /*gcInvalidationFraction=*/0.1)); Assert.assertFalse(catalog_.getDb(dbName).getTable(tblName).isLoaded()); Table table = catalog_.getOrLoadTable(dbName, tblName); Assert.assertTrue(table.isLoaded()); Assert.assertEquals(ticker.now_, table.getLastUsedTime()); long previousTriggerCount = catalog_.getCatalogdTableInvalidator().triggerCount_.get(); long triggerCount; do { triggerCount = catalog_.getCatalogdTableInvalidator().triggerCount_.get(); Thread.sleep(100); } while (triggerCount == previousTriggerCount); Assert.assertEquals(previousTriggerCount + 1, triggerCount); }
profile_ = new TRuntimeProfileNode("Frontend", /*num_children=*/ 0, /*counters=*/new ArrayList<>(), /*metadata=*/-1L, /*indent=*/false, /*info_strings=*/new HashMap<>(), /*info_strings_display_order*/new ArrayList<>(), /*child_counters_map=*/ImmutableMap.of(ROOT_COUNTER_NAME, new HashSet<>())); public static Scope createNewWithScope() { return new Scope(new FrontendProfile()); } @Nonnull public static FrontendProfile getCurrent() { FrontendProfile prof = THREAD_LOCAL.get(); Preconditions.checkState(prof != null, "no profile in scope"); return prof; }
private boolean shouldEvictFromFullHeapAfterGc() { if (!invalidateTableOnMemoryPressure_) { return false; } long gcCount = oldGenGcBean_.getCollectionCount(); if (gcCount > lastObservedGcCount_) { lastObservedGcCount_ = gcCount; GcInfo lastGcInfo = oldGenGcBean_.getLastGcInfo(); if (lastGcInfo == null) { LOG.warn("gcBean.getLastGcInfo() returns null. Will continue without invalidating tables based on memory pressure this time."); return false; } MemoryUsage tenuredGenUsage = lastGcInfo.getMemoryUsageAfterGc().get(oldGcGenName_); return tenuredGenUsage.getMax() * oldGenFullThreshold_ < tenuredGenUsage.getUsed(); } return false; }
public long getGcCount() { return oldGenGcBean_.getCollectionCount(); } public boolean isMemoryPressure() { long gcCount = getGcCount(); if (gcCount > lastObservedGcCount_) { lastObservedGcCount_ = gcCount; GcInfo lastGcInfo = oldGenGcBean_.getLastGcInfo(); if (lastGcInfo == null) { LOG.warn("gcBean.getLastGcInfo() returns null. Will continue without invalidating tables based on memory pressure this time."); return false; } MemoryUsage tenuredGenUsage = lastGcInfo.getMemoryUsageAfterGc().get(oldGcGenName_); if (tenuredGenUsage == null) { throw new NullPointerException("Memory usage for tenured generation is null."); } return tenuredGenUsage.getMax() * oldGenFullThreshold_ < tenuredGenUsage.getUsed(); } return false; }
public FtraceEvent(ITmfTrace trace, long rank, FtraceField field) { super(trace, rank, TmfTimestamp.fromNanos(field.getTs()), FtraceEventTypeFactory.get(field.getName()), field.getContent()); fField = field; fName = field.getName(); fCallsite = null; } wifiMacAddressPref.setSummary(!TextUtils.isEmpty(macAddress) ? macAddress : getString(R.string.status_unavailable)); Preference wifiIpAddressPref = findPreference(KEY_CURRENT_IP_ADDRESS); String ipAddress = null; if (wifiInfo != null) { long addr = wifiInfo.getIpAddress(); if (addr != 0) { // handle negative values when first octet > 127 if (addr < 0) addr += 0x100000000L; ipAddress = String.format("%d.%d.%d.%d", addr & 0xFF, (addr >> 8) & 0xFF, (addr >> 16) & 0xFF, (addr >> 24) & 0xFF); } } wifiIpAddressPref.setSummary(ipAddress == null ? getString(R.string.status_unavailable) : ipAddress); // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.sshd; import static java.lang.annotation.RetentionPolicy.RUNTIME; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.Target; /** * Annotation tagged on a concrete Command to describe what it is doing */ @Target({ElementType.TYPE}) @Retention(RUNTIME) public @interface CommandMetaData { String name(); String descr() default ""; } if (removedDb == null) { // Nothing was removed from the catalogd's cache. resp.result.setVersion(catalog_.getCatalogVersion()); return; } // Make sure the cache directives, if any, of the underlying tables are removed for (String tableName : removedDb.getAllTableNames()) { uncacheTable(removedDb.getTable(tableName)); } removedObject = removedDb.toTCatalogObject(); updateDatabasePrivileges(db.getName(), /* tableName */ null, params.server_name, db.getMetaStoreDb().getOwnerName(), db.getMetaStoreDb().getOwnerType(), /* newOwner */ null,
table = catalog_.removeTable(params.getTable_name().db_name, params.getTable_name().table_name); if (table == null) { resp.result.setVersion(catalog_.getCatalogVersion()); return; } resp.result.setVersion(table.getCatalogVersion()); uncacheTable(table); if (table.getMetaStoreTable() != null) { updateDatabasePrivileges(table.getDb().getName(), table.getName(), params.server_name, table.getMetaStoreTable().getOwner(), table.getMetaStoreTable().getOwnerType(), /* newOwner */ null, /* newOwnerType */ null, resp); } removedObject.setType(TCatalogObjectType.TABLE); removedObject.setTable(new TTable()); removedObject.getTable().setTbl_name(tableName.getTbl()); removedObject.getTable().setDb_name(tableName.getDb()); removedObject.setCatalog_version(resp.result.getVersion()); resp.result.addToRemoved_catalog_objects(removedObject); }
// list of the revoked privileges that contain the grant option. The rolePrivileges // parameter will contain a list of new privileges without the grant option that are // granted. If this is simply a revoke of a privilege without grant options, the // api will still return revoked privileges, but the rolePrivileges will be empty // since there will be no newly granted privileges. rolePrivileges = Lists.newArrayList(); removedGrantOptPrivileges = catalog_.getSentryProxy().revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), rolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); Preconditions.checkNotNull(rolePrivileges); List<TCatalogObject> updatedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: rolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); }
import com.google.gerrit.extensions.restapi.NotImplementedException; import com.google.gerrit.extensions.restapi.PreconditionFailedException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.restapi.RestReadView; import com.google.gerrit.reviewdb.client.Change; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.reviewdb.client.RefNames; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.ChangeUtil; import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.change.ArchiveFormat; import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.config.GerritServerConfig; import com.google.gerrit.server.git.MergeOp; import com.google.gerrit.server.git.MergeOpRepoManager; import com.google.gerrit.server.git.MergeOpRepoManager.OpenRepo; import com.google.gerrit.server.ioutil.LimitedByteArrayOutputStream; import com.google.gerrit.server.ioutil.LimitedByteArrayOutputStream.LimitExceededException; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.gerrit.server.project.NoSuchProjectException; import com.google.gerrit.server.update.UpdateException; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; public static native void arraycopy(Object src, int srcPos, Object dst, int dstPos, int length); private static final int ARRAYCOPY_SHORT_T_ARRAY_THRESHOLD = 32; public static <T> void arraycopy(T[] src, int srcPos, T[] dst, int dstPos, int length) { if (src.getClass() != dst.getClass() || dst.getClass() != Object[].class || dst.getClass().isAssignableFrom(src.getClass())) { arraycopy(src, srcPos, dst, dstPos, length); } } private long size = 0; private Path tmpFile; public CleanFilter(Repository db, InputStream in, OutputStream out) throws IOException { super(in, out); lfsUtil = new LfsUtil(db.getDirectory().toPath().resolve("lfs")); Files.createDirectories(lfsUtil.getLfsTmpDir()); tmpFile = lfsUtil.createTmpFile(); this.out = out; } resp.result.setVersion(role.getCatalogVersion()); private void grantRevoke
} if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog. if (grantRevokePrivParams.isIs_grant()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setVersion(updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version()); } else if (privileges.get(0).isHas_grant_opt()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion(updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version() > removedPrivs.get(removedPrivs.size() - 1).getCatalog_version() ? updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version() : removedPrivs.get(removedPrivs.size() - 1).getCatalog_version()); } else { resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion(
private static final String ERROR_MSG_BAD_COLUMN_VALUE = "Raw value '" + ROW_BAD_COLUMN_VALUE + "' couldn't be parsed to type Type: int8 for column 'byteFld'"; private static final String POLICY_REJECT = "REJECT"; private static final String POLICY_WARN = "WARN"; private static final String POLICY_IGNORE = "IGNORE"; @Rule public ExpectedException thrown = ExpectedException.none(); @Test public void testMissingColumnThrowsExceptionDefaultConfig() throws Exception { Context additionalContext = new Context(); additionalContext.put(PATTERN_PROP, TEST_REGEXP_MISSING_COLUMN); testThrowsException(additionalContext, ERROR_MSG_MISSING_COLUMN, ROW_MISSING_COLUMN); } @Test public void testMissingColumnThrowsExceptionDeprecated() throws Exception { Context additionalContext = new Context(); additionalContext.put(PATTERN_PROP, TEST_REGEXP_MISSING_COLUMN); additionalContext.put(SKIP_MISSING_COLUMN_PROP, String.valueOf(false)); testThrowsException(additionalContext, ERROR_MSG_MISSING_COLUMN, ROW_MISSING_COLUMN); } @Test public void testMissingColumnThrowsException() throws Exception { Context additionalContext = new Context(); additionalContext.put(PATTERN_PROP, TEST_REGEXP_MISSING_COLUMN); testThrowsException(additionalContext, ERROR_MSG_MISSING_COLUMN, ROW_MISSING_COLUMN); }
* The phases of aggregate computation are as follows. Also see AggregateInfo. - Only a non-distinct class: - Example: SELECT max(a) FROM... - 1-phase aggregation - One distinct class, and optionally a non-distinct class: - Example: SELECT count(distinct a)[, max(b)] FROM... - coalesced into a single AggregateInfo to preserve the pre-IMPALA-110 behavior - 2-phase aggregation, 1st phase groups by GROUP BY ples DISTINCT exprs, 2nd phase groups by GROUP BY - the non-distinct class is carried along the two phases, aggregated in 1st phase and merged in 2nd phase - Multiple distinct classes, and optionally a non-distinct class - Example: SELECT count(distinct a), count(distinct b)[, max(c)] FROM... - 2-phase aggregation followed by a transposition aggregation - aggregation nodes update and maintain the state of all aggregation classes at once
final private Thread daemonThread_; final private double oldGenFullThreshold_; final private double gcInvalidationFraction_; @VisibleForTesting AtomicLong scanCount_ = new AtomicLong(); private GarbageCollectorMXBean oldGenGcBean_; private String oldGcGenName_; private long lastObservedGcCount_; private boolean stopped_ = false; private long lastInvalidationTime_;
private boolean shouldEvictFromFullHeapAfterGc() { if (!invalidateTableOnMemoryPressure_) { return false; } long gcCount = oldGenGcBean_.getCollectionCount(); if (gcCount > lastObservedGcCount_) { lastObservedGcCount_ = gcCount; GcInfo lastGcInfo = oldGenGcBean_.getLastGcInfo(); if (lastGcInfo == null) { LOG.warn("gcBean.getLastGcInfo() returns null. Will continue without invalidating tables based on memory pressure this time."); return false; } MemoryUsage tenuredGenUsage = lastGcInfo.getMemoryUsageAfterGc().get(oldGcGenName_); return tenuredGenUsage.getMax() * oldGenFullThreshold_ < tenuredGenUsage.getUsed(); } return false; }
* If a user with the same name already exists it will be overwritten. */ public User addUser(String userName) { Principal user = addPrincipal(userName, Sets.<String>newHashSet(), TPrincipalType.USER); Preconditions.checkState(user instanceof User); return (User) user; } /** * Add a user to the catalog if it doesn't exist. This is necessary so privileges * can be added for a user. For example owner privileges. */ public org.apache.impala.catalog.User addUserIfNotExists(String owner) { versionLock_.writeLock().lock(); try { org.apache.impala.catalog.User user = getAuthPolicy().getUser(owner); if (user == null) { user = addUser(owner); } return user; } finally { versionLock_.writeLock().unlock(); } } private Principal addPrincipal(String principalName, Set<String> grantGroups, TPrincipalType type) { versionLock_.writeLock().lock(); try { Principal principal = Principal.newInstance(principalName, type, grantGroups); // ... rest of the code } finally { versionLock_.writeLock().unlock(); } }
public FullPackageLoader(@Nonnull JackLibrary jackLibrary, @Nonnull JPhantomLookup lookup) { super(jackLibrary, jackLibrary.getLibraryVDir(), lookup, NodeLevel.FULL); } public synchronized static ReportManagerRegistry getInstance() { if (instance == null) { instance = new ReportManagerRegistry(); instance.subscribe(ReportManagerConstants.LOG_OUTPUT_DEFAULT); //$NON-NLS-1$ } return instance; } "refs/for/master"); private PushOneCommit.Result createChange(TestRepository<?> repo, String subject, String fileName, String content, List<RevCommit> parents) throws Exception { return createChange(repo, subject, fileName, content, parents, "refs/for/master"); } private PushOneCommit.Result createChange(String subject, List<RevCommit> parents) throws Exception { return createTestChange(testRepo, subject, "", "", parents, "refs/for/master"); } private PushOneCommit.Result createChange(String subject, String fileName, String content, List<RevCommit> parents) throws Exception { return createChange(testRepo, subject, fileName, content, parents, "refs/for/master"); } PrincipalPrivilege privilege = owner.getPrivilege(filter.getPrivilege_name()); if (privilege != null) { PrincipalPrivilege removedPrivilege = catalog_.getAuthPolicy().removePrivilege(privilege); removedPrivilege.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } catch (CatalogException e) { LOG.error("Error modifying privilege: ", e); } private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); } } catch (CatalogException e) { LOG.error("Error adding privilege to catalog: ", e); } }
import java.util.regex.Matcher; import java.util.regex.Pattern; import org.eclipse.osee.framework.core.enums.BranchType; import org.eclipse.osee.framework.jdk.core.type.IResourceRegistry; import org.eclipse.osee.framework.jdk.core.type.ResourceToken; import org.eclipse.osee.orcs.data.BranchReadable; import org.eclipse.osee.orcs.search.BranchQuery; import org.eclipse.osee.template.engine.CompositeRule; import org.eclipse.osee.template.engine.IdentifiableOptionsRule; import org.eclipse.osee.template.engine.PageCreator; import org.eclipse.osee.template.engine.PageFactory; public class OseeAppletPage { //example input for pattern: <input id="selected_branch" type="text" list="baselineBranches" required/><br /> private static final Pattern listAttributePattern = Pattern.compile("<input[^>]+?list=\"([^\"]+)"); private final BranchQuery query; public OseeAppletPage(BranchQuery query) { this.query = query; } public String realizeApplet(IResourceRegistry registry, ResourceToken valuesResource) { PageCreator page = PageFactory.newPageCreator(registry); return realizeApplet(valuesResource, page); } }
public void activate() { refresh(); } public Version getMinVersion() { List<Version> versions = getAllVersions(); if (versions.isEmpty()) { return Version.NO_VERSION; } else if (versions.size() == 1) { return versions.get(0); } else { Version minVersion = versions.get(0); for (Version version : versions) { if (version.compareTo(minVersion) < 0) { minVersion = version; } } return minVersion; } } boolean isFiltered = true; if (artifact != null) { if (FilterType.ONLY_DIRTIES == filter) { isFiltered = !artifact.isDirty(); } } Map<String, Set<TSentryPrivilege>> allUsersPrivileges = sentryPolicyService_.listAllUsersPrivileges(processUser_); for (Map.Entry<String, Set<TSentryPrivilege>> userPrivilegesEntry : allUsersPrivileges.entrySet()) { String userName = userPrivilegesEntry.getKey(); usersToRemove.remove(userName); org.apache.impala.catalog.User user = catalog_.addUserIfNotExists(userName); if (resetVersions_) { user.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } refreshPrivilegesInCatalog(user, allUsersPrivileges); } return usersToRemove; private void refreshPrivilegesInCatalog(Principal principal, Map<String, Set<TSentryPrivilege>> allPrincipalPrivileges) throws CatalogException { // Assume all privileges should be removed. Privileges that still exist are // deleted from this set and we are left with the set of privileges that need // to be removed. }
TableName tableName = table.getTableName(); PrivilegeRequestBuilder builder = new PrivilegeRequestBuilder() .onTable(tableName.getDb(), tableName.getTbl()) .allOf(priv); if (requireGrantOption) { builder.grantOption(); } registerPrivReq(builder.toRequest()); public String getServerName() { return getAuthzConfig().isEnabled() ? getAuthzConfig().getServerName() : null; }
} } Preconditions.checkNotNull(newDb); // TODO(todd): if client is a 'v2' impalad, only send back invalidation resp.result.addToUpdated_catalog_objects(newDb.toTCatalogObject()); } updateOwnerPrivileges(newDb.getName(), /* tableName */ null, params.server_name, /* oldOwner */ null, /* oldOwnerType */ null, newDb.getMetaStoreDb().getOwnerName(), newDb.getMetaStoreDb().getOwnerType(), resp); resp.result.setVersion(newDb.getCatalogVersion()); } /** * If object ownership is enabled in Sentry, we need to update the owner privilege * in the catalog so that any subsequent statements that rely on that privilege, or * the absence, will function correctly without waiting for the next refresh. * If oldOwner is not null, the privilege will be removed. If newOwner is not null, * the privilege will be added. * The catalog will correctly reflect the owner in HMS, however because the owner
String serverName, String oldOwner, PrincipalType oldOwnerType, String newOwner, PrincipalType newOwnerType, TDdlExecResponse resp) { if (catalog_.getSentryProxy() == null || !catalog_.getSentryProxy().isObjectOwnershipEnabled()) return; Preconditions.checkNotNull(serverName); TPrivilege filter; if (tableName == null) { filter = createDatabaseOwnerPrivilegeFilter(databaseName, serverName); } else { filter = createTableOwnerPrivilegeFilter(databaseName, tableName, serverName); } if (!oldOwner.isEmpty()) { removePrivilegeFromCatalog(oldOwner, oldOwnerType, filter, resp); } if (!newOwner.isEmpty()) { addPrivilegeToCatalog(newOwner, newOwnerType, filter, resp); } } private void createFunction(TCreateFunctionParams params, TDdlExecResponse resp) throws ImpalaException { Function fn = Function.fromThrift(params.getFn()); if (LOG.isTraceEnabled()) { LOG.trace(String.format("Adding %s: %s", fn.getClass().getSimpleName(), fn.signatureString())); } }
PrincipalType newOwnerType, TDdlExecResponse resp) { if (catalog_.getSentryProxy() == null || !catalog_.getSentryProxy().isObjectOwnershipEnabled()) return; Preconditions.checkNotNull(serverName); TPrivilege filter; if (tableName == null) { filter = createDatabaseOwnerPrivilegeFilter(databaseName, serverName); } else { filter = createTableOwnerPrivilegeFilter(databaseName, tableName, serverName); } if (oldOwner != null && oldOwner.length() > 0) { removePrivilegeFromCatalog(oldOwner, oldOwnerType, filter, resp); } if (newOwner != null && newOwner.length() > 0) { addPrivilegeToCatalog(newOwner, newOwnerType, filter, resp); } } private void createFunction(TCreateFunctionParams params, TDdlExecResponse resp) throws ImpalaException { Function fn = Function.fromThrift(params.getFn()); if (LOG.isTraceEnabled()) { LOG.trace(String.format("Adding %s: %s", fn.getClass().getSimpleName(), fn.signatureString())); } boolean isPersistentJavaFn = false; if (fn instanceof ScalarFunction) { isPersistentJavaFn = ((ScalarFunction) fn).isPersistentJavaFunction(); } else if (fn instanceof AggregateFunction) { isPersistentJavaFn = ((AggregateFunction) fn).isPersistentJavaFunction(); } if (isPersistentJavaFn) { // Add the function to the catalog catalog_.addJavaFunction((JavaFunction) fn); } else { // Add the function to the local catalog catalog_.addFunction(fn); } resp.setResult(new TCreateFunctionResult()); }
TPrivilege filter, TDdlExecResponse response) { try { Principal owner = catalog_.getAuthPolicy().getPrincipal(ownerString, ownerType == PrincipalType.ROLE ? TPrincipalType.ROLE : TPrincipalType.USER); if (owner != null) { PrincipalPrivilege privilege = owner.getPrivilege(filter.getPrivilege_name()); if (privilege != null) { PrincipalPrivilege removedPrivilege = catalog_.getAuthPolicy().removePrivilege(privilege); removedPrivilege.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } } /** * This is a helper method to take care of catalog related updates when removing * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; // code here } catch (CatalogException e) { LOG.error("Error adding privilege: ", e); } }
PrincipalPrivilege privilege = owner.getPrivilege(filter.getPrivilege_name()); if (privilege != null) { PrincipalPrivilege removedPrivilege = catalog_.getAuthPolicy().removePrivilege(privilege); removedPrivilege.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } else { LOG.error("Error removing privilege: Privilege not found"); } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } } /** * This is a helper method to take care of catalog related updates when removing * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; Reference<Boolean> existingUser = new Reference<>(); if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); } else { owner = catalog_.addRoleIfNotExists(ownerString); filter.setPrincipal_id(owner.getId()); } cPrivilege = new PrincipalPrivilege(owner.getId(), filter); catalog_.getAuthPolicy().addPrivilege(cPrivilege); owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error adding privilege: ", e); } }
} } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } } private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; Reference<Boolean> existingUser = new Reference<>(); if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); } else { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } if (!existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } } catch (CatalogException e) { LOG.error("Error adding privilege to catalog: ", e); } }
public void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; Reference<Boolean> existingUser = new Reference<>(); if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); } else if (ownerType == PrincipalType.ROLE) { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } else { throw new IllegalArgumentException("Invalid owner type: " + ownerType); } if (!existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error adding privilege: ", e); } }
public void addPrivilegeAndCatalogObject(String ownerString, PrincipalType ownerType, Filter filter, User existingUser, Catalog catalog, Response response) { Principal owner; Privilege cPrivilege; if (ownerType == PrincipalType.USER) { owner = catalog.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog.addUserPrivilege(ownerString, filter); } else { owner = catalog.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog.addRolePrivilege(ownerString, filter); } if (!existingUser.getRef()) { owner.setCatalogVersion(catalog.incrementAndGetCatalogVersion()); } response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } private static Partition createHmsPartition(List<TPartitionKeyValue> partitionSpec, org.apache.hadoop.hive.metastore.api.Table msTbl, TableName tableName, String location) { // implementation details }
public List<IPresentationReconciler> getPresentationReconcilers(ISourceViewer sourceViewer, Set<IContentType> contentTypes) { if (this.outOfSync) { sync(); } List<IPresentationReconciler> res = new ArrayList<>(); for (PresentationReconcilerExtension ext : this.extensions.values()) { if (contentTypes.contains(ext.targetContentType)) { res.add(ext); } } return res; } public static void $noinline$foo(int a, int b, int c) { c = c / 42; "".charAt(c); c = c / 42; "".charAt(c); c = c / 42; "".charAt(c); c = c / 42; "".charAt(c); c = c / 42; "".charAt(c); c = c / 42; "".charAt(c); c = c / 42; "".charAt(c); c = c / 42; "".charAt(c); } private static String toLowerFirst(String word) { return word.substring(0, 1).toLowerCase() + word.substring(1); } private static void writeClassFile(Path outputFilePath, StringBuilder builder, boolean force) { File parentFolder = outputFilePath.toFile().getParentFile(); if (!parentFolder.exists()) { parentFolder.mkdirs(); } if (!outputFilePath.toFile().exists() || force) { try { Files.write(outputFilePath, builder.toString().getBytes()); } catch (IOException e) { e.printStackTrace(); } } } private void grantRevokeRolePrivilege(User requestingUser, TGrantRevokePrivParams grantRevokePrivParams, TDdlExecResponse resp) throws ImpalaException { Preconditions.checkNotNull(requestingUser); verifySentryServiceEnabled(); String roleName = grantRevokePrivParams.getRole_name(); List<TPrivilege> privileges = grantRevokePrivParams.getPrivileges(); List<PrincipalPrivilege> addedRolePrivileges = null; List<PrincipalPrivilege> removedGrantOptPrivileges = new ArrayList<>(); if (grantRevokePrivParams.isIs_grant()) { addedRolePrivileges = catalog_.getSentryProxy().grantRolePrivileges(requestingUser, roleName, privileges); addSummary(resp, "Privilege(s) have been granted
private PluginConfigInfo getPluginInfo() { PluginConfigInfo info = new PluginConfigInfo(); info.hasAvatars = toBoolean(avatar.get() != null); info.jsResourcePaths = new ArrayList<>(); for (WebUiPlugin u : plugins) { info.jsResourcePaths.add(String.format("plugins/%s/%s", u.getPluginName(), u.getJavaScriptResourcePath())); } return info; } private List<AccountExternalId.Key> filterKeysByScheme(String keyScheme, ResultSet<AccountExternalId> externalIds) { List<AccountExternalId.Key> filteredExternalIds = new ArrayList<>(); for (AccountExternalId accountExternalId : externalIds) { if (accountExternalId.isScheme(keyScheme)) { filteredExternalIds.add(accountExternalId.getKey()); } } return filteredExternalIds; } public List<IPresentationReconciler> getPresentationReconcilers(ISourceViewer sourceViewer, Set<IContentType> contentTypes) { if (this.outOfSync) { sync(); } List<IPresentationReconciler> res = new ArrayList<>(); for (PresentationReconcilerExtension ext : this.extensions.values()) { if (contentTypes.contains(ext.targetContentType)) { res.add(ext); } } return res; } // list of the revoked privileges that contain the grant option. The // addedRolePrivileges parameter will contain a list of new privileges without the // grant option that are granted. If this is simply a revoke of a privilege without // grant options, the api will still return revoked privileges, but the // addedRolePrivileges will be empty since there will be no newly granted // privileges. addedRolePrivileges = new ArrayList<>(); removedGrantOptPrivileges = catalog_.getSentryProxy() .revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), addedRolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); Preconditions.checkNotNull(addedRolePrivileges); List<TCatalogObject> updatedPrivs = new ArrayList<>(); for (PrincipalPrivilege rolePriv : addedRolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = new ArrayList<>(); for (PrincipalPrivilege rolePriv : removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTC
// grant options, the api will still return revoked privileges, but the // addedRolePrivileges will be empty since there will be no newly granted // privileges. addedRolePrivileges = new ArrayList<>(); removedGrantOptPrivileges = catalog_.getSentryProxy() .revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), addedRolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); Preconditions.checkNotNull(addedRolePrivileges); List<TCatalogObject> updatedPrivs = new ArrayList<>(addedRolePrivileges.size()); for (PrincipalPrivilege rolePriv : addedRolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = new ArrayList<>(removedGrantOptPrivileges.size()); for (PrincipalPrivilege rolePriv : removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); } if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog. }
// privileges. addedRolePrivileges = Lists.newArrayList(); removedGrantOptPrivileges = catalog_.getSentryProxy() .revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), addedRolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); Preconditions.checkNotNull(addedRolePrivileges); List<TCatalogObject> updatedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv : addedRolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv : removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); } if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog. if (grantRevokePrivParams.isIs_grant()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setVersion(...); } else { resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setVersion(...); } }
} if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { if (grantRevokePrivParams.isIs_grant()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setVersion(updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version()); } else if (!privileges.isEmpty() && privileges.get(0).isHas_grant_opt()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion(getLastItemVersion(updatedPrivs) > getLastItemVersion(removedPrivs) ? getLastItemVersion(updatedPrivs) : getLastItemVersion(removedPrivs)); } else { resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion(removedPrivs.get(removedPrivs.size() - 1).getCatalog_version()); } } } /** * Returns the version from the last item in the list. This assumes that the items */
private boolean isObjectOwnershipGrantEnabled() { return catalog_.getSentryProxy() != null && catalog_.getSentryProxy().isObjectOwnershipGrantEnabled(); }
private void verifySentryServiceEnabled() throws CatalogException { if (catalog_.getSentryProxy() == null) { throw new CatalogException("Sentry Service is not enabled on the CatalogServer."); } } private boolean isObjectOwnershipGrantEnabled() { if (catalog_.getSentryProxy() == null) { return false; } return catalog_.getSentryProxy().isObjectOwnershipGrantEnabled(); } private void bulkAlterPartitions(String dbName, String tableName, List<HdfsPartition> modifiedParts) throws ImpalaException { List<org.apache.hadoop.hive.metastore.api.Partition> hmsPartitions = Lists.newArrayList(); for (HdfsPartition p : modifiedParts) { org.apache.hadoop.hive.metastore.api.Partition msPart = p.toHmsPartition(); // perform bulk alter operation } }
originalOwnerName = msDb.getOwnerName(); originalOwnerType = msDb.getOwnerType(); msDb.setOwnerName(params.owner_name); msDb.setOwnerType(PrincipalType.valueOf(params.owner_type.name())); try { applyAlterDatabase(db); } catch (ImpalaRuntimeException e) { msDb.setOwnerName(originalOwnerName); msDb.setOwnerType(originalOwnerType); throw e; } addDbToCatalogUpdate(db, response.result); updateOwnerPrivileges(db.getName(), /* tableName */ null, params.server_name, originalOwnerName, originalOwnerType, db.getMetaStoreDb().getOwnerName(), db.getMetaStoreDb().getOwnerType(), response); addSummary(response, "Updated database."); private void addDbToCatalogUpdate(Db db, TCatalogUpdateResult result) { Preconditions.checkNotNull(db); // Updating the new catalog version and setting it to the DB catalog version while // holding the catalog version lock for an atomic operation. Most DB operations are // short-lived. It is unnecessary to have a fine-grained DB lock. }
public String getCommitSummary() { try (Repository git = args.server.openRepository(project); RevWalk rw = new RevWalk(git); RevWalk merged = new RevWalk(git)) { RevCommit oldId = rw.parseCommit(cmd.getOldId()); RevCommit newId = rw.parseCommit(cmd.getNewId()); rw.reset(); rw.setRevFilter(RevFilter.MERGE_BASE); rw.markStart(rw.parseCommit(oldId)); rw.markStart(rw.parseCommit(newId)); // Find a merge base RevCommit mergeBase = rw.next(); rw.reset(); rw.markStart(oldId); rw.markStart(newId); rw.markUninteresting(mergeBase); RevCommit c; String result = ""; while ((c = rw.next()) != null) { rw.parseBody(c); if (merged.isMergedInto(c, newId)) { result += "+" + c.abbreviate(12) + " " + c.getShortMessage() + "\n"; } else { // Handle other cases } } return result; } } int loopStart = expr.hasCaseExpr() ? 1 : 0; boolean canSimplify = false; for (int i = loopStart; i < numChildren - 1; i += 2) { if (expr.getChild(i).isLiteral()) { canSimplify = true; break; } } if (!canSimplify) { return expr; } List<CaseWhenClause> newWhenClauses = new ArrayList<CaseWhenClause>(); Expr elseExpr = null; for (int i = loopStart; i < numChildren - 1; i += 2) { Expr child = expr.getChild(i); if (child instanceof NullLiteral) { continue; } Expr whenExpr; if (expr.hasCaseExpr()) { if (child.isLiteral()) { BinaryPredicate pred = new BinaryPredicate( BinaryPredicate.Operator.EQ, caseExpr, expr.getChild(i)); // Handle other cases } } } Assert.assertEquals(2, getCount(helper.getCompilerStateFolder(), FileType.JAYCE)); Assert.assertEquals(2, getCount(outputJack, FileType.JAYCE)); @Nonnegative private int getCount(@Nonnull File lib, @Nonnull FileType fileType) throws LibraryIOException { int size =
public SentryProxy(SentryConfig sentryConfig, CatalogServiceCatalog catalog, String kerberosPrincipal) throws ImpalaException { Preconditions.checkNotNull(catalog); Preconditions.checkNotNull(sentryConfig); catalog_ = catalog; if (Strings.isNullOrEmpty(kerberosPrincipal)) { processUser_ = new User(System.getProperty("user.name")); } else { processUser_ = new User(kerberosPrincipal); } sentryPolicyService_ = new SentryPolicyService(sentryConfig); if (sentryConfig.getConfigFile() != null && sentryConfig.getConfigFile().length() > 0) { objectOwnershipConfigValue_ = sentryPolicyService_ .getConfigValue(ServiceConstants.ServerConfig.SENTRY_DB_POLICY_STORE_OWNER_AS_PRIVILEGE); } else { objectOwnershipConfigValue_ = SentryOwnerPrivilegeType.NONE.toString(); } policyReader_.scheduleAtFixedRate(new PolicyReader(false), 0, BackendConfig.INSTANCE.getSentryCatalogPollingFrequency(), TimeUnit.SECONDS); } /** * Refreshes the authorization policy metadata by querying the Sentry Policy Service. */
Preconditions.checkNotNull(catalog); Preconditions.checkNotNull(sentryConfig); catalog_ = catalog; if (Strings.isNullOrEmpty(kerberosPrincipal)) { processUser_ = new User(System.getProperty("user.name")); } else { processUser_ = new User(kerberosPrincipal); } sentryPolicyService_ = new SentryPolicyService(sentryConfig); if (!sentryConfig.getConfigFile().isEmpty()) { objectOwnershipConfigValue_ = sentryPolicyService_ .getConfigValue(ServiceConstants.ServerConfig .SENTRY_DB_POLICY_STORE_OWNER_AS_PRIVILEGE); } else { objectOwnershipConfigValue_ = SentryOwnerPrivilegeType.NONE.toString(); } policyReader_.scheduleAtFixedRate(new PolicyReader(false), 0, BackendConfig.INSTANCE.getSentryCatalogPollingFrequency(), TimeUnit.SECONDS); } /** * Refreshes the authorization policy metadata by querying the Sentry Policy Service. * There is currently no way to get a snapshot of the policy from the Sentry Service, * so this method is called periodically to update the policy. */ private void refreshAuthorizationPolicy() { // Implementation goes here }
// software distributed under the License is distributed on an // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.util; import javax.annotation.concurrent.NotThreadSafe; import java.nio.charset.StandardCharsets; import com.sangupta.murmur.Murmur2; import org.apache.yetus.audience.InterfaceAudience; import org.apache.yetus.audience.InterfaceStability; /** * A Bloom filter implementation. */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private int nBits; private byte[] bitmap; private int nHashes; private byte[] byteBuffer; private HashFunction hashFunction; private BloomFilter(int nBits, byte[] bitmap, int nHashes, HashFunction hashFunction) { this.nBits = nBits; this.bitmap = bitmap; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** * Create a Bloom filter with the given size and false positive rate. * * @param nBytes the number of bytes for the Bloom filter * @param fpRate the desired false positive rate * @return the created Bloom filter */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } }
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.util; import javax.annotation.concurrent.NotThreadSafe; import java.nio.charset.StandardCharsets; import com.sangupta.murmur.Murmur2; import org.apache.yetus.audience.InterfaceAudience; import org.apache.yetus.audience.InterfaceStability; import java.util.BitSet; @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private BitSet bitmap; private int nHashes; private byte[] byteBuffer; private HashFunction hashFunction; private BloomFilter(BitSet bitmap, int nHashes, HashFunction hashFunction) { this.bitmap = bitmap; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } }
public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate, HashFunction hashFunction) { int nBytes = optimalNumOfBytes(expectedCount, fpRate); int nBits = nBytes * 8; byte[] bitmap = new byte[nBits / 8]; int nHashes = computeOptimalHashCount(nBits, optimalExpectedCount(nBits, fpRate)); return new BloomFilter(nBits, bitmap, nHashes, hashFunction); }
public void put(boolean data) { byteBuffer[0] = data ? 1 : 0; updateBitmap(byteBuffer, 1); }
private void updateBitmap(byte[] byteBuffer, int length) { Preconditions.checkArgument(bitmap.size() >= length, "Bitmap size must be greater than or equal to length"); long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp = tmp + h2; } }
private void updateBitmap(byte[] byteBuffer, int length) { long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp += h2; } }
```java import com.google.common.hash.Hashing; import org.apache.kudu.annotations.InterfaceAudience; import org.apache.kudu.annotations.InterfaceStability; import java.nio.charset.StandardCharsets; import java.util.BitSet; @InterfaceAudience.LimitedPrivate("Test") public class BloomFilter { private final int nBits; private final int nHashes; private final BitSet bitmap; public BloomFilter(int nBits, int nHashes) { this.nBits = nBits; this.nHashes = nHashes; this.bitmap = new BitSet(nBits); } private void bitmapSet(BitSet bitmap, long bitPos) { bitmap.set((int) bitPos); } private long pickBit(long hash, int nBits) { return hash % nBits; } private long hash(byte[] data) { return Hashing.murmur3_128().hashBytes(data).asLong(); } private boolean checkIfContains(byte[] data) { long h = hash(data); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp = tmp + h2; } return true; } public boolean mayContain(String data) { byte[] byteBuffer = data.getBytes(StandardCharsets.UTF_8); return checkIfContains(byteBuffer); } public boolean mayContain(boolean data) { byte[] byteBuffer = new byte[1]; byteBuffer[0] = (byte) (data ? 1 : 0); return checkIfContains(byteBuffer); } public boolean mayContain(byte data) { byte[] byteBuffer = new byte[1]; byteBuffer[0] = data; return checkIfContains(byteBuffer); } } ```
private boolean checkIfContains(byte[] bytes) { long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; int remHashes = nHashes; while (remHashes != 0) { long bitPos = pickBit(tmp, nBits); if (!bitmapTest(bitmap, bitPos)) { return false; } tmp = tmp + h2; remHashes--; } return true; }
private boolean checkIfContains(byte[] bytes) { long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; int remHashes = nHashes; while (remHashes != 0) { long bitpos = pickBit(tmp, nBits); if (!bitmapTest(bitmap, bitpos)) { return false; } tmp += h2; remHashes--; } return true; }
private static long computeCrc32(@NonNull byte[] type, @Nullable byte[] data) { CRC32 checksum = new CRC32(); checksum.update(type); if (data != null) { checksum.update(data); } return checksum.getValue(); } import static org.mockito.Matchers.anyString; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.when; import com.android.annotations.NonNull; import com.android.sdklib.mock.MockLog; import com.google.common.base.Optional; import junit.framework.TestCase; import org.mockito.Mock; import org.mockito.MockitoAnnotations; import org.xml.sax.SAXException; import java.io.IOException; import javax.xml.parsers.ParserConfigurationException; public class PlaceholderHandlerTest extends TestCase { @Mock ActionRecorder.Builder mActionRecorder; @Mock MergingReport.Builder mBuilder; MockLog mMockLog = new MockLog(); @Override protected void setUp() throws Exception { super.setUp(); MockitoAnnotations.initMocks(this); when(mBuilder.getLogger()).thenReturn(mMockLog); when(mBuilder.getActionRecorder()).thenReturn(mActionRecorder); } public void testPlaceholders() throws ParserConfigurationException, SAXException, IOException { String xml = "" + "<manifest\n" // rest of the code } myWizardState.put(ATTR_RES_DIR, resPath); myWizardState.put(ATTR_RES_OUT, FileUtil.toSystemIndependentName(resDir.getPath())); File manifestDir = findManifestDirectory(sourceProvider); if (manifestDir != null) { String manifestPath = FileUtil.getRelativePath(ioModuleDir, manifestDir); myWizardState.put(ATTR_MANIFEST_DIR, manifestPath); myWizardState.put(ATTR_MANIFEST_OUT, FileUtil.toSystemIndependentName(manifestDir.getPath())); } String applicationPackageName = gradleProject.computePackageName(); String packageName = null; if (myTargetFolder != null && IdeaSourceProvider.containsFile(sourceProvider, VfsUtilCore.virtualToIoFile(myTargetFolder))) { packageName = getPackageFromDirectory(VfsUtilCore.virtualToIoFile(myTargetFolder), sourceProvider, myModule, myWizardState); if (packageName != null && !packageName.equals(applicationPackageName)) { myWizardState.put(ATTR_APPLICATION_PACKAGE, applicationPackageName); } } long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (
private static int computeOptimalHashCount(int nBits, int elems) { int nHashes = (int)(nBits * kNaturalLog2 / elems); if (nHashes < 1) { nHashes = 1; } return nHashes; }
// software distributed under the License is distributed on an // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.client; import static org.junit.Assert.assertTrue; import java.util.Random; import org.apache.kudu.util.BloomFilter; import org.junit.Test; public class TestBloomFilter { private int nBytes = 32 * 1024; private int kRandomSeed = (int) System.currentTimeMillis(); private int nKeys = 2000; private double fpRate = 0.01; @Test public void testIntGenBFBySizeAndFPRate() { final BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); // Put integers into bloomfilter by random Random rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { bf.put(rand.nextInt()); } // Reset the rand and check existence of the keys. rand = new Random(kRandomSeed); // ... rest of the test code } }
public void testFloat() { final BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); Random rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { bf.put(rand.nextFloat()); } rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { assertTrue(bf.mayContain(rand.nextFloat())); } }
import java.util.List; import org.apache.impala.authorization.PrivilegeRequestBuilder; import org.apache.impala.common.AnalysisException; import org.apache.impala.common.InternalException; import org.apache.impala.common.Pair; import org.apache.impala.thrift.TAdminRequest; import org.apache.impala.thrift.TAdminRequestType; import org.apache.impala.thrift.TNetworkAddress; import org.apache.impala.thrift.TShutdownParams; import com.google.common.base.Joiner; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; public class AdminFnStmt extends StatementBase { private final String fnName_; private final List<Expr> params_; public AdminFnStmt(String fnName, List<Expr> params) { this.fnName_ = Preconditions.checkNotNull(fnName); this.params_ = Preconditions.checkNotNull(params); } public String getFnName() { return fnName_; } public List<Expr> getParams() { return params_; } }
/** * This class is not used since it accesses multiple catalog entities in order to compute a snapshot * of catalog metadata. * * Operations that CREATE/DROP catalog objects such as tables and databases employ the * following locking protocol: * 1. Acquire the metastoreDdlLock_ * 2. Update the Hive Metastore * 3. Increment and get a new catalog version * 4. Update the catalog * 5. Make Sentry cache changes if ownership is enabled. * 5. Release the metastoreDdlLock_ * * It is imperative that other operations that need to hold both the catalog lock and * table locks at the same time follow the same locking protocol and acquire these * locks in that particular order. Also, operations that modify table metadata * (e.g. alter table statements) should not acquire the metastoreDdlLock_. * * TODO: Refactor the CatalogOpExecutor and CatalogServiceCatalog classes and consolidate * the locking protocol into a single class. * * TODO: Improve catalog's consistency guarantees by using a hierarchical locking scheme. */
public Description getDescription(ChangeResource rsrc) { boolean isProjectOwner; try { isProjectOwner = projectControlFactory.controlFor(rsrc.getProject(), rsrc.getUser()).isOwner(); } catch (IOException | NoSuchProjectException e) { isProjectOwner = false; log.error("Cannot retrieve project owner ACL", e); } return new Description() .setLabel("Start Review") .setTitle("Set Ready For Review") .setVisible( and( rsrc.getChange().getStatus() == Status.NEW && rsrc.getChange().isWorkInProgress(), or( rsrc.isUserOwner(), or( isProjectOwner, permissionBackend.user(self).testCond(GlobalPermission.ADMINISTRATE_SERVER) ) ) ) ); } public Description getDescription(ChangeResource rsrc) { boolean isProjectOwner; try { isProjectOwner = projectControlFactory.controlFor(rsrc.getProject(), rsrc.getUser()).isOwner(); } catch (IOException | NoSuchProjectException e) { isProjectOwner = false; log.error("Cannot retrieve project owner ACL", e); } return new Description() .setLabel("WIP") .setTitle("Set Work In Progress") .setVisible( and( rsrc.getChange().getStatus() == Status.NEW && !rsrc.getChange().isWorkInProgress(), or( rsrc.isUserOwner(), or( isProjectOwner, permissionBackend.user(self).testCond(GlobalPermission.ADMINISTRATE_SERVER) ) ) ) ); } /** * application to retain this object for long periods of time. */ public static class PathInfo { public final FileMode fileMode; public final String path; public final ObjectId objectId; protected PathInfo(TreeWalk tw) { fileMode = tw.getFileMode(0); path = tw.getPathString(); objectId = tw.getObjectId(0); } } /** * The revision at which the data was loaded. Is null for data yet to be created. */ @Nullable protected RevCommit revision; protected RevWalk rw; protected ObjectReader reader; protected ObjectInserter inserter; protected DirCache newTree; /** * @return name of the reference storing this configuration. */ protected abstract String getRefName(); /** * Set up the metadata, parsing any state from the loaded revision. */ protected abstract void onLoad()
package org.apache.kudu.util; import javax.annotation.concurrent.NotThreadSafe; import java.nio.charset.StandardCharsets; import java.util.BitSet; import com.sangupta.murmur.Murmur2; import org.apache.yetus.audience.InterfaceAudience; import org.apache.yetus.audience.InterfaceStability; /** * A space-efficient filter which offers an approximate containment check. * * It can be used to filter all the records which are wanted, but doesn't guarantee to filter out * all the records which are not wanted. * * Please check this <a href="https://en.wikipedia.org/wiki/Bloom_filter">wiki</a> for more details. * * The BloomFilter here is a scanning filter and used to shrink the amount of records */ @NotThreadSafe @InterfaceAudience.Public @InterfaceStability.Evolving public class BloomFilter { // implementation code goes here }
/** * A space-efficient filter and offers an approximate containment check. * * <p>It can be used to filter all the records which are wanted, but doesn't guarantee to filter out * all the records which are <i>not</i> wanted. * * <p>Please check this <a href="https://en.wikipedia.org/wiki/Bloom_filter">wiki</a> for more details. * * <p>The {@code BloomFilter} here is a scanning filter and used to shrink the amount of records * returned from TServer. It provides different types of {@code put} methods. When you {@code put} a * record into {@code BloomFilter}, it means you are expecting TServer to return records have * the same value in a scan. * * <p>Here is an example for use: * <pre> * {@code * BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); * bf.put(1); * bf.put(3); * bf.put(4); * } * </pre> */ public class BloomFilter { // implementation details... }
Buggy Code: ```java * the same value in a scan. * * <p>Here is an example for use: * <pre> * {@code * BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); * bf.put(1); * bf.put(3); * bf.put(4); * byte[] bitSet = bf.getBitSet(); * byte[] nHashes = bf.getNHashes(); * String hashFunctionName = bf.getHashFunctionName(); * // TODO: implemnt the interface for serializaing and sending * // (bitSet, nHashes, hashFunctionName) to TServer. * } * </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { if (bitSet.size() < 8) { ``` Review: "implement" and "serializing" Fixed Code: ```java * the same value in a scan. * * <p>Here is an example for use: * <pre> * {@code * BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); * bf.put(1); * bf.put(3); * bf.put(4); * byte[] bitSet = bf.getBitSet(); * byte[] nHashes = bf.getNHashes(); * String hashFunctionName = bf.getHashFunctionName(); * // TODO: implement the interface for serializing and sending * // (bitSet, nHashes, hashFunctionName) to TServer. * } * </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { if (bitSet.size() < 8) { ```
public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { Preconditions.checkArgument(bitSet.size() >= 8, "Number of bits in bitset should be at least 8, but found " + bitSet.length()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } }
@InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { if (bitSet.size() < 8) { throw new IllegalArgumentException("Number of bits in bitset should be at least 8, but found " + bitSet.length()); } this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } }
if (bitSet.size() < 8) { throw new IllegalArgumentException("Number of bits in bitset should be at least 8, but found " + bitSet.length()); } this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate, HashFunction hashFunction) { int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, optimalExpectedCount(nBytes, fpRate)); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); }
public static BloomFilter bySizeAndFPRate(int nBytes, double fpRate, HashFunction hashFunction) { int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, optimalExpectedCount(nBytes, fpRate)); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); } public static BloomFilter byCountAndFPRate(int expectedCount, double fpRate) { return byCountAndFPRate(expectedCount, fpRate, HashFunctions.MURMUR2); } public static BloomFilter byCountAndFPRate(int expectedCount, double fpRate, HashFunction hashFunction) { int nBytes = optimalNumOfBytes(expectedCount, fpRate); int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, expectedCount); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); }
import org.eclipse.emf.compare.rcp.ui.internal.structuremergeviewer.filters.StructureMergeViewerFilter; import org.eclipse.emf.edit.provider.IItemColorProvider; import org.eclipse.emf.edit.provider.IItemFontProvider; import org.eclipse.emf.edit.tree.provider.TreeItemProviderAdapterFactory; /** * A specific implementation of {@link org.eclipse.emf.edit.tree.provider.TreeItemProviderAdapterFactory}. * * @author <a href="mailto:mikael.barbero@obeo.fr">Mikael Barbero</a> * @since 4.0 */ public class TreeItemProviderAdapterFactorySpec extends TreeItemProviderAdapterFactory { /** An instance of {@code StructureMergeViewerFilter}. */ private final StructureMergeViewerFilter filter; /** * Constructor. */ public TreeItemProviderAdapterFactorySpec(StructureMergeViewerFilter filter) { super(); this.filter = filter; supportedTypes.add(IItemFontProvider.class); supportedTypes.add(IItemColorProvider.class); supportedTypes.add(IItemStyledLabelProvider.class); supportedTypes.add(IItemDescriptionProvider.class); supportedTypes.add(ISemanticObjectLabelProvider.class); } /** * {@inheritDoc} * * @see org.eclipse.emf.edit.tree.provider.TreeItemProviderAdapterFactory#createTreeNodeAdapter() */ @Override public Adapter createTreeNodeAdapter() { return new TreeNodeItemProviderSpec(this); } }
private ExternalIdsUpdate(GitRepositoryManager repoManager, AllUsersName allUsersName, ExternalIdCache externalIdCache, PersonIdent committerIdent, PersonIdent authorIdent) { this.repoManager = repoManager; this.allUsersName = allUsersName; this.externalIdCache = externalIdCache; this.committerIdent = committerIdent; this.authorIdent = authorIdent; } public void insert(@NotNull AllocationInfo alloc) { StackTraceElement[] trace = alloc.getStackTrace(); String[] packages; if (trace.length > 0) { int match = 0; for (int i = 0; i < trace.length; i++) { if (myFilter.matcher(trace[i].getClassName()).matches()) { match = i; break; } } // TODO don't use the last trace, but use a user defined filter. String name = trace[match].getClassName(); int ix = name.indexOf("$"); name = ix >= 0 ? name.substring(0, ix) : name; packages = name.split("\\."); } else { packages = new String[] { "< Unknown >" }; } insert(packages, alloc, 0); } public void setValues(@NotNull Color primaryColor, @NotNull Color primaryDarkColor, @NotNull Color accentColor) { myColorPalette = new ColorPalette(primaryColor, primaryDarkColor, accentColor); } updateBitset(byteBuffer, 8); public void put(float data) { put(Float.floatToIntBits(data)); } public void put(double data) { put(Double.doubleToLongBits(data)); } public void put(String data) { put(data.getBytes(StandardCharsets.UTF_8)); } public byte[] getBitSet() { return bitSet.toByteArray(); } public int getNHashes() { return nHashes; } private String getHashFunctionName() { return hashFunction.toString(); } // Mark it `private` and user can only use the `HashFunction` specified in the // enumeration below. Thus user cannot send TServer a self defined `HashFunction`, // which might not be identified by TServer. private interface HashFunction { long hash(byte[] data, int length, long seed); } public enum HashFunctions implements HashFunction { // Currently only Murmur2 is provided as an option for hashing.
// Currently only Murmur2 is provided as an option for hashing. // We can consider to provide some other options like Murmur3, CityHash in the future. MURMUR2() { @Override public long hash(byte[] data, int length, long seed) { return Murmur2.hash(data, length, seed); } @Override public String toString() { return "Murmur2"; } } private void updateBitset(byte[] byteBuffer, int length) { Preconditions.checkArgument(byteBuffer.length >= length); long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = tmp % nBits; bitSet.set((int)bitPos); tmp += h2; } } @InterfaceAudience.LimitedPrivate("Test") public boolean mayContain(byte[] data) { return checkIfContains(data); }
TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onDatabase("functional", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onTable("functional", "alltypes", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes")) .error(accessError(true, "functional.alltypes"), onServer(true, allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onDatabase(true, "functional", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onTable(true, "functional", "alltypes", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))); } finally { authzCatalog_.removeRole("foo_owner"); } // Alter table rename. authorize("alter table functional.alltypes rename to functional_parquet.new_table") .ok(onServer(TPrivilegeLevel.ALL)) .ok(onServer(TPrivilegeLevel.OWNER)) .ok(onDatabase("functional", TPrivilegeLevel.ALL), onDatabase("functional_parquet", TPrivilegeLevel.CREATE))
import java.util.regex.Matcher; import java.util.regex.Pattern; import org.eclipse.osee.framework.core.enums.BranchType; import org.eclipse.osee.framework.jdk.core.type.IResourceRegistry; import org.eclipse.osee.framework.jdk.core.type.ResourceToken; import org.eclipse.osee.orcs.data.BranchReadable; import org.eclipse.osee.orcs.search.BranchQuery; import org.eclipse.osee.template.engine.CompositeRule; import org.eclipse.osee.template.engine.IdentifiableOptionsRule; import org.eclipse.osee.template.engine.PageCreator; import org.eclipse.osee.template.engine.PageFactory; public class OseeAppletPage { //example input for pattern: <input id="selected_branch" type="text" list="baselineBranches" required/><br /> private static final Pattern listAttributePattern = Pattern.compile("<input[^>]+?list=\"([^\"]+)"); private final BranchQuery query; public OseeAppletPage(BranchQuery query) { this.query = query; } public String realizeApplet(IResourceRegistry registry, ResourceToken valuesResource) { PageCreator page = PageFactory.newPageCreator(registry); return realizeApplet(valuesResource, page); } }
private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; if (ownerType == PrincipalType.USER) { Reference<Boolean> existingUser = new Reference<>(); owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); if (!existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } else { owner = catalog_.addRoleIfNotExists(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } response.result.addToRemoved_catalog_objects(cPrivilege.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } finally { catalog_.getLock().writeLock().unlock(); } }
@InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private static final double DEFAULT_FP_RATE = 0.01; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { Preconditions.checkArgument(bitSet.size() >= 8, "Number of bits in bitset should be at least 8, but found %s.", bitSet.size()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySize(int nBytes) { return BySizeAndFPRate(nBytes, DEFAULT_FP_RATE); } }
"bitset should be at least 8, but found %s.", bitSet.size()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter bySize(int nBytes) { return bySizeAndFPRate(nBytes, DEFAULT_FP_RATE); } public static BloomFilter bySizeAndFPRate(int nBytes, double fpRate) { return bySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); }
/** * Generate bloom filter, default hashing is {@code Murmur2}. * * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been {@code put} into the {@code BloomFilter}. */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } /** * Generate bloom filter. * * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been {@code put} into the {@code BloomFilter}. * @param hashFunction hashing used when updating or checking containment, user should pick * the hashing function from {@code HashFunctions} */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate, HashFunction hashFunction) { // implementation } /** * Generate bloom filter, default hashing is {@code Murmur2}. * * @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize(int nBytes) { return BySizeAndFPRate(nBytes, DEFAULT_FP_RATE); }
TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onDatabase("functional", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onTable("functional", "alltypes", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes")) .error(accessError(true, "functional.alltypes"), onServer(true, allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onDatabase(true, "functional", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onTable(true, "functional", "alltypes", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))); } finally { authzCatalog_.removeRole("foo_owner"); } boolean exceptionThrown = false; try { parseAndAnalyze("alter table functional.alltypes set owner role foo_owner", analysisContext_, frontend_); } catch (AnalysisException e) { exceptionThrown = true; assertEquals("Role 'foo_owner' does not exist.", e.getLocalizedMessage()); }
private final long MISSING_TBL_LOAD_WAIT_TIMEOUT_MS = 2 * 60 * 1000; private final long MAX_CATALOG_UPDATE_WAIT_TIME_MS = 2 * 1000; //TODO: Make the reload interval configurable. private static final int AUTHORIZATION_POLICY_RELOAD_INTERVAL_SECS = 5 * 60; private ImpaladCatalog impaladCatalog_; private final AuthorizationConfig authzConfig_; private final AtomicReference<AuthorizationChecker> authzChecker_; private final ScheduledExecutorService policyReader_ = Executors.newScheduledThreadPool(1); private final String defaultKuduMasterHosts_; public Frontend(AuthorizationConfig authorizationConfig, String defaultKuduMasterHosts) { this(authorizationConfig, new ImpaladCatalog(defaultKuduMasterHosts)); } /** * C'tor used by tests to pass in a custom ImpaladCatalog. */ public Frontend(AuthorizationConfig authorizationConfig, ImpaladCatalog catalog) { authzConfig_ = authorizationConfig; impaladCatalog_ = catalog; defaultKuduMasterHosts_ = catalog.getDefaultKuduMasterHosts(); authzChecker_ = new AtomicReference<AuthorizationChecker>(new AuthorizationChecker(authzConfig_, impaladCatalog_.getAuthPolicy())); }
public String getHostname() { return hostPort.getHostString(); }
public void killTabletServerOnPort(int port) throws InterruptedException { Process ts = tserverProcesses.remove(port); if (ts == null) { return; } LOG.info("Killing server at port " + port); destroyAndWaitForProcess(ts); } public void killAllTabletServers() throws InterruptedException { for (Process tserver : tserverProcesses.values()) { destroyAndWaitForProcess(tserver); } tserverProcesses.clear(); } public void restartDeadTabletServers() throws Exception { for (int port : tserverPorts) { if (tserverProcesses.containsKey(port)) { continue; } restartDeadTabletServerOnPort(port); } }
private static String findBinaryDir() { String kuduHomeProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduHomeProp != null) { LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduHomeProp); return kuduHomeProp; } String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { // kudu is available on the path BufferedReader reader = new BufferedReader(new InputStreamReader(process.getInputStream())); String kuduPath = reader.readLine(); LOG.info("Using Kudu binary directory found on the path: {}", kuduPath); return new File(kuduPath).getParent(); } } catch (IOException | InterruptedException e) { LOG.warn("Failed to determine Kudu binary directory: {}", e.getMessage()); } LOG.warn("Unable to find Kudu binary directory. Defaulting to current working directory."); return System.getProperty("user.dir"); }
String kuduHomeProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduHomeProp != null) { LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduHomeProp); return kuduHomeProp; } String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); // ... } } } catch (IOException | InterruptedException e) { LOG.warn("Failed to determine Kudu binary directory", e); } // Default to using the kudu that is available on the path return "kudu";
import java.io.File; import java.io.IOException; import java.io.InputStreamReader; import java.io.Reader; import java.nio.charset.StandardCharsets; import com.google.common.io.CharStreams; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KuduHomeLocator { private static final Logger LOG = LoggerFactory.getLogger(KuduHomeLocator.class); private static final String KUDU_HOME_VAR = "KUDU_HOME"; private static final String UTF_8 = StandardCharsets.UTF_8.name(); public static String locateKuduHome() { // First, check the system property. String kuduHomeProp = System.getProperty("kudu.home"); if (kuduHomeProp != null) { LOG.info("Using Kudu home directory specified by system property 'kudu.home': {}", kuduHomeProp); String kuduBinDir = new File(kuduHomeProp, "bin").getPath(); return kuduBinDir; } // Next, check the environment variable. String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } // Last, use the kudu that is available on the path. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) { LOG.error("Failed to locate Kudu home directory", ex); } return null; } }
String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; // Last, use the kudu that is available on the path. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) { throw new RuntimeException("Error while locating kudu binary", ex); } throw new RuntimeException("Could not locate the kudu binary directory. " + "Set the system variable " + KUDU_BIN_DIR_PROP + ", environment variable " + KUDU_HOME_VAR);
public class AlterViewStmt extends CreateOrAlterViewStmtBase { public AlterViewStmt(TableName tableName, List<ColumnDef> columnDefs, QueryStmt viewDefStmt) { super(false, tableName, columnDefs, null, viewDefStmt); } @Override public void analyze(Analyzer analyzer) throws AnalysisException { // Enforce Hive column labels for view compatibility. analyzer.setUseHiveColLabels(true); viewDefStmt_.analyze(analyzer); Preconditions.checkState(tableName_ != null && !tableName_.isEmpty()); dbName_ = analyzer.getTargetDbName(tableName_); try { owner_ = analyzer.getUser().getShortName(); } catch (InternalException e) { throw new AnalysisException("Error calling getShortName() for user: " + analyzer.getUser().getName(), e); } serverName_ = analyzer.getServerName(); FeTable table = analyzer.getTable(tableName_, Privilege.ALTER); Preconditions.checkNotNull(table); if (!(table instanceof FeView)) { throw new AnalysisException("Table " + tableName_ + " is not a view"); } } }
try { miniCluster.waitFor(); } catch (InterruptedException e) { LOG.warn("Minicluster process did not exit, destroying"); miniCluster.destroy(); } } /** * Returns a master server identified by an address. * * @param hostAndPort unique address identifying the server * @return the DaemonInfo of the server * @throws RuntimeException if the server is not found */ private DaemonInfo getMasterServer(HostAndPort hostAndPort) throws RuntimeException { DaemonInfo d = masterServers.get(hostAndPort); if (d == null) { throw new RuntimeException(String.format("Master server %s not found", hostAndPort)); } return d; } /** * Returns a tablet server identified by an address. * * @param hostAndPort unique address identifying the server * @return the DaemonInfo of the server * @throws RuntimeException if the server is not found */ private DaemonInfo getTabletServer(HostAndPort hostAndPort) throws RuntimeException { DaemonInfo d = tabletServers.get(hostAndPort); if (d == null) { throw new RuntimeException(String.format("Tablet server %s not found", hostAndPort)); } return d; }
import static org.junit.Assert.assertArrayEquals; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; import java.net.InetAddress; import java.net.InetSocketAddress; import java.util.Arrays; import java.util.List; import org.apache.kudu.client.HostAndPort; import org.junit.Test; public class TestNetUtil { @Test public void testParseString() { String aStringWithPort = "1.2.3.4:1234"; HostAndPort hostAndPortForAStringWithPort = NetUtil.parseString(aStringWithPort, 0); assertEquals(hostAndPortForAStringWithPort.getHost(), "1.2.3.4"); assertEquals(hostAndPortForAStringWithPort.getPort(), 1234); String aStringWithoutPort = "1.2.3.4"; HostAndPort hostAndPortForAStringWithoutPort = NetUtil.parseString(aStringWithoutPort, 12345); assertEquals(hostAndPortForAStringWithoutPort.getHost(), "1.2.3.4"); assertEquals(hostAndPortForAStringWithoutPort.getPort(), 12345); } }
private static String findBinaryDir() { String kuduBinDirProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduBinDirProp != null) { LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduBinDirProp); return kuduBinDirProp; } try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) { // Handle exception } // Default behavior if no binary directory is found return null; }
private PrivilegedExecutor privilegedExecutor; public KuduSink() { this(null); } @InterfaceAudience.LimitedPrivate("Test") @InterfaceAudience.Private public KuduSink(KuduClient kuduClient) { this.client = kuduClient; } @Override public synchronized void start() { Preconditions.checkState(table == null && session == null, "Please call stop before calling start on an old instance."); if (client == null) { client = privilegedExecutor.execute(new PrivilegedAction<KuduClient>() { @Override public KuduClient run() { return new KuduClient.KuduClientBuilder(masterAddresses).build(); } }); } session = client.newSession(); session.setFlushMode(SessionConfiguration.FlushMode.MANUAL_FLUSH); session.setTimeoutMillis(timeoutMillis); session.setIgnoreAllDuplicateRows(ignoreDuplicateRows); session.setMutationBufferSpace(batchSize); try { table = client.openTable(tableName); } catch (Exception ex) { sinkCounter.incrementConnectionFailedCount(); // Handle exception } }
TABLE_NAME); batchSize = context.getInteger(BATCH_SIZE, DEFAULT_BATCH_SIZE); timeoutMillis = context.getLong(TIMEOUT_MILLIS, DEFAULT_TIMEOUT_MILLIS); ignoreDuplicateRows = context.getBoolean(IGNORE_DUPLICATE_ROWS, DEFAULT_IGNORE_DUPLICATE_ROWS); String operationProducerType = context.getString(PRODUCER); String kerberosPrincipal = context.getString(KERBEROS_PRINCIPAL); String kerberosKeytab = context.getString(KERBEROS_KEYTAB); String proxyUser = context.getString(PROXY_USER); privilegedExecutor = FlumeAuthenticationUtil.getAuthenticator(kerberosPrincipal, kerberosKeytab).proxyAs(proxyUser); // Check for operations producer, if null set default operations producer type. if (operationProducerType == null || operationProducerType.isEmpty()) { operationProducerType = DEFAULT_KUDU_OPERATION_PRODUCER; logger.warn("No Kudu operations producer provided, using default"); } Context producerContext = new Context(); producerContext.putAll(context.getSubProperties(KuduSinkConfigurationConstants.PRODUCER_PREFIX)); try { Class<? extends KuduOperationsProducer> clazz = (Class<? extends KuduOperationsProducer>) Class.forName(operationProducerType); operationsProducer = clazz.getDeclaredConstructor().newInstance();
.nullable(true).build()); columns.add(new ColumnSchema.ColumnSchemaBuilder("stringField", Type.STRING).build()); columns.add(new ColumnSchema.ColumnSchemaBuilder("decimalField", Type.DECIMAL) .typeAttributes(DecimalUtil.typeAttributes(9, 1)).build()); CreateTableOptions createOptions = new CreateTableOptions() .setRangePartitionColumns(ImmutableList.of("key")) .setNumReplicas(1); return createTable(tableName, new Schema(columns), createOptions); } private List<Event> generateEvents(int eventCount, SchemaLocation schemaLocation) throws Exception { List<Event> events = new ArrayList<>(); for (int i = 0; i < eventCount; i++) { AvroKuduOperationsProducerTestRecord record = new AvroKuduOperationsProducerTestRecord(); record.setKey(10 * i); record.setLongField(2L * i); record.setDoubleField(2.71828 * i); record.setNullableField(i % 2 == 0 ? null : "taco"); record.setStringField(String.format("hello %d", i)); record.setDecimalField(BigDecimal.valueOf(i, 1)); events.add(record); } return events; }
```java return sink; } static KuduSink createSecureSink(String tableName, String masterAddresses, String clusterRoot) { Context context = new Context(); context.put(KERBEROS_KEYTAB, clusterRoot + "/krb5kdc/test-user.keytab"); context.put(KERBEROS_PRINCIPAL, "test-user@KRBTEST.COM"); return createSink(tableName, null, context, masterAddresses); } static void processEventsCreatingSink(KuduClient syncClient, Context context, String tableName, List<Event> events) throws EventDeliveryException { KuduSink sink = createSink(syncClient, tableName, context); sink.start(); processEvents(sink, events); } static void processEvents(KuduSink sink, List<Event> events) throws EventDeliveryException { Channel channel = sink.getChannel(); Transaction tx = channel.getTransaction(); tx.begin(); for (Event e : events) { channel.put(e); } tx.commit(); tx.close(); Status status = sink.process(); if (events.isEmpty()) { assertSame("incorrect status for empty channel", status, Status.BACKOFF); } else { assertSame("incorrect status for non-empty channel", status, Status.READY); } } ```
import org.slf4j.LoggerFactory; import org.apache.kudu.ColumnSchema; import org.apache.kudu.Schema; import org.apache.kudu.Type; import org.apache.kudu.client.BaseKuduTest; import org.apache.kudu.client.CreateTableOptions; import org.apache.kudu.client.KuduTable; import org.apache.kudu.client.MiniKuduCluster.MiniKuduClusterBuilder; public class SecureKuduSinkTest extends BaseKuduTest { private static final Logger LOG = LoggerFactory.getLogger(SecureKuduSinkTest.class); private static final int TICKET_LIFETIME_SECONDS = 10; private static final int RENEWABLE_LIFETIME_SECONDS = 30; @Before public void clearTicketCacheProperty() { // Let Flume authenticate System.clearProperty(KUDU_TICKETCACHE_PROPERTY); } @Override protected MiniKuduClusterBuilder getMiniClusterBuilder() { return super.getMiniClusterBuilder() .kdcTicketLifetime(TICKET_LIFETIME_SECONDS + "s") .kdcRenewLifetime(RENEWABLE_LIFETIME_SECONDS + "s") .enableKerberos(); } @Test public void testEventsWithShortTickets() throws Exception { LOG.info("Creating new table..."); ArrayList<ColumnSchema> columns = new ArrayList<>(1); // Rest of the code... } }
Fixed Code: StatsSetupConst.TRUE); msClient.alter_table(msTable_.getDbName(), msTable_.getTableName(), msTable_); } catch (TException e) { throw new TableLoadingException(e.getMessage()); } } /** * Loads the schema from the Kudu table including column definitions and primary key * columns. Throws an ImpalaRuntimeException if Kudu column data types cannot be * mapped to Impala data types. */ private void loadSchema(org.apache.kudu.client.KuduTable kuduTable) throws ImpalaRuntimeException { Preconditions.checkNotNull(kuduTable); clearColumns(); primaryKeyColumnNames_.clear(); List<FieldSchema> cols = msTable_.getSd().getCols(); cols.clear(); int pos = 0; kuduSchema_ = kuduTable.getSchema(); for (ColumnSchema colSchema: kuduSchema_.getColumns()) { KuduColumn kuduCol = KuduColumn.fromColumnSchema(colSchema, pos); Preconditions.checkNotNull(kuduCol); // Add the HMS column } } public CacheMetrics(MetricMaker metrics, final DynamicMap<Cache<?, ?>> cacheMap) { final CallbackMetric1<String, Long> memEnt = metrics.newCallbackMetric("caches/memory_cached", Long.class, new Description("Memory entries").setGauge().setUnit("entries"), F_NAME); final CallbackMetric1<String, Double> memHit = metrics.newCallbackMetric("caches/memory_hit_ratio", Double.class, new Description("Memory hit ratio").setGauge().setUnit("percent"), fName); final CallbackMetric1<String, Long> memEvict = metrics.newCallbackMetric("caches/memory_eviction_count", Long.class, new Description("Memory eviction count").setGauge() .setUnit("evicted entries"), fName); final CallbackMetric1<String, Long> perDiskEnt = metrics.newCallbackMetric("caches/disk_cached", Long.class, new Description("Disk entries used by persistent cache").setGauge() .setUnit("entries"), fName); final CallbackMetric1<String, Double> perDiskHit = private static long interval(Config rc, String section) { long interval = -1; try { interval = ConfigUtil.getTimeUnit(rc
public PartitionRefImpl(TPartialPartitionInfo p) { this.info_ = p; }
private void computeScanRangeLocations(Analyzer analyzer) { TNetworkAddress networkAddress = addressToTNetworkAddress("localhost:12345"); Integer hostIndex = analyzer.getHostIndex().getIndex(networkAddress); scanRanges_ = Lists.newArrayList( new TScanRangeLocations( new TScanRange(), Lists.newArrayList(new TScanRangeLocation(hostIndex)) ) ); } private boolean tryConvertKuduPredicate(Analyzer analyzer, org.apache.kudu.client.KuduTable table, Expr expr) { if (!(expr instanceof BinaryPredicate)) { return false; } BinaryPredicate predicate = (BinaryPredicate) expr; predicate = normalizeSlotRefComparison(predicate, analyzer); if (predicate == null) { return false; } ComparisonOp op = getKuduOperator(predicate.getOp()); if (op == null) { return false; } SlotRef ref = (SlotRef) predicate.getChild(0); LiteralExpr literal = (LiteralExpr) predicate.getChild(1); if (literal instanceof NullLiteral) { return false; } String colName = ref.getDesc().getColumn().getName(); ColumnSchema column = table.getSchema().getColumn(colName); KuduPredicate kuduPredicate = null; switch (literal.getType().getPrimitiveType()) { case BOOLEAN: { kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((BoolLiteral)literal).getValue()); break; } case TINYINT: // other cases... } // rest of the code... }
if (!(expr instanceof BinaryPredicate)) return false; BinaryPredicate predicate = (BinaryPredicate) expr; predicate = normalizeSlotRefComparison(predicate, analyzer); if (predicate == null) return false; ComparisonOp op = getKuduOperator(predicate.getOp()); if (op == null) return false; SlotRef ref = (SlotRef) predicate.getChild(0); LiteralExpr literal = (LiteralExpr) predicate.getChild(1); if (literal instanceof NullLiteral) return false; String colName = ref.getDesc().getColumn().getName(); ColumnSchema column = table.getSchema().getColumn(colName); KuduPredicate kuduPredicate = null; switch (literal.getType().getPrimitiveType()) { case BOOLEAN: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((BoolLiteral)literal).getValue()); break; case TINYINT: case SMALLINT: case INT: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((NumericLiteral)literal).getLongValue()); break; case BIGINT: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((NumericLiteral)literal).getLongValue()); break; case FLOAT: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((NumericLiteral)literal).getDoubleValue()); break; case DOUBLE: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((NumericLiteral)literal).getDoubleValue()); break; case STRING: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((StringLiteral)literal).getValue()); break; case TIMESTAMP: kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((TimestampLiteral)literal).getValue()); break; default: return false; } return kuduPredicate != null;
// Compute the per-instance number of concurrent partitions, taking the number // of nodes and the data partition of the fragment executing this sink into account. long numConcurrentPartitionsPerInstance; if (inputIsClustered_) { numConcurrentPartitionsPerInstance = 1; } else { numConcurrentPartitionsPerInstance = fragment_.getPerInstanceNdv(queryOptions.getMt_dop(), partitionKeyExprs_); if (numConcurrentPartitionsPerInstance == -1) { numConcurrentPartitionsPerInstance = DEFAULT_NUM_PARTITIONS; } } FeFsTable table = (FeFsTable) targetTable_; // TODO: Estimate the memory requirements more accurately by partition type. Set<HdfsFileFormat> formats = table.getFileFormats(); long perPartitionMemReq = getPerPartitionMemReq(formats); long perInstanceMemEstimate; // The estimate is based purely on the per-partition mem req if the input cardinality_ // or the avg row size is unknown. if (inputNode.getCardinality() == -1 || inputNode.getAvgRowSize() == -1) { perInstanceMemEstimate = numConcurrentPartitionsPerInstance * perPartitionMemReq; }
FunctionCallExpr mergeAggInputFn) { super(); fnName_ = fnName; params_ = params; mergeAggInputFn_ = mergeAggInputFn == null ? null : (FunctionCallExpr) mergeAggInputFn.clone(); if (params.exprs() != null) { children_ = Lists.newArrayList(params_.exprs()); } } public static Expr createExpr(FunctionName fnName, FunctionParams params) { FunctionCallExpr functionCallExpr = new FunctionCallExpr(fnName, params); if (fnName.getFnNamePath().size() == 1 && fnName.getFnNamePath().get(0).equalsIgnoreCase("decode") || fnName.getFnNamePath().size() == 2 && fnName.getFnNamePath().get(0).equalsIgnoreCase(Catalog.BUILTINS_DB) && fnName.getFnNamePath().get(1).equalsIgnoreCase("decode")) { return new CaseExpr(functionCallExpr); } return functionCallExpr; }
public static FunctionCallExpr createMergeAggCall(FunctionCallExpr agg, List<Expr> params) { Preconditions.checkState(agg.isAnalyzed()); Preconditions.checkState(agg.isAggregateFunction()); FunctionCallExpr result = new FunctionCallExpr(agg.fnName_, new FunctionParams(false, params), agg); result.fn_ = agg.fn_; result.type_ = agg.type_; if (agg.isMergeAggFn()) { result.label_ = agg.label_; } else { result.label_ = agg.toSql().replaceFirst(agg.fnName_.toString(), agg.fnName_.toString() + ":merge"); } Preconditions.checkState(!result.type_.isWildcardDecimal()); return result; }
public static FunctionCallExpr createMergeAggCall(FunctionCallExpr agg, List<Expr> params) { Preconditions.checkState(agg.isAnalyzed()); Preconditions.checkState(agg.isAggregateFunction()); FunctionCallExpr result = new FunctionCallExpr(agg.fnName_, new FunctionParams(false, params), agg); result.fn_ = agg.fn_; result.type_ = agg.type_; if (agg.isMergeAggFn()) { result.label_ = agg.label_; } else { result.label_ = agg.toSql().replaceFirst(agg.fnName_.toString(), agg.fnName_.toString() + ":merge"); } Preconditions.checkState(!result.type_.isWildcardDecimal()); return result; }
// For CTAS the overall TExecRequest statement type is DDL, but the // query_exec_request should be DML result.stmt_type = analysisResult.isCreateTableAsSelectStmt() ? TStmtType.DDL : TStmtType.DML; result.query_exec_request.stmt_type = TStmtType.DML; // create finalization params of insert stmt InsertStmt insertStmt = analysisResult.getInsertStmt(); if (insertStmt.getTargetTable() instanceof HdfsTable) { TFinalizeParams finalizeParams = new TFinalizeParams(); finalizeParams.setIs_overwrite(insertStmt.isOverwrite()); finalizeParams.setTable_name(insertStmt.getTargetTableName().getTbl()); finalizeParams.setTable_id(insertStmt.getTargetTable().getId()); String db = insertStmt.getTargetTableName().getDb(); finalizeParams.setTable_db(db == null ? queryCtx.session.database : db); HdfsTable hdfsTable = (HdfsTable) insertStmt.getTargetTable(); finalizeParams.setHdfs_base_dir(hdfsTable.getHdfsBaseDir()); finalizeParams.setStaging_dir(hdfsTable.getHdfsBaseDir() + "/_impala_insert_staging"); queryExecRequest.setFinalize_params(finalizeParams); }
import org.slf4j.LoggerFactory; import com.google.common.base.Objects; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** * Encapsulates all the information needed to compute a list of aggregate functions with * compatible grouping including their distributed execution. * * Each SELECT block containing aggregates will have a single MultiAggregateInfo which * will contain one AggregateInfo per unique list of DISTINCT expressions. If there is * only a single DISTINCT class, a single AggregateInfo will be created which will * represent that class and any non-DISTINCT aggregates. If there is more than one * DISTINCT class, the non-DISTINCT aggregates will be grouped together in their own * AggregateInfo. * * Execution is modeled as a tree of AggregateInfo objects which express the local and * merging aggregate computations. The tree structure looks as follows: * - for non-distinct aggregation: * - aggInfo: contains the original aggregation functions and grouping exprs * - aggInfo.mergeAggInfo: contains the merging aggregation functions (grouping */
private long warnThresholdMs_; private static final long WARN_THRESHOLD_MS = 10000; private long infoThresholdMs_; private static final long INFO_THRESHOLD_MS = 1000; private Thread monitorThread_; private volatile boolean shouldRun = true; private static JvmPauseMonitor INSTANCE = new JvmPauseMonitor(); public static void initPauseMonitor() { if (INSTANCE.isStarted()) return; INSTANCE.init(); } private JvmPauseMonitor() { this(INFO_THRESHOLD_MS, WARN_THRESHOLD_MS); } private JvmPauseMonitor(long infoThresholdMs, long warnThresholdMs) { this.infoThresholdMs_ = infoThresholdMs; this.warnThresholdMs_ = warnThresholdMs; } protected void init() { monitorThread_ = new Thread(new Monitor(), "JVM pause monitor"); monitorThread_.setDaemon(true); monitorThread_.start(); }
switch (catalogObject.getType()) { case DATABASE: return "DATABASE:" + catalogObject.getDb().getDb_name().toLowerCase(); case TABLE: case VIEW: TTable tbl = catalogObject.getTable(); return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; case ROLE: return "ROLE:" + catalogObject.getRole().getRole_name().toLowerCase(); case PRIVILEGE: return "PRIVILEGE:" + catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default: return ""; }
public void testBasicsWithStats() { // Return all rows. Cardinality is row count runTest("SELECT id FROM functional.alltypes", 7300); // Return all rows. Cardinality is row count, // should not be influenced by limited NDV of selected // column. runTest("SELECT bool_col FROM functional.alltypes", 7300); // Result cardinality reduced by limited NDV. // Boolean column has cardinality 3 (true, false, null). // Since we have metadata, and know the column is non-null, // NDV is 2. We select one of them. runTest("SELECT id FROM functional.alltypes WHERE bool_col = TRUE", 7300/2); // Result cardinality reduced by NDV. // NDV should be 10 (from metadata). runTest("SELECT id FROM functional.alltypes WHERE int_col = 1", 7300/10); // Assume classic 0.1 selectivity for other operators // IMPALA-7560 says this should be revised. runTest("SELECT id FROM functional.alltypes WHERE int_col != 1", 730); }
protected void expectCardinality(String query, long expected) { List<PlanFragment> plan = getPlan(query); PlanNode planRoot = plan.get(0).getPlanRoot(); assertEquals(expected, planRoot.getCardinality()); }
protected void runTest(String query, long expected) { List<PlanFragment> plan = getPlan(query); PlanNode planRoot = plan.get(0).getPlanRoot(); assertEquals("Unexpected cardinality for query: " + query, expected, planRoot.getCardinality()); }
private List<PlanFragment> getPlan(String query) { TQueryCtx queryCtx = TestUtils.createQueryContext("default", System.getProperty("user.name")); queryCtx.client_request.setStmt(query); TQueryOptions queryOptions = queryCtx.client_request.getQuery_options(); queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.capturePlan(); try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString(queryOptions, TExplainLevel.EXTENDED)); } return plan; }
// Set up the query context. Note that we need to deep copy it before planning each // time since planning modifies it. TQueryCtx queryCtx = TestUtils.createQueryContext("default", System.getProperty("user.name")); queryCtx.client_request.setStmt(query); TQueryOptions queryOptions = queryCtx.client_request.getQuery_options(); queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.capturePlan(); // Discard the actual execution plan. Return the cached // internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString(queryOptions, TExplainLevel.EXTENDED)); } return plan;
queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.capturePlan(); try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString(queryOptions, TExplainLevel.EXTENDED)); } return plan;
private void computeNdv() { if (desc_.getStats().hasStats()) { numDistinctValues_ = desc_.getStats().getNumDistinctValues(); if (desc_.isNullable() && !desc_.getType().isBoolean()) { long nullCount = desc_.getStats().getNumNulls(); if (nullCount > 0 || nullCount == -1) { numDistinctValues_ = Math.min(numDistinctValues_, MAX_NDV_WITH_NULLS); } } } }
// computeNdv(); FeTable rootTable = resolvedPath.getRootTable(); if (rootTable != null && rootTable.getNumRows() > 0) { numDistinctValues_ = Math.min(numDistinctValues_, rootTable.getNumRows()); } // computePreliminaryNdv(); FeTable rootTable = resolvedPath.getRootTable(); if (rootTable != null && rootTable.getNumRows() > 0) { numDistinctValues_ = computePreliminaryNdv(); } @Override protected float computeEvalCost() { return SLOT_REF_COST; } @Override protected boolean isConstantImpl() { return false; } public SlotDescriptor getDesc() { Preconditions.checkState(isAnalyzed()); Preconditions.checkNotNull(desc_); return desc_; } public SlotId getSlotId() { Preconditions.checkState(isAnalyzed()); Preconditions.checkNotNull(desc_); return desc_.getId(); } public Path getResolvedPath() { Preconditions.checkState(isAnalyzed()); return desc_.getPath(); } @Override
for (String groupName: groupNames) { roles.addAll(fe.getCatalog().getAuthPolicy().getGrantedRoles(groupName)); } for (Role role: roles) { Principal rolePrincipal = getRole(role.getName()); if (rolePrincipal != null) { createShowUserPrivilegesResultRows(result, rolePrincipal.getPrivileges(), filter, rolePrincipal.getName(), TPrincipalType.ROLE); } } return result; } /** * This method adds the rows to the output for the SHOW GRANT USER statement for user * and associated roles. */ private void createShowUserPrivilegesResultRows(TResultSet result, List<PrincipalPrivilege> privileges, TPrivilege filter, String name, TPrincipalType type) { for (PrincipalPrivilege p : privileges) { TPrivilege privilege = p.toThrift(); if (filter != null && isPrivilegeFiltered(filter, privilege)) { continue; } TResultRowBuilder rowBuilder = new TResultRowBuilder(); rowBuilder.add(Strings.nullToEmpty(type.name().toUpperCase())); rowBuilder.add(Strings.nullToEmpty(name)); // add more columns to the rowBuilder as needed result.addToRows(rowBuilder.get()); } }
public synchronized TResultSet getRolePrivileges(String roleName, TPrivilege filter) { TResultSet result = new TResultSet(); result.setSchema(new TResultSetMetadata()); addColumnOutputColumns(result.getSchema()); result.setRows(Lists.<TResultRow>newArrayList()); Role role = getRole(roleName); if (role != null) { for (RolePrivilege p : role.getPrivileges()) { TPrivilege privilege = p.toThrift(); if (filter != null && isPrivilegeFiltered(filter, privilege)) { continue; } TResultRowBuilder rowBuilder = new TResultRowBuilder(); result.addToRows(addShowPrincipalOutputResults(privilege, rowBuilder).get()); } } return result; } private boolean isPrivilegeFiltered(TPrivilege filter, TPrivilege privilege) { filter.setPrivilege_level(privilege.getPrivilege_level()); String privName = RolePrivilege.buildPrivilegeName(filter); // Check if the filter matches the privilege // ... }
Type.STRING.toThrift())); addColumnOutputColumns(result.getSchema()); result.setRows(Lists.<TResultRow>newArrayList()); // A user should be considered to not exist if they do not have any groups. Set<String> groupNames = fe.getAuthzChecker().getUserGroups( new org.apache.impala.authorization.User(principalName)); if (groupNames.isEmpty()) { throw new AnalysisException(String.format("User '%s' does not exist.", principalName)); } Principal user = getUser(principalName); if (user != null) { for (PrincipalPrivilege p : user.getPrivileges()) { TPrivilege privilege = p.toThrift(); if (filter != null) { if (isPrivilegeFiltered(filter, privilege)) continue; } TResultRowBuilder rowBuilder = new TResultRowBuilder(); rowBuilder.add(Strings.nullToEmpty(TPrincipalType.USER.name().toUpperCase())); rowBuilder.add(Strings.nullToEmpty(principalName)); result.addToRows(addShowPrincipalOutputResults(privilege, rowBuilder).get()); } }
import org.apache.sentry.provider.common.GroupMappingService; import java.util.Map; import java.util.Set; public class CustomClusterGroupMapper implements GroupMappingService { private final Map<String, Set<String>> groupsMap_ = Maps.newHashMap(); public CustomClusterGroupMapper() { String devUser = System.getProperty("user.name"); groupsMap_.put(devUser, Sets.newHashSet(devUser)); groupsMap_.put("user_1group", Sets.newHashSet("group_1")); groupsMap_.put("user_2group", Sets.newHashSet("group_2a", "group_2b")); groupsMap_.put("user1_shared", Sets.newHashSet("group_3")); } }
public CustomClusterResourceAuthorizationProvider(String resource, PolicyEngine policy, Model model) { super(policy, new CustomClusterGroupMapper(), model); }
public CustomClusterResourceAuthorizationProvider(Configuration conf, String resource, PolicyEngine policy, Model model) { super(policy, new CustomClusterGroupMapper(), model); }
import org.apache.impala.catalog.Type; import org.apache.impala.common.AnalysisException; import org.apache.impala.thrift.TExprNode; import org.apache.impala.thrift.TExprNodeType; import org.apache.impala.thrift.TSlotRef; import com.google.common.base.Joiner; import com.google.common.base.Objects; import com.google.common.base.Preconditions; public class SlotRef extends Expr { private static final int NULL_ADJUST_THRESHOLD = 1; private final List<String> rawPath_; private final String label_; private SlotDescriptor desc_; public SlotRef(ArrayList<String> rawPath) { super(); rawPath_ = rawPath; label_ = ToSqlUtils.getPathSql(rawPath_); } }
import static org.junit.Assert.fail; import java.util.List; import org.apache.impala.common.ImpalaException; import org.apache.impala.service.Frontend.PlanCtx; import org.apache.impala.testutil.TestUtils; import org.apache.impala.thrift.TExplainLevel; import org.apache.impala.thrift.TQueryCtx; import org.apache.impala.thrift.TQueryOptions; import org.junit.Test; /** * Test the inference of tuple cardinality from NDV and * selectivity. */ public class CardinalityTest extends PlannerTestBase { private static final boolean DEBUG_MODE = false; /** * Test the happy path: table with stats, no all-null cols. */ @Test public void testBasicsWithStats() { // Return all rows. Cardinality is row count; verifyCardinality("SELECT id FROM functional.alltypes", 7300); // Return all rows. Cardinality is row count, // should not be influenced by limited NDV of selected // column. verifyCardinality("SELECT bool_col FROM functional.alltypes", 7300); // Result cardinality reduced by limited NDV. // Boolean column has cardinality 3 (true, false, null). verifyCardinality("SELECT DISTINCT bool_col FROM functional.alltypes", 3); } }
queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.requestPlanCapture(); // Discard the actual execution plan. Return the cached internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { logger.debug(plan.get(0).getExplainString(queryOptions, TExplainLevel.EXTENDED)); } return plan;
public void testJoinWithoutStats() { expectCardinality("SELECT d FROM functional.alltypes, functional.nullrows", 7300 * 26); String baseStmt = "SELECT COUNT(*) " + "FROM functional.alltypes, functional.nullrows " + "GROUP BY "; expectCardinality(baseStmt + "id", 7300); expectCardinality(baseStmt + "a", 26); expectCardinality(baseStmt + "b", 2); expectCardinality(baseStmt + "f", 6); expectCardinality(baseStmt + "c", 1); expectCardinality(baseStmt + "a, c", 26); expectCardinality(baseStmt + "a, f", 156); }
public void testJoins() { // Cartesian product String joinClause = " FROM functional.alltypes t1, functional.alltypes t2 "; expectCardinality("SELECT t1.id" + joinClause, 7300 * 7300); // Cartesian product, reduced by NDV of group key expectCardinality("SELECT COUNT(*)" + joinClause + "GROUP BY t1.id", 7300); expectCardinality("SELECT COUNT(*)" + joinClause + "GROUP BY t1.id, t1.int_col", 7300 * 10); }
import org.apache.hadoop.util.GenericOptionsParser; import org.apache.kudu.test.KuduRule; import org.junit.After; import org.junit.Rule; import org.junit.Test; import org.apache.kudu.mapreduce.CommandLineParser; import org.apache.kudu.mapreduce.HadoopTestingUtility; public class ITExportCsv { private static final String TABLE_NAME = ITExportCsv.class.getName() + "-" + System.currentTimeMillis(); private static final HadoopTestingUtility HADOOP_UTIL = new HadoopTestingUtility(); @Rule public KuduRule harness = new KuduRule(); @After public void tearDown() throws Exception { HADOOP_UTIL.cleanup(); } @Test public void test() throws Exception { Configuration conf = new Configuration(); String testHome = HADOOP_UTIL.setupAndGetTestDir(ITExportCsv.class.getName(), conf).getAbsolutePath(); createFourTabletsTableWithNineRows(harness.getAsyncClient(), TABLE_NAME, DEFAULT_SLEEP); String[] args = new String[] { // test arguments }; CommandLineParser parser = new CommandLineParser(args); GenericOptionsParser gop = new GenericOptionsParser(conf, parser.getRemainingArgs()); ExportCsvJob job = new ExportCsvJob(); job.setConf(conf); int res = job.run(gop.getRemainingArgs()); assertEquals(0, res); } }
package org.apache.kudu.client; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertNotNull; import static org.junit.Assert.assertNotSame; import static org.junit.Assert.assertTrue; import com.stumbleupon.async.Deferred; import org.junit.Test; import org.apache.kudu.util.NetUtil; public class TestConnectionCache { @Test(timeout = 50000) public void test() throws Exception { MiniKuduCluster cluster = null; try { cluster = new MiniKuduCluster.MiniKuduClusterBuilder().numMasterServers(3).build(); final AsyncKuduClient client = new AsyncKuduClient.AsyncKuduClientBuilder(cluster.getMasterAddressesAsString()).build(); // Below we ping the masters directly using RpcProxy, so if they aren't ready to process // RPCs we'll get an error. Here by listing the tables we make sure this won't happen since // the masters are ready to process RPCs when they return from the constructor. client.listTables().join(); // Test connection cache ConnectionCache cache = new ConnectionCache(client, 10); assertNotNull(cache); // Get connection from cache Connection connection1 = cache.getConnection(); assertNotNull(connection1); // Get connection again, should be the same instance Connection connection2 = cache.getConnection(); assertSame(connection1, connection2); // Release connection cache.releaseConnection(connection1); // Get connection again, should be the same instance Connection connection3 = cache.getConnection(); assertSame(connection1, connection3); // Close connection cache.closeConnection(connection1); // Get connection again, should be a different instance Connection connection4 = cache.getConnection(); assertNotSame(connection1, connection4); // Close cache cache.close(); } finally { if (cluster != null) { cluster.shutdown(); } } } }
private MiniKuduClusterBuilder clusterBuilder; private MiniKuduCluster miniCluster; public AsyncKuduClient asyncClient; public KuduClient client; public KuduRule(final MiniKuduClusterBuilder clusterBuilder) { this.clusterBuilder = clusterBuilder; } public KuduRule() { this.clusterBuilder = getBaseClusterBuilder(); } public static MiniKuduClusterBuilder getBaseClusterBuilder() { return new MiniKuduClusterBuilder() .numMasterServers(NUM_MASTER_SERVERS) .numTabletServers(NUM_TABLET_SERVERS); } @Override public Statement apply(Statement base, Description description) { MasterServerConfig masterServerConfig = description.getAnnotation(MasterServerConfig.class); if (masterServerConfig != null) { for(String flag : masterServerConfig.flags()) { clusterBuilder.addMasterServerFlag(flag); } } // Rest of the code }
// Set any master server flags defined in the method level annotation. MasterServerConfig masterServerConfig = description.getAnnotation(MasterServerConfig.class); if (masterServerConfig != null) { for (String flag : masterServerConfig.flags()) { clusterBuilder.addMasterServerFlag(flag); } } // Set any tablet server flags defined in the method level annotation. TabletServerConfig tabletServerConfig = description.getAnnotation(TabletServerConfig.class); if (tabletServerConfig != null) { for (String flag : tabletServerConfig.flags()) { clusterBuilder.addTabletServerFlag(flag); } } // Generate the ExternalResource Statement. Statement statement = super.apply(base, description); // Wrap in the RetryRule to rerun flaky tests. // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. return new RetryRule().apply(statement, description);
// Set any tablet server flags defined in the method level annotation. TabletServerConfig tabletServerConfig = description.getAnnotation(TabletServerConfig.class); if (tabletServerConfig != null) { for(String flag : tabletServerConfig.flags()) { clusterBuilder.addTabletServerFlag(flag); } } // Generate the ExternalResource Statement. Statement statement = super.apply(base, description); // Wrap in the RetryRule to rerun flaky tests. // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. return new RetryRule().apply(statement, description);
// Wrap in the RetryRule to rerun flaky tests. // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. return new RetryRule().apply(statement, description); @Override public void before() throws Exception { FakeDNS.getInstance().install(); LOG.info("Creating a new MiniKuduCluster..."); miniCluster = clusterBuilder.build(); LOG.info("Creating a new Kudu client..."); asyncClient = new AsyncKuduClient.AsyncKuduClientBuilder(miniCluster.getMasterAddressesAsString()) .defaultAdminOperationTimeoutMs(DEFAULT_SLEEP) .build(); client = asyncClient.syncClient(); } @Override public void after() { try { if (asyncClient != null) { client.shutdown(); // No need to explicitly shutdown the async client, // shutting down the sync client effectively does that. } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } }
public void after() { try { if (asyncClient != null) { client.shutdown(); } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } }
public KuduTable createTable(String tableName, Schema schema, CreateTableOptions builder) throws KuduException { LOG.info("Creating table: {}", tableName); return asyncClient.syncClient().createTable(tableName, schema, builder); }
// shutting down the sync client effectively does that. } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } } public KuduClient getClient() { return client; } public AsyncKuduClient getAsyncClient() { return asyncClient; } public KuduTable createTable(String tableName, Schema schema, CreateTableOptions builder) throws KuduException { LOG.info("Creating table: {}", tableName); return asyncClient.syncClient().createTable(tableName, schema, builder); } /** * Helper method to open a table. It sets the default sleep time when joining on the Deferred. * @param name Name of the table * @return A KuduTable * @throws Exception MasterErrorException if the table doesn't exist */ public KuduTable openTable(String name) throws Exception { Deferred<KuduTable> d = asyncClient.openTable(name); return d.join(DEFAULT_SLEEP); }
public void kinit(String username) throws IOException { miniCluster.kinit(username); } public void resetClients() throws IOException { client.shutdown(); asyncClient = new AsyncKuduClient.AsyncKuduClientBuilder(miniCluster.getMasterAddressesAsString()) .defaultAdminOperationTimeoutMs(DEFAULT_SLEEP) .build(); client = asyncClient.syncClient(); } @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD}) public @interface MasterServerConfig { String[] flags(); }
public void analyzePlanHints(Analyzer analyzer) { for (PlanHint hint : planHints_) { if (hint.is("straight_join")) { analyzer.setIsStraightJoin(); } else { analyzer.addWarning("PLAN hint not recognized: " + hint); } } }
public void analyzePlanHints(Analyzer analyzer) { for (PlanHint hint : planHints_) { if (!hint.is("straight_join")) { analyzer.addWarning("PLAN hint not recognized: " + hint); } else { analyzer.setIsStraightJoin(); } } }
// be moved from this location, the user needs to have all permission. sourceDataPath_.analyze(analyzer, Privilege.ALL); // Catch all exceptions thrown by accessing files, and rethrow as AnalysisExceptions. try { Path source = sourceDataPath_.getPath(); FileSystem fs = source.getFileSystem(FileSystemUtil.getConfiguration()); if (!(fs instanceof DistributedFileSystem) && !(fs instanceof S3AFileSystem) && !(fs instanceof AzureBlobFileSystem) && !(fs instanceof SecureAzureBlobFileSystem) && !(fs instanceof AdlFileSystem)) { throw new AnalysisException(String.format("INPATH location '%s' " + "must point to an HDFS, S3A, ADL or ABFS filesystem.", sourceDataPath_)); } if (!fs.exists(source)) { throw new AnalysisException(String.format( "INPATH location '%s' does not exist.", sourceDataPath_)); } // If the source file is a directory, we must be able to read from and write to ... } catch (IOException e) { throw new AnalysisException("Error accessing files: " + e.getMessage()); }
private static final int COMPRESSION_LEVEL = Deflater.BEST_SPEED; public static byte[] deflateCompress(byte[] input) { if (input == null) { return null; } ByteArrayOutputStream bos = new ByteArrayOutputStream(input.length); DeflaterOutputStream stream = new DeflaterOutputStream(bos, new Deflater(COMPRESSION_LEVEL)); try { stream.write(input); stream.close(); } catch (IOException e) { LOG.error("Error compressing input bytes.", e); return null; } return bos.toByteArray(); }
// so it's necessary to use the HMS APIs directly. HiveMetastoreConfig hmsConfig = client.getHiveMetastoreConfig(); HiveConf hiveConf = new HiveConf(); hiveConf.setVar(HiveConf.ConfVars.METASTOREURIS, hmsConfig.getHiveMetastoreUris()); hiveConf.setBoolVar(HiveConf.ConfVars.METASTORE_USE_THRIFT_SASL, hmsConfig.getHiveMetastoreSaslEnabled()); // Check that the owner of the table in the HMS matches. IMetaStoreClient hmsClient = new HiveMetaStoreClient(hiveConf, null, false); assertEquals(owner, hmsClient.getTable("default", "testOverrideTableOwner").getOwner()); // Altering the table should not result in a change of ownership. client.alterTable(tableName, new AlterTableOptions().renameTable("default.testOverrideTableOwner_renamed")); assertEquals(owner, hmsClient.getTable("default", "testOverrideTableOwner_renamed").getOwner()); }
PrivilegeRequest request = new PrivilegeRequestBuilder() .any().onAnyTable(db.getName()).toRequest(); return authzChecker_.get().hasAccess(user, request); public List<DataSource> getDataSrcs(String pattern) { return impaladCatalog_.getDataSources(PatternMatcher.createHivePatternMatcher(pattern)); } public TResultSet getColumnStats(String dbName, String tableName) throws ImpalaException { Table table = impaladCatalog_.getTable(dbName, tableName); TResultSet result = new TResultSet(); TResultSetMetadata resultSchema = new TResultSetMetadata(); result.setSchema(resultSchema); resultSchema.addToColumns(new TColumn("Column", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("Type", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("#Distinct Values", Type.BIGINT.toThrift())); // Generate result set and schema for a SHOW COLUMN STATS command. return result; }
return authzChecker_.get().hasAccess(user, request); } public List<DataSource> getDataSrcs(String pattern) { return impaladCatalog_.getDataSources(PatternMatcher.createHivePatternMatcher(pattern)); } public TResultSet getColumnStats(String dbName, String tableName) throws ImpalaException { Table table = impaladCatalog_.getTable(dbName, tableName); TResultSet result = new TResultSet(); TResultSetMetadata resultSchema = new TResultSetMetadata(); result.setSchema(resultSchema); resultSchema.addToColumns(new TColumn("Column", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("Type", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("#Distinct Values", Type.BIGINT.toThrift())); resultSchema.addToColumns(new TColumn("#Nulls", Type.BIGINT.toThrift())); }
} else { root.setLimit(stmt.getLimit()); root.computeStats(analyzer); } return root; } private PlanNode addUnassignedConjuncts(Analyzer analyzer, List<TupleId> tupleIds, PlanNode root) throws ImpalaException { if (root instanceof EmptySetNode) return root; Preconditions.checkNotNull(root); List<Expr> conjuncts = analyzer.getUnassignedConjuncts(root); for (TupleId tid: tupleIds) { analyzer.createEquivConjuncts(tid, conjuncts); } if (conjuncts.isEmpty()) return root;
// KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { void analyze(Analyzer analyzer) throws AnalysisException; String toSql(); String toSql(ToSqlOptions options); }
List<Expr> tupleIsNullPreds = Lists.newArrayList(); for (Expr rhsExpr: inputSmap.getRhs()) { // Ignore substitutions that are irrelevant at this plan node and its ancestors. if (!rhsExpr.isBoundByTupleIds(input.getTupleIds())) continue; rhsExpr.collect(TupleIsNullPredicate.class, tupleIsNullPreds); } Expr.removeDuplicates(tupleIsNullPreds); sortInfo.addMaterializedExprs(tupleIsNullPreds, analyzer_); } sortInfo.getSortTupleDescriptor().materializeSlots(); return sortInfo; } private PlanNode createSortGroupPlan(PlanNode root, SortGroup sortGroup, List<Expr> partitionExprs) throws ImpalaException { List<Expr> partitionByExprs = sortGroup.partitionByExprs; List<OrderByElement> orderByElements = sortGroup.orderByElements;
public void computeResourceProfile(TQueryOptions queryOptions) { Preconditions.checkState(hasValidStats()); if (type_ == TSortType.TOPN) { long perInstanceMemEstimate = (long) Math.ceil((cardinality_ + offset_) * avgRowSize_); resourceProfile_ = new ResourceProfile(perInstanceMemEstimate, 0); return; } double fullInputSize = getChild(0).cardinality_ * avgRowSize_; boolean hasVarLenSlots = false; for (SlotDescriptor slotDesc : info_.getSortTupleDescriptor().getSlots()) { if (slotDesc.isMaterialized() && !slotDesc.getType().isFixedLengthType()) { hasVarLenSlots = true; break; } } if (hasVarLenSlots) { // Compute memory required for a 2-phase sort double memoryCost = Math.sqrt(fullInputSize); resourceProfile_ = new ResourceProfile((long) memoryCost, 0); } else { // Compute memory required for an in-memory sort long perInstanceMemEstimate = (long) Math.ceil(fullInputSize); resourceProfile_ = new ResourceProfile(perInstanceMemEstimate, 0); } }
private Expr simplifyCompoundPredicate(CompoundPredicate expr) { Expr leftChild = expr.getChild(0); if (!(leftChild instanceof BoolLiteral)) return expr; if (expr.getOp() == CompoundPredicate.Operator.AND) { if (((BoolLiteral) leftChild).getValue()) { return expr.getChild(1); } else { return leftChild; } } else { if (((BoolLiteral) leftChild).getValue()) { return leftChild; } else { return expr.getChild(1); } } }
private boolean isBroadcastExchange() { Preconditions.checkState(!children_.isEmpty()); DataSink sink = getChild(0).getFragment().getSink(); if (sink == null) return false; Preconditions.checkState(sink instanceof DataStreamSink); DataStreamSink streamSink = (DataStreamSink) sink; return !streamSink.getOutputPartition().isPartitioned() && fragment_.isPartitioned(); }
byte[] partitionStats, boolean hasIncrementalStats) { table_ = Preconditions.checkNotNull(table); spec_ = Preconditions.checkNotNull(spec); msPartition_ = Preconditions.checkNotNull(msPartition); fileDescriptors_ = fileDescriptors; partitionStats_ = partitionStats; hasIncrementalStats_ = hasIncrementalStats; Preconditions.checkState(msPartition_.getSd().getCols() == null); }
private class RewriteConditionalFnsRule implements ExprRewriteRule { public static final RewriteConditionalFnsRule INSTANCE = new RewriteConditionalFnsRule(); private RewriteConditionalFnsRule() { } @Override public Expr apply(Expr expr, Analyzer analyzer) throws AnalysisException { if (!expr.isAnalyzed()) { return expr; } if (expr instanceof FunctionCallExpr) { FunctionCallExpr functionCallExpr = (FunctionCallExpr) expr; String functionName = functionCallExpr.getFnName().getFunction(); List<Expr> children = functionCallExpr.getChildren(); if (functionName.equalsIgnoreCase("nullif")) { return rewriteNullIfFunction(children, analyzer); } else if (functionName.equalsIgnoreCase("nvl")) { return rewriteNvlFunction(children, analyzer); } } return expr; } private Expr rewriteNullIfFunction(List<Expr> children, Analyzer analyzer) throws AnalysisException { if (children.size() != 2) { throw new AnalysisException("Invalid number of arguments for nullif function"); } Expr expr1 = children.get(0); Expr expr2 = children.get(1); CaseExpr caseExpr = new CaseExpr(); caseExpr.setCaseExpr(expr1); caseExpr.addWhenClause(new CaseWhenClause(expr1, new NullLiteral())); caseExpr.setElseExpr(expr1); return caseExpr; } private Expr rewriteNvlFunction(List<Expr> children, Analyzer analyzer) throws AnalysisException { if (children.size() != 2) { throw new AnalysisException("Invalid number of arguments for nvl function"); } Expr expr1 = children.get(0); Expr expr2 = children.get(1); CaseExpr caseExpr = new CaseExpr(); caseExpr.setCaseExpr(expr1); caseExpr.addWhenClause(new CaseWhenClause(new IsNullPredicate(expr1), expr2)); caseExpr.setElseExpr(expr1); return caseExpr; } }
Lists.newArrayList( new CaseWhenClause(expr.getChild(0), expr.getChild(1))), expr.getChild(2) ); // ELSE elseExpr END /** * Rewrites IFNULL(a, x), which is an alias * for ISNULL(a, x) and NVL(a, x). * * IFNULL(NULL, x) --> x * IFNULL(a, x) --> a, if a is a non-null literal * IFNULL(a, x) --> * CASE WHEN a IS NULL THEN x ELSE a END */ private Expr rewriteIfNullFn(FunctionCallExpr expr) { Preconditions.checkState(expr.getChildren().size() == 2); Expr child0 = expr.getChild(0); return new CaseExpr( null, // CASE Lists.newArrayList( new CaseWhenClause( new IsNullPredicate(child0, false), expr.getChild(1) ) ), // THEN x child0.clone() // ELSE a ); }
} /** * Test some basic simplifications that are assumed in the * subsequent tests. These uncovered subtle errors and are here * to prevent regressions. */ @Test public void sanityTest() throws ImpalaException { verifySelectRewrite("null + 1", "NULL"); verifySelectRewrite("null is null", "TRUE"); verifySelectRewrite("id + (2 + 3)", "id + 5"); verifySelectRewrite("1 + 2 + id", "3 + id"); // TODO: IMPALA-7766 // verifySelectRewrite("id + 1 + 2", "id + 3"); // TODO: IMPALA-7769 // verifySelectRewrite("cast(null as INT) IS NULL", "TRUE"); // verifySelectRewrite("(null + 1) is null", "TRUE"); // verifySelectRewrite("(1 + 1) is null", "FALSE"); // verifySelectRewrite("CASE WHEN null + 1 THEN 10 ELSE 20 END", "20"); } @Test public void testIf() throws ImpalaException { // Simplifications provided by CASE rewriting
// TODO: IMPALA-7766 // verifySelectRewrite("id + 1 + 2", "id + 3"); // TODO: IMPALA-7769 // verifySelectRewrite("cast(null as INT) IS NULL", "TRUE"); // verifySelectRewrite("(null + 1) is null", "TRUE"); // verifySelectRewrite("(1 + 1) is null", "FALSE"); // verifySelectRewrite("CASE WHEN null + 1 THEN 10 ELSE 20 END", "20"); @Test public void testIf() throws ImpalaException { // Simplifications provided by CASE rewriting verifySelectRewrite("if(true, id, id+1)", "id"); verifySelectRewrite("if(false, id, id+1)", "id + 1"); verifySelectRewrite("if(null, id, id+1)", "id + 1"); // Nothing to simplify verifySelectRewrite("if(id = 0, true, false)", "CASE WHEN id = 0 THEN TRUE ELSE FALSE END"); // Don't simplify if drops last aggregate verifySelectRewrite("if(true, 0, sum(id))", "if(true, 0, sum(id))"); }
SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; } public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr);
public Expr RewritesOk(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOk(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOk(String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rules, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName; ... }
public Expr RewritesOk(String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rules, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName; SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = origExpr; for (ExprRewriteRule rule : rules) { rewrittenExpr = rule.apply(rewrittenExpr, analyzer_); } String rewrittenExprStr = rewrittenExpr.toSql(); Assert.assertEquals(expectedExprStr, rewrittenExprStr); return rewrittenExpr; }
String stmtStr = "select " + exprStr + " from " + tableName; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException {
public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getWhereClause(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; }
public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getWhereClause(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; }
// specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { /** * Perform semantic analysis of node and all of its children. * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node and its descendants. * @param options controls the form of the SQL that is returned. * @see ToSqlOptions */ String toSql(ToSqlOptions options); /** * Returns the SQL string corresponding to this node and its descendants. * This should return the same result as calling toSql(ToSqlOptions.DEFAULT). */ String toSql(); }
package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { void analyze(Analyzer analyzer) throws AnalysisException; String toSql(ToSqlOptions options); String toSql(); }
@Override default LSMComponentType getType() { return LSMComponentType.DISK; } @Override DiskComponentMetadata getMetadata(); long getComponentSize(); int getFileReferenceCount(); void destroy() throws HyracksDataException; default ILSMDiskComponentID getComponentID() throws HyracksDataException; public void acronym(String text, String definition) { assertOpenBlock(); characters(text); characters("("); characters(definition); characters(")"); } for (String line : lines) { int c = line.indexOf(": "); if (c < 0) { rec = new SubmitRecord(); submitRecords.add(rec); int s = line.indexOf(' '); String statusStr = s >= 0 ? line.substring(0, s) : line; Optional<SubmitRecord.Status> status = Enums.getIfPresent(SubmitRecord.Status.class, statusStr); checkFooter(status.isPresent(), FOOTER_SUBMITTED_WITH, line); rec.status = status.get(); if (s >= 0) { rec.errorMessage = line.substring(s); } } else { for (Change change : ReviewDbUtil.unwrapDb(db).changes().all()) { ChangeNotes notes = createFromChangeOnlyWhenNoteDbDisabled(change); if (predicate.apply(notes)) { m.put(change.getProject(), notes); } rec.labels.add(label); Optional<SubmitRecord.Label.Status> status = Enums.getIfPresent(SubmitRecord.Label.Status.class, line.substring(0, c)); checkFooter(status.isPresent(), FOOTER_SUBMITTED_WITH, line); } } } void analyze(Analyzer analyzer) throws AnalysisException; String toSql(ToSqlOptions options); default String toSql() { return toSql(ToSqlOptions.DEFAULT); }
package org.apache.impala.analysis; public enum ToSqlOptions { DEFAULT(false, false), REWRITTEN(true, false), SHOW_IMPLICIT_CASTS(true, true); private boolean rewritten_; private ToSqlOptions(boolean rewritten) { this.rewritten_ = rewritten; } public boolean isRewritten() { return rewritten_; } }
public static String wrapString(String s, int wrapLength) { StringBuilder ret = new StringBuilder(s.length() + 32); String[] split = s.split("\n"); for (int i = 0; i < split.length; i++) { String line = split[i]; String wrappedLine = WordUtils.wrap(line, wrapLength, null, true); ret.append(wrappedLine); if (i < split.length - 1) ret.append("\n"); } return ret.toString(); }
public static String wrapString(String s, int wrapLength) { StringBuilder ret = new StringBuilder(s.length() + 32); String[] split = s.split("\n"); for (int i = 0; i < split.length; i++) { String line = split[i]; String wrappedLine = WordUtils.wrap(line, wrapLength, null, true); ret.append(wrappedLine); if (i < split.length - 1) { ret.append("\n"); } } return ret.toString(); }
public void checkNumericLiteralCasts(AnalysisContext ctx, String columnName, String data, String castColumn) { String query = "insert into table functional.alltypesnopart (" + columnName + ") " + "values(" + data + ")"; String expectedToSql = "INSERT INTO TABLE " + "functional.alltypesnopart(" + columnName + ") " + "SELECT CAST(" + data + " AS " + castColumn + ")"; }
private void assertToSqlWithImplicitCasts(AnalysisContext ctx, String query, String expectedToSqlWithImplicitCasts) { StatementBase stmt = (StatementBase) AnalyzesOk(query, ctx); String actual = stmt.toSql(SHOW_IMPLICIT_CASTS); Assert.assertEquals("Bad sql with implicit casts from original query:\n" + query, expectedToSqlWithImplicitCasts, actual); }
import org.apache.hyracks.algebricks.core.algebra.operators.logical.IndexInsertDeleteUpsertOperator; import org.apache.hyracks.algebricks.core.algebra.operators.logical.InsertDeleteUpsertOperator; import org.apache.hyracks.algebricks.core.algebra.operators.logical.InsertDeleteUpsertOperator.Kind; import org.apache.hyracks.algebricks.core.algebra.operators.logical.SinkOperator; import org.apache.hyracks.algebricks.core.rewriter.base.IAlgebraicRewriteRule; public class ReplaceSinkOpWithCommitOpRule implements IAlgebraicRewriteRule { @Override public boolean rewritePre(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException { return false; } @Override public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException { AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue(); if (op.getOperatorTag() != LogicalOperatorTag.SINK) { return false; } SinkOperator sinkOperator = (SinkOperator) op; List<Mutable<ILogicalExpression>> primaryKeyExprs = null; int datasetId = 0; AbstractLogicalOperator descendantOp = (AbstractLogicalOperator) sinkOperator.getInputs().get(0).getValue(); LogicalVariable upsertVar = null; // TODO Auto-generated method stub return false; } }
public String toString() { return "ProGuard File"; } public Commons.Protocol protocol; @ZoomField(name = "description") public String description; @JsonProperty("admin_state_up") @ZoomField(name = "admin_state_up") public Boolean adminStateUp; @JsonProperty("default_tls_container_ref") @ZoomField(name = "default_tls_container_ref") public String defaultTlsContainerRef; @JsonProperty("sni_container_refs") @ZoomField(name = "sni_container_refs") public List<String> sniContainerRefs; @ZoomField(name = "loadbalancers") public List<UUID> loadBalancers; @JsonProperty("default_pool_id") @ZoomField(name = "default_pool_id") public UUID defaultPoolId; @ZoomField(name = "name") public String name; @Override public String toString() { return MoreObjects.toStringHelper(this) .omitNullValues() .add("id", id) .add("tenantId", tenantId) .add("projectId", projectId) .add("name", name) .add("description", description) .add("connectionLimit", connectionLimit) .add("defaultTlsContainerRef", defaultTlsContainerRef) .toString(); } // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.fixes; import static com.google.common.base.Preconditions.checkNotNull; /** * A modifier of a string. It allows to replace multiple parts of a string by indicating those parts * with indices based on the unmodified string. There is one limitation though: Replacements which * affect lower indices of the string must be specified before replacements for higher indices. */ class StringModifier { private final StringBuilder stringBuilder; private int characterShift = 0; private int previousEndOffset = Integer.MIN_VALUE; StringModifier(String string) { checkNotNull(string, "string must not be null"); stringBuilder = new StringBuilder(string); } /** * Replaces part of the string with another content. When called multiple times, the calls must be * in ascending order of the start offset. * * @param startOffset the start offset of the part to replace * @param endOffset the end offset of the part to
// Negative values always get bytes as unit. // TODO: fix this behaviour if needed. assertEquals("-10B", PrintUtils.printBytesRoundedToMb(-10L)); assertEquals("-123456789B", PrintUtils.printBytesRoundedToMb(-123456789L)); /** * wrap length for testWrapText() - less than 80 to make test layout nicer */ private static final int WRAP_LENGTH = 60; /** * Test for PrintUtils.wrapString(). */ @Test public void testWrapText() { // Simple query wrapping. assertWrap( "Analyzed query: SELECT * FROM functional_kudu.alltypestiny WHERE CAST(bigint_col" + " AS DOUBLE) < CAST(10 AS DOUBLE)", "Analyzed query: SELECT * FROM functional_kudu.alltypestiny\n" + "WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)" ); // Simple query with a hint retains newlines surrounding hint. assertWrap( "SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n", "SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n" ); }
assertWrap("insert into foo values (' " + " " + " ')", "insert into foo values (' \n" + "')"); // test that long words are broken up for clarity assertWrap("select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx", "select\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxx"); private void assertWrap(String input, String expected) { String actual = PrintUtils.wrapString(input, WRAP_LENGTH); assertEquals(expected, actual); assertNoBlankLines(actual); assertNoTerminatingNewline(actual); assertNoLongLines(actual); } private void assertNoLongLines(String s) { for (String line : s.split("\n")) { assertTrue(line.length() <= 80); } }
public static void openDrawer(int drawerLayoutId, int gravity) { onView(withId(drawerLayoutId)).perform(open(gravity)); } + " " + " ')", "insert into foo values (' \n" + "')"); // test that long words are broken up for clarity assertWrap("select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx", "select\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxx"); private void assertWrap(String input, String expected) { String actual = PrintUtils.wrapString(input, WRAP_LENGTH); assertEquals(expected, actual); assertNoBlankLines(actual); assertNoTerminatingNewline(actual); assertNoLongLines(actual); } private void assertNoLongLines(String s) { for (String line : s.split("\n")) { if (line.length() > MAX_LINE_LENGTH) { fail("Line exceeds maximum length: " + line); } } }
import java.util.List; import org.apache.impala.analysis.Analyzer; import org.apache.impala.analysis.CaseExpr; import org.apache.impala.analysis.CaseWhenClause; import org.apache.impala.analysis.Expr; import org.apache.impala.analysis.FunctionCallExpr; import org.apache.impala.analysis.IsNullPredicate; import org.apache.impala.analysis.NullLiteral; import org.apache.impala.common.AnalysisException; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** * Rewrites conditional functions to use a CASE statement. * The conditional functions vanish from the plan after this rewrite: there is no back-end implementation for these functions. * * coalesce(v1, v2, ...) * if(condition, ifTrue, ifFalseOrNull) * ifnull(a, ifNull) * isnull(a, ifNull) * nullif(expr1, expr2) * nvl(a, ifNull) * * Since every function is rewritten to a CASE statement, the planner runs the rule to simplify CASE after this rule. * Where that other rule can perform simplifications, those simplifications are omitted here. However, the CASE */ public class ConditionalFunctionRewriter { public void rewriteConditionalFunctions(Analyzer analyzer, Expr expr) throws AnalysisException { Preconditions.checkNotNull(analyzer); Preconditions.checkNotNull(expr); List<Expr> children = expr.getChildren(); List<Expr> newChildren = Lists.newArrayList(); for (Expr child : children) { if (child instanceof FunctionCallExpr) { FunctionCallExpr functionCall = (FunctionCallExpr) child; String functionName = functionCall.getFnName().getFunction(); switch (functionName) { case "coalesce": rewriteCoalesceFunction(analyzer, functionCall, newChildren); break; case "if": rewriteIfFunction(analyzer, functionCall, newChildren); break; case "ifnull": case "isnull": case "nvl": rewriteNullFunction(analyzer, functionCall, newChildren); break; case "nullif": rewriteNullIfFunction(analyzer, functionCall, newChildren); break; default: newChildren.add(child); break; } } else { newChildren.add(child); } } expr.setChildren(newChildren); } private void rewriteCoalesceFunction(Analyzer analyzer, FunctionCallExpr
switch (expr.getFnName().getFunction()) { case "if": return rewriteIfFn(expr); case "coalesce": return rewriteCoalesceFn(expr); case "isnull": case "nvl": case "ifnull": return rewriteIfNullFn(expr); default: return expr; } private Expr rewriteIfFn(FunctionCallExpr expr) { Preconditions.checkState(expr.getChildren().size() == 3); return new CaseExpr( null, Lists.newArrayList( new CaseWhenClause(expr.getChild(0), expr.getChild(1)) ), expr.getChild(2) ); }
private Expr rewriteCoalesceFn(FunctionCallExpr expr) { List<Expr> revised = new ArrayList<>(); for (Expr childExpr : expr.getChildren()) { if (childExpr.isNullLiteral()) { continue; } revised.add(childExpr); } return new CaseExpr(revised); }
// Negative values always get bytes as unit. // TODO: fix this behaviour if needed. assertEquals("-10B", PrintUtils.printBytesRoundedToMb(-10L)); assertEquals("-123456789B", PrintUtils.printBytesRoundedToMb(-123456789L)); } /** * Wrap length for testWrapText() - less than 80 to make test layout nicer. */ private static final int WRAP_LENGTH = 60; /** * Test for PrintUtils.wrapString(). */ @Test public void testWrapText() { // Simple query wrapping. assertWrap( "Analyzed query: SELECT * FROM functional_kudu.alltypestiny WHERE CAST(bigint_col" + " AS DOUBLE) < CAST(10 AS DOUBLE)", "Analyzed query: SELECT * FROM functional_kudu.alltypestiny\n" + "WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)" ); // Simple query with a hint retains newlines surrounding hint. assertWrap( "SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n" + "tpch_parquet.lineitem ON orders.orderkey = lineitem.orderkey", "SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n" + "tpch_parquet.lineitem ON orders.orderkey = lineitem.orderkey" ); }
"Expr '%s' in select list returns a complex type '%s'.\n" + "Only scalar types are allowed in the select list.", expr.toSql(), expr.getType().toSql())); if (!expr.getType().isSupported() || expr.getType().isInvalid()) { throw new AnalysisException("Unsupported type '" + expr.getType().toSql() + "' in '" + expr.toSql() + "'."); } } if (TreeNode.contains(resultExprs_, AnalyticExpr.class)) { if (fromClause_.isEmpty()) { throw new AnalysisException("Analytic expressions require FROM clause."); } // do this here, not after analyzeAggregation(), otherwise the AnalyticExprs // will get substituted away if (selectList_.isDistinct()) { throw new AnalysisException("cannot combine SELECT DISTINCT with analytic functions"); } } if (whereClause_ != null) { whereClause_.analyze(analyzer); if (whereClause_.contains(Expr.isAggregatePredicate())) {
public static ExprRewriteRule INSTANCE = new FoldConstantsRule(); @Override public Expr apply(Expr expr, Analyzer analyzer) throws AnalysisException { for (Expr child : expr.getChildren()) { if (!child.isLiteral()) { return expr; } } if (expr.isLiteral() || !expr.isConstant()) { return expr; } if (expr instanceof CastExpr) { CastExpr castExpr = (CastExpr) expr; if (castExpr.getChild(0) instanceof NullLiteral) { return expr; } } if (!expr.isAnalyzed()) { expr.analyze(analyzer); } return expr; }
public static String getPartitionKeyValueString(LiteralExpr literalValue, String nullPartitionKeyValue) { Preconditions.checkNotNull(literalValue); if (Expr.IS_NULL_LITERAL.apply(literalValue) || literalValue.getStringValue().isEmpty()) { return nullPartitionKeyValue; } return literalValue.getStringValue(); }
public void testUpdateCatalog() { withAllPrincipalTypes(ctx -> { String principalName = String.format("%s_update", PRINCIPAL_NAME_PREFIX); addCatalogPrincipalPrivileges(ctx.type_, ctx.catalog_, principalName, "functional"); addSentryPrincipalPrivileges(ctx.type_, ctx.sentryService_, principalName, "functional", "functional_kudu"); SentryProxy.refreshSentryAuthorization(ctx.catalog_, ctx.sentryService_, USER, false); checkCatalogPrincipalPrivileges(ctx.type_, ctx.catalog_, principalName, "server=server1->db=functional->grantoption=false", "server=server1->db=functional_kudu->grantoption=false"); }); }
switch (catalogObject.getType()) { case DATABASE: return "DATABASE:" + catalogObject.getDb().getDb_name().toLowerCase(); case TABLE: case VIEW: TTable tbl = catalogObject.getTable(); return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; case ROLE: return "ROLE:" + catalogObject.getRole().getRole_name().toLowerCase(); case PRIVILEGE: return "PRIVILEGE:" + catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default: String principalName = catalogObject.getPrincipal().getPrincipal_name(); if (catalogObject.getPrincipal().getPrincipal_type() == TPrincipalType.ROLE) { principalName = principalName.toLowerCase(); } return "PRINCIPAL:" + principalName; }
return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; case ROLE: return "ROLE:" + catalogObject.getRole().getRole_name().toLowerCase(); case PRIVILEGE: return "PRIVILEGE:" + catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default: throw new IllegalStateException("Unsupported catalog object type: " + catalogObject.getType());
for (SlotDescriptor d: slotsBySize.get(slotSize)) { Preconditions.checkState(d.isMaterialized()); d.setByteSize(slotSize); d.setByteOffset(slotOffset); d.setSlotIdx(slotIdx++); slotOffset += slotSize; // assign null indicator if (d.getIsNullable()) { d.setNullIndicatorByte(nullIndicatorByte); d.setNullIndicatorBit(nullIndicatorBit); nullIndicatorBit = (nullIndicatorBit + 1) % 8; if (nullIndicatorBit == 0) { ++nullIndicatorByte; } } else { // non-nullable slots will have 0 for the byte offset and -1 for the bit mask d.setNullIndicatorBit(-1); d.setNullIndicatorByte(0); } } Preconditions.checkState(slotOffset == totalSlotSize); byteSize_ = totalSlotSize + numNullBytes_;
// specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { void analyze(Analyzer analyzer) throws AnalysisException; String toSql(ToSqlOptions options); }
public List<NodeType> getChildren() { return children_; } public <C extends TreeNode<NodeType>> List<C> getNodesPreOrder() { List<TreeNode<NodeType>> result = new ArrayList<>(); getNodesPreOrderAux(result); return (List<C>) result; } protected void getNodesPreOrderAux(List<TreeNode<NodeType>> result) { result.add(this); for (NodeType child : children_) { child.getNodesPreOrderAux(result); } } public List<TreeNode<NodeType>> getNodesPostOrder() { List<TreeNode<NodeType>> result = new ArrayList<>(); getNodesPostOrderAux(result); return result; } protected void getNodesPostOrderAux(List<TreeNode<NodeType>> result) { for (NodeType child : children_) { child.getNodesPostOrderAux(result); } result.add(this); }
} for (NodeType child: children_) child.collect(predicate, matches); } /** * Add all nodes in the tree that are of class 'cl' to the list 'matches'. * This node is checked first, followed by its children in order. If the node * itself is of class 'cl', the children are skipped. */ @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>, D extends C> void collect(Class<?> cl, Collection<D> matches) { if (cl.equals(getClass())) { matches.add((D) this); return; } for (NodeType child: children_) child.collect(cl, matches); } /** * Add all nodes in the tree that satisfy 'predicate' to the list 'matches' * This node is checked first, followed by its children in order. All nodes * that match in the subtree are added. */ @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>, D extends C> void collectAll(
public static <C extends TreeNode<C>, D extends C> void collect(Collection<C> nodeList, Predicate<? super C> predicate, Collection<D> matches) { for (C node : nodeList) { node.collect(predicate, matches); } } public static <C extends TreeNode<C>, D extends C> void collect(Collection<C> nodeList, Class<C> cl, Collection<D> matches) { for (C node : nodeList) { node.collect(cl, matches); } } @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>> boolean contains(Predicate<? super C> predicate) { if (predicate.apply((C) this)) { return true; } for (NodeType child : children_) { if (child.contains(predicate)) { return true; } } return false; }
public boolean contains(Class<?> cl) { if (cl.equals(getClass())) return true; for (NodeType child : children_) { if (child.contains(cl)) return true; } return false; }
public static <C extends TreeNode<C>> boolean contains(List<C> nodeList, Class<C> cl) { for (C node : nodeList) { if (node.contains(cl)) { return true; } } return false; }
import org.apache.parquet.schema.Type; import org.apache.parquet.schema.GroupType; import org.apache.parquet.schema.LogicalTypeAnnotation; import org.apache.parquet.schema.ListLogicalTypeAnnotation; import org.apache.parquet.schema.MapLogicalTypeAnnotation; import org.apache.parquet.schema.MapKeyValueTypeAnnotation; import org.apache.parquet.schema.PrimitiveType; import org.apache.parquet.schema.Type.Repetition; import org.apache.parquet.schema.Types; import java.util.ArrayList; import java.util.List; public class ParquetTypeConverter { public static Type convertParquetType(org.apache.parquet.schema.Type parquetType) throws AnalysisException { if (parquetType.isPrimitive()) { return convertPrimitive(parquetType.asPrimitiveType()); } else if (parquetType.isGroup()) { return convertGroup(parquetType.asGroupType()); } else { throw new AnalysisException("Unsupported Parquet type: " + parquetType); } } private static Type convertPrimitive(PrimitiveType primitiveType) { return Types.optional(primitiveType.getPrimitiveTypeName()); } private static Type convertGroup(GroupType groupType) throws AnalysisException { List<Type> fields = new ArrayList<>(); for (org.apache.parquet.schema.Type fieldType : groupType.getFields()) { fields.add(convertParquetType(fieldType)); } return Types.buildGroup(Repetition.OPTIONAL).addFields(fields); } private static Type convertArray(GroupType innerGroup) throws AnalysisException { return Types.optionalList().element(convertParquetType(innerGroup.getType(0))); } private static Type convertLogicalParquetType(org.apache.parquet.schema.Type parquetType) throws AnalysisException { LogicalTypeAnnotation logicalType = parquetType.getLogicalTypeAnnotation(); if (logicalType instanceof ListLogicalTypeAnnotation) { return convertArray(parquetType.asGroupType()); } if (logicalType instanceof MapLogicalTypeAnnotation || logicalType instanceof MapKeyValueTypeAnnotation) { throw new AnalysisException("Unsupported Parquet logical type: " + logicalType); } return convertParquetType(parquetType); } }
import org.apache.thrift.TDataSink; import org.apache.thrift.TDataSinkType; import org.apache.thrift.TExecStats; protected final TDataSink toThrift() { TDataSink tsink = new TDataSink(getSinkType()); tsink.setLabel(fragment_.getId() + ":" + getLabel()); TExecStats estimatedStats = new TExecStats(); estimatedStats.setMemory_used(resourceProfile_.getMemEstimateBytes()); tsink.setEstimated_stats(estimatedStats); toThriftInternal(tsink); return tsink; } abstract protected void toThriftInternal(TDataSink tsink); abstract protected TDataSinkType getSinkType(); public void setFragment(PlanFragment fragment) { fragment_ = fragment; } public PlanFragment getFragment() { return fragment_; } public ResourceProfile getResourceProfile() { return resourceProfile_; } public abstract void computeResourceProfile(TQueryOptions queryOptions);
public void testScalarFunctionSql() { // Can't generate SQL for an unresolved function List<Type> args = new ArrayList<>(); Function fn = Function.createFunction("mydb", "fn1", args, Type.INT, false, TFunctionBinaryType.JAVA); try { ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); } catch (UnsupportedOperationException e) { // Expected } // Java function, leave off location and symbol List<Type> args = new ArrayList<>(); Function fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); // Java function, with location and symbol List<Type> args = new ArrayList<>(); Function fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation("/path/to/function"); fn.setSymbol("symbol"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1 LOCATION '/path/to/function' SYMBOL 'symbol'\n"; assertEquals(expected, sql); }
Function fn = Function.createFunction("mydb", "fn1", args, Type.INT, false, TFunctionBinaryType.JAVA); try { ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); } catch (UnsupportedOperationException e) { // Expected } { // Java function, leave off location and symbol List<Type> args = new ArrayList<>(); Function fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = new ArrayList<>(); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); }
fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn.setSymbolName("MyClass"); sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN);
String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn.setSymbolName("MyClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql);
String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); List<Type> args = new ArrayList<>(); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setSymbolName("myClass"); sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); expected = "CREATE FUNCTION mydb.fn1()\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql);
String expected = "CREATE FUNCTION mydb.fn1()\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql); { // C++ function, with location and symbol List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1(VARCHAR(*), BOOLEAN)\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql); }
public void testAggFnSql() { List<Type> args = Lists.newArrayList(Type.INT, Type.BOOLEAN); AggregateFunction fn = new AggregateFunction(new FunctionName("mydb", "fn1"), args, Type.BIGINT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setUpdateFnSymbol("Update"); fn.setInitFnSymbol("Init"); fn.setMergeFnSymbol("Merge"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE AGGREGATE FUNCTION mydb.fn1(INT, BOOLEAN)\n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " UPDATE_FN='Update'\n" + " INIT_FN='Init'\n" + " MERGE_FN='Merge'\n"; assertEquals(expected, sql); }
String sql = "CREATE AGGREGATE FUNCTION mydb.fn1(INT, BOOLEAN)\n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " UPDATE_FN='Update'\n" + " INIT_FN='Init'\n" + " MERGE_FN='Merge'\n"; assertEquals(expected, sql); List<Type> args = Lists.newArrayList(Type.INT, Type.BOOLEAN); AggregateFunction fn = new AggregateFunction(new FunctionName("mydb", "fn1"), args, Type.BIGINT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setUpdateFnSymbol("Update"); fn.setInitFnSymbol("Init"); fn.setMergeFnSymbol("Merge"); fn.setFinalizeFnSymbol("Finalize"); fn.setSerializeFnSymbol("Serialize"); fn.setIntermediateType(Type.INT); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE AGGREGATE FUNCTION mydb.fn1(INT, BOOLEAN)\n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " UPDATE_FN='Update'\n" + " INIT_FN='Init'\n" + " MERGE_FN='Merge'\n";
public void testCreateFunctionSql() { ScalarFunction fn1 = new ScalarFunction(new FunctionName("mydb", "fn1"), new ArrayList<>(), Type.INT, false); fn1.setBinaryType(TFunctionBinaryType.JAVA); fn1.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn1.setSymbolName("MyClass"); List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn2 = new ScalarFunction(new FunctionName("mydb", "fn2"), args, Type.INT, false); fn2.setBinaryType(TFunctionBinaryType.NATIVE); fn2.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn2.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn1, fn2)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass';\n" + "CREATE FUNCTION mydb.fn2\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass';\n"; assertEquals(expected, sql); }
ScalarFunction fn1 = new ScalarFunction(new FunctionName("mydb", "fn1"), new ArrayList<>(), Type.INT, false); fn1.setBinaryType(TFunctionBinaryType.JAVA); fn1.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn1.setSymbolName("MyClass"); List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn2 = new ScalarFunction(new FunctionName("mydb", "fn2"), args, Type.INT, false); fn2.setBinaryType(TFunctionBinaryType.NATIVE); fn2.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn2.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn1, fn2)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass';\n" + "CREATE FUNCTION mydb.fn2(VARCHAR(*), BOOLEAN)\n" + " RETURNS INT\n" +
public RetryRule() { this(Integer.getInteger("rerunFailingTestsCount", 0)); }
protected static boolean compareBitmaps(Bitmap img1, Bitmap img2) { if (img1.getWidth() == img2.getWidth() && img1.getHeight() == img2.getHeight()) { int[] img1Pixels = new int[img1.getWidth() * img1.getHeight()]; int[] img2Pixels = new int[img2.getWidth() * img2.getHeight()]; img1.getPixels(img1Pixels, 0, img1.getWidth(), 0, 0, img1.getWidth(), img1.getHeight()); img2.getPixels(img2Pixels, 0, img2.getWidth(), 0, 0, img2.getWidth(), img2.getHeight()); return Arrays.equals(img1Pixels, img2Pixels); } return false; } @Override public void describeTo(Description description) { description.appendText("has background with drawable ID: " + drawableId); } static boolean compareBitmaps(Bitmap img1, Bitmap img2) { if (img1.getWidth() == img2.getWidth() && img1.getHeight() == img2.getHeight()) { int[] img1Pixels = new int[img1.getWidth() * img1.getHeight()]; int[] img2Pixels = new int[img2.getWidth() * img2.getHeight()]; img1.getPixels(img1Pixels, 0, img1.getWidth(), 0, 0, img1.getWidth(), img1.getHeight()); img2.getPixels(img2Pixels, 0, img2.getWidth(), 0, 0, img2.getWidth(), img2.getHeight()); return Arrays.equals(img1Pixels, img2Pixels); } return false; } // Even though constructors are invoked using a "special" invoke, handles to them can't // be created using findSpecial. Callers must use findConstructor instead. if ("<init>".equals(name)) { throw new NoSuchMethodException("<init> is constructor."); } Method method = refc.getDeclaredMethod(name, type.ptypes()); return findSpecial(method, type, refc, specialCaller); } private MethodHandle findSpecial(Method method, MethodType type, Class<?> refc, Class<?> specialCaller) throws IllegalAccessException { if (Modifier.isPrivate(method.getModifiers())) { // Since this is a private method, we'll need to also make sure that the // lookup class is the same as the refering class. We've already checked that // the specialCaller is the
return new RetryStatement(base, description, retryCount); } private static class RetryStatement extends Statement { private final Statement base; private final Description description; private final int retryCount; RetryStatement(Statement base, Description description, int retryCount) { this.base = base; this.description = description; this.retryCount = retryCount; } @Override public void evaluate() throws Throwable { Throwable lastException; int attempt = 0; do { attempt++; try { base.evaluate(); return; } catch (Throwable t) { // To retry, we catch the exception from evaluate(), log an error, and loop. // We retain and rethrow the last failure if all attempts fail. lastException = t; LOG.error("{}: failed attempt {}", description.getDisplayName(), attempt, t); } } while (attempt <= retryCount); LOG.error("{}: giving up after {} attempts", description.getDisplayName(), attempt); throw lastException; } } }
public void testRetry() { if (failures < MAX_FAILURES) { failures++; assertFalse(String.format("%d failures", failures), true); } // Fall through and pass the test on the final retry. }
package com.couchbase.client.core.env; public enum NetworkResolution { DEFAULT, BLANK, EXTERNAL }
OpenBucketRequest request; if (ClusterDependentTest.minClusterVersion()[0] >= 5) { request = new OpenBucketRequest(TestProperties.bucket(), TestProperties.adminUser(), TestProperties.adminPassword()); } else { request = new OpenBucketRequest(TestProperties.bucket(), TestProperties.username(), TestProperties.password()); } core.send(request).toBlocking().single(); BackpressureException exception = RingBufferMonitor.instance().createException(); assertEquals(0, exception.diagostics().totalCount()); core.send(new CloseBucketRequest(TestProperties.bucket())).toBlocking().single(); }
/** * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.core; import com.couchbase.client.core.tracing.RingBufferDiagnostics; /** * Identifies the need to back off on the supplier side when using a service, because the consumer is overloaded. * * @author Michael Nitschinger * @since 1.0 */ public class BackpressureException extends CouchbaseException { public BackpressureException() {} public BackpressureException(RingBufferDiagnostics diagnostics) { this.diagnostics = diagnostics; } /** * Returns a {@link RingBufferDiagnostics} which, if non-null, gives a granular breakdown of the contents of the * ringbuffer at the time of this exception */ public RingBufferDiagnostics getRingBufferDiagnostics() { return diagnostics; } @Override public String toString() { return "BackpressureException{" + "diagnostics=" + diagnostics + '}'; } private RingBufferDiagnostics diagnostics; }
public RingBufferDiagnostics ringBufferDiagnostics() { return diagnostics; }
RingBufferMonitor ringBufferMonitor = RingBufferMonitor.getInstance(); ringBufferMonitor.addRequest(request); if (coreSendHook == null) { boolean published = requestRingBuffer.tryPublishEvent(REQUEST_TRANSLATOR, request); if (!published) { request.observable().onError(ringBufferMonitor.createException()); } return (Observable<R>) request.observable(); } else { Subject<CouchbaseResponse, CouchbaseResponse> response = request.observable(); Tuple2<CouchbaseRequest, Observable<CouchbaseResponse>> hook = coreSendHook.beforeSend(request, response); boolean published = requestRingBuffer.tryPublishEvent(REQUEST_TRANSLATOR, hook.value1()); if (!published) { request.observable().onError(ringBufferMonitor.createException()); } return (Observable<R>) request.observable(); }
public class RingBufferMonitor { private static RingBufferMonitor instance; static { instance = new RingBufferMonitor(); } private RingBufferMonitor() { // private constructor to prevent instantiation } public static RingBufferMonitor getInstance() { return instance; } }
private AtomicInteger getOrAddCount(CouchbaseRequest request) { if (request instanceof AbstractKeyValueRequest) { return countKeyValue; } else if (request instanceof GenericQueryRequest) { return countQuery; } else if (request instanceof ClusterRequest) { return countCluster; } else if (request instanceof ConfigRequest) { return countConfig; } else if (request instanceof InternalRequest) { return countInternal; } else if (request instanceof BinaryRequest) { return countKeyValue; // renamed to countKeyValue } else if (request instanceof SearchRequest) { return countSearch; } else if (request instanceof ViewRequest) { return countView; } else if (request instanceof AnalyticsRequest) { return countAnalytics; } else { return countOther; } }
private EncryptionConfig encryptionConfig; public static final String ENCRYPTION_PREFIX = "__encrypt_"; private JsonObject() { content = new HashMap<String, Object>(); } private JsonObject(int initialCapacity) { content = new HashMap<String, Object>(initialCapacity); } public static JsonObject empty() { return new JsonObject(); }
sb.append(", viewTimeout=").append(this.viewTimeout); sb.append(", searchTimeout=").append(this.searchTimeout); sb.append(", analyticsTimeout=").append(this.analyticsTimeout); sb.append(", kvTimeout=").append(this.kvTimeout); sb.append(", connectTimeout=").append(this.connectTimeout); sb.append(", dnsSrvEnabled=").append(this.dnsSrvEnabled); if (this.cryptoManager() != null) { sb.append(", cryptoManager=").append(this.cryptoManager.toString()); } return sb;
public class JsonObject extends JsonValue implements Serializable { private static final long serialVersionUID = 8817717605659870262L; private final Map<String, Object> content; private volatile Map<String, String> encryptionPathInfo; private EncryptionConfig encryptionConfig; public static final String ENCRYPTION_PREFIX = "__encrypt_"; private JsonObject() { content = new HashMap<String, Object>(); encryptionPathInfo = new HashMap<String, String>(); } }
public class JsonObject extends JsonValue implements Serializable { private static final long serialVersionUID = 8817717605659870262L; private final Map<String, Object> content; private final Map<String, String> encryptionPathInfo; private EncryptionConfig encryptionConfig; public static final String ENCRYPTION_PREFIX = "__encrypt_"; private JsonObject() { content = new HashMap<String, Object>(); encryptionPathInfo = new HashMap<String, String>(); } private JsonObject(int initialCapacity) { content = new HashMap<String, Object>(initialCapacity); encryptionPathInfo = new HashMap<String, String>(); } }
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.pbb.rev161214.PbbRewriteStateInterfaceAugmentationBuilder; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.pbb.rev161214.interfaces.state._interface.PbbRewriteState; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public final class InterfacesStateReaderFactory implements ReaderFactory { private final NamingContext ifcNamingCtx; private final NamingContext bdNamingCtx; private final DisabledInterfacesManager ifcDisableContext; private final FutureJVppCore jvpp; static final InstanceIdentifier<InterfacesState> IFC_STATE_ID = InstanceIdentifier.create(InterfacesState.class); static final InstanceIdentifier<Interface> IFC_ID = IFC_STATE_ID.child(Interface.class); static final InstanceIdentifier<Interface> IFC_ID_CREATE = InstanceIdentifier.create(Interface.class); @Inject public InterfacesStateReaderFactory(final FutureJVppCore jvpp, @Named("interface-context") final NamingContext ifcNamingCtx, @Named("bridge-domain-context") final NamingContext bdNamingCtx, final DisabledInterfacesManager ifcDisableContext, final InterfaceCacheDumpManager ifaceDumpManager) { this.jvpp = jvpp; this.ifcNamingCtx = ifcNamingCtx; this.bdNamingCtx = bdNamingCtx; this.ifcDisableContext = ifcDisableContext; this.ifaceDumpManager = ifaceDumpManager; } private void computeColumnSet(List<Pair<LogicalVariable, Mutable<ILogicalExpression>>> gbyList) { columnSet.clear(); for (Pair<LogicalVariable, Mutable<ILogicalExpression>> p : gbyList) { ILogicalExpression expr = p.second.getValue(); if (expr.getExpressionTag() == LogicalExpressionTag.VARIABLE) { VariableReferenceExpression v = (VariableReferenceExpression) expr; columnSet.add(v.getVariableReference()); } } } private List<LogicalVariable> getGbyColumns() { return columnSet; } /** * Decrypt value if the name starts with "__encrypt_" */ private Object decrypt(JsonObject object, String providerName) throws Exception { Object decrypted; String key = object.getString("kid"); String alg = object.getString("alg"); CryptoProvider provider = this.cryptoManager.getProvider(providerName);
+ object.getString("ciphertext"); encryptedBytes = Base64.decode(object.getString("ciphertext")); if (object.containsKey("sig")) { byte[] signature = Base64.decode(object.getString("sig")); if (!provider.verifySignature(encryptedValueWithConfig.getBytes(), signature)) { throw new CryptoProviderSigningFailedException("The decryption of the field failed for the alias: " + providerName + " (Signature check for data integrity failed)"); } } byte[] decryptedBytes = provider.decrypt(encryptedBytes); String decryptedString = new String(decryptedBytes, Charset.forName("UTF-8")); decrypted = JacksonTransformers.MAPPER.readValue(decryptedString, Object.class); if (decrypted instanceof Map) { decrypted = JsonObject.from((Map<String, ?>) decrypted); } else if (decrypted instanceof List) { decrypted = JsonArray.from((List<?>) decrypted); } return decrypted; } /** * Retrieves the (potential null) content and not casting its type. * * @param name the key of the field. */
@Nonnull public static File createTempFile(@Nonnull String prefix) throws CannotCreateFileException, CannotChangePermissionException { return createTempFile(prefix, ""); } @Nonnull public static File createTempFile(@Nonnull String prefix, @Nonnull String suffix) throws CannotCreateFileException, CannotChangePermissionException { File baseDir = new File(System.getProperty("java.io.tmpdir")); return createTempFile(prefix, suffix, baseDir); } @Nonnull public static File createTempFile(@Nonnull String prefix, @Nonnull String suffix, @Nonnull Directory baseDir) throws CannotCreateFileException, CannotChangePermissionException { String baseName = prefix + System.currentTimeMillis() + "-"; Location location = null; for (int counter = 0; counter < TEMP_ATTEMPTS; counter++) { File tempFile = new File(baseDir, baseName + counter + suffix); location = new FileLocation(tempFile); try { AbstractStreamFile.create(tempFile, location); FileOrDirectory.unsetPermissions(tempFile, location, Permission.READ | Permission.WRITE | Permission.EXECUTE, ChangePermission.EVERYBODY); } catch (CannotCreateFileException | CannotChangePermissionException e) { throw e; } } return null; } SWTBotTreeItem resourceItem = treeItem[0]; assertEquals("There should be only one viewpoint node under group node", resourceItem.getItems().length); // Level2 SWTBotTreeItem groupItem = resourceItem.getItems()[0]; assertEquals("The level 2 node should be expanded with 6 sub items", 6, groupItem.getItems().length); // Level3 SWTBotTreeItem viewpointItem = groupItem.getItems()[0]; assertEquals(errorMessage(3, 7), 7, viewpointItem.getItems().length); SWTBotTreeItem viewpointItem2 = groupItem.getItems()[2]; assertEquals("The level 3 node should be expanded with 4 sub items", 4, viewpointItem2.getItems().length); // Level4 // We check without expanding the level 4 node that we have only one // sub node corresponding to the empty node. SWTBotTreeItem entitiesDiagramItem2 = viewpointItem2.getItems()[0]; assertEquals("The level 4 node should not be expanded. It should contains only the empty node.", 1, entitiesDiagramItem2.getItems().length); // Then we expand the level 4 nodes to
public Credentials(String username, String password) { this.username = username; this.password = password; }
package com.couchbase.client.dcp; import java.net.InetSocketAddress; public interface CredentialsProvider { Credentials get(InetSocketAddress address) throws RuntimeException; }
package com.couchbase.client.dcp; import java.net.InetSocketAddress; public class StaticCredentialsProvider implements CredentialsProvider { private final Credentials credentials; public StaticCredentialsProvider(String username, String password) { credentials = new Credentials(username, password); } @Override public Credentials get(InetSocketAddress address) throws RuntimeException { return credentials; } }
private SaslClient saslClient; private String selectedMechanism; AuthHandler(final InetSocketAddress address, final ClientEnvironment environment) { Credentials credentials = environment.credentialsProvider().get(address); this.username = credentials.getUsername(); this.password = credentials.getPassword(); } @Override public void channelActive(final ChannelHandlerContext ctx) throws Exception { ByteBuf request = ctx.alloc().buffer(); SaslListMechsRequest.init(request); ctx.writeAndFlush(request); } @Override protected void channelRead0(final ChannelHandlerContext ctx, final ByteBuf msg) throws Exception { // handle message according to the req/res process }
private String clientContextId; private Map<String, Object> rawParams; private boolean pretty; /** * We are exposing this as a boolean, but internally the server * wants it as int. To be forwards compatible */ private int priority; private AnalyticsParams() { pretty = false; priority = 0; }
public AnalyticsParams priority(boolean priority) { return priority(-1); }
public String toString() { return "AnalyticsParams{" + "serverSideTimeout='" + serverSideTimeout + '\'' + ", clientContextId='" + clientContextId + '\'' + ", rawParams=" + rawParams + ", pretty=" + pretty + ", priority=" + (priority != 0 ? "true" : "false") + '}'; }
} public static void setOpaque(int opaque, ByteBuf buffer) { buffer.setInt(OPAQUE_OFFSET, opaque); } public static int getOpaque(ByteBuf buffer) { return buffer.getInt(OPAQUE_OFFSET); } public static long getCas(ByteBuf buffer) { return buffer.getLong(CAS_OFFSET); } private static String formatOpcode(byte opcode) { String name = OPCODE_NAMES[0xff & opcode]; return String.format("0x%02x (%s)", opcode, name == null ? "?" : name); } private static String formatMagic(byte magic) { String name = magic == MAGIC_REQ ? "REQUEST" : (magic == MAGIC_RES) ? "RESPONSE" : "?"; return String.format("0x%02x (%s)", magic, name); }
} DcpControl control = environment.dcpControl(); Credentials credentials = environment.credentialsProvider().get((InetSocketAddress) ch.remoteAddress()); pipeline.addLast(new AuthHandler(credentials.getUsername(), credentials.getPassword())) .addLast(new DcpConnectHandler(environment.connectionNameGenerator(), environment.bucket(), control)) .addLast(new DcpControlHandler(control)); if (control.noopEnabled()) { pipeline.addLast(new IdleStateHandler(2 * control.noopIntervalSeconds(), 0, 0)); } pipeline.addLast(new DcpLoggingHandler(LogLevel.DEBUG)); DcpMessageHandler messageHandler = new DcpMessageHandler(ch, environment, controlHandler); pipeline.addLast(messageHandler); if (environment.persistencePollingEnabled()) { pipeline.addLast(new PersistencePollingHandler(environment, configProvider, messageHandler)); } }
public void shouldSerializeEjectionMethod() { BucketSettings settings = DefaultBucketSettings.builder() .ejectionMethod(EjectionMethod.FULL) .build(); DefaultAsyncClusterManager clusterManager = new DefaultAsyncClusterManager("login", "password", null, null, null); String payload = clusterManager.getConfigureBucketPayload(settings, false); assertTrue(payload.contains("evictionPolicy=fullEviction")); }
/** * An exception denoting that the search engine couldn't parse an FTS request. * * @author Simon Baslé * @since 2.3 */ public class FtsServerOverloadException extends CouchbaseException { public FtsServerOverloadException(String payload) { super("Search server is overloaded. Details: " + payload); } }
package com.couchbase.client.java.error; import com.couchbase.client.core.CouchbaseException; /** * An exception denoting that the search engine couldn't parse an FTS request. * * @author Simon Baslé * @since 2.3 */ public class FtsServerOverloadException extends CouchbaseException { public FtsServerOverloadException(String payload) { super("Search server is overloaded. Details: " + payload); } }
return applyTimeout(core.<SearchQueryResponse>send(request), request, environment, timeout, timeUnit); }) .flatMap(new Func1<SearchQueryResponse, Observable<SearchQueryResponse>>() { @Override public Observable<SearchQueryResponse> call(final SearchQueryResponse r) { if (shouldRetry(r.statusCode())) { return Observable.error(new RetryableException(r)); } return Observable.just(r); } }) .retryWhen(RetryBuilder .anyOf(RetryableException.class) .max(9) .delay(Delay.exponential(TimeUnit.MILLISECONDS, 500, 2)) .doOnRetry(new Action4<Integer, Throwable, Long, TimeUnit>() { @Override public void call(Integer attempt, Throwable error, Long delay, TimeUnit delayUnit) { LOGGER.debug("Retrying {} because of {} (attempt {}, delay {} {})", query.export(), error.getMessage(), attempt, delay, delayUnit); } }) .build() ) .map(new Func1<SearchQueryResponse, AsyncSearchQueryResult>() { @Override public AsyncSearchQueryResult call(final SearchQueryResponse response) {
public N1qlWriter(N1qlMode mode, boolean createDocuments) { this.mode = mode; this.createDocuments = createDocuments; }
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.kududb.client; import org.kududb.annotations.InterfaceAudience; import java.util.List; import java.util.PriorityQueue; import java.util.Queue; import java.util.concurrent.atomic.AtomicLong; @InterfaceAudience.Private public class RequestTracker { private final AtomicLong sequenceIdTracker = new AtomicLong(); private final Queue<Long> incompleteRpcs = new PriorityQueue<>(); static final long UNSET_SEQUENCE_ID = -1; public RequestTracker() { } public long nextSequenceId() { Long next = sequenceIdTracker.incrementAndGet(); incompleteRpcs.add(next); return next; } public long firstIncompleteRpc() { if (incompleteRpcs.isEmpty()) { return UNSET_SEQUENCE_ID; } return incompleteRpcs.peek(); } public void rpcCompleted(long sequenceId) { incompleteRpcs.remove(sequenceId); } } public void testSuggestDesiredDimensions() { final Point min = getScreenSize(); final Point screenSize = min; final int w = min.x * 3; final int h = min.y * 2; assertDesiredMinimum(new Point(min.x / 2, min.y / 2), min, screenSize); assertDesiredMinimum(new Point(w, h), new Point(w, h), screenSize); assertDesiredMinimum(new Point(min.x / 2, h), min); assertDesiredMinimum(new Point(w, min.y / 2), new Point(w, min.y), screenSize); } private static boolean hasActionView(Element intent) { NodeList children = intent.getChildNodes(); for (int i = 0; i < children.getLength(); i++) { Node child = children.item(i); if (child.getNodeType() == Node.ELEMENT_NODE && child.getNodeName().equals(NODE_ACTION)) { Element action = (Element) child; if (action.hasAttributeNS(ANDROID_URI, ATTRIBUTE_NAME)) { Attr attr = action.getAttributeNodeNS(ANDROID_URI, ATTRIBUTE_NAME); if (attr.getValue().equals("android.intent.action.VIEW")) { return true; } } } } return false; } private void
@Override public void flush(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { if (originalPromise != null) { originalPromise.tryFailure(cause); } ctx.fireExceptionCaught(cause); } @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { if (evt instanceof HandshakeDeadlineEvent) { originalPromise().tryFailure(new ConnectTimeoutException("Handshake did not complete before deadline.")); ctx.close(); return; } ctx.fireUserEventTriggered(evt); } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { if (!originalPromise().isDone()) { originalPromise().tryFailure(new ConnectException("Channel became inactive before handshake completed.")); } ctx.fireChannelInactive(); }
@Override protected Tuple2<ByteBuf, Integer> doEncode(final JsonDocument document) throws Exception { addEncryption(document.content()); return Tuple.create(jsonObjectToByteBuf(document.content()), TranscoderUtils.JSON_COMPAT_FLAGS); } @Override protected JsonDocument doDecode(String id, ByteBuf content, long cas, int expiry, int flags, ResponseStatus status) throws Exception { if (!TranscoderUtils.hasJsonFlags(flags)) { throw new TranscodingException("Flags (0x" + Integer.toHexString(flags) + ") indicate non-JSON document for " + "id " + id + ", could not decode."); } JsonObject jsonObject = byteBufToJsonObject(content); jsonObject.setEncryptionConfig(encryptionConfig); return newDocument(id, expiry, jsonObject, cas); } @Override public JsonDocument newDocument(String id, int expiry, JsonObject content, long cas) { JsonDocument document = JsonDocument.create(id, expiry, content, cas); document.content().setEncryptionConfig(this.encryptionConfig); return document; }
public JsonDocument newDocument(String id, int expiry, JsonObject content, long cas) { JsonDocument document = JsonDocument.create(id, expiry, content, cas); document.content().setEncryptionConfig(this.encryptionConfig); return document; }
public Version(String version) { String[] parts = version.split("\\."); major = Integer.valueOf(parts[0]); if (parts.length > 1) { minor = Integer.valueOf(parts[1]); } if (parts.length > 2) { micro = Integer.valueOf(parts[2]); } } JsonDocument doc = JsonDocument.create(id, data); Observable<JsonDocument> result; switch (opts.ingestMethod) { case INSERT: result = bucket.async().insert(doc); break; case UPSERT: result = bucket.async().upsert(doc); break; case REPLACE: result = bucket.async().replace(doc); break; default: return Observable.error(new UnsupportedOperationException("Unsupported ingest method")); } result = result.timeout(kvTimeout, TimeUnit.MILLISECONDS); if (opts.retryBuilder != null) { result = result.retryWhen(opts.retryBuilder.build()); } if (opts.ignoreIngestError) { result = result.onErrorResumeNext(Observable.<JsonDocument>empty()); } return result;
import libcore.util.Base64; import libcore.util.Base64InputStream; import junit.framework.TestCase; import java.io.ByteArrayInputStream; import java.io.IOException; import java.io.InputStream; import java.nio.charset.StandardCharsets; import java.util.Random; public class Base64InputStreamTest extends TestCase { static final String lipsum = "Lorem ipsum dolor sit amet, consectetur adipiscing elit. " + "Quisque congue eleifend odio, eu ornare nulla facilisis eget. " + "Integer eget elit diam, sit amet laoreet nibh. Quisque enim " + "urna, pharetra vitae consequat eget, adipiscing eu ante. " + "Aliquam venenatis arcu nec nibh imperdiet tempor. In id dui " + "eget lorem aliquam rutrum vel vitae eros. In placerat ornare " + "pretium. Curabitur non fringilla mi. Fusce ultricies, turpis " + "eu ultrices suscipit, ligula nisi consectetur eros, dapibus " + "aliquet dui sapien a turpis. Donec ultricies varius ligula, "; public void testBase64InputStream() throws IOException { byte[] data = lipsum.getBytes(StandardCharsets.UTF_8); byte[] encodedData = Base64.encode(data, Base64.DEFAULT); InputStream inputStream = new ByteArrayInputStream(encodedData); Base64InputStream base64InputStream = new Base64InputStream(inputStream, Base64.DEFAULT); byte[] decodedData = new byte[data.length]; int bytesRead = base64InputStream.read(decodedData); assertEquals(data.length, bytesRead); assertEquals(new String(data, StandardCharsets.UTF_8), new String(decodedData, StandardCharsets.UTF_8)); } }
*Refactored Code:* ```java /** * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.java.query.dsl.path; /** * . * * @author Michael Nitschinger */ public enum SelectType { DEFAULT(""), ALL("ALL"), DISTINCT("DISTINCT"), RAW("RAW"), DISTINCT_RAW("DISTINCT RAW"); private final String value; SelectType(String value) { this.value = value; } public String value() { return value; } } ```
public void shouldNotAllowReplaceAndUUID() { AnalyticsIngester.ingest(null, null, AnalyticsIngester.IngestOptions.ingestOptions().ingestMethod(AnalyticsIngester.IngestMethod.REPLACE)); }
private Button createChangeAction() { final Button createChange = new Button("Create change"); createChange.setTitle("Create change directly in browser"); createChange.addClickHandler(new ClickHandler() { @Override public void onClick(ClickEvent event) { CreateChangeAction.call(createChange, getProjectKey().toString()); } }); return createChange; } public void onResponseReceived(Request req, final Response res) { int status = res.getStatusCode(); if (status == Response.SC_NO_CONTENT) { cb.onSuccess(null); if (!background) { RpcStatus.INSTANCE.onRpcComplete(); } } else if (200 <= status && status < 300) { T data; if (isTextBody(res)) { data = NativeString.wrap(res.getText()).cast(); } else if (isJsonBody(res)) { try { // javac generics bug data = RestApi.<T>cast(parseJson(res)); } catch (JSONException e) { if (!background) { RpcStatus.INSTANCE.onRpcComplete(); } cb.onFailure(new StatusCodeException(SC_BAD_RESPONSE, "Invalid JSON: " + e.getMessage())); return; } } else { if (!background) { RpcStatus.INSTANCE.onRpcComplete(); } cb.onFailure(new StatusCodeException(SC_BAD_RESPONSE, "Expected ")); } } } public void reserveExact(int additional) { Preconditions.checkArgument(additional >= 0, "negative additional"); if (data.length - len >= additional) return; data = Arrays.copyOf(data, len + additional); } import com.couchbase.client.java.Cluster; import com.couchbase.client.java.Bucket; import com.couchbase.client.java.analytics.AnalyticsDeferredResultHandle; import com.couchbase.client.java.analytics.AnalyticsParams; import com.couchbase.client.java.analytics.AnalyticsQuery; import com.couchbase.client.java.analytics.AnalyticsQueryResult; import com.couchbase.client.java.analytics.AnalyticsQueryRow; public class AnalyticsDeferredQueryTest { public static void main(String... args) throws Exception { Cluster cluster = CouchbaseCluster.create(); cluster.authenticate("Administrator", "password"); Bucket bucket = cluster.openBucket("default"); AnalyticsQueryResult result = bucket.query(AnalyticsQuery.simple("SELECT 1=1;", AnalyticsParams.build().deferred(true))); byte[] serialized =
import com.couchbase.client.core.annotations.InterfaceAudience; import com.couchbase.client.core.annotations.InterfaceStability; /** * An async handle to fetch the status and results of a deferred Analytics Query * * @author Subhashni Balakrishnan * @since 2.7.2 */ @InterfaceStability.Experimental @InterfaceAudience.Public public interface AnalyticsDeferredResultHandle { /** * Get the status uri * * @return uri */ @InterfaceAudience.Private String getStatusHandleUri(); /** * Get the result uri if available * * @return uri */ @InterfaceAudience.Private String getResultHandleUri(); /** * Get the list of all {@link AnalyticsQueryRow}, the results of the query, if successful. * * @return the list of all {@link AnalyticsQueryRow} */ List<AnalyticsQueryRow> allRows(); /** * Get an iterator over the list of all {@link AnalyticsQueryRow}, the results of the query, if successful. * * @return an iterator over the list of all {@link AnalyticsQueryRow} */ Iterator<AnalyticsQueryRow> rows(); }
"status='" + status + '\'' + ", finalSuccess=" + finalSuccess + ", parseSuccess=" + parseSuccess + ", allRows=" + allRows + ", signature=" + signature + ", info=" + info + ", errors=" + errors + ", requestId='" + requestId + '\'' + ", clientContextId='" + clientContextId + '\'' + ", handle='" + handle + '\'' + '}';
public String getResultHandleUri() { if (this.resultHandle.length() == 0) { throw new IllegalStateException("There is no result handle available, retry status until success"); } return this.resultHandle; }
public KeysPath useNestedLoop() { element(new NestedLoopJoinHintElement()); return new DefaultKeysPath(this); }
public String export() { StringBuilder sb = new StringBuilder(); sb.append("USE HASH("); sb.append(this.side.getValue()); sb.append(")"); return sb.toString(); }
public String export() { return "USE HASH(" + this.side + ")"; }
package com.couchbase.client.java.query.dsl.path; import com.couchbase.client.core.annotations.InterfaceAudience; import com.couchbase.client.core.annotations.InterfaceStability; /** * Hash side for hash based join * * @author Subhashni Balakrishnan */ @InterfaceStability.Experimental @InterfaceAudience.Public public enum HashSide { PROBE("PROBE"), BUILD("BUILD"); private final String value; HashSide(String value) { this.value = value; } public String getValue() { return this.value; } }
/** * Hash side for hash based join * * @author Subhashni Balakrishnan */ @InterfaceStability.Experimental @InterfaceAudience.Public public enum HashSide { /*The PROBE side will use that table to find matches and perform the join*/ PROBE("PROBE"), /*The BUILD side of the join will be used to create an in-memory hash table */ BUILD("BUILD"); private final String value; HashSide(String value) { this.value = value; } public String toString() { return this.value; } }
/** * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of an specific reference name. * <p> * A number that increases when a reference is updated. Implementations define its meaning * (e.g. version counter or timestamp). When the implementation doesn't support versioning, * it throws an {@link UnsupportedOperationException}. * * @return the update index of this reference. * @throws UnsupportedOperationException if the implementation doesn't support versioning */ default long getUpdateIndex() { throw new UnsupportedOperationException(); }
Refactored Code: ```java /** * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of an specific reference name. * <p> * A number that increases when a reference is updated. Implementations define its meaning (e.g. version counter or timestamp). * When the implementation doesn't support versioning, it throws an {@link UnsupportedOperationException}. * * @return the update index of this reference. * @since 1.0 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } ```
public void testUpdateIndexNotImplemented() throws IOException { Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getVersion(); // Not implemented on FS } @Test public void testUpdateIndexNotImplemented2() throws Exception { RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref : refs) { try { ref.getVersion(); fail("FS doesn't implement update index"); } catch (UnsupportedOperationException e) { // ok } } } @Test public void testGetRefs_EmptyDatabase() throws IOException { Map<String, Ref> all; all = refdir.getRefs(RefDatabase.ALL); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_HEADS); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_TAGS); assertTrue("no references", all.isEmpty()); } @Test public void testGetRefs_HeadOnOneBranch() throws IOException { // test implementation }
public class VersionedRef implements Ref { private Ref ref; private long version; public VersionedRef(Ref ref, long version) { this.ref = ref; this.version = version; } @Override public String getName() { return ref.getName(); } @Override public boolean isSymbolic() { return ref.isSymbolic(); } @Override public Ref getLeaf() { return ref.getLeaf(); } @Override public Ref getTarget() { return ref.getTarget(); } @Override public ObjectId getObjectId() { return ref.getObjectId(); } @Override public long getUpdateTime() { return ref.getUpdateTime(); } @Override public long getCreationTime() { return ref.getCreationTime(); } @Override public long getVersion() { return version; } }
private TmfFilterHelper() { // nothing to do } /** * Build an event filter from the regex string in parameter * * @param regexes The filter regex * @param trace The trace this filter applies to * @return An event filter */ public static @Nullable ITmfFilter buildFilterFromRegex(Collection<String> regexes, ITmfTrace trace) { FilterCu compile = FilterCu.compile(IFilterStrings.mergeFilters(regexes)); if (compile == null) { LOGGER.info("Failed to compile event filter from regex"); return null; } return compile.getEventFilter(trace); } /** * Get the regex that corresponds to this filter. The regex should be in the * filter language described in the {@link org.eclipse.tracecompass.tmf.filter.parser} plugin. * And as it may be used to filter anything, so it may not be the direct string * representing of the original filter. For instance, a ITmfFilter specific * for events will do a smart conversion, so that the parameters of the * filter are not hardcoded in the regex. * * @param filter The filter to get the regex from * @return The regex string */ public static String getRegexFromFilter(ITmfFilter filter) { if (filter instanceof FilterCu) { return ((FilterCu) filter).getRegex(); } LOGGER.warning("Failed to get regex from filter"); return null; }
default long getVersion() { throw new UnsupportedOperationException(); }
package org.eclipse.jgit.lib; /** * Decorate a reference adding the update index (version) property. * * Undecorated Refs throw UnsupportedOperationException on getVersion(), * while decorated instances return the expected value. * * The client is responsible to call getVersion() only on refs obtained from * RefDatabase implementations that support versioning (e.g. reftables) * * @since 5.2 */ public class VersionedRef implements Ref { private Ref ref; private long updateIndex; /** * @param ref the Reference * @param updateIndex its update index */ public VersionedRef(Ref ref, long updateIndex) { this.ref = ref; this.updateIndex = updateIndex; } @Override public String getName() { return ref.getName(); } @Override public boolean isSymbolic() { return ref.isSymbolic(); } @Override public ObjectId getObjectId() { return ref.getObjectId(); } @Override public Storage getStorage() { return ref.getStorage(); } @Override public boolean isPeeled() { return ref.isPeeled(); } @Override public Ref getLeaf() { return ref.getLeaf(); } @Override public Ref getTarget() { return ref.getTarget(); } @Override public long getUpdateIndex() { return updateIndex; } }
} else { factory = new UMLPropertyEditorFactory(reference); } EClass type = reference.getEReferenceType(); factory.setContainerLabelProvider(new UMLFilteredLabelProvider()); factory.setReferenceLabelProvider(new EMFLabelProvider()); ITreeContentProvider contentProvider = new UMLContainerContentProvider(source, reference); ResourceSet rs = source == null ? null : source.eResource() == null ? null : source.eResource().getResourceSet(); EMFGraphicalContentProvider provider = ProviderHelper.encapsulateProvider(contentProvider, rs, HistoryUtil.getHistoryID(source, feature, "container")); factory.setContainerContentProvider(provider); factory.setReferenceContentProvider(new FeatureContentProvider(type)); return factory;
/** * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation * Christian W. Damus - bug 485220 *****************************************************************************/ package org.eclipse.papyrus.uml.tools.databinding; import org.eclipse.core.databinding.observable.IObservable; import org.eclipse.emf.edit.domain.EditingDomain; /** * @deprecated Use the {@link org.eclipse.papyrus.infra.services.edit.ui.databinding.AggregatedPapyrusObservableValue} API, instead. * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public class AggregatedPapyrusObservableValue extends org.eclipse.papyrus.infra.services.edit.ui.databinding.AggregatedPapyrusObservableValue { public AggregatedPapyrusObservableValue(EditingDomain domain, IObservable... observableValues) { super(domain, observableValues); } }
* See the License for the specific language governing permissions and * limitations under the License. */ package com.android.hierarchyviewerlib.models; import java.util.ArrayList; import java.util.HashMap; import com.android.ddmlib.IDevice; import com.android.hierarchyviewerlib.device.Window; /** * This is the model for device selection!!! * * @author Konstantin Lopyrev */ public class DeviceSelectionModel { private HashMap<IDevice, Window[]> deviceMap; private HashMap<IDevice, Integer> focusedWindowHashes; private final ArrayList<IDevice> deviceList = new ArrayList<IDevice>(); private ArrayList<WindowChangeListener> windowChangeListeners; private IDevice selectedDevice; private Window selectedWindow; public DeviceSelectionModel() { deviceMap = new HashMap<IDevice, Window[]>(); windowChangeListeners = new ArrayList<WindowChangeListener>(); focusedWindowHashes = new HashMap<IDevice, Integer>(); } public void addDevice(IDevice device, Window[] windows) { synchronized (deviceMap) { deviceMap.put(device, windows); deviceList.add(device); } notifyDeviceConnected(device); } } import org.eclipse.wst.xml.core.internal.provisional.document.IDOMAttr; import org.eclipse.wst.xml.core.internal.provisional.document.IDOMDocument; import org.eclipse.wst.xml.core.internal.provisional.document.IDOMElement; import org.eclipse.wst.xml.core.internal.provisional.document.IDOMModel; import org.w3c.dom.Attr; import org.w3c.dom.NamedNodeMap; import org.w3c.dom.Node; import org.w3c.dom.NodeList; import java.io.IOException; import java.io.UnsupportedEncodingException; import java.util.ArrayList; import java.util.List; import java.util.Set; /** * A text change that operates on android layout using WTP SSE model. * It is base class for Rename Package and Rename Type changes */ public class AndroidLayoutChange extends DocumentChange { private IDocument mDocument; private ITextFileBufferManager mManager; private IFile mFile; private IStructuredModel mModel; private Set<AndroidLayoutChangeDescription> mChanges; /** * @param file * @param lDocument * @param lManager * @param androidLayoutChangeDescription */ public AndroidLayoutChange(IFile file, IDocument document, ITextFileBufferManager manager
import android.telephony.CellLocation; import android.telephony.ServiceState; import android.telephony.gsm.GsmCellLocation; import com.android.internal.telephony.TelephonyProperties; import android.os.SystemProperties; /** * Stores the cell tower state * * {@hide} */ public class CellState { public static String TAG = "CellState"; public static int RADIO_TYPE_GPRS = 1; public static int RADIO_TYPE_CDMA = 2; public static int RADIO_TYPE_WCDMA = 3; private int mCid = -1; private int mLac = -1; private int mMcc = -1; private int mMnc = -1; private int mHomeMcc = -1; private int mHomeMnc = -1; private String mCarrier = null; private int mRadioType = -1; private long mTime = 0; public CellState() { // constructor for invalid cell location } public CellState(ServiceState service, CellLocation location) { if (location instanceof GsmCellLocation) { // code here } } } import android.telephony.CellLocation; import android.telephony.ServiceState; import android.telephony.gsm.GsmCellLocation; import com.android.internal.telephony.TelephonyProperties; import android.os.SystemProperties; /** * Stores the cell tower state * * {@hide} */ public class CellState { public static String TAG = "CellState"; public static int RADIO_TYPE_GPRS = 1; public static int RADIO_TYPE_CDMA = 2; public static int RADIO_TYPE_WCDMA = 3; private int mCid = -1; private int mLac = -1; private int mMcc = -1; private int mMnc = -1; private int mHomeMcc = -1; private int mHomeMnc = -1; private String mCarrier = null; private int mRadioType = -1; private long mTime = 0; public CellState() { // constructor for invalid cell location } public CellState(ServiceState service, CellLocation location) { if (location instanceof GsmCellLocation) { // code here } } } if (cellState.getRadioType() == CellState.RADIO_TYPE
import org.eclipse.gmf.runtime.emf.type.core.requests.SetRequest; import org.eclipse.papyrus.infra.emf.gmf.command.GMFtoEMFCommandWrapper; import org.eclipse.papyrus.infra.services.edit.service.ElementEditServiceUtils; import org.eclipse.papyrus.infra.services.edit.service.IElementEditService; import org.eclipse.papyrus.infra.ui.emf.databinding.EMFObservableList; /** * An ObservableList used to edit collections of EObjects through Papyrus commands * * @author Camille Letavernier * @deprecated Use the org.eclipse.papyrus.infra.gmfdiag.common.databinding.GMFObservableList API, instead * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated @SuppressWarnings("unchecked") public class PapyrusObservableList extends EMFObservableList { /** * Constructor. * * @param wrappedList The list to be edited when #commit() is called * @param domain The editing domain on which the commands will be executed * @param source The EObject from which the list will be retrieved * @param feature The feature representing the list */ public PapyrusObservableList(List<?> wrappedList, TransactionalEditingDomain domain, EObject source, EStructuralFeature feature) { super(wrappedList, domain, source, feature); } }
import org.eclipse.papyrus.infra.services.edit.service.ElementEditServiceUtils; import org.eclipse.papyrus.infra.services.edit.service.IElementEditService; import org.eclipse.papyrus.infra.tools.databinding.AggregatedObservable; import org.eclipse.papyrus.infra.tools.databinding.ReferenceCountedObservable; import org.eclipse.papyrus.infra.ui.emf.databinding.EMFObservableValue; import org.eclipse.papyrus.uml.tools.Activator; /** * An ObservableValue used to edit EObject properties through Papyrus commands * * @author Camille Letavernier * @deprecated Use the org.eclipse.papyrus.infra.gmfdiag.common.databinding.GMFObservableValue API, instead * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public class PapyrusObservableValue extends EMFObservableValue implements AggregatedObservable, CommandBasedObservableValue, ReferenceCountedObservable { private final ReferenceCountedObservable.Support refCount = new ReferenceCountedObservable.Support(this); /** * Constructor. * * @param eObject The EObject to edit * @param eStructuralFeature The structural feature to edit * @param domain The editing domain on which the commands will be executed */ public PapyrusObservableValue(EObject eObject, EStructuralFeature eStructuralFeature, EditingDomain domain) { super(eObject, eStructuralFeature, domain); } }
/* * SPDX-License-Identifier: EPL-2.0 * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.uml.tools.providers; import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName(); // TODO: To be refactored. Merge this class with UMLLabelProvider // should be removed in Papyrus 5.0 (see bug 540821) return name; } return super.getText(source); } } */
/** * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.uml.tools.providers; import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; /** * An implementation of ILabelProvider for UML Profiles. * * @deprecated This class should be merged with UMLLabelProvider in Papyrus 5.0 (see bug 540821) */ @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName(); if (name == null) { name = UNKNOWN_PROFILE; } if (ProfileUtil.isProfileApplied(umlPackage, profile)) { return name; } else { return name + TAG_PROFILE_CHANGED; } } return super.getText(source); } }
import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName(); if (name == null) { name = UNKNOWN_PROFILE; } if (ProfileUtil.isDirty(umlPackage, profile)) { name += TAG_PROFILE_CHANGED; } return name; } return super.getText(source); } }
long[] stack = new long[1]; stack[0] = 0; return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); private ICallStackElement getElement(ITmfEvent event) { Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(String.valueOf(name))) .findFirst();
import java.util.Collection; import java.util.Optional; import org.eclipse.tracecompass.tmf.core.event.ITmfEvent; import org.eclipse.tracecompass.tmf.core.trace.TmfTraceUtils; import org.eclipse.tracecompass.tmf.ctf.core.event.CtfTmfEventType; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTrace; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfIterator; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfIteratorFactory; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfIteratorType; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfEventIterator; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIterator; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorFactory; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorType; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory.CtfTmfTraceIteratorType; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory.CtfTmfTraceIteratorType.CtfTmfTraceIterator; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory.CtfTmfTraceIteratorType.CtfTmfTraceIterator.CtfTmfEventIterator; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory.CtfTmfTraceIteratorType.CtfTmfTraceIterator.CtfTmfEventIterator.CtfTmfEventType; import org.eclipse.tracecompass.tmf.ctf.core.trace.CtfTmfTraceUtils.CtfTmfTraceIteratorTypeFactory.CtfTmfTraceIteratorType.CtfTmfTraceIterator.CtfTmfEventIterator.CtfTmfEventType.CtfTmfEventType;
public static @Nullable Integer getCpu(ITmfEvent event) { Integer cpuObj = TmfTraceUtils.resolveIntEventAspectOfClassForEvent(event.getTrace(), TmfCpuAspect.class, event); if (cpuObj == null) { /* We couldn't find any CPU information, ignore this event */ return null; } return cpuObj; } @Override public Map<String, Collection<Object>> getCallStack(ITmfEvent event) { Map<String, Collection<Object>> map = new HashMap<>(); ITmfEventField content = event.getContent(); ITmfEventField field = content.getField(KERNEL_CALLSTACK_FIELD); if (field != null) { map.put(KERNEL_STACK_NAME, getCallstack(field)); } field = content.getField(USER_CALLSTACK_FIELD); if (field != null) { map.put(USER_STACK_NAME, getCallstack(field)); } return map; } private static Collection<Object> getCallstack(ITmfEventField field) { Object value = field.getValue(); if (value instanceof long[]) { return Arrays.asList((long[]) value); } else { return Collections.emptyList(); } }
```java } long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } private ICallStackElement getElement(ITmfEvent event) { Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(String.valueOf(name))) .findFirst(); Integer threadId = TmfTraceUtils.resolveIntEventAspectOfClassForEvent(event.getTrace(), LinuxTidAspect.class, event); int tid = (threadId == null) ? -1 : threadId; } ```
if (userCs == null) { userCs = Collections.emptyList(); } if (kernelCs.size() + userCs.size() == 0) { long[] stack = new long[1]; stack[0] = 0; return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } private ICallStackElement getElement(ITmfEvent event) { // Find a root elements with the same PID Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(name)) .findFirst(); return events.orElse(null); }
Optional<Resource> representationResource = Optional.ofNullable(resource) .map(rsr -> rsr.getResourceSet()) .filter(resourceSet -> !loadOnDemand || resourceSet.getURIConverter().exists(repResourceURI, new HashMap<>())) .map(resourceSet -> { Resource res = null; try { res = resourceSet.getResource(repResourceURI, loadOnDemand); } catch (Exception e) { throw new RuntimeException(e); } return res; }); String repId = uri.get().fragment(); if (representationResource.isPresent() && repId != null) { return representationResource.get().getContents().stream() .filter(DRepresentation.class::isInstance) .map(DRepresentation.class::cast)
/***************************************************************************** * Copyright (c) 2017, 2018 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-1.0/ * * SPDX-License-Identifier: EPL-1.0 * * Contributors: * Obeo - initial API and implementation ******************************************************************************/ package org.eclipse.sirius.business.internal.representation; import java.util.HashMap; import java.util.Optional; import org.eclipse.emf.common.util.URI; import org.eclipse.emf.ecore.resource.Resource; import org.eclipse.emf.ecore.util.ECrossReferenceAdapter; import org.eclipse.sirius.business.api.resource.ResourceDescriptor; import org.eclipse.sirius.viewpoint.DRepresentation; import org.eclipse.sirius.viewpoint.DRepresentationDescriptor; /** * This class is intended to manage the link between the {@link DRepresentationDescriptor} and its * {@link DRepresentation} through the {@link DRepresentationDescriptor#repPath} attribute. * * @author fbarbin */ public class DRepresentationDescriptorToDRepresentationLinkManager { // implementation goes here }
@Test public void testMirrorAcceptAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.ACCEPT, DifferenceState.MERGED); } @Test public void testMirrorRejectAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.REJECT, DifferenceState.DISCARDED); } private IEMFCompareConfiguration createConfiguration(boolean leftEditable, boolean rightEditable) { CompareConfiguration cc = new CompareConfiguration(); cc.setProperty(EMFCompareConfiguration.MIRRORED, Boolean.TRUE); cc.setLeftEditable(leftEditable); cc.setRightEditable(rightEditable); EMFCompareConfiguration emfCC = new EMFCompareConfiguration(cc); emfCC.setEditingDomain(editingDomain); return emfCC; } class MockMergeAction extends MergeAction { public MockMergeAction(IEMFCompareConfiguration compareConfiguration, Registry mergerRegistry, MergeMode mode, INavigatable navigatable) { super(compareConfiguration, mergerRegistry, mode, navigatable); } @Override public boolean updateSelection(IStructuredSelection selection) { return super.updateSelection(selection); } @Override protected void clearCache() { super.clearCache(); } @Override protected void handleMerge() { super.handleMerge(); } }
public boolean isMirrored() { Object property = getProperty("MIRRORED"); return property instanceof Boolean && ((Boolean) property).booleanValue(); }
public void propertyChange(PropertyChangeEvent event) { if ("MIRRORED".equals(event.getProperty())) { Object newValue = event.getNewValue(); mirroredPropertyChanged(Boolean.TRUE.equals(newValue)); } }
private String getCurrentValueFromViewer(MergeViewerSide side) { boolean isLeft = MergeViewerSide.LEFT == side; if (getCompareConfiguration().isMirrored()) { isLeft = MergeViewerSide.RIGHT == side; } GetContentRunnable runnable = new GetContentRunnable(isLeft); Display.getDefault().syncExec(runnable); return (String) runnable.getResult(); }
@Test public void testMirrorAcceptAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.ACCEPT, DifferenceState.MERGED); } @Test public void testMirrorRejectAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.REJECT, DifferenceState.DISCARDED); } private IEMFCompareConfiguration createConfiguration(boolean leftEditable, boolean rightEditable) { CompareConfiguration cc = new CompareConfiguration(); cc.setProperty(EMFCompareConfiguration.MIRRORED, Boolean.TRUE); cc.setLeftEditable(leftEditable); cc.setRightEditable(rightEditable); EMFCompareConfiguration emfCC = new EMFCompareConfiguration(cc); emfCC.setEditingDomain(editingDomain); return emfCC; } class MockMergeAction extends MergeAction { public MockMergeAction(IEMFCompareConfiguration compareConfiguration, Registry mergerRegistry, MergeMode mode, INavigatable navigatable) { super(compareConfiguration, mergerRegistry, mode, navigatable); } @Override public boolean updateSelection(IStructuredSelection selection) { return super.updateSelection(selection); } @Override protected void clearCache() { super.clearCache(); } // other methods... }
try { int length = string.length(); if (length == 0) return; boolean mode = true; switch (data.textAntialias) { case SWT.DEFAULT: if (!handle.isDrawingToScreen()) mode = false; break; case SWT.OFF: mode = false; break; case SWT.ON: mode = true; break; } handle.saveGraphicsState(); handle.setShouldAntialias(mode); if (length == 1 && (flags & SWT.DRAW_TRANSPARENT) != 0) { doFastDrawText(string, x, y); } else { doDrawText(string, x, y, flags); } handle.restoreGraphicsState(); } finally { uncheckGC(pool); }
public void stop() { log.info("closing jgroups channel {}", channelName); channel.close(); synchronized (urlsByAddress) { peerInfo = Optional.absent(); peerAddress = null; urlsByAddress.clear(); } } public void close() { try { ch.close(); } catch (IOException e) { // Ignore read close failures. } } private static final class LazyReadableChannel implements ReadableChannel { private final DfsReader ctx; private final DfsReftable file; private ReadableChannel ch; LazyReadableChannel(DfsReftable file, DfsReader ctx) { this.file = file; this.ctx = ctx; } private ReadableChannel getChannel() throws IOException { if (ch == null) { ch = ctx.db.openFile(file.desc, file.ext); } return ch; } @Override public int blockSize() { try { return getChannel().blockSize(); } catch (IOException e) { return -1; } } @Override public long position() throws IOException { return getChannel().position(); } @Override public void position(long newPosition) throws IOException { getChannel().position(newPosition); } @Override public void setReadAheadBytes(int bufferSize) throws IOException { getChannel().setReadAheadBytes(bufferSize); } }
package org.eclipse.mylyn.bugzilla.rest.core.tests; import java.util.List; import org.eclipse.mylyn.commons.sdk.util.CommonTestUtil; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite.SuiteClassProvider; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite.TestConfigurationProperty; import org.eclipse.mylyn.commons.sdk.util.TestConfiguration; import org.junit.runner.RunWith; import org.junit.runners.Suite; @RunWith(ManagedSuite.class) @Suite.SuiteClasses({ RepositoryKeyTest.class, BugzillaRestFlagMapperTest.class, BugzillaRestConnectorNoFixtureTest.class }) @TestConfigurationProperty() public class AllBugzillaRestCoreTests { static { if (CommonTestUtil.fixProxyConfiguration()) {
assertTrue(new File(d, "logs/refs/heads").isDirectory()); assertFalse(new File(d, "logs/HEAD").exists()); assertEquals(0, new File(d, "logs/refs/heads").list().length); assertEquals("ref: refs/heads/master\n", read(new File(d, HEAD))); @Test(expected = UnsupportedOperationException.class) public void testVersioningNotImplemented_exactRef() throws IOException { assertFalse(refdir.hasVersioning()); Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getUpdateIndex(); // Not implemented on FS } @Test public void testVersioningNotImplemented_getRefs() throws Exception { assertFalse(refdir.hasVersioning()); RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref : refs) { try { ref.getUpdateIndex(); fail("FS doesn't implement ref versioning"); } catch (UnsupportedOperationException e) { // ok } } } @Test
public void testVersioningNotImplemented_exactRef() throws IOException { assertFalse(refdir.hasVersioning()); Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getUpdateIndex(); // Not implemented on FS } @Test public void testVersioningNotImplemented_getRefs() throws Exception { assertFalse(refdir.hasVersioning()); RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref : refs) { try { ref.getUpdateIndex(); fail("FS doesn't implement ref versioning"); } catch (UnsupportedOperationException e) { // ok } } } @Test public void testGetRefs_EmptyDatabase() throws IOException { Map<String, Ref> all; all = refdir.getRefs(RefDatabase.ALL); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_HEADS); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_TAGS); assertTrue("no references", all.isEmpty()); }
return ref; Ref dst = ref.getTarget(); if (MAX_SYMBOLIC_REF_DEPTH <= depth) { return null; // claim it doesn't exist } dst = exactRef(dst.getName()); if (dst == null) { return ref; } dst = resolve(dst, depth + 1); if (dst == null) { return null; // claim it doesn't exist } return new VersionedRef(new SymbolicRef(ref.getName(), dst), ref.getUpdateIndex()); } @Override public abstract void close() throws IOException;
/** * Get namespace used by bootstrap layer. * * @return namespace used by bootstrap layer, e.g. {@code refs/txn/}. Always * ends in {@code '/'}. */ @Nullable public String getTxnNamespace() { return txnNamespace; } /** {@inheritDoc} */ @Override public void create() throws IOException { bootstrap.create(); } /** {@inheritDoc} */ @Override public boolean hasVersioning() { return false; } /** {@inheritDoc} */ @Override public boolean performsAtomicTransactions() { return true; } /** {@inheritDoc} */ @Override public void refresh() { bootstrap.refresh(); } /** {@inheritDoc} */ @Override public void close() { refs = null; bootstrap.close(); } /** {@inheritDoc} */ @Override public Ref getRef(String name) throws IOException { String[] needle = new String[SEARCH_PATH.length];
// // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package org.eclipse.jgit.lib; import org.eclipse.jgit.annotations.NonNull; import org.eclipse.jgit.annotations.Nullable; import org.eclipse.jgit.lib.internal.VersionedRef; /** * Pairing of a name and the {@link org.eclipse.jgit.lib.ObjectId} it currently * has. * <p> * A ref in Git is (more or less) a variable that holds a single object * identifier. The object identifier can be any valid Git object (blob, tree, * commit, annotated tag, ...). * <p> * The ref name has the attributes of the ref that was asked for as well as the * ref it was resolved to for symbolic refs plus the object id it points to and */ public class Ref { private final String name; private final ObjectId objectId; private final boolean symbolic; private final String targetName; private final ObjectId targetObjectId; private final VersionedRef versionedRef; public Ref(String name, ObjectId objectId) { this(name, objectId, false, null, null, null); } public Ref(String name, ObjectId objectId, boolean symbolic, String targetName, ObjectId targetObjectId, VersionedRef versionedRef) { this.name = name; this.objectId = objectId; this.symbolic = symbolic; this.targetName = targetName; this.targetObjectId = targetObjectId; this.versionedRef = versionedRef; } public String getName() { return name; } public ObjectId getObjectId() { return objectId; } public boolean isSymbolic() { return symbolic; } public String getTargetName() { return targetName; } public ObjectId getTargetObjectId() { return targetObjectId; } public VersionedRef getVersionedRef() { return versionedRef; } }
/** * Indicator of the relative order between updates of a specific reference name. * <p> * A number that increases when a reference is updated. Implementations define its value (e.g. version counter or timestamp). * <p> * By default this throws an {@link UnsupportedOperationException}. The instantiator of the Ref must override this method (e.g. by using the {@link VersionedRef} decorator) if it can provide a version value. * * @return the version of this reference. * @throws UnsupportedOperationException if the creator of the instance (e.g. {@link RefDatabase}) doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } */
/** * Initialize a new reference database at this location. * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on update. * * @return true when the implementation assigns version numbers to sequencer numbers. * @since 5.3 */ public abstract boolean hasVersioning(); /** * Determine if a proposed reference name overlaps with an existing one. * * Reference names use '/' as a component separator, and may be stored in a * hierarchical storage such as a directory on the local filesystem. * * If the reference "refs/heads/foo" exists then "refs/heads/foo/bar" must */
public abstract void create() throws IOException; public abstract void close(); public abstract boolean hasVersioning(); public abstract boolean isReferenceOverlapping(String proposedReference, String existingReference);
return false; } else if (!block.next()) { long pos = block.endPosition(); if (pos >= scanEnd) { return false; } block = readBlock(pos, scanEnd); continue; } block.parseKey(); if (match != null && !block.match(match, prefix)) { block.skipValue(); return false; } long updateIndex = minUpdateIndex + block.readUpdateIndexDelta(); ref = block.readRef(updateIndex); if (!includeDeletes && wasDeleted()) { continue; } return true; } } @Override public Ref getRef() { return ref; } @Override public void close() { // Do nothing. } } private class LogCursorImpl extends LogCursor { private final long scanEnd; private final byte[] match; private String refName; private long updateIndex; private ReflogEntry entry; BlockReader block; LogCursorImpl(long scanEnd, byte[] match) { this.scanEnd = scanEnd; this.match = match;
public boolean hasNext() { while (true) { if (block == null) { return false; } else if (!block.next()) { long pos; if (blockPos != null) { if (listIdx >= blockPos.size()) { return false; } pos = blockPos.get(listIdx++); } else { pos = block.endPosition(); } if (pos >= scanEnd) { return false; } block = readBlock(pos, scanEnd); continue; } block.parseKey(); long updateIndex = minUpdateIndex + block.readUpdateIndexDelta(); ref = block.readRef(updateIndex); ObjectId id = ref.getObjectId(); if (id != null && match.equals(id) && (includeDeletes || !wasDeleted())) { return true; } } } @Override public Ref getRef() { return ref; } @Override public void close() { // Do nothing. }
*Refactor* ```java /** * name. A number that increases when a reference is updated. * * In case of symbolic references, the update index refers to the update of * the symbolic reference iself (e.g. if HEAD points to master, the HEAD * update index will only increase when HEAD changes, regarless how many * times master is updated). * * The update index and its meaning are usually provided by the * {@code RefDatabase} that instantiates the ref. By default this method * throws an {@link UnsupportedOperationException}. Implementors must * overrride it to return a useful value. * * @return the update index (i.e. version) of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } ``` *Refactored* ```java /** * Returns the update index (i.e. version) of this reference. * * The update index and its meaning are usually provided by the * {@code RefDatabase} that instantiates the ref. By default, this method * throws an {@link UnsupportedOperationException}. Implementors must * override it to return a useful value. * * @return the update index of this reference, or -1 if versioning is not supported * @since 5.3 */ default long getUpdateIndex() { return -1; } ```
protected Object createElementViewerInput() { List<TracePackageTraceElement> traceElements = new ArrayList<>(); for (TmfTraceElement tmfTraceElement : fSelectedTraces) { TracePackageTraceElement traceElement = new TracePackageTraceElement(null, tmfTraceElement); TracePackageFilesElement filesElement = new TracePackageFilesElement(traceElement, tmfTraceElement.getResource()); filesElement.setChecked(true); traceElement.addChild(filesElement); String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); traceElement.addChild(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { // Add supplementary files to suppFilesElement } } traceElements.add(traceElement); } return traceElements; }
filesElement.setChecked(true); children.add(filesElement); // Supplementary files try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) { // Handle exception }
// Supplementary files try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) { // Handle exception }
try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) { throw new CoreException(e); }
private T createTest(Class<? extends TestCase> testClass, String methodName, Annotation[] annotations) { return factory.createTest(testClass, methodName, annotations); } // This should close the Raf, and previous implementations wrongly returned a new // open (but useless) channel in this case. fileChannelBeforeClosing.close(); FileChannel fileChannelAfterClosing = raf.getChannel(); assertFalse(fileChannelBeforeClosing.isOpen()); // http://b/19892782 public void testCloseRafBeforeGetChannel_returnChannelWithCloseFdAfterClose() throws Exception { RandomAccessFile raf = new RandomAccessFile(file, "rw"); raf.setLength(10); raf.close(); try { raf.getChannel().size(); fail(); } catch (IOException expected) { return; } assertFalse("Exception expected", true); } private void createRandomAccessFile(File file) throws Exception { // TODO: fix our register maps and remove this otherwise unnecessary // indirection! (http://b/5412580) new RandomAccessFile(file, "rw"); } public void testDirectories() throws Exception { try { new RandomAccessFile(".", "r"); fail(); } catch (FileNotFoundException expected) { } try { new RandomAccessFile(".", "rw"); fail(); } catch (FileNotFoundException expected) { } } TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) { // Should not happen Activator.getDefault().logError("Error finding supplementary files", e
import java.io.ByteArrayOutputStream; import java.io.IOException; import java.util.ArrayList; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import org.eclipse.jgit.internal.storage.io.BlockSource; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectIdRef; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefComparator; import org.eclipse.jgit.lib.SymbolicRef; import org.junit.Test; public class MergedReftableTest { @Test public void noTables() throws IOException { MergedReftable mr = merge(new byte[0][]); try (RefCursor rc = mr.allRefs()) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRef(HEAD)) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRefsWithPrefix(R_HEADS)) { assertFalse(rc.next()); } } @Test public void oneEmptyTable() throws IOException { MergedReftable mr = merge(write()); try (RefCursor rc = mr.allRefs()) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRef(HEAD)) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRefsWithPrefix(R_HEADS)) { assertFalse(rc.next()); } } }
public abstract void create() throws IOException; public abstract void close(); public abstract boolean hasVersioning(); public abstract boolean isReferenceOverlapping(String proposedReference); public abstract boolean isReferenceOverlapping(String existingReference, String proposedReference);
public abstract boolean hasVersioning() { return false; }
*Refactored Code:* ```java /** * With symbolic references, the update index refers to updates of the * symbolic reference itself. For example, if HEAD points to * refs/heads/master, then the update index for exactRef("HEAD") will only * increase when HEAD changes to point to another ref, regardless of how * many times refs/heads/master is updated. * * Should not be used unless the RefDatabase that instantiated the ref supports versioning. * * @return the update index (i.e. version) of this reference. * @throws UnsupportedOperationException if the creator of the instance (e.g. RefDatabase) * doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } ```
public static final String ALL = ""; public abstract void create() throws IOException; public abstract void close(); public boolean hasVersioning() { return false; } public boolean isNameConflicting(String refName) { return false; }
```java boolean isPeeled(); /** * How was this ref obtained? * <p> * The current storage model of a Ref may influence how the ref must be * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of a specific reference * name. A number that increases when a reference is updated. * <p> * With symbolic references, the update index refers to updates of the * symbolic reference itself. For example, if HEAD points to * refs/heads/master, then the update index for exactRef("HEAD") will only * increase when HEAD changes to point to another ref, regardless of how * many times refs/heads/master is updated. * * Should not be used unless the {@code RefDatabase} that instantiated the * ref supports versioning (see {@link RefDatabase#hasVersioning()}) */ @NonNull UpdateIndex getUpdateIndex(); ``` ```java boolean isPeeled(); /** * How was this ref obtained? * <p> * The current storage model of a Ref may influence how the ref must be * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of a specific reference * name. A number that increases when a reference is updated. * <p> * With symbolic references, the update index refers to updates of the * symbolic reference itself. For example, if HEAD points to * refs/heads/master, then the update index for exactRef("HEAD") will only * increase when HEAD changes to point to another ref, regardless of how * many times refs/heads/master is updated. * * Should not be used unless the {@code RefDatabase} that instantiated the * ref supports versioning (see {@link RefDatabase#hasVersioning()}) */ @NonNull UpdateIndex getUpdateIndex(); ``` ```java boolean isPeeled(); /** * How was this ref obtained? * <p> * The current storage model of a Ref may influence how the ref must be * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of a specific reference * name. A number that increases when a
/***************************************************************************** * Copyright (c) 2009, 2018 THALES GLOBAL SERVICES and others. * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation ******************************************************************************/ package org.eclipse.sirius.ui.tools.internal.actions.export; import java.util.Collection; import java.util.Iterator; import java.util.LinkedHashSet; import java.util.Set; import java.util.stream.Collectors; import org.eclipse.emf.ecore.EObject; import org.eclipse.sirius.business.api.dialect.DialectManager; import org.eclipse.sirius.business.api.query.DRepresentationDescriptorQuery; import org.eclipse.sirius.business.api.session.Session; import org.eclipse.sirius.ui.business.api.dialect.DialectUIManager; import org.eclipse.sirius.ui.business.api.dialect.ExportFormat; import org.eclipse.sirius.ui.business.api.dialect.ExportFormat.ExportDocumentFormat; import org.eclipse.sirius.viewpoint.DRepresentationDescriptor; import org.eclipse.sirius.viewpoint.provider.Messages;
public void run() { Collection<DRepresentationDescriptor> repDescriptorsToExport = getRepresentationToExport().stream() .filter(Objects::nonNull) .filter(repDesc -> repDesc.getRepresentation() != null) .collect(Collectors.toList()); if (!repDescriptorsToExport.isEmpty()) { DRepresentationDescriptor firstDRepDescriptorToExport = repDescriptorsToExport.iterator().next(); firstDRepDescriptorToExport.getRepresentation(); Session session = getSession(firstDRepDescriptorToExport); if (session != null) { IPath exportPath = getExportPath(firstDRepDescriptorToExport, session); if (exportPath != null) { exportRepresentation(exportPath, repDescriptorsToExport, session); } } } else { MessageDialog.openInformation(Display.getCurrent().getActiveShell(), Messages.ExportRepresentationsAction_noRepresentationsDialog_title, Messages.ExportRepresentationsAction_noRepresentationsDialog_message); } }
@Deprecated @Nullable public abstract Ref getRef(String name) throws IOException; public Ref findRef(String name) throws IOException { return getRef(name); } /** * Read a single reference. * <p> * Aside from taking advantage of {@link #SEARCH_PATH}, this method may be * able to more quickly resolve a single reference name than obtaining the * complete namespace by {@code getRefs(ALL).get(name)}. * <p> * To read a specific reference without using @{link #SEARCH_PATH}, see * {@link #exactRef(String)}. * * @param name the name of the reference. May be a short name which must be * searched for using the standard {@link #SEARCH_PATH}. * @return the reference (if it exists); else {@code null}. * @throws IOException the reference space cannot be accessed. * @deprecated Use {@link #findRef(String)} instead. */ @Deprecated @Nullable public Ref getRef(String name) throws IOException { return findRef(name); }
public static FirstCommand fromLine(String line) { int nul = line.indexOf('\0'); if (nul < 0) { return new FirstCommand(line, Collections.emptySet()); } Set<String> opts = Arrays.asList(line.substring(nul + 1).split(" ")) .stream() .collect(Collectors.toSet()); return new FirstCommand(line.substring(0, nul), opts); }
protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); } IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (!"jar".equalsIgnoreCase(path.getFileExtension())) { //$NON-NLS-1$ IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } } return null; }
protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); } IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (!"jar".equalsIgnoreCase(path.getFileExtension())) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } } return null; }
IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); // look for files or folders with the given path IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (getType() != ARCHIVE) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); } return null;
static int read(ReadableChannel rc, ByteBuffer buf) throws IOException { int n; do { n = rc.read(buf); } while (0 < n && buf.hasRemaining()); return buf.position(); } static long elapsedMicros(long start) { return (System.nanoTime() - start) / 1000L; } /** * A supplier of readable channel that opens the channel lazily. */ private static class LazyChannel implements AutoCloseable, DfsBlockCache.ReadableChannelSupplier { final DfsReader ctx; ReadableChannel rc = null; LazyChannel(DfsReader ctx) { this.ctx = ctx; } @Override public ReadableChannel get() throws IOException { if (rc == null) { synchronized (this) { if (rc == null) { rc = ctx.db.openFile(desc, ext); } } } return rc; } @Override public void close() throws IOException { if (rc != null) { rc.close(); } } }
import org.eclipse.osgi.util.NLS; final public class ChecksumVerifier extends MessageDigestProcessingStep { private String expectedChecksum; final private String algorithmName; final private String algorithmId; // public to access from tests public ChecksumVerifier(String digestAlgorithm, String algorithmId) { this.algorithmName = digestAlgorithm; this.algorithmId = algorithmId; basicInitialize(null); } @Override public final void initialize(IProvisioningAgent agent, IProcessingStepDescriptor descriptor, IArtifactDescriptor context) { super.initialize(agent, descriptor, context); basicInitialize(descriptor); String data = descriptor.getData(); if (IArtifactDescriptor.DOWNLOAD_CHECKSUM.concat(".").concat(algorithmId).equals(data)) //$NON-NLS-1$ expectedChecksum = ChecksumHelper.getChecksums(context, IArtifactDescriptor.DOWNLOAD_CHECKSUM).get(algorithmId); else if (IArtifactDescriptor.ARTIFACT_CHECKSUM.concat(".").concat(algorithmId).equals(data)) //$NON-NLS-1$ expectedChecksum = ChecksumHelper.getChecksums(context, IArtifactDescriptor.ARTIFACT_CHECKSUM).get(algorithmId); else expectedChecksum = data; if (ofNullable(expectedChecksum).orElse("").isEmpty()) { //$NON-NLS-1$ return; } // Rest of the code } }
private static String selectionToString(Table table) { StringBuilder builder = new StringBuilder(); for (TableItem tableItem : table.getSelection()) { if (builder.length() > 0) { builder.append(System.lineSeparator()); } for (int column = 0; column < table.getColumnCount(); column++) { if (column > 0) { builder.append('\t'); } builder.append(tableItem.getText(column)); } } return builder.toString(); }
sessionId.toAPI(), userId.toAPI()); authorizationService.checkProjectAdminAccess(sessionId.toAPI(), null, ESProjectAdminPrivileges.DeleteOrgUnit); ACUser userToDelete = null; for (final Iterator<ACUser> iter = getUsers().iterator(); iter.hasNext();) { final ACUser user = iter.next(); /* check if we were created by the deleted user */ if (user.getCreatedBy() != null && user.getCreatedBy().equals(userId.getId())) { user.setCreatedBy(null); } /* check if we are the deleted user */ if (user.getId().equals(userId)) { userToDelete = user; } } for (final ACGroup group : getGroups()) { if (group.getCreatedBy() != null && group.getCreatedBy().equals(userId.getId())) { group.setCreatedBy(null); } } /* perform deletion */ if (userToDelete != null) { final List<ACGroup> groups = getGroups(sessionId, userId); save(); }
Fixed Code: ```java if (user.getCreatedBy() != null && user.getCreatedBy().equals(userId.getId())) { user.setCreatedBy(null); save(); } /* check if we are the deleted user */ if (user.getId().equals(userId)) { userToDelete = user; } for (final ACGroup group : getGroups()) { if (group.getCreatedBy() != null && group.getCreatedBy().equals(userId.getId())) { group.setCreatedBy(null); save(); } } /* perform deletion */ if (userToDelete != null) { final List<ACGroup> groups = getGroups(sessionId, userId); for (final ACGroup acGroup : groups) { removeMember(sessionId, acGroup.getId(), userId); } getAccessControl().getOrgUnitProviderService().removeUser(userToDelete.toAPI()); // TODO: move ecore delete into ServerSpace#deleteUser implementation EcoreUtil.delete(userToDelete); save(); } ``` Refactor the Buggy Code using the Review without comments
/* act */ adminBroker2.deleteUser(createdUser1.getId()); /* assert */ assertEquals(initialSize - 1, adminBroker.getUsers().size()); assertNull(findUser(USER_NAME_2).getCreatedBy()); } private ACUser findUser(String name) throws ESException { for (final ACUser user : adminBroker.getUsers()) { if (user.getName().equals(name)) { return user; } } return null; } private ACGroup findGroup(String name) throws ESException { for (final ACGroup group : adminBroker.getGroups()) { if (group.getName().equals(name)) { return group; } } return null; } @Test(expected = AccessControlException.class) public void testLoginOfCreatedUserWithNoPasswordSet() throws ESException { adminBroker.createUser(USER_NAME); ACUser user = null; for (final ACUser u : adminBroker.getUsers()) { if (u.getName().equals(USER_NAME)) { user = u; break; } } }
throw new StorageException(StorageException.NOSAVE, e); } } private void checkForNulls(Object... objects) throws InvalidInputException { for (final Object obj : objects) { if (obj == null) { throw new InvalidInputException(); } } } private <T extends ACOrgUnit<?>> List<T> removeInvisibleOrgUnits(List<T> orgUnits, ESSessionId sessionId) throws AccessControlException { /* * regular users can't see any orgunits, while server admins can see all of them. Only server admins have * reduced visibility. */ final ESOrgUnitId adminId = getAccessControl().getSessions().resolveToOrgUnitId(sessionId); final Optional<ACOrgUnit<?>> orgUnit = ACHelper.getOrgUnit( getAccessControl().getOrgUnitProviderService(), adminId); if (!orgUnit.isPresent()) { return orgUnits; } final List<Role> allRolesOfAdmin = ACHelper.getAllRoles( getAccessControl().getOrgUnitResolverServive(), orgUnit.get()); if (Iterables.any(allRolesOfAdmin, new HasRolePredicate(ServerAdmin.class))) { return orgUnits; }
package org.eclipse.emf.emfstore.server.accesscontrol.test; import static org.eclipse.emf.emfstore.client.test.common.util.ProjectUtil.share; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertTrue; import static org.junit.Assert.fail; import java.util.Arrays; import java.util.LinkedHashSet; import java.util.List; import java.util.Set; import org.eclipse.emf.emfstore.client.ESUsersession; import org.eclipse.emf.emfstore.client.test.common.dsl.Roles; import org.eclipse.emf.emfstore.client.test.common.util.ServerUtil; import org.eclipse.emf.emfstore.internal.server.model.accesscontrol.ACGroup; import org.eclipse.emf.emfstore.internal.server.model.accesscontrol.ACOrgUnit; public class AccessControlTest { /******************************************************************************* * Copyright (c) 2011-2014 EclipseSource Muenchen GmbH and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Edgar Mueller - initial API and implementation ******************************************************************************/ public void testAccessControl() { // Test code here } }
getAdminBroker().addMember(group, otherGroup); getAdminBroker().addMember(otherGroup, newUser); ProjectUtil.share(getUsersession(), getLocalProject()); final ProjectSpace clonedProjectSpace = cloneProjectSpace(getProjectSpace()); ProjectUtil.share(getSuperUsersession(), clonedProjectSpace.toAPI()); getAdminBroker().changeRole(getProjectSpace().getProjectId(), group, Roles.writer()); getAdminBroker().changeRole(getProjectSpace().getProjectId(), otherGroup, Roles.writer()); final int oldSize = getAdminBroker().getGroups().size(); getAdminBroker().deleteGroup(group); assertEquals(oldSize - 1, getAdminBroker().getGroups().size()); @Test public void deleteUser() throws ESException { makeUserPA(); final ACOrgUnitId newUser = ServerUtil.createUser(getSuperUsersession(), getNewUsername()); final ACOrgUnitId group = ServerUtil.createGroup(getSuperUsersession(), getNewGroupName()); final ACOrgUnitId otherGroup = ServerUtil.createGroup(getSuperUsersession(), getNewOtherGroupName()); }
import org.junit.runners.Parameterized.Parameters; import org.mockito.ArgumentCaptor; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @RunWith(ParameterizedPlatformTestRunner.class) public class JmsMomImplementorTest { private static final Logger LOG = LoggerFactory.getLogger(JmsMomImplementorTest.class); @ClassRule public static final ArtemisJmsBrokerTestRule ARTEMIS_RULE = new ArtemisJmsBrokerTestRule(); private IBean<? extends JmsTestMom> m_momBean; private IBean<? extends IJmsMessageHandler> m_messageHandlerBean; private List<IDisposable> m_disposables; private String m_testJobExecutionHint; @Rule public TestName m_testName = new TestName(); public long m_t0; private static final AtomicInteger MOM_COUNTER = new AtomicInteger(0); @Parameters public static List<IScoutTestParameter> getParameters() { List<IScoutTestParameter> parametersList = new LinkedList<IScoutTestParameter>(); // We do not need jmx for unit testing. Also we must disable watchTopicAdvisories else some concurrent issues with broker recreation will happen // ... } }
try { Jobs.getJobManager().awaitDone(testJobsFilter, 10, TimeUnit.SECONDS); LOG.info("All jobs have finished after {} ms", StringUtility.formatNanos(System.nanoTime() - t0)); } catch (TimedOutError e) { LOG.warn("Some cancelled jobs are still running after {} ms! Please check their implementation.", StringUtility.formatNanos(System.nanoTime() - t0)); } BeanTestingHelper.get().unregisterBean(m_messageHandlerBean); m_messageHandlerBean = null; uninstallTestMom(); // ensure activeMQ is stopped BrokerService brokerService = BrokerRegistry.getInstance().findFirst(); if (brokerService != null) { brokerService.stop(); brokerService.waitUntilStopped(); } LOG.info("Finished test in {} ms", StringUtility.formatNanos(System.nanoTime() - m_t0)); LOG.info("</{}>", m_testName.getMethodName()); } @Test @NonParameterized public void testInstanceScoped() { JmsMomImplementor mom1 = BEANS.get(JmsMomImplementor.class); }
} })); // Initiate 'request-reply' communication final String request = "hello world"; String testee = MOM.request(JmsTestMom.class, queue, request); // Verify final String expectedReply = "HELLO WORLD"; assertEquals(expectedReply, testee); IMarshaller marshaller = BEANS.get(CONFIG.getPropertyValue(DefaultMarshallerProperty.class)); verifyRequestReplyMessageLogger(queue, marshaller, request, expectedReply); } private static <DTO> void verifyRequestReplyMessageLogger(IDestination<DTO> expectedDestination, IMarshaller marshaller, DTO expectedRequest, DTO expectedReply) { verify(BEANS.get(IJmsMessageHandler.class), times(2)).handleOutgoing(any(), any(), any()); verifyMessageLoggerHandleOutgoingCalled(expectedDestination, marshaller, expectedRequest); verifyMessageLoggerHandleOutgoingCalled(null, marshaller, expectedReply); // "reply" message is sent only with JMS destination (but without a Scout MOM destination) verify(BEANS.get(IJmsMessageHandler.class), times(2)).handleIncoming(eq(expectedDestination), any(), any()); verifyMessageLoggerHandleIncomingCalled(expectedDestination, marshaller, expectedRequest, expectedReply); }
void init(Map<Object, Object> properties); void handleIncoming(IDestination<?> destination, Message message, IMarshaller marshaller); void handleOutgoing(IDestination<?> destination, Message message, IMarshaller marshaller);
/** * This method is called directly before a JMS message is "sent" by the <i>MessageProducer</i>. "Sent" means that the * <i>send</i> method of the message producer is called. Therefore it is not guaranteed that the time, at which this * method is called, is the <i>sent time</i> of the JMS message (e.g. in a transactional context). * * The message has already been processed (marshalled) by the MOM framework. * * @param destination the MOM destination this message is being sent to. <b>Attention:</b> This might be <code>null</code> in * case of a 'request-reply' communication, where the reply message is only sent back through the JMS * destination defined by {@link Message#getJMSReplyTo()} (and not through a MOM destination) */ void handleOutgoing(IDestination<?> destination, Message message, IMarshaller marshaller); }
protected Message createMessage(final int messageType, final Session session) throws JMSException { switch (messageType) { case MESSAGE_TYPE_TEXT: return session.createTextMessage(); case MESSAGE_TYPE_BYTES: return session.createBytesMessage(); case MESSAGE_TYPE_NO_PAYLOAD: return session.createMessage(); default: throw new PlatformException("Unsupported message type '{}'", messageType); } } public IMarshaller getMarshaller() { return m_marshaller; } public JmsMessageWriter writeTransferObject(final Object transferObject) throws JMSException { final Object transportObject = m_marshaller.marshall(transferObject, m_marshallerContext); m_marshallerContext.put(CTX_PROP_NULL_OBJECT, Boolean.valueOf(transferObject == null).toString()); }
protected JmsMessageWriter writeContext(final String property, final Map<String, String> context) throws JMSException { if (context.isEmpty()) { return this; } final String json = (String) BEANS.get(JsonMarshaller.class).marshall(context, new HashMap<>()); writeProperty(property, json); return this; } public Message build() throws JMSException { writeContext(JMS_PROP_MARSHALLER_CONTEXT, m_marshallerContext); if (m_message instanceof BytesMessage) { ((BytesMessage) m_message).reset(); } return m_message; }
/** * Computes the identifier to name the {@link Connection}. * * @param properties the properties map * @return the computed client ID */ protected String computeClientId(final Map<Object, Object> properties) { final String clientId = ObjectUtility.toString(properties.get(JMS_CLIENT_ID)); if (clientId != null) { return clientId; } final String nodeId = BEANS.get(NodeIdentifier.class).get(); return StringUtility.join(" ", m_symbolicName, StringUtility.box("(", nodeId, ")")); } /** * Returns the message handler. * * @return the message handler */ public IJmsMessageHandler getMessageHandler() { return m_messageHandler; } /** * Exception Handler used in MOM. */ public static class MomExceptionHandler extends ExceptionHandler { }
import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertTrue; public class BundleWriterTest extends SampleDataRepositoryTestCase { @Rule public ExpectedException thrown = ExpectedException.none(); @Test public void testEmptyBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, new byte[0]); } @Test public void testNonBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, "Not a bundle file".getBytes(StandardCharsets.UTF_8)); } @Test public void testGarbageBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, (TransportBundle.V2_BUNDLE_SIGNATURE + '\n' + "Garbage") .getBytes(StandardCharsets.UTF_8)); } @Test public void testWriteSingleRef() throws Exception { // Create a tiny bundle, (well one of) the first commits only final byte[] bundle = makeBundle("refs/heads/firstcommit", ObjectId.fromString("deadbeefdeadbeefdeadbeefdeadbeefdeadbeef")); Repository newRepo = createBareRepository(); fetchFromBundle(newRepo, bundle); Ref ref = newRepo.exactRef("refs/heads/firstcommit"); assertTrue(ref != null); assertEquals(ObjectId.fromString("deadbeefdeadbeefdeadbeefdeadbeefdeadbeef"), ref.getObjectId()); } }
* key is not specified) * @param credentialsProvider * provider to use when querying for signing key credentials (eg. * passphrase) * @throws CanceledException * when signing was canceled (eg., user aborted when entering * passphrase) */ public abstract void sign(@NonNull CommitBuilder commit, String gpgSigningKey, @NonNull PersonIdent committer, CredentialsProvider credentialsProvider) throws CanceledException; /** * Indicates is a signing key is available for the specified committer and/or signing key. * * @param gpgSigningKey * the signing key (passed as is to the GPG signing tool) * @param committer * the signing identity (to help with key lookup in case signing * key is not specified) * @param credentialsProvider * provider to use when querying for signing key credentials (eg. * passphrase) * @return <code>true</code> if a signing key is available, * <code>false</code> otherwise * @throws CanceledException */ public abstract boolean isSigningKeyAvailable(String gpgSigningKey, @NonNull PersonIdent committer, CredentialsProvider credentialsProvider) throws CanceledException;
/** * Indicates if a signing key is available for the specified committer and/or signing key. * * @param signingKey the ID of the signing key (passed as is to the GPG signing tool) * @param committer the signing identity (to help with key lookup in case signing key is not specified) * @param credentialsProvider provider to use when querying for signing key credentials (eg. passphrase) * @return true if a signing key is available, false otherwise * @throws CanceledException when signing was canceled (eg., user aborted when entering passphrase) */ public abstract boolean canLocateSigningKey(String signingKey, PersonIdent committer, CredentialsProvider credentialsProvider); /** * Signs the commit using the specified signing key, committer, and credentials provider. * * @param commit the commit to sign * @param signingKey the ID of the signing key (passed as is to the GPG signing tool) * @param committer the signing identity * @param credentialsProvider provider to use when querying for signing key credentials (eg. passphrase) * @throws CanceledException when signing was canceled (eg., user aborted when entering passphrase) */ public abstract void sign(CommitBuilder commit, String signingKey, PersonIdent committer, CredentialsProvider credentialsProvider) throws CanceledException;
protected void doSetValue(Object value) { super.doSetValue(value); }
public class RevealElementsAction extends AbstractRevealElementsAction<Object> { public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } public RevealElementsAction(final String text) { super(text); } public static boolean isHidden(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } public static boolean isHiddenSelection(List<IDiagramElementEditPart> selectedElements) { for (IDiagramElementEditPart selectedElement : selectedElements) { if (!isHidden(selectedElement)) { return false; } } return true; } }
public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } public RevealElementsAction(final String text) { super(text); } public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; }
protected ICommand getMoveCommand(MoveRequest req) { ICommand moveCommand = super.getMoveCommand(req); Map<?, ?> elementsToMove = req.getElementsToMove(); Iterator<?> iterator = elementsToMove.entrySet().iterator(); boolean moveAllowed = true; while (moveAllowed && iterator.hasNext()) { Entry<?, ?> entrySet = (Entry<?, ?>) iterator.next(); if (entrySet.getKey() instanceof MessageOccurrenceSpecification) { MessageOccurrenceSpecification mos = (MessageOccurrenceSpecification) entrySet.getKey(); EObject container = mos.eContainer(); if (null != container && container != req.getTargetContainer()) { moveAllowed = false; } } } if (!moveAllowed) { moveCommand = UnexecutableCommand.INSTANCE; } return moveCommand; } private List<Pair<NetworkSecurityConfig.Builder, Set<Domain>>> parseConfigEntry(XmlResourceParser parser, Set<String> seenDomains, NetworkSecurityConfig.Builder parentBuilder, int configType) throws IOException, XmlPullParserException, ParserException { List<Pair<NetworkSecurityConfig.Builder, Set<Domain>>> builders = new ArrayList<>(); NetworkSecurityConfig.Builder builder = new NetworkSecurityConfig.Builder(); builder.setParent(parentBuilder); Set<Domain> domains = new ArraySet<>(); boolean seenPinSet = false; boolean seenTrustAnchors = false; boolean defaultOverridePins = configType == CONFIG_DEBUG; String configName = parser.getName(); int outerDepth = parser.getDepth(); builders.add(new Pair<>(builder, domains)); for (int i = 0; i < parser.getAttributeCount(); i++) { String name = parser.getAttributeName(i); if ("hstsEnforced".equals(name)) { // ... } } // ... return anchors; } // ... public static void testArrayElementSetter() throws Throwable { MethodHandle setter = MethodHandles.arrayElementSetter(int[].class); int[] array = new int[2]; setter.invoke(array, 0, 42); setter.invoke(array, 1, 43); if (array[0] != 42) { System.out.println("Unexpected value: " + array[0]); } if (array[1] != 43) { System.out.println("Unexpected value: " + array[1]); } } // ... public RevealElementsAction
public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } public RevealElementsAction(final String text) { super(text); } public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; }
public static boolean isHidden(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } public static boolean isHidden(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isHidden((IDiagramElementEditPart) next); } } return result; }
public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); } else { result = false; } } return result; } @Override public boolean isActive(IDiagramElementEditPart selectedElement) { return isActive(selectedElement); }
public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); } else { result = false; } } return result; }
public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); } else { result = false; } } return result; }
if (vpe instanceof DDiagramElement && this.selection instanceof DiagramOutlinePage.TreeSelectionWrapper) { final DiagramOutlinePage.TreeSelectionWrapper wrapper = (DiagramOutlinePage.TreeSelectionWrapper) this.selection; final RootEditPart root = wrapper.getRoot(); final DDiagramEditor diagramEditor = (DDiagramEditor) wrapper.getViewer().getProperty(DDiagramEditor.EDITOR_ID); runRevealCommand(root, diagramEditor, (DDiagramElement) vpe); } else if (vpe instanceof IDiagramElementEditPart) { Optional<DDiagramElement> optional = Optional.of((IGraphicalEditPart) vpe) .map(IGraphicalEditPart::resolveSemanticElement) .filter(DDiagramElement.class::isInstance) .map(DDiagramElement.class::cast); if (optional.isPresent()) { IDiagramElementEditPart diagramElementEditPart = (IDiagramElementEditPart) vpe; SelectionRequest request = new SelectionRequest(); request.setType(RequestConstants.REQ_OPEN); diagramElementEditPart.performRequest(request); } }
private void runRevealCommand(final RootEditPart root, final DDiagramEditor editor, final DDiagramElement vpe) { final Object adapter = editor.getAdapter(IDiagramCommandFactoryProvider.class); final IDiagramCommandFactoryProvider cmdFactoryProvider = (IDiagramCommandFactoryProvider) adapter; final TransactionalEditingDomain transactionalEditingDomain = TransactionUtil.getEditingDomain(editor.getEditingDomain().getResourceSet()); final IDiagramCommandFactory emfCommandFactory = cmdFactoryProvider.getCommandFactory(transactionalEditingDomain); final Command cmd = emfCommandFactory.buildRevealCommand(vpe); final TransactionalEditingDomain domain = TransactionUtil.getEditingDomain(vpe); CompoundCommand allInOne = new CompoundCommand(cmd.getLabel()); allInOne.append(cmd); domain.getCommandStack().execute(allInOne); }
package org.eclipse.sirius.diagram.ui.tools.internal.actions.visibility; import org.eclipse.gef.Disposable; import org.eclipse.gmf.runtime.diagram.ui.parts.IDiagramWorkbenchPart; import org.eclipse.jface.action.IAction; import org.eclipse.jface.viewers.ISelection; import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.PlatformUI; public class TabbarRevealElementsAction extends RevealElementsAction implements Disposable { private IDiagramWorkbenchPart representationPart; public TabbarRevealElementsAction(final String text) { super(text); } public void setActionPart(IDiagramWorkbenchPart part) { this.representationPart = part; } @Override public void selectionChanged(IAction action, ISelection s) { super.selectionChanged(action, s); } }
import org.eclipse.jface.viewers.ISelection; import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.PlatformUI; public class TabbarRevealElementsAction extends RevealElementsAction implements Disposable { private IDiagramWorkbenchPart representationPart; public TabbarRevealElementsAction(final String label) { super(label); } public void setActionPart(IDiagramWorkbenchPart part) { this.representationPart = part; } @Override public void selectionChanged(IAction action, ISelection s) { IWorkbenchPart selectedPart = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage().getActivePart(); if (representationPart != null && !representationPart.equals(selectedPart)) { return; } super.selectionChanged(action, s); setEnabled(isEnabled()); } @Override public boolean isEnabled() { // implementation } }
import org.eclipse.sirius.diagram.ui.tools.internal.actions.visibility.RevealElementsAction; public class CanShowElementTester extends PropertyTester { @Override public boolean test(Object receiver, String property, Object[] args, Object expectedValue) { boolean result = false; if ("canShowElement".equals(property)) { if (receiver instanceof IStructuredSelection) { result = RevealElementsAction.isActive((IStructuredSelection) receiver); } else if (receiver instanceof IDiagramElementEditPart) { result = RevealElementsAction.isActive((IDiagramElementEditPart) receiver); } } return result; } }
private void activateShowHideModeUsingTabbar() { SWTBotGefEditPart swtBotEditPart = getEditPart("new EClass 4", DNodeNameEditPart.class); hideShow(element, swtBotEditPart, true); } private void hideShow(DDiagramElement element, SWTBotGefEditPart swtBotEditPart, boolean isLabelHidden) { int count = 1; if (!isLabelHidden) { count = 3; } for (int i = 1; i <= count; i++) { editor.reveal(swtBotEditPart.part()); OperationDoneCondition done = new OperationDoneCondition(); performHideReveal(swtBotEditPart, i, "Hide element"); bot.waitUntil(done); SWTBotUtils.waitAllUiEvents(); if (isLabelHidden) { // perform additional actions if the label is hidden } } }
bot.waitUntil(done); SWTBotUtils.waitAllUiEvents(); if (isLabelHidden) { assertFalse(element.getGraphicalFilters().stream().anyMatch(HideLabelFilter.class::isInstance)); } else { assertFalse(element.getGraphicalFilters().stream().anyMatch(HideFilter.class::isInstance)); } } private void performHideReveal(SWTBotGefEditPart swtBotEditPart, int i, String toolTip) { switch (i) { case 0: swtBotEditPart.doubleClick(); break; case 1: swtBotEditPart.contextMenu(toolTip).click(); break; case 2: swtBotEditPart.tabbarAction(toolTip).click(); break; } }
String pattern = IValueFormatConstants.DEFAULT_DATE_PATTERN; String input = "2019-01-18T12:42:03.409Z"; ScoutAssert.assertThrows(ParseException.class, () -> new SimpleDateFormat(pattern).parse(input)); ScoutAssert.assertThrows(ParseException.class, () -> new StrictSimpleDateFormat(pattern).parse(input)); pattern = IValueFormatConstants.TIMESTAMP_PATTERN; ScoutAssert.assertThrows(ParseException.class, () -> new SimpleDateFormat(pattern).parse(input)); ScoutAssert.assertThrows(ParseException.class, () -> new StrictSimpleDateFormat(pattern).parse(input));
package org.eclipse.jgit.lib; import static java.util.stream.Collectors.toList; import java.io.IOException; import java.util.ArrayList; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Set; import java.util.stream.Collectors; import org.eclipse.jgit.annotations.NonNull; import org.eclipse.jgit.annotations.Nullable; /** * Abstraction of name to {@link org.eclipse.jgit.lib.ObjectId} mapping. * <p> * A reference database stores a mapping of reference names to * {@link org.eclipse.jgit.lib.ObjectId}. Every * {@link org.eclipse.jgit.lib.Repository} has a single reference database, * mapping names to the tips of the object graph contained by the repository. * * @since 3.0 */ public abstract class RefDatabase { private static final String REFS = "refs"; private static final String HEAD = "HEAD"; private static final String TAGS = "tags"; private static final String REMOTES = "remotes"; private static final String REFS_TAGS = REFS + '/' + TAGS; private static final String REFS_REMOTES = REFS + '/' + REMOTES; private static final String REFS_HEADS = REFS + '/' + "heads"; private static final String REFS_REMOTES_PREFIX = REFS_REMOTES + '/'; private static final String REFS_TAGS_PREFIX = REFS_TAGS + '/'; private static final String REFS_HEADS_PREFIX = REFS_HEADS + '/'; private static final String REFS_HEAD = REFS + '/' + HEAD; private static final String REFS_HEAD_MASTER = REFS_HEADS_PREFIX + "master"; private static final String REFS_HEAD_DETACHED = REFS_HEADS + "/detached"; private static final String REFS_HEAD_DETACHED_PREFIX = REFS_HEAD_DETACHED + '/'; private static final String REFS_HEADS_MASTER = REFS_HEADS_PREFIX + "master"; private static final String REFS_HEADS_PREFIX_SHORT = "refs/heads/"; private static final String REFS_REMOTES_PREFIX_SHORT = "refs/remotes/"; private static final String REFS_TAGS_PREFIX_SHORT = "refs/tags/"; private static final String REFS_HEAD_MASTER_SHORT = "refs/heads/master"; private static final String REFS_HEAD_DETACHED_SHORT = "refs/heads
import java.io.IOException; import java.util.ArrayList; import java.util.Collections; import java.util.List; import org.eclipse.jgit.annotations.NonNull; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; /** * This class provides methods to retrieve references from a reference space. * * @since 5.2 */ @NonNull public class RefUtils { /** * Returns a list of references that have the given prefixes. * * @param prefixes the prefixes to match * @return a list of matching references * @throws IOException if the reference space cannot be accessed */ public List<Ref> getRefsByPrefix(String... prefixes) throws IOException { List<Ref> result = new ArrayList<>(); for (String prefix : prefixes) { result.addAll(getRefsByPrefix(prefix)); } return Collections.unmodifiableList(result); } /** * Returns all references that resolve directly to the given {@link ObjectId}. * Includes peeled {@link ObjectId}s. This is the inverse lookup of * {@link #exactRef(String...)}. * * <p> * The default implementation uses a linear scan. Implementors of {@link RefDatabase} should * override this method directly if a better implementation is possible. * * @param id the {@link ObjectId} to resolve * @return a {@link List} of {@link Ref}s whose tip points to the provided id * @throws IOException if the reference space cannot be accessed */ public List<Ref> getRefsByObjectId(ObjectId id) throws IOException { List<Ref> result = new ArrayList<>(); // Implementation goes here return Collections.unmodifiableList(result); } }
* Includes peeled {@link ObjectId}s. This is the inverse lookup if {@link #exactRef(String...)}. * The default implementation uses a linear scan. Implementors of {@link RefDatabase} should override this method directly if a better implementation is possible. * @param id {@link ObjectId} to resolve * @return a {@link Set} of {@link Ref}s whose tip points to the provided id. * @throws java.io.IOException the reference space cannot be accessed. * @since 5.3 */ @NonNull public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { return getRefs().stream() .filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())) .collect(Collectors.toSet()); } /** * Check if any refs exist in the ref database. * @return true if any refs exist, false otherwise. * @throws java.io.IOException the reference space cannot be accessed. */ public boolean hasRefs() throws IOException { return !getRefs().isEmpty(); }
import static java.util.stream.Collectors.toSet; ... /** * @return a {@link Set} of {@link Ref}s whose tip points to the provided * id. * @throws java.io.IOException * the reference space cannot be accessed. * @since 5.3 */ @NonNull public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { return getRefs().stream() .filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())) .collect(toSet()); } /** * Check if any refs exist in the ref database. * <p> * This uses the same definition of refs as {@link #getRefs()}. In * particular, returns {@code false} in a new repository with no refs * under {@code refs/} and {@code HEAD} pointing to a branch yet to be * born, and returns {@code true} in a repository with no refs under * {@code refs/} and a detached {@code HEAD} pointing to history. */
package org.eclipse.tracecompass.analysis.os.linux.core.inputoutput; import org.eclipse.jdt.annotation.Nullable; import org.eclipse.osgi.util.NLS; /** * Externalized message strings from the I/O Analysis * * @author Houssem Daoud */ public class Messages extends NLS { private static final String BUNDLE_NAME = "org.eclipse.linuxtools.lttng2.kernel.core.inputoutput.analysis.messages"; //$NON-NLS-1$ /** Help text for the Data provider */ public static @Nullable String DisksIODataProviderFactory_helpText; /** Help text for the IO analysis */ public static @Nullable String LttngInputOutputModule_Help; static { // initialize resource bundle NLS.initializeMessages(BUNDLE_NAME, Messages.class); } private Messages() { } }
import org.eclipse.osgi.util.NLS; /** * Externalized Strings for the ThreadStatusDataProvider package */ class Messages extends NLS { private static final String BUNDLE_NAME = "org.eclipse.tracecompass.internal.analysis.os.linux.core.threadstatus.messages"; //$NON-NLS-1$ /** attribute cpu name */ public static String ThreadStatusDataProvider_attributeCpuName; /** */ public static String ThreadStatusDataProviderFactory_title; /** DataProvider help text */ public static String ThreadStatusDataProviderFactory_descriptionText; static { // initialize resource bundle NLS.initializeMessages(BUNDLE_NAME, Messages.class); } private Messages() { } }
List<IDataProviderDescriptor> descriptors = new ArrayList<>(); Set<String> existingModules = new HashSet<>(); for (ISegmentStoreProvider module : modules) { IAnalysisModule analysis = (IAnalysisModule) module; if (!existingModules.contains(analysis.getId())) { DataProviderDescriptor.Builder builder = new DataProviderDescriptor.Builder(); builder.setId(encode(SegmentStoreScatterDataProvider.ID + ':' + analysis.getId())) .setName(Objects.requireNonNull(NLS.bind(Messages.SegmentStoreScatterGraphDataProvider_title, analysis.getName()))) .setDescription(Objects.requireNonNull(NLS.bind(Messages.SegmentStoreScatterGraphDataProvider_description, analysis.getName()))) .setProviderType(ProviderType.TREE_TIME_XY); descriptors.add(builder.build()); } } return descriptors;
private static void waitForShadowProjectUpdated(String parentProjectName) { for (int i = 1; i < 5000 && (TmfProjectModelHelper.getShadowProject(parentProjectName).exists()); i *= 2) { delay(i); } } public String getTypeName() { return "Insertion Feature"; } /* * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the * License for the specific language governing permissions and limitations under * the License. */ package com.google.gerrit.client; import com.google.gwt.core.client.EntryPoint; /** * Base class for writing Gerrit Web UI plugins * * Writing a plugin: * <ol> * <li>Declare subtype of Plugin</li> * <li>Bind WebUiPlugin.class to GwtWebUiPlugin implementation in Gerrit-Module class</li> * </ol> */ public abstract class Plugin implements EntryPoint { @Override public final void onModuleLoad() { // not used } /** * Initialize plugin */ protected abstract void init(); } return Status.OK_STATUS; public File getPath() { return path; } public boolean isDirty() { return false; } public InputStream read(String item, IProgressMonitor monitor) throws IOException { File file = getFile(item); return new FileInputStream(file); } public void release() { store.release(this); } public OutputStream write(String item, IProgressMonitor monitor) throws IOException { File file = getFile(item); return new BufferedOutputStream(new FileOutputStream(file)); } private File getFile(String item) { File file = new File(path, item); if (!file.getParentFile().exists()) { file.getParentFile().mkdirs(); } return file; }
package org.apache.hyracks.algebricks.core.algebra.operators.logical; import java.util.ArrayList; import java.util.List; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalOperator; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalPlan; import org.apache.hyracks.algebricks.core.algebra.base.LogicalVariable; public abstract class AbstractOperatorWithNestedPlans extends AbstractLogicalOperator { protected final List<ILogicalPlan> nestedPlans; public AbstractOperatorWithNestedPlans() { nestedPlans = new ArrayList<ILogicalPlan>(); } public AbstractOperatorWithNestedPlans(List<ILogicalPlan> nestedPlans) { this.nestedPlans = nestedPlans; } public List<ILogicalPlan> getNestedPlans() { return nestedPlans; } @Override public boolean hasNestedPlans() { return true; } } private List<AddressRangePosition> getAddressRangePositions(String category) { List<Position> list = getDocumentManagedPositions().get(category); @SuppressWarnings({ "unchecked", "cast", "rawtypes" }) private List<AddressRangePosition> getAddressRangePositions(String category) { List<Position> list = getDocumentManagedPositions().get(category); @SuppressWarnings({ "unchecked", "cast", "rawtypes" }) List<AddressRangePosition> addressRangePositions = (List<AddressRangePosition>) (List<?>) list; return addressRangePositions; } } import java.util.ArrayList; import java.util.List; import org.apache.commons.lang3.mutable.Mutable; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalOperator; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalPlan; import org.apache.hyracks.algebricks.core.algebra.base.LogicalVariable; public abstract class AbstractOperatorWithNestedPlans extends AbstractLogicalOperator { protected final List<ILogicalPlan> nestedPlans; public AbstractOperatorWithNestedPlans() { nestedPlans = new ArrayList<ILogicalPlan>(); } public AbstractOperatorWithNestedPlans(List<ILogicalPlan> nestedPlans) { this.nestedPlans = nestedPlans; } public List<ILogicalPlan> getNestedPlans() { return nestedPlans; } @Override public boolean has
if (!destinationFile.exists()) { destinationFile.mkdirs(); } while (entries.hasMoreElements()) { ZipEntry entry = entries.nextElement(); File outputFile = new File(destinationFile, entry.getName()); if (entry.isDirectory() && !outputFile.exists()) { outputFile.mkdirs(); continue; } if (!outputFile.getParentFile().exists()) { outputFile.getParentFile().mkdirs(); } try (InputStream inputStream = new BufferedInputStream(zipFile.getInputStream(entry)); OutputStream outStream = new BufferedOutputStream(new FileOutputStream(outputFile))) { copyStream(inputStream, outStream); } outputFiles.add(outputFile); if (monitor != null) { monitor.worked(1); } } return outputFiles; } private static void copyStream(InputStream in, OutputStream out) throws IOException { Assert.isNotNull(in); Assert.isNotNull(out); byte[] buffer = new byte[4096]; int readCount; while ((readCount = in.read(buffer)) != -1) { out.write(buffer, 0, readCount); } }
private final CommonStore store; public CommonStorable(CommonStore store, File path) { this.store = store; this.path = path; } public void delete(String item) throws CoreException { getFile(item).delete(); } public void deleteAll() throws CoreException { File[] children = path.listFiles(); if (children != null) { // validate for (File child : children) { if (child.isDirectory()) { throw new CoreException(new Status(IStatus.ERROR, CommonsCorePlugin.ID_PLUGIN, NLS.bind("The storage location ''{0}'' contains sub directories", path))); //$NON-NLS-1$ } } // delete all files for (File child : children) { child.delete(); } } if (path.exists()) { path.delete(); } } public boolean exists(String handle) { if (!path.exists()) { return false; } return getFile(handle).exists(); } public IStatus flush() { return Status.OK_STATUS; }
public static void createZipFile(File zipFile, List<File> files, String rootPath, IProgressMonitor monitor) throws FileNotFoundException, IOException { if (rootPath == null) { rootPath = ""; } else if (!rootPath.endsWith("\\") || !rootPath.endsWith("/")) { rootPath += "/"; } try (ZipOutputStream zipOut = new ZipOutputStream(new BufferedOutputStream(new FileOutputStream(zipFile)))) { for (File file : files) { try { addZipEntry(zipOut, rootPath, file); if (monitor != null) { monitor.worked(1); } } catch (Exception e) { StatusHandler.log(new Status(IStatus.ERROR, ICommonsCoreConstants.ID_PLUGIN, "Could not add " + file.getName() + " to zip", e)); } } } }
public static String changeSeparator(String path, char oldSeparator, char newSeparator) { return path.replace(oldSeparator, newSeparator); } public static void copy(File source, File dest) throws IOException { try (InputStream in = new FileInputStream(source); OutputStream out = new BufferedOutputStream(new FileOutputStream(dest))) { transferData(in, out); } } public static void copyFolder(File sourceFolder, File targetFolder) throws IOException { for (File currFile : sourceFolder.listFiles()) { if (currFile.isFile()) { File destFile = new File(targetFolder, currFile.getName()); copy(currFile, destFile); } } }
package org.eclipse.mylyn.monitor.core; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; import org.eclipse.core.runtime.IStatus; import org.eclipse.core.runtime.Status; import org.eclipse.mylyn.commons.core.StatusHandler; import org.eclipse.mylyn.internal.monitor.core.IMonitorCoreConstants; /** * Used for logging interaction events. * * @author Mik Kersten * @since 2.0 */ public abstract class AbstractMonitorLog { protected File outputFile; protected FileOutputStream outputStream; protected boolean started = false; public AbstractMonitorLog() { super(); } public void startMonitoring() { synchronized (this) { if (started) { return; } else { started = true; } } try { if (!outputFile.exists()) { outputFile.createNewFile(); } outputStream = new FileOutputStream(outputFile, true); } catch (Exception e) { StatusHandler.log(new Status(IStatus.ERROR, IMonitorCoreConstants.ID_PLUGIN, "Failed to start monitoring", e)); } } }
public void dispose() { fExpressionHistory.dispose(); fLocalExpressionHistory.clear(); if (fDocumentListener != null && getSourceViewer() != null && getSourceViewer().getDocument() != null) { getSourceViewer().getDocument().removeDocumentListener(fDocumentListener); } fListeners.clear(); super.dispose(); }
DNode element = (DNode) ((Node) part.getModel()).getElement(); assertFalse("The node should not have its label filtered.", element.getGraphicalFilters().stream().anyMatch(HideLabelFilter.class::isInstance)); activateShowHideModeUsingTabbar(); SWTBotGefEditPart swtBotEditPart = getEditPart("new EClass 4", DNodeNameEditPart.class); hideShow(element, swtBotEditPart, true); private void hideShow(DDiagramElement element, SWTBotGefEditPart swtBotEditPart, boolean isLabelHidden) { int count = 0; if (!isLabelHidden) { count = 2; } }
Diagram data = (Diagram) annotationEntry.getData(); Optional<?> missingNode = data.getChildren().stream().filter(child -> "_Sx9-MCLeEemN0s24dvRntQ".equals(((IdentifiedElement) ((Node) child).getElement()).getUid())).findFirst(); assertFalse("GMF cleaning has not been done while refreshing representation.", missingNode.isPresent()); @Override protected void tearDown() throws Exception { /* Delete the temporary project */ super.tearDown(); }
package org.eclipse.osee.framework.jdk.core.type; import java.util.ArrayList; import java.util.Collection; import java.util.List; public class TreeNode<TreeType> { private TreeType myself; private TreeNode<TreeType> parent; private List<TreeNode<TreeType>> children; protected TreeNode(TreeNode<TreeType> parent, TreeType myself) { this.parent = parent; this.myself = myself; this.children = new ArrayList<>(); } public TreeNode(TreeType myself) { this(null, myself); } @SuppressWarnings("null") public TreeNode() { this(null); } public TreeNode<TreeType> getParent() { return parent; } public TreeType getSelf() { return myself; } public List<TreeNode<TreeType>> getChildren() { return children; } }
import java.util.List; import java.util.Objects; import java.util.function.Function; import java.util.function.Predicate; import org.eclipse.tracecompass.internal.tmf.analysis.xml.core.fsm.model.values.DataDrivenValue; import org.eclipse.tracecompass.internal.tmf.analysis.xml.core.fsm.module.IAnalysisDataContainer; import org.eclipse.tracecompass.statesystem.core.ITmfStateSystem; import org.eclipse.tracecompass.tmf.core.event.ITmfEvent; public interface DataDrivenCondition extends IDataDrivenRuntimeObject { /** * Condition operators used to compare 2 values together */ public enum ConditionOperator implements Predicate<Integer> { /** equal */ EQ(i -> i == 0), /** not equal */ NE(i -> i != 0), /** Greater or equal */ GE(i -> i >= 0), /** Greater than */ GT(i -> i > 0), /** Less or equal */ LE(i -> i <= 0), /** Less than */ LT(i -> i < 0); } }
private static String[] getProtocolsToKeep(final String[] enabledProtocols) { final List<String> remainingProtocols = new ArrayList<String>(); for (final String protocol : enabledProtocols) { if (protocol.equals(SSLV3) || protocol.equals(SSLV2_HELLO)) { continue; } remainingProtocols.add(protocol); } if (remainingProtocols.isEmpty()) { throw new IllegalStateException("No other protocol allowed"); } return remainingProtocols.toArray(new String[remainingProtocols.size()]); }
final SSLContext context = SSLContext.getInstance("TLS"); //$NON-NLS-1$ context.init(ServerKeyStoreManager.getInstance().getKeyManagerFactory().getKeyManagers(), null, null); serverSocketFactory = context.getServerSocketFactory(); } catch (final NoSuchAlgorithmException exception) { shutdown(serverSocketFactory, exception); } catch (final KeyManagementException exception) { shutdown(serverSocketFactory, exception); } catch (final ServerKeyStoreException exception) { shutdown(serverSocketFactory, exception); } return disableSSLv3AndReturn(serverSocketFactory.createServerSocket(pPort, backlog, addr)); private void shutdown(SSLServerSocketFactory serverSocketFactory, Exception e) { if (serverSocketFactory == null) { ModelUtil.logException(Messages.XmlRpcBuiltinWebServer_ServerSocketInitFailed, e); EMFStoreController.getInstance().shutdown(new FatalESException()); } }
private static final String TAG_SELECTION = "selection"; //$NON-NLS-1$ private static final String TAG_EXPANDED = "expanded"; //$NON-NLS-1$ private static final String TAG_ELEMENT = "element"; //$NON-NLS-1$ private static final String TAG_IS_ENABLED = "isEnabled"; //$NON-NLS-1$ private static final String TAG_PATH = "path"; //$NON-NLS-1$ private static final String TAG_CURRENT_FRAME = "currentFrame"; //$NON-NLS-1$ private EmptyWorkspaceHelper emptyWorkspaceHelper; private IPartListener partListener = new IPartListener() { @Override public void partActivated(IWorkbenchPart part) { if (part instanceof IEditorPart) { editorActivated((IEditorPart) part); } } @Override public void partBroughtToTop(IWorkbenchPart part) { if (part instanceof IEditorPart) { editorActivated((IEditorPart) part); } } @Override public void partClosed(IWorkbenchPart part) { } @Override public void partDeactivated(IWorkbenchPart part) { } @Override public void partOpened(IWorkbenchPart part) { } };
private static final String MEMENTO_REGEXP_FILTER_REGEXP_ATTRIBUTE = "regexp"; private static final String MEMENTO_REGEXP_FILTER_ENABLED_ATTRIBUTE = "enabled"; private int rootMode; private String workingSetLabel; private List<UserFilter> userFilters; private EmptyWorkspaceHelper emptyWorkspaceHelper; @Override public void init(IViewSite site, IMemento memento) throws PartInitException { super.init(site, memento); userFilters = new ArrayList<UserFilter>(); if (memento != null) { IMemento[] filters = memento.getChildren(MEMENTO_REGEXP_FILTER_ELEMENT); for (IMemento filterMemento : filters) { String regexp = filterMemento.getString(MEMENTO_REGEXP_FILTER_REGEXP_ATTRIBUTE); Boolean enabled = filterMemento.getBoolean(MEMENTO_REGEXP_FILTER_ENABLED_ATTRIBUTE); userFilters.add(new UserFilter(regexp, enabled)); } } } @Override public void saveState(IMemento aMemento) { // Code for saving state }
public void createPartControl(Composite aParent) { emptyWorkspaceHelper = new EmptyWorkspaceHelper(aParent); super.createPartControl(aParent); getCommonViewer().setMapper(new ResourceToItemsMapper(getCommonViewer())); getCommonViewer().setData(NavigatorPlugin.RESOURCE_REGEXP_FILTER_DATA, this.userFilters); if (this.userFilters.stream().anyMatch(UserFilter::isEnabled)) { getCommonViewer().refresh(); } }
private final Map<EPackage, String> packageToInferedSource = new LinkedHashMap<EPackage, String>(); private final Map<EPackage, Text> packageToSourceText = new LinkedHashMap<EPackage, Text>(); private final Map<EPackage, Text> packageToTargetText = new LinkedHashMap<EPackage, Text>(); private final Map<EPackage, Button> packageToUpdateButton = new LinkedHashMap<EPackage, Button>(); private final Pattern VERSION_NUMBER_PATTERN = Pattern.compile("(?<=\\bv?|[-_])\\d+\\b"); private final List<EPackage> packages; private final Set<EPackage> changedPackages; protected ReleaseWizardPage(String pageName, String description, ImageDescriptor titleImage, List<EPackage> packages, Set<EPackage> changedPackages) { super(pageName, pageName, titleImage); setDescription(description); this.packages = packages; }
IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { PlatformUI.getWorkbench().getDisplay().asyncExec(() -> { Display.getDefault().timerExec(200, switchTopControlRunnable); }); return; } } }
public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions = null; private IAction newProjectAction = null; public EmptyWorkspaceHelper(Composite parent) { // code implementation } }
public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions = null; private IAction newProjectAction = null; public EmptyWorkspaceHelper(Composite parent) { displayArea = parent; layout = new StackLayout(); displayArea.setLayout(layout); createEmptyArea(displayArea); } // Rest of the code... }
public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions; private IAction newProjectAction; public EmptyWorkspaceHelper(Composite parent) { displayArea = parent; layout = new StackLayout(); displayArea.setLayout(layout); createEmptyArea(displayArea); registerListeners(); } // ... }
public void setNonEmptyControl(Control control) { this.control = control; emptyArea.setBackground(control.getBackground()); switchTopControl(); }
public void dispose() { parentControl.addDisposeListener(e -> { PlatformUI.getWorkbench().getActiveWorkbenchWindow().removePerspectiveListener(this); ResourcesPlugin.getWorkspace().removeResourceChangeListener(this); JFaceResources.getColorRegistry().removeListener(this); }); }
private void readProjectWizardActions() { IWorkbench wb = PlatformUI.getWorkbench(); IWorkbenchWindow win = wb.getActiveWorkbenchWindow(); IWorkbenchPage page = win.getActivePage(); String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { IWizardDescriptor wizardDesc = WorkbenchPlugin.getDefault().getNewWizardRegistry().findWizard(wizardId); if (wizardDesc == null) { continue; } String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(WorkbenchPlugin.getDefault().getNewWizardRegistry(), wizardId); projectWizardActions.add(action); } } } }
private void readProjectWizardActions() { IWorkbench wb = PlatformUI.getWorkbench(); IWorkbenchWindow win = wb.getActiveWorkbenchWindow(); IWorkbenchPage page = win.getActivePage(); String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { IWizardDescriptor wizardDesc = WorkbenchPlugin.getDefault().getNewWizardRegistry().findWizard(wizardId); if (wizardDesc == null) { continue; } String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(WorkbenchPlugin.getDefault().getNewWizardRegistry(), wizardId); projectWizardActions.add(action); } } } }
private boolean switchTopControl() { Control oldTop = layout.topControl; IProject[] projs = ResourcesPlugin.getWorkspace().getRoot().getProjects(); if (projs.length > 0) { if (!control.isDisposed()) { layout.topControl = control; } } else { layout.topControl = emptyArea; } return oldTop != layout.topControl; }
public void resourceChanged(IResourceChangeEvent event) { IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { Display.getDefault().asyncExec(() -> { Display.getDefault().timerExec(200, switchTopControlRunnable); return; }); } } } }
public void propertyChange(PropertyChangeEvent event) { if (JFacePreferences.HYPERLINK_COLOR.equals(event.getProperty())) { recreateEmptyArea(); } }
private Button createChangeAction() { final Button createChange = new Button("Create change"); createChange.setTitle("Create change directly in browser"); createChange.addClickHandler(new ClickHandler() { @Override public void onClick(ClickEvent event) { CreateChangeAction.call(createChange, getProjectKey().toString()); } }); return createChange; } public void reserveExact(int additional) { Preconditions.checkArgument(additional >= 0, "negative additional"); if (data.length - len >= additional) return; data = Arrays.copyOf(data, len + additional); } public Version(String version) { String[] parts = version.split("\\."); major = Integer.valueOf(parts[0]); if (parts[1] != null) { this.minor = Integer.valueOf(parts[1]); } if (parts[2] != null) { this.micro = Integer.valueOf(parts[2]); } } IWorkingSetManager workingSetManager = getPlugin().getWorkbench().getWorkingSetManager(); workingSetManager.removePropertyChangeListener(propertyChangeListener); if (collapseAllHandler != null) { collapseAllHandler.dispose(); } if (getActionGroup() != null) { getActionGroup().dispose(); } Control control = viewer.getControl(); if (dragDetectListener != null && control != null && control.isDisposed() == false) { control.removeListener(SWT.DragDetect, dragDetectListener); } emptyWorkspaceHelper.dispose(); super.dispose();
public final class EmptyWorkspaceHelper { /** * This class uses a stack layout to switch between the "original" composite of * the view and an additional composite given the user the explanatory text. * This text is displayed when no projects are in the workspace. Once projects * are created this class switches back to the "original" composite of the view. * * The explanatory text explains the current situation that no projects are * available and provides a list of options to create projects. This list * contains links to: * 1. Project creation wizards specific to the current perspective * 2. The "New Project Wizard" to allow creation of project of any type * * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown. * * This class also takes care of refreshing these links when the user switches * the perspective. */ }
private void dispose(Listener listener) { PlatformUI.getWorkbench().getActiveWorkbenchWindow().removePerspectiveListener(listener); ResourcesPlugin.getWorkspace().removeResourceChangeListener(listener); JFaceResources.getColorRegistry().removeListener(listener); parent.removeDisposeListener(listener); parent = null; }
String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { IWizardRegistry newWizardRegistry = WorkbenchPlugin.getDefault().getNewWizardRegistry(); IWizardDescriptor wizardDesc = newWizardRegistry.findWizard(wizardId); if (wizardDesc != null) { String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(newWizardRegistry, wizardId); projectWizardActions.add(action); } } } }
public void resourceChanged(IResourceChangeEvent event) { IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { PlatformUI.getWorkbench().getDisplay().asyncExec(() -> PlatformUI.getWorkbench().getDisplay().timerExec(200, switchTopControlRunnable)); return; } } } }
package org.eclipse.emfforms.spi.common.sort; import java.math.BigInteger; import java.util.Comparator; import java.util.regex.Matcher; import java.util.regex.Pattern; /** * A comparator for strings that compares numbers which are part of compared string as numbers and not as strings. * This allows string that are a mixture of numbers and text (e.g. house numbers) in an intuitive fashion. * For instance, plain string sorting sorts 200A greater than 1000A. This comparator sorts 1000A greater than 200A. * * @author Lucas Koehler * @since 1.20 */ public final class NumberAwareStringComparator implements Comparator<String> { private static final Pattern PATTERN = Pattern.compile("(\\D*)(\\d*)"); //$NON-NLS-1$ private static NumberAwareStringComparator instance; /** * @return the static {@link NumberAwareStringComparator} instance. */ }
private Action fOpenManifestAction; private Action fOpenSchemaAction; private Action fOpenSystemEditorAction; private Action fOpenClassFileAction; private Action fOpenTextEditorAction; private Action fSelectDependentAction; private Action fSelectInJavaSearchAction; private Action fSelectAllAction; private PDERefactoringAction fRefactorAction; private CollapseAllAction fCollapseAllAction; private DisabledFilter fHideExtEnabledFilter = new DisabledFilter(true); private DisabledFilter fHideExtDisabledFilter = new DisabledFilter(false); private WorkspaceFilter fHideWorkspaceFilter = new WorkspaceFilter(); private JavaFilter fJavaFilter = new JavaFilter(); private CopyToClipboardAction fCopyAction; private Clipboard fClipboard; private Object fRoot = null; class DisabledFilter extends ViewerFilter { boolean fEnabled; DisabledFilter(boolean enabled) { fEnabled = enabled; } @Override public boolean select(Viewer v, Object parent, Object element) { if (element instanceof IPluginModelBase) { IPluginModelBase model = (IPluginModelBase) element; return model.getUnderlyingResource() != null || model.isEnabled() != fEnabled; } return true; } }
boolean hideDisabledExternal = !settings.getBoolean(SHOW_EXDISABLED); if (hideWorkspace) { fTreeViewer.addFilter(fHideWorkspaceFilter); } if (hideEnabledExternal) { fTreeViewer.addFilter(fHideExtEnabledFilter); } if (hideDisabledExternal) { fTreeViewer.addFilter(fHideExtDisabledFilter); } fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); Job.createSystem("", monitor -> { PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> { fSourcePluginFilter = new SourcePluginFilter(state); fTreeViewer.addFilter(fSourcePluginFilter); }); } }).schedule();
boolean hideEnabledExternal = settings.getBoolean(HIDE_EXENABLED); boolean hideDisabledExternal = !settings.getBoolean(SHOW_EXDISABLED); if (hideWorkspace) { fTreeViewer.addFilter(fHideWorkspaceFilter); } if (hideEnabledExternal) { fTreeViewer.addFilter(fHideExtEnabledFilter); } if (hideDisabledExternal) { fTreeViewer.addFilter(fHideExtDisabledFilter); } fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); if (PDECore.getDefault().getModelManager().isInitialized()) { PDEState state = PDECore.getDefault().getModelManager().getState(); fSourcePluginFilter = new SourcePluginFilter(state); } else { Job.createSystem("", monitor -> { PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> { fSourcePluginFilter = new SourcePluginFilter(state); }); } }).schedule(); }
private long size = 0; private Path tmpFile; public CleanFilter(Repository db, InputStream in, OutputStream out) throws IOException { super(in, out); lfsUtil = new LfsUtil(db.getDirectory().toPath().resolve("lfs")); Files.createDirectories(lfsUtil.getLfsTmpDir()); tmpFile = lfsUtil.createTmpFile(); this.out = out; } return rule; private final Map<Project.NameKey, ProjectState> all; private final ProjectCache projectCache; private final CapabilityControl.Factory capabilityControlFactory; private final ChangeControl.AssistedFactory changeControlFactory; private final PermissionCollection.Factory sectionSorter; private final InMemoryRepositoryManager repoManager; private final GroupControl.Factory controlFactory; private final GroupJson json; private final Provider<ListIncludedGroups> listIncludes; private final AllProjectsName allProjectsName = new AllProjectsName("All-Projects"); private final ProjectConfig allProjects; @SuppressWarnings("unchecked") public Util() { all = new HashMap<>(); repoManager = new InMemoryRepositoryManager(); try { Repository repo = repoManager.createRepository(allProjectsName); allProjects = new ProjectConfig(new Project.NameKey(allProjectsName.get())); allProjects.load(repo); allProjects.getLabelSections().put(CR.getName(), CR); add(allProjects); } catch (IOException | ConfigInvalidException e) { throw new RuntimeException(e); } projectCache = new ProjectCache() { @Override protected ProjectState get(Project.NameKey projectName) { return all.get(projectName); } }; } public ProjectTagsScreen(Project.NameKey toShow) { super(toShow); } fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); if (PDECore.getDefault().getModelManager().isInitialized()) { PDEState state = PDECore.getDefault().getModelManager().getState(); fSourcePluginFilter = new SourcePluginFilter(state); } else { Job.createSystem("", monitor -> { PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> { fSourcePluginFilter = new SourcePluginFilter(state); fTreeViewer.addFilter(fSourcePluginFilter); });
IContainer parent = tpdFile.getParent(); String fileName = tpdFile.getFullPath().removeFileExtension().addFileExtension("target").lastSegment(); IFile portableTargetFile = parent.getFile(new Path(fileName)); IFolder eclipseFolder = parent.getParent().getFolder(new Path(targetSuffix)); if (!eclipseFolder.exists()) { eclipseFolder.create(true, true, new NullProgressMonitor()); } IFile eclipseTargetFile = eclipseFolder.getFile(fileName.replaceAll("portable", targetSuffix)); InputStream convertedStream = convert(portableTargetFile.getContents(), "http://download.eclipse.org/", "file:/home/data/httpd/download.eclipse.org/"); convertedStream = convert(convertedStream, "https://download.eclipse.org/", "file:/home/data/httpd/download.eclipse.org/"); if (eclipseTargetFile.exists()) { eclipseTargetFile.setContents(convertedStream, IResource.NONE, null); } else { eclipseTargetFile.create(convertedStream, true, null); }
/** * Resolves the tip SHA1 of an ObjectId in the RefDatabase. * * @param id The ObjectId to resolve * @return A Set of Refs whose tips point to the provided id * @throws IOException If the reference space cannot be accessed * @since 5.3 */ @NonNull public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { return getRefs().stream() .filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())) .collect(toSet()); } /** * Checks if any refs exist in the ref database. * * This uses the same definition of refs as getRefs(). In particular, it returns false in a new repository with no refs under refs/ and HEAD pointing to a branch yet to be created. * * @return True if any refs exist, false otherwise * @throws IOException If the reference space cannot be accessed */ public boolean hasRefs() throws IOException { return !getRefs().isEmpty(); }
protected IStatus run(IProgressMonitor monitor) { Diagnostic result = converter.generateTargetDefinitionFile(tpdURI, new NullProgressMonitor()); if (result.getSeverity() >= Diagnostic.WARNING) { Activator.getDefault().getLog().log(BasicDiagnostic.toIStatus(result)); } try { file.getParent().refreshLocal(IResource.DEPTH_ONE, null); generateEclipseTarget(file); } catch (CoreException ex) { return new Status(IStatus.ERROR, Activator.PLUGIN_ID, "Unexpected exception", ex);//$NON-NLS-1$ } return BasicDiagnostic.toIStatus(result); }
public final class WidgetFactory { private WidgetFactory() { } public static ButtonFactory button(int style) { return ButtonFactory.newButton(style); } public static TextFactory text(int style) { return TextFactory.newText(style); } public static LabelFactory label(int style) { return LabelFactory.newLabel(style); } }
public void testUniqueLayoutData() { GridDataFactory gridDataFactory = GridDataFactory.fillDefaults().grab(true, false); TestFactory factory = TestFactory.newTest().layoutData(gridDataFactory::create); Label label = factory.create(shell); Label label2 = factory.create(shell); assertNotEquals(label.getLayoutData(), label2.getLayoutData()); }
public void testUniqueLayoutData() { GridDataFactory gridDataFactory = GridDataFactory.fillDefaults().grab(true, false); TestFactory factory = TestFactory.newTest().tooltip("toolTip").enabled(false).layoutData(gridDataFactory::create); Label label = factory.create(shell); Label label2 = factory.create(shell); assertNotSame(label.getLayoutData(), label2.getLayoutData()); }
indent.addSelectionListener(widgetSelectedAdapter(event -> { Spinner spinner = (Spinner) event.widget; styledText.setIndent(spinner.getSelection()); })); label = new Label(composite, SWT.NONE); label.setText(getResourceString("Spacing")); //$NON-NLS-1$ Spinner spacing = new Spinner(composite, SWT.BORDER); spacing.addSelectionListener(widgetSelectedAdapter(event -> { Spinner spinner = (Spinner) event.widget; styledText.setLineSpacing(spinner.getSelection()); })); // Button to Enable Mouse Navigator in StyledText Button enableMouseNavigator = new Button(composite, SWT.CHECK); enableMouseNavigator.setText(getResourceString("MouseNav")); enableMouseNavigator.addSelectionListener(widgetSelectedAdapter(event -> styledText.setMouseNavigatorEnabled(enableMouseNavigator.getSelection()))); coolItem = new CoolItem(coolBar, SWT.NONE); coolItem.setControl(composite); CoolItem[] coolItems = coolBar.getItems(); for (CoolItem item : coolItems) { Control control = item.getControl(); Point size = control.computeSize(SWT.DEFAULT, SWT.DEFAULT); item.setMinimumSize(size); }
private static String internalGetString(String key) { try { return RESOURCE_BUNDLE.getString(key); } catch (MissingResourceException e) { return '!' + key + '!'; } }
public String toString() { if (eObject == null) { return "<null>-" + side; } return eObject.eClass().getName() + '-' + side.getName(); }
public String toString() { return super.toString() + '-' + side.getName(); }
shortMessage += "..."; //$NON-NLS-1$ } // Get the author String author = null; if (lastCommit.getFullMessage().contains(Constants.SIGNED_OFF_BY_TAG)) { try { final String subSignedOff = lastCommit.getFullMessage().substring(lastCommit.getFullMessage().indexOf(Constants.SIGNED_OFF_BY_TAG) + Constants.SIGNED_OFF_BY_TAG.length()); author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; } catch (Exception e) { // Do nothing } } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } if (!shortMessage.isEmpty() && !author.isEmpty()) { constructName.append("("); //$NON-NLS-1$ if (!shortMessage.isEmpty()) { constructName.append("\""); //$NON-NLS-1$ constructName.append(shortMessage); constructName.append("\", "); //$NON-NLS-1$ } }
final String projectName = project.getName(); // Get the branch name final String fullBranchName = branch.getName(); final String shortBranchName = fullBranchName.substring(fullBranchName.indexOf(Constants.R_REMOTES) + Constants.R_REMOTES.length() + Constants.DEFAULT_REMOTE_NAME.length() + 1); final List<IProject> importedProject = new ArrayList<IProject>(1); try { new ProgressMonitorDialog(shell).run(true, false, monitor -> { monitor.beginTask(taskName, 6); try { // First, reset the current branch monitor.subTask("Reset the branch"); GitUtils.resetHardCurrentBranch(git); monitor.worked(1); // First, checkout the master branch (else we can't delete the other branch) monitor.subTask("Checkout the master"); GitUtils.checkoutExistingBranch(git, Constants.MASTER); monitor.worked(1); // Second, we have to delete local branch if exist monitor.subTask("Delete the local branch"); GitUtils.deleteLocalBranch(git, shortBranchName); monitor.worked(1); // Third, we have to delete remote branch if exist monitor.subTask("Delete the remote branch"); GitUtils.deleteRemoteBranch(git, Constants.DEFAULT_REMOTE_NAME, shortBranchName); monitor.worked(1); // Fourth, we have to import the project monitor.subTask("Import the project"); IProject imported = importProject(projectName, git, monitor); importedProject.add(imported); monitor.worked(1); // Fifth, we have to checkout the branch monitor.subTask("Checkout the branch"); GitUtils.checkoutExistingBranch(git, shortBranchName); monitor.worked(1); } catch (Exception e) { // Handle exception } finally { monitor.done(); } }); } catch (Exception e) { // Handle exception }
protected Element getRootElement(final Object selectedObject) { Element result = null; // Manage the possible selected file final IFile file = PapyrusFileUtils.getFile(selectedObject); if (null != file) { String fullPath = file.getFullPath().toString(); if (fullPath.endsWith("DomainsDefinition.uml")) { fullPath = fullPath.replace("DomainsDefinition.uml", ".uml"); } URI modelURI = URI.createPlatformResourceURI(fullPath, false); if (!"uml".equals(modelURI.fileExtension())) { modelURI = modelURI.trimFileExtension().appendFileExtension("uml"); } final ModelSet modelSet = new ModelSet(); final Resource resource = modelSet.getResource(modelURI, true); if (null != resource) { final EObject root = resource.getContents().get(0); if (root instanceof Element) { result = (Element) root; } } } // Manage other possibilities if (null == result && selectedObject instanceof IAdaptable) { // ... } return result; }
import java.text.SimpleDateFormat; import java.util.Date; public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); PersonIdent authorIdent = lastCommit.getAuthorIdent(); Date authorDate = authorIdent.getWhen(); SimpleDateFormat dateFormat = new SimpleDateFormat("dd-MM-yyyy HH:mm:ss"); return dateFormat.format(authorDate); } return "Not specified"; }
public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); PersonIdent authorIdent = lastCommit.getAuthorIdent(); Date authorDate = authorIdent.getWhen(); SimpleDateFormat dateFormat = new SimpleDateFormat("dd-MM-yyyy HH:mm:ss"); return dateFormat.format(authorDate); } return Messages.NotSpecified; }
final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); String author = null; if (lastCommit.getFullMessage().contains(Constants.SIGNED_OFF_BY_TAG)) { try { final String subSignedOff = lastCommit.getFullMessage().substring(lastCommit.getFullMessage().indexOf(Constants.SIGNED_OFF_BY_TAG) + Constants.SIGNED_OFF_BY_TAG.length()); author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; } catch (Exception e) { // Do nothing } } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } return author; } return "Unknown";
String author = null; try { String subSignedOff = lastCommit.getFullMessage().substring(lastCommit.getFullMessage().lastIndexOf("Signed-off-by:") + 14); author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; } catch (Exception e) { // Do nothing } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } return author != null && !author.isEmpty() ? author : "Unknown";
public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); return lastCommit.getShortMessage(); } return "Not specified"; }
package org.eclipse.papyrus.gitlight.git.data; import java.util.NoSuchElementException; import java.util.StringTokenizer; /** * This class represents the catalog version. */ public class CatalogVersion { protected int major; protected int minor; private final static String SEPARATOR = "."; public static final CatalogVersion emptyVersion = new CatalogVersion(0, 0); public CatalogVersion(final int major, final int minor) { updateVersion(major, minor); } public int getMajor() { return major; } public int getMinor() { return minor; } public void updateVersion(final int major, final int minor) { if (major < 0 || minor < 0) { throw new IllegalArgumentException("Version numbers must be positive"); } this.major = major; this.minor = minor; } public static CatalogVersion parseVersion(final String version) { StringTokenizer tokenizer = new StringTokenizer(version, SEPARATOR); try { int major = Integer.parseInt(tokenizer.nextToken()); int minor = Integer.parseInt(tokenizer.nextToken()); return new CatalogVersion(major, minor); } catch (NoSuchElementException e) { throw new IllegalArgumentException("Invalid version format: " + version); } catch (NumberFormatException e) { throw new IllegalArgumentException("Invalid version format: " + version); } } @Override public String toString() { return major + SEPARATOR + minor; } }
/** * The 'version' details name key. */ public static final String VERSION_DETAILS_NAME = "current"; /** * The master repository path. */ public static final String MASTER_REPOSITORY_PATH = Constants.DEFAULT_REMOTE_NAME + "/" + Constants.MASTER; /** * The contribution branch name prefix. */ public static final String CONTRIBUTION_BRANCH_PREFIX = "Review_"; /** * The initial commit message. */ public static final String INITIAL_COMMIT_MESSAGE = "Initial commit"; /** * The git folder. */ public static final String GIT_FOLDER = "\\" + Constants.DOT_GIT; /** * The change id. */ public static final String CHANGE_ID = "Change-Id: I0000000000000000000000000000000000000000"; }
public static void copyProject(final Git git, final IProject project) { final Repository repository = git.getRepository(); final URI gitPath = URI.createURI(repository.getWorkTree().toString().replace("\\", "/")); // Copy all project and sub files copySubFolder(project, gitPath); // Add this copied files to git addGitFiles(git, repository.getWorkTree(), ""); }
public static void copyFolder(final String source, final String dest) { final File srcFolder = getFolder(source); final File destFolder = getFolder(dest); if (srcFolder.exists()) { if (!destFolder.exists()) { destFolder.mkdir(); } // Copy sub folders and files for (final File subFile : srcFolder.listFiles()) { if (subFile.isDirectory()) { copyFolder(subFile.getAbsolutePath(), dest + "/" + subFile.getName()); } else { try { copyFile(subFile.getAbsolutePath(), dest + "/" + subFile.getName()); } catch (IOException e) { Activator.getLogHelper().error(e); } } } } }
package org.eclipse.papyrus.gitlight.review.profile; import org.eclipse.emf.common.EMFPlugin; import org.eclipse.emf.common.util.ResourceLocator; public final class Activator extends EMFPlugin { public static final Activator INSTANCE = new Activator(); private static Implementation plugin; private static class Implementation extends EclipsePlugin { public Implementation() { super(new ResourceLocator[] {}); } } public Activator() { super(new ResourceLocator[] {}); } public ResourceLocator getPluginResourceLocator() { return plugin; } }
/** * Finds the active shell and moves it to the end of the given array, so the * findControl() will find the controls from the active shell first */ private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } // find the index of the active shell and exchange last one with active int activeShellIndex = -1; for (int i = 0; i < shells.length; i++) { if (shells[i] == activeShell) { activeShellIndex = i; break; } } if (activeShellIndex != -1) { Shell temp = shells[lastIndex]; shells[lastIndex] = shells[activeShellIndex]; shells[activeShellIndex] = temp; } }
import org.eclipse.pde.internal.ui.wizards.plugin.NewProjectCreationOperation; import org.eclipse.pde.internal.ui.wizards.plugin.PluginContentPage; import org.eclipse.pde.internal.ui.wizards.plugin.PluginFieldData; import org.eclipse.ui.IWorkingSet; import org.eclipse.ui.PlatformUI; public class CreateNattableConfigurationWizard extends AbstractTableWizard { private static final String DOT = "."; //$NON-NLS-1$ private final TableConfiguration configuration; private Resource initialResource; private TableConfigurationHelper helper; private boolean isProjectCreation = false; } import org.eclipse.core.internal.resources.MarkerInfo; import java.io.UnsupportedEncodingException; import java.util.Iterator; import java.util.Map; import org.eclipse.core.internal.utils.*; import org.eclipse.core.runtime.Assert; import org.eclipse.osgi.util.NLS; public class MarkerInfo implements IMarkerSetElement, Cloneable, IStringPoolParticipant { protected static final Integer INTEGER_ONE = 1; protected static final Integer INTEGER_TWO = 2; protected static final Integer INTEGER_ZERO = 0; } protected Supplier<String> internalGetAttribute(String attr) { Widget widget = getWidget(); switch(attr){ case "style": return () -> swtStyles; case "class": return () -> Objects.toString(getCSSClass(widget), ""); case "swt-data-class": return () -> getSWTDataClass(widget); default: return null; } } public static Control findControl(Display displayToSearch, Point locationToFind) { Shell[] shells = displayToSearch.getShells(); fixShellOrder(displayToSearch, shells); return findControl(shells, locationToFind); } private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } for (int i = 0; i < shells.length; i++) { if (shells[i] == activeShell) { Shell temp = shells[lastIndex]; shells[lastIndex] = activeShell; shells[i] = temp; break; } } }
private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } // Find the index of the active shell and exchange the last one with the active shell for (int i = 0; i < shells.length; i++) { if (shells[i] == activeShell) { Shell toMove = shells[lastIndex]; shells[i] = toMove; shells[lastIndex] = activeShell; break; } } }
Fixed Code: ```java package org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model; import java.util.ArrayList; import java.util.List; public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; private final ITimeGraphEntry fEntry; private final long fTime; private final long fDuration; public TimeLineEvent(ITimeGraphEntry entry, long time, long duration) { this(entry, time, duration, new ArrayList<>()); } public TimeLineEvent(ITimeGraphEntry entry, long time, long duration, List<Long> values) { super(entry, time, duration); fEntry = entry; fTime = time; fDuration = duration; fValues = values; } public List<Long> getValues() { return fValues; } public ITimeGraphEntry getEntry() { return fEntry; } public long getTime() { return fTime; } public long getDuration() { return fDuration; } } ``` Refactored Code: ```java package org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model; import java.util.ArrayList; import java.util.List; public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; public TimeLineEvent(ITimeGraphEntry entry, long time, long duration) { this(entry, time, duration, new ArrayList<>()); } public TimeLineEvent(ITimeGraphEntry entry, long time, long duration, List<Long> values) { super(entry, time, duration); fValues = values; } public List<Long> getValues() { return fValues; } } ```
int columns = headers.length; sheetWriter.startSheet(setPrimary.getName(), headers.length); sheetWriter.writeRow((Object[]) headers); for (DispoItem item : items) { Map<String, MCDCCoverageData> mcdcToCoverageData = new HashMap<>(); List<DispoAnnotationData> annotations = item.getAnnotationsList(); for (DispoAnnotationData annotation : annotations) { writeRowAnnotation(sheetWriter, columns, item, annotation, setPrimary.getName(), levelToResolutionTypesToCount, leveltoUnitToCovered, mcdcToCoverageData, levelsInSet); } } sheetWriter.endSheet(); // START COVER SHEET sheetWriter.startSheet("Cover Sheet", headers.length); List<String> coverSheetHeadersList = new ArrayList<>(); coverSheetHeadersList.add(" "); if (levelsInSet.contains(CoverageLevel.A)) { coverSheetHeadersList.add("MCDC"); } if (levelsInSet.contains(CoverageLevel.B)) { coverSheetHeadersList.add("Branch"); }
import org.eclipse.equinox.http.servlet.internal.servlet.Match; import org.eclipse.equinox.http.servlet.internal.util.Const; import org.eclipse.equinox.http.servlet.internal.util.DispatchTargets; import org.eclipse.equinox.http.servlet.internal.util.RequestInfoDTO; import java.util.Set; public class ServletPathResolver { public DispatchTargets resolve(Set<ContextController> contextControllers, String requestURI, String extension, String queryString, Match match, RequestInfoDTO requestInfoDTO) { if (contextControllers.isEmpty()) { return null; } String contextPath = contextControllers.iterator().next().getContextPath(); requestURI = requestURI.substring(contextPath.length()); int pos = requestURI.lastIndexOf('/'); String servletPath = requestURI; String pathInfo = null; if (match == Match.CONTEXT_ROOT) { pathInfo = Const.SLASH; servletPath = Const.BLANK; } else if (match == Match.DEFAULT_SERVLET) { pathInfo = servletPath; servletPath = Const.SLASH; } do { for (ContextController contextController : contextControllers) { DispatchTargets dispatchTargets = contextController.getDispatchTargets(null, requestURI, servletPath, pathInfo, extension, queryString, match, requestInfoDTO); if (dispatchTargets != null) { return dispatchTargets; } } if ((match == Match.EXACT) || (match == Match.CONTEXT_ROOT) || (match == Match.DEFAULT_SERVLET)) { break; } if (pos > -1) { String newServletPath = requestURI.substring(0, pos); pathInfo = requestURI.substring(pos); servletPath = newServletPath; pos = newServletPath.lastIndexOf('/'); } else { break; } } while (true); return null; } }
// check for new pack files. If set to true (default) we use the // lastmodified attribute of the folder and assume that no new // pack files can be in this folder if his modification time has // not changed. boolean trustFolderStat = config.getBoolean( ConfigConstants.CONFIG_CORE_SECTION, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, true ); if (force || (!trustFolderStat) || old.snapshot.isModified(packDirectory)) { PackList newList = scanPacks(old, force); return old != newList; } return false;
private static final int MENU_DELETE = 3; private static final int MENU_DIAL = 4; private static final String INTENT_EXTRA_NAME = "name"; private static final String INTENT_EXTRA_NUMBER = "number"; private static final Uri FDN_CONTENT_URI = Uri.parse("content://icc/fdn"); private static final String FDN_CONTENT_PATH_WITH_SUB_ID = "content://icc/fdn/subId/"; private SubscriptionInfoHelper mSubscriptionInfoHelper; private PersistableBundle carrierConfig; private Phone mPhone; private boolean mFdnDialDirectlySupported = false; @Override public void onCreate(Bundle icicle) { super.onCreate(icicle); ActionBar actionBar = getActionBar(); if (actionBar != null) { actionBar.setDisplayHomeAsUpEnabled(true); } mSubscriptionInfoHelper = new SubscriptionInfoHelper(this, getIntent()); mSubscriptionInfoHelper.setActionBarTitle(getActionBar(), getResources(), R.string.fdn_list_with_label); mPhone = mSubscriptionInfoHelper.getPhone(); carrierConfig = PhoneGlobals.getInstance().getCarrierConfigForSubId(mPhone.getSubId()); }
private final Map<String, Object> nameMap; public CapabilityIndex(Iterator<IInstallableUnit> itor) { nameMap = new HashMap<>(300); namespaceMap = new HashMap<>(10); while (itor.hasNext()) { IInstallableUnit iu = itor.next(); Collection<IProvidedCapability> pcs = iu.getProvidedCapabilities(); for (IProvidedCapability pc : pcs) { namespaceMap.computeIfAbsent(pc.getNamespace(), n -> new HashSet<>()).add(iu); nameMap.compute(pc.getName(), (n, v) -> { if (v == null || v == iu) { return iu; } else if (v instanceof IInstallableUnit) { Collection<IInstallableUnit> list = new HashSet<>(); list.add((IInstallableUnit) v); list.add(iu); return list; } else { ((Collection<IInstallableUnit>) v).add(iu); return v; } }); } } } private Object getRequirementIDs(IEvaluationContext ctx, IExpression requirement, Object queriedKeys) { switch (requirement.getExpressionType()) { case IExpression.TYPE_AND : // rest of the code } }
private static void collectMatchingIUs(Map<String, ?> indexToUse, String name, Collection<IInstallableUnit> collector) { Object v = indexToUse.get(name); if (v == null) return; if (v instanceof IInstallableUnit) collector.add((IInstallableUnit) v); else collector.addAll((Collection<IInstallableUnit>) v); }
private void validatePage() { String message = null; if (userText.getText().trim().isEmpty()) { message = Messages.CredentialsWizardPage_ErrorUser; } else if (passwordText.getText().trim().isEmpty()) { message = Messages.CredentialsWizardPage_ErrorPassword; } setErrorMessage(message); setPageComplete(message == null); }
private static DiffPreferencesInfo updateDefaults(DiffPreferencesInfo input) { DiffPreferencesInfo result = DiffPreferencesInfo.defaults(); try { for (Field field : update.getClass().getDeclaredFields()) { if (skipField(field)) { continue; } Object newVal = field.get(update); if (newVal != null) { field.set(def, newVal); } } } catch (IllegalAccessException e) { e.printStackTrace(); } return def; } public UUID getAnonymousId() { UUID result = anonymousId; if (result == null) { synchronized (this) { result = anonymousId; if (result == null) { result = anonymousId = readOrCreateAnonymousId(); } } } return result; } while (itor.hasNext()) { IInstallableUnit iu = itor.next(); Collection<IProvidedCapability> pcs = iu.getProvidedCapabilities(); for (IProvidedCapability pc : pcs) { namespaceMap.computeIfAbsent(pc.getNamespace(), n -> new HashSet<>()).add(iu); nameMap.compute(pc.getName(), (n, v) -> { if (v == null || v == iu) { return iu; } else if (v instanceof IInstallableUnit) { Collection<IInstallableUnit> list = new HashSet<>(); list.add((IInstallableUnit) v); list.add(iu); return list; } else { ((Collection<IInstallableUnit>) v).add(iu); return v; } }); } } private Object getRequirementIDs(IEvaluationContext ctx, IExpression requirement, Object queriedKeys) { switch (requirement.getExpressionType()) { case IExpression.TYPE_AND: // AND is OK if at least one of the branches require the queried key for (IExpression expr : ExpressionUtil.getOperands(requirement)) { // code for handling the requirement } // code for handling other expression types } }
public void createArtifact(@Nullable ArtifactToken parent, ArtifactToken artifact) { ArtifactToken art = createArtifact(artifact); if (parent != null) { addChild(parent, art); } }
public boolean post(Event event) { Lock lock = OS.lock; lock.lock(); try { synchronized (Device.class) { if (isDisposed()) error(SWT.ERROR_DEVICE_DISPOSED); if (event == null) error(SWT.ERROR_NULL_ARGUMENT); if (!OS.IS_X11) { return false; } long /*int*/ xDisplay = OS.gdk_x11_display_get_xdisplay(OS.gdk_display_get_default()); int type = event.type; switch (type) { case SWT.KeyDown: case SWT.KeyUp: { int keyCode = 0; long /*int*/ keysym = untranslateKey(event.keyCode); if (keysym != 0) keyCode = OS.XKeysymToKeycode(xDisplay, keysym); if (keyCode == 0) { char key = event.character; ... } ... } ... } } } finally { lock.unlock(); } }
import org.eclipse.uml2.uml.Type; import org.eclipse.uml2.uml.UMLFactory; import org.eclipse.uml2.uml.UMLPackage; /** * Utility class for <code>org.eclipse.uml2.uml.Package</code><BR> */ public class PackageUtil { /** * Extension of UML models (also declared in class UmlModel. This class is not accessible here, * since oep.uml.tools depends on oep.uml.tools.utils, but not vice versa */ public static final String UML_EXT = org.eclipse.papyrus.uml.tools.model.UmlModel.UML_FILE_EXTENSION; /** * Apply a profile and every subprofiles to a package. Also import types defined in profile * * @param profileToApply profile to apply on package * @param package_ on which profiles are applied * @param withSubProfiles true if subprofiles must be automatically imported * @return true if the model was modified */ public static boolean applyProfile(org.eclipse.uml2.uml.Package package_, org.eclipse.uml2.uml.Profile profileToApply, boolean withSubProfiles) { // Returns true if the model was modified // ... } }
public static Package getUserModel(ExecutionEvent event) { ServiceUtilsForHandlers serviceUtils = ServiceUtilsForHandlers.getInstance(); try { ModelSet modelSet = serviceUtils.getModelSet(event); URI uri = modelSet.getURIWithoutExtension().appendFileExtension(UML_EXT); Resource userResource = modelSet.getResource(uri, false); if (userResource != null && userResource.getContents().size() > 0) { EObject topEObj = userResource.getContents().get(0); if ((topEObj instanceof Package) && (!(topEObj instanceof Profile))) { return (Package) topEObj; } } } catch (ServiceException e) { Activator.log.error(e); } return null; }
breakStatement.setSourceRange(statement.sourceStart, statement.sourceEnd - statement.sourceStart + 1); if (statement.label != null) { final SimpleName name = new SimpleName(this.ast); name.internalSetIdentifier(new String(statement.label)); retrieveIdentifierAndSetPositions(statement.sourceStart, statement.sourceEnd, name); breakStatement.setLabel(name); } else if (statement.expression != null && this.ast.apiLevel >= AST.JLS12_INTERNAL) { final Expression expression = convert(statement.expression); breakStatement.setExpression(expression); int sourceEnd = retrieveSemiColonPosition(expression); if (sourceEnd == -1) { breakStatement.setSourceRange(statement.sourceStart, statement.sourceEnd - statement.sourceStart + 2); } else { breakStatement.setSourceRange(statement.sourceStart, sourceEnd - statement.sourceStart + 1); } } return breakStatement;
private void disposeIfExited(final Control control, MouseEvent e) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt)) { tipShell.dispose(); } } }
Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt)) { tipShell.dispose(); } }
imgData.type = getImageFormat(loader); imgDataList.add(imgData); } else { long /*int*/ start_time = OS.g_malloc(8); OS.g_get_current_time(start_time); long /*int*/ animation_iter = GDK.gdk_pixbuf_animation_get_iter(pixbuf_animation, start_time); int delay_time = 0; int time_offset = 0; int num_frames = 32; for (int i = 0; i < num_frames; i++) { delay_time = GDK.gdk_pixbuf_animation_iter_get_delay_time(animation_iter); time_offset += delay_time; OS.g_time_val_add(start_time, time_offset * 1000); boolean update = GDK.gdk_pixbuf_animation_iter_advance(animation_iter, start_time); if (update) { long /*int*/ curr_pixbuf = GDK.gdk_pixbuf_animation_iter_get_pixbuf(animation_iter);
delay_time = GDK.gdk_pixbuf_animation_iter_get_delay_time(animation_iter); time_offset += delay_time; OS.g_time_val_add(start_time, time_offset * 1000); boolean update = GDK.gdk_pixbuf_animation_iter_advance(animation_iter, start_time); if (update) { long /*int*/ curr_pixbuf = GDK.gdk_pixbuf_animation_iter_get_pixbuf(animation_iter); long /*int*/ pixbuf_copy = GDK.gdk_pixbuf_copy(curr_pixbuf); ImageData imgData = pixbufToImageData(pixbuf_copy); if (this.logicalScreenHeight == 0 && this.logicalScreenWidth == 0) { this.logicalScreenHeight = imgData.height; this.logicalScreenWidth = imgData.width; } imgData.type = getImageFormat(loader); imgData.delayTime = delay_time; imgDataList.add(imgData); } else { break; } } ImageData[] imgDataArray = new ImageData[imgDataList.size()];
public ImageData[] load(String filename) { if (filename == null) { SWT.error(SWT.ERROR_NULL_ARGUMENT); } InputStream stream = null; try { stream = new FileInputStream(filename); return load(stream); } catch (IOException e) { SWT.error(SWT.ERROR_IO, e); } finally { try { if (stream != null) { stream.close(); } } catch (IOException e) { // Ignore error } } return null; }
static long /*int*/ gdk_pixbuf_new_from_file(String filename) { int length = filename.length(); char[] chars = new char[length]; filename.getChars(0, length, chars, 0); byte[] buffer = Converter.wcsToMbcs(chars, true); long /*int*/ pixbuf = GDK.gdk_pixbuf_new_from_file(buffer, null); return pixbuf; } static long /*int*/ imageDataToPixbuf(ImageData imgData) { int colorspace = GDK.GDK_COLORSPACE_RGB; boolean has_alpha = imgData.alphaData != null; int width = imgData.width; int height = imgData.height; int rowstride = imgData.scanlinePad; long /*int*/ buffer_ptr = OS.g_malloc(imgData.data.length); C.memmove(buffer_ptr, imgData.data, imgData.data.length); long /*int*/ pixbuf = GDK.gdk_pixbuf_new_from_data(buffer_ptr, colorspace, has_alpha, 8, width, height, rowstride, null, null); return pixbuf; }
long /*int*/ [] len = new long /*int*/ [1]; if (type == null) SWT.error(SWT.ERROR_UNSUPPORTED_FORMAT); GDK.gdk_pixbuf_save_to_bufferv(pixbuf, buffer, len, type, null, null, null); byte[] byteArray = new byte[(int) len[0]]; C.memmove(byteArray, buffer[0], byteArray.length); try { stream.write(byteArray); } catch (IOException e) { SWT.error(SWT.ERROR_IO); } // FileFormat.save(stream, format, this);
/** * Abstract tool tip handler. * * @since 3.2 * @author Loic Prieur-Drevon - extracted from {@link TimeGraphTooltipHandler} */ public abstract class TmfAbstractToolTipHandler { private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; /** * Important note: this is being added to a display filter, this may leak, * make sure it is removed when not needed. */ private final Listener fListener = event -> { Shell tipShell = fTipShell; if (tipShell != null) { disposeIfExited(tipShell, event); } }; private void disposeIfExited(final Control control, Event e) { if (!control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { // Check if the mouse pointer is outside the tool tip shell if (!bounds.contains(pt)) { control.getDisplay().asyncExec(() -> { if (!control.isDisposed()) { control.dispose(); } }); } } } } } /** * Dispose the tool tip shell and remove the listener. */ public void dispose() { if (fTipShell != null && !fTipShell.isDisposed()) { fTipShell.dispose(); } if (fTipComposite != null && !fTipComposite.isDisposed()) { fTipComposite.dispose(); } Display.getDefault().removeFilter(SWT.MouseMove, fListener); } }
private void disposeIfExited(final Control control, Event e) { if (!control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); } }
Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); }
createTooltipShell(timeGraphControl.getShell()); for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { // avoid displaying empty tool tips. return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); Display.getDefault().addFilter(SWT.MouseExit, fListener);
public static void beforeClass() { SWTBotUtils.initialize(); Thread.currentThread().setName("SWTBotTest"); /* set up for swtbot */ SWTBotPreferences.TIMEOUT = 60000; /* 60 second timeout */ SWTBotPreferences.KEYBOARD_LAYOUT = "EN_US"; SWTWorkbenchBot bot = new SWTWorkbenchBot(); SWTBotUtils.closeView("welcome", bot); /* Finish waiting for eclipse to load */ WaitUtils.waitForJobs(); /* Create project */ SWTBotUtils.createProject(PROJECT_NAME); }
checkWidget(); if (listener == null) error(SWT.ERROR_NULL_ARGUMENT); if (eventTable == null) return; eventTable.unhook(SWT.Verify, listener); } @Override GdkRGBA getContextBackgroundGdkRGBA() { if (background != null && (state & BACKGROUND) != 0) { return background; } return defaultBackground(); } @Override void setBackgroundGdkRGBA(long /*int*/ context, long /*int*/ handle, GdkRGBA rgba) { if (GTK.GTK4) { background = rgba; super.setBackgroundGdkRGBA(context, handle, rgba); } else { if (rgba == null) { background = defaultBackground(); } else { background = rgba; } String css; String properties; String name; name = GTK.GTK_VERSION >= OS.VERSION(3, 20, 0) ? "spinbutton" : "GtkSpinButton"; String color = display.gtk_rgba_to_css_string(background); css = name + " { " + color + " }"; properties = "* { " + color + " }"; OS.gtk_widget_override_background_color(handle, GTK.GTK_STATE_FLAG_NORMAL, rgba); OS.gtk_widget_override_color(handle, GTK.GTK_STATE_FLAG_NORMAL, rgba); OS.gtk_css_provider_load_from_data(OS.gtk_widget_get_style_context(handle), Converter.wcsToMbcs(css, true), -1, null); OS.gtk_css_provider_load_from_data(OS.gtk_widget_get_style_context(handle), Converter.wcsToMbcs(properties, true), -1, null); } }
Buggy Code: ```java public void run() { try { Thread.sleep(2000); try { Libcore.os.shutdown(dc.socket().getFileDescriptor$(), OsConstants.SHUT_RDWR); } catch (ErrnoException expected) { assertEquals(OsConstants.ENOTCONN, expected.errno); } } catch (Exception ex) { fail(ex.getMessage()); } } ``` Fixed Code: ```java public void run() { try { Thread.sleep(2000); try { Libcore.os.shutdown(dc.socket().getFileDescriptor$(), OsConstants.SHUT_RDWR); } catch (ErrnoException expected) { assertEquals(OsConstants.ENOTCONN, expected.errno); } } catch (Exception ex) { killerThreadException.set(ex); } } ``` Buggy Code: ```java // This should close the Raf, and previous implementations wrongly returned a new // open (but useless) channel in this case. fileChannelBeforeClosing.close(); FileChannel fileChannelAfterClosing = raf.getChannel(); assertFalse(fileChannelBeforeClosing.isOpen()); } // http://b/19892782 public void testCloseRafBeforeGetChannel_returnChannelWithCloseFdAfterClose() throws Exception { RandomAccessFile raf = new RandomAccessFile(file, "rw"); raf.setLength(10); raf.close(); try { raf.getChannel().size(); fail(); } catch (IOException expected) { return; } assertFalse("Exception expected", true); } private void createRandomAccessFile(File file) throws Exception { // TODO: fix our register maps and remove this otherwise unnecessary // indirection! (http://b/5412580) new RandomAccessFile(file, "rw"); } public void testDirectories() throws Exception { try { new RandomAccessFile(".", "r"); fail(); } catch (FileNotFoundException expected) { } try { new RandomAccessFile(".", "rw"); fail(); } ``` Fixed Code: ```java // This should close the Raf, and previous implementations wrongly returned a new // open (but useless) channel in this case. fileChannelBeforeClosing.close(); FileChannel fileChannelAfterClosing = raf.getChannel(); assertFalse(fileChannelBeforeClosing.isOpen()); } // http://b/19892782 public void test
public void testNothing() { assertNotNull(editorBot); final SWTBotTable tableBot = editorBot.bot().table(); tableBot.getTableItem(0).click(3); SWTBotText textBot = editorBot.bot().text(); textBot.typeText("LoggerA|LoggerB|LoggerC"); textBot.pressShortcut(Keystrokes.CTRL, Keystrokes.CR); fBot.waitUntil(Conditions.tableHasRows(tableBot, 6), 5000); tableBot.getTableItem(1).contextMenu(EXPORT_TO_TSV).click(); assertTsvContentsEquals(ImmutableList.of(HEADER_TEXT, EVENT1_TEXT, EVENT2_TEXT, EVENT3_TEXT)); fBot.closeAllEditors(); } private static void assertTsvContentsEquals(final List<String> expected) throws FileNotFoundException, IOException { File file = new File(fAbsolutePath); fBot.waitUntil(new FileLargerThanZeroCondition(file)); try (BufferedReader br = new BufferedReader(new FileReader(file))) { List<String> lines = br.lines().collect(Collectors.toList()); assertEquals("File content", expected, lines); } finally { file.delete(); } }
import org.eclipse.sirius.viewpoint.Messages; import com.google.common.base.Preconditions; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.List; import java.util.Set; import java.util.function.Predicate; import org.eclipse.emf.common.notify.Notification; import org.eclipse.emf.ecore.EObject; /** * A class providing useful methods for refresh. * * @author mbats */ public final class RefreshHelper { private static List<Predicate<Notification>> impactingNotificationPredicates = new ArrayList<>(); /** * Prevent instantiation. */ private RefreshHelper() { } /** * Checks whether at least one changes of which we are notified, concern a semantic model or a specific graphical * change (registered through {@link #registerImpactingNotification(Predicate)}). * * @param notifications * the model changes. * @return <code>true</code> if the changes impact a semantic model or a specific graphical change. */ public static boolean isImpactingNotification(final Collection<Notification> notifications) { boolean isImpactingNotification = false; Set<EObject> alreadyDoneNotifiers = new HashSet<>(); for (Notification notification : notifications) { Object notifier = notification.getNotifier(); if (notifier instanceof EObject) { EObject eObjectNotifier = (EObject) notifier; if (alreadyDoneNotifiers.add(eObjectNotifier)) { if (isImpactingNotification(eObjectNotifier)) { isImpactingNotification = true; break; } } } } return isImpactingNotification; } /** * Register a predicate to determine if a notification is impacting. * * @param predicate * the predicate to register. */ public static void registerImpactingNotification(Predicate<Notification> predicate) { Preconditions.checkNotNull(predicate); impactingNotificationPredicates.add(predicate); } private static boolean isImpactingNotification(EObject eObject) { for (Predicate<Notification> predicate : impactingNotificationPredicates) { if (predicate.test(eObject)) { return true; } } return false; } }
import org.eclipse.sirius.viewpoint.Messages; import com.google.common.base.Preconditions; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.List; import java.util.Set; import java.util.function.Predicate; /** * A class providing useful methods for refresh. * * @author mbats */ public final class RefreshHelper { private static List<Predicate<Notification>> impactingNotificationPredicates = new ArrayList<>(); /** * Prevent instantiation. */ private RefreshHelper() { } /** * Checks whether at least one changes of which we are notified, concern a semantic model or a specific graphical * change (registered through {@link #registerImpactingNotification(Predicate)}). * * @param notifications the model changes. * @return <code>true</code> if the changes impact a semantic model or a specific graphical change. */ public static boolean isImpactingNotification(final Collection<Notification> notifications) { boolean isImpactingNotification = false; Set<EObject> alreadyDoneNotifiers = new HashSet<>(); for (Notification notification : notifications) { Object notifier = notification.getNotifier(); if (notifier instanceof EObject) { EObject eObjectNotifier = (EObject) notifier; // Check if the notifier is already processed if (alreadyDoneNotifiers.contains(eObjectNotifier)) { continue; } alreadyDoneNotifiers.add(eObjectNotifier); if (isImpactingSemanticChange(eObjectNotifier) || isImpactingGraphicalChange(notification)) { isImpactingNotification = true; break; } } } return isImpactingNotification; } /** * Checks if the given EObject is an impacting semantic change. * * @param eObject the EObject to check. * @return <code>true</code> if the EObject is an impacting semantic change, <code>false</code> otherwise. */ private static boolean isImpactingSemanticChange(EObject eObject) { // TODO: Implement the logic to check if the EObject is an impacting semantic change return false; } /** * Checks if the given notification is an impacting graphical change. * * @param notification the notification to check. * @return <code>true</code> if the notification is an impacting graphical change, <code>false</code>
protected static boolean isImpactingNotification(Notification notification, EObject notifier, Set<EObject> alreadyDoneNotifiers, Map<EObject, Resource> notifierWithResource, Map<EObject, Boolean> notifierIsInAirdOrSrmResource) { Resource notifierResource = notifierWithResource.get(notifier); // Check if the notifier has a resource if (notifierResource != null) { // Check if the notifier is in an AIRD or SRM resource boolean isInAirdOrSrmResource = notifierIsInAirdOrSrmResource.getOrDefault(notifier, ResourceQuery.isAirdOrSrmResource(notifierResource)); if (isInAirdOrSrmResource) { return true; } } // Check if the notification concerns a semantic model change if (notification.getFeature() != null && notification.getFeature().eContainer() instanceof EPackage) { return true; } // Check if the notification concerns a specific graphical change if (notification.getNotifier() instanceof View) { return true; } // Check if the notification has already been checked if (alreadyDoneNotifiers.contains(notifier)) { return false; } alreadyDoneNotifiers.add(notifier); // Check if the notification concerns a semantic model change or a specific graphical change for the notifier's children if (notifier instanceof EObject) { for (EObject child : ((EObject) notifier).eContents()) { if (isImpactingNotification(notification, child, alreadyDoneNotifiers, notifierWithResource, notifierIsInAirdOrSrmResource)) { return true; } } } return false; }
private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; private final Listener fListener = this::disposeIfExited; private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); bounds.x -= OFFSET; bounds.y -= OFFSET; if (!bounds.contains(pt)) { tipShell.dispose(); control.getDisplay().removeFilter(SWT.MouseMove, fListener); } } } }
createTooltipShell(timeGraphControl.getShell()); for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); Display.getDefault().addFilter(SWT.MouseMove, fListener);
private void createTooltipShell(Shell parent) { final Display display = parent.getDisplay(); if (fTipShell != null && !fTipShell.isDisposed()) { fTipShell.dispose(); } fTipShell = new Shell(parent, SWT.ON_TOP | SWT.TOOL); fTipShell.addDisposeListener(e -> Display.getDefault().removeFilter(SWT.MouseMove, fListener)); GridLayout gridLayout = new GridLayout(); gridLayout.numColumns = 2; gridLayout.marginWidth = 2; gridLayout.marginHeight = 2; fTipShell.setLayout(gridLayout); fTipShell.setBackground(display.getSystemColor(SWT.COLOR_INFO_BACKGROUND)); fTipComposite = new Composite(fTipShell, SWT.NONE); fTipComposite.setLayout(new GridLayout(3, false)); setupControl(fTipComposite); }
public static void cleanUp() { SWTBotUtils.closeViewById(UML2DVIEW_ID, fBot); fFileLocation.delete(); fLogger.removeAllAppenders(); tearDown(); }
public static void tearDown() { fLogger.removeAllAppenders(); fFileLocation.delete(); } Review: The tearDown() method should also delete the project.
for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); Display display = Display.getDefault(); display.addFilter(SWT.MouseMove, fListener); display.addFilter(SWT.FocusOut, fListener);
import org.eclipse.jdt.core.IJavaElement; import org.eclipse.jdt.core.IMethod; import org.eclipse.jdt.core.JavaModelException; import org.eclipse.jdt.core.dom.CompilationUnit; import org.eclipse.jdt.core.dom.ConstructorInvocation; import org.eclipse.jdt.core.dom.Expression; import org.eclipse.jdt.core.dom.IMethodBinding; import org.eclipse.jdt.core.dom.MethodInvocation; import org.eclipse.jdt.internal.corext.dom.HierarchicalASTVisitor; import org.eclipse.jdt.internal.ui.JavaPlugin; public class CalleeJavaMethodParameterVisitor extends HierarchicalASTVisitor { private final CompilationUnit cu; private final List<ICodeMining> minings; private final ICodeMiningProvider provider; public CalleeJavaMethodParameterVisitor(CompilationUnit cu, List<ICodeMining> minings, ICodeMiningProvider provider) { this.cu = cu; this.minings = minings; this.provider = provider; } @Override public boolean visit(ConstructorInvocation constructorInvocation) { List<?> arguments = constructorInvocation.arguments(); if (!arguments.isEmpty()) { IMethod method = resolveMethodBinding(constructorInvocation.resolveConstructorBinding()); collectParameterNamesCodeMinings(method, arguments); } return super.visit(constructorInvocation); } @Override public boolean visit(MethodInvocation methodInvocation) { List<?> arguments = methodInvocation.arguments(); if (!arguments.isEmpty()) { IMethod method = resolveMethodBinding(methodInvocation.resolveMethodBinding()); collectParameterNamesCodeMinings(method, arguments); } return super.visit(methodInvocation); } private IMethod resolveMethodBinding(IMethodBinding methodBinding) { IJavaElement element = methodBinding.getJavaElement(); if (element instanceof IMethod) { return (IMethod) element; } return null; } private void collectParameterNamesCodeMinings(IMethod method, List<?> arguments) { try { String[] parameterNames = method.getParameterNames(); for (int i = 0; i < arguments.size(); i++) { Expression argument = (Expression) arguments.get(i); String parameterName = parameterNames[i]; ICodeMining codeMining = provider.createCodeMining(parameterName, argument.getStartPosition()); minings.add(codeMining); } } catch (JavaModelException e) { JavaPlugin.log(e); } } }
String targets[] = { "peer1", "peer2" }; try (BufferedRandomAccessFile braf = new BufferedRandomAccessFile(fFileLocation, "rw")) { braf.writeBytes(TRACE_START); for (int i = 0; i < 20000; i++) { braf.writeBytes(makeEvent(i * 100, eventNames[i % 2], targets[i % 2], targets[(i + 1) % 2], Integer.toString(i % 2 + 1000))); } braf.writeBytes(TRACE_END); } beforeTest(); /** * Open a trace in an editor */ public static void beforeTest() { SWTBotUtils.createProject(PROJECT_NAME); SWTBotTreeItem treeItem = SWTBotUtils.selectTracesFolder(fBot, PROJECT_NAME); assertNotNull(treeItem); SWTBotUtils.openTrace(PROJECT_NAME, fFileLocation.getAbsolutePath(), XMLSTUB_ID); SWTBotUtils.openView(UML2DVIEW_ID); } /** * Delete the file */ @AfterClass public static void cleanUp() { SWTBotUtils.closeViewById(UML2DVIEW_ID, fBot); fFileLocation.delete(); }
public void tearDown() { fBot.closeAllEditors(); cleanUp(); } private void cleanUp() { SWTBotUtils.deleteProject(PROJECT_NAME, fBot); }
fBot = new SWTWorkbenchBot(); /* finish waiting for eclipse to load */ WaitUtils.waitForJobs(); fFileLocation = File.createTempFile("sample", ".xml"); try (BufferedRandomAccessFile braf = new BufferedRandomAccessFile(fFileLocation, "rw")) { braf.writeBytes(TRACE_START); for (int i = 0; i < 100; i++) { braf.writeBytes(makeEvent(i * 100, i % 4)); } braf.writeBytes(TRACE_END); } SWTBotUtils.createProject(PROJECT_NAME); SWTBotTreeItem treeItem = SWTBotUtils.selectTracesFolder(fBot, PROJECT_NAME); assertNotNull(treeItem); SWTBotUtils.openTrace(PROJECT_NAME, fFileLocation.getAbsolutePath(), XMLSTUB_ID); SWTBotUtils.openView(ColorsView.ID); fLogger.removeAllAppenders(); fFileLocation.delete(); tearDown();
public static void cleanUp() { fLogger.removeAllAppenders(); fFileLocation.delete(); tearDown(); }
mgr.addJobChangeListener(changeListener); for (int i = 0; i < 10; i++) { SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); // Add little delay so that threads have a chance to start SWTBotUtils.delay(500); workbenchbot.closeAllEditors(); if (!status.isOK()) { SWTBotUtils.deleteProject(TRACE_PROJECT_NAME, workbenchbot); fail(handleErrorStatus(status)); } } SWTBotUtils.deleteProject(TRACE_PROJECT_NAME, workbenchbot);
IKernelTrace trace = new TmfXmlKernelTraceStub(); IPath filePath = Activator.getAbsoluteFilePath(CPU_USAGE_FILE); IStatus status = trace.validate(null, filePath.toOSString()); if (!status.isOK()) { fail(status.getException().getMessage()); } try { trace.initTrace(null, filePath.toOSString(), TmfEvent.class); } catch (TmfTraceException e) { fail(e.getMessage()); } deleteSuppFiles(trace); ((TmfTrace) trace).traceOpened(new TmfTraceOpenedSignal(null, trace, null)); /* FIXME: Make sure this analysis is finished before running the CPU analysis. This block can be removed once analysis dependency and request precedence is implemented */ IAnalysisModule module = null; for (IAnalysisModule mod : TmfTraceUtils.getAnalysisModulesOfClass(trace, TidAnalysisModule.class)) { module = mod; } assertNotNull(module); module.schedule(); module.waitForCompletion(); /* End of the FIXME block */ fModule = TmfTraceUtils.getAnalysisModuleOfClass(trace, KernelCpuUsageAnalysis.class, KernelCpuUsageAnalysis.ID);
public static void setUp() { ITmfTrace trace = KERNEL_TEST_CASE.getKernelTrace(); deleteSuppFiles(trace); ((TmfTrace) trace).traceOpened(new TmfTraceOpenedSignal(null, trace, null)); IAnalysisModule module = null; for (IAnalysisModule mod : TmfTraceUtils.getAnalysisModulesOfClass(trace, KernelAnalysisModule.class)) { module = mod; } assertNotNull(module); module.schedule(); module.waitForCompletion(); fModule = TmfTraceUtils.getAnalysisModuleOfClass(trace, KernelAnalysisModule.class, KernelAnalysisModule.ID); fTrace = trace; }
private final Object fReconcilerLock= new Object(); private JavaTemplatesPage fTemplatesPage; private IJavaReconcilingListener fCodeMiningsReconcilingListener; public CompilationUnitEditor() { setDocumentProvider(JavaPlugin.getDefault().getCompilationUnitDocumentProvider()); setEditorContextMenuId("#CompilationUnitEditorContext"); setRulerContextMenuId("#CompilationUnitRulerContext"); setOutlinerContextMenuId("#CompilationUnitOutlinerContext"); fSavePolicy= null; fJavaEditorErrorTickUpdater= new JavaEditorErrorTickUpdater(this); fCorrectionCommands= null; }
package org.eclipse.jdt.ui.tests.activation; import java.util.Arrays; import java.util.HashSet; import java.util.Set; import org.junit.Assert; import org.osgi.framework.Bundle; import org.eclipse.jdt.testplugin.JavaProjectHelper; import org.eclipse.core.runtime.Platform; import org.eclipse.ui.IWorkbench; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.PlatformUI; import org.eclipse.jdt.core.ICompilationUnit; import org.eclipse.jdt.core.IJavaProject; import org.eclipse.jdt.core.IPackageFragment; import org.eclipse.jdt.core.IPackageFragmentRoot; import org.eclipse.jdt.internal.ui.javaeditor.EditorUtility; import junit.framework.TestCase; public class JavaActivationTest extends TestCase { private IJavaProject project; }
import org.osgi.framework.Bundle; import org.eclipse.jdt.testplugin.JavaProjectHelper; import org.eclipse.core.runtime.Platform; import org.eclipse.ui.IWorkbench; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.PlatformUI; import org.eclipse.jdt.core.ICompilationUnit; import org.eclipse.jdt.core.IJavaProject; import org.eclipse.jdt.core.IPackageFragment; import org.eclipse.jdt.core.IPackageFragmentRoot; import org.eclipse.jdt.internal.ui.javaeditor.EditorUtility; import junit.framework.TestCase; public class JavaActivationTest extends TestCase { private IJavaProject project; private static final String[] inactiveBundles= new String[] { "org.apache.xerces", "org.eclipse.jdt.astview", "org.eclipse.jdt.jeview", "org.eclipse.reftracker", "org.eclipse.swt.sleak", "org.eclipse.swt.spy", "com.jcraft.jsch", "javax.servlet", "javax.servlet.jsp", "org.apache.ant", "org.apache.commons.el", "org.apache.commons.logging", "org.apache.jasper", "org.apache.lucene", "org.apache.lucene.analysis" }; }
protected List<AbstractNodeMapping> getListOfMappingsToMove(DDiagram diagram) { List<AbstractNodeMapping> returnedList = new ArrayList<>(); returnedList.add(DiagramServices.getDiagramServices().getContainerMapping(diagram, IMappingNameConstants.CRB_COMPONENT_MAPPING)); return returnedList; } public List<String> getOwnerGroups(Project.NameKey project) { String[] groups = cfg.getStringList(SECTION_NAME, findSubSection(project.get()), OWNER_GROUP_NAME); return Arrays.asList(groups); } public class LocalSearchProfilerAdapter implements ILocalSearchAdapter { private final Map<MatcherReference, PlanProfile> profile = new HashMap<>(); private final Map<SearchPlanExecutor, int[]> currentBodies = new HashMap<>(); private class PlanProfile { final int[][] bodies; final ArrayList<List<ISearchOperation>> operations; public PlanProfile(LocalSearchMatcher lsMatcher) { ImmutableList<SearchPlanExecutor> plan = lsMatcher.getPlan(); bodies = new int[plan.size()][]; operations = new ArrayList<>(plan.size()); for (int i = 0; i < bodies.length; i++) { List<ISearchOperation> ops = plan.get(i).getSearchPlan().getOperations(); operations.add(ops); bodies[i] = new int[ops.size()]; } } public void register(LocalSearchMatcher lsMatcher) { ImmutableList<SearchPlanExecutor> plan = lsMatcher.getPlan(); for (int i = 0; i < bodies.length; i++) { // code omitted for brevity } } } } IPackageFragment pack = sourceFolder.createPackageFragment("pack0", false, null); StringBuffer buf = new StringBuffer(); buf.append("package pack0;\n"); buf.append("public class List1 {\n}\n"); return pack.createCompilationUnit("List1.java", buf.toString(), false, null); public void testOpenJavaEditor() throws Exception { ICompilationUnit unit = createTestCU(); EditorUtility.openInEditor(unit); Set<String> set = new HashSet<>(Arrays.asList(inactiveBundles)); checkNotLoaded(set); } public void checkNotLoaded(Set<String> inactiveBundles) { Bundle bundle = Platform.getBundle("org.eclipse.jdt.ui.tests"); Bundle[] bundles = bundle.getBundleContext().getBundles(); for (int i = 0
private static IType createAutoType(ICPPASTInitializerClause initClause, IASTDeclSpecifier declSpec, IASTDeclarator declarator) { if (initClause == null) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } IType type = AutoTypeResolver.AUTO_TYPE; IType initType = null; ValueCategory valueCat = null; ICPPClassTemplate initializer_list_template = null; if (initClause instanceof ICPPASTInitializerList) { initializer_list_template = get_initializer_list(declSpec); if (initializer_list_template == null) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } type = (IType) CPPTemplates.instantiate(initializer_list_template, new ICPPTemplateArgument[] { new CPPTemplateTypeArgument(type) }, initClause); if (type instanceof IProblemBinding) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } } type = decorateType(type, declSpec, declarator); final ICPPEvaluation evaluation = initClause.getEvaluation(); initType = evaluation.getTypeOrFunctionSet(declarator); valueCat = evaluation.getValueCategory(declarator); }
import static org.junit.Assert.assertNotNull; public ScheduleConfig(Config rc, String section, String subsection) { this(rc, section, subsection, ZonedDateTime.now(systemDefault())); } public int chooseRunningDeviceStep(String[] deviceNames) { JRadioButtonFixture chooseRunningDeviceRadioButton = new JRadioButtonFixture(robot, findRadioButtonByText("Choose a running device")); chooseRunningDeviceRadioButton.requireEnabled(); chooseRunningDeviceRadioButton.requireVisible(); chooseRunningDeviceRadioButton.click(); JBTable deviceTable = robot.finder().findByType(target, JBTable.class); assertNotNull(deviceTable); JTableFixture deviceTableFixture = new JTableFixture(robot, deviceTable); int deviceColumnIndex = deviceTable.getColumn("Device").getModelIndex(); int compatibleColumnIndex = deviceTable.getColumn("Compatible").getModelIndex(); ArrayList<Integer> rowsToSelect = new ArrayList<Integer>(deviceTable.getRowCount()); HashSet<String> deviceNameHashes = new HashSet<String>(Arrays.asList(deviceNames)); for (int i = 0; i < deviceTable.getRowCount(); ++i) { IDevice device = (IDevice) deviceTable.getModel().getValueAt(i, deviceColumnIndex); ThreeState launchCompatibility = ((LaunchCompatibility) deviceTable.getModel().getValueAt(i, compatibleColumnIndex)).isCompatible(); } } public static void findAndSetPlatformSources(@NotNull IAndroidTarget target, @NotNull SdkModificator sdkModificator) { File sources = findPlatformSources(target); if (sources != null) { VirtualFile virtualFile = VfsUtil.findFileByIoFile(sources, true); if (virtualFile != null) { for (VirtualFile file : sdkModificator.getRoots(OrderRootType.SOURCES)) { if (file.equals(virtualFile)) { return; } } } } } Ref doPeel(Ref leaf) throws MissingObjectException, IOException { try (RevWalk rw = new RevWalk(repository)) { RevObject obj = rw.parseAny(leaf.getObjectId()); if (obj instanceof RevTag) { return new ObjectIdRef.PeeledTag(leaf.getStorage(), leaf.getName(), leaf.getObjectId(), rw.peel(obj).copy(), hasVersioning() ? leaf.getUpdateIndex() : Ref.UNDEFINED_UPDATE_INDEX); } else { return new ObjectIdRef.PeeledNonTag(leaf.getStorage(), leaf.getName(),
public abstract class TmfAbstractToolTipHandler { private static final int MOUSE_DEADZONE = 5; private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; private final Listener fListener = this::disposeIfExited; private final Listener fFocusLostListener = event -> { Shell tipShell = fTipShell; if (tipShell != null) { tipShell.dispose(); } }; private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); Rectangle deadzone = fInitialDeadzone; if (deadzone == null) { deadzone = new Rectangle(bounds.x - MOUSE_DEADZONE, bounds.y - MOUSE_DEADZONE, bounds.width + 2 * MOUSE_DEADZONE, bounds.height + 2 * MOUSE_DEADZONE); fInitialDeadzone = deadzone; } if (!deadzone.contains(pt)) { tipShell.dispose(); } } } } }
private static final int MOUSE_DEADZONE = 5; private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; private final Listener fListener = this::disposeIfExited; private final Listener fFocusLostListener = event -> { Shell tipShell = fTipShell; if (tipShell != null) { tipShell.dispose(); } }; private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); } } } }
/* The match pattern for <uses-library> */ private static final Pattern PATTERN_USES_LIBRARY = Pattern.compile("^use.*library"); /** The main issue discovered by this detector */ public static final Issue ISSUE = Issue.create( "ManifestTypos", //$NON-NLS-1$ "Checks for manifest typos", "This check looks through the manifest , and if it finds any tags " + "that look like likely misspellings, they are flagged.", Category.CORRECTNESS, 5, Severity.WARNING, ManifestTypoDetector.class, Scope.MANIFEST_SCOPE ); /** Constructs a new {@link ManifestTypoDetector} check */ public ManifestTypoDetector() { } @NonNull @Override public Speed getSpeed() { return Speed.FAST; } @Override public boolean appliesTo(@NonNull Context context, @NonNull File file) { return file.getName().equals(ANDROID_MANIFEST_XML); } @Override public Collection<String> getApplicableElements() { return XmlScanner.ALL; } public int getMetricsCategory() { return MetricsEvent.QS_SCREENSHOT_TILE; } 5, Severity.WARNING, IMPLEMENTATION); /** Not explicitly defining application icon */ public static final Issue APPLICATION_ICON = Issue.create( "MissingApplicationIcon", //$NON-NLS-1$ "Missing application icon", "Checks that the application icon is set", "You should set an icon for the application as whole because there is no " + "default. This attribute must be set as a reference to a drawable resource " + "containing the image (for example `@drawable/icon`).", Category.ICONS, 5, Severity.WARNING, IMPLEMENTATION ); /** Constructs a new {@link ManifestOrderDetector} check */ public ManifestOrderDetector() { } private boolean mSeenApplication; /** Number of times we've seen the <uses-sdk> element */ private int mSeenUsesSdk; /** Activities we've encountered */ private final Set<String> mActivities = new HashSet<String>(); /** Features we've encountered */ private final Set<String> mUsesFeatures = new HashSet<String>(); /** Permission basenames */ } return result; } /** * Sets the completion proposal categories which are excluded from the * default proposal list and reloads the registry. * * @param categories the array with the IDs of the excluded categories * @see #CODEASSIST_EXCLUDED_CATEGORIES * @since
assert (myEditor.getCaptureId() != null); if (myEditor.getDeviceId() == null) { return; } DefaultListModel model = new DefaultListModel(); model.ensureCapacity(myFrameData.size()); for (ScrubberLabelData data : myFrameData) { model.addElement(data); } setModel(model); if (myFrameData.size() == 0) { myList.getEmptyText().setText(StatusText.DEFAULT_EMPTY_TEXT); } ImageFetcher imageFetcher = new ImageFetcher(client); imageFetcher.prepareFetch(myEditor.getDeviceId(), myEditor.getCaptureId(), myEditor.getContext()); myScrubberCellRenderer.setup(imageFetcher); myList.setCellRenderer(myScrubberCellRenderer); public String getUsage() { StringBuilder sb = new StringBuilder(); sb.append("<key>" + separator + "<value>"); sb.append(" where <key> is "); sb.append(keyParser.getUsage()); sb.append(" and where <value> is "); sb.append(valueParser.getUsage()); return sb.toString(); } public void testTraceSetExperiment() { TmfExperiment exp = createExperiment(trace1, trace2); openTrace(trace1); openTrace(exp); ITmfTrace[] expected = new ITmfTrace[] { trace1, trace2 }; Collection<ITmfTrace> actual = tm.getActiveTraceSet(); assertEquals(2, actual.size()); assertEquals(expected, actual); } public boolean visit(ConstructorInvocation constructorInvocation) { List<?> arguments = constructorInvocation.arguments(); if (!arguments.isEmpty()) { IMethodBinding constructorBinding = constructorInvocation.resolveConstructorBinding(); IMethod method = resolveMethodBinding(constructorBinding); collectParameterNamesCodeMinings(method, arguments, constructorBinding.isVarargs()); } return super.visit(constructorInvocation); }
public boolean visit(MethodInvocation methodInvocation) { List<?> arguments = methodInvocation.arguments(); if (!arguments.isEmpty()) { IMethodBinding methodBinding = methodInvocation.resolveMethodBinding(); IMethod method = resolveMethodBinding(methodBinding); if (method != null) { collectParameterNamesCodeMinings(method, arguments, methodBinding.isVarargs()); } } return super.visit(methodInvocation); }
/*****************************************************************************
package org.eclipse.viatra.query.runtime.matchers.memories; /** * Represents that a replacement between timestamps. * Either old or new can be null, but not at the same time. * * @author Tamas Szabo */ public class TimestampReplacement<Timestamp extends Comparable<Timestamp>> { public final Timestamp oldValue; public final Timestamp newValue; public TimestampReplacement(final Timestamp oldValue, final Timestamp newValue) { if (oldValue == null && newValue == null) { throw new IllegalArgumentException("Old and new cannot be both null at the same time!"); } this.oldValue = oldValue; this.newValue = newValue; } }
/*************************************************************************** * Copyright (c) 2019 CEA LIST and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * CEA LIST - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.model2doc.core.generatorconfiguration.operations; import org.eclipse.emf.common.util.URI; import org.eclipse.osgi.util.NLS; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentStructureGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.internal.Activator; /** * Utility class for the operations of GeneratorConfiguration metamodel */ public class GeneratorConfigurationOperations { 	/** 	 * 	 * @param generatorConfiguration 	 * a generatorConfiguration element 	 * @param uriKind 	 * the kind of expected URI 	 * @param fileExtension 	 * the expected file extension 	 * @return the computed URI 	 */ 	public static URI computeURI(DefaultDocumentGeneratorConfiguration generatorConfiguration, String uriKind, 			String fileExtension) { 		// implementation 	} 	/** 	 * 	 * @param generatorConfiguration 	 * a generatorConfiguration element 	 * @param uriKind 	 * the kind of expected URI 	 * @param fileExtension 	 * the expected file extension 	 * @return the computed URI 	 */ 	public static URI computeURI(DefaultDocumentStructureGeneratorConfiguration generatorConfiguration, String uriKind, 			String fileExtension) { 		// implementation 	} 	/** 	 * 	 * @param generatorConfiguration 	 * a generatorConfiguration element 	 * @param uriKind 	 * the kind of expected URI 	 * @param fileExtension 	 * the expected file extension 	 * @return the computed URI 	 */ 	public static URI computeURI(DefaultDocumentStructureGeneratorConfiguration generatorConfiguration, String uriKind, 			String fileExtension) { 		// implementation 	} }
/** * SPDX-License-Identifier: EPL-2.0 * Contributors: * CEA LIST - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.model2doc.core.generatorconfiguration.operations; import org.eclipse.emf.common.util.URI; import org.eclipse.osgi.util.NLS; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentStructureGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.internal.Activator; /** * Utility class for the operations of GeneratorConfiguration metamodel */ public class GeneratorConfigurationOperations { /** * @param generatorConfiguration a generatorConfiguration element * @param uriKind the kind of expected URI * @param fileExtension the extension file * @return the path of the file build from the parameters */ public static final String getDocumentStructureFileEcoreURI(final DefaultDocumentStructureGeneratorConfiguration generatorConfiguration, final String fileExtension) { final String folderName = generatorConfiguration.getStructureFolder(); final String documentName = generatorConfiguration.getDocumentName(); // Rest of the code... } }
private final String myTitle; private Combo branchText; private Combo remoteText; private Button rebase; public BranchConfigurationDialog(Shell shell, String branchName, Repository repository) { super(shell); myBranchName = branchName; myRepository = repository; myConfig = myRepository.getConfig(); setShellStyle(getShellStyle() | SWT.SHELL_TRIM); myTitle = UIText.BranchConfigurationDialog_BranchConfiguration; setHelpAvailable(false); } @Override protected Control createDialogArea(Composite parent) { Composite main = new Composite(parent, SWT.NONE); GridLayoutFactory.fillDefaults().numColumns(2).applyTo(main); GridDataFactory.fillDefaults().grab(true, false).indent(5, 5).applyTo(main); Label branchLabel = new Label(main, SWT.NONE); branchLabel.setText("Upstream &Branch:"); //$NON-NLS-1$ branchText = new Combo(main, SWT.BORDER); GridDataFactory.fillDefaults().grab(true, false).applyTo(branchText); try { // TODO: Add code here } catch (Exception e) { // Handle exception } return main; } public boolean canFlipToNextPage() { final boolean hasAtLeastOneFileToScan = !((BatchImportTraceWizard) getWizard()).getFilesToScan().isEmpty(); if (hasAtLeastOneFileToScan) { setErrorMessage(null); } else { setErrorMessage(Messages.ImportTraceWizardPageSelectDirectories_4); } return hasAtLeastOneFileToScan; } public void run() { MessageDialog.open(MessageDialog.INFORMATION, null, UIText.AutoRebaseProcess_AutoRebaseStarted, dialogMessage, SWT.NONE); } return newURI.toString(); } if (false == uri.isPlatform()) { final String projectName = generatorConfiguration.eResource().getURI().segment(1); uri = URI.createPlatformResourceURI(projectName, true).appendSegment(folderName); } if (uri.isPlatform()) { if (uri.isPlatformPlugin()) { Activator.log.warn(NLS.bind("The path {0} must not be a platform path", uri.toString())); return null; } return uri.appendSegment(documentName).appendFileExtension(fileExtension).toString(); } return null; } public static final String getDocumentFileOSURI(final DefaultDocumentGeneratorConfiguration
private final String myTitle; private Combo branchText; private Combo remoteText; private Button rebase; public BranchConfigurationDialog(Shell shell, String branchName, Repository repository) { super(shell); myBranchName = branchName; myRepository = repository; myConfig = myRepository.getConfig(); setShellStyle(getShellStyle() | SWT.SHELL_TRIM); myTitle = UIText.BranchConfigurationDialog_BranchConfiguration; setHelpAvailable(false); } @Override protected Control createDialogArea(Composite parent) { Composite main = new Composite(parent, SWT.NONE); GridLayoutFactory.fillDefaults().numColumns(2).applyTo(main); GridDataFactory.fillDefaults().grab(true, false).indent(5, 5).applyTo(main); Label branchLabel = new Label(main, SWT.NONE); branchLabel.setText("Upstream &Branch:"); //$NON-NLS-1$ branchText = new Combo(main, SWT.BORDER); GridDataFactory.fillDefaults().grab(true, false).applyTo(branchText); try { // code for creating dialog area } catch (Exception e) { // handle exception } return main; } public boolean canFlipToNextPage() { final boolean hasAtLeastOneFileToScan = !((BatchImportTraceWizard) getWizard()).getFilesToScan().isEmpty(); if (hasAtLeastOneFileToScan) { setErrorMessage(null); } else { setErrorMessage(Messages.ImportTraceWizardPageSelectDirectories_4); } return hasAtLeastOneFileToScan; } public void run() { MessageDialog.open(MessageDialog.INFORMATION, null, UIText.AutoRebaseProcess_AutoRebaseStarted, dialogMessage, SWT.NONE); } return newURI.toString(); if (false == uri.isPlatform()) { final String projectName = configuration.eResource().getURI().segment(1); uri = URI.createPlatformResourceURI(projectName, true).appendSegment(folderName); } if (uri.isPlatform()) { if (uri.isPlatformPlugin()) { Activator.log.warn(NLS.bind("The path {0} must not be a platform path", uri.toString())); return null; } uri = uri.appendSegment(documentName).appendFileExtension(fileExtension); } return null; }
import org.junit.Test; public class CtfTmfExperimentTrimmingTest { private static ITmfTrace fNewExperiment; @BeforeClass public static void beforeClass() throws IOException { SWTBotUtils.initialize(); SWTBotPreferences.TIMEOUT = 20000; fLogger.removeAllAppenders(); fLogger.addAppender(new NullAppender()); File parentDir = FileUtils.toFile(FileLocator.toFileURL(CtfTestTrace.TRACE_EXPERIMENT.getTraceURL())); File[] traceFiles = parentDir.listFiles(); ITmfTrace traceValidator = new CtfTmfTrace(); fBot = new SWTWorkbenchBot(); SWTBotUtils.createProject(PROJECT_NAME); int openedTraces = 0; for (File traceFile : traceFiles) { String absolutePath = traceFile.getAbsolutePath(); if (traceValidator.validate(null, absolutePath).isOK()) { // open trace SWTBotUtils.openTrace(absolutePath); openedTraces++; } } // create experiment fNewExperiment = new CtfTmfExperiment(); fNewExperiment.indexTrace(true); fNewExperiment.waitForCompletion(); } @Test public void testTrimExperiment() { // test code here } }
protected boolean hasJREInClassPath(IJavaProject javaProject) { if (javaProject != null) { try { IClasspathEntry[] oldClasspaths = javaProject.getRawClasspath(); for (int i = 0; i < oldClasspaths.length; i++) { if (isJREContainer(oldClasspaths[i].getPath())) { return true; } } } catch (JavaModelException e) { e.printStackTrace(); } } return false; }
getRequirementFilter(symbolicName, versionRange)); Collection<BundleCapability> matchingBundleCapabilities = fwkWiring.findProviders(ModuleContainer .createRequirement(IdentityNamespace.IDENTITY_NAMESPACE, directives, Collections.emptyMap())); if (matchingBundleCapabilities.isEmpty()) { return null; } Bundle[] results = matchingBundleCapabilities.stream() .map(c -> c.getRevision().getBundle()) .filter(bundle -> (bundle.getState() & (Bundle.INSTALLED | Bundle.UNINSTALLED)) == 0) .sorted((b1, b2) -> b2.getVersion().compareTo(b1.getVersion())) .toArray(Bundle[]::new); return results.length > 0 ? results : null;
try { XMultiServiceFactory xMultiServiceFactory = odtEditor.getXMultiServiceFactory(); // create a text table Object obj = xMultiServiceFactory.createInstance("com.sun.star.text.TextTable"); XTextTable textTable = UnoRuntime.queryInterface(XTextTable.class, obj); // Default background color Object backColor = 0x6AA84F; // If defined style then update backColor if (style != null) { backColor = style; } if (numRows > 0 && numCols > 0) { // Verify if there are row titles if (table.getRowTitles() != null && !table.getRowTitles().isEmpty()) { // update column counters numCols++; } // Verify if there are column titles if (table.getColumnTitles() != null && !table.getColumnTitles().isEmpty()) { // update row counter numRows++; } // Initialize and add table textTable.initialize(numRows, numCols); addTextContent(xTextCursor, textTable); endParagraph(xTextCursor); } } catch (Exception e) { e.printStackTrace(); }
boolean isValueDependent(); boolean isConstantExpression(); boolean isNoexcept(boolean inCalledContext); boolean isEquivalentTo(ICPPEvaluation other); IType getType(); IValue getValue();
public boolean isNoexcept(boolean inCalledContext) { return true; }
public boolean isNoexcept(boolean inCalledContext) { if (inCalledContext) { return true; } else { return false; } }
public boolean isNoexcept(boolean inCalledContext) { assert false; return true; }
public boolean isNoexcept(boolean inCalledContext) { assert false; return true; }
public boolean isNoexcept(boolean inCalledContext) { return false; }
public boolean isNoexcept(boolean inCalledContext) { assert false; return false; }
private void ensureSize(int index) { List<@Nullable IEventDeclaration> list = fEvents; if (list instanceof ArrayList) { if (index > 50000) { fEvents = new SparseList(fEvents); } ((ArrayList<@Nullable IEventDeclaration>) list).ensureCapacity(index); while (list.size() <= index) { list.add(null); } } }
public SparseList(List<@Nullable IEventDeclaration> events) { for(int i = 0; i < events.size(); i++) { IEventDeclaration event = events.get(i); if(event != null) { add(i, event); } } }
public boolean add(@Nullable IEventDeclaration e) { synchronized (this) { fInnerEvents.put(fNextAdded, e); fNextAdded++; } return true; }
public boolean addAll(int index, Collection<? extends @Nullable IEventDeclaration> c) { int key = index; for (IEventDeclaration event : c) { if (event != null) { add(key, event); } key++; } return true; }
public void add(int index, @Nullable IEventDeclaration element) { if (index > fLastAdded) { fLastAdded = index; } add(element); }
public class Text extends Scrollable { int tabs, oldStart, oldEnd; boolean doubleClick, ignoreModify, ignoreVerify, ignoreCharacter, allowPasswordChar; String message; int[] segments; int clearSegmentsCount = 0; RECT searchRect, cancelRect; boolean mouseInSearch, mouseInCancel; static final char LTR_MARK = '\u200e'; static final char RTL_MARK = '\u200f'; static final int IDI_SEARCH = 101; static final int IDI_CANCEL = 102; static final int SEARCH_ICON_MARGIN = 4; public static final int LIMIT; public static final String DELIMITER; /* This code is intentionally commented. */ }
public long getTimeWriting() { return statistics.timeWriting; } public long getTreesTraversed() { return statistics.treesTraversed; } public long getTimeTotal() { return statistics.timeCounting + statistics.timeSearchingForReuse + statistics.timeSearchingForSizes + statistics.timeCompressing + statistics.timeWriting; }
/***************************************************************************** * Copyright (c) 2019 Ericsson * * All rights reserved. This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1.0 which * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *****************************************************************************/ package org.eclipse.tracecompass.tmf.ui.viewers; import org.eclipse.swt.SWT; import org.eclipse.swt.events.MouseEvent; import org.eclipse.swt.events.MouseTrackAdapter; import org.eclipse.swt.graphics.Point; import org.eclipse.swt.graphics.Rectangle; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.layout.GridLayout; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Control; import org.eclipse.swt.widgets.Display; import org.eclipse.swt.widgets.Event; import org.eclipse.swt.widgets.Label; import org.eclipse.swt.widgets.Listener; import org.eclipse.swt.widgets.Shell; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.widgets.TimeGraphTooltipHandler; /** * Abstract tool tip handler. * * @since 3.2 */ public abstract class AbstractToolTipHandler { // TODO: Implement the abstract tool tip handler }
final Display display = parent.getDisplay(); if (fTipShell != null && !fTipShell.isDisposed()) { fTipShell.dispose(); } fTipShell = new Shell(parent, SWT.ON_TOP | SWT.TOOL); // Deregister display filters on dispose fTipShell.addDisposeListener(e -> e.display.removeFilter(SWT.MouseMove, fListener)); fTipShell.addDisposeListener(e -> e.display.removeFilter(SWT.FocusOut, fFocusLostListener)); fTipShell.addListener(SWT.Deactivate, e -> { if (fTipShell.isDisposed()) { fTipShell.dispose(); } }); GridLayout gridLayout = new GridLayout(); gridLayout.numColumns = 2; gridLayout.marginWidth = 2; gridLayout.marginHeight = 2; fTipShell.setLayout(gridLayout); fTipShell.setBackground(display.getSystemColor(SWT.COLOR_INFO_BACKGROUND)); fTipComposite = new Composite(fTipShell, SWT.NONE); fTipComposite.setLayout(new GridLayout(3, false)); setupControl(fTipComposite);
private boolean considerBinding(IBinding binding, ASTNode node) { if (!(binding instanceof IVariableBinding)) return false; boolean result = Bindings.equals(fFieldBinding, ((IVariableBinding) binding).getVariableDeclaration()); if (!result || (fEncapsulateDeclaringClass && !fGetter.isEmpty() && !fSetter.isEmpty())) return result; AbstractTypeDeclaration type = ASTNodes.getParent(node, AbstractTypeDeclaration.class); if (type != null) { ITypeBinding declaringType = type.resolveBinding(); return !Bindings.equals(fDeclaringClassBinding, declaringType); } return true; }
invocation.setName(ast.newSimpleName(fSetter)); if (receiver != null) invocation.setExpression((Expression)fRewriter.createCopyTarget(receiver)); invocation.arguments().add(argument); if ("++".equals(operator)) { //$NON-NLS-1$ argument.setOperator(InfixExpression.Operator.PLUS); } else if ("--".equals(operator)) { //$NON-NLS-1$ argument.setOperator(InfixExpression.Operator.MINUS); } else { Assert.isTrue(false, "Should not happen"); //$NON-NLS-1$ } fReferencingSetter = true; MethodInvocation getter = ast.newMethodInvocation(); getter.setName(ast.newSimpleName(fGetter)); if (receiver != null) getter.setExpression((Expression)fRewriter.createCopyTarget(receiver)); argument.setLeftOperand(getter); argument.setRightOperand(ast.newNumberLiteral("1")); //$NON-NLS-1$ fReferencingGetter = true; return invocation;
if (fEncapsulateDeclaringClass) { comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_use_accessors); } else { comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_do_not_use_accessors); } if (fGenerateJavadoc) { comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_generate_comments); } final EncapsulateFieldDescriptor descriptor = RefactoringSignatureDescriptorFactory.createEncapsulateFieldDescriptor(project, description, comment.asString(), arguments, flags); arguments.put(JavaRefactoringDescriptorUtil.ATTRIBUTE_INPUT, JavaRefactoringDescriptorUtil.elementToHandle(project, fField)); arguments.put(ATTRIBUTE_VISIBILITY, Integer.valueOf(JdtFlags.getVisibilityCode(visibility)).toString()); arguments.put(ATTRIBUTE_INSERTION, Integer.valueOf(fInsertionIndex).toString()); if (fCreateSetter) { arguments.put(ATTRIBUTE_SETTER, fSetterName); } if (fCreateGetter) { arguments.put(ATTRIBUTE_GETTER, fGetterName); } arguments.put(ATTRIBUTE_COMMENTS, Boolean.valueOf(fGenerateJavadoc).toString()); arguments.put(ATTRIBUTE_DECLARING, Boolean.valueOf(fEncapsulateDeclaringClass).toString()); final DynamicValidationRefactoringChange result = new DynamicValidationRefactoringChange(descriptor, getName()); TextChange[] changes = fChangeManager.getAllChanges(); pm.beginTask(NO_NAME, changes.length);
//extern "C"{ //void func(); //} public void testLinkage2_Bug299482() throws Exception { fOptions.put(DefaultCodeFormatterConstants.FORMATTER_INSERT_SPACE_BEFORE_OPENING_BRACE_IN_LINKAGE_DECLARATION, DefaultCodeFormatterConstants.FALSE); assertFormatterResult(); } //extern "C" { //void func(); //} //extern "C" //{ //void func(); //} public void testLinkage3_Bug299482() throws Exception { fOptions.put(DefaultCodeFormatterConstants.FORMATTER_BRACE_POSITION_FOR_LINKAGE_DECLARATION, DefaultCodeFormatterConstants.NEXT_LINE); } //#define EMPTY1(x) //#define EMPTY2(x) //int main() { // EMPTY1(bool x = true); // EMPTY2(bool x = true); // return 0; //} //#define EMPTY1(x) //#define EMPTY2(x) //int main() { // EMPTY1(bool x = true); // EMPTY2(bool x = true); // return 0; //} public void testEmptyMacros_Bug361768() throws Exception { assertFormatterResult(); }
/***************************************************************************** * Copyright (c) 2019 Obeo. * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *****************************************************************************/ package org.eclipse.sirius.tests.sample.component.service; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.List; import java.util.function.Predicate; import org.eclipse.emf.common.notify.Notification; import org.eclipse.emf.ecore.EObject; import org.eclipse.gmf.runtime.notation.DrawerStyle; import org.eclipse.gmf.runtime.notation.Node; import org.eclipse.gmf.runtime.notation.NotationPackage; import org.eclipse.sirius.diagram.DDiagram; import org.eclipse.sirius.diagram.DDiagramElement; import org.eclipse.sirius.diagram.DNodeContainer; import org.eclipse.sirius.diagram.business.api.query.EObjectQuery; import org.eclipse.sirius.diagram.ui.business.api.view.SiriusGMFHelper; import org.eclipse.sirius.ext.base.Option;
components.addAll(component.getReferences2()); for (Component child : component.getChildren()) { components.addAll(getReference2Hierarchy(child)); } return components; } /** * Determines if a reference should be displayed. * * @param source The source component * @param sourceView The source view * @param targetView The target view * @return True if the reference should be displayed; otherwise false */ public boolean isReferenceToDisplay(Component source, DNodeContainer sourceView, DNodeContainer targetView) { if (!isIndirectlyCollapsed(sourceView) && !isIndirectlyCollapsed(targetView)) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer) { if (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion")) { for (DDiagramElement child2 : ((DNodeContainer) child).getOwnedDiagramElements()) { // Check if there is a shortest reference to display if (child2 instanceof DEdge) { DEdge edge = (DEdge) child2; if (edge.getTargetNode() == targetView) { return false; } } } } } } return true; } return false; }
import java.util.Collection; import org.eclipse.gmf.runtime.notation.Node; import org.eclipse.sirius.diagram.DNodeContainer; import org.eclipse.sirius.diagram.ui.tools.api.graphical.edit.styles.DrawerStyle; import org.eclipse.sirius.diagram.ui.tools.api.graphical.edit.styles.SiriusGMFHelper; public class MyClass { protected boolean isIndirectlyCollapsed(DNodeContainer container) { if (isContainerCollapsed(container)) { return true; } else if (container.eContainer() instanceof DNodeContainer && isContainerCollapsed((DNodeContainer) container.eContainer())) { return true; } else { return false; } } protected boolean isContainerCollapsed(DNodeContainer container) { Node gmfNode = SiriusGMFHelper.getGmfNode(container); if (gmfNode != null) { for (Object subNode : gmfNode.getChildren()) { if (subNode instanceof Node) { for (Object style : ((Node) subNode).getStyles()) { if (style instanceof DrawerStyle) { return ((DrawerStyle) style).isCollapsed(); } } } } } return false; } private void appendChildren(Component component, Collection<Component> allChildren) { // implementation } }
SWTBotGefEditPart parentEdgeTargetEditPart = editor.getEditPart("DC.2.1", AbstractDiagramElementContainerEditPart.class); DEdgeEditPart edgeEditPart = (DEdgeEditPart) ((AbstractDiagramElementContainerEditPart) edgeSourceEditPart.part()).getSourceConnections().get(0); assertTrue("The edge should be visible after diagram opening.", edgeEditPart.getFigure().isVisible()); collapseOrExpandContainer(parentEdgeSourceEditPart); assertFalse("The edge should be hidden after collapsing the container of the target of the edge.", edgeEditPart.getFigure().isVisible()); assertEquals("The edge already exists, even if it is not visible.", 1, ((AbstractDiagramElementContainerEditPart) edgeSourceEditPart.part()).getSourceConnections().size()); assertEquals("No edge from the collapsed container should appear because the collapse notification has not yet been registered.", 0, ((AbstractDiagramElementContainerEditPart) edgeSourceEditPart.part()).getTargetConnections().size());
private void collapseOrExpandContainer(SWTBotGefEditPart container) { ICondition editPartResizedCondition = new CheckEditPartResized(container); // Select the region contained in the container AbstractDiagramElementContainerEditPart part = (AbstractDiagramElementContainerEditPart) container.part(); GraphicalHelper.getAbsoluteBoundsIn100Percent(part); Point top = GraphicalHelper.getAbsoluteBoundsIn100Percent(part).getTop(); editor.click(top.getTranslated(0, 40)); // Collapse the region bot.waitUntil(new ICondition() { @Override public boolean test() throws Exception { IFigure handleLayer = LayerManager.Helper.find(part).getLayer(LayerConstants.HANDLE_LAYER); Point toggleFigureLocation; if (handleLayer != null) { for (Object figure : handleLayer.getChildren()) { if (figure instanceof CompartmentCollapseHandle) { toggleFigureLocation = ((CompartmentCollapseHandle) figure).getLocation(); if (toggleFigureLocation.x != 0 && toggleFigureLocation.y != 0) { // Use the center of the figure and click on it return true; } } } } return false; } }); // Click on the toggle figure bot.waitUntil(new ICondition() { @Override public boolean test() throws Exception { IFigure handleLayer = LayerManager.Helper.find(part).getLayer(LayerConstants.HANDLE_LAYER); Point toggleFigureLocation; if (handleLayer != null) { for (Object figure : handleLayer.getChildren()) { if (figure instanceof CompartmentCollapseHandle) { toggleFigureLocation = ((CompartmentCollapseHandle) figure).getLocation(); if (toggleFigureLocation.x != 0 && toggleFigureLocation.y != 0) { // Use the center of the figure and click on it editor.click(toggleFigureLocation); return true; } } } } return false; } }); }
private Repository remoteRepository; private URIish remoteURI; @Override @Before public void setUp() throws Exception { super.setUp(); final TestRepository<Repository> src = createTestRepository(); final String srcName = src.getRepository().getDirectory().getName(); ServletContextHandler app = server.addContext("/git"); GitServlet gs = new GitServlet(); gs.setRepositoryResolver((HttpServletRequest req, String name) -> { if (!name.equals(srcName)) { throw new RepositoryNotFoundException(name); } final Repository db = src.getRepository(); db.incrementOpen(); return db; }); gs.setReceivePackFactory(new DefaultReceivePackFactory() { @Override public ReceivePack create(HttpServletRequest req, Repository db) throws ServiceNotEnabledException, ServiceNotAuthorizedException { ReceivePack rp = super.create(req, db); rp.sendError("message line 1"); rp.sendError("no soup for you!"); rp.sendError("come back next year!"); return rp; } }); app.addServlet(new ServletHolder(gs), "/*"); }
private URIish remoteURI; @Override @Before public void setUp() throws Exception { super.setUp(); final TestRepository<Repository> src = createTestRepository(); final String srcName = src.getRepository().getDirectory().getName(); ServletContextHandler app = server.addContext("/git"); GitServlet gs = new GitServlet(); gs.setRepositoryResolver((HttpServletRequest req, String name) -> { if (!name.equals(srcName)) throw new RepositoryNotFoundException(name); final Repository db = src.getRepository(); db.incrementOpen(); return db; }); gs.setReceivePackFactory(new DefaultReceivePackFactory() { @Override public ReceivePack create(HttpServletRequest req, Repository db) throws ServiceNotEnabledException, ServiceNotAuthorizedException { ReceivePack rp = super.create(req, db); rp.sendError("message line 1"); rp.sendError("no soup for you!"); rp.sendError("come back next year!"); return rp; } }); app.addServlet(new ServletHolder(gs), "/*"); server.setUp(); }
private void verifyObjectsOrder(ObjectId objectsOrder[]) { final List<PackIndex.MutableEntry> entries = new ArrayList<>(); for (MutableEntry me : pack) { entries.add(me.cloneEntry()); } Collections.sort(entries, (MutableEntry o1, MutableEntry o2) -> Long.signum(o1.getOffset() - o2.getOffset())); int i = 0; for (MutableEntry me : entries) { assertEquals(objectsOrder[i++].toObjectId(), me.toObjectId()); } }
public Optional<T> getFirstResult() { Collection<T> list = getResult(); if (list != null) { return list.stream().findFirst(); } return Optional.empty(); }
protected void setResult(Collection<T> newUserSelection) { result = newUserSelection; }
if (name1 == null) { name1 = ""; } if (name2 == null) { name2 = ""; } return coll.compare(name1, name2); // Find primary feature for (AboutInfo feature : features) { if (feature.getFeatureId().equals(primaryFeatureId)) { setInitialSelection(feature); return; } } // set a safe default setInitialSelection(Collections.emptyList());
private boolean matches(IService service, Class<?>[] argumentTypes) { assert service.getNumberOfParameters() != argumentTypes.length; boolean result = true; final List<IType> parameterTypes = service.getParameterTypes(queryEnvironment); for (int i = 0; i < parameterTypes.size() && result; i++) { if (argumentTypes[i] != null && !parameterTypes.get(i).isAssignableFrom(new ClassType(queryEnvironment, argumentTypes[i]))) { result = false; break; } } return result; } private static DiffPreferencesInfo updateDefaults(DiffPreferencesInfo input) { DiffPreferencesInfo result = DiffPreferencesInfo.defaults(); try { for (Field field : update.getClass().getDeclaredFields()) { if (skipField(field)) { continue; } Object newVal = field.get(update); if (newVal != null) { field.set(def, newVal); } } } catch (IllegalAccessException e) { e.printStackTrace(); } return def; } public UUID getAnonymousId() { UUID result = anonymousId; if (result == null) { synchronized (this) { result = anonymousId; if (result == null) { result = anonymousId = readOrCreateAnonymousId(); } } } return result; } public abstract class AbstractSelectionDialog<T> extends TrayDialog { private Collection<T> result; private List<T> initialSelection; private String title; private String message = ""; private int dialogBoundsStrategy = Dialog.DIALOG_PERSISTLOCATION | Dialog.DIALOG_PERSISTSIZE; private IDialogSettings dialogBoundsSettings = null; protected AbstractSelectionDialog(Shell parentShell) { super(parentShell); } public Collection<T> getResult() { return result != null ? result : Collections.emptyList(); } }
public Optional<T> getFirstResult() { Collection<T> list = getResult(); if (list == null) { return Optional.empty(); } Iterator<T> iterator = list.iterator(); if (iterator.hasNext()) { return Optional.of(iterator.next()); } return Optional.empty(); }
private static DiffPreferencesInfo updateDefaults(DiffPreferencesInfo input) { DiffPreferencesInfo result = DiffPreferencesInfo.defaults(); try { for (Field field : update.getClass().getDeclaredFields()) { if (skipField(field)) { continue; } Object newVal = field.get(update); if (newVal != null) { field.set(def, newVal); } } } catch (IllegalAccessException e) { e.printStackTrace(); } return def; }
private boolean matches(IService service, Class<?>[] argumentTypes) { assert service.getNumberOfParameters() != argumentTypes.length; boolean result = true; final List<IType> parameterTypes = service.getParameterTypes(queryEnvironment); for (int i = 0; i < parameterTypes.size() && result; i++) { if (argumentTypes[i] != null && !parameterTypes.get(i).isAssignableFrom(new ClassType(queryEnvironment, argumentTypes[i]))) { result = false; break; } } return result; } private static DiffPreferencesInfo updateDefaults(DiffPreferencesInfo input) { DiffPreferencesInfo result = DiffPreferencesInfo.defaults(); try { for (Field field : update.getClass().getDeclaredFields()) { if (skipField(field)) { continue; } Object newVal = field.get(update); if (newVal != null) { field.set(def, newVal); } } } catch (IllegalAccessException e) { e.printStackTrace(); } return def; } for (Object o : callbacks) { try { Object result = results.get(o); if (o instanceof AsyncCallback) { @SuppressWarnings("unchecked") AsyncCallback<Object> cb = (AsyncCallback<Object>) o; cb.onSuccess(result); } else { @SuppressWarnings("unchecked") com.google.gwtjsonrpc.common.AsyncCallback<Object> cb = (com.google.gwtjsonrpc.common.AsyncCallback<Object>) o; cb.onSuccess(result); } } catch (Throwable t) { if (caught == null) { caught = t; } } } if (caught != null) { if (caught instanceof RuntimeException) { throw (RuntimeException) caught; } else if (caught instanceof Error) { throw (Error) caught; } else { throw new RuntimeException(caught); } } protected void setResult(T... newUserSelection) { result = null; if (newUserSelection != null) { result = Arrays.asList(newUserSelection); } }
import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } }
ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } @Test public void testShouldNotSearchPacksAgainTheSecondTime() throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); assertTrue(dir.searchPacksAgain(dir.packList.get())); // Make sure that the modified and read timestamps so that a full // file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION,null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir(
assertNotNull(fIterator); assertEquals(fIterator, fIterator); try (CtfIterator obj = (CtfIterator) fTrace.createIterator();) { assertNotNull(obj); assertNotEquals(fIterator, obj); CtfLocation ctfLocation1 = new CtfLocation(new CtfLocationInfo(1, 0)); obj.setLocation(ctfLocation1); obj.increaseRank(); assertEquals(fIterator, obj); } CtfTmfTrace trace = CtfTmfTestTraceUtils.getTrace(CtfTestTrace.FUNKY_TRACE); assertNotNull(trace); try(CtfIterator funky = (CtfIterator) trace.createIterator()){ assertNotEquals(fIterator, funky); } try(CtfIterator iter = (CtfIterator) fTrace.createIterator();){ CTFTrace otherTrace = new CTFTrace(fTrace.getPath()); try(CTFTraceReader tr = new CTFTraceReader(otherTrace)){ assertNotEquals(iter, tr); } } trace.dispose(); try(CtfIterator iter1 = (CtfIterator) fTrace.createIterator(); CtfIterator iter2 = (CtfIterator) fTrace.createIterator()){ assertEquals(iter1, iter2); iter2.setRank(2); assertNotEquals(iter1, iter2); }
assertNotNull(obj); assertNotEquals(fIterator, obj); CtfLocation ctfLocation1 = new CtfLocation(new CtfLocationInfo(1, 0)); obj.setLocation(ctfLocation1); obj.increaseRank(); assertEquals(fIterator, obj); } CtfTmfTrace trace = CtfTmfTestTraceUtils.getTrace(CtfTestTrace.FUNKY_TRACE); assertNotNull(trace); try (CtfIterator funky = (CtfIterator) trace.createIterator()) { assertNotEquals(fIterator, funky); } try (CtfIterator iter = (CtfIterator) fTrace.createIterator()) { CTFTrace otherTrace = new CTFTrace(fTrace.getPath()); try (CTFTraceReader tr = new CTFTraceReader(otherTrace)) { assertNotEquals(iter, tr); } } trace.dispose(); try (CtfIterator iter1 = (CtfIterator) fTrace.createIterator(); CtfIterator iter2 = (CtfIterator) fTrace.createIterator()) { assertEquals(iter1, iter2); iter2.setRank(2); assertNotEquals(iter1, iter2); } /** * Run the boolean equals(Object) method test. Compare with an empty object. */ @Test public void testEquals_empty() {
public static double ceil(double d) { final long bits = Double.doubleToRawLongBits(d); int highBits = (int) (bits >>> 32); // high word of d int lowBits = (int) bits; // low word of d int exp = ((highBits >> 20) & 0x7ff) - 0x3ff; // value of exponent /* negative exponent */ if (exp < 0) { if (HUGE + d > 0.0) { if (highBits < 0) { // if |d| < 1 return -0 highBits = 0x80000000; } else if ((highBits | lowBits) != 0) { // raise inexact if d != 0, this is ignored by Java highBits = 0x3ff00000; // return 1 } lowBits = 0; } } /* exponent in range [0, 20) */ else if (exp < 0x014) { i = (0x000fffff) >> exp; } return d; // d is integral } /* exponent in range [21,51] */ else { i = (0xffffffff) >> (exp - 0x014); /* d is integral */ if ((lowBits & i) == 0) { return d; } /* raise inexact flag: this is ignored by Java */ if (HUGE + d > 0.0) { if (highBits > 0) { if (exp == 0x014) { highBits +=1; } else { int j = lowBits + (0x1 << (0x34 - exp)); // careful, should be unsigned if (j < lowBits) { highBits += 0x1; // carry occurred } lowBits = j; } } lowBits &= (~i); } } return Double.longBitsToDouble(((long)highBits << 32) | lowBits);
// if ret == true, then currentEvent is non-null if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); /* Update the current location accordingly */ if (ret) { fCurLocation = new CtfLocation(new CtfLocationInfo(Objects.requireNonNull(currentEvent).getTimestamp().getValue(), 0)); } else { fCurLocation = NULL_LOCATION; } return ret;
package org.eclipse.jgit.internal.storage.file; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.concurrent.Callable; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; import org.eclipse.jgit.internal.storage.pack.PackWriter; import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { // Test code here }
package org.eclipse.jgit.internal.storage.file; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.concurrent.Callable; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; import org.eclipse.jgit.internal.storage.pack.PackWriter; import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false); } }
import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); // Test code goes here } } }
import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; import java.util.Arrays; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(Boolean.TRUE, Boolean.FALSE); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime() throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); // test code continues... } }
FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); assertTrue(dir.searchPacksAgain(dir.packList.get())); // Make sure that the modified and read timestamps so that a full // file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository<>(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir(final ObjectDirectory dir) { Callable<ObjectId> callable = new Callable<ObjectId>() { public ObjectId call() throws Exception { return dir.newInserter().insert(Constants.OBJ_BLOB, new byte[0]); } }; return Collections.singleton(callable); }
// file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir(final ObjectDirectory dir) { Callable<ObjectId> callable = new Callable<ObjectId>() { public ObjectId call() throws Exception { return dir.newInserter().insert(Constants.OBJ_BLOB, new byte[0]); } }; return Collections.nCopies(4, callable); }
assertTrue(traceAdapter.isThereATraceBetween(_A, _B, upDatedTraceModel)); // Clear selection view SelectionView.getOpenedView().clearSelection(); // create a selection with class A List<Object> selection = new ArrayList<>(); selection.add(_A); // test that internal links show for direct elements ToggleTransitivityHandler.setTraceViewTransitive(false); DisplayInternalLinksHandler.showInternalLinks(true); DiagramTextProviderHandler provider = new DiagramTextProviderHandler(); String directlyConnectedElements = provider.getDiagramText(selection); assertTrue(directlyConnectedElements.equals(EXPECTED_TEXT_FOR_INTERNAL_LINKS)); }
assertEquals(1331668250328561095L, middleEvent.getTimestamp().toNanos()); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 1L))); CtfTmfEvent doubleEvent = iterator.getCurrentEvent(); assertNotNull(doubleEvent); assertEquals(1331668247328921944L, doubleEvent.getTimestamp().toNanos()); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); assertEquals("sched_switch", doubleEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 9001000000L))); CtfTmfEvent overNineThousandEvent = iterator.getCurrentEvent(); assertNotNull(overNineThousandEvent); assertEquals(1331668247328925363L, overNineThousandEvent.getTimestamp().toNanos()); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", overNineThousandEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 4L))); CtfTmfEvent quadEvent = iterator.getCurrentEvent(); assertNotNull(quadEvent); assertEquals(new CtfLocationInfo(1331668247328921944L, 1L), iterator.getLocation().getLocationInfo());
assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 1L))); CtfTmfEvent doubleEvent = iterator.getCurrentEvent(); assertNotNull(doubleEvent); assertEquals(1331668247328921944L, doubleEvent.getTimestamp().toNanos()); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); // test that events will be in cpu order assertEquals("sched_switch", doubleEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 9001000000L))); CtfTmfEvent overNineThousandEvent = iterator.getCurrentEvent(); assertNotNull(overNineThousandEvent); assertEquals(1331668247328925363L, overNineThousandEvent.getTimestamp().toNanos()); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", overNineThousandEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 4L))); CtfTmfEvent quadEvent = iterator.getCurrentEvent(); assertNotNull(quadEvent); assertEquals(1331668247328925363L, quadEvent.getTimestamp().toNanos()); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", quadEvent.getName()); assertFalse(iterator.seek(CtfLocation.INVALID_LOCATION));
} } catch (CTFException e) { Activator.getDefault().logError(e.getMessage(), e); return false; } /* * Check if there is already one or more events for that timestamp, and * assign the location index correctly */ long index = 0; ITmfEvent currentEvent = getCurrentEvent(); ret &= (currentEvent != null); ITmfEvent previousEvent = currentEvent; for (long i = 0; ret && i < ctfLocationData.getIndex(); i++) { // if ret == true, then currentEvent is non-null if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { index = 0; break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); } /* Update the current location accordingly */ if (ret) { fCurLocation = new CtfLocation(new CtfLocationInfo(Objects.requireNonNull(previousEvent).getTimestamp().getValue(), index)); } else { fCurLocation = NULL_LOCATION; }
// if ret == true, then currentEvent is non-null if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { index = 0; break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); } /* Update the current location accordingly */ if (ret) { fCurLocation = new CtfLocation(new CtfLocationInfo(Objects.requireNonNull(currentEvent).getTimestamp().getValue(), index)); } else { fCurLocation = NULL_LOCATION; } return ret;
private boolean checkNullDefaultFlow() { return !this.switchLabeledRules; } @Override public FlowInfo analyseCode(BlockScope currentScope, FlowContext flowContext, FlowInfo flowInfo) { try { flowInfo = this.expression.analyseCode(currentScope, flowContext, flowInfo); if ((this.expression.implicitConversion & TypeIds.UNBOXING) != 0 || (this.expression.resolvedType != null && (this.expression.resolvedType.id == T_JavaLangString || this.expression.resolvedType.isEnum()))) { this.expression.checkNPE(currentScope, flowContext, flowInfo, 1); } SwitchFlowContext switchContext = (SwitchFlowContext) flowContext; if (this.expression.resolvedType != null && this.expression.resolvedType.isBaseType()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.constant != Constant.NotAConstant) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.resolvedType != null && this.expression.resolvedType.isEnum()) { flowInfo = flowInfo.mergedWith(switchContext.initsOnBreak); } if (this.expression.res
import java.io.IOException; import javax.servlet.Filter; import javax.servlet.FilterChain; import javax.servlet.FilterConfig; import javax.servlet.ServletException; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class MyFilter implements Filter { private FilterConfig filterConfig; @Override public void init(FilterConfig filterConfig) throws ServletException { this.filterConfig = filterConfig; } @Override public void destroy() { // Cleanup resources } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest httpRequest = (HttpServletRequest) request; HttpServletResponse httpResponse = (HttpServletResponse) response; chain.doFilter(httpRequest, httpResponse); httpResponse.sendError(HttpServletResponse.SC_NOT_FOUND); } }
package org.eclipse.tracecompass.internal.tmf.ui.views; public interface ITmfTimeNavigationProvider { void horizontalScroll(boolean left); }
public interface ITmfZoomToSelectionProvider { void zoomToSelection(); }
/* * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.views.handler; import org.eclipse.core.commands.AbstractHandler; import org.eclipse.core.commands.ExecutionEvent; import org.eclipse.core.commands.ExecutionException; import org.eclipse.tracecompass.tmf.ui.views.TmfView; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.IWorkbenchWindow; import org.eclipse.ui.PlatformUI; import org.eclipse.ui.handlers.HandlerUtil; /** * Base handler, makes sure we have a timegraph control selected * * @author Matthew Khouzam */ abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute(ExecutionEvent event) throws ExecutionException { // Check if we are closing down IWorkbenchWindow window = PlatformUI.getWorkbench().getActiveWorkbenchWindow(); if (window == null) { return null; } IWorkbenchPart part = HandlerUtil.getActivePart(event); if (part instanceof TmfView) { execute((TmfView) part); } return null; } public abstract void execute(TmfView timegraph); }
abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute(ExecutionEvent event) throws ExecutionException { IWorkbenchWindow window = PlatformUI.getWorkbench().getActiveWorkbenchWindow(); if (window == null) { return null; } IWorkbenchPart part = HandlerUtil.getActivePart(event); if (part instanceof TmfView) { execute((TmfView) part); } return null; } public abstract void execute(TmfView view); }
import org.eclipse.tracecompass.internal.tmf.ui.views.ITmfTimeZoomProvider; import org.eclipse.tracecompass.tmf.ui.views.TmfView; public class TmfViewZoomInHandler extends TmfViewBaseHandler { @Override public void execute(TmfView view) { ITmfTimeZoomProvider zoomer = view.getAdapter(ITmfTimeZoomProvider.class); if (zoomer != null) { zoomer.zoom(true); } } }
import org.eclipse.sirius.tests.swtbot.support.api.editor.SWTBotSiriusDiagramEditor; import org.eclipse.sirius.tests.swtbot.support.utils.SWTBotUtils; import org.eclipse.swt.SWT; import org.eclipse.swtbot.eclipse.gef.finder.widgets.SWTBotGefEditPart; public class EditPartSelectionTest extends AbstractSiriusSwtBotGefTestCase { private static final String DATA_UNIT_DIR = "/data/unit/selection/"; private static final String MODEL = "TestSelection.ecore"; private static final String SESSION_FILE = "TestSelection.aird"; private static final String VSM_FILE = "My.odesign"; private static final String REPRESENTATION_DECRIPTION_NAME = "Entities"; private static final String REPRESENTATION_NAME = "diagram"; private static final PrecisionPoint INITIAL_NODE_CENTER_POSITION = new PrecisionPoint(856.0, 412.0); private Session session; @Override protected void onSetUpBeforeClosingWelcomePage() throws Exception { // Code goes here } }
import org.eclipse.egerrit.core.rest.CommentRange; import com.google.gwtorm.client.Column; public class CommentRange { @Column(id = 1) protected int startLine; @Column(id = 2) protected int startCharacter; @Column(id = 3) protected int endLine; @Column(id = 4) protected int endCharacter; public CommentRange() { } public CommentRange(int sl, int sc, int el, int ec) { startLine = sl; startCharacter = sc; endLine = el; endCharacter = ec; } public int getStartLine() { return startLine; } public int getStartCharacter() { return startCharacter; } public int getEndLine() { return endLine; } public int getEndCharacter() { return endCharacter; } public void setStartLine(int sl) { startLine = sl; } public void setStartCharacter(int sc) { startCharacter = sc; } public void setEndLine(int el) { endLine = el; } public void setEndCharacter(int ec) { endCharacter = ec; } }
assertNull(getCurrentEvent(iterator)); assertEquals(0L, iterator.getCurrentTimestamp()); assertFalse(iterator.advance()); CtfLocationInfo middleLocation = new CtfLocationInfo(1331668250328561095L, 0L); assertTrue(iterator.seek(middleLocation)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561095L, getTimestampInNanos(event)); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); CtfLocationInfo middleLocationIndexedOne = new CtfLocationInfo(1331668250328561095L, 1L); assertTrue(iterator.seek(middleLocationIndexedOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561761L, getTimestampInNanos(event)); assertEquals(1331668250328561761L, iterator.getCurrentTimestamp()); assertEquals(new CtfLocationInfo(1331668250328561761L, 0L), iterator.getLocation().getLocationInfo()); CtfLocationInfo duplicateLocationIndexedOne = new CtfLocationInfo(1331668247328921944L, 1L); assertTrue(iterator.seek(duplicateLocationIndexedOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328921944L, getTimestampInNanos(event));
assertTrue(iterator.seek(middleLocation)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561095L, getTimestampInNanos(event)); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); CtfLocationInfo middleLocationIndexeOne = new CtfLocationInfo(1331668250328561095L, 1L); assertTrue(iterator.seek(middleLocationIndexeOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561761L, getTimestampInNanos(event)); assertEquals(1331668250328561761L, iterator.getCurrentTimestamp()); assertEquals(new CtfLocationInfo(1331668250328561761L, 0L), iterator.getLocation().getLocationInfo()); // double timestamp at 15:50:47.328921944 CtfLocationInfo duplicateLocationIndexedOne = new CtfLocationInfo(1331668247328921944L, 1L); assertTrue(iterator.seek(duplicateLocationIndexedOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328921944L, getTimestampInNanos(event)); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); // test that events will be in cpu order assertEquals("sched_switch", event.getName()); assertEquals(duplicateLocationIndexedOne, iterator.getLocation().getLocationInfo());
Rectangle getBoundsInPixels () { computeRuns(null); int width = 0; if (wrapWidth != -1) { width = wrapWidth; } else { for (int line=0; line<runs.length; line++) { width = Math.max(width, lineWidth[line] + getLineIndent(line)); } } return new Rectangle (0, 0, width, lineY[lineY.length - 1]); } package com.google.gerrit.server.query.change; import com.google.gerrit.reviewdb.client.Change; import com.google.gerrit.server.index.ChangeField; import com.google.gerrit.server.index.IndexPredicate; import com.google.gwtorm.server.OrmException; public class DependsOnPredicate extends IndexPredicate<ChangeData> { DependsOnPredicate(String prefix) { super(ChangeField.DEPENDS_ON, prefix); } @Override public boolean match(ChangeData object) throws OrmException { Change c = object.change(); try { for (FooterLine f : c.commitFooters()) { if (f.getKey().equals()) { return f.getValue(); } } } catch (NoSuchChangeException | IOException e) { } return null; } @Override public int getCost() { return 1; } } } progress.endTask(); return new SiteIndexer.Result(sw, ok.get(), done.get(), failed.get()); } private List<Project.NameKey> collectProjects(ProgressMonitor progress) throws OrmException { progress.beginTask("Collecting projects", ProgressMonitor.UNKNOWN); List<Project.NameKey> names = new ArrayList<>(); for (Project.NameKey nameKey : projectCache.all()) { names.add(nameKey); } progress.endTask(); return names; } CtfLocationInfo duplicateLocationOutOfBounds = new CtfLocationInfo(1331668247328921944L, 4L); assertTrue(iterator.seek(duplicateLocationOutOfBounds)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328925363L, getTimestampInNanos(event)); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", event.getName()); // next event location assertEquals(new CtfLocationInfo(1331668247328925363L, 0L), iterator.getLocation().getLocationInfo()); Ctf
import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import org.eclipse.tracecompass.ctf.core.event.CtfTmfEvent; import org.eclipse.tracecompass.ctf.core.iterator.CtfIterator; import org.eclipse.tracecompass.ctf.core.trace.CtfLocation; import org.eclipse.tracecompass.ctf.core.trace.CtfLocationInfo; import org.eclipse.tracecompass.ctf.core.trace.CtfLocation.INVALID_LOCATION; import org.eclipse.tracecompass.ctf.core.trace.CtfTmfTrace; import org.junit.After; import org.junit.Before; import org.junit.Test; public class CtfIteratorTest { private CtfIterator fIterator; private CtfTmfTrace fTrace; @Before public void setUp() throws Exception { fTrace = new CtfTmfTrace(); fIterator = new CtfIterator(fTrace); } @After public void tearDown() throws Exception { fIterator.dispose(); fTrace.dispose(); } @Test public void testGetCurrentEvent() { CtfTmfEvent event = new CtfTmfEvent(); fIterator.setCurrentEvent(event); assertEquals(event, fIterator.getCurrentEvent()); } @Test public void testGetTimestampInNanos() { CtfTmfEvent event = new CtfTmfEvent(); event.setTimestamp(1331668247328925363L); assertEquals(1331668247328925363L, getTimestampInNanos(event)); } @Test public void testSetLocation() { CtfLocation location = new CtfLocation(new CtfLocationInfo(1, 0)); fIterator.setLocation(location); } private static long getTimestampInNanos(CtfTmfEvent event) { return event.getTimestamp().toNanos(); } }
import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import org.eclipse.tracecompass.ctf.core.event.CtfTmfEvent; import org.eclipse.tracecompass.ctf.core.iterator.CtfIterator; import org.eclipse.tracecompass.ctf.core.trace.CtfLocation; import org.eclipse.tracecompass.ctf.core.trace.CtfLocationInfo; import org.eclipse.tracecompass.tmf.core.trace.location.ITmfLocation; import org.junit.Test; public class CtfIteratorTest { private CtfIterator fIterator; public CtfIteratorTest() { fIterator = new CtfIterator(); } @Test public void testGetCurrentEvent() { CtfTmfEvent event = new CtfTmfEvent(); fIterator.setCurrentEvent(event); assertEquals(event, getCurrentEvent(fIterator)); } @Test public void testGetTimestampInNanos() { CtfTmfEvent event = new CtfTmfEvent(); event.setTimestamp(1331668247328925363L); assertEquals(1331668247328925363L, getTimestampInNanos(event)); } @Test public void testSetLocation() { CtfLocation location = new CtfLocation(new CtfLocationInfo(1, 0)); fIterator.setLocation(location); } private static CtfTmfEvent getCurrentEvent(CtfIterator iterator) { return iterator.getCurrentEvent(); } private static long getTimestampInNanos(CtfTmfEvent event) { return event.getTimestamp().toNanos(); } }
public boolean isReferenceToDisplay(Component source, DNodeContainer sourceView, DNodeContainer targetView) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer && (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion"))) { for (DDiagramElement grandchild : ((DNodeContainer) child).getOwnedDiagramElements()) { if (isReferenceDisplayedByChild((DNodeContainer) grandchild, targetView)) { return false; } } } } return true; }
// if (!isIndirectlyCollapsed(sourceView) && !isIndirectlyCollapsed(targetView)) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer && (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion"))) { for (DDiagramElement grandchild : ((DNodeContainer) child).getOwnedDiagramElements()) { if (isReferenceDisplayedByChild((DNodeContainer) grandchild, targetView)) { return false; } } } } return true; // } // return false;
/** * Copyright (c) 2010, 2019 THALES GLOBAL SERVICES * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - Initial API and implementation */ package org.eclipse.sirius.tests.swtbot.support.api.editor; import java.util.Iterator; import java.util.List; import java.util.concurrent.atomic.AtomicBoolean; import org.eclipse.core.runtime.IAdaptable; import org.eclipse.draw2d.FigureCanvas; import org.eclipse.draw2d.IFigure; import org.eclipse.draw2d.Label; import org.eclipse.draw2d.LightweightSystem; import org.eclipse.draw2d.geometry.Point; import org.eclipse.draw2d.text.TextFlow; import org.eclipse.gef.EditPart; import org.eclipse.gef.GraphicalEditPart; import org.eclipse.gef.GraphicalViewer; import org.eclipse.sirius.ext.gmf.runtime.gef.ui.figures.SiriusWrapLabel; import org.eclipse.sirius.tests.swtbot.support.api.widget.SWTBotSiriusFigureCanvas;
/* * Copyright (c) 2012, 2019 THALES GLOBAL SERVICES * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - Initial API and implementation */ package org.eclipse.sirius.tests.swtbot.support.api.widget; import java.util.concurrent.atomic.AtomicBoolean; import org.eclipse.draw2d.FigureCanvas; import org.eclipse.draw2d.LightweightSystem; import org.eclipse.swt.SWT; import org.eclipse.swt.events.KeyEvent; import org.eclipse.swt.widgets.Canvas; import org.eclipse.swt.widgets.Event; import org.eclipse.swt.widgets.Text; import org.eclipse.swtbot.eclipse.gef.finder.widgets.SWTBotGefFigureCanvas; import org.eclipse.swtbot.swt.finder.exceptions.WidgetNotFoundException; import org.eclipse.swtbot.swt.finder.finders.UIThreadRunnable; import org.eclipse.swtbot.swt.finder.results.Result; import org.eclipse.swtbot.swt.finder.results.VoidResult; import org.eclipse.swtbot.swt.finder.utils.SWTUtils; /**
/***************************************************************************** * Copyright (c) 2019 THALES GLOBAL SERVICES. * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *****************************************************************************/ package org.eclipse.sirius.tests.swtbot; import org.eclipse.draw2d.IFigure; import org.eclipse.draw2d.geometry.PrecisionPoint; import org.eclipse.draw2d.geometry.Rectangle; import org.eclipse.gef.GraphicalEditPart; import org.eclipse.gef.LayerConstants; import org.eclipse.gef.editparts.LayerManager; import org.eclipse.gmf.runtime.diagram.ui.editparts.AbstractBorderedShapeEditPart; import org.eclipse.gmf.runtime.diagram.ui.editparts.ConnectionEditPart; import org.eclipse.gmf.runtime.diagram.ui.editparts.IGraphicalEditPart; import org.eclipse.gmf.runtime.draw2d.ui.figures.PolylineConnectionEx; import org.eclipse.sirius.business.api.session.Session; import org.eclipse.sirius.diagram.DDiagram; import org.eclipse.sirius.diagram.ui.edit.api.part.AbstractDiagramBorderNodeEditPart; */
Fixed Code: ```java @Override protected void tearDown() throws Exception { assertEquals("Test triggered errors.", 0, loggedErrors.get()); Platform.removeLogListener(errorLogListener); super.tearDown(); } public void testUTF8InputEven() throws Exception { processConsoleUTF8Input("", 5000); } public void testUTF8InputOdd() throws Exception { processConsoleUTF8Input("", 5001); } ```
import org.eclipse.debug.tests.AbstractDebugTest; /** * Tests the {@link StreamsProxy}. */ public class StreamsProxyTests extends AbstractDebugTest { public StreamsProxyTests() { super(StreamsProxyTests.class.getSimpleName()); } public StreamsProxyTests(String name) { super(name); } /** * Test console receiving UTF-8 output from process where two-byte UTF-8 * characters start at even offsets. * * @throws Exception if the test gets in trouble */ public void testReceiveUTF8Even() throws Exception { // 4500 characters results in 9000 byte of output which should be more // than most common buffer sizes. receiveUTF8Test("", 4500); } /** * Test console receiving UTF-8 output from process where two-byte UTF-8 * characters start at odd offsets. * * @throws Exception if the test gets in trouble */ public void testReceiveUTF8Odd() throws Exception { // 4500 characters results in 9000 byte of output which should be more // than most common buffer sizes. receiveUTF8Test("", 4500); } }
public void testSet() { List<String> reference = Arrays.asList("Pomme", "Peche", "Poire", "Banane"); List<String> test = createList(reference); assertEquals(reference, test); assertEquals(reference, test); test.set(0, "pomme"); assertNotEquals(reference, test); try { test.set(-1, "pomme"); fail("Should not get here"); } catch (IndexOutOfBoundsException e) { // correct flow } try { test.set(5, "pomme"); fail("Should not get here"); } catch (IndexOutOfBoundsException e) { // correct flow } }
assertEquals("yo", iterator.next()); iterator.previous(); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); iterator.next(); iterator.next(); iterator.next(); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.previous(); assertEquals(1, iterator.previousIndex()); assertEquals(4, iterator.nextIndex()); try { iterator.remove(); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.set("hej"); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.add("hi"); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow }
package org.eclipse.tracecompass.internal.ctf.core.utils; import java.util.Collection; import java.util.Iterator; import java.util.LinkedHashMap; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; /** * Sparse list, a list that supports * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()} , {@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li> * <li>{@link #lastIndexOf(Object)}</li> * </ul> */ public class SparseList<E> implements List<E> { private final Map<Integer, E> elements; public SparseList() { elements = new LinkedHashMap<>(); } @Override public int size() { return elements.size(); } @Override public boolean isEmpty() { return elements.isEmpty(); } @Override public boolean contains(Object o) { return elements.containsValue(o); } @Override public Iterator<E> iterator() { return elements.values().iterator(); } @Override public Object[] toArray() { return elements.values().toArray(); } @Override public <T> T[] toArray(T[] a) { return elements.values().toArray(a); } @Override public boolean add(E e) { int index = elements.size(); elements.put(index, e); return true; } @Override public boolean remove(Object o) { for (Iterator<Entry<Integer, E>> iterator = elements.entrySet().iterator(); iterator.hasNext();) { Entry<Integer, E> entry = iterator.next(); if (Objects.equals(entry.getValue(), o)) { iterator.remove(); return true; } } return false; } @Override public boolean containsAll(Collection<?> c) { return elements.values().containsAll(c); } @Override public boolean addAll(Collection<? extends E> c) { int index = elements.size(); for (E e :
protected int getThreshold() { if (!selectFeedbackEnabled) { if (getViewer().getControl() instanceof Table) return ((Table) getViewer().getControl()).getItemHeight() / 2; if (getViewer().getControl() instanceof Tree) return ((Tree) getViewer().getControl()).getItemHeight() / 2; if (getViewer().getControl() instanceof List) return ((List) getViewer().getControl()).getItemHeight() / 2; } // fixed default threshold return 5; }
public GenericReadOnlyListIterator(List<E> list, int start, int end) { fList = list; fCursor = start; fStart = start; fEnd = end; }
Fixed Code: ```java package org.eclipse.tracecompass.internal.ctf.core.utils; import java.util.Collection; import java.util.HashMap; import java.util.Iterator; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; /** * Sparse list, a list optimized for when most of the data is null. * * Note: this iterates in the sorted order. * * This implementation supports: * - add(Object) * - contains(Object) * - clear() * - iterator() * - isEmpty() * - toArray() * - toArray(Object[]) */ public class SparseList<E> implements List<E> { // Implementation details omitted for brevity } ``` Refactor the Buggy Code using the Review without comments
public class SparseList<E> implements List<E> { private final Map<Integer, E> fInnerEvents = new HashMap<>(); private int fSize = 0; public SparseList(List<E> events) { ensureSize(events.size()); for (int i = 0; i < events.size(); i++) { E element = events.get(i); fInnerEvents.put(i, element); } } // other methods... }
public class SparseList<E> implements List<E> { private final Map<Integer, E> fElements = new HashMap<>(); private int fSize = 0; public SparseList(List<E> elements) { ensureSize(elements.size()); for (int i = 0; i < elements.size(); i++) { E element = elements.get(i); if (element != null) { set(i, element); } } } public SparseList() { // Do nothing } @Override public int size() { return fSize; } @Override public boolean isEmpty() { return fSize == 0; } @Override public boolean contains(Object o) { return fElements.containsValue(o); } @Override public Iterator<E> iterator() { return fElements.values().iterator(); } @Override public Object[] toArray() { return fElements.values().toArray(); } @Override public <T> T[] toArray(T[] a) { return fElements.values().toArray(a); } @Override public boolean add(E e) { set(fSize, e); return true; } @Override public boolean remove(Object o) { for (int i = 0; i < fSize; i++) { if (Objects.equals(fElements.get(i), o)) { remove(i); return true; } } return false; } @Override public boolean containsAll(Collection<?> c) { return fElements.values().containsAll(c); } @Override public boolean addAll(Collection<? extends E> c) { for (E element : c) { add(element); } return true; } @Override public boolean addAll(int index, Collection<? extends E> c) { ensureSize(fSize + c.size()); for (E element : c) { add(index++, element); } return true; } @Override public boolean removeAll(Collection<?> c) { boolean modified = false; for (int i = 0; i < fSize; i++) { if (c.contains(fElements.get(i))) { remove(i); modified = true; } }
public boolean contains(Object o) { return fInnerEvents.containsValue(o); }
public boolean add(E e) { synchronized (this) { fInnerEvents.put(fSize, e); fSize++; } return true; }
public boolean containsAll(Collection<?> c) { return fInnerEvents.values().containsAll(c); }
public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { if (event != null) { set(key, event); key++; } } return true; }
public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { if (event != null) { set(key, event); } key++; } return true; }
@Override public boolean containsAll(Collection<?> c) { return fInnerEvents.values().containsAll(c); } @Override public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { if (event != null) { set(key, event); } key++; } return true; } @Override public E get(int index) { if (index < 0 || index >= fSize) { throw new IndexOutOfBoundsException("Tried to access index " + index + " Sparse list size " + fSize); } return fInnerEvents.get(index); } @Override public E set(int index, E element) { if (index < 0 || index >= fSize) { throw new IndexOutOfBoundsException("Tried to access index " + index + " Sparse list size " + fSize); } return fInnerEvents.put(index, element); }
public ELEMENT next() { if (!hasNext()) { throw new NoSuchElementException(); } fCursor++; ELEMENT element = fList.get(fCursor); return element; }
public int nextIndex() { return fCursor; }
public void testNoexceptOperator_545021() throws Exception { BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("fun_is_not_noexcept", 0); helper.assertVariableValue("unevaluated_fun_is_noexcept", 1); helper.assertVariableValue("fun_noexcept_is_noexcept", 1); }
helper.assertVariableValue("constexpr_ctor_is_noexcept", 1); helper.assertVariableValue("aggregate_init_is_noexcept", 1); helper.assertVariableValue("not_noexcept_conditional", 0); helper.assertVariableValue("is_noexcept_conditional", 1); helper.assertVariableValue("throw_is_not_noexcept", 0); // int fun(); // int fun(int); // template<typename T> // int funt(T); // template<typename T> // int funt_noexcept(T) noexcept; constexpr bool unevaluated_fun_is_noexcept = noexcept(fun); constexpr bool funt_is_not_noexcept = noexcept(funt(1)); constexpr bool funt_noexcept_is_noexcept = noexcept(funt_noexcept(1)); public void testNoexceptOperator2_545021() throws Exception { BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("unevaluated_fun_is_noexcept", 1); helper.assertVariableValue("funt_is_not_noexcept", 0); helper.assertVariableValue("funt_noexcept_is_noexcept", 1); } // struct type1{ // void operator=(int); // bool operator!(); // }; // type1 t1;
Fixed Code: ```cpp // void operator=(int); // bool operator!(); // }; // type1 t1; // struct type2{ // void operator=(int) noexcept; // bool operator!() noexcept; // }; // type2 t2; // constexpr bool binaryop_is_not_noexcept = noexcept(t1 = 1); // constexpr bool unaryop_is_not_noexcept = noexcept(!t1); // constexpr bool noexcept_binaryop_is_noexcept = noexcept(t2 = 1); // constexpr bool noexcept_unaryop_is_noexcept = noexcept(t2 = 1); public void testNoexceptOperator3_545021() throws Exception { BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("binaryop_is_not_noexcept", 0); helper.assertVariableValue("unaryop_is_not_noexcept", 0); helper.assertVariableValue("noexcept_binaryop_is_noexcept", 1); helper.assertVariableValue("noexcept_unaryop_is_noexcept", 1); } // void fun(); // void fun_taking_funptr(void(*ptr)()) noexcept; // // constexpr bool is_noexcept = noexcept(fun_taking_funptr(fun)); ```
private final boolean isRValueReference; private final boolean takesVarargs; private final ICPPEvaluation noexceptSpecifier; public CPPFunctionType(IType returnType, IType[] types) { this(returnType, types, false, false, false, false, false, null); }
public boolean isNoexcept(boolean inCalledContext) { ICPPFunction overload = getOverload(); if (overload != null) { return EvalUtil.evaluateNoexceptSpecifier(overload.getType().getNoexceptSpecifier()); } return fArg1.isNoexcept(inCalledContext) && fArg2.isNoexcept(inCalledContext); }
public boolean isNoexcept(boolean inCalledContext) { return fPositive.isNoexcept(inCalledContext) && fNegative.isNoexcept(inCalledContext); }
public boolean isNoexcept(boolean inCalledContext) { return EvalUtil.evaluateNoexceptSpecifier(fConstructor.getType().getNoexceptSpecifier()); }
public boolean isNoexcept(boolean inCalledContext) { return true; }
public boolean isNoexcept(boolean inCalledContext) { return true; }
public boolean isNoexcept(boolean inCalledContext) { if (inCalledContext) { return EvalUtil.bindingIsNoexcept(getMember()); } else { return true; } }
public boolean isNoexcept(boolean inCalledContext) { // This assert is used to indicate that this method should not be called. assert false; return true; }
public boolean isNoexcept(boolean inCalledContext) { if (fOperator == op_throw) { return false; } ICPPFunction overload = getOverload(); return (overload != null) && EvalUtil.evaluateNoexceptSpecifier(overload.getType().getNoexceptSpecifier()); }
public void testToString() { List<String> reference = Arrays.asList("Pomme", "Peche", "Poire", "Banane"); List<String> test = createList(reference); assertEquals("[0:Pomme, 1:Peche, 2:Poire, 3:Banane]", test.toString()); }
private static void testListIterator(List<String> test) { ListIterator<String> iterator = test.listIterator(0); assertTrue(iterator.hasNext()); assertFalse(iterator.hasPrevious()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); assertEquals("yo", iterator.next()); iterator.previous(); assertTrue(iterator.hasPrevious()); assertEquals("yo", iterator.previous()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); iterator.next(); iterator.next(); iterator.next(); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.previous(); assertEquals(3, iterator.previousIndex()); assertEquals(4, iterator.nextIndex()); try { iterator.remove(); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.set("hej"); fail("Should not get here"); } catch (IllegalStateException e) { // correct flow } }
import java.util.HashMap; import java.util.Iterator; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; import org.eclipse.jdt.annotation.Nullable; /** * Sparse list, a list optimized for when most of the data is <code>null</code>. * Nulls will increment the size of the data structure but not stored as null * means the data is not present. * * Note: this iterates in the sorted order. * * This implementation supports: * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()}</li> * <li>{@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li> * </ul> */ public class SparseList<T> implements List<T> { // implementation details }
import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; import org.eclipse.jdt.annotation.Nullable; /** * Sparse list, a list optimized for when most of the data is <code>null</code>. * Nulls will increment the size of the data structure but not stored as null * means the data is not present. * * This implementation supports: * - {@link #add(Object)} * - {@link #contains(Object)} * - {@link #clear()} * - {@link #iterator()} * - {@link #isEmpty()} * - {@link #toArray()} * - {@link #toArray(Object[])} * - {@link #set(int, Object)} */
public class SparseList<E> implements List<E> { private final Map<Integer, E> fInnerElements = new HashMap<>(); private int fSize = 0; public SparseList(List<E> events) { ensureSize(events.size()); for (int i = 0; i < events.size(); i++) { E element = events.get(i); if (element != null) { set(i, element); } } } public SparseList() { // Do nothing } @Override public int size() { return fSize; } @Override public boolean isEmpty() { return fSize == 0; } @Override public boolean contains(Object o) { return fInnerElements.containsValue(o); } @Override public Iterator<E> iterator() { return fInnerElements.values().iterator(); } @Override public Object[] toArray() { return fInnerElements.values().toArray(); } @Override public <T> T[] toArray(T[] a) { return fInnerElements.values().toArray(a); } @Override public boolean add(E e) { set(fSize, e); return true; } @Override public boolean remove(Object o) { for (Map.Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { fInnerElements.remove(entry.getKey()); return true; } } return false; } @Override public boolean containsAll(Collection<?> c) { return fInnerElements.values().containsAll(c); } @Override public boolean addAll(Collection<? extends E> c) { int index = fSize; for (E element : c) { set(index++, element); } return true; } @Override public boolean addAll(int index, Collection<? extends E> c) { ensureSize(fSize + c.size()); for (E element : c) { set(index++, element); } return true; } @Override public boolean removeAll(Collection<?> c) { boolean modified = false; for (Map.Entry<Integer, E> entry : fInnerElements.entrySet()) { if (c.contains(entry.getValue()))
public boolean isEmpty() { return super.isEmpty(); }
public boolean contains(Object o) { return fInnerElements.containsValue(o); }
int size = fInnerElements.size(); Object[] retVal = new Object[size]; Iterator<E> iterator = iterator(); for (int i = 0; i < size; i++) { Object next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } retVal[i] = next; } return retVal; } /** * {@inheritDoc} * * Warning, will throw exceptions if a[] is the wrong type. */ @Override public <T> T[] toArray(T[] a) { int size = Math.min(a.length, fInnerElements.size()); Iterator<E> iterator = iterator(); for (int i = 0; i < size; i++) { @Nullable E next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } a[i] = (T) next; } return a; } @Override public boolean add(E e) { if (e != null) { // add implementation } return false; }
public int indexOf(Object o) { for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { return entry.getKey(); } } return -1; }
public int lastIndexOf(Object o) { int last = -1; for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { last = Math.max(last, entry.getKey()); } } return last; }
private void fixSize() { perspSwitcherToolbar.pack(); perspSwitcherToolbar.getParent().pack(); perspSwitcherToolbar.requestLayout(); }
public TimeGraphEntry(@NonNull TimeGraphEntryModel model) { setModel(model); }
public boolean equals(Object obj) { if (!super.equals(obj)) { return false; } if (obj instanceof TimeLineEvent) { TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false; }
protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); if (path.getDevice() == null) { // search relative to the workspace if no device present IResource member = root.findMember(path); if (member != null) { return member; } } // look for files or folders with the given path IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (getType() != ARCHIVE) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } @SuppressWarnings("deprecation") IFile[] files = root.findFilesForLocation(path); if (files.length > 0) { return files[0]; } if (getType() != ARCHIVE) { @SuppressWarnings("deprecation") IContainer[] containers = root.findContainersForLocation(path); if (containers.length > 0) { return containers[0]; } } } return null; }
import org.eclipse.jdt.core.IMember; import org.eclipse.jdt.core.search.IJavaSearchConstants; public abstract class MethodWrapper extends PlatformObject { public static IMethodWrapperDynamic fMethodWrapperCore = new MethodWrapperDynamicCore(); public static final void setMethodWrapperDynamic(IMethodWrapperDynamic core) { fMethodWrapperCore = core; } private Map<String, MethodCall> fElements = null; private Map<String, Map<String, MethodCall>> fMethodCache; private final MethodCall fMethodCall; private final MethodWrapper fParent; private int fLevel; }
private static void testListIterator(List<String> test) { ListIterator<String> iterator = test.listIterator(0); assertTrue(iterator.hasNext()); assertFalse(iterator.hasPrevious()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); assertEquals("yo", iterator.next()); assertEquals("yo", iterator.previous()); assertEquals("Hola", iterator.previous()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } assertEquals("Hola", iterator.next()); assertEquals("yo", iterator.next()); assertEquals("quiero", iterator.next()); assertEquals("un", iterator.next()); assertEquals("UNSUPPORTEDOPERATIONEXCEPTION!", iterator.next()); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } assertEquals("UNSUPPORTEDOPERATIONEXCEPTION!", iterator.previous()); assertEquals(3, iterator.previousIndex()); }
public GenericReadOnlyListIterator(List<E> list, int startIndex) { fList = list; fStart = startIndex; fEnd = list.size(); fCursor = startIndex - 1; }
public GenericReadOnlyListIterator(List<E> list, int start, int end) { fList = list; fStart = start; fEnd = end; fCursor = start + 1; }
public boolean hasNext() { return fCursor < fEnd; }
public boolean hasPrevious() { return fCursor > 0; }
public boolean contains(Object o) { return (o == null && size() > fInnerElements.size()) || fInnerElements.containsValue(o); }
public static Matcher<View> thatFirstMatches(final Matcher<View> viewMatcher) { return new TypeSafeMatcher<View>() { private boolean matched; private View matchedView; @Override protected boolean matchesSafely(View view) { if (matched) return matchedView == view; matched = viewMatcher.matches(view); if (matched) { matchedView = view; } return matched; } @Override public void describeTo(Description description) { description.appendText("that first matches "); viewMatcher.describeTo(description); } }; } public static void printOutput(InputStream input) throws IOException { String candidate = IOUtils.toString(input, "UTF-8"); System.out.println(candidate); } protected IStatus run(final IProgressMonitor monitor) { SubMonitor subMonitor = SubMonitor.convert(monitor); if (fTraceWithSize != null) { monitor.beginTask("", traceWithSize.size()); } else { monitor.beginTask("", IProgressMonitor.UNKNOWN); } while (!monitor.isCanceled()) { try { long prevNbEvents = fTrace.getNbEvents(); Thread.sleep(250); long nbEvents = fTrace.getNbEvents(); if (fTraceWithSize != null) { final int done = traceWithSize.progress(); monitor.worked(done - alreadyDone); alreadyDone = done; } setName(Messages.TmfCheckpointIndexer_Indexing + ' ' + fTrace.getName() + " (" + String.format("%,d", nbEvents) + ")"); long rate = (nbEvents - prevNbEvents) * 4; } catch (InterruptedException e) { // Handle interruption } } } @Nullable E next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } if (next != null) { Class<? extends @NonNull Object> elementClass = next.getClass(); if (!Objects.equals(elementClass, componentType) && !elementClass.isInstance(componentType)) { throw new ArrayStoreException("Cannot convert from (" + elementClass + " to " + newArray.getClass().getComponentType()); } } newArray[i] = (T) next;
public int indexOf(Object o) { if (o == null && contains(null)) { for (int i = 0; i < size(); i++) { if (!fInnerElements.containsKey(i)) { return i; } } } for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { return entry.getKey(); } } return -1; }
public Spliterator<E> spliterator() { return fInnerElements.values().spliterator(); }
public ListIterator<E> listIterator(int index) { return new GenericReadOnlyListIterator<>(this, index, size()); }
public void add(int index, E element) { throw new UnsupportedOperationException("No add(index) in " + this.getClass().getName()); }
public E remove(int index) { throw new UnsupportedOperationException("No delete in " + this.getClass().getName()); }
public boolean remove(Object o) { throw new UnsupportedOperationException("No remove in " + this.getClass().getName()); }
public boolean addAll(int index, Collection<? extends E> c) { throw new UnsupportedOperationException("No addAll(index) in " + this.getClass().getName()); //$NON-NLS-1$ }
throw new UnsupportedOperationException("No subList(fromIndex, toIndex) in " + this.getClass().getName()); //$NON-NLS-1$
/***************************************************************************** * Copyright (c) 2019 vogella GmbH and others. * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Simon Scholz <simon.scholz@vogella.com> - initial API and implementation *****************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.di.annotations.Evaluate; import org.eclipse.e4.ui.model.application.ui.MImperativeExpression; public class ImperativeExpressionTestEvaluationPersistedState { public static final String PERSISTED_STATE_TEST = "persisted-state-test"; @Evaluate public boolean isVisible(MImperativeExpression exp) { return exp.getPersistedState().containsKey(PERSISTED_STATE_TEST); } }
final class BitmapCalculator { private final RevWalk walk; private final BitmapIndex bitmapIndex; private final ProgressMonitor pm; private long countOfBitmapIndexMisses; private final BitmapWalkHook preWalkHook; private final BitmapWalkHook postWalkHook; interface BitmapWalkHook { void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) throws IOException; } BitmapCalculator(RevWalk walk, BitmapIndex bitmapIndex, ProgressMonitor pm, BitmapWalkHook preWalkHook, BitmapWalkHook postWalkHook) { this.walk = walk; this.bitmapIndex = bitmapIndex; this.pm = pm; this.preWalkHook = preWalkHook; this.postWalkHook = postWalkHook; } }
private final RevWalk walk; private final BitmapIndex bitmapIndex; private final ProgressMonitor pm; private long countOfBitmapIndexMisses; private final BitmapWalkHook preWalkHook; private final BitmapWalkHook postWalkHook; interface BitmapWalkHook { void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) throws IOException; } private static final BitmapWalkHook NULL_BITMAP_HOOK = new BitmapWalkHook() { @Override public void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) { // implementation goes here } };
import java.util.Collection; import java.util.HashMap; import java.util.HashSet; import java.util.List; import java.util.Map; import java.util.Set; final public class PatchSetPublishDetailFactory implements Action<PatchSetPublishDetail> { final PatchSet.Id patchSetId; protected AccountInfoCache accounts; protected PatchSetInfo patchSetInfo; protected Change change; protected List<PatchLineComment> drafts; protected Map<ApprovalCategory.Id, Set<ApprovalCategoryValue.Id>> allowed; protected Map<ApprovalCategory.Id, ChangeApproval> given; public PatchSetPublishDetailFactory(PatchSet.Id patchSetId) { this.patchSetId = patchSetId; } @Override public PatchSetPublishDetail run(ReviewDb db) throws OrmException, Failure { final AccountInfoCacheFactory acc = new AccountInfoCacheFactory(db); final Account.Id me = Common.getAccountId(); final Change.Id changeId = patchSetId.getParentKey(); change = db.changes().get(changeId); try { patchSetInfo = PatchSetInfoFactory.patchSetInfoForPatchSetId(patchSetId); } catch (PatchSetInfoNotAvailableException e) { throw new Failure(e); } // Rest of the code... } }
public void set(Object[] newContents) { Assert.isNotNull(newContents); data.clear(); data.addAll(Arrays.asList(newContents)); IConcurrentModelListener[] listeners = getListeners(); for (IConcurrentModelListener listener : listeners) { listener.setContents(newContents); } }
// copy only linked resource children (267173) if (source.isLinked() && source.getLocation().equals(existing.getLocation())) { children = filterNonLinkedResources(children); ResourceDescription[] overwritten = copy(children, destinationPath, resourcesAtDestination, iterationProgress, uiInfo, false, createVirtual, createLinks, relativeToVariable); overwrittenResources.addAll(Arrays.asList(overwritten)); } else { // delete the destination folder, copying a linked folder over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(1), uiInfo, false); iterationProgress.setWorkRemaining(100); if ((createLinks || createVirtual) && (source.isLinked() == false) && (source.isVirtual() == false)) { IFolder folder = workspaceRoot.getFolder(destinationPath); if (createVirtual) { folder.create(IResource.VIRTUAL, true, iterationProgress.split(1)); } else { folder.createLink(source.getLocation(), IResource.REPLACE, iterationProgress.split(1)); } } }
if (mapping == null) continue; ResourceTraversal[] traversals = null; try { traversals = mapping.getTraversals(ResourceMappingContext.LOCAL_CONTEXT, new NullProgressMonitor()); } catch (CoreException e) { StatusManager.getManager().handle(e, IDEWorkbenchPlugin.IDE_WORKBENCH); } if (traversals != null) { IResource[] resources = null; for (ResourceTraversal traversal : traversals) { resources = traversal.getResources(); if (resources != null) { result.addAll(Arrays.asList(resources)); } } } else { result.add(resource); } // all that can be converted are done, answer new selection if (result.isEmpty()) { return StructuredSelection.EMPTY; } return new StructuredSelection(result.toArray());
static Set<IResource> getResourcesForFilter(MarkerFieldFilterGroup group, IResource[] selectedResources, IWorkspaceRoot root) { HashSet<IResource> resourceSet = new HashSet<>(); switch (group.getScope()) { case MarkerFieldFilterGroup.ON_ANY: { resourceSet.add(root); break; } case MarkerFieldFilterGroup.ON_SELECTED_ONLY: case MarkerFieldFilterGroup.ON_SELECTED_AND_CHILDREN: { resourceSet.addAll(Arrays.asList(selectedResources)); break; } case MarkerFieldFilterGroup.ON_ANY_IN_SAME_CONTAINER: { for (IResource resource : getProjects(selectedResources)) { resourceSet.add(resource); } break; } case MarkerFieldFilterGroup.ON_WORKING_SET: { group.refresh(); resourceSet.addAll(Arrays.asList(group.getResourcesInWorkingSet())); break; } } return resourceSet; }
public interface ITimeGraphEntry extends ISelection { public enum DisplayStyle { STATE, LINE } ITimeGraphEntry getParent(); boolean hasChildren(); }
public void addEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Need to be a TimeLineEvent"); } super.addEvent(event); }
public void addEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Need to be a TimeLineEvent"); } super.addEvent(event); }
public TimeLineEvent(ITimeGraphEntry entry, long time) { super(entry, time, 0); }
public TimeLineEvent(ITimeGraphEntry entry, long time, long duration, List<Long> values) { super(entry, time, duration); fValues = values; }
public boolean equals(Object obj) { if (!super.equals(obj)) { return false; } if (obj instanceof TimeLineEvent) { TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false; }
public boolean equals(Object obj) { if (!super.equals(obj)) { return false; } if (obj instanceof TimeLineEvent) { TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false; }
public String toString() { StringBuilder builder = new StringBuilder(); builder.append("[TimeLineEvent Values=").append(getValues()) .append(", Entry=").append(getEntry()) .append(", Time=").append(getTime()) .append(']'); return builder.toString(); }
private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); List<List<LongPoint>> toDraw = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); } }
private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); List<List<LongPoint>> toDraw = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); } }
// clamp 0 - max positive long long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); List<List<LongPoint>> toDraw = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } // add event to the appropriate series toDraw.get(0).add(new LongPoint(x, xEnd)); } // remaining code...
} while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x > rect.x + rect.width || xEnd < rect.x) { continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; }
if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { // rest of the code }
} int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i));
if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); if (i >= toDraw.size()) { toDraw.add(new ArrayList<>()); } toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < nbSeries; i++) { RGBA rgba = colors.get(i); // rest of the code }
long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < nbSeries; i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha); }
Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < toDraw.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha); gc.setForeground(color); List<LongPoint> series = toDraw.get(i); int[] points = new int[series.size() * 2]; for (int point = 0; point < series.size(); point++) { LongPoint longPoint = series.get(point); points[point * 2] = longPoint.x; // rest of the code } }
/***************************************************************************** * Copyright (c) 2000, 2021 IBM Corporation and others. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation *****************************************************************************/ package org.eclipse.jface.viewers; import org.eclipse.core.runtime.Assert; import org.eclipse.swt.dnd.DND; import org.eclipse.swt.dnd.DropTargetAdapter; import org.eclipse.swt.dnd.DropTargetEvent; import org.eclipse.swt.dnd.TransferData; import org.eclipse.swt.graphics.Point; import org.eclipse.swt.graphics.Rectangle; import org.eclipse.swt.widgets.Item; import org.eclipse.swt.widgets.List; import org.eclipse.swt.widgets.Table; import org.eclipse.swt.widgets.TableItem; import org.eclipse.swt.widgets.Tree; import org.eclipse.swt.widgets.TreeItem; /** * This adapter class provides generic drag-and-drop support for a viewer. * <p> */ class ViewerDropAdapter extends DropTargetAdapter { // Implementation here }
for (int i = 0; i < resources.length; i++) { // Copy the resources and record the overwrites that would // be restored if this operation were reversed ResourceDescription[] overwrites; overwrites = WorkspaceUndoUtil.copy(new IResource[] { resources[i] }, getDestinationPath(resources[i], i), resourcesAtDestination, subMonitor.split(1), uiInfo, true, fCreateGroups, fCreateLinks, fRelativeToVariable); // Accumulate the overwrites into the full list overwrittenResources.addAll(Arrays.asList(overwrites)); } // Are there any previously overwritten resources to restore now? if (resourceDescriptions != null) { for (ResourceDescription resourceDescription : resourceDescriptions) { if (resourceDescription != null) { resourceDescription.createResource(subMonitor.split(1)); } } } // Reset resource descriptions to the just overwritten resources setResourceDescriptions(overwrittenResources.toArray(new ResourceDescription[overwrittenResources.size()])); // Reset the target resources to refer to the resources in their new location. setTargetResources(resourcesAtDestination);
for (int i = 0; i < resources.length; i++) { // Move the resources and record the overwrites that would // be restored if this operation were reversed ResourceDescription[] overwrites; overwrites = WorkspaceUndoUtil.move(new IResource[] { resources[i] }, getDestinationPath(resources[i], i), resourcesAtDestination, undoDestinationPaths, subMonitor.split(1), uiInfo, true); // Accumulate the overwrites into the full list overwrittenResources.addAll(Arrays.asList(overwrites)); } // Are there any previously overwritten resources to restore now? if (resourceDescriptions != null) { for (ResourceDescription resourceDescription : resourceDescriptions) { if (resourceDescription != null) { resourceDescription.createResource(subMonitor.split(1)); } } } // Reset resource descriptions to the just overwritten resources setResourceDescriptions(overwrittenResources.toArray(new ResourceDescription[overwrittenResources.size()])); // Reset the target resources to refer to the resources in their new // location. setTargetResources(resourcesAtDestination.toArray(new IResource[resourcesAtDestination.size()]));
// copy only linked resource children (267173) if (source.isLinked() && source.getLocation().equals(existing.getLocation())) { children = filterNonLinkedResources(children); } ResourceDescription[] overwritten = copy(children, destinationPath, resourcesAtDestination, iterationProgress, uiInfo, false, createVirtual, createLinks, relativeToVariable); overwrittenResources.addAll(Arrays.asList(overwritten)); } else { // delete the destination folder, copying a linked folder over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(1), uiInfo, false); iterationProgress.setWorkRemaining(100); if ((createLinks || createVirtual) && (source.isLinked() == false) && (source.isVirtual() == false)) { IFolder folder = workspaceRoot.getFolder(destinationPath); if (createVirtual) { folder.create(IResource.VIRTUAL, true, iterationProgress.split(1)); } else { folder.createLink(source.getLocation(), IResource.NONE, iterationProgress.split(1)); } } }
IResource[] children = ((IContainer) resource).members(); // move only linked resource children (267173) if (resource.isLinked() && resource.getLocation().equals(existing.getLocation())) { children = filterNonLinkedResources(children); } ResourceDescription[] overwritten = move(children, destinationPath, resourcesAtDestination, reverseDestinations, iterationProgress.split(90), uiInfo, false); overwrittenResources.addAll(Arrays.asList(overwritten)); // Delete the source. No need to record it since it will get moved back. delete(resource, iterationProgress.split(10), uiInfo, false, false); } else { // delete the destination folder, moving a linked folder over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(10), uiInfo, false); // Record the original path reverseDestinations.add(resource.getFullPath()); }
if (mapping == null) continue; ResourceTraversal[] traversals = null; try { traversals = mapping.getTraversals(ResourceMappingContext.LOCAL_CONTEXT, new NullProgressMonitor()); } catch (CoreException e) { StatusManager.getManager().handle(e, IDEWorkbenchPlugin.IDE_WORKBENCH); } if (traversals != null) { IResource[] resources = null; for (ResourceTraversal traversal : traversals) { resources = traversal.getResources(); if (resources != null) { result.addAll(Arrays.asList(resources)); } } } else { result.add(resource); } // all that can be converted are done, answer new selection if (result.isEmpty()) { return StructuredSelection.EMPTY; } return new StructuredSelection(result.toArray());
Map<MarkerQueryResult, Collection<IConfigurationElement>> resultsTable = entry.getValue(); if (resultsTable.containsKey(result)) { Iterator<IConfigurationElement> elements = resultsTable.get(result).iterator(); while (elements.hasNext()) { IConfigurationElement element = elements.next(); IMarkerResolutionGenerator generator = null; try { generator = (IMarkerResolutionGenerator) element.createExecutableExtension(ATT_CLASS); IMarkerResolution[] res = generator.getResolutions(marker); if (res != null) { resolutions.addAll(Arrays.asList(res)); } else { StatusManager.getManager().handle(new Status(IStatus.ERROR, IDEWorkbenchPlugin.IDE_WORKBENCH, IStatus.ERROR, "Failure in " + generator.getClass().getName() + " from plugin " + element.getContributor().getName() + ": getResolutions(IMarker) must not return null", null), StatusManager.LOG); } } catch (CoreException e) { Policy.handle(e); } } } }
IPath location = resources[i].getLocation(); if (location != null) { fileNames[actualLength++] = location.toOSString(); } if (actualLength > 0) { if (actualLength < length) { String[] tempFileNames = fileNames; fileNames = new String[actualLength]; System.arraycopy(tempFileNames, 0, fileNames, 0, actualLength); } anEvent.data = fileNames; return true; } return false;
private INavigatorContentDescriptor contributor; private INavigatorContentDescriptor firstClassContributor; private NavigatorContentService contentService; public ContributorTrackingSet(NavigatorContentService aContentService) { contentService = aContentService; } public ContributorTrackingSet(NavigatorContentService aContentService, Object[] elements) { super.addAll(Arrays.asList(elements)); contentService = aContentService; } @Override public boolean add(Object o) { if (contributor != null) { contentService.rememberContribution(contributor, firstClassContributor, o); } return super.add(o); } @Override public boolean remove(Object o) { contentService.forgetContribution(o); return super.remove(o); } @Override public void clear() { Iterator it = iterator(); while (it.hasNext()) contentService.forgetContribution(it.next()); super.clear(); }
updateFilterActivation = true; } // We don't turn of non-UI visible filters here, they have to be manipulated explicitly if (!visibleFilterDescriptors[i].isVisibleInUi()) { if (nonUiVisible == null) nonUiVisible = new ArrayList<String>(); nonUiVisible.add(visibleFilterDescriptors[i].getId()); } /* If so, update */ if (updateFilterActivation) { if (nonUiVisible != null) { nonUiVisible.addAll(Arrays.asList(filterIdsToActivate)); filterIdsToActivate = nonUiVisible.toArray(new String[]{}); } setActiveFilterIds(filterIdsToActivate); persistFilterActivationState(); updateViewer(); // the action providers may no longer be enabled, so we // reset the selection. StructuredViewer commonViewer = (StructuredViewer) contentService.getViewer(); commonViewer.setSelection(StructuredSelection.EMPTY); }
new WizardPatternFilter(), true); viewer = filteredTree.getViewer(); filteredTree.setFont(parent.getFont()); filteredTree.setQuickSelectionMode(true); viewer.setContentProvider(new WizardContentProvider()); viewer.setLabelProvider(new WorkbenchLabelProvider()); viewer.setComparator(DataTransferWizardCollectionComparator.INSTANCE); ArrayList inputArray = new ArrayList(); boolean expandTop = false; if (wizardCategories != null) { if (wizardCategories.getParent() == null) { inputArray.addAll(Arrays.asList(wizardCategories.getCategories())); } else { expandTop = true; inputArray.add(wizardCategories); } } // ensure the category is expanded. If there is a remembered expansion it will // be set later. if (expandTop) { viewer.setAutoExpandLevel(2); } AdaptableList input = new AdaptableList(inputArray); // filter wizard list according to capabilities that are enabled viewer.addFilter(new WizardActivityFilter()); viewer.setInput(input);
filterTree.setQuickSelectionMode(true); final TreeViewer treeViewer = filterTree.getViewer(); treeViewer.setContentProvider(new WizardContentProvider()); treeViewer.setLabelProvider(new WorkbenchLabelProvider()); treeViewer.setComparator(NewWizardCollectionComparator.INSTANCE); treeViewer.addSelectionChangedListener(this); ArrayList inputArray = new ArrayList(); inputArray.addAll(Arrays.asList(primaryWizards)); boolean expandTop = false; if (wizardCategories != null) { if (wizardCategories.getParent() == null) { inputArray.addAll(Arrays.asList(wizardCategories.getCategories())); } else { expandTop = true; inputArray.add(wizardCategories); } } if (expandTop) { treeViewer.setAutoExpandLevel(2); } AdaptableList input = new AdaptableList(inputArray); treeViewer.setInput(input); filterTree.setBackground(parent.getDisplay().getSystemColor(SWT.COLOR_WIDGET_BACKGROUND)); treeViewer.getTree().setFont(parent.getFont()); treeViewer.addDoubleClickListener(event -> { // Double click action });
queuedEvents.add(prefId); return; if (listeners != null) { listeners.firePropertyChange(prefId); } @Override public final void addListener(String[] eventsOfInterest, IPropertyMapListener listener) { if (listeners == null) { listeners = new PropertyListenerList(); attachListener(); } listeners.add(eventsOfInterest, listener); } protected final void firePropertyChange(String[] prefIds) { if (ignoreCount > 0) { queuedEvents.addAll(Arrays.asList(prefIds)); return; } if (listeners != null) { listeners.firePropertyChange(prefIds); } } public final void startTransaction() { ignoreCount++; } public final void endTransaction() { ignoreCount--; if (ignoreCount == 0 && !queuedEvents.isEmpty()) { if (listeners != null) { listeners.firePropertyChange((String[]) queuedEvents.toArray(new String[queuedEvents.size()])); } queuedEvents.clear(); } } @Override public boolean equals(Object toCompare) {
package org.eclipse.e4.ui.tests.workbench; import java.util.ArrayList; import java.util.Arrays; /** * Class used to capture the SWT structure expected when rendering a particular UI model. */ public class SWTResult { public Class clazz; public String text; public ArrayList<SWTResult> kids = new ArrayList<>(); public SWTResult(Class theClass, String theText, SWTResult[] children) { clazz = theClass; text = theText; if (children != null) { kids.addAll(Arrays.asList(children)); } } }
public void setSize(int size) { currentElements = new TestElement[size]; System.arraycopy(allElements, 0, currentElements, 0, currentElements.length); }
public void addMember(String person) { TeamMember newMember = new TeamMember(person, this); TeamMember[] newMembers = new TeamMember[members.length + 1]; System.arraycopy(members, 0, newMembers, 0, members.length); newMembers[newMembers.length - 1] = newMember; members = null; members = newMembers; newMembers = null; fireModelChanged(new ComparatorModelChange(TestModelChange.INSERT, this, newMember)); }
protected LeasedSmtpConnection withConnectionPool(SmtpConnectionPool connectionPool) { m_smtpConnectionPool = connectionPool; return this; }
protected Transport getTransport() { return m_transport; } public ConnectionPool getConnectionPool() { return m_connectionPool; } public boolean isClosed() { return m_closed; }
@ApplicationScoped public class SmtpConnectionPool { private static final Logger LOG = LoggerFactory.getLogger(SmtpConnectionPool.class); protected static final String JOB_NAME_CLOSE_IDLE_CONNECTIONS = "smtp-close-idle-connections"; protected final Object m_poolLock = new Object(); protected final Set<SmtpConnectionPoolEntry> m_idleEntries = new HashSet<>(); protected final Set<SmtpConnectionPoolEntry> m_leasedEntries = new HashSet<>(); protected final String m_jobExecutionHint = "smtp-connection-pool." + UUID.randomUUID().toString(); protected long m_lastPoolEntryNo = 0; protected long m_maxIdleTime; protected long m_maxConnectionLifetime; protected boolean m_destroyed; // Rest of the code... }
protected void destroy() { if (m_destroyed) { return; } synchronized (m_poolLock) { if (m_destroyed) { return; } Jobs.getJobManager().cancel(Jobs.newFutureFilterBuilder() .andMatchExecutionHint(m_jobExecutionHint) .toFilter(), true); Stream.of(m_idleEntries, m_leasedEntries) .flatMap(Collection::stream) .forEach(this::safeCloseTransport); m_idleEntries.clear(); m_leasedEntries.clear(); m_destroyed = true; } }
package org.eclipse.scout.rt.mail.smtp; import javax.mail.Session; import javax.mail.Transport; import org.eclipse.scout.rt.platform.Bean; @Bean public class SmtpConnectionPoolEntry { private String m_name; private SmtpServerConfig m_smtpServerConfig; private Session m_session; private Transport m_transport; private long m_createTime; private long m_idleSince; public SmtpConnectionPoolEntry withName(String name) { m_name = name; return this; } public SmtpConnectionPoolEntry withSmtpServerConfig(SmtpServerConfig smtpServerConfig) { m_smtpServerConfig = smtpServerConfig; return this; } public SmtpConnectionPoolEntry withSession(Session session) { m_session = session; return this; } public SmtpConnectionPoolEntry withTransport(Transport transport) { m_transport = transport; return this; } public SmtpConnectionPoolEntry withCreateTime(long createTime) { m_createTime = createTime; return this; } public SmtpConnectionPoolEntry withIdleSince(long idleSince) { m_idleSince = idleSince; return this; } public Session getSession() { return m_session; } public Transport getTransport() { return m_transport; } public long getCreateTime() { return m_createTime; } public long getIdleSince() { return m_idleSince; } }
public Map<String, String> getAdditionalSessionProperties() { return m_additionalSessionProperties; } /** * These properties are added after the other properties, thus can override predefined properties such as host, port * or user. * * @param additionalSessionProperties * Additional properties used to create {@link Session} for SMTP server connection. */ public SmtpServerConfig withAdditionalSessionProperties(Map<String, String> additionalSessionProperties) { m_additionalSessionProperties = additionalSessionProperties; return this; } public int getPoolSize() { return m_poolSize; } /** * @param poolSize * Specifies the size of the connection pool to use with this {@link SmtpServerConfig#}. If 0, smtp * connection pooling is disabled. */ public SmtpServerConfig withPoolSize(int poolSize) { m_poolSize = poolSize; return this; } @Override public int hashCode() { final int prime = 31; int result = 1; // ... rest of the code }
ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = -1; while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width) { continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); // rest of the code } }
// event is out of bounds continue; TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); seriesModel.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (TimeLineEvent ref : refs) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(ref); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
} TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), 0); seriesModel.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } if (refs.isEmpty()) { return; } for (TimeLineEvent ref : refs) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(ref); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
/***************************************************************************** * Copyright (c) 2019 IBM Corporation and others. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation *****************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.contexts.IEclipseContext; import org.eclipse.e4.ui.internal.workbench.E4Workbench; import org.eclipse.e4.ui.internal.workbench.swt.E4Application; import org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine; import org.eclipse.e4.ui.model.application.MApplication; import org.eclipse.e4.ui.model.application.ui.advanced.MArea; import org.eclipse.e4.ui.model.application.ui.basic.MCompositePart; import org.eclipse.e4.ui.model.application.ui.basic.MPart; import org.eclipse.e4.ui.model.application.ui.basic.MPartStack; import org.eclipse.e4.ui.model.application.ui.basic.MWindow;
/***************************************************************************** * Copyright (c) 2019 IBM Corporation and others. * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation ******************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.contexts.IEclipseContext; import org.eclipse.e4.ui.internal.workbench.E4Workbench; import org.eclipse.e4.ui.internal.workbench.swt.E4Application; import org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine; import org.eclipse.e4.ui.model.application.MApplication; import org.eclipse.e4.ui.model.application.ui.advanced.MArea; import org.eclipse.e4.ui.model.application.ui.basic.MCompositePart; import org.eclipse.e4.ui.model.application.ui.basic.MPart; import org.eclipse.e4.ui.model.application.ui.basic.MPartStack; import org.eclipse.e4.ui.model.application.ui.basic.MWindow;
public void testMultipleStacksUnderTheAreaCreateACTabFolder() { MWindow window = ems.createModelElement(MWindow.class); MArea area = ems.createModelElement(MArea.class); MPartStack stack1 = ems.createModelElement(MPartStack.class); stack1.getChildren().add(ems.createModelElement(MPart.class)); stack1.getChildren().add(ems.createModelElement(MPart.class)); MPartStack stack2 = ems.createModelElement(MPartStack.class); stack2.getChildren().add(ems.createModelElement(MPart.class)); stack2.getChildren().add(ems.createModelElement(MPart.class)); area.getChildren().add(stack1); area.getChildren().add(stack2); window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext); wb.createAndRunUI(window); // Make sure the widget is now a CTabFolder }
public void testStackInsideMCompositePartDoesNotCreateACTabFolder() { MWindow window = ems.createModelElement(MWindow.class); MArea area = ems.createModelElement(MArea.class); MCompositePart composite = ems.createModelElement(MCompositePart.class); MPartStack stack1 = ems.createModelElement(MPartStack.class); stack1.getChildren().add(ems.createModelElement(MPart.class)); stack1.getChildren().add(ems.createModelElement(MPart.class)); MPartStack stack2 = ems.createModelElement(MPartStack.class); stack2.getChildren().add(ems.createModelElement(MPart.class)); stack2.getChildren().add(ems.createModelElement(MPart.class)); composite.getChildren().add(stack1); composite.getChildren().add(stack2); area.getChildren().add(composite); window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext); }
composite.getChildren().add(stack1); composite.getChildren().add(stack2); // Place the container in the area area.getChildren().add(composite); // Add area to the window window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext); wb.createAndRunUI(window); // Make sure the widget is now a CTabFolder Assert.assertFalse(area.getWidget() instanceof CTabFolder);
public void testNoSEBools() { try { assertEquals(0, getBooleanNames().length); } catch (NullPointerException e) { // expected } } public void emptyLine() { String html = parseToHtml(" "); assertEquals("", html); } public void test_SystemProperties() { Properties originalProperties = System.getProperties(); try { Properties testProperties = new Properties(); testProperties.put("testIncInt", "notInt"); System.setProperties(testProperties); assertNull("returned incorrect default Integer", Integer.getInteger("testIncInt")); assertEquals(new Integer(4), Integer.getInteger("testIncInt", 4)); assertEquals(new Integer(4), Integer.getInteger("testIncInt", new Integer(4))); } finally { System.setProperties(originalProperties); } } public void testDynamicItem_AddOne() { contextRule.createAndRunWorkbench(window); ToolBarManager tbm = getManager(toolBar); assertEquals(0, tbm.getSize()); MToolItem toolItem1 = ems.createModelElement(MDirectToolItem.class); toolBar.getChildren().add(toolItem1); assertEquals(1, tbm.getSize()); }
protected int getThreshold() { return 5; }
public void refresh() { fCategoryViewer.setInput(fModel); super.refresh(); }
import org.eclipse.cdt.core.dom.ast.cpp.ICPPConstructor; import org.eclipse.cdt.core.dom.ast.cpp.ICPPMethod; import org.eclipse.cdt.core.dom.ast.cpp.SemanticQueries; import org.eclipse.cdt.internal.core.dom.parser.ASTQueries; import org.eclipse.cdt.internal.core.dom.parser.cpp.ClassTypeHelper; import org.eclipse.cdt.internal.core.dom.parser.cpp.ICPPDeferredClassInstance; @SuppressWarnings("restriction") public class VirtualMethodCallChecker extends AbstractIndexAstChecker { public static final String VIRTUAL_CALL_ID = "org.eclipse.cdt.codan.internal.checkers.VirtualMethodCallProblem"; //$NON-NLS-1$ public static final String THROW_ID = "org.eclipse.cdt.codan.internal.checkers.ThrowInDestructorProblem"; //$NON-NLS-1$ @Override public void processAst(IASTTranslationUnit ast) { ast.accept(new OnEachClass()); } private enum DECL_TYPE { CTOR, DTOR } class OnEachClass extends ASTVisitor { private final Stack<DECL_TYPE> ctorDtorStack = new Stack<>(); OnEachClass() { shouldVisitDeclarations = true; shouldVisitDeclarators = true; shouldVisitImplicitNames = true; shouldVisitInitializers = true; shouldVisitNames = true; shouldVisitParameterDeclarations = true; shouldVisitStatements = true; shouldVisitTypeIds = true; } @Override public int visit(IASTDeclaration declaration) { if (declaration instanceof IASTFunctionDefinition) { IASTFunctionDefinition functionDefinition = (IASTFunctionDefinition) declaration; IASTFunctionDeclarator functionDeclarator = functionDefinition.getDeclarator(); IASTName functionName = functionDeclarator.getName(); ICPPMethod method = ASTQueries.findAncestorWithType(functionName, ICPPMethod.class); if (method != null) { if (method.isVirtual()) { reportProblem(VIRTUAL_CALL_ID, functionName); } if (isDestructor(method)) { ctorDtorStack.push(DECL_TYPE.DTOR); } } } return PROCESS_CONTINUE; } @Override public int leave(IASTDeclaration declaration) { if (declaration instanceof IASTFunctionDefinition) { IASTFunctionDefinition functionDefinition = (IASTFunctionDefinition) declaration; IASTFunctionDeclarator functionDe
private static SyscallLookup create() { try { IPath path = Activator.getDefault().getAbsolutePath(new Path(SYSCALL_TSV_PATH)); if (path != null) { File file = path.toFile(); if (!file.exists()) { Activator.getDefault().logError("Syscall names not available!"); //$NON-NLS-1$ return null; } return new SyscallLookup(FileUtils.readLines(file, "UTF-8")); //$NON-NLS-1$ } } catch (IOException e) { Activator.getDefault().logError("Failed to read file", e); //$NON-NLS-1$ } return new SyscallLookup(Collections.emptyList()); }
doStagefrightTest(R.raw.cve_2015_3873_b_20718524); public void testStagefright_cve_2015_3862_b_22954006() throws Exception { doStagefrightTest(R.raw.cve_2015_3862_b_22954006); } public void testStagefright_cve_2015_3867_b_23213430() throws Exception { doStagefrightTest(R.raw.cve_2015_3867_b_23213430); } public void testStagefright_cve_2015_3873_b_21814993() throws Exception { doStagefrightTest(R.raw.cve_2015_3873_b_21814993); } public void testStagefright_bug_25812590() throws Exception { doStagefrightTest(R.raw.bug_25812590); } public void testStagefright_bug_26070014() throws Exception { doStagefrightTest(R.raw.bug_26070014); } public void testStagefright_cve_2015_6608_b_23680780() throws Exception { doStagefrightTest(R.raw.cve_2015_6608_b_23680780); } private void doStagefrightTest(final int rid) throws Exception { class MediaPlayerCrashListener implements MediaPlayer.OnErrorListener, MediaPlayer.OnPreparedListener, MediaPlayer.OnCompletionListener { @Override
public boolean visit(LambdaExpression lambdaExpression) { IMethodBinding binding = lambdaExpression.resolveMethodBinding(); IVariableBinding[] synVars = binding.getSyntheticOuterLocals(); List<Field> allFields = underlyingThisObject.referenceType().fields(); ListIterator<Field> listIterator = allFields.listIterator(); int i = 0; if (getUnderlyingMethod().isStatic()) { if (synVars.length == allFields.size()) { while (listIterator.hasNext()) { FieldImpl field = (FieldImpl) listIterator.next(); String newName = synVars[i].getName(); FieldImpl newField = new FieldImpl((VirtualMachineImpl) field.virtualMachine(), (ReferenceTypeImpl) field.declaringType(), field.getFieldID(), newName, field.signature(), field.genericSignature(), field.modifiers()); listIterator.set(newField); } } } else { if (synVars.length + 1 == allFields.size()) { while (listIterator.hasNext()) { FieldImpl field = (FieldImpl) listIterator.next(); String newName = field.name(); // rest of the code } } } }
int auto = repo.getConfig().getInt(ConfigConstants.CONFIG_GC_SECTION, ConfigConstants.CONFIG_KEY_AUTO, DEFAULT_AUTOLIMIT); if (auto <= 0) { return false; } int n = 0; int threshold = (auto + 255) / 256; Path dir = repo.getObjectsDirectory().toPath().resolve("17"); //$NON-NLS-1$ if (!Files.exists(dir)) { return false; } try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir, new DirectoryStream.Filter<Path>() { public boolean accept(Path file) throws IOException { return Files.isRegularFile(file) && PATTERN_LOOSE_OBJECT .matcher(file.getFileName().toString()) .matches(); } })) { Iterator<Path> iter = stream.iterator(); while (iter.hasNext()) { if (n++ > threshold) { return true; } } } catch (IOException e) { LOG.error(e.getMessage(), e); } return false;
public void setAllChecked(boolean state) { for (TreeItem item : super.getTree().getItems()) { item.setChecked(state); } if (state) { Object[] visible = getFilteredChildren(getRoot()); ITreeContentProvider contentProvider = null; if (getContentProvider() instanceof ITreeContentProvider) { contentProvider = (ITreeContentProvider) getContentProvider(); } if (contentProvider == null) { checkState.addAll(Arrays.asList(visible)); } else { Set<Object> toCheck = new HashSet<>(); for (Object element : visible) { addFilteredChildren(element, contentProvider, toCheck); } checkState.addAll(toCheck); } } else { if (checkState != null) { Object[] visible = filter(checkState.toArray()); for (Object element : visible) { checkState.remove(element); } } } }
protected IToken scanToken() { return null; } private @NonNull Set<IHyperlinkDetector> getHyperlinkDetectors() { Set<IHyperlinkDetector> allDetectors = new LinkedHashSet<>(); IHyperlinkDetector[] configuredDetectors = configuration.getHyperlinkDetectors(viewer); if (configuredDetectors != null && configuredDetectors.length > 0) { allDetectors.addAll(Arrays.asList(configuredDetectors)); if (preferenceStore.getBoolean(URL_HYPERLINK_DETECTOR_KEY) || !preferenceStore.getBoolean(AbstractTextEditor.PREFERENCE_HYPERLINKS_ENABLED)) { return allDetectors; } allDetectors.add(new MultiURLHyperlinkDetector()); } return allDetectors; }
public static boolean evaluateNoexceptSpecifier(ICPPEvaluation noexceptSpecifier) { if (noexceptSpecifier instanceof IntegralValue) { IntegralValue v = (IntegralValue) noexceptSpecifier; if (v.numberValue() != null) { return v.numberValue().longValue() == 1; } } return false; }
candidate = entry; it.remove(); break; } if (candidate != null && !candidate.getTransport().isConnected()) { LOG.debug("Releasing pooled SMTP connection {}; transport is already closed, not returning to idle pool.", candidate); candidate = null; } if (candidate != null) { IDateProvider dateProvider = BEANS.get(IDateProvider.class); if (dateProvider.currentMillis().getTime() - candidate.getCreateTime() < m_maxConnectionLifetime) { LOG.debug("Releasing pooled SMTP connection {}; returning to idle pool.", candidate); candidate.withIdleSince(dateProvider.currentMillis().getTime()); m_idleEntries.add(candidate); } else { LOG.debug("Releasing pooled SMTP connection {}; pooled connection reached max lifetime of {}s, not returning to idle pool.", candidate, m_maxConnectionLifetime / 1000d); } } m_poolLock.notifyAll();
} public SmtpServerConfig withAdditionalSessionProperties(Map<String, String> additionalSessionProperties) { m_additionalSessionProperties = additionalSessionProperties; return this; } public int getPoolSize() { return m_poolSize; } public SmtpServerConfig withPoolSize(int poolSize) { m_poolSize = poolSize; return this; } @Override public int hashCode() { final int prime = 31; int result = 1;
int cpusNode = cpuSs.getQuarkAbsolute(Attributes.CPUS); final @NonNull List<@NonNull Integer> subAttributes = cpuSs.getSubAttributes(cpusNode, false); int cpus = Integer.MIN_VALUE; for (Integer quark : subAttributes) { cpus = Math.max(Integer.parseInt(cpuSs.getAttributeName(quark)), cpus); } return Math.max(subAttributes.size(), cpus); } catch (AttributeNotFoundException e) { Activator.getDefault().logError("Error: getting number of core" + e.getMessage(), e); //$NON-NLS-1$ } return -1;
if (cpuSs != null) { try { int cpusNode = cpuSs.getQuarkAbsolute(Attributes.CPUS); final @NonNull List<@NonNull Integer> subAttributes = cpuSs.getSubAttributes(cpusNode, false); int cpus = Integer.MIN_VALUE; for (Integer quark : subAttributes) { cpus = Math.max(Integer.parseInt(cpuSs.getAttributeName(quark)), cpus); } return Math.max(subAttributes.size(), cpus); } catch (AttributeNotFoundException e) { Activator.getDefault().logError(e.getMessage(), e); } } return -1;
public boolean isWorkspaceCompatible(URL url) { if (url == null) { return false; } if (WORKSPACE_CHECK_REFERENCE_BUNDLE_VERSION == null) { // no reference bundle installed, no check possible return true; } Version version = readWorkspaceVersion(url); // if the version could not be read, then there is not any existing // workspace data to trample, e.g., perhaps its a new directory that // is just starting to be used as a workspace if (version == null) { return true; } final Version ide_version = toMajorMinorVersion(WORKSPACE_CHECK_REFERENCE_BUNDLE_VERSION); Version workspace_version = toMajorMinorVersion(version); int versionCompareResult = workspace_version.compareTo(ide_version); // equality test is required since any version difference (newer // or older) may result in data being trampled if (versionCompareResult == 0) { return true; } // At this point workspace has been detected to be from a version // other than the current ide version -- find out if the user wants // to use it anyhow. return false; }
public @Nullable ImageDescriptor getImageDescripterFromPath(String path) { return AbstractUIPlugin.imageDescriptorFromPlugin(PLUGIN_ID, path); }
} else if (columnIndex == 1) { try { return attribute.getDisplayableString(); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else if (columnIndex == 2) { try { return attribute.getId().toString(); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else if (columnIndex == 3) { try { return attribute.getAttributeType().getIdString(); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else { return attribute.getGammaId().toString(); }
public void applyUrl(boolean include) throws CoreException { String value = include ? recomputeUrl() : null; if (getCurrentItem() != null) { getCurrentItem().setURL(value); } } private String recomputeUrl() { ISiteFeature feature = getCurrentItem(); if (feature == null) { return null; } StringBuilder sb = new StringBuilder(); sb.append("features/").append(feature.getId()).append("_"); //$NON-NLS-1$ //$NON-NLS-2$ try { sb.append(new Version(feature.getVersion())); } catch (Exception e) { sb.append("0.0.0"); //$NON-NLS-1$ } sb.append(".jar"); //$NON-NLS-1$ return sb.toString(); }
public static SyscallLookup getInstance() { SyscallLookup instance = INSTANCE; if (instance == null) { instance = create(); INSTANCE = instance; } return instance; }
private static SyscallLookup create() { try { IPath path = Activator.getDefault().getAbsolutePath(new Path(SYSCALL_TSV_PATH)); if (path != null) { File file = path.toFile(); if (!file.exists()) { Activator.getDefault().logWarning("Syscall names not available!"); //$NON-NLS-1$ return new SyscallLookup(Collections.emptyList()); } return new SyscallLookup(FileUtils.readLines(file, "UTF-8")); //$NON-NLS-1$ } } catch (IOException e) { Activator.getDefault().logError("Failed to read file", e); //$NON-NLS-1$ } return new SyscallLookup(Collections.emptyList()); }
import com.android.sched.util.log.stats.CounterImpl; import com.android.sched.util.log.stats.StatisticId; import com.android.sched.vfs.InputVFile; import com.android.sched.vfs.UnionVFSReadOnlyException; import com.android.sched.vfs.VPath; import java.io.File; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.Collections; import java.util.HashSet; import java.util.Iterator; import java.util.List; import java.util.Map; import java.util.Set; import javax.annotation.CheckForNull; import javax.annotation.Nonnull; @ImplementationName(iface = InputFilter.class, name = "incremental") @HasKeyId public class IncrementalInputFilter extends CommonFilter implements InputFilter { @Nonnull public static final BooleanPropertyId INCREMENTAL_LOG = BooleanPropertyId .create("jack.incremental.log", "Enable incremental log") .addDefaultValue(Boolean.FALSE); @Nonnull public static final StatisticId<Counter> COMPILED_FILES = new StatisticId<Counter>( "jack.compiled-files", "Number of compiled files", CounterImpl.class, CounterImpl.Factory.class); } public native void put(OcRepresentation ocRepresentation, QueryParamsMap queryParamsMap, OnPutListener onPutListener) throws OcException;
if (type == null) { return value; } IJavaStackFrame stackFrame = getStackFrame(javaValue); if (stackFrame == null) { return value; } IJavaProject project = JavaDebugUtils.resolveJavaProject(stackFrame); if (project == null) { return value; } IAstEvaluationEngine evaluationEngine = JDIDebugPlugin.getDefault().getEvaluationEngine(project, (IJavaDebugTarget) stackFrame.getDebugTarget()); EvaluationBlock evaluationBlock = new EvaluationBlock(javaValue, type, (IJavaThread) stackFrame.getThread(), evaluationEngine); if (fValue == null) { // evaluate each variable IJavaVariable[] variables = new IJavaVariable[fVariables.length]; for (int i = 0; i < fVariables.length; i++) { variables[i] = new JDIPlaceholderVariable(fVariables[i][0], evaluationBlock.evaluate(fVariables[i][1]), javaValue); } return new LogicalObjectStructureValue(javaValue, variables); } // evaluate the logical value IJavaValue logicalValue = evaluationBlock.evaluate(fValue); if (logicalValue instanceof JDIValue) { // ... handle JDIValue }
.getEvaluationEngine(project, (IJavaDebugTarget) stackFrame.getDebugTarget()); EvaluationBlock evaluationBlock = new EvaluationBlock(javaValue, type, (IJavaThread) stackFrame.getThread(), evaluationEngine); if (fValue == null) { // evaluate each variable IJavaVariable[] variables = new IJavaVariable[fVariables.length]; for (int i = 0; i < fVariables.length; i++) { variables[i] = new JDIPlaceholderVariable(fVariables[i][0], evaluationBlock.evaluate(fVariables[i][1]), javaValue); } return new LogicalObjectStructureValue(javaValue, variables); } // evaluate the logical value IJavaValue logicalValue = evaluationBlock.evaluate(fValue); if (logicalValue instanceof JDIValue) { ((JDIValue) logicalValue).setLogicalParent(javaValue); } return logicalValue; } catch (CoreException e) { if (e.getStatus().getCode() == IJavaThread.ERR_THREAD_NOT_SUSPENDED) { throw e; } JDIDebugPlugin.log(e); } return value; } /** * Returns the <code>IJavaReferenceType</code> from the specified
private void createLink(String prefix, final Artifact art, String action, Artifact thisArt, RelationTypeSide relation, TeamWf teamWf) { try { Label label = editor.getToolkit().createLabel(this, prefix + " \"" + getTeamName(thisArt) + "\" " + action + getCompletedCancelledString(art) + " \"" + getTeamName(art) + "\" "); Hyperlink link = editor.getToolkit().createHyperlink(this, String.format("\"%s\" - %s", art.getName().length() < 60 ? art.getName() : art.getName().substring(0, 60), AtsClientService.get().getAtsId(art)), SWT.NONE); if (art.equals(thisArt)) { artAndRelToHyperlink.put(thisArt, relation, link); artAndRelToLabel.put(thisArt, relation, label); } else { artAndRelToHyperlink.put(art, relation, link); artAndRelToLabel.put(art, relation, label); } link.addHyperlinkListener(new IHyperlinkListener() { @Override public void linkEntered(HyperlinkEvent e) { // do nothing } }); } catch (Exception e) { // handle exception } }
IASTExpression fNameExp = fCall.getFunctionNameExpression(); IBinding fBinding = null; if (fNameExp instanceof IASTIdExpression) { IASTIdExpression fName = (IASTIdExpression) fNameExp; fBinding = fName.getName().resolveBinding(); } else if (fNameExp instanceof IASTFieldReference) { IASTFieldReference fName = (IASTFieldReference) fNameExp; if (referencesThis(fName.getFieldOwner())) fBinding = fName.getFieldName().resolveBinding(); } if (fBinding instanceof ICPPMethod) { ICPPMethod method = (ICPPMethod) fBinding; if (method.isPureVirtual() || ClassTypeHelper.isVirtual(method)) { reportProblem(VIRTUAL_CALL_ID, expression); } } return PROCESS_CONTINUE;
fBinding = fName.getName().resolveBinding(); } else if (fNameExp instanceof IASTFieldReference) { IASTFieldReference fName = (IASTFieldReference) fNameExp; if (referencesThis(fName.getFieldOwner())) fBinding = fName.getFieldName().resolveBinding(); } if (fBinding != null && fBinding instanceof ICPPMethod) { ICPPMethod method = (ICPPMethod) fBinding; if (method.isPureVirtual() || ClassTypeHelper.isVirtual(method)) { IASTNode problemNode = expression; reportProblem(VIRTUAL_CALL_ID, problemNode); } } } } return PROCESS_CONTINUE;
if (functionDefinition.isDefaulted() && SemanticQueries.isCopyOrMoveConstructor(constructor)) { return null; } if (constructor.getClassOwner().getKey() == ICompositeType.k_union) { return null; } // Skip delegating constructors. for (ICPPASTConstructorChainInitializer memberInitializer : functionDefinition.getMemberInitializers()) { IASTName memberName = memberInitializer.getMemberInitializerId(); if (memberName != null) { IBinding memberBinding = memberName.resolveBinding(); ICPPClassType classType = null; if (memberBinding instanceof ICPPClassType || memberBinding instanceof ICPPConstructor) { classType = (ICPPClassType) memberBinding; } if (classType instanceof ICPPDeferredClassInstance) { classType = ((ICPPDeferredClassInstance) classType).getClassTemplate(); } if (classType != null && classType.isSameType(constructor.getClassOwner())) { return null; } } } return constructor;
@NonNullByDefault public class TmfEventTableColumn { private final ITmfEventAspect<?> fAspect; private final List<ITmfEventAspect<?>> fAspectDuplicate = new ArrayList<>(); public TmfEventTableColumn(ITmfEventAspect<?> aspect) { fAspect = aspect; fAspectDuplicate.add(aspect); } public void addDuplicateAspect(ITmfEventAspect<?> duplicate) { fAspectDuplicate.add(duplicate); } }
public TmfEventTableColumn(ITmfEventAspect<?> aspect) { fAspect = aspect; fAspectDuplicate.add(aspect); }
public String getItemString(ITmfEvent event) { final String EMPTY_STRING = ""; String s = NonNullUtils.nullToEmptyString(fAspect.resolve(event)); if (fAspectDuplicate.size() > 1 && s.equals(EMPTY_STRING)) { for (ITmfEventAspect<?> aspect : fAspectDuplicate) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if (!eventString.isEmpty()) { return eventString; } } } return s; }
public class MyClass { private static final String EMPTY_STRING = ""; public String getItemString(ITmfEvent event) { for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if (eventString != EMPTY_STRING) { return eventString; } } return EMPTY_STRING; } }
public String getItemString(ITmfEvent event) { final String EMPTY_STRING = ""; for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if (eventString != EMPTY_STRING) { return eventString; } } return EMPTY_STRING; }
public String getItemString(ITmfEvent event) { for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if (!eventString.isEmpty()) { return eventString; } } return EMPTY_STRING; }
/***************************************************************************** * Copyright (c) 2011-2013 EclipseSource Muenchen GmbH and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Johannes Faltermeier - initial API and implementation *****************************************************************************/ package org.eclipse.emf.emfstore.client.test.ui.controllers; import java.io.IOException; import org.eclipse.emf.emfstore.common.ESObserver; import org.eclipse.emf.emfstore.internal.client.model.ESWorkspaceProviderImpl; import org.eclipse.emf.emfstore.internal.client.ui.controller.UIShowHistoryController; import org.eclipse.emf.emfstore.internal.common.observer.ObserverExceptionListener; import org.eclipse.emf.emfstore.server.exceptions.ESException; import org.eclipse.swtbot.eclipse.finder.widgets.SWTBotView; import org.eclipse.swtbot.swt.finder.finders.UIThreadRunnable; import org.eclipse.swtbot.swt.finder.results.VoidResult; import org.junit.Test; public class UIHistoryViewCloseTest extends AbstractUIControllerTestWithCommit { @Override @Test public void testController() throws ESException { // Test implementation } }
public void init(IWorkbench workbench) { setDescription(Messages.CapraGenericPreferences_description); setPreferenceStore(new ScopedPreferenceStore(InstanceScope.INSTANCE, CAPRA_PREFERENCE_PAGE_ID)); }
@SuppressWarnings("restriction") public class TreeMasterDetailComposite extends Composite implements IEditingDomainProvider { private static final String SELECT_A_NODE = JGitText.get().selectANode; private static final String LOADING = JGitText.get().loading; private final Object input; private final EditingDomain editingDomain; private TreeViewer treeViewer; private IMasterDetailSelectionProvider selectionProvider; private Sash verticalSash; private Composite detailComposite; private DetailViewManager detailManager; private Object lastRenderedObject; private final TreeMasterDetailSWTCustomization customization; // constructor and other methods }
public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { boolean result = false; for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { String propOs = property.getOs().trim(); if (propOs.isEmpty() || os.isEmpty() || propOs.equals(os)) { String propArch = property.getArch(); if (arch.isEmpty() || propArch.isEmpty() || propArch.equals(arch)) { result = true; break; } } } } return result; }
public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { String propOs = property.getOs().trim(); if (propOs.length() == 0 || os.length() == 0) { return true; } else if (os.equals(propOs)) { String propArch = property.getArch(); if (arch.length() == 0 || propArch.length() == 0) { return true; } } } } return false; }
if (name.equals(property.getName().trim())) { String propOs = property.getOs().trim(); if (propOs.length() == 0 || os.length() == 0) { result = true; break; } else if (os.equals(propOs)) { String propArch = property.getArch(); if (arch.length() == 0 || propArch.length() == 0) { result = true; break; } } }
public boolean checkCompatibility(Property property, String os, String arch) { boolean result = false; String propOs = property.getOs().trim(); if (propOs.length() == 0 || os.length() == 0) { result = true; } else if (os.equals(propOs)) { String propArch = property.getArch(); if (arch.length() == 0 || propArch.length() == 0) { result = true; } } return result; }
String propOs = property.getOs().trim(); // length zero means all OS versions if (propOs.length() == 0 || os.length() == 0) { result = true; break; } else if (os.equals(propOs)) { String propArch = property.getArch(); // length zero means all architecture versions if (arch.length() == 0 || propArch.length() == 0) { result = true; break; } } else { continue; } } } return result;
IConfigurationProperty configuration = (IConfigurationProperty) obj; switch (index) { case 0: return configuration.getName(); case 1: return configuration.getValue(); case 2: return configuration.getOs(); case 3: return configuration.getArch(); } return null; } private class PropertyDialog extends StatusDialog { private static final String EMPTY_MESSAGE = ""; private Text fName; private Text fValue; private Combo fOS; private Combo fArch; private IConfigurationProperty fEdit; private Set<IConfigurationProperty> fExistingProperties; private String[] COMBO_OSLABELS = new String[] { PDEUIMessages.PropertiesSection_All, Platform.OS_LINUX, Platform.OS_MACOSX, Platform.OS_WIN32 }; private String[] COMBO_ARCHLABELS = new String[] { PDEUIMessages.PropertiesSection_All, Platform.ARCH_X86, Platform.ARCH_X86_64 }; public PropertyDialog(Shell shell, IConfigurationProperty property, Set<IConfigurationProperty> existingProperties) { super(shell); fEdit = property; fExistingProperties = existingProperties; } }
public void addEvent(ITimeEvent event) { if (isValidEvent(event)) { super.addEvent(event); } }
public void setEventList(List<ITimeEvent> eventList) { if (eventList != null) { List<ITimeEvent> filteredList = eventList.stream() .filter(TimeGraphLineEntry::isValidEvent) .collect(Collectors.toList()); super.setEventList(filteredList); } }
public void updateZoomedEvent(ITimeEvent event) { super.updateZoomedEvent(event); }
private static boolean isValidEvent(ITimeEvent event) { return (event instanceof TimeLineEvent); }
// add style Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } if (seriesModel.isEmpty()) { return; } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha); gc.setForeground(color); List<LongPoint> series = seriesModel.get(i); // rest of the code }
public String toString() { return getClass().getSimpleName() + " time=" + fTime + (hasValue() ? (" value=" + getLabel()) : ""); }
seriesModel.add(new ArrayList<>()); // add style Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); if (values.size() < i) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); // rest of the code }
private Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); if (values.size() < i) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); // rest of the code }
Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); if (values.size() < i) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); }
public void addEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Needs to be a TimeLineEvent"); } super.addEvent(event); }
RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); List<LongPoint> seriesToAdd = seriesModel.get(i); long val = values.size() >= nbSeries ? values.get(i) : seriesToAdd.get(seriesToAdd.size() - 1).y; max = Math.max(Math.abs(val), max); min = 0; seriesToAdd.add(new LongPoint(x, val)); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha();
public class TimeLineDisplay extends AbstractTimeEventDisplay { public TimeLineDisplay() { super(); } @Override public void setEventList(List<ITimeEvent> eventList) { super.setEventList(eventList); } @Override public void updateZoomedEvent(ITimeEvent event) { super.updateZoomedEvent(event); } @Override public DisplayStyle getStyle() { return DisplayStyle.LINE; } }
Fixed Code: ```java package org.eclipse.tracecompass.internal.tmf.ui.widgets.timegraph.model; import java.text.NumberFormat; import java.util.ArrayList; import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.StringJoiner; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.ITimeGraphEntry; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.TimeEvent; /** * Generic TimeEvent implementation * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; private String fLabel = null; /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values * The values associated with this event */ public TimeLineEvent(ITimeGraphEntry entry, long time, List<Long> values) { super(entry, time); fValues = values; } /** * Get the values associated with this event * * @return The values associated with this event */ public List<Long> getValues() { return fValues; } /** * Set the label for this event * * @param label * The label for this event */ public void setLabel(String label) { fLabel = label; } /** * Get the label for this event * * @return The label for this event */ public String getLabel() { return fLabel; } @Override public String toString() { StringJoiner joiner = new StringJoiner(", ", "[", "]"); for (Long value : fValues) { joiner.add(NumberFormat.getNumberInstance(Locale.getDefault()).format(value)); } return super.toString() + " " + joiner.toString(); } @Override public int hashCode()
package org.eclipse.tracecompass.internal.tmf.ui.widgets.timegraph.model; import java.text.NumberFormat; import java.util.ArrayList; import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.StringJoiner; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.ITimeGraphEntry; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.TimeEvent; /** * Generic TimeEvent implementation * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; private String fLabel = null; /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values * The values associated with this event */ public TimeLineEvent(ITimeGraphEntry entry, long time, List<Long> values) { super(entry, time); fValues = values; } /** * Get the values associated with this event * * @return The values associated with this event */ public List<Long> getValues() { return fValues; } /** * Set the label for this event * * @param label * The label for this event */ public void setLabel(String label) { fLabel = label; } /** * Get the label for this event * * @return The label for this event */ public String getLabel() { return fLabel; } @Override public String toString() { StringJoiner joiner = new StringJoiner(", "); for (Long value : fValues) { joiner.add(NumberFormat.getNumberInstance(Locale.getDefault()).format(value)); } return super.toString() + " - " + joiner.toString(); } @Override public int hashCode() { return Objects.hash(super.hashCode(), f
/** * Standard constructor * * @param entry The entry matching this event * @param time The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry The entry matching this event * @param time The timestamp of this event * @param values The values to display */ public TimeLineEvent(ITimeGraphEntry entry, long time, List<Long> values) { super(entry, time, 0); fValues = values; } /** * Add a value * * @param value the value to add, it will be displayed as a line */ public void addValue(long value) { fValues.add(value); } @Override public String getLabel() { String label = fLabel; if (label == null) { // ... } // ... }
private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { long max = Long.MIN_VALUE; long min = 0; List<List<LongPoint>> seriesModel = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = -1; boolean isEmpty = true; while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width) { continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } isEmpty = false; } if (isEmpty) { return; } // rest of the code }
public void setEventList(List<ITimeEvent> eventList) { if (eventList != null) { super.setEventList(eventList.stream() .filter(this::isValidEvent) .collect(Collectors.toList())); } }
public String getLabel() { String label = fLabel; if (label == null) { StringJoiner sj = new StringJoiner(", "); getValues().forEach((Long value) -> sj.add(NumberFormat.getNumberInstance(Locale.getDefault()).format(value))); label = sj.toString(); fLabel = label; } return label; }
public List<Long> getValues() { return new ArrayList<>(fValues); }
public void register() { Chart chart = getChart(); chart.getPlotArea().addMouseTrackListener(this); chart.getPlotArea().addMouseMoveListener(this); chart.getPlotArea().addPaintListener(this); fTooltipHandler.activateHoverHelp(chart.getPlotArea()); }
public void deregister() { Chart chart = getChart(); if ((chart != null) && !chart.isDisposed()) { chart.getPlotArea().removeMouseTrackListener(this); chart.getPlotArea().removeMouseMoveListener(this); chart.getPlotArea().removePaintListener(this); fTooltipHandler.deactivateHoverHelp(chart.getPlotArea()); } }
for (int i = 0; i < 10; i++) { appendRandomLine(f); git.add().addFilepattern("file").call(); git.commit().setMessage("message" + i).call(); } FileBasedConfig c = db.getConfig(); c.setInt(ConfigConstants.CONFIG_GC_SECTION, null, ConfigConstants.CONFIG_KEY_AUTOPACKLIMIT, 1); c.save(); Collection<PackFile> packs = gc(Deflater.NO_COMPRESSION); assertEquals("expected 1 packfile after gc", 1, packs.size()); PackFile p1 = packs.iterator().next(); PackFileSnapshot snapshot = p1.getFileSnapshot(); packs = gc(Deflater.BEST_COMPRESSION); assertEquals("expected 1 packfile after gc", 1, packs.size()); PackFile p2 = packs.iterator().next(); File pf = p2.getPackFile();
public void setEventList(List<ITimeEvent> eventList) { super.setEventList(eventList); }
public void addValue(@Nullable Long value) { fValues.add(value); }
protected SWTBotTreeItem[] getPaneBasedSelectionWizardTreeitems() { SWTBotSiriusDiagramEditor representation = (SWTBotSiriusDiagramEditor) openRepresentation(localSession.getOpenedSession(), REPRESENTATION_DESCRIPTION_NAME, REPRESENTATION_NAME, DDiagram.class); representation.setFocus(); representation.activateTool("Pane Based Selection"); representation.click(50, 100); bot.waitUntil(Conditions.shellIsActive("Pane Based")); SWTBot wizardBot = bot.shell("Pane Based").bot(); SWTBotTree tree = wizardBot.tree().select(0); SWTBotTreeItem swtBotTreeItem = tree.getAllItems()[0]; SWTBotTreeItem[] items = swtBotTreeItem.getItems(); return items; }
assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } public void testCancelFirstWizard() { cancelFirstWizard(); Session session = localSession.getOpenedSession(); assertNotNull(THERE_IS_NO_SESSION, session); assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } public void testCancelSecondWizard() { cancelSecondWizard(TREE_NAME); Session session = localSession.getOpenedSession(); assertNotNull(THERE_IS_NO_SESSION, session); assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } public void testEmptySirius() { createOnContextMenu(); bot.waitUntil(Conditions.shellIsActive("Create Representation Wizard")); SWTBotShell shell = bot.shell("Create Representation Wizard");
public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { String propOs = property.getOs() != null ? property.getOs().trim() : ""; if (ALL_OS.equals(propOs) || ALL_OS.equals(os) || propOs.equals(os)) { String propArch = property.getArch() != null ? property.getArch().trim() : ""; if (propArch.equals(arch) || ALL_ARCH.equals(arch) || ALL_ARCH.equals(propArch)) { return true; } } } } return false; }
import org.eclipse.mylyn.context.core.AbstractContextStructureBridge; import org.eclipse.mylyn.context.core.ContextCore; import org.eclipse.mylyn.context.core.IInteractionElement; import org.eclipse.mylyn.context.sdk.util.AbstractResourceContextTest; import org.eclipse.mylyn.context.sdk.util.ContextTestUtil; import org.eclipse.mylyn.internal.resources.ui.ResourcesUiBridgePlugin; import org.eclipse.mylyn.internal.resources.ui.ResourcesUiPreferenceInitializer; import org.eclipse.ui.IWorkingSet; import org.eclipse.ui.IWorkingSetManager; import org.eclipse.ui.PlatformUI; /** * @author Mik Kersten * @author Carsten Reckord (bug 334024: focused package explorer not working if top level element is working set) */ public class ResourceContextTest extends AbstractResourceContextTest { @Override protected void setUp() throws Exception { super.setUp(); ResourcesUiBridgePlugin.getInterestUpdater().setSyncExec(true); ContextTestUtil.triggerContextUiLazyStart(); ResourcesUiBridgePlugin.getDefault() .getPreferenceStore() .setValue(ResourcesUiPreferenceInitializer.PREF_MODIFIED_DATE_EXCLUSIONS, false); } @Override protected void tearDown() throws Exception { super.tearDown(); ResourcesUiBridgePlugin.getInterestUpdater().setSyncExec(false); } } package com.google.gerrit.server.auth.ldap; import com.google.common.cache.LoadingCache; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gerrit.server.account.GroupMembership; import com.google.gerrit.server.account.ListGroupMembership; import com.google.gerrit.server.project.ProjectCache; import java.util.HashSet; import java.util.Set; import java.util.concurrent.ExecutionException; class LdapGroupMembership implements GroupMembership { private final LoadingCache<String, Set<AccountGroup.UUID>> membershipCache; private final ProjectCache projectCache; private final String id; private GroupMembership membership; LdapGroupMembership(LoadingCache<String, Set<AccountGroup.UUID>> membershipCache, ProjectCache projectCache, String id) { this.membershipCache = membershipCache; this.projectCache = projectCache; this.id = id; } @Override public boolean contains(AccountGroup.UUID groupId) { return get().contains(groupId); } @Override public boolean containsAnyOf(Iterable<AccountGroup.UUID> groupIds) { return get().containsAnyOf(groupIds); } } import android.app.Notification
private static void sanitizeList(List<ITimeEvent> sourceList, Consumer<List<ITimeEvent>> listConsumer) { if (sourceList != null) { // Sets a filtered list List<ITimeEvent> events = new ArrayList<>(); for (ITimeEvent event : sourceList) { if (isValidEvent(event)) { events.add(event); } else { events.add(null); } } listConsumer.accept(events); } }
} private void appendRandomLine(File f, int length, Random r) throws IOException { try (Writer w = Files.newBufferedWriter(f.toPath(), StandardOpenOption.APPEND)) { appendRandomLine(w, length, r); } } private void appendRandomLine(File f) throws IOException { appendRandomLine(f, 5, new Random()); } private void appendRandomLine(Writer w, int len, Random r) throws IOException { final int a = 32; // ' ' int e = 126; // '~' for (int i = 0; i < len; i++) { w.append((char) (a + r.nextInt(1 + e - a))); } } private Git createTestRepo(int testDataSeed, int testDataLength) throws IOException, GitAPIException, NoFilepatternException, NoHeadException, NoMessageException, UnmergedPathsException, ConcurrentRefUpdateException, WrongRepositoryStateException, AbortedByHookException { // Create a repo with two commits and one file. Each commit adds // testDataLength number of bytes. Data are random bytes. Since the
appendRandomLine(f, testDataLength, r); git.add().addFilepattern("file").call(); git.commit().setMessage("message2").call().getId(); return git; } @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); PackFile pf = repackAndCheck(5, null, null, null); }
git.commit().setMessage("message2").call().getId(); return git; } @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); }
Fixed Code: ```java git.commit().setMessage("message2").call().getId(); return git; } @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); } ```
// content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); String name = pf.getPackName(); Long length = Long.valueOf(pf.getPackFile().length()); long m1 = packFilePath.toFile().lastModified(); }
@Test public void testDetectModificationAlthoughSameSizeAndModificationTime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); String name = pf.getPackName(); Long length = Long.valueOf(pf.getPackFile().length()); long m1 = packFilePath.toFile().lastModified(); }
.getPackChecksum()); assumeTrue(m3 == m2); } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // To avoid that JGit detects modifications by checking the filekey create // two new packfiles upfront and create copies of them. Then modify the // packfiles inplace by opening them for write and copy content. @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtimeAndFileKey() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile. Make a copy of it PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); Path packFileBasePath = packFilePath.resolveSibling(
@Test public void testDetetctModificationAlthoughtSameSizeAndModificationtimeAndFileKey() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); Path packFileBasePath = packFilePath.resolveSibling(); // Create two new packfiles upfront and create copies of them Path packFile1Path = packFileBasePath.resolve("pack-1.pack"); Path packFile2Path = packFileBasePath.resolve("pack-2.pack"); Files.copy(packFilePath, packFile1Path); Files.copy(packFilePath, packFile2Path); // Modify the packfiles inplace by opening them for write and copying content try (FileChannel packFile1Channel = FileChannel.open(packFile1Path, StandardOpenOption.WRITE); FileChannel packFile2Channel = FileChannel.open(packFile2Path, StandardOpenOption.WRITE)) { packFile1Channel.transferFrom(packFilePath, 0, packFile1Channel.size()); packFile2Channel.transferFrom(packFilePath, 0, packFile2Channel.size()); } // Verify that JGit detects modifications assumeFalse(pf.hasObjectFile(packFile1Path.toFile())); assumeFalse(pf.hasObjectFile(packFile2Path.toFile())); }
@Test public void shouldIndexInRemoteOnChangeIndexedEvent() throws Exception { expect(restClientMock.index(CHANGE_ID)).andReturn(true); replayAll(); indexEventHandler.onChangeIndexed(id.get()); verifyAll(); } @Test public void shouldDeleteFromIndexInRemoteOnChangeDeletedEvent() throws Exception { reset(cd); expect(restClientMock.deleteFromIndex(CHANGE_ID)).andReturn(true); replayAll(); indexEventHandler.onChangeDeleted(id.get()); verifyAll(); } @Test public void testIndexEventHandlerIsForwarded() throws Exception { setUpMocks(false); Context.setForwardedEvent(true); indexEventHandler.onChangeIndexed(id.get()); indexEventHandler.onChangeDeleted(id.get()); Context.unsetForwardedEvent(); verifyAll(); } @Test public void duplicateEventOfAQueuedEventShouldGetDiscarded() { reset(poolMock); poolMock.execute(indexEventHandler.new SyncIndexTask(CHANGE_ID, false)); expectLastCall().once(); replayAll(); indexEventHandler.onChangeIndexed(id.get()); indexEventHandler.onChangeIndexed(id.get()); verifyAll(); } @Test public void shouldNotCallRemoteWhenEventIsForwarded() throws Exception { reset(poolMock); replayAll(); Context.setForwardedEvent(true); indexEventHandler.onChangeIndexed(id.get()); indexEventHandler.onChangeDeleted(id.get()); Context.unsetForwardedEvent(); verifyAll(); } private volatile Throwable cause; private int consumed = 0; private boolean poisoned = false; public Throwable cause() { return cause; } package com.android.tools.idea.gfx.rpccore; import java.util.HashMap; import java.util.Map; public class Decoder { @NotNull private final Map<Integer, RpcObject> decoded; @NotNull private final InputStream in; @NotNull private final byte[] buf; public Decoder(com.android.tools.idea.gfx.binary.Decoder binary) { this.binary = binary; this.decoded = new HashMap<Integer, RpcObject>(); } public RpcObject object(RpcObjectFactory factory) { int key = binary.uint16(); if (key == RpcObject.NULL_ID) { return null; } RpcObject obj = decoded.get(key); if (obj != null) { return obj; } int type = binary.uint16(); obj = factory.Create(type, this); decoded.put(key, obj); } Pack
public void setImage(Image image) { checkWidget(); if ((style & SWT.SEPARATOR) != 0) { return; } if (image != null && image.isDisposed()) { error(SWT.ERROR_INVALID_ARGUMENT); } this.image = image; updateStyleBits(image == null); OS.InvalidateRect(handle, null, true); }
public void setText(String string) { checkWidget(); if (string == null) { error(SWT.ERROR_NULL_ARGUMENT); } if ((style & SWT.SEPARATOR) != 0) { return; } updateStyleBits(true); if (string.equals(text)) { return; } text = string; string = Display.withCrLf(string); TCHAR buffer = new TCHAR(getCodePage(), string, true); OS.SetWindowText(handle, buffer); if ((state & HAS_AUTO_DIRECTION) != 0) { updateTextDirection(AUTO_TEXT_DIRECTION); } }
protected List<ISourceContainer> getEntriesAsList() { ISourceContainer[] entries = getViewer().getEntries(); List<ISourceContainer> list = new ArrayList<>(entries.length); for (ISourceContainer entry : entries) { list.add(entry); } return list; }
public void setEntries(ISourceContainer[] entries) { fEntries.clear(); for (ISourceContainer entry : entries) { if (entry != null) { fEntries.add(entry); } } if (getInput() == null) { setInput(fEntries); if (!fEntries.isEmpty() && fEntries.get(0) != null) { setSelection(new StructuredSelection(fEntries.get(0))); } } else { refresh(); } fPanel.setDirty(true); fPanel.updateLaunchConfigurationDialog(); }
public void addEntries(ISourceContainer[] entries) { int index = 0; IStructuredSelection sel = getStructuredSelection(); if (!sel.isEmpty()) { index = fEntries.indexOf(sel.getFirstElement()); } for (ISourceContainer entry : entries) { if (!fEntries.contains(entry)) { fEntries.add(index, entry); index++; } } refresh(); if (entries.length > 0) { setSelection(new StructuredSelection(entries)); } fPanel.setDirty(true); fPanel.updateLaunchConfigurationDialog(); }
public void setOrganizers(IBreakpointOrganizer[] organizers) { // remove previous listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.removePropertyChangeListener(this); } } fOrganizers = organizers; if (organizers != null && organizers.length == 0) { fOrganizers = null; } // add listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.addPropertyChangeListener(this); } } if (!fDisposed) { fViewer.getControl().setRedraw(false); // maintain expansion based on visible breakpoints IBreakpoint[] breakpoints = null; if (isShowingGroups()) { breakpoints = fViewer.getVisibleBreakpoints(); } reorganize(); if (isShowingGroups() && breakpoints != null) { // restore expansion for (Object fElement : fElements) { BreakpointContainer container = (BreakpointContainer) fElement; for (IBreakpoint breakpoint : breakpoints) { if (container.contains(breakpoint)) { fViewer.expandToLevel(container, AbstractTreeViewer.ALL_LEVELS); fViewer.updateCheckedState(container); } } } } } }
public void setOrganizers(IBreakpointOrganizer[] organizers) { // remove previous listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.removePropertyChangeListener(this); } } fOrganizers = organizers; if (organizers != null && organizers.length == 0) { fOrganizers = null; } // add listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.addPropertyChangeListener(this); } } if (!fDisposed) { fViewer.getControl().setRedraw(false); // maintain expansion based on visible breakpoints IBreakpoint[] breakpoints = null; if (isShowingGroups()) { breakpoints = fViewer.getVisibleBreakpoints(); } reorganize(); if (isShowingGroups() && breakpoints != null) { // restore expansion for (Object fElement : fElements) { BreakpointContainer container = (BreakpointContainer) fElement; for (IBreakpoint breakpoint : breakpoints) { if (container.contains(breakpoint)) { fViewer.expandToLevel(container, AbstractTreeViewer.ALL_LEVELS); fViewer.updateCheckedState(container); } } } } } }
public boolean isValidProperty(String property) { if (fFilters == null) { return true; } return Arrays.asList(fFilters).contains(property); }
public String getRawMemoryString() { if (fStrRep == null) { StringBuffer buffer = new StringBuffer(); fStrRep = RenderingsUtil.convertByteArrayToHexString(getByteArray()); fStrRep = fStrRep.toUpperCase(); buffer = buffer.append(fStrRep); // pad unavailable bytes with padded string from memory block String paddedString = null; int bufferCounter = 0; for (MemoryByte fByte : fBytes) { // if byte is invalid if (!fByte.isReadable()) { if (paddedString == null) { paddedString = fPaddedString; if (paddedString.length() > TableRenderingLine.numCharPerByteForHex) { paddedString = paddedString.substring(0, TableRenderingLine.numCharPerByteForHex); } } buffer.replace(bufferCounter, bufferCounter + TableRenderingLine.numCharPerByteForHex, paddedString); } bufferCounter += TableRenderingLine.numCharPerByteForHex; } fStrRep = buffer.toString(); } return fStrRep; }
fSashForm.setMaximizedControl(variablesViewer.getControl()); fDetailsAnchor = SWTFactory.createComposite(fSashForm, parent.getFont(), 1, 1, GridData.FILL_BOTH, 0, 0); fSashForm.setWeights(getLastSashWeights()); fSelectionProvider = new SelectionProviderWrapper(variablesViewer); getSite().setSelectionProvider(fSelectionProvider); createOrientationActions(variablesViewer); IPreferenceStore prefStore = DebugUIPlugin.getDefault().getPreferenceStore(); String orientation = prefStore.getString(getDetailPanePreferenceKey()); for (ToggleDetailPaneAction fToggleDetailPaneAction : fToggleDetailPaneActions) { fToggleDetailPaneAction.setChecked(fToggleDetailPaneAction.getOrientation().equals(orientation)); } fDetailPane = new DetailPaneProxy(this); fDetailPane.addProperyListener(new IPropertyListener() { @Override public void propertyChanged(Object source, int propId) { firePropertyChange(propId); } }); setDetailPaneOrientation(orientation); IMemento memento = getMemento(); if (memento != null) { variablesViewer.initState(memento); } variablesViewer.addModelChangedListener(this); variablesViewer.addViewerUpdateListener(this); initDragAndDrop(variablesViewer); return variablesViewer;
protected void saveAllCheckedActionStates() { IToolBarManager tbm = getViewSite().getActionBars().getToolBarManager(); IContributionItem[] items = tbm.getItems(); for (IContributionItem contributionItem : items) { if (contributionItem instanceof ActionContributionItem) { ActionContributionItem item = (ActionContributionItem) contributionItem; IAction action = item.getAction(); if (action.getStyle() == IAction.AS_CHECK_BOX && action.isEnabled()) { saveCheckedActionState(action); } } } }
public ExportBreakpointsOperation(IBreakpoint[] breakpoints) { fBreakpoints = breakpoints; fWriter = new StringWriter(); } @Override public void run(IProgressMonitor monitor) throws InvocationTargetException { SubMonitor localmonitor = SubMonitor.convert(monitor, ImportExportMessages.ExportOperation_0, fBreakpoints.length); XMLMemento memento = XMLMemento.createWriteRoot(IImportExportConstants.IE_NODE_BREAKPOINTS); try (Writer writer = fWriter;) { for (IBreakpoint breakpoint : fBreakpoints) { if (localmonitor.isCanceled()) { return; } IMarker marker = breakpoint.getMarker(); IMemento root = memento.createChild(IImportExportConstants.IE_NODE_BREAKPOINT); root.putString(IImportExportConstants.IE_BP_ENABLED, Boolean.toString(breakpoint.isEnabled())); root.putString(IImportExportConstants.IE_BP_REGISTERED, Boolean.toString(breakpoint.isRegistered())); // ... continue with the rest of the code } } catch (IOException e) { throw new InvocationTargetException(e); } }
public ExportBreakpointsOperation(IBreakpoint[] breakpoints) { fBreakpoints = breakpoints; fWriter = new StringWriter(); } @Override public void run(IProgressMonitor monitor) throws InvocationTargetException { SubMonitor localmonitor = SubMonitor.convert(monitor, ImportExportMessages.ExportOperation_0, fBreakpoints.length); XMLMemento memento = XMLMemento.createWriteRoot(IImportExportConstants.IE_NODE_BREAKPOINTS); try (Writer writer = fWriter;) { for (IBreakpoint fBreakpoint : fBreakpoints) { if (localmonitor.isCanceled()) { return; } IBreakpoint breakpoint = fBreakpoint; IMarker marker = breakpoint.getMarker(); IMemento root = memento.createChild(IImportExportConstants.IE_NODE_BREAKPOINT); root.putString(IImportExportConstants.IE_BP_ENABLED, Boolean.toString(breakpoint.isEnabled())); root.putString(IImportExportConstants.IE_BP_REGISTERED, Boolean.toString(breakpoint.isRegistered())); root.putString(IImportExportConstants.IE_BP_PERSISTANT, Boolean.toString(breakpoint.isPersisted())); //write out the resource information } } catch (IOException e) { throw new InvocationTargetException(e); } }
if (scroll != null && !scroll.isDisposed()) { scroll.removeSelectionListener(fScrollbarSelectionListener); } if (!fTableCursor.isDisposed()) { fTableCursor.removeTraverseListener(fCursorTraverseListener); fTableCursor.removeKeyListener(fCursorKeyAdapter); fTableCursor.removeMouseListener(fCursorMouseListener); } fCursorEditor.dispose(); fTextViewer = null; fTableViewer = null; fTableCursor = null; for (CellEditor fEditor : fEditors) { fEditor.dispose(); } JFaceResources.getFontRegistry().removeListener(this); IMemoryRenderingSynchronizationService syncService = getMemoryRenderingContainer().getMemoryRenderingSite().getSynchronizationService(); if (syncService != null) { syncService.removePropertyChangeListener(this); } DebugUIPlugin.getDefault().getPreferenceStore().removePropertyChangeListener(this); fToolTipShell.dispose(); if (getPopupMenuManager() != null) { getPopupMenuManager().removeMenuListener(fMenuListener); } super.dispose();
import org.eclipse.emf.edit.provider.ComposedAdapterFactory; import org.eclipse.emf.edit.provider.ReflectiveItemProviderAdapterFactory; import org.eclipse.jface.databinding.swt.WidgetValueProperty; import org.eclipse.jface.viewers.CellEditor; import org.eclipse.swt.SWT; import org.eclipse.swt.events.FocusEvent; import org.eclipse.swt.events.FocusListener; import org.eclipse.swt.graphics.Image; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Control; @SuppressWarnings("restriction") public class SingleReferenceCellEditor extends CellEditor implements ECPCellEditor, ECPElementAwareCellEditor { private EObject rowElement; private ReferenceService referenceService; private EReference eReference; private Composite composite; private ComposedAdapterFactory composedAdapterFactory; private AdapterFactoryItemDelegator adapterFactoryItemDelegator; /** * The constructor. * * @param parent the parent composite */ public SingleReferenceCellEditor(Composite parent) { super(parent); } /** * Alternate constructor with SWT style bits. * * @param parent the parent composite * @param style the SWT style bits */ public SingleReferenceCellEditor(Composite parent, int style) { super(parent, style); } }
public String getFormattedString(Object value) { if (value == null) { return ""; } return adapterFactoryItemDelegator.getText(value); }
Refactored Code: ```java package org.eclipse.emf.ecp.view.internal.table.swt.cell; import org.eclipse.emf.ecore.EObject; import org.eclipse.emf.ecore.EReference; import org.eclipse.emf.ecore.EStructuralFeature; import org.eclipse.emf.ecp.edit.spi.swt.table.ECPCellEditorTester; import org.eclipse.emf.ecp.view.spi.context.ViewModelContext; /** * Single reference cell editor tester. * * @author Mat Hansen <mhansen@eclipsesource.com> * @since 1.21 */ public class SingleReferenceCellEditorTester implements ECPCellEditorTester { @Override public int isApplicable(EObject eObject, EStructuralFeature eStructuralFeature, ViewModelContext viewModelContext) { if (!EReference.class.isInstance(eStructuralFeature)) { return NOT_APPLICABLE; } final EReference eReference = EReference.class.cast(eStructuralFeature); if (eReference.getUpperBound() == 1) { return 10; } return NOT_APPLICABLE; } } ```
private void analyzeReferencedPackages(PackageVisibilityStatement[] statements, CompilationUnitScope scope) { for (PackageVisibilityStatement statement : statements) { PackageBinding packageBinding = statement.resolvedPackage; if (packageBinding == null) { continue; } packageBinding = packageBinding.getIncarnation(this.binding); if (packageBinding != null && packageBinding.hasCompilationUnit(true)) { continue; } scope.problemReporter().invalidPackageReference(IProblem.PackageDoesNotExistOrIsEmpty, statement); } }
void display(JsArray<NativeString> values) { int row = 1; for (String v : Natives.asList(values)) { populate(row, v); row++; } } String webUrl(); default String changeViewUrl(@Nullable Project.NameKey project, Change.Id id) { return Optional.of(url + "c/" + (project != null ? project.get() + "/+/" : "") + id.get()); } // Translate from the host index (local to the HdfsTable) to network address. Integer tableHostIdx = replicaHostIdxs.get(i); TNetworkAddress networkAddress = partition.getTable().getHostIndex().getEntry(tableHostIdx); Preconditions.checkNotNull(networkAddress); // Translate from network address to the global (to this request) host index. Integer globalHostIdx = analyzer.getHostIndex().getIndex(networkAddress); location.setHost_idx(globalHostIdx); location.setVolume_id(block.getDiskId(i)); location.setIs_cached(block.isCached(i)); locations.add(location); } // create scan ranges, taking into account maxScanRangeLength long currentOffset = block.getOffset(); long remainingLength = block.getLength(); while (remainingLength > 0) { long currentLength = remainingLength; if (maxScanRangeLength > 0 && remainingLength > maxScanRangeLength) { currentLength = maxScanRangeLength; } } if (checkForSplit && this.environment.useModuleSystem) { char[][] declaringModuleNames = null; if (isUnnamed()) { IModuleAwareNameEnvironment moduleEnv = (IModuleAwareNameEnvironment) this.environment.nameEnvironment; declaringModuleNames = moduleEnv.getUniqueModulesDeclaringPackage(new char[][] {packageName}, ANY); } packageBinding = combineWithPackagesFromOtherRelevantModules(packageBinding, packageBinding.compoundName, declaringModuleNames); } this.declaredPackages.put(packageName, packageBinding.getVisibleFor(this, true, true/*need to see empty parent packages, too*/)); if (packageBinding.parent == null) { this.environment.knownPackages.put(packageName, packageBinding); } return packageBinding; } private PackageBinding combineWithPackagesFromOtherRelevantModules(PackageBinding currentBinding, char[][] compoundName, char[][] declaringModuleNames) { boolean save = this.isPackageLookupActive; this.isPackageLookupActive = true; try { for (ModuleBinding moduleBinding
PackageBinding combineWithSiblings(PackageBinding childPackage, char[] name, ModuleBinding module) { ModuleBinding primaryModule = childPackage.enclosingModule; boolean activeSave = primaryModule.isPackageLookupActive; primaryModule.isPackageLookupActive = true; try { char[] flatName = CharOperation.concatWith(childPackage.compoundName, '.'); for (PackageBinding incarnation : this.incarnations) { ModuleBinding moduleBinding = incarnation.enclosingModule; if (moduleBinding == module) continue; if (childPackage.isDeclaredIn(moduleBinding)) continue; PackageBinding next = moduleBinding.getDeclaredPackage(flatName); childPackage = combine(next, childPackage, primaryModule); } return childPackage; } finally { primaryModule.isPackageLookupActive = activeSave; } }
final Object image = adapterFactoryItemDelegator.getImage(value); return SWTImageHelper.getImage(image); @Override public int getColumnWidthWeight() { return 0; } @Override public UpdateValueStrategy getTargetToModelStrategy(DataBindingContext databindingContext) { return null; } @Override public UpdateValueStrategy getModelToTargetStrategy(DataBindingContext databindingContext) { return null; } @Override public void setEditable(boolean editable) { } @Override public int getMinWidth() { return 100; } /** * {@inheritDoc} * * @see org.eclipse.jface.viewers.CellEditor#createControl(org.eclipse.swt.widgets.Composite) */ @Override protected Control createControl(Composite parent) { composite = new Composite(parent, SWT.NONE); composite.addFocusListener(new FocusListener() { private boolean focused; @Override public void focusLost(FocusEvent e) { } @Override public void focusGained(FocusEvent e) { if (focused) { return; } focused = true; try { // Code to handle focus event } finally { focused = false; } } }); return composite; }
package org.eclipse.papyrus.model2doc.odt.internal.transcription; public class CustomFields { private CustomFields() { // to prevent instantiation } public static final String AUTHORS = "Authors"; public static final String VERSION = "Version"; }
package org.eclipse.papyrus.model2doc.odt.internal.transcription; public class CustomFields { private CustomFields() { // to prevent instantiation } public static final String AUTHORS = "Authors"; public static final String VERSION = "Version"; }
public void writeAuthors(final Collection<IAuthor> authors) { if (authors.size() > 0) { final XTextDocument document = odtEditor.getXTextDocument(); final XDocumentPropertiesSupplier xsDocProp = UnoRuntime.queryInterface(XDocumentPropertiesSupplier.class, document); XDocumentProperties props = xsDocProp.getDocumentProperties(); final Iterator<IAuthor> iterator = authors.iterator(); String allAuthorsLabel = ""; if (iterator.hasNext()) { final IAuthor firstAuthor = iterator.next(); allAuthorsLabel = firstAuthor.buildMultiAuthorLabel(ECollections.toEList(authors)); props.setAuthor(firstAuthor.buildAuthorLabel()); } XPropertyContainer userDefined = props.getUserDefinedProperties(); try { userDefined.removeProperty(CustomFields.AUTHORS); } catch (UnknownPropertyException | NotRemoveableException e) { // nothing to do } try { userDefined.addProperty(CustomFields.AUTHORS, com.sun.star.beans.PropertyAttribute.REMOVABLE, allAuthorsLabel); } catch (IllegalArgumentException | PropertyExistException | IllegalTypeException e) { Activator.log.error(e); } } }
String allAuthorsLabel = ""; if (iterator.hasNext()) { final IAuthor firstAuthor = iterator.next(); allAuthorsLabel = firstAuthor.buildMultiAuthorLabel(ECollections.toEList(authors)); props.setAuthor(firstAuthor.buildAuthorLabel()); } XPropertyContainer userDefined = props.getUserDefinedProperties(); // we need to remove the property if it already exist, in order to be change its value try { userDefined.removeProperty(CustomFields.AUTHORS); } catch (UnknownPropertyException | NotRemoveableException e) { // nothing to do } try { userDefined.addProperty(CustomFields.AUTHORS, com.sun.star.beans.PropertyAttribute.REMOVABLE, allAuthorsLabel); } catch (IllegalArgumentException | PropertyExistException | IllegalTypeException e) { Activator.log.error(e); }
public void testInitialStateWithCondition() { ITmfStateSystem stateSystem = fModule.getStateSystem(fModule.getId()); assertNotNull(stateSystem); try { int quark = stateSystem.getQuarkAbsolute("fsm1"); ITmfStateInterval interval = stateSystem.querySingleState(END_TIME, quark); long count1 = interval.getStateValue().unboxLong(); quark = stateSystem.getQuarkAbsolute("fsm2"); interval = stateSystem.querySingleState(END_TIME, quark); long count2 = interval.getStateValue().unboxLong(); assertEquals("Test the count value", count1, count2); } catch (AttributeNotFoundException | StateSystemDisposedException e) { fail("Failed to query the state system"); } }
if (!isPinned) { // Remove and dispose any previous adorned image Image previouslyAdornedImage = (Image) element.getTransientData().get("previouslyAdorned"); //$NON-NLS-1$ if (previouslyAdornedImage != null && !previouslyAdornedImage.isDisposed()) { previouslyAdornedImage.dispose(); } element.getTransientData().remove(IPresentationEngine.ADORNMENT_PIN); } else { Image adornedImage = resUtils.adornImage(image, pinImage); if (adornedImage != image) { // Dispose the previous adorned image if it exists Image previouslyAdornedImage = (Image) element.getTransientData().get("previouslyAdorned"); //$NON-NLS-1$ if (previouslyAdornedImage != null && !previouslyAdornedImage.isDisposed()) { previouslyAdornedImage.dispose(); } element.getTransientData().put("previouslyAdorned", adornedImage); //$NON-NLS-1$ } return adornedImage; }
public final Image getImage(MUILabel element) { return getImage(element, false); }
private Image adornImage(MUIElement element, Image image, boolean imageChanged) { if (element.getTags().contains(IPresentationEngine.ADORNMENT_PIN)) { // Only if Pinned Image Image previousImage = (Image) element.getTransientData().get(ADORN_ICON_IMAGE_KEY); boolean exist = previousImage != null && !previousImage.isDisposed(); // Cached image exist if (imageChanged || !exist) { if (imageChanged && exist) { disposeAdornedImage(element); // Need to dispose old image. If image changed } Image adornedImage = resUtils.adornImage(image, pinImage); if (adornedImage != image) { element.getTransientData().put(ADORN_ICON_IMAGE_KEY, adornedImage); } return adornedImage; } return previousImage; } return image; }
protected void showTab(MUIElement tabElement) { MPerspective persp = (MPerspective) tabElement; Control ctrl = (Control) persp.getWidget(); if (ctrl == null) { ctrl = (Control) renderer.createGui(persp); } else if (ctrl.getParent() != persp.getParent().getWidget()) { Composite parent = (Composite) persp.getParent().getWidget(); ctrl.setParent(parent); } super.showTab(persp); // relayout the perspective Composite psComp = ctrl.getParent(); StackLayout sl = (StackLayout) psComp.getLayout(); if (sl != null) { sl.topControl = ctrl; psComp.layout(); } ctrl.moveAbove(null); // Force a context switch IEclipseContext context = persp.getContext(); context.get(EPartService.class).switchPerspective(persp); // Move any other controls to 'limbo' Control[] kids = psComp.getChildren(); Shell limbo = (Shell) context.get("limbo"); for (Control child : kids) { if (child != ctrl) { child.setParent(limbo); } } }
private boolean loadMappingsFromOldWorkspace(Map<String, Integer> map) { String STATE_FILE = ".fileTypes"; IPath pluginStateLocation = TeamPlugin.getPlugin().getStateLocation().append(STATE_FILE); File f = pluginStateLocation.toFile(); if (!f.exists()) { return false; } try (DataInputStream input = new DataInputStream(new FileInputStream(f))) { map.putAll(readOldFormatExtensionMappings(input)); } catch (IOException ex) { TeamPlugin.log(IStatus.ERROR, ex.getMessage(), ex); return false; } finally { f.delete(); } return true; }
```java public class HexUtils { private static final int ASCII_DIGITS_START_POSITION = 48; private static final int ASCII_UPPERCASE_LETTERS_START_POSITION = 65; private HexUtils() { // private constructor to prevent instantiation } public static String bytesToHex(byte[] bytes) { StringBuilder hexString = new StringBuilder(); for (byte b : bytes) { String hex = Integer.toHexString(b & 0xFF); if (hex.length() == 1) { hexString.append('0'); } hexString.append(hex); } return hexString.toString(); } public static byte[] hexToBytes(String hexString) { return hexToBytes(hexString, "(?<=\\G.{2})"); } private static byte hexCharacterToBin(char character) { if ('0' <= character && character <= '9') { return (byte) (character - ASCII_DIGITS_START_POSITION); } else if ('A' <= character && character <= 'F') { return (byte) (character - ASCII_UPPERCASE_LETTERS_START_POSITION + 10); } else { throw new IllegalArgumentException("Invalid hex character: " + character); } } private static byte[] hexToBytes(String hexString, String delimiter) { String[] hexArray = hexString.split(delimiter); byte[] bytes = new byte[hexArray.length]; for (int i = 0; i < hexArray.length; i++) { bytes[i] = hexCharacterToBin(hexArray[i].charAt(0)); } return bytes; } } ```
public TableUserFilterManager getUserFilterManager() { return (TableUserFilterManager) propertySupport.getProperty(PROP_USER_FILTER_MANAGER); } @Override public void setUserFilterManager(TableUserFilterManager m) { propertySupport.setProperty(PROP_USER_FILTER_MANAGER, m); } @Override public ITableCustomizer getTableCustomizer() { return (ITableCustomizer) propertySupport.getProperty(PROP_TABLE_CUSTOMIZER); } @Override public void setTableCustomizer(ITableCustomizer c) { propertySupport.setProperty(PROP_TABLE_CUSTOMIZER, c); } @Override public IPage<?> getParentPage() { return (IPage<?>) propertySupport.getProperty(PROP_PARENT_PAGE); } @Override public ITypeWithClassId getContainer() { IWidget parentWidget = getParent(); if (parentWidget != null) { return parentWidget; } return getParentPage(); } /** * Do not use this internal method */ public void setParentPageInternal(IPage<?> container) { propertySupport.setProperty(PROP_PARENT_PAGE, container); } @Override public boolean isSortEnabled() { return propertySupport.getPropertyBool(PROP_SORT_ENABLED); }
public class LocalSelectionTransfer extends ByteArrayTransfer { private static final String TYPE_NAME = "local-selection-transfer-format" + System.currentTimeMillis(); private static final int TYPEID = registerType(TYPE_NAME); private static final LocalSelectionTransfer INSTANCE = new LocalSelectionTransfer(); private ISelection selection; private long selectionSetTime; protected LocalSelectionTransfer() { // do nothing } public static LocalSelectionTransfer getTransfer() { return INSTANCE; } public ISelection getSelection() { return selection; } public void setSelection(ISelection selection) { this.selection = selection; this.selectionSetTime = System.currentTimeMillis(); } @Override protected int[] getTypeIds() { return new int[] { TYPEID }; } @Override protected String[] getTypeNames() { return new String[] { TYPE_NAME }; } @Override protected void javaToNative(Object object, TransferData transferData) { if (object instanceof ISelection) { ISelection selection = (ISelection) object; if (isSupportedType(transferData)) { byte[] bytes = serializeSelection(selection); if (bytes != null) { super.javaToNative(bytes, transferData); } } } } @Override protected Object nativeToJava(TransferData transferData) { if (isSupportedType(transferData)) { byte[] bytes = (byte[]) super.nativeToJava(transferData); return deserializeSelection(bytes); } return null; } private byte[] serializeSelection(ISelection selection) { // serialize the selection to bytes return null; } private ISelection deserializeSelection(byte[] bytes) { // deserialize the bytes to a selection return null; } }
private String convertToEditableTimeInterval(String string) { if (string.length() == 0) return string; long value; try { value = Long.parseLong(string); } catch (NumberFormatException e) { value = 0; } if (value == 0) return Long.toString(0); for (int i = 0; i < timeIntervalPrefixes.length - 1; i++) { if (value % timeIntervalScale[i] != 0) return Long.toString(value) + timeIntervalPrefixes[i]; value /= timeIntervalScale[i]; } return Long.toString(value) + timeIntervalPrefixes[timeIntervalPrefixes.length - 1]; } private String convertFromEditableTimeInterval(String string) { if (string.length() == 0) return string; for (int i = 1; i < timeIntervalPrefixes.length; i++) { if (string.endsWith(timeIntervalPrefixes[i])) { long value = Long.parseLong(string.substring(0, string.length() - 1)); for (int j = 0; j < i; j++) value *= timeIntervalScale[j]; return Long.toString(value); } } return string; }
public String toString() { String rv = "Item "; if (parent != null) { rv = parent.toString() + "."; } rv += counter; return rv; }
// produce = false; else { if (filter.requiresCommitBody()) c.parseBody(walker); produce = filter.include(walker, c); } for (int i = 0; i < c.parents.length; i++) { RevCommit p = c.parents[i]; if ((p.flags & SEEN) != 0) continue; if ((p.flags & PARSED) == 0) p.parseHeaders(walker); p.flags |= SEEN; if (firstParent && i > 0) { continue; } pending.add(p); } walker.carryFlagsImpl(c); if ((c.flags & UNINTERESTING) != 0) { if (pending.everbodyHasFlag(UNINTERESTING)) { final RevCommit n = pending.peek(); if (n != null && n.commitTime >= last.commitTime) { // This is too close to call. The next commit we // would pop is dated after the last one produced. // We have to keep going to ensure that we carry // flags as much as necessary. // continue; } } }
private void queryAdapterTypes(Map<String, AdapterType> adapters, Resource res) { try { QueryResponse queryResp = executeQuery("SELECT * FROM AdapterTypes", res); setAdapterTypes(queryResp.getQueryResult(), adapters); } catch (Exception e) { logger.error(MessageFormat.format(Messages.DTL_QueryFailed, "Adapter Types")); } } @Override public void createFBInstance(final FBDeploymentData fbData, final Resource res) throws DeploymentException { // check first if FBType exists Map<String, AdapterType> adapters = getAdapterTypes(fbData.getFb().getType().getInterfaceList()); if (!adapters.isEmpty()) { queryAdapterTypes(adapters, res); createAdapterTypes(adapters, res); } // if the FBType does not exist create it if (!getTypes().contains(fbData.getFb().getType().getName())) { try { createFBType(fbData.getFb().getType(), res); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fbData.getFb().getType().getName())); } } super.createFBInstance(fbData, res); } private static Map<String, AdapterType> getAdapterTypes(InterfaceList interfaceList) { // implementation omitted }
RevCommit a = commit(); RevCommit b1 = commit(a); RevCommit b2 = commit(a); RevCommit c1 = commit(b1); RevCommit c2 = commit(b2); RevCommit d = commit(c1, c2); rw.reset(); rw.setFirstParent(true); markStart(d); assertCommit(d, rw.next()); assertCommit(c1, rw.next()); assertCommit(b1, rw.next()); assertCommit(a, rw.next()); assertNull(rw.next()); @Test public void testSecondParentAncestorOfFirstParent() throws Exception { RevCommit a = commit(); RevCommit b = commit(a); RevCommit c = commit(b, a); rw.reset(); rw.setFirstParent(true); markStart(c); assertCommit(c, rw.next()); assertCommit(b, rw.next()); assertCommit(a, rw.next()); assertNull(rw.next()); } @Test public void testFirstParentMultipleOccurrences() throws Exception { RevCommit a = commit(); RevCommit b = commit(a); RevCommit c = commit(b); rw.reset(); rw.setFirstParent(true); markStart(c); assertCommit(c, rw.next()); assertCommit(b, rw.next()); assertCommit(a, rw.next()); assertNull(rw.next()); }
final class Generator { static final int HAS_REWRITE = 1 << 1; static final int NEEDS_REWRITE = 1 << 2; static final int SORT_TOPO = 1 << 3; static final int HAS_UNINTERESTING = 1 << 4; protected final boolean firstParent; protected Generator(boolean firstParent) { this.firstParent = firstParent; } void shareFreeList(BlockRevQueue q) { // Do nothing by default. } int getFlags() { // Implementation not shown } }
public <T extends ITmfTreeDataProvider<? extends ITmfTreeDataModel>> void removeDataProvider(ITmfTrace trace, T provider) { fInstances.remove(trace, provider); }
protected String getDebuggeeClassName() { return GetValues006Debuggee.class.getName(); } private void checkCreateFBType(FB fb, Resource res) { if (!getTypes().contains(fb.getType().getName())) { try { createFBType(fb.getType(), res); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fb.getType().getName())); } } }
// if the FPType does not exist create it if (!getTypes().contains(fb.getType().getName())) { try { createFBType(fb.getType()); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fb.getType().getName())); } } public void createFBType(final FBType fbType) throws DeploymentException { setAttribute(getDevice(), "FBType", getTypes()); if (fbType instanceof BasicFBType || fbType instanceof CompositeFBType) { if (fbType instanceof CompositeFBType) { createFBTypesOfCFB(fbType); } String request = createLuaRequestMessage(fbType); sendCreateFBTypeREQ(fbType, request); } } private void sendCreateFBTypeREQ(final FBType fbType, String request) throws DeploymentException { try { String result = sendREQ("", request); if (result.contains("Reason")) { // handle error } } catch (IOException e) { throw new DeploymentException(e); } }
addLocalDeclarationSplit(rewrite); else addLocalDeclarationRemoval(rewrite); if (fInitializeIn == INITIALIZE_IN_CONSTRUCTOR) addInitializersToConstructors(rewrite); addTempRenames(rewrite); addFieldDeclaration(rewrite); CompilationUnitChange result= new CompilationUnitChange(RefactoringCoreMessages.PromoteTempToFieldRefactoring_name, fCu); result.setDescriptor(new RefactoringChangeDescriptor(getRefactoringDescriptor())); TextEdit resultingEdits; Map<String, String> formatter= (this.fFormatterOptions == null) ? fCu.getJavaProject().getOptions(true) : this.fFormatterOptions; try { resultingEdits= rewrite.rewriteAST(new Document(fCu.getSource()), formatter); } catch (JavaModelException e) { resultingEdits= rewrite.rewriteAST(); } TextChangeCompatibility.addTextEdit(result, RefactoringCoreMessages.PromoteTempToFieldRefactoring_editName, resultingEdits); return result; finally { pm.done(); } } private void addTempRenames(ASTRewrite rewrite) { boolean noNameChange= fFieldName.equals(fTempDeclarationNode.getName().getIdentifier()); if (fLinkedProposalModel == null && noNameChange) { return; // no changes needed }
public CompilationUnitChange refactorCode(ASTRewrite rewrite, CompilationUnit fCu) { addInitializersToConstructors(rewrite); addTempRenames(rewrite); addFieldDeclaration(rewrite); CompilationUnitChange result = new CompilationUnitChange(RefactoringCoreMessages.PromoteTempToFieldRefactoring_name, fCu); result.setDescriptor(new RefactoringChangeDescriptor(getRefactoringDescriptor())); TextEdit resultingEdits; Map<String, String> formatter = (this.fFormatterOptions == null) ? fCu.getJavaProject().getOptions(true) : this.fFormatterOptions; try { resultingEdits = rewrite.rewriteAST(new Document(fCu.getSource()), formatter); } catch (JavaModelException e) { resultingEdits = rewrite.rewriteAST(); } TextChangeCompatibility.addTextEdit(result, RefactoringCoreMessages.PromoteTempToFieldRefactoring_editName, resultingEdits); return result; } private void addTempRenames(ASTRewrite rewrite) { boolean noNameChange = fFieldName.equals(fTempDeclarationNode.getName().getIdentifier()); if (fLinkedProposalModel == null && noNameChange) { return; // no changes needed } TempOccurrenceAnalyzer analyzer = new TempOccurrenceAnalyzer(fTempDeclarationNode, false); analyzer.perform(); }
@Override public IBaseLabelProvider getLabelProvider() { return super.getLabelProvider(); } @SuppressWarnings({ "rawtypes" }) @Override protected List getSelectionFromWidget() { if (virtualManager != null) { return getVirtualSelection(); } Widget[] items = doGetSelection(); List<Object> list = new ArrayList<>(items.length); for (Widget item : items) { Object e = item.getData(); if (e != null) { list.add(e); } } return list; }
Policy.getLog().log(new Status(IStatus.WARNING, Policy.JFACE, message, new RuntimeException())); return; } } } /** * Returns all selected items for the given SWT control. * * @param control * the control * @return the list of selected items */ protected abstract Item[] getSelection(Control control); @SuppressWarnings({ "rawtypes" }) @Override protected List getSelectionFromWidget() { Widget[] items = getSelection(getControl()); List<Object> list = new ArrayList<>(items.length); for (Widget item : items) { Object e = item.getData(); if (e != null) { list.add(e); } } return list; } /* * Overridden in AbstractTreeViewer to fix bug 108102 (code copied from * StructuredViewer to avoid introducing new API) */ @Override protected void handleDoubleSelect(SelectionEvent event) { // handle case where an earlier selection listener disposed the control. Control control = getControl();
protected void setSelectionToWidget(ISelection selection, boolean reveal) { if (selection instanceof ITreeSelection) { ITreeSelection treeSelection = (ITreeSelection) selection; setSelectionToWidget(Arrays.asList(treeSelection.getPaths()), reveal); } else { super.setSelectionToWidget(selection, reveal); } }
import java.util.Map.Entry; import java.util.Set; import java.util.TimerTask; import java.util.logging.Level; import java.util.logging.Logger; import org.apache.asterix.common.config.AsterixFeedProperties; import org.apache.asterix.external.feed.api.IFeedManager; import org.apache.asterix.external.feed.api.IFeedMessageService; import org.apache.asterix.external.feed.api.IFeedMetricCollector.ValueType; import org.apache.asterix.external.feed.api.IFeedRuntime.FeedRuntimeType; import org.apache.asterix.external.feed.api.IFeedRuntime.Mode; import org.apache.asterix.external.feed.dataflow.StorageFrameHandler; import org.apache.asterix.external.feed.management.FeedConnectionId; import org.apache.asterix.external.feed.message.FeedReportMessage; import org.apache.asterix.external.feed.message.FeedTupleCommitAckMessage; import org.apache.asterix.external.feed.message.FeedTupleCommitResponseMessage; import org.apache.asterix.external.feed.message.ScaleInReportMessage; import org.apache.asterix.external.feed.message.StorageReportFeedMessage; import org.apache.asterix.external.feed.policy.FeedPolicyAccessor; public class MonitoredBufferTimerTasks { }
private void checkCreateFBType(FBType fbType) { // if the FBType does not exist, create it if (!getTypes().contains(fbType.getName())) { try { createFBType(fbType); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fbType.getName())); } } }
private static List<IProject> getSelectedProjects(ISelection selection) { List<IProject> projectSelection = new ArrayList<>(); if (selection instanceof IStructuredSelection) { for (Object element : ((StructuredSelection) selection).toList()) { if (element instanceof AutomationSystem) { projectSelection.add(((AutomationSystem) element).getProject()); } } } return projectSelection; }
public void reveal() { // resolved.ifPresent(RevealStep::reveal); }
private static Collection<LSBasedHyperlink> collectHyperlinks(final IDocument document, final IRegion linkRegion, Either<List<? extends Location>, List<? extends LocationLink>> locations, Collection<LSBasedHyperlink> allLinks) { if (locations == null) { return allLinks; } else if (locations.isLeft()) { allLinks.addAll(locations.getLeft().stream().filter(Objects::nonNull).map(location -> new LSBasedHyperlink(location, linkRegion)).collect(Collectors.toList())); } else { allLinks.addAll(locations.getRight().stream().filter(Objects::nonNull).map(locationLink -> { IRegion selectionRegion = linkRegion; Range originSelectionRange = locationLink.getOriginSelectionRange(); if (originSelectionRange != null) { try { int offset = LSPEclipseUtils.toOffset(originSelectionRange.getStart(), document); int endOffset = LSPEclipseUtils.toOffset(originSelectionRange.getEnd(), document); selectionRegion = new Region(offset, endOffset - offset); } catch (BadLocationException e) { LanguageServerPlugin.logError(e.getMessage(), e); } } return new LSBasedHyperlink(locationLink, selectionRegion); }).collect(Collectors.toList())); } return allLinks; }
protected void addChildVisual(final EditPart childEditPart, final int index) { boolean visible = true; if (childEditPart instanceof InterfaceEditPart) { IInterfaceElement iElement = ((InterfaceEditPart) childEditPart).getModel(); if (iElement instanceof AdapterDeclaration) { visible = isVarVisible(); } } EditPart refEditPart = null; if (index < getChildren().size()) { refEditPart = (EditPart) getChildren().get(index); } if (childEditPart instanceof InterfaceEditPart) { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).getModel().isIsInput()) { if (((InterfaceEditPart) childEditPart).isEvent()) { insertChild(getLeftEventInterfaceContainer(), refEditPart, child); } else { if (visible) { insertChild(getLeftVarInterfaceContainer(), refEditPart, child); } } } } }
protected void removeChildVisual(final EditPart childEditPart) { boolean visible = true; if (childEditPart.getModel() instanceof AdapterDeclaration) { visible = isVarVisible(); } if (childEditPart instanceof InterfaceEditPart) { if (((InterfaceEditPart) childEditPart).getModel().isIsInput()) { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).isEvent()) { getLeftEventInterfaceContainer().remove(child); } else { if (visible) { getLeftVarInterfaceContainer().remove(child); } else { getLeftInterfaceContainer().remove(child); } } } else { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).isEvent()) { getRightEventInterfaceContainer().remove(child); } else { if (visible) { getRightVarInterfaceContainer().remove(child); } else { getRightInterfaceContainer().remove(child); } } } } else { super.removeChildVisual(childEditPart); } }
import org.eclipse.emf.ecore.EObject; import org.eclipse.emf.ecore.EStructuralFeature; import org.eclipse.emf.ecore.InternalEObject; import org.eclipse.emf.ecore.resource.Resource; import com.google.common.base.Objects; import java.util.HashMap; import java.util.Map; /** * An helper to check EObject equality.</br> * It extends and override EcoreUtil.EqualityHelper so that equals methods ignore EAttribute that are ID=true. * * @author mchauvin */ public final class EqualityHelper extends org.eclipse.emf.ecore.util.EcoreUtil.EqualityHelper { private static boolean enableUriFragmentCache = false; private static final Map<EObject, String> eUriFragmentCache = new HashMap<>(); private static final Map<EObject, EObject> eUriFragmentContainerCache = new HashMap<>(); private static final Map<EObject, EStructuralFeature> eUriFragmentContainingFeatureCache = new HashMap<>(); public static synchronized void setEnableUriFragmentCache(boolean enable) { enableUriFragmentCache = enable; if (!enable) { eUriFragmentCache.clear(); eUriFragmentContainerCache.clear(); eUriFragmentContainingFeatureCache.clear(); } } @Override protected boolean haveEqualAttribute(EObject eObject1, EObject eObject2, EAttribute attribute) { boolean isID = attribute.isID(); return isID || super.haveEqualAttribute(eObject1, eObject2, attribute); } }
public static boolean isInActivatedLayer(DiagramMappingsManager session, final DDiagramElement element, final DDiagram parentDiagram) { final DiagramElementMapping mapping = element.getDiagramElementMapping(); if (!LayerHelper.withoutLayersMode(mapping)) { final DDiagram diagram; if (parentDiagram != null) { diagram = parentDiagram; } else { diagram = element.getParentDiagram(); } if (diagram != null) { final Layer activeLayer = session.getActiveLayer(diagram); if (activeLayer != null) { return activeLayer.getActivatedMappings().contains(mapping); } } } return false; }
boolean reveal(EObject object, EStructuralFeature feature); RevealStep reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object, VElement scope); boolean reveal(EObject object,
/** * Attempt to reveal a {@code feature} of an {@code object} in the most appropriate * (by best effort) control within the given {@code scope}. * * @param object an object to reveal * @param feature a specific feature (implying a detail control) to reveal * @param scope a control within which to attempt to reveal the {@code object} * @return {@code true} if the {@code object} was revealed; {@code false}, otherwise */ RevealStep reveal(EObject object, EStructuralFeature feature, VElement scope); /** * Register a reveal provider. * * @param provider the reveal provider to register */ void addRevealProvider(EMFFormsRevealProvider provider); /** * Unregister a reveal provider. * * @param provider the reveal provider to unregister */ void removeRevealProvider(EMFFormsRevealProvider provider); }
public int getRed() { if (isDisposed()) { SWT.error(SWT.ERROR_GRAPHIC_DISPOSED); } // Convert the red value from double to short int r = (((int)(handle.red * 65535.0 + 0.5)) >> 8); return Math.min(r, 255); }
public int getRed() { if (isDisposed()) { SWT.error(SWT.ERROR_GRAPHIC_DISPOSED); } int r = (((int)(handle.red * 65535.0 + 0.5)) >> 8); return Math.min(r, 255); }
public class BucketUpdateResponseHandler extends SimpleChannelUpstreamHandler { private volatile boolean readingChunks; private String lastResponse; private ChannelFuture receivedFuture; private CountDownLatch latch; private StringBuilder partialResponse; private static final Logger LOGGER = Logger.getLogger(BucketUpdateResponseHandler.class.getName()); @Override public void messageReceived(final ChannelHandlerContext context, final MessageEvent event) { ChannelFuture channelFuture = event.getFuture(); setReceivedFuture(channelFuture); if (this.partialResponse == null) { this.partialResponse = new StringBuilder(); } if (readingChunks) { HttpChunk chunk = (HttpChunk) event.getMessage(); if (chunk.isLast()) { readingChunks = false; } else { String curChunk = chunk.getContent().toString("UTF-8"); if (curChunk.matches("\n\n\n\n")) { setLastResponse(partialResponse.toString()); partialResponse = null; getLatch().countDown(); if (monitor != null) { // do something } } } } } } private static final String PREFIX = "<entry gammaId=\""; private static final String POSTFIX = "\"/>\n"; private final Collection<Integer> gammaIds; public AttributeTaggingOperation(Collection<Integer> gammaIds) { super(AttributeTaggingOperation.class.getSimpleName(), Activator.PLUGIN_ID); this.gammaIds = gammaIds; } @Override protected void doWork(IProgressMonitor monitor) throws Exception { long start = System.currentTimeMillis(); StringBuilder response = new StringBuilder(); ByteArrayInputStream inputStream = null; try { Map<String, String> parameters = new HashMap<String, String>(); parameters.put("sessionId", ClientSessionManager.getSessionId()); if (DbUtil.isDbInit()) { parameters.put("wait", "true"); } StringBuilder payload = new StringBuilder(XML_START); for (int data : gammaIds) { payload.append(PREFIX); payload.append(data); payload.append(POSTFIX); } payload.append(XML_FINISH); // rest of the code } finally { // cleanup code } } public static List<Function> extractFunctions(String db, org.apache.hadoop.hive.metastore.api.Function function) throws ImpalaRuntimeException { List<Function> result = Lists.newArrayList(); boolean compatible = true; StringBuilder warnMessage = new StringBuilder(); if (function.get
public int compareTo(VdIcon other) { return mName.compareTo(other.mName); } registerMockResponse("GET /ccds/solution/10101010-1010-1010-1010-101010101010", MockResponse.success("mockCDSSolutionResponse.json")); registerMockResponse("GET /ccds/solution/10101010-1010-1010-1010-101010101010/revision", MockResponse.success("mockCDSSolutionRevisionsResponse.json")); registerMockResponse("GET /ccds/revision/a0a0a0a0-a0a0-a0a0-a0a0-a0a0a0a0a0a0/artifact", MockResponse.success("mockCDSSolutionRevisionArtifactsResponse.json")); registerMockResponse("GET /ccds/solution/f0f0f0f0-f0f0-f0f0-f0f0-f0f0f0f0f0f0", new MockResponse(400, "Error", "mockCDSNoEntryWithIDResponse.json")); StaticProfileTest.class, DynamicProfileTest.class, StaticStereotypeTest.class, StaticStereotypedElementChangeTests.class, DynamicStereotypeTest.class, DynamicStereotypedElementChangeTests.class, ImplicationsAssociationTest.class, ImplicationsTransitionTest.class, ImplicationsInterfaceRealizationTest.class, StaticStereotypedElementItemProviderTest.class, DynamicStereotypedElementItemProviderTest.class, OpaqueElementBodyChangeDiffTest.class, OpaqueElementBodyChangeMergeTest.class, DanglingStereotypeApplicationTest.class, TestNonRegPseudoConflict_484576.class, RemoveStereotypeApplicationPseudoConflictTest.class, MultiplicityElementChangesTest.class, InstanceSpecificationClassifiersMergeTest.class, AddMessageSubDiffTest.class, StereotypeApplicationConflictTests.class, public class AllTests { public static void main(String[] args) { TestRunner.run(suite()); } public static Test suite() { return new JUnit4TestAdapter(AllTests.class); } }
/***************************************************************************** * Copyright (c) 2014, 2017 Obeo and others. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Obeo - initial API and implementation * Christian W. Damus - bug 522080 ******************************************************************************/ package org.eclipse.emf.compare.uml2.internal.postprocessor; import java.util.Iterator; import java.util.Map; import org.eclipse.emf.common.util.Monitor; import org.eclipse.emf.common.util.URI; import org.eclipse.emf.compare.Comparison; import org.eclipse.emf.compare.ComparisonCanceledException; import org.eclipse.emf.compare.Diff; import org.eclipse.emf.compare.Match; import org.eclipse.emf.compare.diff.DefaultDiffEngine; import org.eclipse.emf.compare.diff.FeatureFilter; import org.eclipse.emf.compare.postprocessor.IPostProcessor; import org.eclipse.emf.compare.uml2.internal.postprocessor.extension.stereotype.UMLStereotypedElementChangeFactory;
static URI getStereotypeURI(EObject stereotypeApplication) { return EcoreUtil.getURI(stereotypeApplication.eClass()); }
public static <K, L, V> V put(Map<K, Map<L, V>> mapOfMaps, K key1, L key2, V value) { Map<L, V> map = mapOfMaps.get(key1); if (map == null) { map = Maps.newHashMap(); mapOfMaps.put(key1, map); } return map.put(key2, value); } protected boolean isStereotypeApplication(EObject object) { // implementation }
/*****************************************************************************
import java.util.Dictionary; import java.util.logging.Level; import java.util.regex.Matcher; import java.util.regex.Pattern; import org.eclipse.core.runtime.Platform; import org.eclipse.core.runtime.preferences.IEclipsePreferences; import org.eclipse.core.runtime.preferences.InstanceScope; import org.eclipse.osee.framework.logging.OseeLog; import org.eclipse.ote.services.core.ServiceUtility; import org.eclipse.swt.widgets.Display; import org.eclipse.ui.IStartup; import org.osgi.framework.Bundle; import org.osgi.framework.BundleEvent; import org.osgi.framework.BundleListener; public class SetTitleBar implements IStartup { @Override public void earlyStartup() { String title = getTitle(); if (title != null) { setTitle(title); } else if (ServiceUtility.getContext() != null) { ServiceUtility.getContext().addBundleListener(new BundleListener() { @Override public void bundleChanged(BundleEvent event) { if (event.getType() == Bundle.ACTIVE) { if (event.getBundle().getSymbolicName().equals("bundle.to.base.off.here")) { String t = getTitle(); if (t != null) { setTitle(t); } } } } }); } } private String getTitle() { // TODO: Implement getTitle() method return null; } private void setTitle(String title) { // TODO: Implement setTitle() method } }
import java.io.File; import org.eclipse.core.resources.ResourcesPlugin; import org.eclipse.jface.action.Action; import org.eclipse.jface.action.IContributionItem; import org.eclipse.swt.program.Program; import org.eclipse.swt.widgets.Display; import org.eclipse.ui.IPartListener; import org.eclipse.ui.IViewPart; import org.eclipse.ui.IViewReference; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.IWorkbenchWindow; import org.eclipse.ui.PlatformUI; import org.eclipse.ui.part.ViewPart; import org.eclipse.ui.texteditor.StatusLineContributionItem; public class WorkspaceStatusLineContributionItem { private static String ID = "org.eclipse.ote.simple.oteide.product.load"; private String shortText; private StatusLineContributionItem item; private String path; public WorkspaceStatusLineContributionItem() { path = ResourcesPlugin.getWorkspace().getRoot().getLocation().toString(); shortText = getShortPath(path); item = new StatusLineContributionItem(ID, true, shortText.length()); } private static String getShortPath(String path) { // implementation goes here } }
private static String getUriFragment(EObject eObj) { if (eObj == null) { return null; } if (enableUriFragmentCache) { String cachedUriFragment = E_URI_FRAGMENT_CACHE.get(eObj); if (cachedUriFragment != null) { return cachedUriFragment; } } EObject container = eObj.eContainer(); EStructuralFeature eContainingFeature = eObj.eContainingFeature(); String uriFragment; if (container == null || eContainingFeature == null) { uriFragment = null; } else { uriFragment = container.eURIFragmentSegment(eContainingFeature, eObj); } if (enableUriFragmentCache) { E_URI_FRAGMENT_CACHE.put(eObj, uriFragment); } return uriFragment; } private static boolean sameType(EObject eObj1, EObject eObj2) { return eObj1 != null && eObj2 != null && eObj1.getClass() == eObj2.getClass(); } public static synchronized void setUriFragmentCacheEnabled(boolean enable) { enableUriFragmentCache = enable; if (!enable) { E_URI_FRAGMENT_CACHE.clear(); } } private static class Record { private final String uriFragment; private final EObject eContainer; private final EStructuralFeature containingFeature; Record(String uriFragment, EObject container, EStructuralFeature containingFeature) { this.uriFragment = uriFragment; this.eContainer = container; this.containingFeature = containingFeature; } }
@ApplicationScoped public class ApiDocGenerator { public static final String STATIC_RESOURCE_PARAM = "r"; protected static final String TEXT_ELEMENT_SEPARATOR = "\t"; protected static final String TEXT_LINE_SEPARATOR = "\n"; public List<ResourceDescriptor> getResourceDescriptors() { return BEANS.all(IRestResource.class).stream() .filter(this::acceptRestResource) .sorted(Comparator.comparing(res -> res.getClass().getSimpleName())) .sorted(Comparator.comparing(res -> "/" + getPath(res))) .map(this::toResourceDescriptor) .filter(Objects::nonNull) .collect(Collectors.toList()); } protected ResourceDescriptor toResourceDescriptor(IRestResource resource) { String resourcePath = "/" + getPath(resource); // rest of the code } }
public static class ResourceDescriptor { private IRestResource m_resource; private String m_path; private String m_basePath; // first segment of "path" private String m_name; private String m_anchor; private Function<Boolean, String> m_descriptionFunction; private List<MethodDescriptor> m_methods; public IRestResource getResource() { return m_resource; } public ResourceDescriptor withResource(IRestResource resource) { m_resource = resource; return this; } public String getPath() { return m_path; } public ResourceDescriptor withPath(String path) { m_path = path; return this; } public String getBasePath() { return m_basePath; } public ResourceDescriptor withBasePath(String basePath) { m_basePath = basePath; return this; } public String getDescription(boolean asHtml) { return m_descriptionFunction.apply(asHtml); } public ResourceDescriptor withDescription(Function<Boolean, String> descriptionFunction) { m_descriptionFunction = descriptionFunction; return this; } public List<MethodDescriptor> getMethods() { return m_methods; } public ResourceDescriptor withMethods(List<MethodDescriptor> methods) { m_methods = methods; return this; } } // Usage example: ResourceDescriptor descriptor = new ResourceDescriptor() .withResource(resource) .withPath(path) .withBasePath(basePath) .withDescription(asHtml -> asHtml ? m_descriptionHtml : m_descriptionText) .withMethods(methods);
import org.eclipse.scout.rt.shared.AbstractIcons; import org.eclipse.scout.rt.shared.data.basic.FontSpec; import org.eclipse.scout.rt.shared.services.lookup.ILookupCall; import org.eclipse.scout.rt.shared.services.lookup.ILookupRow; import org.eclipse.scout.rt.shared.services.lookup.LocalLookupCall; import org.eclipse.scout.rt.shared.services.lookup.LookupRow; @ClassId("c6ee18fd-e630-4d92-81b1-cd0147c902d4") public class DefaultTileTableHeaderBox extends AbstractGroupBox implements ITileTableHeaderBox { private TableListener m_tableListener; private boolean m_isGrouping; private boolean m_isSorting; protected TableListener createTableListener() { return new TableAdapter() { @Override public void tableChanged(TableEvent e) { handleTableEvent(e); } }; } protected void handleTableEvent(TableEvent e) { switch (e.getType()) { case TableEvent.TYPE_COLUMN_HEADERS_UPDATED: syncSortingGroupingFields(); break; } } protected void syncSortingGroupingFields() { try { // don't call execChangedValue since it would trigger sort/group again getSortByField().setValueChangeTriggerEnabled(false); // TODO: Add implementation for syncSortingGroupingFields } finally { getSortByField().setValueChangeTriggerEnabled(true); } } }
protected void execChangedValue() { try { m_isGrouping = true; if (getValue() == null) { getTable().getColumnSet().removeGroupColumn(CollectionUtility.firstElement(getTable().getColumnSet().getGroupedColumns())); } else { getTable().getColumnSet().handleGroupingEvent(getValue(), false, true); } ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); } finally { m_isGrouping = false; } }
protected void execChangedValue() { try { m_isSorting = true; if (getValue() == null) { getTable().getColumnSet().removeSortColumn(CollectionUtility.firstElement(getTable().getColumnSet().getSortColumns())); ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); } else { getTable().getColumnSet().handleSortEvent(getValue().getLeft(), false, getValue().getRight()); ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); } } finally { m_isSorting = false; } }
package org.eclipse.scout.rt.rest.error; import javax.ws.rs.core.MediaType; import javax.ws.rs.core.Response; import javax.ws.rs.core.Response.Status; import org.eclipse.scout.rt.platform.BEANS; import org.eclipse.scout.rt.platform.Bean; import org.eclipse.scout.rt.platform.context.CorrelationId; /** * Builder for {@link ErrorDo} and {@link ErrorResponse} objects. */ @Bean public class ErrorResponseBuilder { private int m_httpStatus; private String m_code; private String m_title; private String m_message; public ErrorResponseBuilder withStatus(int httpStatus) { m_httpStatus = httpStatus; return this; } public ErrorResponseBuilder withStatus(Status status) { m_httpStatus = status.getStatusCode(); return this; } public ErrorResponseBuilder withTitle(String title) { m_title = title; return this; } public ErrorResponseBuilder withMessage(String message) { m_message = message; return this; } public ErrorResponseBuilder withCode(int code) { m_code = code; return this; } public ErrorResponseBuilder withCode(String code) { m_code = code; return this; } public ErrorResponseBuilder withCode(Enum<?> code) { m_code = code.name(); return this; } public ErrorResponseBuilder withCode(Enum<?> code, String prefix) { m_code = prefix + code.name(); return this; } public ErrorResponseBuilder withCode(Enum<?> code, Class<?> prefixClass) { m_code = prefixClass.getSimpleName() + "." + code.name(); return this; } public ErrorResponseBuilder withCode(Enum<?> code, Class<?> prefixClass, String prefix) { m_code = prefixClass.getSimpleName() + "." + prefix + code.name(); return this; } public ErrorResponseBuilder withCode(Enum<?> code, String prefix, String suffix) { m_code = prefix + code.name() + suffix; return this; } public ErrorResponseBuilder withCode(Enum<?> code, Class<?> prefixClass, String prefix, String suffix) { m_code = prefixClass.getSimpleName() + "." + prefix + code.name() + suffix; return this; } public ErrorResponseBuilder withCode(Enum<?> code, String prefix, Class<?> suffixClass) { m_code = prefix + code.name() + "." + suffixClass.getSimpleName(); return this;
/******************************************************************************/ package org.eclipse.scout.rt.rest.error; import javax.ws.rs.core.MediaType; import javax.ws.rs.core.Response; import javax.ws.rs.core.Response.Status; import org.eclipse.scout.rt.platform.BEANS; import org.eclipse.scout.rt.platform.Bean; import org.eclipse.scout.rt.platform.context.CorrelationId; /** * Builder for {@link ErrorDo} and {@link ErrorResponse} objects. */ @Bean public class ErrorResponseBuilder { private int m_status; private String m_errorCode; private String m_title; private String m_message; public ErrorResponseBuilder withStatus(int status) { m_status = status; return this; } public ErrorResponseBuilder withStatus(Status status) { m_status = status.getStatusCode(); return this; } public ErrorResponseBuilder withTitle(String title) { m_title = title; return this; } public ErrorResponseBuilder withMessage(String message) { m_message = message; return this; } public ErrorResponseBuilder withCode(int code) { m_errorCode = String.valueOf(code); return this; } }
public ErrorResponseBuilder withHttpStatus(int status) { m_status = status; return this; }
public ErrorResponseBuilder withErrorCode(int code) { m_code = String.valueOf(code); return this; }
public ErrorResponseBuilder withErrorCode(String errorCode) { m_code = errorCode; return this; }
import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.jface.window.Window; import org.eclipse.ltk.ui.refactoring.RefactoringWizardOpenOperation; import org.eclipse.swt.widgets.Shell; import org.eclipse.ui.handlers.HandlerUtil; import org.eclipse.core.commands.AbstractHandler; import org.eclipse.core.commands.ExecutionEvent; import org.eclipse.core.commands.ExecutionException; import org.eclipse.core.resources.IResource; import org.eclipse.jface.dialogs.MessageDialog; import org.eclipse.jface.wizard.WizardDialog; import org.eclipse.ltk.core.refactoring.RefactoringStatus; import org.eclipse.ltk.ui.refactoring.RefactoringUIPlugin; import org.eclipse.ltk.ui.refactoring.resource.RenameResourceWizard; import org.eclipse.ui.PlatformUI; public class RenameResourceHandler extends AbstractHandler { @Override public Object execute(ExecutionEvent event) throws ExecutionException { Shell activeShell = HandlerUtil.getActiveShell(event); IStructuredSelection selection = (IStructuredSelection) HandlerUtil.getCurrentSelection(event); if (selection != null && !selection.isEmpty()) { IResource resource = (IResource) selection.getFirstElement(); if (resource != null) { RenameResourceWizard wizard = new RenameResourceWizard(resource); WizardDialog dialog = new WizardDialog(activeShell, wizard); if (dialog.open() == Window.OK) { return null; } } } return null; } }
protected void addUserInputPages() { RenameResourceProcessor processor = getRefactoring().getAdapter(RenameResourceProcessor.class); RenameResourceRefactoringConfigurationPage page = new RenameResourceRefactoringConfigurationPage(processor); addPage(page); }
@Override public Object execute(ExecutionEvent event) throws ExecutionException { Shell activeShell = HandlerUtil.getActiveShell(event); Object newNameValue = HandlerUtil.getVariable(event, LTK_RENAME_COMMAND_NEWNAME_PARAMETER_KEY); String newName = null; if (newNameValue instanceof String) { newName = (String) newNameValue; } else if (newNameValue != null) { RefactoringUIPlugin.logErrorMessage(RefactoringUIMessages.RenameResourceHandler_ERROR_EXPECTED_STRING + newNameValue.getClass().getName()); } ISelection sel = HandlerUtil.getCurrentSelection(event); if (sel instanceof IStructuredSelection) { IResource resource = getCurrentResource((IStructuredSelection) sel); if (resource != null) { RenameResourceWizard refactoringWizard; if (newName != null) { refactoringWizard = new RenameResourceWizard(resource, newName); } else { refactoringWizard = new RenameResourceWizard(resource); } RefactoringWizardOpenOperation op = new RefactoringWizardOpenOperation(refactoringWizard); try { op.run(activeShell, RefactoringUIMessages.RenameResourceHandler_title); } catch (InterruptedException e) { // do nothing } } } return null; }
private static List<String> convert(Collection<StyleWrapper> themesRaw) { List<String> themes = new ArrayList<String>(themesRaw.size()); for (StyleWrapper theme : themesRaw) { themes.add(theme.getName()); } Collections.sort(themes); return themes; } private static final String PENDING_REVIEWER_FIELD = ChangeField.PENDING_REVIEWER.getName(); private static final String PENDING_REVIEWER_BY_EMAIL_FIELD = ChangeField.PENDING_REVIEWER_BY_EMAIL.getName(); private static final String REF_STATE_FIELD = ChangeField.REF_STATE.getName(); private static final String REF_STATE_PATTERN_FIELD = ChangeField.REF_STATE_PATTERN.getName(); private static final String REVIEWEDBY_FIELD = ChangeField.REVIEWEDBY.getName(); private static final String REVIEWER_FIELD = ChangeField.REVIEWER.getName(); private static final String REVIEWER_BY_EMAIL_FIELD = ChangeField.REVIEWER_BY_EMAIL.getName(); private static final String HASHTAG_FIELD = ChangeField.HASHTAG_CASE_AWARE.getName(); private static final String STAR_FIELD = ChangeField.STAR.getName(); private static final String SUBMIT_RECORD_LENIENT_FIELD = ChangeField.STORED_SUBMIT_RECORD_LENIENT.getName(); private static final String SUBMIT_RECORD_STRICT_FIELD = ChangeField.STORED_SUBMIT_RECORD_STRICT.getName(); private static final String UNRESOLVED_COMMENT_COUNT_FIELD = ChangeField.UNRESOLVED_COMMENT_COUNT.getName(); private ISubject stockMarketSubject; Market market; Map<String, List<Double>> history; public MarketHistory(Market market) { super(); this.market = market; history = new HashMap<String, List<Double>>(); } @Override public void setSubject(ISubject priceSetter) { this.stockMarketSubject = priceSetter; } public void startHistoryWithPrice(String symbol, Double newPrice) throws StockMarketExpection { if (!history.containsKey(symbol)) { List<Double> priceList = new ArrayList<Double>(); priceList.add(newPrice); history.put(symbol, priceList); } } @Override public void update() { Stock updatedStock = (Stock) stockMarketSubject.getUpdate(); if (market.getStockForSymbol(updatedStock.getSymbol()) == null) { return; } } private class CellModifier implements ICellModifier { @Override public boolean canModify(final Object element, final String property) { return (VALUE_PROPERTY.equals(property) || COMMENT_PROPERTY.equals(property)); } @Override
import org.eclipse.fordiac.ide.model.commands.change.ChangeCommentCommand; import org.eclipse.fordiac.ide.model.commands.change.ChangeNameCommand; import org.eclipse.fordiac.ide.model.libraryElement.Device; import org.eclipse.gef.EditPart; import org.eclipse.swt.SWT; import org.eclipse.swt.events.SelectionAdapter; import org.eclipse.swt.events.SelectionEvent; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.layout.GridLayout; import org.eclipse.swt.widgets.Button; import org.eclipse.swt.widgets.Combo; import org.eclipse.swt.widgets.Composite; public class DeviceSection extends AbstractDevResInterfaceSection { protected static String[] profileNames = null; protected Combo profile; protected Button getResources; @Override public void refresh() { super.refresh(); if (null != type) { setProfile(); getResources.setEnabled("DynamicTypeLoad".equals(((Device) getType()).getProfile())); } } private void setProfile() { int i = 0; for (String p : profile.getItems()) { if (p.equals(((Device) getType()).getProfile())) { profile.select(i); break; } i++; } } }
teamArt.getAtsId()); // Confirm that all blocking reviews are completed // Loop through this state's blocking reviews to confirm complete if (teamArt.isTeamWorkflow()) { for (IAtsAbstractReview review : ReviewManager.getReviewsFromCurrentState(teamArt)) { AbstractReviewArtifact reviewArt = (AbstractReviewArtifact) AtsClientService.get().getQueryService().getArtifact(review); if (reviewArt.getReviewBlockType() == ReviewBlockType.Commit && !reviewArt.isCompletedOrCancelled()) { AWorkbench.popup("Committing Branch Error!", "All blocking reviews must be completed before committing a new branch. Please complete all blocking reviews in order to continue."); return; } } } if (!overrideStateValidation) { final MutableBoolean adminOverride = new MutableBoolean(false); // Check extension points for valid commit for (IAtsStateItem item : AtsStateItemManager.getStateItems()) { final Result tempResult = item.committing(teamArt); if (tempResult.isFalse()) { // Allow Admin to override state validation if (isAdmin()) { adminOverride.setTrue(); } else { AWorkbench.popup("Committing Branch Error!", "The branch cannot be committed due to state validation rules. Please contact an administrator for assistance."); return; } } } if (adminOverride.isFalse()) { AWorkbench.popup("Committing Branch Error!", "The branch cannot be committed due to state validation rules. Please contact an administrator for assistance."); return; } }
null); @Override public String getMarkingTag() { return ManagedEntityArtifact.MARKING_TAG; } @Override public IAbstractArtifactInternal getModel() { return MODEL; } public String getLabel() { return getMetadata().getLabel(this); } public ManagedEntityArtifact(ArtifactManager artifactMgr) { super(artifactMgr); setIStandardSpecifics(new OssjEntitySpecifics(this)); } @Override public IAbstractArtifactInternal extractFromClass(JavaClass javaClass, ArtifactManager artifactMgr, IProgressMonitor monitor) { ManagedEntityArtifact result = new ManagedEntityArtifact(javaClass, artifactMgr, monitor); return result; } public ManagedEntityArtifact(JavaClass javaClass, ArtifactManager artifactMgr, IProgressMonitor monitor) { super(javaClass, artifactMgr, monitor); OssjEntitySpecifics specifics = new OssjEntitySpecifics(this); specifics.build(); setIStandardSpecifics(specifics); }
} else if (OS.RegOpenKeyEx(OS.HKEY_LOCAL_MACHINE, key, 0, OS.KEY_READ, phkResult) == 0) { // Try reading from HKLM regKeyFound = true; } if (regKeyFound) { int[] lpcbData = new int[1]; TCHAR buffer = new TCHAR(0, "AppsUseLightTheme", true); //$NON-NLS-1$ int result = OS.RegQueryValueEx(phkResult[0], buffer, 0, null, (TCHAR) null, lpcbData); if (result == 0) { int[] lpData = new int[1]; result = OS.RegQueryValueEx(phkResult[0], buffer, 0, null, lpData, lpcbData); if (result == 0) { isDarkTheme = (lpData[0] == 0); } } OS.RegCloseKey(phkResult[0]); } return isDarkTheme;
public abstract class AnyObjectId implements Comparable<AnyObjectId> { /** * Compare two object identifier byte sequences for equality. * * @param firstObjectId the first identifier to compare. Must not be null. * @param secondObjectId the second identifier to compare. Must not be null. * @return true if the two identifiers are the same. */ @Deprecated @SuppressWarnings("AmbiguousMethodReference") public static boolean equals(final AnyObjectId firstObjectId, final AnyObjectId secondObjectId) { if (firstObjectId == secondObjectId) return true; // We test word 3 first since the git file-based ODB // uses the first byte of w1, and we use w2 as the // hash code, one of those probably came up with these // two instances which we are comparing for equality. // Therefore the first two words are very likely to be // the same, and the third word is very likely different. return firstObjectId.w3 == secondObjectId.w3 && firstObjectId.w2 == secondObjectId.w2 && firstObjectId.w1 == secondObjectId.w1; } }
handleMiddleClick(event); }); private void handleMiddleClick(MouseEvent event) throws CoreException { if (event.button == 2 && event.widget instanceof Tree) { TreeItem item = ((Tree) event.widget).getItem(new Point(event.x, event.y)); if (item == null) { return; } Object data = item.getData(); if (data instanceof IProject) { IProject project = (IProject) data; if (project.isOpen()) { project.close(new NullProgressMonitor()); } } } }
} @Override public boolean isHidden(File path) throws IOException { return FileUtil.isHidden(path); } @Override public void setHidden(File path, boolean hidden) throws IOException { FileUtil.setHidden(path, hidden); } @Override public String readSymLink(File path) throws IOException { return FileUtil.readSymlink(path); } @Override public void createSymLink(File path, String target) throws IOException { FileUtil.createSymLink(path, target); } @Override public Attributes getAttributes(File path) { return FileUtil.getFileAttributesBasic(this, path); } }
RebaseTodoLine line = null; String commentString = RawParseUtils.decode(buf, tokenBegin, lineEnd + 1); try { int skip = tokenBegin + 1; // skip '#' skip = nextParsableToken(buf, skip, lineEnd); if (skip != -1) { line = parseLine(buf, skip, lineEnd); if (line != null) { line.setAction(Action.COMMENT); line.setComment(commentString); } } } catch (Exception e) { line = null; } finally { if (line == null) { line = new RebaseTodoLine(commentString); } r.add(line); }
package edu.wpi.cs.wpisuitetng.modules.taskmanager.model; import java.util.List; import edu.wpi.cs.wpisuitetng.Session; import edu.wpi.cs.wpisuitetng.database.Data; import edu.wpi.cs.wpisuitetng.exceptions.BadRequestException; import edu.wpi.cs.wpisuitetng.exceptions.ConflictException; import edu.wpi.cs.wpisuitetng.exceptions.NotFoundException; import edu.wpi.cs.wpisuitetng.exceptions.NotImplementedException; import edu.wpi.cs.wpisuitetng.exceptions.WPISuiteException; import edu.wpi.cs.wpisuitetng.modules.EntityManager; import edu.wpi.cs.wpisuitetng.modules.Model; public class ActivityEntityManager implements EntityManager<ActivityModel> { private Data db; /** * Constructs the entity manager. This constructor is called by * {@link edu.wpi.cs.wpisuitetng.ManagerLayer#ManagerLayer()}. To make sure * this happens, be sure to place add this entity manager to the map in the * ManagerLayer file. * * @param db a reference to the persistent database */ }
private void addPatterns(String... searchStrings) { if (searchStrings == null) { return; } for (String searchString : searchStrings) { if (searchString == null || searchString.isEmpty()) { continue; } Node node = root; for (char c : searchString.toCharArray()) { node = node.add(c); } node.match = searchString; } }
public class MultiStringMatcher { public static interface Match { String getText(); int getOffset(); } }
public Match indexOf(String text, int offset) { if (strings.isEmpty()) { throw new IllegalStateException("No strings to search for have been added to this matcher"); } List<Match> matches = find(text, offset, true); if (matches.isEmpty()) { return null; } // Find the leftmost longest match Iterator<Match> iterator = matches.iterator(); Match result = iterator.next(); while (iterator.hasNext()) { Match candidate = iterator.next(); int comparison = Integer.compare(candidate.getOffset(), result.getOffset()); if (comparison < 0) { result = candidate; } } return result; }
// we have a full match. Standard Aho-Corasick would take the fail link on // the next character, which may or may not take us to root, and keep on // looking for more matches. We stop instead if we are looking only for the // first match. Note that we _do_ have a match at least from this node itself, // since terminal nodes in the trie always match, and it is by definition // also the longest match. matches.add(new MatchResult(node.match, i - node.match.length() + 1)); break; if (node.match != null) { matches.add(new MatchResult(node.match, i - node.match.length() + 1)); } if (!firstOnly || matches.isEmpty()) { Node out = node.output; while (out != null) { matches.add(new MatchResult(out.match, i - out.match.length() + 1)); out = out.output; } } return matches;
@Test public void noStrings003() throws Exception { thrown.expect(IllegalStateException.class); MultiStringMatcher.builder().add((String[]) null).build(); } @Test public void fluent001() throws Exception { MultiStringMatcher m = MultiStringMatcher.builder().add("he", "she", "his", "hers").build(); test(m.indexOf("ushers", 0), "she", 1); } @Test public void fluent002() throws Exception { MultiStringMatcher m = MultiStringMatcher.builder().add("he", "she").add("his", "hers").build(); testList(m.find("ushers", 0), "[[she, 1], [he, 2], [hers, 2]]"); }
public Match indexOf(String text, int offset) { List<Match> matches = find(text, offset, true); if (matches.isEmpty()) { return null; } // Find the leftmost longest match. Match result = matches.get(0); for (int i = 1; i < matches.size(); i++) { Match cand = matches.get(i); if (cand.getOffset() > result.getOffset()) { // Results are ordered by offset. There will be no leftmost match as all we checked. break; } if (cand.getText().length() > result.getText().length()) { result = cand; } } return result; }
package org.eclipse.tycho.pomless; import java.io.File; import java.io.FileFilter; import java.io.IOException; import org.apache.maven.model.Model; import org.apache.maven.model.io.ModelParseException; import org.codehaus.plexus.component.annotations.Component; import org.sonatype.maven.polyglot.mapping.Mapping; import org.w3c.dom.Element; @Component(role = Mapping.class, hint = "eclipse-target-definition") public class TychoTargetMapping extends AbstractXMLTychoMapping { private static final String TARGET_EXTENSION = ".target"; public static final String ROLE = "eclipse-target-definition"; @Override public String getFlavour() { return ROLE; } @Override protected boolean isValidLocation(String location) { return location.endsWith(TARGET_EXTENSION); } @Override protected File getPrimaryArtifact(File dir) { File file = new File(dir, dir.getName() + TARGET_EXTENSION); if (file.exists()) { return file; } File[] listFiles = dir.listFiles(new FileFilter() { @Override public boolean accept(File file) { return file.getName().endsWith(TARGET_EXTENSION); } }); if (listFiles != null && listFiles.length > 0) { return listFiles[0]; } return null; } @Override protected Model parseModel(File file) throws IOException, ModelParseException { return super.parseModel(file); } @Override protected void writeModel(Model model, Element root) { super.writeModel(model, root); } }
@Override public void checkPermission(Permission requested) { for (Permission permission : permissions) { if (permission.implies(requested)) { return; } } super.checkPermission(requested); } @After public void tearDown() throws Exception { System.setSecurityManager(originalSecurityManager); FileUtils.delete(root, FileUtils.RECURSIVE); } @Test public void testInitAndClone() throws IOException, GitAPIException { File remote = new File(root, "remote"); File local = new File(root, "local"); try (Git git = Git.init().setDirectory(remote).call()) { JGitTestUtil.write(new File(remote, "hello.txt"), "Hello world!"); git.add().addFilepattern(".").call(); git.commit().setMessage("Initial commit").call(); } }
protected static File searchPath(String path, String... lookFor) { if (path == null) return null; for (String p : path.split(File.pathSeparator)) { for (String command : lookFor) { final File file = new File(p, command); try { if (file.isFile()) { return file.getAbsoluteFile(); } } catch (SecurityException e) { LOG.warn(JGitText.get().pathNotAccessibleSkipIt(file.getPath())); } } } return null; }
protected Control createDialogArea(Composite parent) { Composite main = new Composite(parent, SWT.NONE); GridLayoutFactory.fillDefaults().numColumns(2).applyTo(main); GridDataFactory.fillDefaults().grab(true, false).indent(5, 5).applyTo(main); Label branchLabel = new Label(main, SWT.NONE); branchLabel.setText(UIText.BranchConfigurationDialog_UpstreamBranchLabel); branchText = new Combo(main, SWT.BORDER); GridDataFactory.fillDefaults().grab(true, false).applyTo(branchText); try { for (Ref ref : myRepository.getRefDatabase().getRefs(Constants.R_HEADS).values()) { branchText.add(ref.getName()); } for (Ref ref : myRepository.getRefDatabase().getRefs(Constants.R_REMOTES).values()) { branchText.add(ref.getName()); } } catch (IOException e) { Activator.logError("Exception getting Refs", e); } Label remoteLabel = new Label(main, SWT.NONE); remoteLabel.setText("Rem&ote:"); // TODO } public void createControl(Composite parent) { Composite container = new Composite(parent, SWT.NULL); GridLayout layout = new GridLayout(); container.setLayout(layout); layout.numColumns = 3; layout.verticalSpacing = 9; Label label = new Label(container, SWT.NULL); label.setText(Messages.getString("StapNewWizardPage.ScriptName")); //$NON-NLS-1$ fileText = new Text(container, SWT.BORDER | SWT.SINGLE); GridData gd = new GridData(GridData.FILL_HORIZONTAL); fileText.setLayoutData(gd); fileText.addModifyListener(new ModifyListener() { public void modifyText(ModifyEvent e) { dialogChanged(); } }); label = new Label(container, SWT.NULL); // XXX just create a new layout with different width label = new Label(container, SWT.NULL); label.setText("&Directory:"); containerText = new Text(container, SWT.BORDER | SWT.SINGLE); gd = new GridData(GridData.FILL_HORIZONTAL); containerText.setLayoutData(gd); containerText.addModifyListener(new ModifyListener() { public void modifyText(ModifyEvent e) { dialogChanged(); } }); } public void refreshTraceType() { try { fTraceTypeId = getResource().getPersistentProperty
@Override public void synchronize(final IProject project, RemoteLocation rl, IResourceDelta delta, IProgressMonitor monitor, Set<SyncFlag> syncFlags) throws CoreException { if (project == null || rl == null) { throw new NullPointerException(); } if (project != null && delta != null && project.getFile(gitDir).getFullPath().isPrefixOf(delta.getFullPath())) { return; } RemoteLocation remoteLoc = new RemoteLocation(rl); ProjectAndRemoteLocationPair syncTarget = new ProjectAndRemoteLocationPair(project, remoteLoc); if(syncFlags.contains(SyncFlag.WAIT_FOR_LR)) { try { SyncInt si = syncLRPending.get(syncTarget); // ... } catch (InterruptedException e) { // ... } } // ... }
@Override public void synchronize(final IProject project, RemoteLocation rl, IResourceDelta delta, IProgressMonitor monitor, Set<SyncFlag> syncFlags) throws CoreException { if (project == null || rl == null) { throw new NullPointerException(); } if (project != null && delta != null && project.getFile(gitDir).getFullPath().isPrefixOf(delta.getFullPath())) { return; // ignore deltas prefixed by gitDir } RemoteLocation remoteLoc = new RemoteLocation(rl); ProjectAndRemoteLocationPair syncTarget = new ProjectAndRemoteLocationPair(project, remoteLoc); if(syncFlags.contains(SyncFlag.WAIT_FOR_LR)) { try { SyncInt si = syncLRPending.get(syncTarget); if (si != null) { si.waitForZero(); } } catch (InterruptedException e) { Activator.log(e); } return; } }
public void paste() { checkWidget(); if ((style & SWT.READ_ONLY) != 0) return; OS.SendMessage(handle, OS.WM_PASTE, 0, 0); } void stateFlagsAdd(int flags) { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); if (tagCBoxPtr == 0) return; final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); stateFlags[0] |= flags; OS.MoveMemory(stateFlagsPtr, stateFlags, 4); }
private boolean stateFlagsTest() { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); if (tagCBoxPtr == 0) { return false; } final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); return (stateFlags[0] == 0x02006002); }
boolean stateFlagsTest() { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); if (tagCBoxPtr != 0) { final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); return (stateFlags[0] == 0x02006002); } return false; } @Override void register() { // Bug 550423: When non-XP-theme COMMCTL32.DLL gets loaded, undocumented internal data is not there. We do not support that. }
protected void execute() { MetroOrchestrationService ceManager = get(MetroOrchestrationService.class); argEvcConnIdList.forEach(id -> { EvcConnId evcId = EvcConnId.of(id); if (ceManager.evcMap.containsKey(evcId)) { ceManager.removeEvc(evcId); print("Removed EVC %s", evcId.toString()); } else { print("EVC %s doesn't exist", evcId.toString()); } }); } if (Predicate.isEquivalencePredicate(e)) { BinaryPredicate bp = ((BinaryPredicate) e); if (bp.isSingleColumnPredicate(slotRef, null)) { columnNames.add(slotRef.getRef().getDesc().getColumn().getName()); } else { ignore = true; logExpr = e; break; } } else if (e instanceof IsNullPredicate) { IsNullPredicate nullPredicate = (IsNullPredicate) e; Column partColumn = nullPredicate.getBoundSlot().getDesc().getColumn(); Preconditions.checkState(clusterColumns.contains(partColumn)); partColNames.add(partColumn.getName()); } else { ignore = true; logExpr = e; break; } if (ignore) { partitionShouldExist_ = null; LOG.info(String.format("Ignoring IF EXISTS since there are more general partition expr %s.", logExpr)); } else if (columnNames.size() < table.getMetaStoreTable().getPartitionKeysSize()) { partitionShouldExist_ = null; } if (length == OS.CB_ERR) { int count = (int)/*64*/OS.SendMessage(handle, OS.CB_GETCOUNT, 0, 0); if (0 <= index && index < count) { error(SWT.ERROR_ITEM_NOT_REMOVED); } error(SWT.ERROR_INVALID_RANGE); } buffer = new TCHAR(getCodePage(), length + 1); int result = (int)/*64*/OS.SendMessage(handle, OS.CB_GETLBTEXT, index, buffer); if (result == OS.CB_ERR) { int count = (int)/*64*/OS.SendMessage(handle, OS.CB_GETCOUNT, 0, 0); if (0 <= index && index < count) { error(SWT.ERROR_ITEM_NOT_REMOVED); } error(SWT.ERROR_INVALID_RANGE);
private static final String pageName = "Scripts"; private ToolItem abortButton; private ToolItem abortBatchButton; private CoolBar coolBar; private ToolItem deleteButton; private Label hostConnectLabel; private LoadWidget loadWidget; protected ToolItem runButton; private SaveWidget saveWidget; private ScriptTableViewer scriptTable; private StatusWindowWidget statusWindow; private final TestManagerEditor testManagerEditor; private ProgramButtonProviderService programButtonProviderService; public ScriptPage(Composite parent, int style, TestManagerEditor parentTestManager) { super(parent, style, parentTestManager); this.testManagerEditor = parentTestManager; } public void addFile(String fullPath) { scriptTable.addFile(fullPath); } @Override public void createPage() { super.createPage(); Composite parent = (Composite) getContent(); coolBar = new CoolBar(parent, SWT.FLAT); createControlsToolBar(coolBar); createConfigurationToolBar(coolBar); packCoolBar(); }
} // Example: As above, but to be moved to the appropriate class/location. ILibraryLinkerProviderService libraryLinkerProviderService = OsgiUtil.getService(ILibraryLinkerProvider.class, LibraryLinkerProviderService.class); for (ILibraryLinkerProvider provider : libraryLinkerProviderService.getLibraryLinkerProviders()) { provider.getLibraryLinkers(); } // Example: As above, but to be moved to the appropriate class/location. ILaunchAndKillProviderService launchAndKillProviderService = OsgiUtil.getService(ILaunchAndKillProvider.class, LaunchAndKillProviderService.class); // @formatter:off // Example to launch and kill processes: for (ILaunchAndKillProvider provider : launchAndKillProviderService.getLaunchAndKillProviders()) { Collection<ILaunchAndKill> launchers = provider.getLaunchers(); Collection<ILaunchAndKill> killers = provider.getKillers(); for (ILaunchAndKill launcher : launchers) { Process launchProcess; // To access Process methods //launchProcess = launcher.executeProcess(); // Launches the process break; } for (ILaunchAndKill killer : killers) { Process killProcess; // To access Process methods
if (selection.getFirstElement() instanceof Table) { this.exportedTable = (Table) selection.getFirstElement(); } else if (selection instanceof TableStructuredSelection) { final TableStructuredSelection tss = (TableStructuredSelection) selection; final INattableModelManager tableModelManager = (INattableModelManager) tss.getAdapter(INattableModelManager.class); if (null != tableModelManager) { this.exportedTable = tableModelManager.getTable(); } } Assert.isNotNull(this.exportedTable, "We can't found the table to export"); //$NON-NLS-1$ IStatus status = TableChecker.checkTable(this.exportedTable); if (false == status.isOK()) { addPage(new WarningOnCurrentTableWizardPage(status)); } this.outputPage = new DefineOutputPluginWizardPage(); this.tableDataPage = new DefineTableConfigurationDataWizardPage(); this.outputPage.setExportedTable(this.exportedTable); this.tableDataPage.setExportedTable(this.exportedTable); addPage(outputPage); addPage(tableDataPage);
if (field != null) { return new JDIFieldVariable(debugTarget, field, getUnderlyingObject(), fLogicalParent); } // Check possible references of variables defined in outer class for (Field outer : synteticFields) { // retrieve the reference to the "outer" object JDIFieldVariable syntVariable = new JDIFieldVariable(debugTarget, outer, getUnderlyingObject(), fLogicalParent); IValue value = syntVariable.getValue(); if (value instanceof JDIObjectValue) { JDIObjectValue outerObject = (JDIObjectValue) value; if (outerObject != null) { // ask "outer" object about field probably declared within return outerObject.getField(name, outer.signature()); } } } } catch (RuntimeException e) { targetRequestFailed( MessageFormat.format(JDIDebugModelMessages.JDIObjectValue_exception_retrieving_field, e.toString()), e); } // it is possible to return null return null; } static List<ReferenceType> superTypes(ReferenceType type) { List<ReferenceType> superTypes = new ArrayList<>(); ReferenceType t = type;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.Routing; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.RoutingBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class InterfaceRoutingCustomizerTest extends WriterCustomizerTest { private static final String IFACE_CTX_NAME = "interface-ctx"; private static final String IF_NAME = "eth1"; private static final int IF_INDEX = 1; private static final InstanceIdentifier<Routing> IID = InstanceIdentifier.create(Interfaces.class) .child(Interface.class, new InterfaceKey(IF_NAME)) .augmentation(VppInterfaceAugmentation.class) .child(Routing.class); private InterfaceRoutingCustomizer customizer; @Override protected void setUpTest() throws Exception { customizer = new InterfaceRoutingCustomizer(api, new NamingContext("ifacePrefix", IFACE_CTX_NAME)); } }
import java.util.Collections; import java.util.Set; import org.junit.Test; import org.mockito.ArgumentCaptor; import org.mockito.Captor; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.Interfaces; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.interfaces.Interface; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.interfaces.InterfaceKey; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.SubinterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.SubInterfaces; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.sub.interfaces.SubInterface; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.sub.interfaces.SubInterfaceBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VxlanVni; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.Vxlan; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.VxlanBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class VxlanCustomizerTest extends WriterCustomizerTest implements AddressTranslator { private static final byte ADD_VXLAN = 1; private static final byte DEL_VXLAN = 0; @Mock private DisabledInterfacesManager disableContext; private VxlanCustomizer customizer; private String ifaceName; private InstanceIdentifier<Vxlan> id; private static Vxlan generateVxlan(long vni) { final VxlanBuilder builder = new VxlanBuilder(); builder.setSrc(new IpAddressNoZone(new Ipv4AddressNoZone("192.168.20.10"))); // rest of the code } }
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceStateAugmentationBuilder; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces.state._interface.Routing; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces.state._interface.RoutingBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class InterfaceRoutingCustomizerTest extends ReaderCustomizerTest<Routing, RoutingBuilder> { private static final String IFC_CTX_NAME = "ifc-test-instance"; private static final String IF_NAME = "local0"; private static final int IF_ID = 1; private static final Long IP4_VRF_ID = 1L; private static final Long IP6_VRF_ID = 2L; private NamingContext interfacesContext; public InterfaceRoutingCustomizerTest() { super(Routing.class, VppInterfaceStateAugmentationBuilder.class); } @Override public void setUp() { // Code for setup } }
namingContext.removeChild(PARENT_1, CHILD_1, mappingContext); verify(mappingContext, times(1)).put(instanceIdentifierArgumentCaptor.capture(), mappingArgumentCaptor.capture()); assertEquals(instanceIdentifierArgumentCaptor.getValue(), parentKey(PARENT_1)); final Mapping mapping = mappingArgumentCaptor.getValue(); final List<Value> values = mapping.getValue(); assertEquals(PARENT_1, mapping.getName()); assertThat(values, hasSize(2)); assertThat(values, containsInAnyOrder(valueFor(CHILD_2, 2), valueFor(CHILD_3, 3))); @Test public void removeChildNonExistingParent() { namingContext.removeChild(NON_EXISTING_PARENT, CHILD_1, mappingContext); // if parent does not exist, do nothing verify(mappingContext, times(0)).put(Mockito.any(), Mockito.any()); } private Value valueFor(final String name, final int index) { return new ValueBuilder().setName(name).setIndex(index).withKey(new ValueKey(name)).build(); }
import io.fd.hc2vpp.ipsec.read.IpsecReaderFactory; import io.fd.hc2vpp.ipsec.write.IpsecWriterFactory; import io.fd.honeycomb.translate.read.ReaderFactory; import io.fd.honeycomb.translate.write.WriterFactory; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * Module class instantiating nat plugin components. */ public class IpsecModule extends AbstractModule { private static final Logger LOG = LoggerFactory.getLogger(IpsecModule.class); public static final String SAD_ENTRIES_MAPPING = "sad-entries-mapping"; @Override protected void configure() { LOG.info("Installing IPSec module"); bind(MultiNamingContext.class).toInstance(new MultiNamingContext(SAD_ENTRIES_MAPPING, 1)); LOG.info("Injecting writers factories"); final Multibinder<WriterFactory> writerFactoryBinder = Multibinder.newSetBinder(binder(), WriterFactory.class); writerFactoryBinder.addBinding().to(IpsecWriterFactory.class).in(Singleton.class); LOG.info("Injecting readers factories"); final Multibinder<ReaderFactory> readerFactoryBinder = Multibinder.newSetBinder(binder(), ReaderFactory.class); readerFactoryBinder.addBinding().to(IpsecReaderFactory.class).in(Singleton.class); } }
import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecStateSpdAugmentationBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.Spd; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.spd.SpdEntries; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public final class IpsecReaderFactory implements ReaderFactory { private static final InstanceIdentifier<IpSecState> IPSEC_STATE_ID = InstanceIdentifier.create(IpSecState.class); private FutureJVppCore vppApi; @Inject public IpsecReaderFactory(final FutureJVppCore vppApi) { this.vppApi = vppApi; } @Override public void init(@Nonnull final ModifiableReaderRegistryBuilder registry) { registry.subtreeAdd(Sets.newHashSet( InstanceIdentifier.create(IpSecState.class).child(Sa.class), InstanceIdentifier.create(IpSecState.class).augmentation(IpsecStateSpdAugmentation.class).child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpSecStateCustomizer(vppApi))); } }
import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecStateSpdAugmentationBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.Spd; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.spd.SpdEntries; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public final class IpsecReaderFactory implements ReaderFactory { private static final InstanceIdentifier<IpsecState> IPSEC_STATE_ID = InstanceIdentifier.create(IpsecState.class); private FutureJVppCore vppApi; @Inject public IpsecReaderFactory(final FutureJVppCore vppApi) { this.vppApi = vppApi; } @Override public void init(@Nonnull final ModifiableReaderRegistryBuilder registry) { registry.subtreeAdd(Sets.newHashSet( InstanceIdentifier.create(IpsecState.class).child(Sa.class), InstanceIdentifier.create(IpsecState.class).augmentation(IpsecStateSpdAugmentation.class).child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpsecStateCustomizer(vppApi))); } }
InstanceIdentifier.create(IpsecState.class) .augmentation(IpsecStateSpdAugmentation.class) .child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpsecStateCustomizer(vppApi))); registry.addStructuralReader(IPSEC_STATE_ID.augmentation(IpsecStateSpdAugmentation.class), IpsecStateSpdAugmentationBuilder.class); registry.subtreeAdd(Sets.newHashSet(InstanceIdentifier.create(Spd.class).child(SpdEntries.class)), new GenericInitListReader<>(IPSEC_STATE_ID.augmentation(IpsecStateSpdAugmentation.class).child(Spd.class), new IpsecStateSpdCustomizer(vppApi)));
public IpsecStateCustomizer(final FutureJVppCore vppApi) { super(vppApi); this.ipsecSaDetailsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSaDetailsReplyDump, Void>() .withExecutor(new IpsecStateCustomizer.IpsecStateSaDetailsDumpExecutor(vppApi)) .acceptOnly(IpsecSaDetailsReplyDump.class) .build(); }
return Initialized.create(id, readValue); } @Nonnull @Override public IpsecStateBuilder getBuilder(@Nonnull final InstanceIdentifier<IpsecState> id) { return new IpsecStateBuilder(); } @Override public void readCurrentAttributes(@Nonnull final InstanceIdentifier<IpsecState> id, @Nonnull final IpsecStateBuilder builder, @Nonnull final ReadContext ctx) throws ReadFailedException { final Optional<IpsecSaDetailsReplyDump> dumpSa = ipsecSaDetailsReplyDumpManager.getDump(id, ctx.getModificationCache()); if (dumpSa.isPresent()) { LinkedList<Sa> listSa = new LinkedList<>(); IpsecSaDetailsReplyDump reply = dumpSa.get(); for (IpsecSaDetails details : reply.ipsecSaDetails) { SaBuilder saBuilder = new SaBuilder(); saBuilder.setSpi(Integer.toUnsignedLong(details.spi)); saBuilder.setAntiReplayWindow(Long.valueOf(details.replayWindow).intValue()); saBuilder.setAuthenticationAlgorithm(IkeIntegrityAlgorithmT.forValue(details.integAlg)); saBuilder.setEncryptionAlgorithm(IkeEncryptionAlgorithmT.forValue(details.cryptoAlg)); listSa.add(saBuilder.build()); } builder.setSa(listSa); } } @Override
if (dumpSa.isPresent()) { LinkedList<Sa> listSa = new LinkedList<>(); IpsecSaDetailsReplyDump reply = dumpSa.get(); for (IpsecSaDetails details : reply.ipsecSaDetails) { SaBuilder saBuilder = new SaBuilder(); saBuilder.setSpi(Integer.toUnsignedLong(details.spi)); saBuilder.setAntiReplayWindow(Long.valueOf(details.replayWindow).intValue()); saBuilder.setAuthenticationAlgorithm(IkeIntegrityAlgorithmT.forValue(details.integAlg)); saBuilder.setEncryptionAlgorithm(IkeEncryptionAlgorithmT.forValue(details.cryptoAlg)); listSa.add(saBuilder.build()); } builder.setSa(listSa); } @Override public void merge(@Nonnull final Builder<? extends DataObject> parentBuilder, @Nonnull final IpsecState readValue) { IpsecStateBuilder ipsecParentBuilder = (IpsecStateBuilder)parentBuilder; ipsecParentBuilder.setHoldDown(readValue.getHoldDown()); ipsecParentBuilder.setPolicy(readValue.getPolicy()); ipsecParentBuilder.setProposal(readValue.getProposal()); ipsecParentBuilder.setRedundancy(readValue.getRedundancy()); ipsecParentBuilder.setSa(readValue.getSa()); }
implements EntityDumpExecutor<IpsecSaDetailsReplyDump, Void>, JvppReplyConsumer { private final FutureJVppCore jvpp; IpsecStateSaDetailsDumpExecutor(final FutureJVppCore jvpp) { this.jvpp = jvpp; } @Nonnull @Override public IpsecSaDetailsReplyDump executeDump(final InstanceIdentifier<?> identifier, final Void params) throws ReadFailedException { IpsecSaDump dump = new IpsecSaDump(); dump.saId = -1; return getReplyForRead(jvpp.ipsecSaDump(dump).toCompletableFuture(), identifier); } }
Fixed Code: } } } @Override public void updateCurrentAttributes(@Nonnull final InstanceIdentifier<IkeGlobalConfiguration> id, @Nonnull final IkeGlobalConfiguration dataBefore, @Nonnull final IkeGlobalConfiguration dataAfter, @Nonnull final WriteContext writeContext) throws WriteFailedException { writeCurrentAttributes(id, dataAfter, writeContext); } @Override public void deleteCurrentAttributes(@Nonnull final InstanceIdentifier<IkeGlobalConfiguration> id, @Nonnull final IkeGlobalConfiguration dataBefore, @Nonnull final WriteContext writeContext) throws WriteFailedException { // TODO Auto-generated method stub }
String name = id.firstKeyOf(Policy.class).getName(); if (dataAfter.getLocal() != null) { setProfileId(id, name, dataAfter.getLocal().getIdentity(), true); } if (dataAfter.getRemote() != null) { setProfileId(id, name, dataAfter.getRemote().getIdentity(), false); } @Override public void deleteCurrentAttributes(@Nonnull final InstanceIdentifier<Identity> id, @Nonnull final Identity dataBefore, @Nonnull final WriteContext writeContext) throws WriteFailedException { } @Override public void updateCurrentAttributes(@Nonnull final InstanceIdentifier<Identity> id, @Nonnull final Identity dataBefore, @Nonnull final Identity dataAfter, @Nonnull final WriteContext writeContext) throws WriteFailedException { writeCurrentAttributes(id, dataAfter, writeContext); } private void setProfileId(final InstanceIdentifier<Identity> id, final String profileName, final org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.identity.grouping.Identity data, final boolean isLocalId) throws WriteFailedException { // implementation goes here }
IpsecSadEntriesAugmentation augment = dataAfter.augmentation(IpsecSadEntriesAugmentation.class); if (augment != null && augment.getSaId() != null) { entry.sadId = augment.getSaId(); } if (dataAfter.getSpi() != null) { entry.spi = dataAfter.getSpi().intValue(); } if (dataAfter.getAntiReplayWindow() != null) { entry.useAntiReplay = dataAfter.getAntiReplayWindow() > 0 ? BYTE_TRUE : BYTE_FALSE; } if (dataAfter.getSaMode() != null) { entry.isTunnel = Integer.valueOf(dataAfter.getSaMode().getIntValue()).byteValue(); } entry.isAdd = adding ? ByteDataTranslator.BYTE_TRUE : ByteDataTranslator.BYTE_FALSE; if (dataAfter.getEsp() != null) { entry.protocol = 1; fillEspAuthentication(entry, dataAfter.getEsp()); fillEspEncryption(entry, dataAfter.getEsp()); } else if (dataAfter.getAh() != null) { entry.protocol = 0; }
import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecIkeGlobalConfAugmentation; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecSadEntriesAugmentation; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecSpdEntriesAugmentation; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public final class IpsecWriterFactory implements WriterFactory { private static final InstanceIdentifier<Ikev2> IKE2_ID = InstanceIdentifier.create(Ikev2.class); private static final InstanceIdentifier<Ipsec> IPSEC_ID = InstanceIdentifier.create(Ipsec.class); private static final InstanceIdentifier<Sad> SAD_ID = IPSEC_ID.child(Sad.class); private static final InstanceIdentifier<SadEntries> SAD_ENTRIES_ID = SAD_ID.child(SadEntries.class); private static final InstanceIdentifier<Spd> SPD_ID = IPSEC_ID.child(Spd.class); private final FutureJVppCore vppApi; private MultiNamingContext sadEntriesMapping; @Inject public IpsecWriterFactory(FutureJVppCore vppApi) { this.vppApi = vppApi; } }
public void init(@Nonnull final ModifiableWriterRegistryBuilder registry) { registry.subtreeAdd(Sets.newHashSet( InstanceIdentifier.create(SadEntries.class).child(SourceAddress.class), InstanceIdentifier.create(SadEntries.class).child(DestinationAddress.class), InstanceIdentifier.create(SadEntries.class).child(Ah.class) .child(org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ipsec.sa.ah.grouping.ah.authentication.algorithm.hmac.sha1._96.HmacSha196.class), InstanceIdentifier.create(SadEntries.class).child(Ah.class) .child(org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ipsec.sa.ah.grouping.ah.authentication.algorithm.hmac.md5._96.HmacMd596.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Authentication.class).child(HmacSha196.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Authentication.class).child(HmacMd596.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Encryption.class).child(Aes128Cbc.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Encryption.class).child(Aes192Cbc.class) )); }
org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ikev2.policy.profile.grouping.Authentication.class), InstanceIdentifier.create(Policy.class).child(TrafficSelectors.class)), new GenericListWriter<>(IKE2_ID.child(Policy.class), new Ikev2PolicyCustomizer(vppApi))); registry.subtreeAdd(Sets.newHashSet(InstanceIdentifier.create(Identity.class).child(Local.class), InstanceIdentifier.create(Identity.class).child(Remote.class)), new GenericWriter<>(IKE2_ID.child(Policy.class).child(Identity.class), new Ikev2PolicyIdentityCustomizer(vppApi)));
package io.fd.hc2vpp.ipsec; import com.google.inject.AbstractModule; import com.google.inject.Singleton; import com.google.inject.multibindings.Multibinder; import io.fd.hc2vpp.common.translate.util.MultiNamingContext; import io.fd.hc2vpp.ipsec.read.IpsecReaderFactory; import io.fd.hc2vpp.ipsec.write.IpsecWriterFactory; import io.fd.honeycomb.translate.read.ReaderFactory; import io.fd.honeycomb.translate.write.WriterFactory; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class IpsecModule extends AbstractModule { private static final Logger LOG = LoggerFactory.getLogger(IpsecModule.class); private static final String SAD_ENTRIES_MAPPING = "sad-entries-mapping"; @Override protected void configure() { LOG.info("Installing IPSec module"); bind(MultiNamingContext.class).toInstance(new MultiNamingContext(SAD_ENTRIES_MAPPING, 1)); LOG.info("Injecting writers factories"); final Multibinder<WriterFactory> writerFactoryBinder = Multibinder.newSetBinder(binder(), WriterFactory.class); writerFactoryBinder.addBinding().to(IpsecWriterFactory.class).in(Singleton.class); } }
super(vppApi); IpsecStateSpdsReplyDumpExecutor spdsExecutor = new IpsecStateSpdCustomizer.IpsecStateSpdsReplyDumpExecutor(vppApi); this.ipsecSpdsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSpdsDetailsReplyDump, Void>() .withExecutor(spdsExecutor) .acceptOnly(IpsecSpdsDetailsReplyDump.class) .build(); this.ipsecSpdDetailsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSpdDetailsReplyDump, Void>() .withExecutor(new IpsecStateSpdCustomizer.IpsecStateSpdDetailsDumpExecutor(vppApi, spdsExecutor)) .acceptOnly(IpsecSpdDetailsReplyDump.class) .build();
public void init(@Nonnull final ModifiableWriterRegistryBuilder registry) { InstanceIdentifier<Policer> IID = InstanceIdentifier.create(Policer.class); registry.subtreeAdd( Sets.newHashSet( IID.child(ConformAction.class), IID.child(ExceedAction.class), IID.child(ViolateAction.class) ), new GenericListWriter<>( POLICER_IID, new PolicerCustomizer(vppApi, policerContext), new PolicerValidator(policerContext) ) ); }
/* Copyright (c) 2017 Cisco and/or its affiliates. * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at: * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package io.fd.hc2vpp.l3.write.ipv4; import static com.google.common.base.Preconditions.checkNotNull; import io.fd.hc2vpp.common.translate.util.NamingContext; import io.fd.honeycomb.translate.write.DataValidationFailedException; import io.fd.honeycomb.translate.write.Validator; import io.fd.honeycomb.translate.write.WriteContext; import javax.annotation.Nonnull;
public static final class StatsConnectionInfo { public final long queueAddress; public final int clientIndex; public final int status; // FIXME throw exception instead public final int pid; public StatsConnectionInfo(long queueAddress, int clientIndex, int status, int pid) { this.queueAddress = queueAddress; this.clientIndex = clientIndex; this.status = status; this.pid = pid; } } private static native StatsConnectionInfo statsConnect(String clientName); private static native void statsDisconnect();
public void onInterfaceStatisticsDetails(final io.fd.jvpp.stats.dto.InterfaceStatisticsDetails reply) { io.fd.jvpp.stats.callback.InterfaceStatisticsDetailsCallback callback; final int replyId = reply.context; if (LOG.isLoggable(java.util.logging.Level.FINE)) { LOG.fine(String.format("Received InterfaceStatisticsDetails event message: %s", reply)); } synchronized (requests) { callback = (io.fd.jvpp.stats.callback.InterfaceStatisticsDetailsCallback) requests.remove(replyId); } if (callback != null) { callback.onInterfaceStatisticsDetails(reply); } }
package io.fd.jvpp.stats.dto; public final class InterfaceStatisticsDump implements io.fd.jvpp.dto.JVppDump { @Override public int hashCode() { return java.util.Objects.hash(); } @Override public boolean equals(final Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } return true; } @Override public String toString() { return "InterfaceStatisticsDump{}"; } @Override public void writeObject(BufferWriter writer) { // TODO: Implement writeObject method } @Override public void readObject(BufferReader reader) { // TODO: Implement readObject method } }
} synchronized(requests) { CompletableFuture<? extends JVppReply<?>> replyFuture = requests.get(contextId); if (replyFuture == null) { // reply not received yet, put new future to map replyDumpFuture = new CompletableDumpFuture<>(contextId, emptyReplyDump); requests.put(contextId, replyDumpFuture); } else { // reply already received, save existing future replyDumpFuture = (CompletableDumpFuture<DUMP>) replyFuture; } } synchronized (requests) { // reply already received, complete future replyDumpFuture.complete(replyDumpFuture.getReplyDump()); requests.remove(contextId); } // TODO in case of timeouts/missing replies, requests from the map are not removed // consider adding cancel method, that would remove requests from the map and cancel // associated replyCompletableFuture return replyDumpFuture; } catch (VppInvocationException ex) { final CompletableFuture<DUMP> replyCompletableFuture = new CompletableFuture<>(); replyCompletableFuture.completeExceptionally(ex); return replyCompletableFuture; } }
.get(replyId); if (completableFuture == null) { // reply received before writer created future, // create new future, and put into map to notify sender that reply is already received, // following details replies will add information to this future completableFuture = new io.fd.jvpp.stats.future.AbstractFutureJVppInvoker.CompletableDumpFuture<>(replyId, new InterfaceStatisticsDetailsReplyDump()); requests.put(replyId, completableFuture); } completableFuture.getReplyDump().interfaceStatisticsDetails = reply; }
public InterfaceStatisticsCustomizer(final NamingContext ifcNamingCtx, final FutureJVppStatsFacade jvppStats, final InterfaceStatisticsCollectionManager statisticsManager) { this.ifcNamingCtx = checkNotNull(ifcNamingCtx, "Naming context should not be null"); this.jvppStats = checkNotNull(jvppStats, "JVpp Stats facade should not be null"); this.statisticsManager = checkNotNull(statisticsManager, "Statistics Collection Manager should not be null"); }
.setInMulticastPkts(new Counter64(BigInteger.valueOf(detail.inMulticastPkts))) .setInBroadcastPkts(new Counter64(BigInteger.valueOf(detail.inBroadcastPkts))) .setInErrors(new Counter32(new Long(detail.inErrors))); } } } @Override public void merge(@Nonnull final Builder<? extends DataObject> builder, @Nonnull final Statistics statistics) { ((InterfaceBuilder) builder).setStatistics(statistics); } private InterfaceStatisticsDetails getStatisticsDump(InstanceIdentifier<Statistics> id) throws ReadFailedException { LOG.info("Sending InterfaceStatisticsDump request..."); final InterfaceStatisticsDump request = new InterfaceStatisticsDump(); final Future<InterfaceStatisticsDetailsReplyDump> replyFuture = jvppStats.interfaceStatisticsDump(request).toCompletableFuture(); final InterfaceStatisticsDetailsReplyDump reply; try { reply = replyFuture.get(); } catch (Exception e) { throw new ReadFailedException(id, e); } if (reply == null || reply.interfaceStatisticsDetails == null) { throw new ReadFailedException(id, new IllegalStateException("Received null response for empty dump: " + reply)); } return reply.interfaceStatisticsDetails; }
public L2Validator(final NamingContext interfaceContext, final NamingContext bridgeDomainContext) { checkNotNull(interfaceContext, "interfaceContext should not be null"); checkNotNull(bridgeDomainContext, "bridgeDomainContext should not be null"); }
public SubInterfaceL2Validator(final NamingContext interfaceContext, final NamingContext bridgeDomainContext) { checkNotNull(interfaceContext, "interfaceContext should not be null"); checkNotNull(bridgeDomainContext, "bridgeDomainContext should not be null"); }
public VxlanValidator(@Nonnull final NamingContext interfaceNamingContext, @Nonnull final DisabledInterfacesManager disabledInterfacesManager) { checkNotNull(interfaceNamingContext, "interfaceContext should not be null"); checkNotNull(disabledInterfacesManager, "DisabledInterfacesManager should not be null"); }
private void validateVxlan(final Vxlan data) { checkNotNull(data.getSrc()); checkNotNull(data.getDst()); if (data.getSrc().getIpv4AddressNoZone() == null) { checkArgument(data.getDst().getIpv4AddressNoZone() == null, "Inconsistent ip addresses: %s, %s", data.getSrc(), data.getDst()); } else { checkArgument(data.getDst().getIpv6AddressNoZone() == null, "Inconsistent ip addresses: %s, %s", data.getSrc(), data.getDst()); } checkArgument(data.getEncapVrfId() != null && data.getEncapVrfId().getValue() != null, "encap-vrf-id is mandatory but was not given"); checkNotNull(data.getVni()); }
public String getTxtProjectName() { return mProjectNameResult; } private void createTxtProjectName(Composite parent) { mTxtProjectName = new Text(parent, SWT.BORDER); mTxtProjectName.addModifyListener(new ModifyListener() { @Override public void modifyText(ModifyEvent e) { mProjectNameResult = mTxtProjectName.getText(); } }); }
public String getTxtProjectID() { return mTxtProjectID.getText(); }
public String getTxtProjectPath() { return mTxtProjectPath.getText(); }
import javax.annotation.PostConstruct; import org.eclipse.jface.viewers.TreeViewer; import org.eclipse.swt.SWT; import org.eclipse.swt.layout.FormAttachment; import org.eclipse.swt.layout.FormData; import org.eclipse.swt.layout.FormLayout; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Tree; import com.samsung.dali.modelconverter.view.dialogs.TizenPathDialog; public class SceneGraphPart { @PostConstruct public void createComposite(Composite parent) { TizenPathDialog.VerifyTizenPath(parent.getShell(), false); parent.setLayout(new FormLayout()); TreeViewer treeViewer = new TreeViewer(parent, SWT.BORDER); Tree tree = treeViewer.getTree(); FormData fd_tree = new FormData(); fd_tree.bottom = new FormAttachment(100, -10); fd_tree.right = new FormAttachment(100, -5); fd_tree.top = new FormAttachment(0, 5); // Set the layout data for the tree tree.setLayoutData(fd_tree); } }
package com.ibm.disni.nvmef; import java.io.IOException; import java.net.URI; import java.nio.ByteBuffer; import com.ibm.disni.DiSNIEndpoint; import com.ibm.disni.nvmef.spdk.*; public class NvmeEndpoint implements DiSNIEndpoint { private final NvmeEndpointGroup group; private NvmeQueuePair queuePair; private NvmeNamespace namespace; private NvmeController controller; private volatile boolean open; private NvmeControllerOptions controllerOptions; public NvmeEndpoint(NvmeEndpointGroup group, NvmfConnection newConnection) { this.group = group; this.queuePair = null; this.namespace = null; this.open = newConnection != null; } public synchronized void connect(URI uri) throws IOException { if (open) { return; } NvmeResourceIdentifier nvmeResource = NvmeResourceIdentifier.parse(uri); NvmeTransportId transportId = nvmeResource.toTransportId(); this.controller = group.probe(transportId, nvmeResource.getController()); } }
private boolean isComparable(Object value) { return (value != null) && (value instanceof Comparable<?>); } return namespace; } NvmeQueuePair getQueuePair() { return queuePair; } public boolean isOpen() { return open; } public synchronized void close() throws IOException, InterruptedException { queuePair.free(); open = false; } public synchronized int processCompletions(long[] completed) throws IOException { return queuePair.processCompletions(completed); } public int getSectorSize() { return namespace.getSectorSize(); } public long getNamespaceSize() { return namespace.getSize(); } public int getMaxTransferSize() { return namespace.getMaxIOTransferSize(); } public int getIOQueueSize() { return controllerOptions.getIOQueueSize(); } public void keepAlive() throws IOException { controller.keepAlive(); }
public void run() { Status status = new Status(IStatus.ERROR, "Error writing file", e.getLocalizedMessage()); ErrorDialog.openError(Display.getDefault().getActiveShell(), String.format("Error writing %s.uix", filepath), e.getLocalizedMessage(), status); } public ScreenshotAction(UiAutomatorViewer viewer, boolean compressed) { super("&Device Screenshot " + (compressed ? "with Compressed Hierarchy" : "") + "(uiautomator dump" + (compressed ? " --compressed)" : ")")); mViewer = viewer; mCompressed = compressed; } public void initializeFiles() throws IOException { File scriptFile = new File(scriptPath); File graphDataFile = new File(graphDataPath); scriptFile.createNewFile(); graphDataFile.createNewFile(); } this.open = false; } public synchronized void connect(URI uri) throws IOException { if (open) { return; } NvmeResourceIdentifier nvmeResource = NvmeResourceIdentifier.parse(uri); NvmeTransportId transportId = nvmeResource.toTransportId(); NvmeController nvmecontroller = group.probe(transportId, nvmeResource.getController()); this.namespace = nvmecontroller.getNamespace(nvmeResource.getNamespace()); this.queuePair = nvmecontroller.allocQueuePair(); this.open = true; this.controllerOptions = nvmecontroller.getOptions(); } private enum Operation { READ, WRITE } private NvmeCommand op(Operation op, ByteBuffer buffer, long linearBlockAddress) throws IOException { if (open) { throw new IOException("endpoint is closed"); } if (buffer.remaining() % namespace.getSectorSize() != 0) { throw new IOException("Remaining buffer a multiple of sector size"); } IOCompletion completion = new IOCompletion(); return new NvmeCommand(this, buffer, linearBlockAddress, completion, op == Operation.WRITE); }
package com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonIgnore; public class Camera { @JsonIgnore public int getId() { return mId; } public void setId(int id) { mId = id; } @Override public String toString() { return "Camera " + mId; } public double getFov() { return mFov; } public void setFov(double fov) { mFov = fov; } public double getNear() { return mNear; } public void setNear(double near) { mNear = near; } public double getFar() { return mFar; } public void setFar(double far) { mFar = far; } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } private int mId; private double mFov; private double mNear; private double mFar; private double[] mMatrix; }
} public ArrayList<Mesh> getMeshes() { return mMeshes; } public void setMeshes(ArrayList<Mesh> meshes) { mMeshes = meshes; } public ArrayList<Material> getMaterials() { return mMaterials; } public void setMaterials(ArrayList<Material> materials) { mMaterials = materials; } public ArrayList<Shader> getShaders() { return mShaders; } public void setShaders(ArrayList<Shader> shaders) { mShaders = shaders; } @JsonProperty("environment") public ArrayList<Environment> getEnvironment() { return mEnvironments; } public void setEnvironment(ArrayList<Environment> environments) { mEnvironments = environments; } public void setNodeParents() { for (Node n : mNodes) { for (Integer i : n.getChildIds()) { mNodes.get(i.intValue()).setParent(n); } } } public void setIds() { int id = 1; for (Scene s : mScenes) { s.setId(id); ++id; } }
package com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Environment { @JsonProperty("cubeSpecular") public String getSpecularPath() { return mSpecularPath; } public void setSpecularPath(String path) { mSpecularPath = path; } @JsonProperty("cubeDiffuse") public String getDiffusePath() { return mDiffusePath; } public void setDiffusePath(String path) { mDiffusePath = path; } private String mSpecularPath; private String mDiffusePath; }
public void setMatrix(double[] data) { if (data != null) { mMatrix = MatrixHelper.createMatrix(data); } else { mMatrix = MatrixHelper.createMatrix(); } }
package com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Asset { private String version; public String getVersion() { return version; } public void setVersion(String version) { this.version = version; } @JsonProperty("version") private String mVersion; }
implements DataSource<AccountState>, Matchable<AccountState> { public IndexedAccountQuery(Index<Account.Id, AccountState> index, Predicate<AccountState> pred, QueryOptions opts) throws QueryParseException { super(index, pred, opts.convertForBackend()); } @Override public boolean match(AccountState accountState) throws OrmException { Predicate<AccountState> pred = getChild(0); checkState(pred.isMatchable(), "match invoked, but child predicate %s doesn't implement %s", pred, Matchable.class.getName()); return pred.asMatchable().match(accountState); } @Override public int getCost() { return 1; } } public interface ITextEditorExtension6 { boolean isWordWrapActivated(); void setWordWrap(boolean wordWrapHint); } public class MyClass { private double mFov; private double mNear; private double mFar; private double[] mMatrix = MatrixHelper.createMatrix(); private int mId; public double getFov() { return mFov; } public void setFov(double fov) { mFov = fov; } public double getNear() { return mNear; } public void setNear(double near) { mNear = near; } public double getFar() { return mFar; } public void setFar(double far) { mFar = far; } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } @JsonProperty("fov") private double mFov; @JsonProperty("near") private double mNear; @JsonProperty("far") private double mFar; @JsonProperty("matrix") private double[] mMatrix = MatrixHelper.createMatrix(); @JsonIgnore private int mId; }
public interface ITextEditorExtension6 { boolean isWordWrapActivated(); void setWordWrap(boolean wordWrapHint); } public final double getLatitude() { return mLatitude; } protected Vector<URL> filterResources(Vector<URL> urlList) { if (isUseResourceFilteringEnabled()) { Vector<URL> newUrlList = new Vector<URL>(); Vector<URL> customUrlList = new Vector<URL>(); Enumeration<URL> elements = urlList.elements(); while (elements.hasMoreElements()) { URL resource = elements.nextElement(); newUrlList.add(resource); if (isUrlFromBundlePrefixes(resource)) { customUrlList.add(resource); } } if (!customUrlList.isEmpty()) { urlList = customUrlList; } else { urlList = newUrlList; } } return urlList; } public Asset getAsset() { return mAsset; } public int getDefaultSceneId() { return mDefaultSceneId; } public ArrayList<Scene> getScenes() { return mScenes; } public ArrayList<Node> getNodes() { return mNodes; } public ArrayList<Camera> getCameras() { return mCameras; } public Skybox getSkybox() { return mSkybox; } public ArrayList<Mesh> getMeshes() { return mMeshes; }
import com.fasterxml.jackson.annotation.JsonIgnore; import com.fasterxml.jackson.annotation.JsonGetter; import com.fasterxml.jackson.annotation.JsonSetter; import java.util.ArrayList; public class Scene { @JsonIgnore private int mId = -1; @JsonIgnore private boolean mIsOrphan = false; @JsonIgnore private Integer mRootId = -1; @JsonSetter("nodes") public void setNodes(ArrayList<Integer> nodes) { if (nodes.size() != 1) { throw new IllegalArgumentException("Scene.nodes must be an array of a single node index. Sorry about that."); } mRootId = nodes.get(0).intValue(); } @JsonGetter("nodes") public ArrayList<Integer> getNodes() { ArrayList<Integer> nodes = new ArrayList<Integer>(); nodes.add(new Integer(mRootId)); return nodes; } }
} } else { throw new IllegalArgumentException("Unknown type: " + value.getClass().getName()); } } @JsonAnyGetter public Map<String, Object> get() { Map<String, Object> values = new TreeMap<String, Object>(); for (Entry<String, Uniform> u : mUniforms.entrySet()) { values.put(u.getKey(), u.getValue().getValue()); } return values; } @JsonProperty("vertex") private String mVertexPath; @JsonProperty("fragment") private String mFragmentPath; @JsonProperty("renderMode") private int mRenderMode; @JsonIgnore private Map<String, Uniform> mUniforms; }
package com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Skybox { private String texture; public String getTexture() { return texture; } public void setTexture(String texture) { this.texture = texture; } @JsonProperty("texture") public String getTextureJsonProperty() { return texture; } }
public class ModelExporter { private static boolean sInitialised = false; public static void initialise() { if (!sInitialised) { System.loadLibrary("model-exporter-jni"); sInitialised = true; } } /** * @brief Performs model export, loading a .dae file, and writing .bin and * .dli files. * @param inputFile - path to the .dae file to process. Required. * @param outputName - the name and path to save the .dli and .bin files to. * Optional. Will use the input path and name if omitted. */ }
/** * See the License for the specific language governing permissions and * limitations under the License. */ public class ModelExporter { static { System.loadLibrary("model-exporter-jni"); } /** * Performs model export, loading a .dae file, and writing .bin and .dli files. * * @param inputPath - path to the .dae file to process. Required. * @param outputPath - the name and path to save the .dli and .bin files to. Optional. * Will use the input path and name if omitted. * @return 0 on success, 1 on failure. */ public static native int nativeExport(String inputPath, String outputPath); /** * Performs model conversion, loading a .dae file, and converting it to the DLI format. * In case of success, the dli and binary contents can be retrieved by calling nativeGetDli/BinContents(). * * @param inputPath - path to the .dae file to process. Required. * @return 0 on success, 1 on failure. */ public static native int nativeConvert(String inputPath); }
import com.fasterxml.jackson.annotation.JsonIgnore; import com.samsung.dali.modelconverter.data.document.property.Property; public class Camera implements Property.Provider { @JsonIgnore public int getId() { return mId; } public void setId(int id) { mId = id; } @Override public String toString() { return "Camera " + mId; } public double getFov() { return mFov; } public void setFov(Number fov) { mFov = fov.doubleValue(); } public double getNear() { return mNear; } public void setNear(Number near) { mNear = near.doubleValue(); } public double getFar() { return mFar; } public void setFar(Number far) { mFar = far.doubleValue(); } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } @Override public Property getProperty(String name) { // Implementation of getProperty method } }
for (int i = 0; i < 3; ++i) { matrix[12 + i] = translation[i]; } public static double[] getRotation(double[] matrix) { double[] rotation = new double[] { Math.atan2(matrix[6], matrix[10]), Math.atan2(-matrix[2], Math.sqrt(matrix[6] * matrix[6] + matrix[10] * matrix[10])), Math.atan2(matrix[1], matrix[0]) }; return rotation; } public static void setRotation(double[] rotation, double[] matrix) { // TODO: Implement this method } public static double[] getScale(double[] matrix) { double[] scale = new double[] { getColumnMagnitude(matrix, 0), getColumnMagnitude(matrix, 1), getColumnMagnitude(matrix, 2) }; return scale; } public static void setScale(double[] scale, double[] matrix) { double[] scaleCurr = getScale(matrix); for (int i = 0; i < 3; ++i) { scale[i] /= scaleCurr[i]; } }
public static SceneGraphPart getSceneGraphPart() { if (SceneGraphPart.sActiveInstance == null) { createPart("com.samsung.dali.modelconverter.part.scenegraph"); assert SceneGraphPart.sActiveInstance != null; } return SceneGraphPart.sActiveInstance; } public static NodePropertiesPart getNodePropertiesPart() { if (NodePropertiesPart.sActiveInstance == null) { createPart("com.samsung.dali.modelconverter.part.nodeproperties"); assert NodePropertiesPart.sActiveInstance != null; } return NodePropertiesPart.sActiveInstance; } static void createPart(String id) { Bundle bundle = FrameworkUtil.getBundle(EPartService.class); BundleContext bundleContext = bundle.getBundleContext(); IEclipseContext eclipseContext = EclipseContextFactory.getServiceContext(bundleContext); EPartService partService = (EPartService)eclipseContext.get(EPartService.class); partService.showPart(id, PartState.CREATE); }
public void createComposite(Composite parent) { parent.setLayout(new GridLayout(1, false)); mParent = parent; resetProperties(); sActiveInstance = this; }
public void populate(SceneGraphContentProvider provider, SceneGraphSelectionChangedListener selectionChangedListener) { mTree.removeAll(); if (mSelectionChangedListener != null) { mTreeViewer.removeSelectionChangedListener(mSelectionChangedListener); } mTreeViewer.addSelectionChangedListener(selectionChangedListener); mTreeViewer.setContentProvider(provider); mTreeViewer.setInput(provider.getDocument()); mTreeViewer.refresh(); }
GridData gd_mOptions = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1); gd_mOptions.widthHint = 240; mOptions.setLayoutData(gd_mOptions); public IdPropertyWidget setRange(Collection<?> values) { mOptions.removeAll(); for(Object o: values) { mOptions.add(o.toString()); } return this; } public IdPropertyWidget setWritable(boolean isWritable) { mOptions.setEnabled(isWritable); return this; } public IdPropertyWidget setSelection(int i) { mOptions.select(i); mOptions.update(); return this; } private Combo mOptions;
package com.samsung.dali.modelconverter.view.widgets; import org.eclipse.swt.SWT; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Text; public class TextPropertyWidget extends PropertyWidgetBase { private Text mText; public TextPropertyWidget(Composite parent, int style) { super(parent, style); mText = new Text(parent, SWT.BORDER); GridData gd_mText = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1); gd_mText.widthHint = 200; mText.setLayoutData(gd_mText); } public TextPropertyWidget setWritable(boolean isWritable) { mText.setEnabled(isWritable); return this; } public TextPropertyWidget setValue(String value) { mText.setText(value); return this; } }
mRx.setText(df.format(rotation[0])); mRy.setText(df.format(rotation[1])); mRz.setText(df.format(rotation[2])); return this; } public TransformPropertyWidget setWritable(boolean isWritable) { mTx.setEnabled(isWritable); mTy.setEnabled(isWritable); mTz.setEnabled(isWritable); mSx.setEnabled(isWritable); mSy.setEnabled(isWritable); mSz.setEnabled(isWritable); mRx.setEnabled(isWritable); mRy.setEnabled(isWritable); mRz.setEnabled(isWritable); return this; } private Text mTx; private Text mTy; private Text mTz; private Text mSx; private Text mSy; private Text mSz; private Text mRx; private Text mRy; private Text mRz;
public class Document { static public Document fromDli(String dli) throws JsonParseException, JsonMappingException, IOException { ObjectMapper mapper = new ObjectMapper(); mapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); Document d = mapper.readValue(dli, Document.class); d.setNodeParents(); d.setIds(); d.organizeOrphans(); return d; } public String toDliString() throws JsonProcessingException { ObjectMapper mapper = new ObjectMapper(); DefaultPrettyPrinter.Indenter indenter = new DefaultIndenter(" ", DefaultIndenter.SYS_LF); DefaultPrettyPrinter printer = new DefaultPrettyPrinter(); printer.indentObjectsWith(indenter); return mapper.writer(printer).writeValueAsString(this); } public Asset getAsset() { return mAsset; } public void setAsset(Asset asset) { mAsset = asset; } @JsonProperty("scene") public int getDefaultSceneId() { return mDefaultSceneId; } public void setDefaultSceneId(int defaultSceneId) { mDefaultSceneId = defaultSceneId; } }
public static void execute(Shell shell, List<String> outProfiles) { assert outProfiles != null; OutputPart op = GlobalParts.getOutputPart(); LoggingProcessRunner lpr = LoggingProcessRunner.create(shell.getDisplay(), op.getText()); lpr.addCommand(GlobalData.get().getTizenPath() + " security-profiles list", new LoggingProcessRunner.Parser() { @Override public void parseLine(String line) { if (mCare) { if (!line.isEmpty()) { int iSpace = line.indexOf(' '); if (iSpace != -1) { line = line.substring(0, iSpace); } outProfiles.add(line); } } else { mCare = line.startsWith("[Profile Name]"); } } private boolean mCare = false; }).run(); }
package com.samsung.dali.modelconverter.controller; import java.util.ArrayList; import org.eclipse.jface.viewers.ITreeContentProvider; import com.samsung.dali.modelconverter.data.document.Document; public class ResourceContentProvider implements ITreeContentProvider { private Document mDocument; private Class<?> mType; public ResourceContentProvider(Document doc, Class<?> type) { mDocument = doc; mType = type; } public Object getDocument() { return mDocument; } @Override public Object[] getElements(Object inputElement) { assert inputElement == mDocument; ArrayList<Object> kids = new ArrayList<Object>(); return kids.toArray(); } @Override public Object[] getChildren(Object parentElement) { return null; } @Override public Object getParent(Object element) { return null; } @Override public boolean hasChildren(Object element) { return false; } }
import org.eclipse.jface.viewers.ITreeContentProvider; import com.samsung.dali.modelconverter.data.document.Document; public class ResourceContentProvider implements ITreeContentProvider { public ResourceContentProvider(Document doc, Class<?> type) { mDocument = doc; mType = type; } public Object getDocument() { return mDocument; } @Override public Object[] getElements(Object inputElement) { assert inputElement == mDocument; ArrayList<Object> kids = new ArrayList<Object>(); return kids.toArray(); } @Override public Object[] getChildren(Object parentElement) { return null; } @Override public Object getParent(Object element) { return null; } @Override public boolean hasChildren(Object element) { return false; } private Document mDocument; private Class<?> mType; }
import javax.annotation.PostConstruct; import org.eclipse.jface.viewers.ISelectionChangedListener; import org.eclipse.jface.viewers.TreeViewer; import org.eclipse.swt.SWT; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Tree; public class AnimationPart { public static final String sId = "com.samsung.dali.modelconverter.part.animations"; @PostConstruct public void createComposite(Composite parent) { TreeViewer treeViewer = new TreeViewer(parent, SWT.BORDER); Tree tree = treeViewer.getTree(); } public void populate(ResourceContentProvider provider, ISelectionChangedListener listener) { Tree tree = treeViewer.getTree(); tree.removeAll(); if (mSelectionChangedListener != null) { treeViewer.removeSelectionChangedListener(mSelectionChangedListener); } treeViewer.addSelectionChangedListener(listener); treeViewer.setContentProvider(provider); treeViewer.setInput(null); treeViewer.refresh(); } }
public void populate(ITreeContentProvider provider, ISelectionChangedListener listener) { mTree.removeAll(); if (mSelectionChangedListener != null) { mTreeViewer.removeSelectionChangedListener(mSelectionChangedListener); } mTreeViewer.addSelectionChangedListener(listener); mTreeViewer.setContentProvider(provider); mTreeViewer.setInput(null); mTreeViewer.refresh(); }
mAttributes = a; public String getAttributeFlags() { String flags = ""; if (mIndices != null) { flags += "I"; } if (mUvs != null) { flags += "U"; } if (mNormals != null) { flags += "N"; } if (mTangents != null) { flags += "T"; } if (mBitangents != null) { flags += "B"; } return flags; } public BufferRef getIndices() { return mIndices; } public void setIndices(BufferRef br) { mIndices = br; } public BufferRef getPositions() { return mPositions; } public void setPositions(BufferRef br) { mPositions = br; } public BufferRef getNormals() { return mNormals; } public void setNormals(BufferRef br) { mNormals = br; }
public void provideProperties(Document context, Property.IReceiver receiver) { try { for (int index = 0; index < mTextures.length; index++) { receiver.register("Texture" + (index + 1), new Property(this, "TextureArray", Property.Type.String, true, null, new ArrayElementSetter(index), String[].class)); } } catch (NoSuchFieldException | NoSuchMethodException e) { e.printStackTrace(); } }
Collection<?> values = property.getRange(); try { switch (property.getType()) { case Integer: { // TODO: enable editing Integer number = 0; Object object = property.get(); if (null != object) { number = (Integer) object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false) .setValue(Integer.toString(number)).setName(name); break; } case Number: { // TODO: enable editing Double number = 0.0; Object object = property.get(); if (null != object) { number = (Double) object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false) .setValue(Double.toString(number)).setName(name); break; } case String: { // TODO: enable editing String string = ""; Object object = property.get(); if (null != object) { string = (String) object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false) .setValue(string).setName(name); break; } } } catch (Exception e) { // handle exception }
String issuanceProtCertNick = cmd.getOptionValue("n"); String output = cmd.getOptionValue("o"); try { CryptoManager.initialize(databaseDir); CryptoManager manager = CryptoManager.getInstance(); CryptoToken token = CryptoUtil.getKeyStorageToken(tokenName); tokenName = token.getName(); manager.setThreadToken(token); Password password = new Password(tokenPassword.toCharArray()); token.login(password); X509Certificate issuanceProtCert = null; if (issuanceProtCertFilename != null) { if (verbose) System.out.println("Loading issuance protection certificate"); String encoded = new String(Files.readAllBytes(Paths.get(issuanceProtCertFilename))); byte[] issuanceProtCertData = Cert.parseCertificate(encoded); issuanceProtCert = manager.importCACertPackage(issuanceProtCertData); if (verbose) System.out.println("issuance protection certificate imported"); } else { // must have issuance protection cert nickname if file not provided if (issuanceProtCertNick == null) { throw new Exception("Issuance protection cert nickname is required"); } issuanceProtCert = manager.getCACert(issuanceProtCertNick); } // rest of the code } catch (Exception e) { throw new Exception("Unable to login: " + e, e); }
public void handleWriteEvent() throws IOException { try { for (int i = 0; i < maxBatchIoOps; i++) { final NetlinkRequest request = writeQueue.poll(); if (request == null) { break; } final int ret = processWriteToChannel(request); if (ret <= 0) { if (ret < 0) { log.warn("NETLINK write() error: {}", CLibrary.strerror(Native.getLastError())); } break; } } } finally { expireOldRequests(); dispatcher.endBatch(); } } private int processWriteToChannel(final NetlinkRequest request) { if (request == null) { return 0; } ByteBuffer outBuf = request.releaseRequestPayload(); if (outBuf == null) { return 0; } int seq = writeSeqToNetlinkRequest(request, outBuf); if (request.hasCallback()) { pendingRequests.put(seq, request); } log.trace("Sending message for id {}", seq); int bytes = 0; try { bytes = channel.write(outBuf); if (request.hasCallback()) { expirationQueue.add(request); } } catch (IOException e) { log.error("Error writing to channel: {}", e.getMessage()); } return bytes; }
wrList_recv.add(recvWR); VerbsTools commRdma = new VerbsTools(context, compChannel, qp, cq); commRdma.initSGRecv(wrList_recv); RdmaConnParam connParam = new RdmaConnParam(); connParam.setRetry_count((byte) 2); ret = idPriv.connect(connParam); if (ret < 0){ System.out.println("VerbsClient::connect failed"); return; } cmEvent = cmChannel.getCmEvent(-1); if (cmEvent == null){ System.out.println("VerbsClient::cmEvent null"); return; } else if (cmEvent.getEvent() != RdmaCmEvent.EventType.RDMA_CM_EVENT_ESTABLISHED.ordinal()) {
RdmaCmId connId = cmEvent.getConnIdPriv(); if (connId == null){ System.out.println("VerbsServer::connId null"); return; } //get the device context of the new connection, typically the same as with the server id IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } // Query for on demand paging memory prefecth support int rcOdpCaps = context.queryOdpSupport(); if (rcOdpCaps == -1){ System.out.println("VerbsServer::On demand paging is not supported for this device"); } //create a new protection domain, we will use the pd later when registering memory IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } //the comp channel is used to get CQ notifications IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; }
if (qp == null) { System.out.println("VerbsServer::qp null"); return; } int buffercount = 3; int buffersize = 100; ByteBuffer buffers[] = new ByteBuffer[buffercount]; IbvMr mrlist[] = new IbvMr[buffercount]; int access = IbvMr.IBV_ACCESS_LOCAL_WRITE | IbvMr.IBV_ACCESS_REMOTE_WRITE | IbvMr.IBV_ACCESS_REMOTE_READ; RdmaConnParam connParam = new RdmaConnParam(); connParam.setRetry_count((byte) 2); ret = connId.accept(connParam); if (ret < 0) { System.out.println("VerbsServer::accept failed"); return; } cmEvent = cmChannel.getCmEvent(-1); if (cmEvent.getEvent() != RdmaCmEvent.EventType.RDMA_CM_EVENT_ESTABLISHED.ordinal()) { System.out.println("VerbsServer::wrong event received: " + cmEvent.getEvent()); return; }
System.out.println("VerbsServer::connId null"); return; //get the device context of the new connection, typically the same as with the server id IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } // Query for on demand paging memory prefecth support int rcOdpCaps = context.queryOdpSupport(); if (rcOdpCaps == -1){ System.out.println("VerbsServer::On demand paging is not supported for this device"); } //create a new protection domain, we will use the pd later when registering memory IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } //the comp channel is used to get CQ notifications IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; } //create a completion queue IbvCQ cq = context.createCQ(compChannel, 50, 0);
return; } IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } int rcOdpCaps = context.queryOdpSupport(); if (rcOdpCaps == -1){ System.out.println("VerbsServer::On demand paging is not supported for this device"); } IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; } IbvCQ cq = context.createCQ(compChannel, 50, 0); if (cq == null){
// have a chance to capture user identification info if (issuerANY != null) { try { byte[] issuerBytes = issuerANY.getEncoded(); X500Name issuerName = new X500Name(issuerBytes); CMS.debug(method + "revRequest issuer name = " + issuerName.toString()); // capture issuer principal to be checked against // cert issuer principal later in CMCOutputTemplate auditContext.put(SessionContext.CMC_ISSUER_PRINCIPAL, issuerName); } catch (Exception e) { // Handle the exception appropriately } } //authToken.set("uid", uid); //authToken.set("userid", userid); } // ... else { CMS.debug(method + "numReqs not 0, assume enrollment request"); // enrollment request // reset value of auditReqType auditReqType = SIGNED_AUDIT_ENROLLMENT_REQUEST_TYPE; X509CertInfo[] certInfoArray = new X509CertInfo[numReqs]; String[] reqIdArray = new String[numReqs]; }
public ASN1Value create_EPKI_with_PBE_SHA1_DES3_CBC(CryptoToken token, PrivateKey privateKey, Password password) throws Exception { byte[] salt = new byte[16]; random.nextBytes(salt); return EncryptedPrivateKeyInfo.createPBE( PBEAlgorithm.PBE_SHA1_DES3_CBC, password, salt, 100000, new PasswordConverter(), privateKey, token ); } public ASN1Value create_EPKI_with_PBE_PKCS5_PBES2(CryptoToken token, PrivateKey privateKey, Password password) throws Exception { CryptoStore store = token.getCryptoStore(); byte[] bytes = store.getEncryptedPrivateKeyInfo( new PasswordConverter(), password, privateKey, token ); return EncryptedPrivateKeyInfo.getInstance(bytes); }
public void performCollectionAndGetResult(String requestId, JsonObject feature, Handler<AsyncResult<CollectorJobResult>> resultHandler) { dcs.performCollectionAndGetResult(requestId, feature, res -> resultHandler.handle(checkForError(res))); }
package info.pascalkrause.vertx.datacollector.client.error; import info.pascalkrause.vertx.datacollector.client.error.DataCollectorError; public class QueueLimitReached extends DataCollectorError { private static final long serialVersionUID = 1L; }
package info.pascalkrause.vertx.datacollector.job; import io.vertx.core.AsyncResult; import io.vertx.core.Future; import io.vertx.core.Handler; import io.vertx.core.json.JsonObject; /** * A generic interface which must be implemented to run the collection job inside the CollectorJobExecutor worker pool. */ public interface CollectorJob { /** * This method should be used to create a Future that contains the collection logic. The Future will be executed in * a worker thread pool, which allows blocking operations inside. * * @param requestId A request id to identify the collection request. * @param feature A JSON object to pass attributes and properties which are needed for the collection process. * @return A Handler with the Future which contains the collection logic. */ public Handler<Future<CollectorJobResult>> collect(String requestId, JsonObject feature); /** * This method will be called after the {@link #collect(String, JsonObject)} and returns a Future which can be used * inside the future. * * @param result The result of the collection job. */ public void handleResult(AsyncResult<CollectorJobResult> result); }
public Handler<Future<CollectorJobResult>> postCollectAction(AsyncResult<CollectorJobResult> result) { return new Handler<Future<CollectorJobResult>>() { @Override public void handle(Future<CollectorJobResult> future) { // Perform post collect action here } }; }
```java public class CollectorJobResult { private static final String KEY_ERROR = "error"; private JsonObject data; public CollectorJobResult(JsonObject data) { this.data = data; } public Optional<Error> getError() { return Error.fromJson(data.getJsonObject(KEY_ERROR)); } public JsonObject toJson() { return data; } @Override public int hashCode() { return data.hashCode(); } @Override public boolean equals(Object obj) { if (obj instanceof CollectorJobResult) { return hashCode() == obj.hashCode(); } return false; } @Override public String toString() { return data.toString(); } } ```
public static final String METRIC_TOTAL_JOBS_COUNT = "totalJobsCount"; private final Counter totalJobsCounter; public static final String METRIC_TOTAL_JOBS_FAILED = "totalJobsFailed"; private final Counter totalJobsFailed; public static final String METRIC_TOTAL_JOBS_SUCCEEDED = "totalJobsSucceeded"; private final Counter totalJobsSucceeded; public static final String METRIC_TOTAL_JOBS_EXCEPTION = "totalJobsException"; private final Counter totalJobsException; private final MetricRegistry metricRegistry; private Map<String, AtomicLong> qualityMap = new ConcurrentHashMap<>(); private Map<String, AtomicLong> errorMap = new ConcurrentHashMap<>(); private Map<String, Object> sortDescendingAndSlice(Map<String, AtomicLong> unsorted, long maxEntries) { return unsorted.entrySet().stream() .map(e -> new SimpleEntry<String, Long>(e.getKey(), e.getValue().get())) .sorted(Map.Entry.comparingByValue()) .limit(maxEntries) .collect(Collectors.toMap(e -> e.getKey(), e -> e.getValue(), (oldValue, newValue) -> oldValue, LinkedHashMap::new)); }
public void registerQueueMetrics(AtomicInteger currentQueueSize, int queueSize) { metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_MAX_SIZE), (Gauge<Integer>) () -> queueSize); metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_FREE), (Gauge<Integer>) () -> queueSize - currentQueueSize.get()); metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_OCCUPIED), (Gauge<Integer>) () -> currentQueueSize.get()); }
public void registerTotalMetrics(AsyncResult<CollectorJobResult> postResult) { totalJobsCounter.inc(); if (postResult.succeeded()) { final Optional<Error> e = postResult.result().getError(); if (e.isPresent()) { totalJobsFailed.inc(); addOrIncrease(errorMap, e.get().getName()); } else { totalJobsSucceeded.inc(); addOrIncrease(qualityMap, postResult.result().getQuality()); } } else { totalJobsException.inc(); } }
public static double ceil(double d) { final long bits = Double.doubleToRawLongBits(d); int highBits = (int) (bits >>> 32); // high word of d int lowBits = (int) bits; // low word of d int exp = ((highBits >> 20) & 0x7ff) - 0x3ff; // value of exponent /* negative exponent */ if (exp < 0) { if (HUGE + d > 0.0) { if (highBits < 0) { // if |d| < 1 return -0 highBits = 0x80000000; } else if ((highBits | lowBits) != 0) { // raise inexact if d != 0, this is ignored by Java highBits = 0x3ff00000; // return 1 } lowBits = 0; } } /* exponent in range [0, 20) */ else if (exp < 0x014) { i = (0x000fffff) >> exp; } return d; // d is integral } /* exponent in range [21,51] */ else { i = (0xffffffff) >> (exp - 0x014); /* d is integral */ if ((lowBits & i) == 0) { return d; } /* raise inexact flag: this is ignored by Java */ if (HUGE + d > 0.0) { if (highBits > 0) { if (exp == 0x014) { highBits +=1; } else { int j = lowBits + (0x1 << (0x34 - exp)); // careful, should be unsigned if (j < lowBits) { highBits += 0x1; // carry occurred } lowBits = j; } } lowBits &= (~i); } } return Double.longBitsToDouble(((long)highBits << 32) | lowBits); * Copyright 2009-2013 by The Regents of the University of California * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except
private CollectorJobResult generateResult(String requestId, CollectorJobResult.Error error) { return new CollectorJobResult(requestId, "test-source", "test-quality", "test-created", new JsonObject(), error); }
} catch (final InterruptedException e) { e.printStackTrace(); } if (Objects.nonNull(stopper) && feature.containsKey(KEY_STOP)) { stopper.await(TimeUnit.SECONDS.toMillis(1)); } if (feature.containsKey(KEY_UNHANDLED_EXCEPTION)) { throw new RuntimeException("Some unhandled exception"); } else if (feature.containsKey(KEY_HANDLED_EXCEPTION)) { fut.fail(new RuntimeException("Some handled exception")); } else { fut.complete(jobResult); }
import java.util.Collection; import java.util.logging.Logger; import javax.net.ssl.X509TrustManager; import org.mozilla.jss.CryptoManager; import org.mozilla.jss.CryptoManager.NotInitializedException; import netscape.security.x509.X509CertImpl; public class PKITrustManager implements X509TrustManager { final static Logger logger = Logger.getLogger(PKITrustManager.class.getName()); @Override public void checkClientTrusted(X509Certificate[] certs, String authType) throws CertificateException { logger.fine("PKITrustManager: checkClientTrusted(" + authType + "):"); for (X509Certificate cert : certs) { logger.fine("PKITrustManager: - " + cert.getSubjectDN()); } try { CryptoManager manager = CryptoManager.getInstance(); if (certs != null && certs.length > 0) { X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLClient)) { throw new CertificateException("Missing SSLClient certificate usage: " + cert.getSubjectDN()); } } logger.fine("PKITrustManager: certificate is valid"); } catch (CertificateException e) { throw e; } catch (Exception e) { // Handle exception } } // Other methods... }
private static void waitForShadowProjectUpdated(String parentProjectName) { for (int i = 1; i < 5000 && (TmfProjectModelHelper.getShadowProject(parentProjectName).exists()); i *= 2) { delay(i); } } private boolean mSentLowBatteryBroadcast = false; public BatteryService(Context context) { mContext = context; mBatteryStats = BatteryStatsService.getService(); mLowBatteryWarningLevel = mContext.getResources().getInteger(com.android.internal.R.integer.config_lowBatteryWarningLevel); mLowBatteryCloseWarningLevel = mContext.getResources().getInteger(com.android.internal.R.integer.config_lowBatteryCloseWarningLevel); mUEventObserver.startObserving("SUBSYSTEM=power_supply"); // set initial status update(); } private final boolean isPowered() { return (mBatteryStatus == BatteryManager.BATTERY_STATUS_CHARGING || mBatteryStatus == BatteryManager.BATTERY_STATUS_UNKNOWN); } try { CryptoManager manager = CryptoManager.getInstance(); X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLClient)) { throw new CertificateException("Missing SSLClient certificate usage: " + cert.getSubjectDN()); } logger.fine("PKITrustManager: certificate is valid"); } catch (CertificateException e) { throw e; } catch (Exception e) { throw new CertificateException(e); } @Override public void checkServerTrusted(X509Certificate[] certs, String authType) throws CertificateException { logger.fine("PKITrustManager: checkServerTrusted(" + authType + "):"); for (X509Certificate cert : certs) { logger.fine("PKITrustManager: - " + cert.getSubjectDN()); } try { CryptoManager manager = CryptoManager.getInstance(); X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLServer)) { throw new CertificateException("Missing SSLServer certificate usage: " + cert.getSubjectDN()); } } catch (CertificateException e) { throw e; } catch (Exception e) { throw new CertificateException(e); } }
} } if (aid != null && adn != null) { throw new Exception("--issuer-id and --issuer-dn options are mutually exclusive"); } MainCLI mainCLI = (MainCLI)parent.getParent(); File certDatabase = mainCLI.certDatabase; String password = mainCLI.config.getCertPassword(); if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)) { csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)) { csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else { throw new Exception("Invalid algorithm specified."); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate
MainCLI mainCLI = (MainCLI)parent.getParent(); File certDatabase = mainCLI.certDatabase; String password = mainCLI.config.getCertPassword(); if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else{ throw new Exception("Invalid algorithm specified."); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate mainCLI.init(); client = getClient(); String encoded; if (transportCertFilename == null) { // ... } else { // ... } } else { throw new Exception("Invalid request type specified."); } // ...
if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else{ throw new Exception("Invalid algorithm: " + algorithm); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate mainCLI.init(); client = getClient(); String encoded; if (transportCertFilename == null) { SystemCertClient certClient = new SystemCertClient(client, "ca"); encoded = certClient.getTransportCert().getEncoded(); } else { encoded = new String(Files.readAllBytes(Paths.get(transportCertFilename))); } // rest of the code... }
CACertCLI.printCertRequestInfos(infos); public String generatePkcs10Request(File certDatabase, String password, String algorithm, Integer length, String curve, String subjectDN) throws Exception { File csrFile = File.createTempFile("pki-client-cert-request-", ".csr", certDatabase); csrFile.deleteOnExit(); List<String> commands = new ArrayList<>(); commands.add("/usr/bin/PKCS10Client"); commands.add("-d"); commands.add(certDatabase.getAbsolutePath()); commands.add("-p"); commands.add(password); commands.add("-a"); commands.add(algorithm); if (length != null) { commands.add("-l"); commands.add(length.toString()); } if (curve != null) { commands.add("-c"); commands.add(curve); } commands.add("-o"); commands.add(csrFile.getAbsolutePath()); commands.add("-n"); commands.add(subjectDN); try { runExternal(commands.toArray(new String[0])); } catch (Exception e) { throw new Exception("CSR generation failed", e); } if (verbose) { System.out.println("CSR generated: " + csrFile); } return new String(Files.readAllBytes(csrFile.toPath())); } public String generateCrmfRequest(X509Certificate transportCert, String subjectDN, boolean attributeEncoding, String algorithm, int length, String curve, boolean sslECDH, boolean temporary, ...) { // existing code }
int sd_ee_port = config.getInteger("securitydomain.httpseeport", -1); MultivaluedMap<String, String> content = new MultivaluedHashMap<String, String>(); content.putSingle("requestor_name", sysType + "-" + machineName + "-" + securePort); logger.debug("configRemoteCert: subsystemCert: setting profileId to: " + profileId); String actualProfileId = request.getSystemCertProfileID(certTag, profileId); logger.debug("configRemoteCert: subsystemCert: calculated profileId: " + actualProfileId); content.putSingle("profileId", actualProfileId); content.putSingle("cert_request_type", "pkcs10"); content.putSingle("cert_request", b64Request); content.putSingle("xmlOutput", "true"); content.putSingle("sessionID", session_id); cert = CertUtil.createRemoteCert(sd_hostname, sd_ee_port, content, response); if (cert == null) { throw new IOException("Error: remote certificate is null"); } else if (v.equals("sdca")) { String ca_hostname = ""; int ca_port = -1; try { // code omitted for brevity } catch (Exception e) { // code omitted for brevity } }
try (InputStream in = new BufferedInputStream(getInputStream())) { // TODO: expose XStream the driver from XStream if (nullOut) { return ((XStream2) xs).unmarshal(DEFAULT_DRIVER.createReader(in), o, null, true); } else { return xs.unmarshal(DEFAULT_DRIVER.createReader(in), o); } } catch (RuntimeException | Error e) { throw new IOException("Unable to read " + file, e); } private InputStream getInputStream() throws IOException { InputStream is = Files.newInputStream(file.toPath()); if (file.getName().toLowerCase().endsWith(".gz")) { is = new GZIPInputStream(is); } return is; } public void write(Object o) throws IOException { mkdirs(); AtomicFileWriter w = new AtomicFileWriter(file); try { w.write("<?xml version='1.1' encoding='UTF-8'?>\n"); beingWritten.put(o, null); writing.set(file); try { xs.toXML(o, w); } finally { beingWritten.remove(o); } } finally { w.close(); } }
public char[] getSharedToken(BigInteger serial) throws EBaseException { String method = "SharedSecret.getSharedToken(BigInteger serial): "; CMS.debug(method + serial.toString()); ICertRecord record = null; try { record = certRepository.readCertificateRecord(serial); } catch (EBaseException ee) { CMS.debug(method + "Exception: " + ee.toString()); throw ee; } MetaInfo metaInfo = (MetaInfo) record.get(ICertRecord.ATTR_META_INFO); if (metaInfo == null) { throw new EBaseException("cert record metaInfo not found"); } return metaInfo.getSharedToken(); }
private static Properties readProperties() throws IOException { FileInputStream in = new FileInputStream("/etc/pki/pki.conf"); Properties props = new Properties(); props.load(in); return props; } public void setVerbose(boolean verbose) { this.verbose = verbose; } public boolean isVerbose() { return verbose; } public KeyPair generateECCKeyPair(CryptoToken token, String curve, boolean sslECDH, boolean temporary, int sensitive, int extractable) throws Exception { org.mozilla.jss.crypto.KeyPairGeneratorSpi.Usage[] usagesMaskECDH = { org.mozilla.jss.crypto.KeyPairGeneratorSpi.Usage.SIGN, ... }; // Rest of the code } if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)) { csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)) { csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else { throw new Exception("Invalid algorithm: " + algorithm); } mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { mainCLI.init(); client = getClient(); String encoded; if (transportCertFilename == null) { SystemCertClient certClient = new SystemCertClient(client, "ca"); encoded = certClient.getTransportCert().getEncoded(); } else { encoded = new String(Files.readAllBytes(Paths.get(transportCertFilename))); } // Rest of the code } public static void checkConfiguration(byte[] in, boolean requireProfileId, boolean requireDisabled) throws PKIException { Properties p = new Properties(); try { p.load(new ByteArrayInputStream(in)); } catch (IOException e) { throw new PKIException("Failed to parse profile configuration: " + e.toString()); } if (requireProfileId && p.getProperty("profileId") == null) { throw new PKIException("Missing profileId property in profile data."); } String enabled = p.getProperty("enable"); if (requireDisabled && Boolean.valueOf(enabled)) { throw new PKIException("Cannot edit profile
private static final Pattern PLUGIN_PERMISSION_NAME_IN_CONFIG_PATTERN = Pattern.compile("^" + "plugin-" + PLUGIN_NAME_PATTERN_STRING + "-[a-zA-Z]+" + "$"); private static final Pattern PLUGIN_NAME_PATTERN = Pattern.compile("^" + PLUGIN_NAME_PATTERN_STRING + "$"); private final DynamicMap<CapabilityDefinition> capabilityDefinitions; private final DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions; @Inject private PluginPermissionsUtil(DynamicMap<CapabilityDefinition> capabilityDefinitions, DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions) { this.capabilityDefinitions = capabilityDefinitions; this.pluginProjectPermissionDefinitions = pluginProjectPermissionDefinitions; } /** * Collects all the plugin declared capabilities. */
private PluginPermissionsUtil(DynamicMap<CapabilityDefinition> capabilityDefinitions, DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions) { this.capabilityDefinitions = capabilityDefinitions; this.pluginProjectPermissionDefinitions = pluginProjectPermissionDefinitions; }
public boolean testOrFalse(ProjectPermission perm) { try { return test(perm); } catch (PermissionBackendException e) { logger.warn("Cannot test " + perm + "; assuming false", e); return false; } } public BooleanCondition testCond(ProjectPermission perm) { return new PermissionBackendCondition.ForProject(this, perm); } public abstract Map<String, Ref> filter(Map<String, Ref> refs, Repository repo, RefFilterOptions opts) throws PermissionBackendException; @AutoValue public abstract static class RefFilterOptions { public abstract boolean filterMeta(); public abstract boolean filterTagsSeparately(); public abstract Builder toBuilder(); }
public Map<String, Ref> filter(Map<String, Ref> refs, Repository repo, RefFilterOptions opts) throws PermissionBackendException { if (refFilter == null) { refFilter = refFilterFactory.create(ProjectControl.this); } return refFilter.filter(refs, repo, opts); } private boolean can(CoreOrPluginProjectPermission perm) throws PermissionBackendException { if (perm instanceof ProjectPermission) { return can((ProjectPermission) perm); } else if (perm instanceof PluginProjectPermission) { return false; } throw new PermissionBackendException(perm.describeForException() + " unsupported"); } private boolean can(ProjectPermission perm) throws PermissionBackendException { switch (perm) { case ACCESS: return user.isInternalUser() || isOwner() || canPerformOnAnyRef(Permission.READ); case READ: return allRefsAreVisible(Collections.emptySet()); case CREATE_REF: return canAddRefs(); case CREATE_TAG_REF: return canAddTagRefs(); case CREATE_CHANGE: return canCreateChanges(); default: return false; } }
private final Timer1<String> latencyPerPush; private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("number of changes uploaded in a single push.").setCumulative(), Field.ofEnum(ResultChangeIds.Key.class, "type", "type of update (replace, create, autoclose)") ); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description("average delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)") ); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)") ); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate() ); }
Field.ofEnum(ResultChangeIds.Key.class, "type", "type of update (replace, create, autoclose)")); latencyPerChange = metricMaker.newTimer("receivecommits/latency", new Description("average delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer("receivecommits/push_latency", new Description("delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); timeouts = metricMaker.newCounter("receivecommits/timeout", new Description("rate of push timeouts").setRate()); private final Metrics metrics; private final ReceiveCommits receiveCommits; private final ResultChangeIds resultChangeIds; private final PermissionBackend.ForProject perm; private final ReceivePack receivePack; private final ExecutorService executor; private final RequestScopePropagator scopePropagator;
metricMaker.newTimer( "receivecommits/latency", new Description("average delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)") ); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)") ); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate() ); private final Metrics metrics; private final ReceiveCommits receiveCommits; private final ResultChangeIds resultChangeIds; private final PermissionBackend.ForProject perm; private final ReceivePack receivePack; private final ExecutorService executor; private final RequestScopePropagator scopePropagator; private final ReceiveConfig receiveConfig; private final ContributorAgreementsChecker contributorAgreements; private final long timeoutMillis; private final ProjectState projectState; private final IdentifiedUser user;
List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); metrics.changes.record(ResultChangeIds.Key.CREATED, created.size()); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(ResultChangeIds.Key.REPLACED, replaced.size()); totalChanges += replaced.size() + created.size(); if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; } else if (totalChanges > 0) { pushType = ResultChangeIds.Key.AUTOCLOSED.name(); } else { pushType = "NORMAL"; } if (totalChanges > 0 && !pushType.equals("NORMAL")) { metrics.latencyPerChange.record(pushType, deltaNanos / totalChanges, NANOSECONDS); } metrics.latencyPerPush.record(pushType, deltaNanos, NANOSECONDS);
Optional<Checker> checker = getChecker(checkerUuid); checkState(checker.isPresent(), "Tried to get a non-existing test checker as CheckerInfo"); return checkerJson.format(checker.get()); public TestCheckerUpdate.Builder forUpdate() { return TestCheckerUpdate.builder(this::updateChecker); } private void updateChecker(TestCheckerUpdate testCheckerUpdate) throws Exception { CheckerUpdate checkerUpdate = toCheckerUpdate(testCheckerUpdate); checkersUpdate.updateChecker(checkerUuid, checkerUpdate); if (testCheckerUpdate.forceInvalidConfig().orElse(false)) { try (Repository repo = repoManager.openRepository(allProjectsName)) { new TestRepository<>(repo) .branch(CheckerRef.refsCheckers(checkerUuid)) .commit() .add(CheckerConfig.CHECKER_CONFIG_FILE, "invalid-config") .create(); } } } private CheckerUpdate toCheckerUpdate(TestCheckerUpdate checkerUpdate) { CheckerUpdate.Builder builder = CheckerUpdate.builder(); checkerUpdate.name().ifPresent(builder::setName); checkerUpdate.description().ifPresent(builder::setDescription); checkerUpdate.url().ifPresent(builder::setUrl); }
import com.google.gerrit.reviewdb.client.Project; import java.util.Arrays; import java.util.Optional; import java.util.stream.Stream; @AutoValue public abstract class TestCheckerUpdate { public abstract Optional<String> name(); public abstract Optional<String> description(); public abstract Optional<String> url(); public abstract Optional<Project.NameKey> repository(); public abstract Optional<CheckerStatus> status(); public abstract Optional<ImmutableSortedSet<BlockingCondition>> blockingConditions(); public abstract Optional<String> query(); public abstract boolean forceInvalidConfig(); // Changed from Optional<Boolean> to boolean abstract ThrowingConsumer<TestCheckerUpdate> checkerUpdater(); public static Builder builder(ThrowingConsumer<TestCheckerUpdate> checkerUpdater) { return new AutoValue_TestCheckerUpdate.Builder().checkerUpdater(checkerUpdater); } @AutoValue.Builder public abstract static class Builder { public abstract Builder name(String name); public abstract Builder description(String description); public Builder clearDescription() { return description(""); } public abstract Builder url(String url); public Builder clearUrl() { return url(""); } public abstract Builder repository(Project.NameKey repository); public abstract Builder forceInvalidConfig(boolean forceInvalidConfig); // Changed from Optional<Boolean> to boolean public abstract TestCheckerUpdate build(); } }
checkOperations.newCheck(key).setState(CheckState.RUNNING).upsert(); checkerOperations.checker(checkerUuid).forUpdate().forceInvalidConfig().update(); exception.expect(RestApiException.class); exception.expectMessage("Cannot retrieve checker " + checkerUuid); checksApiFactory.revision(patchSetId).id(checkerUuid.toString()).get(); @Test public void getNonExistingCheckFails() throws Exception { exception.expect(ResourceNotFoundException.class); exception.expectMessage("Not found: non-existing"); checksApiFactory.revision(patchSetId).id("non-existing").get(); }
parseTag(commit); if (branch == null) { branch = parseBranch(commit); } PatchSet.Id psId = parsePatchSetId(commit); PatchSetState psState = parsePatchSetState(commit); if (psState != null) { patchSetStates.putIfAbsent(psId, psState); if (psState == PatchSetState.DELETED) { deletedPatchSets.add(psId); } } Account.Id accountId = parseIdent(commit); ownerId = Optional.ofNullable(accountId); Account.Id realAccountId = parseRealAccountId(commit, accountId); if (changeId == null) { changeId = parseChangeId(commit); } String currSubject = parseSubject(commit); if (currSubject != null) { subject = subject != null ? subject : currSubject; originalSubject = currSubject; } parseChangeMessage(psId, accountId, realAccountId, commit, ts); topic = Optional.ofNullable(parseTopic(commit));
@Singleton private static class Metrics { private final Histogram1<ResultChangeIds.Key> changes; private final Timer1<String> latencyPerChange; private final Timer1<String> latencyPerPush; private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("number of changes uploaded in a single push.") .setCumulative(), Field.ofEnum(ResultChangeIds.Key.class, "type", "type of push (create/replace, autoclose)")); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description("processing delay per push, averaged over the updated changes in a push.") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("processing delay per push.") .setUnit(Units.MILLISECONDS) .setCumulative()); timeouts = metricMaker.newCounter( "receivecommits/timeouts", new Description("number of timeouts during push processing.") .setCumulative()); } public void flush() { receiveCommits.getMessageSender().flush(); } }
private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("Number of changes uploaded in a single push.") .setCumulative(), Field.ofEnum(ResultChangeIds.Key.class, "type", "Type of push (replace, create, autoclose)") ); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description("Processing delay per push, averaged over the updated changes in a push.") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "Type of push (create/replace, autoclose)") ); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("Processing delay for a single push") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "Type of push (create/replace, autoclose, normal)") ); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("Rate of push timeouts") .setRate() ); }
private static ProjectAccessInput createAccessInput(String accessSection, String permissionName) { ProjectAccessInput accessInput = new ProjectAccessInput(); PermissionRuleInfo ruleInfo = new PermissionRuleInfo(PermissionRuleInfo.Action.ALLOW, false); PermissionInfo email = new PermissionInfo(null, null); email.rules = ImmutableMap.of(SystemGroupBackend.REGISTERED_USERS.get(), ruleInfo); AccessSectionInfo accessSectionInfo = new AccessSectionInfo(); accessSectionInfo.permissions = ImmutableMap.of(permissionName, email); accessInput.add = ImmutableMap.of(accessSection, accessSectionInfo); return accessInput; }
public void isPluginPermissionNameValid() { ImmutableList<String> validPluginPermissions = ImmutableList.of("plugin-foo-a", "plugin-foo-a-b"); for (String permission : validPluginPermissions) { assertThat(isPluginPermission(permission)) .named("valid plugin permission: %s", permission) .isTrue(); } }
public void isPluginPermissionNameInvalidReturnFalse() { ImmutableList<String> validPluginPermissions = ImmutableList.of( "create", "label-Code-Review", "plugin-foo", "plugin-foo", "plugin-foo-a-", "plugin-foo-a1" ); for (String permission : validPluginPermissions) { assertThat(isPluginPermission(permission)) .named("invalid plugin permission: %s", permission) .isFalse(); } }
public void testIsPluginPermissionInvalidNameReturnFalse() { ImmutableList<String> invalidPluginPermissions = ImmutableList.of( "create", "label-Code-Review", "plugin-foo", "plugin-foo", "plugin-foo-a-", "plugin-foo-a1" ); for (String permission : invalidPluginPermissions) { assertThat(isPluginPermission(permission)) .named("invalid plugin permission: %s", permission) .isFalse(); } }
import com.google.common.base.Objects; import com.google.common.base.Preconditions; public class BoolTestPredicate extends Predicate { private final String UNKNOWN_LITERAL = "UNKNOWN"; private final boolean isNegated_; public BoolTestPredicate(Expr e, LiteralExpr v, boolean isNegated) { super(); this.isNegated_ = isNegated; Preconditions.checkNotNull(e); Preconditions.checkNotNull(v); children_.add(e); children_.add(v); } protected BoolTestPredicate(BoolTestPredicate other) { super(other); isNegated_ = other.isNegated_; } public boolean isNegated() { return isNegated_; } @Override public boolean equals(Object obj) { // implementation } } public class LttngRelayDConnector_NOTSUPPORTED implements ILttngRelaydConnector { @Override public List<SessionResponse> getSessions() throws IOException { throw new UnsupportedOperationException(); } @Override public AttachSessionResponse attachToSession(SessionResponse lttngViewerSession) throws IOException { throw new UnsupportedOperationException(); } @Override public String getMetadata(AttachSessionResponse attachedSession) throws IOException { throw new UnsupportedOperationException(); } @Override public TracePacketResponse getNextPacket(StreamResponse stream) throws IOException { throw new UnsupportedOperationException(); } @Override public TracePacketResponse getPacketFromStream(IndexResponse index, long id) throws IOException { throw new UnsupportedOperationException(); } @Override public List<StreamResponse> getNewStreams() throws IOException { throw new UnsupportedOperationException(); } } public class MyClass { // other code public void configure() { bind(CapabilityDefinition.class) .annotatedWith(Exports.named(TEST_PLUGIN_CAPABILITY)) .toInstance(new CapabilityDefinition() { @Override public String getDescription() { return "A Plugin Capability"; } }); bind(PluginProjectPermissionDefinition.class) .annotatedWith(Exports.named(TEST_PLUGIN_PROJECT_PERMISSION)) .toInstance(new PluginProjectPermissionDefinition() { @Override public String getDescription() { return "A Plugin Project Permission"; } }); } // other code @Test public void setAccess_addPluginCapability_succeed() throws Exception { String pluginCapability = TEST_PLUGIN_NAME + "-"
} @Override public void addRelatedLink(String issueKey, URL relatedUrl, String description) throws IOException { addComment( issueKey, "Related URL: " + createLinkForWebui(relatedUrl.toExternalForm(), description)); } @Override public void addValueToField(String issueKey, String value, String fieldId) throws IOException { execute( () -> { log.debug("Adding value {} to field {} on issue {}", value, fieldId, issueKey); jiraClient.addValueToField(issueKey, value, fieldId); return null; }); } @Override public void performAction(String issueKey, String actionName) throws IOException { execute( () -> { log.debug("Performing action {} on issue {}", actionName, issueKey); doPerformAction(issueKey, actionName); return issueKey; }); } private void doPerformAction(String issueKey, String actionName) throws IOException, InvalidTransitionException { log.debug("Trying to perform action: {} on issue {}", actionName, issueKey);
private final Checks checks; private final Provider<ChecksUpdate> checksUpdate; private final CheckJson checkJson; @Inject PostCheck(Checks checks, @UserInitiated Provider<ChecksUpdate> checksUpdate, CheckJson checkJson) { this.checks = checks; this.checksUpdate = checksUpdate; this.checkJson = checkJson; } @Override public CheckInfo apply(RevisionResource rsrc, CheckInput input) throws OrmException, IOException, RestApiException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { throw new BadRequestException("checkerUuid is required"); } CheckKey key = CheckKey.create(rsrc.getProject(), rsrc.getPatchSet().getId(), CheckerUuid.parse(input.checkerUuid)); Optional<Check> check = checks.getCheck(key); if (!check.isPresent()) { if (input.state == null) { throw new BadRequestException("state is required on creation"); } Check updatedCheck = checksUpdate.get().createCheck(key, toCheckUpdate(input)); // rest of the code } // rest of the code }
import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.plugins.checks.PostCheck; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; @Singleton public class UpdateCheck implements RestModifyView<CheckResource, CheckInput> { private final PostCheck postCheck; @Inject UpdateCheck(PostCheck postCheck) { this.postCheck = postCheck; } @Override public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, OrmException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().toString(); } else if (!checkResource.getCheckerUuid().toString().equals(input.checkerUuid)) { throw new BadRequestException( String.format( "checkerUuid must either be null or the same as on the resource:\n" + "the check resource belongs to checker %s," + " but in the input checker %s was specified", checkResource.getCheckerUuid(), input.checkerUuid ) ); } // Rest of the code } }
private static int getInt(Config cfg, String section, String name, int defaultValue) { try { return cfg.getInt(section, name, defaultValue); } catch (IllegalArgumentException e) { multisiteLog.error("invalid value for {}; using default value {}", name, defaultValue); multisiteLog.debug("Failed to retrieve integer value: {}", e.getMessage(), e); return defaultValue; } }
Buggy Code: public CachedPage(int cpid, ByteBuffer buffer, IPageReplacementStrategy pageReplacementStrategy) { this.cpid = cpid; this.buffer = buffer; this.pageReplacementStrategy = pageReplacementStrategy; pinCount = new AtomicInteger(); dirty = new AtomicBoolean(); latch = new ReentrantReadWriteLock(true); replacementStrategyObject = pageReplacementStrategy.createPerPageStrategyObject(cpid); dpid = -1; valid = false; confiscated = new AtomicBoolean(false); queueInfo = null; ctorStack = new Throwable().getStackTrace(); } Fixed Code: public CachedPage(int cpid, ByteBuffer buffer, IPageReplacementStrategy pageReplacementStrategy) { this.cpid = cpid; this.buffer = buffer; this.pageReplacementStrategy = pageReplacementStrategy; pinCount = new AtomicInteger(); dirty = new AtomicBoolean(); latch = new ReentrantReadWriteLock(true); replacementStrategyObject = pageReplacementStrategy.createPerPageStrategyObject(cpid); dpid = -1; valid = false; confiscated = new AtomicBoolean(false); queueInfo = null; }
private static boolean getBoolean(Config cfg, String section, String name, boolean defaultValue) { try { return cfg.getBoolean(section, name, defaultValue); } catch (IllegalArgumentException e) { multisiteLog.error("invalid value for {}; using default value {}", name, defaultValue); multisiteLog.debug("Failed to retrieve boolean value: {}", e.getMessage(), e); return defaultValue; } }
import com.googlesource.gerrit.plugins.multisite.forwarder.ForwarderModule; import com.googlesource.gerrit.plugins.multisite.forwarder.broker.BrokerForwarderModule; import com.googlesource.gerrit.plugins.multisite.index.IndexModule; import com.googlesource.gerrit.plugins.multisite.kafka.consumer.KafkaConsumerModule; import com.googlesource.gerrit.plugins.multisite.kafka.router.ForwardedEventRouterModule; import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.FileReader; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Paths; import java.util.UUID; public class Module extends AbstractModule { private final Configuration config; @Inject public Module(Configuration config) { this.config = config; } @Override protected void configure() { bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(MultiSiteLogFile.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } install(new LifecycleModule() { @Override protected void configure() { listener().to(MultiSiteLogFile.class); } }); } }
protected void configure() { bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(MultiSiteLogFile.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class); }
// You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.broker.kafka; import static com.googlesource.gerrit.plugins.multisite.MultiSiteLogFile.multisiteLog; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.InstanceId; import com.googlesource.gerrit.plugins.multisite.broker.BrokerSession; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.UUID; import java.util.concurrent.ExecutionException; import java.util.concurrent.Future; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; public class KafkaSession implements BrokerSession { private final Configuration properties; private final Producer<String, byte[]> producer; private final String instanceId; @Inject public KafkaSession(Configuration properties, InstanceId instanceId) { this.properties = properties; this.instanceId = instanceId.get(); this.producer = createProducer(); } private Producer<String, byte[]> createProducer() { return new KafkaProducer<>(properties.getKafkaConfig()); } @Override public void send(EventFamily eventFamily, byte[] event) { String topic = properties.getKafkaTopic(eventFamily); String key = UUID.randomUUID().toString(); ProducerRecord<String, byte[]> record = new ProducerRecord<>(topic, key, event); Future<RecordMetadata> future = producer.send(record); try { RecordMetadata metadata = future.get(); multisiteLog().atFine().log("Sent event to Kafka topic %s, partition %d, offset %d", metadata.topic(), metadata.partition(), metadata.offset()); } catch (InterruptedException | ExecutionException e) { multisiteLog().atSevere().withCause(e).
public void connect() { if (isOpen()) { return; } multisiteLog.info("Connect to {}...", properties.getKafka().getBootstrapServers()); setConnectionClassLoader(); producer = new KafkaProducer<>(properties.kafkaPublisher()); multisiteLog.info("Connection established."); }
Fixed Code: public void evict(CacheEntry entry) throws CacheNotFoundException { Cache<?, ?> cache = cacheMap.get(entry.getPluginName(), entry.getCacheName()); if (cache == null) { throw new CacheNotFoundException(entry.getPluginName(), entry.getCacheName()); } try { Context.setForwardedEvent(true); if (Constants.PROJECT_LIST.equals(entry.getCacheName())) { cache.invalidateAll(); multisiteLog.debug("Invalidated cache {}", entry.getCacheName()); } else { cache.invalidate(entry.getKey()); multisiteLog.debug("Invalidated cache {}[{}]", entry.getCacheName(), entry.getKey()); } } finally { Context.unsetForwardedEvent(); } }
Buggy Code: public CachedPage(int cpid, ByteBuffer buffer, IPageReplacementStrategy pageReplacementStrategy) { this.cpid = cpid; this.buffer = buffer; this.pageReplacementStrategy = pageReplacementStrategy; pinCount = new AtomicInteger(); dirty = new AtomicBoolean(); latch = new ReentrantReadWriteLock(true); replacementStrategyObject = pageReplacementStrategy.createPerPageStrategyObject(cpid); dpid = -1; valid = false; confiscated = new AtomicBoolean(false); queueInfo = null; ctorStack = new Throwable().getStackTrace(); } Fixed Code: public CachedPage(int cpid, ByteBuffer buffer, IPageReplacementStrategy pageReplacementStrategy) { this.cpid = cpid; this.buffer = buffer; this.pageReplacementStrategy = pageReplacementStrategy; pinCount = new AtomicInteger(); dirty = new AtomicBoolean(); latch = new ReentrantReadWriteLock(true); replacementStrategyObject = pageReplacementStrategy.createPerPageStrategyObject(cpid); dpid = -1; valid = false; confiscated = new AtomicBoolean(false); queueInfo = null; }
SourceAwareEventWrapper event = valueDeserializer.deserialize(consumerRecord.topic(), consumerRecord.value()); if (event.getHeader().getSourceInstanceId().equals(instanceId)) { multisiteLog.debug("Dropping event {} produced by our instanceId {}", event.toString(), instanceId.toString()); droppedEventListeners.forEach(l -> l.onEventDropped(event)); } else { try { multisiteLog.info("Header[{}] Body[{}]", event.getHeader(), event.getBody()); eventRouter.route(event.getEventBody(gsonProvider)); } catch (IOException e) { multisiteLog.error("Malformed event '{}': [Exception: {}]", event.getHeader().getEventType(), e); } catch (PermissionBackendException | OrmException e) { multisiteLog.error("Cannot handle message {}: [Exception: {}]", event.getHeader().getEventType(), e); } } catch (Exception e) { multisiteLog.error("Malformed event '{}': [Exception: {}]", new String(consumerRecord.value()), e); }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. // Copyright (C) 2018 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software
public static String stripEndSlash(String name) { name = LintUtils.getFormattedParameters("/$", name).get(0); return name; }
private static String strip(String name) { String projectName = ProjectUtil.stripGitSuffix(name); projectName = ProjectUtil.stripEndSlash(projectName); return projectName; }
@Test public void createProjectWithGitSuffix() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + ".git").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } @Test public void createProjectThatEndsWithSlash() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + "/").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } @Test public void createProjectThatContainsSlash() throws Exception { String newProjectName = name("newProject/newProject"); ProjectInfo p = gApi.projects().create(newProjectName).get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); }
assertHead(newProjectName, "refs/heads/master"); } public void createProjectThatEndsWithSlash() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + "/").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } public void createProjectThatContainsSlash() throws Exception { String newProjectName = name("newProject/newProject"); ProjectInfo p = gApi.projects().create(newProjectName).get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } @Test public void createProjectWithProperties() throws Exception { String newProjectName = name("newProject");
adminSshSession.assertFailure(); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNull(); } @Test public void withDotGit() throws Exception { String newGroupName = "newGroup"; adminRestSession.put("/groups/" + newGroupName); String newProjectName = "newProject"; adminSshSession.exec("gerrit create-project --branch master --owner " + newGroupName + " " + newProjectName + ".git"); adminSshSession.assertSuccess(); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertThat(projectState.getName()).isEqualTo(newProjectName); } @Test public void withEndSlash() throws Exception { String newGroupName = "newGroup"; adminRestSession.put("/groups/" + newGroupName); String newProjectName = "newProject"; adminSshSession.exec("gerrit create-project --branch master --owner " + newGroupName + " " + newProjectName + "/"); adminSshSession.assertSuccess(); }
} @VisibleForTesting void setReportSyntaxError(boolean value) { reportSyntaxError = value; } int getMinOwnerVoteLevel(ProjectState projectState, ChangeData c) { if (projectState == null) { logger.atSevere().log("Null projectState for change %s", getChangeId(c)); return minOwnerVoteLevel; } return getPluginConfig(projectState).getInt(MIN_OWNER_VOTE_LEVEL, minOwnerVoteLevel); } } enum EnforcementLevel { DISABLED, WARN, ENFORCE; static final String CONFIG_NAME = "ENFORCE_LEVEL"; }
protected Destination(Injector injector, RemoteSiteUser.Factory replicationUserFactory, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, GroupBackend groupBackend, ReplicationStateListener stateLog, GroupIncludeCache groupIncludeCache, DynamicItem<EventDispatcher> eventDispatcher, @Assisted DestinationConfiguration cfg) { config = cfg; this.eventDispatcher = eventDispatcher; gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.stateLog = stateLog; CurrentUser remoteUser; if (!cfg.getAuthGroupNames().isEmpty()) { ImmutableSet.Builder<AccountGroup.UUID> builder = ImmutableSet.builder(); for (String name : cfg.getAuthGroupNames()) { GroupReference g = GroupBackends.findExactSuggestion(groupBackend, name); if (g != null) { builder.add(g.getUUID()); addRecursiveParents(g.getUUID(), builder, groupIncludeCache); } else { // Handle error case } } authGroups = builder.build(); } else { authGroups = ImmutableSet.of(); } // Rest of the constructor code }
protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class); bind(DfsRefDatabase.class).to(InMemoryDfsRefDatabase.class); }
private boolean isImmutableRef(String refName) { return refName.startsWith("refs/changes") && !refName.endsWith("/meta"); }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.server.git.validators.RefOperationValidationListener; import com.google.inject.AbstractModule; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.NoOpDfsRefDatabase; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.SharedRefDatabase; public class ValidationModule extends AbstractModule { @Override protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class); } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import static com.google.common.truth.Truth.assertThat; import static org.hamcrest.CoreMatchers.nullValue; import static org.hamcrest.CoreMatchers.sameInstance; import static org.mockito.Mockito.any; import static org.mockito.Mockito.argThat; import static org.mockito.Mockito.doReturn; import static org.mockito.Mockito.doThrow; import static org.mockito.Mockito.eq; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.verifyZeroInteractions;
Refactored Code: .when(dfsRefDatabase) .compareAndPut(any(), eq(null), any()); doThrow(new NullPointerException("newRef is null")) .when(dfsRefDatabase) .compareAndPut(any(), any(), eq(null)); doThrow(new NullPointerException("project name is null")) .when(dfsRefDatabase) .compareAndPut(eq(null), any(), any()); validator = new InSyncChangeValidator(dfsRefDatabase, repoManager); repoManager.createRepository(PROJECT_NAMEKEY); } @Test public void shouldNotVerifyStatusOfImmutablePatchSetRefs() throws Exception { testRefReceivedEvent.command = RECEIVE_COMMAND_CREATE_PATCHSET_REF; final List<ValidationMessage> validationMessages = validator.onRefOperation(testRefReceivedEvent); assertThat(validationMessages).isEmpty(); verifyZeroInteractions(dfsRefDatabase); } @Test public void shouldInsertNewRefInDfsDatabaseWhenHandlingRefCreationEvents() throws Exception { testRefReceivedEvent.command = RECEIVE_COMMAND_CREATE_REF; }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.common.flogger.FluentLogger; import com.google.gerrit.acceptance.LightweightPluginDaemonTest; import com.google.gerrit.acceptance.LogThreshold; import com.google.gerrit.acceptance.NoHttpd; import com.google.gerrit.acceptance.PushOneCommit; import com.google.gerrit.acceptance.TestPlugin; import com.google.inject.AbstractModule; import org.junit.Test; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin(name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.validation.Module") public class MultiSiteValidationIT extends LightweightPluginDaemonTest { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); @Override public void setUpTestPlugin() throws Exception { installPlugin("multi-site"); } @Test public void testValidation() throws Exception { logger.atInfo().log("Running testValidation"); PushOneCommit.Result result = createChange(); result.assertOkStatus(); } }
public static void floatTest() { float f = 0; float fc = 1f; for (int i = 0; i < 2; i++) { f -= fc; f = (-f); } System.out.println(f); } public static final String KUDU_STORAGE_HANDLER = "com.cloudera.kudu.hive.KuduStorageHandler"; public static final String KEY_TABLET_REPLICAS = "kudu.num_tablet_replicas"; public static final long KUDU_RPC_TIMEOUT_MS = 50000; private String kuduTableName_; private String kuduMasters_; Device d = getDevice(sdk); File location = sdk.getLocation(); assert location != null; SystemImageDescription systemImageDescription = getSystemImageDescription(location.getAbsolutePath()); String cardSize = AvdEditWizard.toIniString(DEFAULT_INTERNAL_STORAGE, false); File hardwareSkinPath = AvdEditWizard.resolveSkinPath(d.getDefaultHardware().getSkinFile(), systemImageDescription); String displayName = String.format("%1$s %2$s %3$s", d.getDisplayName(), systemImageDescription.getVersion(), systemImageDescription.getAbiType()); String internalName = AvdEditWizard.cleanAvdName(connection, displayName, true); Map<String, String> settings = getAvdSettings(internalName, d); settings.put(AvdManagerConnection.AVD_INI_DISPLAY_NAME, displayName); return connection.createOrUpdateAvd(null, internalName, d, systemImageDescription, ScreenOrientation.PORTRAIT, false, cardSize, hardwareSkinPath, settings, false); public PerCheckOperations check(CheckKey key) { // implementation } public TestCheckUpdate.Builder newCheck(CheckKey key) { // implementation }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.server.notedb.NotesMigration; import com.google.inject.Inject; public class GerritNoteDbStatus implements NoteDbStatus { private final NotesMigration notesMigration; @Inject public GerritNoteDbStatus(NotesMigration notesMigration) { this.notesMigration = notesMigration; } @Override public boolean enabled() { return notesMigration.commitChangeWrites(); } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; /** * Returns the status of changes migration. */ public interface NoteDbStatus { /** * Status of NoteDb migration. * * @return true if Gerrit has been migrated to NoteDb */ boolean enabled(); }
// Name of plugin and namespace. static final String PLUGIN_NAME = "find-owners"; static final String PROLOG_NAMESPACE = "find_owners"; private final PluginConfigFactory configFactory; // Global/plugin config parameters. private boolean addDebugMsg = false; private int minOwnerVoteLevel = 1; private int maxCacheAge = 0; private int maxCacheSize = 1000; private boolean reportSyntaxError = false; private boolean alwaysShowButton = false; private String ownersFileName = OWNERS; private static final FluentLogger logger = FluentLogger.forEnclosingClass(); Config(PluginConfigFactory configFactory) { this.configFactory = configFactory; if (configFactory == null) { // When called from integration tests. return; } PluginConfig gc = configFactory.getFromGerritConfig(PLUGIN_NAME); // Get config variables from the plugin section of gerrit.config addDebugMsg = gc.getBoolean(ADD_DEBUG_MSG, false); reportSyntaxError = gc.getBoolean(REPORT_SYNTAX_ERROR, false); alwaysShowButton = gc.getBoolean(ALWAYS_SHOW_BUTTON, false); }
import com.google.inject.Inject; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import com.google.inject.Provider; import com.google.gerrit.extensions.annotations.RequiresCapability; import com.google.gerrit.extensions.common.GroupInfo; import com.google.gerrit.extensions.common.TopLevelResource; import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.NameAlreadyUsedException; import com.google.gerrit.extensions.restapi.OrmException; import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.GerritPersonIdent; import com.google.gerrit.server.config.GerritServerConfig; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.gerrit.server.group.GroupsCollection; import com.google.gerrit.server.group.PerformCreateGroup; import com.google.gerrit.server.group.PerformCreateGroup.Factory; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group.db.GroupIncludeCache; import com.google.gerrit.server.group
import com.googlesource.gerrit.plugins.multisite.forwarder.events.ChangeIndexEvent; import java.util.ArrayList; import java.util.List; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Before; import org.junit.Test; import org.testcontainers.containers.KafkaContainer; @NoHttpd @LogThreshold(level = "INFO") @Sandboxed @TestPlugin(name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.kafka.consumer.EventConsumerIT$KafkaTestContainerModule") public class EventConsumerIT extends LightweightPluginDaemonTest { private static final int QUEUE_POLL_TIMEOUT_MSECS = 30000; static { System.setProperty("gerrit.notedb", "READ_WRITE"); } public static class KafkaTestContainerModule extends LifecycleModule { public class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) { this.kafka = kafka; } @Override public void start() throws Exception { } @Override public void stop() throws Exception { kafka.stop(); } } private final KafkaContainer kafka; public KafkaTestContainerModule() { kafka = new KafkaContainer(); } @Override protected void configure() { bind(KafkaContainer.class).toInstance(kafka); bind(LifecycleListener.class).annotatedWith(Names.named("KafkaStopAtShutdown")) .toInstance(new KafkaStopAtShutdown(kafka)); } } // Test methods }
public boolean isPreview() { return !mItems.isEmpty() && mItems.get(mItems.size() - 1).isPreview(); } super.setUpTestPlugin(); if (!notesMigration.commitChangeWrites()) { throw new IllegalStateException("NoteDb is mandatory for running the multi-site plugin"); } @Test public void createChangeShouldPropagateChangeIndexAndRefUpdateStreamEvent() throws Exception { LinkedBlockingQueue<SourceAwareEventWrapper> droppedEventsQueue = captureDroppedEvents(); drainQueue(droppedEventsQueue); PushOneCommit.Result r = createChange(); List<Event> createdChangeEvents = receiveFromQueue(droppedEventsQueue, 4); assertThat(createdChangeEvents).hasSize(4); ChangeData change = r.getChange(); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("change-index")) .collect(toSet()) ).containsExactlyElementsIn( ImmutableList.of( createChangeIndexEvent(change.project().get(), change.getId().get(), getParentCommit(change)) ) ); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("ref-updated")) .map(RefUpdatedEvent.class::cast) .map(e -> e.getRefName()) .collect(toSet()) ).containsExactlyElementsIn( ImmutableList.of( RefNames.fullName(change.getDest().branch()), RefNames.fullName(change.getDest().branch() + "-meta"), RefNames.fullName(change.getDest().branch() + "-drafts") ) ); }
.collect(toSet())) .containsExactlyElementsIn( ImmutableList.of( createChangeIndexEvent( change.project().get(), change.getId().get(), getParentCommit(change) ) ) ); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("ref-updated")) .map(RefUpdatedEvent.class::cast) .map(e -> e.getRefName()) .collect(toSet()) ) .containsExactlyElementsIn( ImmutableList.of( "refs/sequences/changes", change.currentPatchSet().getRefName(), "refs/meta" ) ); PatchSetCreatedEvent patchSetCreated = createdChangeEvents .stream() .filter(e -> e.type.equals("patchset-created")) .map(PatchSetCreatedEvent.class::cast) .findFirst() .get(); PatchSetAttribute patchSetAttribute = patchSetCreated.patchSet.get(); PatchSet currentPatchSet = change.currentPatchSet(); assertThat(patchSetAttribute.number).isEqualTo(currentPatchSet.getPatchSetId()); assertThat(patchSetAttribute.revision).isEqualTo(currentPatchSet.getRevision().get()); assertThat(patchSetAttribute.ref).isEqualTo(currentPatchSet.getRefName());
import com.google.inject.TypeLiteral; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.Module; import com.googlesource.gerrit.plugins.multisite.broker.GsonProvider; import com.googlesource.gerrit.plugins.multisite.forwarder.events.ChangeIndexEvent; import java.util.ArrayList; import java.util.List; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Test; import org.testcontainers.containers.KafkaContainer; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin(name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.kafka.consumer.EventConsumerIT$KafkaTestContainerModule") public class EventConsumerIT extends LightweightPluginDaemonTest { private static final int QUEUE_POLL_TIMEOUT_MSECS = 30000; public static class KafkaTestContainerModule extends LifecycleModule { public class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) { this.kafka = kafka; } @Override public void start() throws Exception { } @Override public void stop() throws Exception { kafka.stop(); } } } }
protected void configure() { if (!noteDb.enabled()) { throw new ProvisionException("Gerrit is still running on ReviewDb: please migrate to NoteDb and then reload the multi-site plugin."); } listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } install(new ValidationModule()); bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class); }
import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.Singleton; import java.util.List; import java.util.stream.Stream; @Singleton public class PendingChecksImpl implements PendingChecks { private final Provider<ListPendingChecks> listPendingChecksProvider; @Inject PendingChecksImpl(Provider<ListPendingChecks> listPendingChecksProvider) { this.listPendingChecksProvider = listPendingChecksProvider; } @Override public List<PendingChecksInfo> list(String checkerUuidString, CheckState... checkStates) throws RestApiException { CheckerUuid checkerUuid = CheckerUuid.tryParse(checkerUuidString) .orElseThrow(() -> new BadRequestException(String.format("invalid checker UUID: %s", checkerUuidString))); try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setChecker(checkerUuid); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } } @Override // other methods }
this.listPendingChecksProvider = listPendingChecksProvider; } @Override public List<PendingChecksInfo> list(String checkerUuidString, CheckState... checkStates) throws RestApiException { CheckerUuid checkerUuid = CheckerUuid.tryParse(checkerUuidString) .orElseThrow(() -> new BadRequestException(String.format("invalid checker UUID: %s", checkerUuidString))); try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setChecker(checkerUuid); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } } @Override public List<PendingChecksInfo> listForScheme(String scheme, CheckState... checkStates) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setScheme(scheme); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } }
if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } @Override public List<PendingChecksInfo> listForScheme(String scheme, CheckState... checkStates) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setScheme(scheme); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks for scheme", e); } }
import com.google.gerrit.extensions.annotations.Exports; import com.google.gerrit.extensions.annotations.PluginName; import com.google.gerrit.server.config.PluginConfigFactory; import com.google.gerrit.server.config.ProjectConfigEntry; import com.google.inject.AbstractModule; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.its.base.ItsHookModule; import com.googlesource.gerrit.plugins.its.base.its.ItsConfig; import com.googlesource.gerrit.plugins.its.base.its.ItsFacade; import com.googlesource.gerrit.plugins.its.base.its.ItsFacadeFactory; import com.googlesource.gerrit.plugins.its.base.workflow.CustomAction; import static com.googlesource.gerrit.plugins.its.jira.JiraConfig.*; package com.googlesource.gerrit.plugins.its.jira; public class JiraModule extends AbstractModule { private final String pluginName; @Inject public JiraModule(@PluginName String pluginName) { this.pluginName = pluginName; } @Override protected void configure() { bind(ItsConfig.class).annotatedWith(Exports.named(pluginName)).to(JiraConfig.class); bind(ItsFacade.class).annotatedWith(Exports.named(pluginName)).to(JiraItsFacade.class); bind(ItsFacadeFactory.class).annotatedWith(Exports.named(pluginName)).to(JiraItsFacadeFactory.class); bind(ItsHookModule.class).annotatedWith(Exports.named(pluginName)).to(JiraHookModule.class); bind(PluginConfigFactory.class).annotatedWith(Exports.named(pluginName)).toInstance(new PluginConfigFactory(pluginName)); bind(ProjectConfigEntry.class).annotatedWith(Exports.named(pluginName)).toInstance(new ProjectConfigEntry("Jira", null)); bind(CustomAction.class).annotatedWith(Exports.named(pluginName)).to(JiraCustomAction.class); } }
String email = preferredEmails.get(owner); for (String path : result.owner2paths.get(owner)) { addOwnerPathPair(email, path); } for (String glob : result.noParentGlobs) { add2dir2Globs(Util.getDirName(glob) + "/", glob); } if (config.getReportSyntaxError()) { Ordering.natural().sortedCopy(result.errors).forEach(e -> logger.atSevere().log(e)); Ordering.natural().sortedCopy(result.warnings).forEach(w -> logger.atWarning().log(w)); }
private static void saveReadFile(Map<String, String> readFiles, String project, String file, String content) { if (readFiles != null) { readFiles.put(project + ":" + file, content); } }
private static void checkIncludeOrFile(List<CommitValidationMessage> messages, String path, int num, String line) { // TODO: Check if an included file exists and with valid syntax. // An included file could be a new file added by a CL and not in the repository yet add(messages, "unchecked: " + path + ":" + num + ": " + Parser.getIncludeOrFile(line), false); }
private GitRepositoryManager repoManager; private String branch; private IncludeStack stack; private List<String> logs; private Map<String, Result> savedResults; static class IncludeStack { Deque<String> projectName; Deque<String> filePath; Set<String> allFiles; IncludeStack(String project, String file) { projectName = new ArrayDeque<>(); filePath = new ArrayDeque<>(); allFiles = new HashSet<>(); push(project, file); } void push(String project, String file) { projectName.push(project); filePath.push(file); allFiles.add(project + ":" + file); } void pop() { allFiles.remove(currentProject() + ":" + currentFile()); projectName.pop(); filePath.pop(); } }
void push(String project, String file) { projectName.push(project); filePath.push(file); allFiles.add(project + ":" + file); }
void pop() { allFiles.remove(currentProject() + ":" + currentFile()); projectName.pop(); filePath.pop(); }
boolean contains(String project, String file) { return allFiles.contains(project + ":" + file); }
rp.sendError("internal error while processing changes"); // ReceiveCommits has tried its best to catch errors, so anything at this // point is very bad. for (ReceiveCommand c : commands) { if (c.getResult() == Result.NOT_ATTEMPTED) { c.setResult(Result.REJECTED_OTHER_REASON, "internal error"); } } } finally { w.sendMessages(); } long deltaNanos = System.nanoTime() - startNanos; int totalChanges = 0; String pushType; if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(pushType, created.size() + replaced.size()); totalChanges += replaced.size() + created.size(); } else { List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED); if (!autoclosed.isEmpty()) { pushType = ResultChangeIds.Key.AUTOCLOSED.name();
} finally { w.sendMessages(); } long deltaNanos = System.nanoTime() - startNanos; int totalChanges = 0; String pushType; if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(pushType, created.size() + replaced.size()); totalChanges = replaced.size() + created.size(); } else { List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED); if (!autoclosed.isEmpty()) { pushType = ResultChangeIds.Key.AUTOCLOSED.name(); metrics.changes.record(ResultChangeIds.Key.AUTOCLOSED.name(), autoclosed.size()); totalChanges = autoclosed.size(); } else { pushType = "NORMAL"; } } if (totalChanges > 0) { metrics.latencyPerChange.record(pushType, deltaNanos / totalChanges, NANOSECONDS); } metrics.latencyPerPush.record(pushType, deltaNanos, NANOSECONDS);
String patchsetRevision = change.currentPatchSet().getRevision().get(); String patchsetRef = change.currentPatchSet().getRefName(); Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue); assertThat(eventsByType.get("change-index")) .containsExactly(createChangeIndexEvent(project, changeNum, getParentCommit(change))); assertThat(eventsByType.get("ref-updated") .stream() .map(e -> ((RefUpdatedEvent) e).getRefName()) .collect(toSet())) .containsAllOf(changeNotesRef, patchsetRef); List<Event> patchSetCreatedEvents = eventsByType.get("patchset-created"); assertThat(patchSetCreatedEvents).hasSize(1); assertPatchSetAttributes((PatchSetCreatedEvent) patchSetCreatedEvents.get(0), patchsetNum, patchsetRevision, patchsetRef); } private void assertPatchSetAttributes(PatchSetCreatedEvent patchSetCreated, int patchsetNum, String patchsetRevision, String patchsetRef) { PatchSetAttribute patchSetAttribute = patchSetCreated.patchSet.get(); assertThat(patchSetAttribute.number).isEqualTo(patchsetNum); assertThat(patchSetAttribute.revision).isEqualTo(patchsetRevision); }
import java.util.List; import java.util.ArrayList; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; import java.util.stream.Collectors; public class EventProcessor { private static final int QUEUE_POLL_TIMEOUT_MSECS = 1000; public List<Event> processEvents(LinkedBlockingQueue<SourceAwareEventWrapper> queue) throws InterruptedException { GsonProvider gsonProvider = plugin.getSysInjector().getInstance(Key.get(GsonProvider.class)); List<Event> eventsList = new ArrayList<>(); SourceAwareEventWrapper event; while ((event = queue.poll(QUEUE_POLL_TIMEOUT_MSECS, TimeUnit.MILLISECONDS)) != null) { eventsList.add(event.getEventBody(gsonProvider)); } return eventsList; } }
private final CheckResource checkResource; @Inject CheckApiImpl(GetCheck getCheck, UpdateCheck updateCheck, @Assisted CheckResource checkResource) { this.getCheck = getCheck; this.updateCheck = updateCheck; this.checkResource = checkResource; } @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { try { Arrays.stream(options).forEach(getCheck::addOption); return getCheck.apply(checkResource); } catch (Exception e) { throw asRestApiException("Cannot retrieve check", e); } } @Override public CheckInfo update(CheckInput input) throws RestApiException { try { return updateCheck.apply(checkResource, input); } catch (Exception e) { throw asRestApiException("Cannot update check", e); } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.client; import java.lang.reflect.InvocationTargetException; import java.util.EnumSet; /** * Enum that can be expressed as a bitset in query parameters. */ public interface ListOption { int getValue(); static <T extends Enum<T> & ListOption> EnumSet<T> fromBits(Class<T> clazz, int v) { EnumSet<T> r = EnumSet.noneOf(clazz); T[] values; try { @SuppressWarnings("unchecked") T[] tmp = (T[]) clazz.getMethod("values").invoke(null); values = tmp; } catch (IllegalAccessException | NoSuchMethodException | InvocationTargetException e) { throw new IllegalStateException(e); } for (T o : values) { if ((v & (1 << o.getValue())) != 0) { r.add(o); v &= ~(1 << o.getValue()); } } if (v != 0) { throw new IllegalArgumentException("Unknown bits set in " + v); } return r; } }
import com.google.gerrit.server.git.PureRevertCache; import com.google.gerrit.server.notedb.ChangeNotes; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.InvalidObjectIdException; import org.eclipse.jgit.lib.ObjectId; @Singleton public class PureRevert { private final PureRevertCache pureRevertCache; @Inject PureRevert(PureRevertCache pureRevertCache) { this.pureRevertCache = pureRevertCache; } public boolean isPureRevert(ChangeNotes notes, @Nullable String claimedOriginal) throws OrmException, IOException, BadRequestException, ResourceConflictException { PatchSet currentPatchSet = notes.getCurrentPatchSet(); if (currentPatchSet == null) { throw new ResourceConflictException("current revision is missing"); } if (claimedOriginal == null) { return pureRevertCache.isPureRevert(notes); } ObjectId claimedOriginalObjectId; try { claimedOriginalObjectId = ObjectId.fromString(claimedOriginal); } catch (InvalidObjectIdException e) { throw new BadRequestException("invalid object ID"); } return pureRevertCache.isPureRevert(notes, claimedOriginalObjectId); } }
@Override public boolean isPureRevert(String projectName, String currentRevision, String claimedOriginal) { PatchSet currentPatchSet = notes.getCurrentPatchSet(); if (currentPatchSet == null) { throw new ResourceConflictException("current revision is missing"); } if (claimedOriginal == null) { return pureRevertCache.isPureRevert(notes); } ObjectId claimedOriginalObjectId; try { claimedOriginalObjectId = ObjectId.fromString(claimedOriginal); } catch (InvalidObjectIdException e) { throw new BadRequestException("invalid object ID"); } boolean result = pureRevertCache.isPureRevert(notes.getProjectName(), ObjectId.fromString(notes.getCurrentPatchSet().getRevision().get()), claimedOriginalObjectId); return result; }
import org.eclipse.jgit.diff.DiffFormatter; import org.eclipse.jgit.errors.InvalidObjectIdException; import org.eclipse.jgit.errors.MissingObjectException; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectInserter; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.merge.ThreeWayMerger; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; @Singleton public class PureRevertCache { static final String ID_CACHE = "pure_revert"; public static class Module extends CacheModule { @Override protected void configure() { persist(ID_CACHE, Cache.PureRevertKeyProto.class, Boolean.class) .maximumWeight(100) .loader(Loader.class) .version(1) .keySerializer(new ProtobufSerializer<>(Cache.PureRevertKeyProto.parser())) .valueSerializer(BooleanCacheSerializer.INSTANCE); } } private final LoadingCache<PureRevertKeyProto, Boolean> cache; private final PatchSetUtil psUtil; private final ChangeNotes.Factory notesFactory; @Inject PureRevertCache(LoadingCache<PureRevertKeyProto, Boolean> cache, PatchSetUtil psUtil, ChangeNotes.Factory notesFactory) { this.cache = cache; this.psUtil = psUtil; this.notesFactory = notesFactory; } // rest of the code... }
private final LoadingCache<PureRevertKeyProto, Boolean> cache; private final PatchSetUtil psUtil; private final ChangeNotes.Factory notesFactory; @Inject PureRevertCache( @Named(ID_CACHE) LoadingCache<PureRevertKeyProto, Boolean> cache, PatchSetUtil psUtil, ChangeNotes.Factory notesFactory ) { this.cache = cache; this.psUtil = psUtil; this.notesFactory = notesFactory; } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code claimedOriginal}. * * @param claimedRevert the claimed revert to check * @return {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code claimedOriginal} * @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ChangeNotes} */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { // implementation }
import com.google.gerrit.server.project.ProjectControl; import com.google.gerrit.sshd.BaseCommand.UnloggedFailure; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import java.util.ArrayList; import java.util.Arrays; import java.util.List; import java.util.Map; import java.util.Optional; import java.util.stream.Collectors; public class ChangeArgumentParser { private final CurrentUser currentUser; private final ChangesCollection changesCollection; private final ChangeFinder changeFinder; private final ReviewDb db; private final ChangeNotes.Factory changeNotesFactory; private final ChangeControl.GenericFactory changeControlFactory; @Inject ChangeArgumentParser(CurrentUser currentUser, ChangesCollection changesCollection, ChangeFinder changeFinder, ReviewDb db, ChangeNotes.Factory changeNotesFactory, ChangeControl.GenericFactory changeControlFactory) { this.currentUser = currentUser; this.changesCollection = changesCollection; this.changeFinder = changeFinder; this.db = db; this.changeNotesFactory = changeNotesFactory; this.changeControlFactory = changeControlFactory; } public void addChange(String id, Map<Change.Id, ChangeResource> changes) throws UnloggedFailure, OrmException { // Code implementation } } public class Definition<T, Q extends QueryBuilder<T>> { private final Map<String, OperatorFactory<T, Q>> opFactories = new HashMap<>(); public Definition(Class<Q> clazz) { if (clazz != null) { Class<?> c = clazz; while (c != QueryBuilder.class) { registerOperatorFactories(c, null); c = c.getSuperclass(); } } } public Definition(Iterable<? extends DynamicBuilder<T>> builders) { if (builders != null) { for (DynamicBuilder<T> builder : builders) { registerOperatorFactories(builder); } } } } public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { if (claimedRevert.getChange().getRevertOf() == null) { throw new BadRequestException("revertOf not set"); } PatchSet ps = psUtil.current(notesFactory.createChecked(claimedRevert.getProjectName(), claimedRevert.getChange().getRevertOf())); return isPureRevert(claimedRevert.getProjectName(), ObjectId.fromString(claimedRevert.getCurrent
ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(ps.getRevision().get())); } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * * @return {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * @throws IOException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ObjectId}s */ public boolean isPureRevert(Project.NameKey project, ObjectId claimedRevert, ObjectId claimedOriginal) throws IOException, BadRequestException { try { return cache.get(key(project, claimedRevert, claimedOriginal)); } catch (ExecutionException e) { Throwables.throwIfInstanceOf(e.getCause(), BadRequestException.class); throw new IOException(e); } } @VisibleForTesting static PureRevertKeyProto key(
Project.NameKey project = new Project.NameKey(key.getProject()); try (Repository repo = repoManager.openRepository(project); ObjectInserter oi = repo.newObjectInserter(); RevWalk rw = new RevWalk(repo)) { RevCommit claimedOriginalCommit; try { claimedOriginalCommit = rw.parseCommit(original); } catch (InvalidObjectIdException | MissingObjectException e) { throw new BadRequestException("invalid object ID"); } if (claimedOriginalCommit.getParentCount() == 0) { return false; } RevCommit claimedRevertCommit = rw.parseCommit(revert); if (claimedRevertCommit.getParentCount() == 0) { return false; } // Rebase claimed revert onto claimed original ThreeWayMerger merger = mergeUtilFactory .create(projectCache.checkedGet(project)) .newThreeWayMerger(oi, repo.getConfig()); merger.setBase(claimedRevertCommit.getParent(0)); boolean success = merger.merge(claimedRevertCommit, claimedOriginalCommit); if (!success || merger.getResultTreeId() == null) { // Merge conflict during rebase return false; } }
public void createProject(CredentialsProvider credentialsProvider, URIish uri, String projectName, String head) { OutputStream errStream = newErrorBufferStream(); String cmd = "gerrit create-project --branch " + head + " " + projectName; try { execute(credentialsProvider, uri, cmd, errStream); } catch (IOException e) { log.error(String.format("Error creating remote repository at %s:%n" + " Exception: %s%n Command: %s%n Output: %s", uri, e, cmd, errStream), e); } } Ref destRef = git.getRefDatabase().exactRef(resource.getRef()); if (destRef == null) { throw new ResourceNotFoundException(resource.getRef()); } RevCommit targetCommit = rw.parseCommit(destRef.getObjectId()); RevCommit sourceCommit = MergeUtil.resolveCommit(git, rw, source); if (!resource.getControl().canReadCommit(db.get(), git, sourceCommit)) { throw new BadRequestException("Do not have read permission for: " + source); } if (rw.isMergedInto(sourceCommit, targetCommit)) { throw new ChangeAlreadyMergedException("'" + source + "' has already been merged!"); } result.mergeable = m.merge(false, targetCommit, sourceCommit); if (m instanceof ResolveMerger) { result.conflicts = ((ResolveMerger) m).getUnmergedPaths(); } TUpdateCatalogCacheRequest req = new TUpdateCatalogCacheRequest(); TUniqueId default_catalog_service_id = new TUniqueId(0L, 0L); for (byte[] catalogUpdate : thriftCatalogUpdates) { TUpdateCatalogCacheRequest incrementalRequest = new TUpdateCatalogCacheRequest(); JniUtil.deserializeThrift(protocolFactory_, incrementalRequest, catalogUpdate); if (!req.isSetIs_delta()) { req.setIs_delta(incrementalRequest.isIs_delta()); } if (!incrementalRequest.getCatalog_service_id().equals(default_catalog_service_id)) { req.setCatalog_service_id(incrementalRequest.getCatalog_service_id()); } if (!req.isSetUpdated_objects()) { req.setUpdated_objects(incrementalRequest.getUpdated_objects()); } else { req.getUpdated_objects().addAll(incrementalRequest.getRemoved_objects()); } if (!req.isSetRemoved_objects()) { req.setRemoved_objects(incrementalRequest.removed_objects); } else
public void testPureRevertCacheKey() { ObjectId revert = ObjectId.zeroId(); ObjectId original = ObjectId.fromString("deadbeefdeadbeefdeadbeefdeadbeefdeadbeef"); byte[] serializedRevert = new byte[20]; byte[] serializedOriginal = new byte[20]; revert.copyRawTo(serializedRevert, 0); original.copyRawTo(serializedOriginal, 0); Cache.PureRevertKeyProto key = PureRevertCache.key(new Project.NameKey("test"), revert, original); assertThat(key) .isEqualTo(Cache.PureRevertKeyProto.newBuilder() .setProject("test") .setClaimedRevert(ByteString.copyFrom(serializedRevert)) .setClaimedOriginal(ByteString.copyFrom(serializedOriginal)) .build()); }
static String getFileKey(String project, String file) { return project + ":" + file; }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper; import static com.google.common.base.Preconditions.checkArgument; import java.io.IOException; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.ExponentialBackoffRetry; public class CuratorFrameworkBuilder { private ZkConfig config = null; public CuratorFrameworkBuilder config(ZkConfig config) { this.config = config; return this; } public CuratorFramework build() throws IOException { // Implementation goes here } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper; import com.google.common.base.MoreObjects; import java.io.Serializable; import org.apache.curator.framework.CuratorFrameworkFactory; import org.eclipse.jgit.lib.Config; /** Configuration for a Zookeeper setup. */ public class ZkConfig implements Serializable { private static final long serialVersionUID = 1L; public static final int DEFAULT_SESSION_TIMEOUT_MS; public static final int DEFAULT_CONNECTION_TIMEOUT_MS; static { // Initialize constants } // Rest of the code }
public static final int DEFAULT_CONNECTION_TIMEOUT_MS; static { CuratorFrameworkFactory.Builder b = CuratorFrameworkFactory.builder(); DEFAULT_SESSION_TIMEOUT_MS = b.getSessionTimeoutMs(); DEFAULT_CONNECTION_TIMEOUT_MS = b.getConnectionTimeoutMs(); } private static final String SECTION = "zookeeper"; private static final String KEY_CONNECT_STRING = "connectString"; private static final String KEY_SESSION_TIMEOUT = "sessionTimeout"; private static final String KEY_CONNECTION_TIMEOUT = "connectionTimeout"; // TODO(dborowitz): Configure RetryPolicy. private final String connectString; private final int sessionTimeoutMs; private final int connectionTimeoutMs; private final String zookeeperRoot; ZkConfig( final String connectString, final String zookeeperRoot, final int sessionTimeoutMs, final int connectionTimeoutMs) { this.connectString = connectString; this.sessionTimeoutMs = sessionTimeoutMs; this.connectionTimeoutMs = connectionTimeoutMs; this.zookeeperRoot = zookeeperRoot; } public static ZkConfig fromConfig(Config cfg) { return new ZkConfig( cfg.getString(SECTION, null, KEY_CONNECT_STRING), cfg.getInt(SECTION, null, KEY_SESSION_TIMEOUT, DEFAULT_SESSION_TIMEOUT_MS), cfg.getInt(SECTION, null, KEY_CONNECTION_TIMEOUT, DEFAULT_CONNECTION_TIMEOUT_MS), cfg.getString(SECTION, null, KEY_ZOOKEEPER_ROOT)); }
return true; } private boolean doCreate(ZkRefInfoMarshaller marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception { if (infoCurrentlyInZkMaybe.isPresent()) { logger.atWarning().log("Asked to create ref %s but it is already in ZK at path %s", newRefInfo.refName(), ZkRefInfoMarshaller.pathFor(newRefInfo)); return false; } marshaller.create(newRefInfo); return true; } static class TombstoneRef implements Ref { static TombstoneRef forRef(final Ref targetRef) { return new TombstoneRef(targetRef.getName()); } private final String name; private TombstoneRef(String name) { this.name = name; } @Override public String getName() { return name; } @Override public boolean isSymbolic() { return false; } @Override public Ref getLeaf() { return null; } @Override public Ref getTarget() { return null; } }
assertThat(marshaller.read(aProjectName(), aChangeRefName())).isEqualTo(Optional.empty()); @Test public void shouldUpdateAZrefInfo() throws Exception { ZkRefInfo newRefInfo = aZkRefInfo(); ZkRefInfo updateRefInfo = new ZkRefInfo( newRefInfo.projectName(), newRefInfo.refName(), anObjectId(), Instant.now(), UUID.randomUUID()); // Make sure new refInfo and updateRefInfo are never the same assertThat(newRefInfo).isNotEqualTo(updateRefInfo); marshaller.create(newRefInfo); marshaller.update(updateRefInfo); Optional<ZkRefInfo> readUpdatedRefInfo = marshaller.read(updateRefInfo.projectName(), updateRefInfo.refName()); assertThat(readUpdatedRefInfo).isEqualTo(Optional.of(updateRefInfo)); } @Test public void shouldFailToReadZkRefInfoIfSomeOfTheInfoIsMissing() throws Exception { String projectName = aProjectName(); String refName = aChangeRefName(); curator.createContainers(ZkRefInfoMarshaller.pathFor(projectName, refName)); expectedException.expect(CorruptedZkStorageException.class); }
public boolean equals(Object other) { if (this == other) { return true; } if (other == null || getClass() != other.getClass()) { return false; } ZkRefInfo zkRefInfo = (ZkRefInfo) other; return Objects.equal(refName, zkRefInfo.refName) && Objects.equal(projectName, zkRefInfo.projectName) && Objects.equal(objectId, zkRefInfo.objectId) && Objects.equal(lastWriterInstanceId, zkRefInfo.lastWriterInstanceId) && Objects.equal(lastUpdatedAt, zkRefInfo.lastUpdatedAt); }
marshaller.read(projectName, newRef.getName()); final ZkRefInfo newRefInfo = new ZkRefInfo(projectName, newRef, instanceId); if (isCreate) { return doCreate(marshaller, infoCurrentlyInZkMaybe, newRefInfo); } else { return doUpdate(oldRef, marshaller, infoCurrentlyInZkMaybe, newRefInfo); } } catch (Exception e) { logger.atWarning().withCause(e).log( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)); throw new IOException( String.format("Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)), e); } private boolean doUpdate( Ref oldRef, ZkRefInfoMarshaller marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo ) throws Exception { if (!infoCurrentlyInZkMaybe.isPresent()) { logger.atWarning().log( "Asked to update ref %s but it is not in ZK at path %s", newRef.getName(), ZkRefInfoMarshaller.pathFor(projectName, newRef) ); throw new IOException( String.format( "Asked to update ref %s but it is not in ZK at path %s", newRef.getName(), ZkRefInfoMarshaller.pathFor(projectName, newRef) ) ); } // Perform the update logic here return true; }
} } catch (Exception e) { logger.atWarning().withCause(e).log( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)); throw new IOException( String.format( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)), e); } } private boolean doUpdate( Ref oldRef, ZkRefInfoMarshaller marshaller, ZkRefInfo infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception { if (infoCurrentlyInZkMaybe == null) { logger.atWarning().log( "Asked to update ref %s but it is not in ZK at path %s", newRefInfo.refName(), ZkRefInfoMarshaller.pathFor(newRefInfo)); return false; } if (!infoCurrentlyInZkMaybe.objectId().equals(oldRef.getObjectId())) { logger.atWarning().log(
import java.io.IOException; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.test.TestingServer; import org.junit.Test; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin(name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.validation.ValidationIT$Module") public class ValidationIT extends LightweightPluginDaemonTest { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); CuratorFramework framework; public static class Module extends LifecycleModule { public class ZookeeperStopAtShutdown implements LifecycleListener { private final TestingServer zookeeper; public ZookeeperStopAtShutdown(TestingServer zookeeper) { this.zookeeper = zookeeper; } @Override public void stop() { try { zookeeper.stop(); } catch (IOException e) { logger.atWarning().withCause(e).log("Cannot start zookeeper"); throw new RuntimeException("Cannot start zookeeper", e); } } @Override public void start() { try { zookeeper.start(); } catch (Exception e) { logger.atWarning().withCause(e).log("Cannot start zookeeper"); throw new RuntimeException("Cannot start zookeeper", e); } } } } }
protected void configure() { TestingServer zookeeper = null; try { zookeeper = new TestingServer(); } catch (Exception e) { throw new RuntimeException("Cannot init zookeeper", e); } install(new ValidationModule()); super.configure(); listener().toInstance(new ZookeeperStopAtShutdown(zookeeper)); }
import org.junit.Ignore; @Ignore public interface RefFixture { String ALLOWED_CHARS = "abcdefghilmnopqrstuvz"; String ALLOWED_DIGITS = "1234567890"; String ALLOWED_NAME_CHARS = ALLOWED_CHARS + ALLOWED_CHARS.toUpperCase() + ALLOWED_DIGITS; static ZkRefInfo aZkRefInfo() { return new ZkRefInfo(aProjectName(), aChangeRefName(), anObjectId(), Instant.now(), UUID.randomUUID()); } static String aProjectName() { return generateRandomString(20, ALLOWED_NAME_CHARS); } static ObjectId anObjectId() { return ObjectId.fromString(generateRandomNumericString(40)); } static String aChangeRefName() { return "refs/for/" + generateRandomString(10, ALLOWED_NAME_CHARS); } static Ref aRefObject(String refName, ObjectId objectId) { return new TestRef(refName, objectId); } static Ref aRefObject(String refName) { return aRefObject(refName, anObjectId()); } static Ref aRefObject() { return aRefObject(aChangeRefName(), anObjectId()); } static String generateRandomString(int length, String allowedChars) { StringBuilder sb = new StringBuilder(length); Random random = new Random(); for (int i = 0; i < length; i++) { int index = random.nextInt(allowedChars.length()); sb.append(allowedChars.charAt(index)); } return sb.toString(); } static String generateRandomNumericString(int length) { StringBuilder sb = new StringBuilder(length); Random random = new Random(); for (int i = 0; i < length; i++) { int digit = random.nextInt(10); sb.append(digit); } return sb.toString(); } }
import static RefFixture.anObjectId; import static RefFixture.aChangeRefName; public void shouldCreateANewRef() { ObjectId objectId = anObjectId(); String refName = aChangeRefName(); Ref aNewRef = zkSharedRefDatabase.newRef(refName, objectId); assertThat(aNewRef.getName()).isEqualTo(refName); assertThat(aNewRef.getObjectId()).isEqualTo(objectId); assertThat(aNewRef.getStorage()).isEqualTo(Storage.NETWORK); }
import java.util.Arrays; import javax.crypto.Cipher; import javax.crypto.KeyGenerator; import javax.crypto.NoSuchPaddingException; import javax.crypto.SecretKey; import javax.crypto.spec.IvParameterSpec; @Singleton public class LfsAuthTokenHandler { private static final Logger log = LoggerFactory.getLogger(LfsAuthTokenHandler.class); private static final int IV_LENGTH = 16; private static final String ALGORITHM = "AES"; static final DateTimeFormatter DATE_TIME = DateTimeFormat.forPattern("YYYYMMDDHHmmss"); private final SecureRandom random; private final SecretKey key; @Inject public LfsAuthTokenHandler() { this.random = new SecureRandom(); this.key = generateKey(); } public String generateToken(int expirationSeconds, String... params) { try { byte[] initVector = new byte[IV_LENGTH]; random.nextBytes(initVector); Cipher cipher = cipher(initVector, Cipher.ENCRYPT_MODE); return Base64.encodeBytes(Bytes.concat(initVector, cipher.doFinal(String.format("%s~%s", Joiner.on('~').join(params), DATE_TIME.print(DateTime.now().plusSeconds(expirationSeconds)))))); } catch (Exception e) { log.error("Error generating token", e); return null; } } private SecretKey generateKey() { try { KeyGenerator keyGen = KeyGenerator.getInstance(ALGORITHM); keyGen.init(128); return keyGen.generateKey(); } catch (NoSuchAlgorithmException e) { log.error("Error generating key", e); return null; } } }
marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); assertThat(zkSharedRefDatabase.compareAndRemove(projectName, oldRef)).isTrue(); Optional<ZkRefInfo> inZk = marshaller.read(projectName, oldRef.getName()); assertThat(inZk.isPresent()).isTrue(); assertThat(inZk.get().projectName()).isEqualTo(projectName); assertThat(inZk.get().refName()).isEqualTo(oldRef.getName()); assertThat(inZk.get().objectId()).isEqualTo(ObjectId.zeroId()); @Test public void shouldNotCompareAndPutSuccessfullyAfterACompareAndRemove() throws Exception { Ref oldRef = aRefObject(); String projectName = RefFixture.aProjectName(); marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); zkSharedRefDatabase.compareAndRemove(projectName, oldRef); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, aRefObject(oldRef.getName()))).isFalse(); }
return "/" + projectName + "/" + refName; } private final CuratorFramework client; public ZkRefInfoDAO(CuratorFramework client) { this.client = client; } public ZkRefInfo read(String projectName, String refName) throws Exception { final String rootPath = pathFor(projectName, refName); if (!exists(rootPath)) { throw new Exception("Root path does not exist"); } final Optional<ObjectId> objectId = readObjectIdAt(rootPath + "/" + OBJECT_ID_PATH); if (!objectId.isPresent()) { throw new CorruptedZkStorageException( String.format("Corrupted content for ref %s, missing some of the sub info, %s present: %b", refName, OBJECT_ID_PATH, objectId.isPresent())); } return new ZkRefInfo(projectName, refName, objectId.get()); } public void update(ZkRefInfo info) throws Exception { writeInTransaction(info, () -> client.transactionOp().setData()); } public void create(ZkRefInfo info) throws Exception { writeInTransaction(info, () -> client.transactionOp().create()); }
import org.apache.curator.framework.recipes.locks.InterProcessMutex; import org.apache.curator.framework.recipes.locks.Locker; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; public class ZkSharedRefDatabase implements SharedRefDatabase { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CuratorFramework client; private final Duration lockTimeout; private final UUID instanceId; @Inject public ZkSharedRefDatabase(CuratorFramework client, @Named("ZkLockTimeout") Duration lockTimeout, @InstanceId UUID instanceId) { this.client = client; this.lockTimeout = lockTimeout; this.instanceId = instanceId; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, TombstoneRef.forRef(oldRef)); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { boolean isCreate = oldRef == NULL_REF; final ZkRefInfoDAO marshaller = new ZkRefInfoDAO(client); final InterProcessMutex refPathMutex = new InterProcessMutex(client, getRefPath(projectName)); try (Locker locker = new Locker(refPathMutex, lockTimeout)) { if (!locker.lock()) { logger.atWarning().log("Failed to acquire lock for project: %s", projectName); return false; } RefInfo oldRefInfo = marshaller.getRefInfo(projectName, oldRef.getName()); if (oldRefInfo == null) { if (!isCreate) { logger.atWarning().log("Failed to compare and put ref for project: %s", projectName); return false; } } else { if (!oldRefInfo.getRef().getObjectId().equals(oldRef.getObjectId())) { logger.atWarning().log("Failed to compare and put ref for project: %s", projectName); return false; } } RefInfo newRefInfo = new RefInfo(newRef, instanceId); marshaller.putRefInfo(projectName, newRef.getName(), newRefInfo); return true; } catch (Exception e) { logger.atWarning().withCause(e).log("Failed to compare and put ref for project: %s", projectName); return false;
import com.google.gerrit.extensions.annotations.Exports; import com.google.gerrit.extensions.config.FactoryModule; import com.google.gerrit.plugins.checks.Checker; import com.google.gerrit.plugins.checks.Checkers; import com.google.gerrit.plugins.checks.api.BlockingCondition; import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.plugins.checks.api.CombinedCheckState; import com.google.gerrit.plugins.checks.api.ListChecks; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.project.SubmitRuleOptions; import com.google.gerrit.server.query.change.ChangeData; import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; import java.util.Map; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder() }
import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId; private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); result.assertOkStatus(); testChangeId = result.getChangeId(); testPatchSetId = result.getPatchSetId(); approve(testChangeId); testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED); } }
import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); result.assertOkStatus(); testPatchSetId = result.getPatchSetId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(result.getChangeId()); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED); assertThat(checkerOperations.checker(testCheckerUuid).get().getBlockingConditions()) .containsExactly(BlockingCondition.STATE_NOT_PASSING); } }
// about checks. approve(testChangeId); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED); assertThat(checkerOperations.checker(testCheckerUuid).get().getBlockingConditions()) .containsExactly(BlockingCondition.STATE_NOT_PASSING); @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. Project.NameKey otherRepo = new Project.NameKey("other-project"); gApi.projects().create(otherRepo.get()); checkerOperations.checker(testCheckerUuid).forUpdate().repository(otherRepo).update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getRepository()) .isEqualTo(otherRepo); gApi.changes().id(testChangeId).current().submit(); }
@Test public void disabledCheckerNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations.checker(testCheckerUuid).forUpdate().disable().update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.DISABLED); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void enabledCheckerNotBlockingSubmitIfNoBlockingCondition() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations .checker(testCheckerUuid) .forUpdate() .repository(otherRepo) .update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getRepository()) .isEqualTo(otherRepo); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); }
gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); @Test public void enabledCheckerBlockingSubmitIfInBlockingState() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); exception.expect(ResourceConflictException.class); exception.expectMessage("Passing all blocking checks required"); gApi.changes().id(testChangeId).current().submit(); } @Test public void multipleCheckerBlockingSubmit() throws Exception { // Two enabled and required checkers. They are blocking if any of them isn't passing. CheckerUuid testCheckerUuid2 = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .create(); postCheckResult(testCheckerUuid, CheckState.SUCCESSFUL); postCheckResult(testCheckerUuid2, CheckState.FAILED); exception.expect(ResourceConflictException.class); exception.expectMessage("Passing all blocking checks required"); gApi.changes().id(testChangeId).current().submit(); } @Test public void multipleCheckerNotBlockingSubmit() throws Exception { // Two enabled and required checkers. They are not blocking if all of them are passing. CheckerUuid testCheckerUuid2 = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .create(); postCheckResult(testCheckerUuid, CheckState.SUCCESSFUL); postCheckResult(testCheckerUuid2, CheckState.SUCCESSFUL); gApi.changes().id(testChangeId).current().submit(); }
public class OwnersParser { public Result parseFile(String dir, String[] lines) { Result result = new Result(); int n = 0; for (String line : lines) { parseLine(result, dir, line, ++n); } return result; } public Result parseFile(String dir, String content) { Result result = new Result(); int n = 0; String[] lines = content.split("\n"); for (String line : lines) { parseLine(result, dir, line, ++n); } return result; } private void parseLine(Result result, String dir, String line, int lineNumber) { // Parse the line and add the parsed data to the result } } public class Result { // Define the data structure for storing the parsed result }
public static void parseIncludedFile(Result result, String dir, int num, String[] parsedKPF, boolean isInclude) { if (isInclude) { includeFile(result, dir, num, parsedKPF, true); } else { result.errors.add(errorMsg(stack.currentFile(), num, "ignored unknown line", line)); } } public static void includeFile(Result result, String dir, int num, String[] parsedKPF, boolean isInclude) { // implementation }
} } /** * Find and parse an included file and append data to the 'result'. * For an 'include' statement, parsed data is all append to the given result parameter. * For a 'file:' statement or directive, only owner emails are appended. * If the project+file name is found in the stored result set, the stored result is reused. * The inclusion is skipped if to be included file is already on the including file stack. * * @param result to where the included file data should be added. * @param dir the including file's directory or glob. * @param num source code line number * @param parsedKPF the parsed line of include or file directive. * @param addAll to add all parsed data into result or not. */ private void includeFile(Result result, String dir, int num, String[] parsedKPF, boolean addAll) { String keyword = parsedKPF[0]; String project = parsedKPF[1];
assertThat(r2.owner2paths).isEmpty(); assertThat(r2.warnings).containsExactly(w2, w1); assertThat(r2.noParentGlobs).containsExactly(b2, b1); assertThat(r1.noParentGlobs).containsExactly(b1); assertThat(r2.errors).containsExactly(e2, e1); r1.append(r2, "", true); assertThat(r1.owner2paths).isEmpty(); assertThat(r2.owner2paths).isEmpty(); assertThat(r1.warnings).containsExactly(w1, w2); assertThat(r1.warnings).containsExactly(w2, w1); assertThat(r1.noParentGlobs).containsExactly(b2, b1); assertThat(r1.errors).containsExactly(e1, e2); assertThat(r1.errors).containsExactly(e2, e1);
import org.eclipse.jgit.treewalk.filter.PathFilterGroup; import org.junit.Test; @TestPlugin(name = "find-owners", sysModule = "com.googlesource.gerrit.plugins.findowners.Module") public class OwnersFileSubmitRuleIT extends AbstractDaemonTest { @Test public void TestChangeWithoutPermissions() throws Exception { createTestRepositoryContent(); setProjectConfig("enforceLevel", "ENFORCE"); PushOneCommit.Result r = createCommitAndPush(testRepo, "refs/for/master", "test message", "A/1/foo.c", "void main()"); approve(r.getChangeId()); ChangeInfo result = gApi.changes().id(r.getChangeId()).get(); assertThat(result.submittable).isFalse(); } private void createTestRepositoryContent() throws Exception { grant(project, "refs/for/master", Permission.PUSH); TestRepository<InMemoryRepository>.CommitBuilder cb = testRepo.branch("master").commit(); cb.add("OWNERS", "alice@example.com\nbob@example.com\n"); cb.add("A/1/foo.c", "int main()\n"); } }
import com.google.gerrit.reviewdb.client.ChangeNotes; import com.google.gerrit.server.cache.CacheModule; import com.google.gerrit.server.cache.proto.Cache.PureRevertKeyProto; import com.google.gerrit.server.change.ChangeNotes.Factory; import com.google.gerrit.server.change.ChangeNotes.RevId; import com.google.gerrit.server.change.ChangeNotes.RevertOf; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.Builder; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.Builder; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.Builder; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.RevertOfKeyProtoTypeTypeType; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.Builder; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.RevertOfKeyProtoTypeTypeType; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.Builder; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey.RevertOfKeyProto.RevertOfKeyProtoType.RevertOfKeyProtoTypeType.RevertOfKeyProtoTypeTypeType; import com.google.gerrit.server.change.ChangeNotes.RevertOf.RevertOfKey
/** * @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ChangeNotes} */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { if (claimedRevert.getChange().getRevertOf() == null) { throw new BadRequestException("revertOf not set"); } ChangeNotes changeNotes = notesFactory.createChecked( claimedRevert.getProjectName(), claimedRevert.getChange().getRevertOf()); return isPureRevert( claimedRevert.getProjectName(), ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(changeNotes.getCurrentPatchSet().getRevision().get())); } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. */
private final GitRepositoryManager repositoryManager; private final Set<Project.NameKey> repositoryNameKeys; @Inject public JGitHealthCheck(ListeningExecutorService executor, HealthCheckConfig config, GitRepositoryManager repositoryManager) { super(executor, config, JGIT); this.repositoryManager = repositoryManager; this.repositoryNameKeys = config.getJGITRepositories(JGIT); } @Override protected Result doCheck() throws Exception { for (Project.NameKey repoNameKey : repositoryNameKeys) { try (Repository repo = repositoryManager.openRepository(repoNameKey)) { repo.open(repo.resolve("refs/meta/config")).getType(); } } return Result.PASSED; } }
generateSshHostKeys(); remover.remove("bc(pg|pkix|prov)-.*[.]jar"); private static boolean isOff(String listenHostname) { return "off".equalsIgnoreCase(listenHostname) || "none".equalsIgnoreCase(listenHostname) || "no".equalsIgnoreCase(listenHostname); } private void generateSshHostKeys() throws InterruptedException, IOException { if (!exists(site.ssh_key) && (!exists(site.ssh_rsa) || !exists(site.ssh_dsa) || !exists(site.ssh_ed25519) || !exists(site.ssh_ecdsa))) { System.err.print("Generating SSH host key ..."); System.err.flush(); // Generate the SSH daemon host key using ssh-keygen. // final String comment = "gerrit-code-review@" + hostname(); // Workaround for JDK-6518827 - zero-length argument ignored on Win32 String emptyPassphraseArg = HostPlatform.isWin32() ? "\"\"" : ""; if (!exists(site.ssh_rsa)) { System.err.print(" rsa..."); System.err.flush(); new ProcessBuilder( Review: This should be formatted with gjf. Fixed Code: generateSshHostKeys(); remover.remove("bc(pg|pkix|prov)-.*[.]jar"); private static boolean isOff(String listenHostname) { return "off".equalsIgnoreCase(listenHostname) || "none".equalsIgnoreCase(listenHostname) || "no".equalsIgnoreCase(listenHostname); } private void generateSshHostKeys() throws InterruptedException, IOException { if (!exists(site.ssh_key) && (!exists(site.ssh_rsa) || !exists(site.ssh_dsa) || !exists(site.ssh_ed25519) || !exists(site.ssh_ecdsa))) { System.err.print("Generating SSH host key ..."); System.err.flush(); // Generate the SSH daemon host key using ssh-keygen. // final String comment = "gerrit-code-review@" + hostname(); // Workaround for JDK-6518827 - zero-length argument ignored on Win32 String emptyPassphraseArg = HostPlatform.isWin32() ? "\"\"" : ""; if (!exists(site.ssh_rsa)) { System.err.print(" rsa..."); System.err.flush(); new ProcessBuilder( Buggy Code: private String keyToString(Object key) { if(key instanceof StringKey) { return ((String
public Collection<SubmitRecord> evaluate(ChangeData cd, SubmitRuleOptions options) { ProjectState projectState = projectCache.get(cd.project()); PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance(projectState, pluginName); EnforcementLevel enforce_level = pluginConfig.getEnum(EnforcementLevel.CONFIG_NAME, EnforcementLevel.DISABLED); if (enforce_level == EnforcementLevel.DISABLED) { return ImmutableList.of(); } Checker checker = new Checker(repoManager, pluginConfigFactory, projectState, cd, 1); int result; try { OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager) .get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } }
public Collection<SubmitRecord> evaluate(ChangeData cd, SubmitRuleOptions options) { ProjectState projectState = projectCache.get(cd.project()); PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance(projectState, pluginName); EnforcementLevel enforceLevel = pluginConfig.getEnum(EnforcementLevel.CONFIG_NAME, EnforcementLevel.DISABLED); if (enforceLevel == EnforcementLevel.DISABLED) { return ImmutableList.of(); } Checker checker = new Checker(repoManager, pluginConfigFactory, projectState, cd, 1); int result; try { OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager) .get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } }
protected void writeLog(IStatus[] statuses) { if (logFile.exists()) { logFile.delete(); } for (IStatus status : statuses) { RuntimeLog.log(status); } } throws ResourceNotFoundException, OrmException, IOException { if (input == null) { input = new Input(); } Account a = dbProvider.get().accounts().get(user.getAccountId()); if (a == null) { throw new ResourceNotFoundException("account not found"); } a.setStatus(input.status); dbProvider.get().accounts().update(Collections.singleton(a)); byIdCache.evict(a.getId()); return Strings.isNullOrEmpty(a.getStatus()) ? Response.<String>none() : Response.ok(a.getFullName()); } writeTrashFile("target/com/B.java", ""); writeTrashFile("target/org/A.java", ""); writeTrashFile("target/org/B.java", ""); writeTrashFile(".gitignore", "/target"); git.add().addFilepattern("readme").call(); git.commit().setMessage("initial").call(); diff = new IndexDiff(db, Constants.HEAD, new FileTreeIterator(db)); diff.diff(); assertEquals(new HashSet<String>(Arrays.asList("src")), diff.getUntrackedFolders()); git.add().addFilepattern("src").call(); writeTrashFile("sr/com/X1.java", ""); writeTrashFile("src/tst/A.java", ""); writeTrashFile("src/tst/B.java", ""); deleteTrashFile(".gitignore"); diff = new IndexDiff(db, Constants.HEAD, new FileTreeIterator(db)); diff.diff(); assertEquals(new HashSet<String>(Arrays.asList("target", "src/tst")), diff.getUntrackedFolders()); pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } SubmitRecord sr = new SubmitRecord(); sr.requirements = SUBMIT_REQUIREMENTS; if (result >= 0) { sr.status = Status.OK; return ImmutableList.of(sr); } sr.status = enforceLevel == ENFORCE ? Status.NOT_READY : Status.OK; return ImmutableList.of(sr);
import com.google.gerrit.extensions.api.changes.SubmitInput; import com.google.gerrit.extensions.common.ChangeInfo; import com.google.gerrit.server.config.PluginConfig; import org.eclipse.jgit.lib.ObjectLoader; import org.eclipse.jgit.revwalk.RevObject; import org.eclipse.jgit.revwalk.RevTree; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Test; @TestPlugin(name = "find-owners", sysModule = "com.googlesource.gerrit.plugins.findowners.Module") public class OwnersFileSubmitRuleIT extends LightweightPluginDaemonTest { @Test public void testChangeWithoutPermissions() throws Exception { createTestRepositoryContent(); configurePlugin("enforceLevel", "ENFORCE"); PushOneCommit.Result r = createChange("test message", "A/1/foo.c", "void main()\n"); approve(r.getChangeId()); ChangeInfo result = gApi.changes().id(r.getChangeId()).get(); assertThat(result.submittable).isFalse(); } private void createTestRepositoryContent() throws Exception { addFile("init", "OWNERS", "per-file *.c = alice@example.com, bob@example.com\n"); } }
public String pathFor(String projectName, String refName) { return "/" + projectName + "/" + refName; } public static String pathFor(String projectName, String refName) { return "/" + projectName + "/" + refName; } private final CuratorFramework client; public ZkRefInfoDAO(CuratorFramework client) { this.client = client; } public Optional<ZkRefInfo> read(String projectName, String refName) throws Exception { final String rootPath = pathFor(projectName, refName); if (!exists(rootPath)) return Optional.empty(); final ObjectId objectId = readObjectIdAt(rootPath + "/" + OBJECT_ID_PATH); return Optional.of(new ZkRefInfo(projectName, refName, objectId)); } public void update(ZkRefInfo info) throws Exception { writeInTransaction(info, () -> client.transactionOp().setData()); } public void create(ZkRefInfo info) throws Exception { client.createContainers(pathFor(info)); writeInTransaction(info, () -> client.transactionOp().create().withMode(PERSISTENT)); } private void writeInTransaction(
import com.google.gerrit.server.query.change.ChangeData; import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder() .setFallbackText("All required checks must pass") .setType("passing_all_blocking_checks") .build(); public static class Module extends FactoryModule { @Override public void configure() { bind(SubmitRule.class) .annotatedWith(Exports.named("ChecksSubmitRule")) .to(ChecksSubmitRule.class); } } private final Checks checks; @Inject public ChecksSubmitRule(Checks checks) { this.checks = checks; } @Override public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) { Project.NameKey project = changeData.project(); Change.Id changeId = changeData.getId(); // rest of the code } }
import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder() .setFallbackText("Passing all blocking checks required") .setType("checks_pass") .build(); public static class Module extends FactoryModule { @Override public void configure() { bind(SubmitRule.class) .annotatedWith(Exports.named("ChecksSubmitRule")) .to(ChecksSubmitRule.class); } } private final Checks checks; @Inject public ChecksSubmitRule(Checks checks) { this.checks = checks; } @Override public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) { Project.NameKey project = changeData.project(); Change.Id changeId = changeData.getId(); PatchSet.Id currentPathSetId; try { // code logic here } catch (OrmException | IOException e) { logger.atSevere().withCause(e).log("Failed to evaluate submit rule for change %s", changeId); return Collections.emptyList(); } } }
import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId; private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); result.assertOkStatus(); testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); approve(testChangeId); testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { // Test code here } }
testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. Project.NameKey otherRepo = new Project.NameKey("other-project"); checkerOperations.checker(testCheckerUuid).forUpdate().repository(allProjects).update(); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations.checker(testCheckerUuid).forUpdate().disable().update(); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); }
private static class Helper { public static String pathFor(String projectName, Ref ref) { return pathFor(projectName, ref.getName()); } public static String pathFor(String projectName, String refName) { return "/" + projectName + "/" + refName; } public static ObjectId readObjectId(byte[] value) { return ObjectId.fromRaw(value); } public static byte[] writeObjectId(ObjectId value) throws IOException { final ByteArrayOutputStream out = new ByteArrayOutputStream(); final DataOutputStream stream = new DataOutputStream(out); value.copyRawTo(stream); return out.toByteArray(); } }
import com.google.common.collect.ImmutableList; import com.google.gerrit.extensions.api.changes.RevisionApi; import com.google.gerrit.extensions.common.CheckInfo; import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.ResourceConflictException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.server.change.RevisionResource; import com.google.inject.Inject; import java.io.IOException; import java.util.Map; import java.util.stream.Collectors; import static java.util.stream.Collectors.toMap; public class ListChecks implements RevisionApi.ListChecks { private final CheckBackfiller checkBackfiller; private final CheckJson.Factory checkJsonFactory; private final Checkers checkers; private final Checks checks; @Inject ListChecks( CheckBackfiller checkBackfiller, CheckJson.Factory checkJsonFactory, Checkers checkers, Checks checks) { this.checkBackfiller = checkBackfiller; this.checkJsonFactory = checkJsonFactory; this.checkers = checkers; this.checks = checks; } @Override public ImmutableList<CheckInfo> apply(RevisionResource resource) throws AuthException, BadRequestException, ResourceConflictException, RestApiException, IOException { CheckJson checkJson = checkJsonFactory.create(options); Map<CheckerUuid, Checker> checkersByUuid = checkers.checkersOf(resource.getProject()).stream() .collect(toMap(Checker::getUuid, c -> c)); ImmutableList.Builder<CheckInfo> result = ImmutableList.builderWithExpectedSize(checkersByUuid.size()); for (Check check : checks.getChecks(resource.getProject(), resource.getPatchSet().getId())) { checkersByUuid.remove(check.key().checkerUuid()); result.add(checkJson.format(check)); } for (Check check : checkBackfiller.getBackfilledChecksForRelevantCheckers( checkersByUuid.values(), resource.getNotes(), resource.getPatchSet().getId())) { result.add(checkJson.format(check)); } return result.build(); } }
Optional<Check> getCheck(CheckKey checkKey) throws OrmException, IOException; @AutoValue abstract class GetChecksOptions { public abstract boolean backfillChecks(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_Checks_GetChecksOptions.Builder().setBackfillChecks(false); } public static GetChecksOptions defaults() { return builder().build(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setBackfillChecks(boolean backfillChecks); public abstract GetChecksOptions build(); } }
private final CuratorFramework client; private final RetryPolicy retryPolicy; @Inject public ZkSharedRefDatabase(CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } else { final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } }
@Inject public ZkSharedRefDatabase(CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } else { final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } } catch (Exception e) { logger.atWarning().withCause(e).log("Failed to compare and put ref"); throw new IOException("Failed to compare and put ref", e); } }
import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.server.config.AllProjectsName; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private static final SubmitRequirementInfo SUBMIT_REQUIREMENT_INFO = new SubmitRequirementInfo( "NOT_READY", "All required checks must pass", "checks_pass", ImmutableMap.of()); @Inject private AllProjectsName allProjects; private String testChangeId; private PatchSet.Id testPatchSetId; @Before public void setUp() throws Exception { allProjects = plugin.getSysInjector().getInstance(AllProjectsName.class); PushOneCommit.Result result = createChange(); testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { // Test code here } }
protected void configure() { bind(ChangesCollection.class); bind(Revisions.class); bind(Reviewers.class); bind(DraftComments.class); bind(Comments.class); bind(Files.class); bind(Votes.class); bind(BlameCache.class).to(BlameCacheImpl.class); DynamicMap.mapOf(binder(), CHANGE_KIND); DynamicMap.mapOf(binder(), COMMENT_KIND); DynamicMap.mapOf(binder(), DRAFT_COMMENT_KIND); DynamicMap.mapOf(binder(), FILE_KIND); DynamicMap.mapOf(binder(), REVIEWER_KIND); DynamicMap.mapOf(binder(), REVISION_KIND); DynamicMap.mapOf(binder(), CHANGE_EDIT_KIND); DynamicMap.mapOf(binder(), VOTE_KIND); get(CHANGE_KIND).to(GetChange.class); get(CHANGE_KIND, "detail").to(GetDetail.class); get(CHANGE_KIND, "topic").to(GetTopic.class); get(CHANGE_KIND, "in").to(IncludedIn.class); get(CHANGE_KIND, "hashtags").to(GetHashtags.class); } // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.gerrit.sshd.CommandMetaData; import com.google.gerrit.sshd.SshCommand; import com.google.gson.JsonObject; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.replication.ReplicationConfig.FilterType; import org.kohsuke.args4j.Option; import java.util.List; @CommandMetaData(name = "list", description = "List specific slaves information") final class ListCommand extends SshCommand { private static final char endl = '\n'; @Option(name = "--detail", usage = "Display slave detail information") private boolean detail; @Option(name = "--slave", metaVar = "PATTERN", usage = "pattern to match slave name on") private String slave; @Option(name = "--format", usage = "plain|json output format, plain is the default") private String format; @Inject private ReplicationConfig config; @Override protected void run() { List<Destination> dest = config.getDestinations(FilterType.ALL); for (Destination d : dest) { // code logic here } } } import org.eclipse.sirius.diagram
public String getStoreKey() { return m_storeKey; } protected String getStoreKey() { return m_storeKey; } public boolean isTypeSupported(Class<T> clazz) { // TODO: Add other types? Float, etc if (String.class.isAssignableFrom(clazz) || Integer.class.isAssignableFrom(clazz) || Boolean.class.isAssignableFrom(clazz)) { return true; } return false; } protected boolean isTypeSupported(Class<T> clazz) { // TODO: Add other types? Float, etc if (String.class.isAssignableFrom(clazz) || Integer.class.isAssignableFrom(clazz) || Boolean.class.isAssignableFrom(clazz)) { return true; } return false; } @Before public void setUpCheckersPlugin() throws Exception { checkerOperations = plugin.getSysInjector().getInstance(CheckerOperations.class); checkOperations = plugin.getSysInjector().getInstance(CheckOperations.class); checkersApi = plugin.getHttpInjector().getInstance(Checkers.class); checksApiFactory = plugin.getHttpInjector().getInstance(ChecksFactory.class); pendingChecksApi = plugin.getHttpInjector().getInstance(PendingChecks.class); allowGlobalCapabilities(group("Administrators").getGroupUUID(), "checks-administrateCheckers"); } protected TestCheckerCreation.Builder newRequiredChecker() { return checkerOperations .newChecker() .repository(project) .status(CheckerStatus.ENABLED) .blockingConditions(BlockingCondition.STATE_NOT_PASSING); }
Buggy Code: ```java fetch(repo, checkerRef + ":checkerRef"); repo.reset("checkerRef"); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.PUSH); PushOneCommit.Result r = pushFactory.create(admin.getIdent(), repo).to(checkerRef); r.assertErrorStatus(); r.assertMessage("direct update of checker ref not allowed"); } @Test public void submitToCheckerRefsIsDisabled() throws Exception { // TODO(xchangcheng): remove the "disable" after figuring out the expecting behavior of // CombinedCheckState. Currently, this **not-required** checker is blocking submission but // it shouldn't. CheckerUuid checkerUuid = checkerOperations.newChecker().status(CheckerStatus.DISABLED).create(); String checkerRef = checkerUuid.toRefName(); String changeId = createChangeWithoutCommitValidation(checkerRef); grantLabel( "Code-Review", -2, 2, allProjects, CheckerRef.REFS_CHECKERS + "*", false, adminGroupUuid(), false ); approve(changeId); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.SUBMIT); exception.expect(ResourceConflictException.class); } ``` Refactored Code: ```java fetch(repo, checkerRef + ":checkerRef"); repo.reset("checkerRef"); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.PUSH); PushOneCommit.Result r = pushFactory.create(admin.getIdent(), repo).to(checkerRef); r.assertErrorStatus(); r.assertMessage("direct update of checker ref not allowed"); } @Test public void submitToCheckerRefsIsDisabled() throws Exception { CheckerUuid checkerUuid = checkerOperations.newChecker().status(CheckerStatus.DISABLED).create(); String checkerRef = checkerUuid.toRefName(); String changeId = createChangeWithoutCommitValidation(checkerRef); grantLabel( "Code-Review", -2, 2, allProjects, CheckerRef.REFS_CHECKERS + "*", false, adminGroupUuid(), false ); approve(changeId); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.SUBMIT); exception.expect(ResourceConflictException.class); } ```
@Inject private AllProjectsName allProjects; testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. Project.NameKey otherRepo = new Project.NameKey(allProjects.get()); checkerOperations.checker(checkerUuid).forUpdate().repository(otherRepo).update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); checkerOperations.checker(checkerUuid).forUpdate().disable().update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } // @Test
public void emptyString() { ParameterizedString p = new ParameterizedString(""); assertThat(p.getPattern()).isEqualTo(""); assertThat(p.getRawPattern()).isEqualTo(""); assertThat(p.getParameterNames().isEmpty()).isTrue(); Map<String, String> a = new HashMap<>(); assertThat(p.bind(a)).isNotNull(); assertThat(p.bind(a)).isEmpty(); assertThat(p.replace(a)).isEmpty(); } import org.eclipse.jgit.api.errors.GitAPIException; import org.junit.Test; import java.io.IOException; import java.util.List; public class GetRelatedIT extends AbstractDaemonTest { @Inject private ChangeEditUtil editUtil; @Inject private ChangeEditModifier editModifier; @Test public void getRelatedNoResult() throws GitAPIException, IOException, Exception { PushOneCommit push = pushFactory.create(db, admin.getIdent()); PatchSet.Id ps = push.to(git, "refs/for/master").getPatchSetId(); List<ChangeAndCommit> related = getRelated(ps); assertThat(related).isEmpty(); } @Test public void getRelatedLinear() throws GitAPIException, IOException, Exception { add(git, "a.txt", "1"); Commit c1 = createCommit(git, admin.getIdent(), "subject: 1"); add(git, "b.txt", "2"); Commit c2 = createCommit(git, admin.getIdent(), "subject: 2"); pushHead(git, "refs/for/master", false); for (Commit c : ImmutableList.of(c2, c1)) { // code block } } public void emptyString() { ParameterizedString p = new ParameterizedString(""); assertThat(p.getPattern()).isEqualTo(""); assertThat(p.getRawPattern()).isEqualTo(""); assertThat(p.getParameterNames().isEmpty()).isTrue(); Map<String, String> a = new HashMap<>(); assertThat(p.bind(a)).isNotNull(); assertThat(p.bind(a)).isEmpty(); assertThat(p.replace(a)).isEmpty(); } import org.eclipse.jgit.api.errors.GitAPIException; import org.junit.Test; import java.io.IOException; import java.util.List; public class GetRelatedIT extends AbstractDaemonTest { @Inject private ChangeEditUtil editUtil; @Inject private ChangeEditModifier editModifier; @Test public void
CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.SUCCESSFUL); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isFalse(); CheckerUuid checkerUuid = newRequiredChecker().create(); CheckerUuid testCheckerUuid2 = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.SUCCESSFUL); postCheckResult(testCheckerUuid2, CheckState.FAILED); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isFalse();
import com.google.gwt.user.client.ui.Anchor; import com.google.gwt.user.client.ui.Composite; import com.google.gwt.user.client.ui.HTMLPanel; import com.google.gwt.user.client.ui.Label; import com.google.gwtorm.client.KeyUtil; import java.util.LinkedList; import java.util.List; public class PatchSetSelectBox extends Composite { interface Binder extends UiBinder<HTMLPanel, PatchSetSelectBox> { } private static Binder uiBinder = GWT.create(Binder.class); interface BoxStyle extends CssResource { String selected(); String sideMarker(); String hidden(); } PatchScript script; Patch.Key patchKey; PatchSet.Id idSideA; PatchSet.Id idSideB; PatchSet.Id idActive; Side side; PatchScreen.Type screenType; List<Anchor> links; @UiField HTMLPanel linkPanel; @UiField BoxStyle style; @UiField SpanElement sideMarker; public enum Side { A, B } public PatchSetSelectBox(Side side, final PatchScreen.Type type) { this.side = side; this.screenType = type; return Collections.emptyList(); } public int getCount() { return count; } public void reset() { count = 0; } @Override public Module createModule() { return new AbstractModule() { @Override protected void configure() { testRefOperationListener = new TestRefOperationValidationListener(); DynamicSet.bind(binder(), RefOperationValidationListener.class) .toInstance(testRefOperationListener); } }; } static { System.setProperty("gerrit.notedb", "ON"); } @After public void cleanup() { testRefOperationListener.reset(); } @Test public void aNormalPushShouldTriggerARefOperationValidation() throws Exception { PushOneCommit.Result r = createCommitAndPush(testRepo, "refs/heads/master", "msg", "file", "content"); assertThat(testRefOperationListener.getCount()).isEqualTo(1); } @Test public void aMagicRefUpdateShouldTriggerARefOperationValidationOnChangesBranch() throws Exception { PushOneCommit.Result r = createChange("refs/for/master"); } }
String.format("checker %s not found", checkerUuid))); if (checker.getStatus() == CheckerStatus.DISABLED) { return ImmutableList.of(); } List<ChangeData> changes = queryMatchingChangesFor(checker); List<PendingChecksInfo> pendingChecks = new ArrayList<>(changes.size()); for (ChangeData cd : changes) { getMatchingPendingChecks(cd.project(), cd.currentPatchSet().getId()) .ifPresent(pendingChecks::add); } return pendingChecks; } private List<ChangeData> queryMatchingChangesFor(Checker checker) throws ConfigInvalidException, OrmException { Predicate<ChangeData> predicate = new ProjectPredicate(checker.getRepository().get()); if (checker.getQuery().isPresent()) { String query = checker.getQuery().get(); try { predicate = Predicate.and(predicate, queryBuilderProvider.get().parse(query)); } catch (QueryParseException e) { logger.atWarning().withCause(e).log( "Invalid query for checker %s: %s", checker.getUuid(), query); } } return queryProvider.get().query(predicate); }
CheckablePatchSetInfo patchSet = actual().patchSet; Truth.assertThat(patchSet).named("patch set").isNotNull(); return patchSet;
install(new NoteDbCheckersModule()); bind(CapabilityDefinition.class) .annotatedWith(Exports.named(AdministrateCheckersCapability.NAME)) .to(AdministrateCheckersCapability.class); DynamicSet.bind(binder(), CommitValidationListener.class) .to(CheckerCommitValidator.class) .in(SINGLETON); DynamicSet.bind(binder(), MergeValidationListener.class) .to(CheckerMergeValidator.class) .in(SINGLETON); DynamicSet.bind(binder(), RefOperationValidationListener.class) .to(CheckerRefOperationValidator.class) .in(SINGLETON); bind(ChangeAttributeFactory.class) .annotatedWith(Exports.named("checks")) .to(ChangeCheckAttributeFactory.class); bind(DynamicOptions.DynamicBean.class) .annotatedWith(Exports.named(GetChange.class)) .to(GetChangeOptions.class); install(new ApiModule());
import org.eclipse.jgit.lib.ObjectId; import org.junit.Test; public class CheckerDefinitionTest { @Test public void notRequiredIfNoBlockingCondition() { Checker checker = newChecker().setBlockingConditions(ImmutableSortedSet.of()).build(); assertThat(checker.isRequired()).isFalse(); } @Test public void requiredIfHasBlockingConditionStateNotPassing() { Checker checker = newChecker().setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)).build(); assertThat(checker.isRequired()).isTrue(); } private Checker.Builder newChecker() { return Checker.builder() .setRepository(new NameKey("test-repo")) .setStatus(CheckerStatus.ENABLED) .setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)) .setUuid(CheckerUuid.parse("schema:any-id")) .setCreatedOn(TimeUtil.nowTs()) .setUpdatedOn(TimeUtil.nowTs()) .setRefState(ObjectId.zeroId()); } }
import org.assertj.core.api.Assertions; import org.junit.Test; public class CheckerTest { @Test public void requiredIfHasNoBlockingCondition() { Checker checker = newChecker().build(); Assertions.assertThat(checker.isRequired()).isFalse(); } @Test public void requiredIfHasBlockingConditionStateNotPassing() { Checker checker = newChecker() .setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)) .build(); Assertions.assertThat(checker.isRequired()).isTrue(); } private Checker.Builder newChecker() { return Checker.builder() .setRepository(new NameKey("test-repo")) .setStatus(CheckerStatus.ENABLED) .setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)) .setUuid(CheckerUuid.parse("schema:any-id")) .setCreatedOn(TimeUtil.nowTs()) .setUpdatedOn(TimeUtil.nowTs()) .setRefState(ObjectId.zeroId()); } }
public CombinedCheckState reload(Project.NameKey project, PatchSet.Id psId) throws OrmException { CombinedCheckStateCacheKeyProto key = key(project, psId); CombinedCheckState newState = loader.load(key); CombinedCheckState oldState = cache.getIfPresent(key); if (newState != oldState) { cache.put(key, newState); } return newState; } @VisibleForTesting public void putForTest(Project.NameKey project, PatchSet.Id psId, CombinedCheckState state) { cache.put(key(project, psId), state); } @VisibleForTesting public CacheStats getStats() { return cache.stats(); }
private ChangeCheckInfo forGetChange(ChangeData cd, GetChangeOptions opts) throws OrmException { if (opts != null && opts.combined) { return new ChangeCheckInfo(combinedCheckStateCache.reload(cd.project(), cd.change().currentPatchSetId())); } return null; } private ChangeCheckInfo forQueryChanges(ChangeData cd, QueryChangesOptions opts) throws OrmException { if (opts != null && opts.combined) { return new ChangeCheckInfo(combinedCheckStateCache.get(cd.project(), cd.change().currentPatchSetId())); } return null; }
RefUpdate refUpdate = repo.updateRef(refName); refUpdate.setExpectedOldObjectId(parent); refUpdate.setNewObjectId(newCommitId); refUpdate.setRefLogIdent(personIdent); refUpdate.setRefLogMessage(message, false); refUpdate.update(); RefUpdateUtil.checkResult(refUpdate); try { combinedCheckStateCache.reload(checkKey.project(), checkKey.patchSet()); } catch (OrmException e) { logger.atWarning().withCause(e).log("failed to reload CombinedCheckState for %s", checkKey); } gitRefUpdated.fire(checkKey.project(), refUpdate, currentUser.map(user -> user.state()).orElse(null)); return readSingleCheck(checkKey, repo, rw, newCommitId); } private void assertCheckerIsPresent(CheckerUuid checkerUuid) throws ConfigInvalidException, IOException { checkers.getChecker(checkerUuid).orElseThrow(() -> new IOException(checkerUuid + " missing")); } private boolean updateNotesMap(CheckKey checkKey, CheckUpdate checkUpdate, Repository repo, RevWalk rw, ObjectInserter ins, ObjectId curr, ObjectId newCommitId) throws IOException { try (ObjectReader reader = rw.getObjectReader()) { NoteMap noteMap = NoteMap.read(reader, curr); Note note = noteMap.get(checkKey.patchSet()); if (note == null) { return false; } CheckState oldState = note.getState(); CheckState newState = checkUpdate.getState(); if (oldState == newState) { return false; } note.setState(newState); noteMap.set(checkKey.patchSet(), note); noteMap.write(reader, ins); return true; } }
public void setReviewerUpdates(List<ReviewerStatusUpdate> reviewerUpdates) { this.reviewerUpdates = reviewerUpdates; } @Test public void updatingCheckStateUpdatesCache() throws Exception { CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); cache.putForTest(project, psId, CombinedCheckState.IN_PROGRESS); CacheStats start = clone(cache.getStats()); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.IN_PROGRESS)); CacheStats stats = cache.getStats().minus(start); assertThat(stats.hitCount()).isEqualTo(1); assertThat(stats.missCount()).isEqualTo(0); // Set non-required checker to FAILED, updating combined check state to WARNING. stats = cache.getStats().minus(start); assertThat(stats.hitCount()).isEqualTo(2); assertThat(stats.missCount()).isEqualTo(0); }
protected JComponent createNorthPanel() { JPanel titlePanel = new JPanel(new BorderLayout()); JBLabel label = new JBLabel("Your Virtual Devices"); Font font = label.getFont(); if (font == null) { font = UIUtil.getLabelFont(); } font = new Font(font.getName(), font.getStyle() | Font.BOLD, font.getSize() + 4); label.setFont(font); label.setBorder(new EmptyBorder(18, 12, 12, 12)); titlePanel.add(label, BorderLayout.WEST); return titlePanel; } public CreateAvdAction(@NotNull AvdInfoProvider avdInfoProvider) { super(avdInfoProvider, "Create Virtual Device...", "Create a new Android Virtual Device", AllIcons.General.Add); } @Singleton public class ForwardedIndexChangeHandler extends ForwardedIndexingHandler<String> { private final ChangeIndexer indexer; private final SchemaFactory<ReviewDb> schemaFactory; private final ChangeFinder changeFinder; @Inject ForwardedIndexChangeHandler(ChangeIndexer indexer, SchemaFactory<ReviewDb> schemaFactory, ChangeFinder changeFinder) { this.indexer = indexer; this.schemaFactory = schemaFactory; this.changeFinder = changeFinder; } @Override protected void doIndex(String id, Optional<?> body) throws IOException, OrmException { ChangeNotes change = null; try (ReviewDb db = schemaFactory.open()) { change = changeFinder.findOne(id); if (change != null) { indexer.index(db, change.getChange()); log.debug("Change {} successfully indexed", id); } } catch (Exception e) { if (!isCausedByNoSuchChangeException(e)) { throw e; } log.debug("Change {} was deleted, aborting forwarded indexing the change.", id); } if (change == null) { // Handle the case when change is null } } public Account.Id getAccountId() { return accountId; } ExternalId.Key getExternalId() { return externalId; } String getSessionId() { return sessionId; } String getAuth() { return auth; } boolean needsCookieRefresh() { return refreshCookieAt <= nowMs(); } boolean isPersistentCookie() { return persistentCookie; } private void
private transient String auth; Val( Account.Id accountId, long refreshCookieAt, boolean persistentCookie, ExternalId.Key externalId, long expiresAt, String sessionId, String auth) { this.accountId = accountId; this.refreshCookieAt = refreshCookieAt; this.persistentCookie = persistentCookie; this.externalId = externalId; this.expiresAt = expiresAt; this.sessionId = sessionId; this.auth = auth; } public long getExpiresAt() { return expiresAt; } public Account.Id getAccountId() { return accountId; } ExternalId.Key getExternalId() { return externalId; } String getSessionId() { return sessionId; } String getAuth() { return auth; } boolean needsCookieRefresh() { return refreshCookieAt <= nowMs(); } boolean isPersistentCookie() { return persistentCookie; } private void writeObject(ObjectOutputStream out) throws IOException { writeVarInt32(out, 1); writeVarInt32(out, accountId.get()); }
// See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.server.git.validators.RefOperationValidationListener; import com.google.inject.AbstractModule; import com.google.inject.name.Names; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.SharedRefDatabase; public class ValidationModule extends AbstractModule { private Configuration cfg; public ValidationModule(Configuration cfg) { this.cfg = cfg; } @Override protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class); bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getSplitBrain().getZookeeper().buildCurator()); bind(RetryPolicy.class).annotatedWith(Names.named("ZkLockRetryPolicy")); } }
ZookeeperTestContainerSupport zookeeperContainer; ZkSharedRefDatabase zkSharedRefDatabase; @Before public void setup() { zookeeperContainer = new ZookeeperTestContainerSupport(); zkSharedRefDatabase = new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); } @After public void cleanup() { zookeeperContainer.cleanup(); } @Test public void shouldCompareAndCreateSuccessfully() throws Exception { Ref ref = refOf(AN_OBJECT_ID_1); zookeeperContainer.createRefInZk(A_TEST_PROJECT_NAME, ref); assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue(); assertThat(zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref)) .isEqualTo(ref.getObjectId()); } @Test public void shouldCompareAndPutSuccessfully() throws Exception { Ref oldRef = refOf(AN_OBJECT_ID_1); Ref newRef = refOf(AN_OBJECT_ID_2); String projectName = A_TEST_PROJECT_NAME; zookeeperContainer.createRefInZk(projectName, oldRef); zkSharedRefDatabase.compareAndPut(projectName, oldRef, newRef); assertThat(zookeeperContainer.readRefValueFromZk(projectName, newRef)) .isEqualTo(newRef.getObjectId()); }
private static void assertInvalidQuery(String query, String expectedMessage) { try { CheckerQuery.clean(query); assert_().fail("expected BadRequestException"); } catch (BadRequestException e) { assertThat(e).hasMessageThat().isEqualTo(expectedMessage); } }
private void hasType(int expectedType) { isNotNull(); int actualType = actual().getType(); check("type()") .that(actualType) .named("expected %s, actual %s", typeName(expectedType), typeName(actualType)) .isEqualTo(expectedType); }
for (GitReferenceUpdatedListener.Update u : event.getUpdates()) { if (u.getRefName().startsWith("refs/changes/")) { cache.invalidate(new Project.NameKey(event.getProjectName())); break; } } static class Loader extends CacheLoader<Project.NameKey, List<Change>> { private final SchemaFactory<ReviewDb> schema; @Inject Loader(SchemaFactory<ReviewDb> schema) { this.schema = schema; } @Override public List<Change> load(Project.NameKey key) throws Exception { final ReviewDb db = schema.open(); try { return Collections.unmodifiableList(db.changes().byProject(key).toList()); } finally { db.close(); } } } }
private void reflowAsync() { Display.getDefault().asyncExec(new Runnable() { @Override public void run() { getParentSection().getTaskEditorPage().reflow(); } }); } public void handleEvent(Event event) { if (columnDataList.get(event.index).getPercentageProvider() != null) { TmfStatisticsTreeNode node = (TmfStatisticsTreeNode) event.item.getData(); if (TmfBaseColumnDataProvider.HIDDEN_FOLDER_LEVELS.contains(node.getName())) { return; } double percentage = columnDataList.get(event.index).getPercentageProvider().getPercentage(node); if ((event.detail & SWT.SELECTED) > 0) { event.gc.fillRectangle(event.x, event.y, event.width, event.height); event.detail &= ~SWT.SELECTED; } // Drawing the percentage text // if events are present in top node // and the current node is not the top node // and if is total or partial events column. // If not, exit the method. } } if (checkerUuid == null) { throw new BadRequestException("checker UUID is required"); } Checker checker = checkers.getChecker(checkerUuid) .orElseThrow(() -> new UnprocessableEntityException(String.format("checker %s not found", checkerUuid))); if (checker.getStatus() == CheckerStatus.DISABLED) { return ImmutableList.of(); } // The query system can only match against the current patch set; ignore non-current patch sets // for now. List<ChangeData> changes = checker.queryMatchingChanges(retryHelper, queryBuilderProvider.get(), changeQueryProvider); List<PendingChecksInfo> pendingChecks = new ArrayList<>(changes.size()); for (ChangeData cd : changes) { getPostFilteredPendingChecks(cd.project(), cd.currentPatchSet().getId()) .ifPresent(pendingChecks::add); } return pendingChecks; private Optional<PendingChecksInfo> getPostFilteredPendingChecks(Project.NameKey project, PatchSet.Id patchSetId) throws OrmException, IOException { CheckState checkState = getCheckState(project, patchSetId); // ... implementation details ... }
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.plugins.checks.index; import static com.google.common.base.Preconditions.checkNotNull; import com.google.gerrit.index.query.QueryParseException; import com.google.gerrit.plugins.checks.Check; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gwtorm.server.OrmException; public class CheckStatePredicate extends CheckPredicate { public static CheckStatePredicate parse(String value) throws QueryParseException { return new CheckStatePredicate( CheckState.tryParse(value) .orElseThrow( () -> new QueryParseException(String.format("invalid check state: %s", value)))); } private final CheckState checkState; public CheckStatePredicate(CheckState checkState) { super(CheckQueryBuilder.FIELD_STATE, checkState.name()); this.checkState = checkNotNull(checkState, "checkState"); } @Override public boolean match(Check check) throws OrmException { return checkState.equals(check.state()); } }
public CheckerPredicate(CheckerUuid checkerUuid) { super(CheckQueryBuilder.FIELD_CHECKER, Objects.requireNonNull(checkerUuid, "checkerUuid must not be null").toString()); this.checkerUuid = checkerUuid; }
boolean isRest(ServletRequest req) { return req instanceof HttpServletRequest && resturi.matcher(((HttpServletRequest) req).getServletPath()).matches(); }
public void containsMessages(String... expectedLines) { checkArgument(expectedLines.length > 0, "use hasNoMessages()"); isNotNull(); Iterable<String> got = Splitter.on("\n").split(trimMessages()); check("trimmedMessages()").that(got).containsAllIn(expectedLines).inOrder(); }
@Test public void insertCheckerTwice() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); CheckerUuid checkerUuid = CheckerUuid.parse("foo:bar"); Project.NameKey project = new Project.NameKey("some-project"); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid); } @Test public void removeCheckers() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project = new Project.NameKey("some-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("bar:baz"); CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:bar"); CheckerUuid checkerUuid3 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project); checkersByRepositoryNotes.insert(checkerUuid2, project); checkersByRepositoryNotes.insert(checkerUuid3, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project)); }
CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project1); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1)).containsExactly(checkerUuid1); assertThat(checkersByRepositoryNotes.get(project2)).isEmpty(); checkersByRepositoryNotes.remove(checkerUuid2, project1); checkersByRepositoryNotes.remove(checkerUuid1, project2); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1)).containsExactly(checkerUuid1); assertThat(checkersByRepositoryNotes.get(project2)).isEmpty(); @Test public void updateCheckers() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project1 = new Project.NameKey("some-project"); Project.NameKey project2 = new Project.NameKey("other-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("foo:bar"); CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project1); checkersByRepositoryNotes.insert(checkerUuid2, project1); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1)).containsExactly(checkerUuid1); assertThat(checkersByRepositoryNotes.get(project2)).isEmpty(); }
Fixed Code: ```java CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); CheckerUuid checkerUuid = CheckerUuid.parse("foo:bar"); Project.NameKey project = new Project.NameKey("some-project"); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThatCommitMessage() .isEqualTo("Update checkers by repository\n\nChecker: " + checkerUuid.toString() + "\nRepository: " + project.get()); @Test public void noNewCommitOnNoOp() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project = new Project.NameKey("some-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("foo:bar"); checkersByRepositoryNotes.insert(checkerUuid1, project); commit(checkersByRepositoryNotes); ObjectId commitId = getRefsMetaCheckersState(); checkersByRepositoryNotes.insert(checkerUuid1, project); commit(checkersByRepositoryNotes); assertThat(getRefsMetaCheckersState()).isEqualTo(commitId); checkersByRepositoryNotes.update(checkerUuid1, project, project); commit(checkersByRepositoryNotes); assertThat(getRefsMetaCheckersState()).isEqualTo(commitId); } ```
List<SQLEntry> entries = new ArrayList<>(); for (Entry<String, Collection<SQLEntry>> entry : eventsDb.getEvents(query).asMap().entrySet()) { String projectName = entry.getKey(); try { permissionBackend .currentUser() .project(new Project.NameKey(projectName)) .check(ProjectPermission.ACCESS); entries.addAll(entry.getValue()); } catch (AuthException e) { // Ignore } catch (PermissionBackendException e) { log.atFine().withCause(e).log("Cannot check project access permission"); } } return entries.stream().sorted().map(SQLEntry::getEvent).collect(toList()); @Override public void storeEvent(ProjectEvent event) { Project.NameKey projectName = event.getProjectNameKey(); // Rest of the method implementation }
private final ListMultimap<GitilesView.Type, Filter> filters = LinkedListMultimap.create(); private final Map<GitilesView.Type, HttpServlet> servlets = Maps.newHashMap(); private final Config config; private final Renderer renderer; private final GitilesUrls urls; private final Linkifier linkifier; private final GitilesAccess.Factory accessFactory; private final RepositoryResolver<HttpServletRequest> resolver; private final VisibilityCache visibilityCache; private final TimeCache timeCache; private final BlameCache blameCache; private final GitwebRedirectFilter gitwebRedirect; private final Filter errorHandler; private boolean initialized; GitilesFilter() {} GitilesFilter(Config config, Renderer renderer, GitilesUrls urls, GitilesAccess.Factory accessFactory, RepositoryResolver<HttpServletRequest> resolver, VisibilityCache visibilityCache, TimeCache timeCache, BlameCache blameCache, GitwebRedirectFilter gitwebRedirect, Filter errorHandler) { this.config = checkNotNull(config, "config"); this.renderer = renderer; this.urls = urls; this.accessFactory = accessFactory; this.resolver = resolver; this.visibilityCache = visibilityCache; this.timeCache = timeCache; this.blameCache = blameCache; this.gitwebRedirect = gitwebRedirect; this.errorHandler = errorHandler; }
package com.google.gitiles; import javax.annotation.Nullable; import javax.servlet.http.HttpServletResponse; public class RequestFailureException extends RuntimeException { private final FailureReason reason; private String publicErrorMessage = null; public RequestFailureException(FailureReason reason) { super(); this.reason = reason; } public RequestFailureException(FailureReason reason, Throwable cause) { super(cause); this.reason = reason; } public RequestFailureException withPublicErrorMessage(String format, Object... params) { this.publicErrorMessage = String.format(format, params); return this; } public FailureReason getReason() { return reason; } @Nullable public String getPublicErrorMessage() { return publicErrorMessage; } public enum FailureReason { AMBIGUOUS_OBJECT(HttpServletResponse.SC_BAD_REQUEST), BLAME_REGION_NOT_FOUND(HttpServletResponse.SC_NOT_FOUND), CANNOT_PARSE_GITILES_VIEW(HttpServletResponse.SC_NOT_FOUND), INCORECT_PARAMETER(HttpServletResponse.SC_BAD_REQUEST), INCORRECT_OBJECT_TYPE(HttpServletResponse.SC_NOT_FOUND), // Add more failure reasons here } }
public MultiSiteGitRepositoryManager(MultiSiteRepository.Factory multiSiteRepoFactory, GitRepositoryManager gitRepositoryManager) { this.gitRepositoryManager = gitRepositoryManager; this.multiSiteRepoFactory = multiSiteRepoFactory; }
protected void configure() { factory(MultiSiteRepository.Factory.class); factory(MultiSiteRefDatabase.Factory.class); factory(MultiSiteRefUpdate.Factory.class); bind(GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); install(new ZkValidationModule(cfg)); }
protected void configure() { factory(MultiSiteRepository.Factory.class); factory(MultiSiteRefDatabase.Factory.class); factory(MultiSiteRefUpdate.Factory.class); DynamicSet.bind(binder(), GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); DynamicSet.bind(binder(), SharedRefDatabase.class).to(ZkSharedRefDatabase.class); install(new ZkValidationModule(cfg)); }
import com.google.gerrit.reviewdb.client.Project.SubmitType; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.config.AllProjectsName; import com.google.gerrit.server.project.PerformCreateProject; import com.google.gerrit.server.project.CreateProject.Input; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.assistedinject.Assisted; import java.util.Collections; @RequiresCapability(GlobalCapability.CREATE_PROJECT) class CreateProject implements RestModifyView<TopLevelResource, Input> { static class Input { String name; String parent; boolean permissionsOnly; boolean createEmptyCommit; } static class ProjectInfo { final String kind = "gerritcodereview#project"; String id; Input createdWith; void finish(Input input, final AllProjectsName allProjectName) { createdWith = input; id = Url.encode(createdWith.name); if (Strings.isNullOrEmpty(createdWith.parent)) { createdWith.parent = allProjectName.get(); } } } static interface Factory { CreateProject create(String name); } private final PerformCreateProject.Factory createProjectFactory; }
public MultiSiteRepository(MultiSiteRefDatabase.Factory multiSiteRefDbFactory, @Assisted String projectName, @Assisted Repository repository, @Assisted BaseRepositoryBuilder repositoryBuilder) { super(repositoryBuilder); this.multiSiteRefDbFactory = multiSiteRefDbFactory; this.projectName = projectName; this.repository = repository; }
public RefDatabase getRefDatabase() { return multiSiteRefDbFactory.create(projectName, repository.getRefDatabase()); }
import com.googlecode.prolog_cafe.lang.SymbolTerm; import java.io.File; import java.io.IOException; import java.util.ArrayList; import java.util.List; import org.kohsuke.args4j.Option; public class PrologShell extends AbstractProgram { @Option(name = "-s", metaVar = "FILE.pl", usage = "file to load") private List<String> fileName = new ArrayList<>(); @Option(name = "-q", usage = "quiet mode without banner") private boolean quiet; @Override public int run() { if (!quiet) { banner(); } BufferingPrologControl pcl = new BufferingPrologControl(); pcl.setPrologClassLoader(new PrologClassLoader(getClass().getClassLoader())); pcl.setEnabled(Prolog.Feature.IO, true); pcl.setEnabled(Prolog.Feature.STATISTICS, true); pcl.configureUserIO(System.in, System.out, System.err); pcl.initialize(Prolog.BUILTIN); for (String file : fileName) { String path; try { path = new File(file).getCanonicalPath(); } catch (IOException e) { // Handle exception } pcl.load(path); } pcl.run(); return 0; } private void banner() { // Display banner } }
public void replaceChangeMessage(ChangeUpdate update, String targetMessageId, String newMessage) { update.deleteChangeMessageByRewritingHistory(targetMessageId, newMessage); } public static boolean isAutogenerated(@Nullable String tag) { return tag != null && tag.startsWith(AUTOGENERATED_TAG_PREFIX); } public static ChangeMessageInfo createChangeMessageInfo(ChangeMessage message, AccountLoader accountLoader) { PatchSet.Id patchNum = message.getPatchSetId(); }
@Singleton public class MultiSiteGitRepositoryManager implements GitRepositoryManager { private final GitRepositoryManager gitRepositoryManager; @Inject MultiSiteRepository.Factory multiSiteRepoFactory; @Inject public MultiSiteGitRepositoryManager(LocalDiskRepositoryManager localDiskRepositoryManager) { this.gitRepositoryManager = localDiskRepositoryManager; } public MultiSiteGitRepositoryManager(GitRepositoryManager gitRepositoryManager) { this.gitRepositoryManager = gitRepositoryManager; } @Override public Repository openRepository(NameKey name) throws RepositoryNotFoundException, IOException { Repository openRepository = gitRepositoryManager.openRepository(name); return multiSiteRepoFactory.create(name.get(), openRepository); } @Override public Repository createRepository(NameKey name) throws RepositoryCaseMismatchException, RepositoryNotFoundException, IOException { Repository createdRepository = gitRepositoryManager.createRepository(name); return multiSiteRepoFactory.create(name.get(), createdRepository); } @Override public SortedSet<NameKey> list() { return gitRepositoryManager.list(); } }
@Inject public JGitHealthCheck(ListeningExecutorService executor, HealthCheckConfig config, GitRepositoryManager repositoryManager) { super(executor, config, JGIT); this.repositoryManager = repositoryManager; this.repositoryNameKeys = config.getJGITRepositories(JGIT); } @Override protected Result doCheck() throws Exception { for (Project.NameKey repoNameKey : repositoryNameKeys) { try (Repository repo = repositoryManager.openRepository(repoNameKey)) { repo.open(repo.resolve("refs/meta/config")).getType(); } } return Result.PASSED; } public List<String> getMenuIdNames() { if (myMenus != null) { return myMenus; } boolean token = RenderSecurityManager.enterSafeRegion(myCredential); try { final XmlFile xmlFile = myRenderTask.getPsiFile(); String commaSeparatedMenus = xmlFile == null ? null : AndroidPsiUtils.getRootTagAttributeSafely(xmlFile, ATTR_MENU, TOOLS_URI); if (commaSeparatedMenus != null) { myMenus = new ArrayList<String>(); Iterables.addAll(myMenus, Splitter.on(',').trimResults().omitEmptyStrings().split(commaSeparatedMenus)); } else { final String fqn = xmlFile == null ? null : AndroidPsiUtils.getDeclaredContextFqcn(myRenderTask.getModule(), xmlFile); if (fqn != null) { final Project project = xmlFile.getProject(); DumbService.getInstance(project).smartInvokeLater(new Runnable() { @Override public void run() { // Glance at the onCreateOptionsMenu of the associated context and use any menus found there. } }); } } } finally { RenderSecurityManager.exitSafeRegion(token); } return myMenus; } public int getNavigationMode() { XmlFile xmlFile = myRenderTask.getPsiFile(); String navMode = StringUtil.notNullize(xmlFile == null ? null : AndroidPsiUtils.getRootTagAttributeSafely(xmlFile, ATTR_NAV_MODE, TOOLS_URI)).trim(); if (navMode.equalsIgnoreCase(VALUE_NAV_MODE_TABS)) { return NAVIGATION_MODE_TABS; } if (navMode.equalsIgnoreCase(VALUE_NAV_MODE_LIST)) { return NAVIGATION_MODE_LIST; } return NAVIGATION_MODE_STANDARD; } this.gitRepositoryManager = localDiskRepositoryManager; public MultiSiteGitRepositoryManager
import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Configuration { private static final Logger log = LoggerFactory.getLogger(Configuration.class); public static final String PLUGIN_NAME = "multi-site"; static final String INSTANCE_ID_FILE = "instanceId.data"; static final String THREAD_POOL_SIZE_KEY = "threadPoolSize"; static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; static final int DEFAULT_THREAD_POOL_SIZE = 4; static final String NUM_STRIPED_LOCKS = "numStripedLocks"; static final int DEFAULT_NUM_STRIPED_LOCKS = 10; }
import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate; private final RefDatabase refDb; private final SharedRefDatabase sharedRefDb; private final List<ReceiveCommand> receiveCommands; private final String projectName; public static class RefPair { final Ref oldRef; final Ref newRef; final Exception exception; RefPair(Ref oldRef, Ref newRef) { this.oldRef = oldRef; this.newRef = newRef; this.exception = null; } RefPair(Ref newRef, Exception e) { this.newRef = newRef; this.oldRef = SharedRefDatabase.NULL_REF; this.exception = e; } public boolean hasFailed() { return exception != null; } } }
private final Index index; private final KafkaSubscriber subscriber; private final Kafka kafka; private final ZookeeperConfig zookeeperConfig; @Inject Configuration(SitePaths sitePaths) { this(new FileBasedConfig(sitePaths.etc_dir.resolve(PLUGIN_NAME + ".config").toFile(), FS.DETECTED)); load(); }
protected void configure() { bind(ReplicationQueue.class).in(Scopes.SINGLETON); bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(ReplicationQueue.class); DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), HeadUpdatedListener.class).to(ReplicationQueue.class); bind(OnStartStop.class).in(Scopes.SINGLETON); bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(OnStartStop.class); bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(ReplicationLogFile.class); bind(CredentialsFactory.class) .to(AutoReloadSecureCredentialsFactoryDecorator.class) .in(Scopes.SINGLETON); bind(CapabilityDefinition.class) .annotatedWith(Exports.named(START_REPLICATION)) .to(StartReplicationCapability.class); install(new FactoryModuleBuilder().build(PushAll.Factory.class)); install(new FactoryModuleBuilder().build(ReplicationState.Factory.class)); bind(ReplicationConfig.class).to(AutoReloadConfigDecorator.class); DynamicSet.setOf(binder(), ReplicationStateListener.class); }
try { rateLimiterHolder = limitsPerAccount.get(accountId); } catch (ExecutionException e) { rateLimiterHolder = Holder.EMPTY; log.warn("Cannot get rate limits for account ''{}''", accountId, e); } } else { try { rateLimiterHolder = limitsPerRemoteHost.get(req.getRemoteHost()); } catch (ExecutionException e) { rateLimiterHolder = Holder.EMPTY; log.warn("Cannot get rate limits for anonymous access from remote host ''%s''", req.getRemoteHost(), e); } } if (!rateLimiterHolder.hasGracePermits() && rateLimiterHolder.get() != null && !rateLimiterHolder.get().tryAcquire()) { String msg = MessageFormat.format(limitExceededMsg, rateLimiterHolder.get().getRate() * SECONDS_PER_HOUR, rateLimiterHolder.getBurstPermits()); ((HttpServletResponse) res).sendError(SC_TOO_MANY_REQUESTS, msg); return; } } chain.doFilter(req, res); } boolean isRest(ServletRequest req) {
public void run() { try { dispatcher.get().postEvent(new HeartbeatEvent()); } catch (OrmException e) { logger.error("Failed to post heartbeat event: {}", e.getMessage(), e); } }
if (itemTs.isPresent()) { count++; newLastIndexTs = maxTimestamp(newLastIndexTs, itemTs.get()); } catch (Exception e) { log.atSevere().withCause(e).log("Unable to reindex %s %s", itemNameString, c); errors++; } long elapsedNanos = stopwatch.stop().elapsed(TimeUnit.NANOSECONDS); if (count > 0) { log.atInfo().log("%s %ss reindexed in %d msec (%d/sec), %d failed", count, itemNameString, elapsedNanos / 1000000L, (count * 1000L) / (elapsedNanos / 1000000L), errors); } else if (errors > 0) { log.atInfo().log("%d %ss failed to reindex", errors, itemNameString); } else { log.atFine().log("Scanning finished"); } indexTs.update(itemName, newLastIndexTs.toLocalDateTime()); } catch (Exception e) { log.atSevere().withCause(e).log("Unable to scan %ss", itemNameString); }
try { ChangeChecker checker = changeCheckerFactory.create(id); Optional<ChangeNotes> changeNotes = checker.getChangeNotes(); if (changeNotes.isPresent()) { ChangeNotes notes = changeNotes.get(); reindex(notes); if (checker.isChangeUpToDate(indexEvent)) { if (retryCount > 0) { log.atWarning().log("Change %s has been eventually indexed after %d attempt(s)", id, retryCount); } else { log.atFine().log("Change {} successfully indexed", id); } } else { log.atWarning().log("Change %s seems too old compared to the event timestamp (event-Ts=%s >> change-Ts=%s)", id, indexEvent, checker); rescheduleIndex(id, indexEvent, retryCount + 1); } } else { indexer.delete(parseChangeId(id)); log.atWarning().log("Change %s could not be found in the local Git repository (eventTs=%s), deleted from index", id, indexEvent); } } catch (Exception e) { // Handle exception }
setHeaders(rsp); try { List<String> params = Splitter.on('/').splitToList(req.getPathInfo()); String cacheName = params.get(CACHENAME_INDEX); String json = req.getReader().readLine(); forwardedCacheEvictionHandler.evict(CacheEntry.from(cacheName, GsonParser.fromJson(cacheName, json))); rsp.setStatus(SC_NO_CONTENT); } catch (CacheNotFoundException e) { log.atSevere().log("Failed to process eviction request: {}", e.getMessage()); sendError(rsp, SC_BAD_REQUEST, e.getMessage()); } catch (IOException e) { log.atSevere().withCause(e).log("Failed to process eviction request"); sendError(rsp, SC_BAD_REQUEST, e.getMessage()); }
for (; ; ) { try { execCnt++; tryOnce(); log.atFine().log("%s %s towards %s OK", action, key, destination); return true; } catch (ForwardingException e) { int maxTries = cfg.http().maxTries(); log.atFine().withCause(e).log("Failed to %s %s on %s [%d/%s]", action, key, destination, execCnt, maxTries); if (!e.isRecoverable()) { log.atSevere().withCause(e).log("%s %s towards %s failed with unrecoverable error; giving up", action, key, destination); return false; } if (execCnt >= maxTries) { log.atSevere().log("Failed to %s %s on %s after %d tries; giving up", action, key, destination, maxTries); return false; } log.atFine().log("Retrying to %s %s on %s", action, key, destination); try { Thread.sleep(cfg.http().retryInterval()); } catch (InterruptedException ie) { log.atFine().withCause(ie).log("Interrupted while sleeping"); return false; } } }
try { action, key, destination); return false; } if (execCnt >= maxTries) { log.atSevere().log( "Failed to %s %s on %s after %d tries; giving up", action, key, destination, maxTries); return false; } log.atFine().log("Retrying to %s %s on %s", action, key, destination); try { Thread.sleep(cfg.http().retryInterval()); } catch (InterruptedException ie) { log.atSevere().withCause(e).log( "%s %s towards %s was interrupted; giving up", action, key, destination); Thread.currentThread().interrupt(); return false; }
public void viewAccepted(View view) { log.atInfo().log("viewAccepted(view: %s) called", view); synchronized (this) { if (view.getMembers().size() > 2) { log.atWarning().log("%d members joined the jgroups cluster %s (%s). Only two members are supported. Members: {}", view.getMembers().size(), jgroupsConfig.clusterName(), channel.getName(), view.getMembers()); } if (peerAddress != null && !view.getMembers().contains(peerAddress)) { log.atInfo().log("viewAccepted(): removed peerInfo"); peerAddress = null; peerInfo = Optional.empty(); } } if (view.size() > 1) { try { channel.send(new Message(null, myUrl)); } catch (Exception e) { log.atSevere().withCause(e).log("Sending a message over channel %s to cluster %s failed", channel.getName(), jgroupsConfig.clusterName()); } } }
public void connect() { try { channel = getChannel(); Optional<InetAddress> address = finder.findAddress(); if (address.isPresent()) { log.atFine().log("Protocol stack: %s", channel.getProtocolStack()); channel.getProtocolStack().getTransport().setBindAddress(address.get()); log.atFine().log("Channel bound to {}", address.get()); } else { log.atWarning().log("Channel not bound: address not present"); } channel.setReceiver(this); channel.setDiscardOwnMessages(true); channel.connect(jgroupsConfig.clusterName()); log.atInfo().log( "Channel %s successfully joined jgroups cluster %s", channel.getName(), jgroupsConfig.clusterName() ); } catch (Exception e) { if (channel != null) { log.atSevere().withCause(e).log( "joining cluster %s (channel %s) failed", jgroupsConfig.clusterName(), channel.getName() ); } else { log.atSevere().withCause(e).log( "joining cluster %s failed", jgroupsConfig.clusterName() ); } } }
import com.google.gerrit.extensions.annotations.Listen; import com.google.gerrit.server.events.CommitReceivedEvent; import com.google.gerrit.server.git.validators.CommitValidationException; import com.google.gerrit.server.git.validators.CommitValidationListener; import com.google.gerrit.server.git.validators.CommitValidationMessage; import com.google.inject.Singleton; @Listen @Singleton public class CommitMessageLengthValidation implements CommitValidationListener { @Override public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException { final RevCommit commit = receiveEvent.commit; final AbbreviatedObjectId id = commit.abbreviate(7); List<CommitValidationMessage> messages = new ArrayList<CommitValidationMessage>(); if (65 < commit.getShortMessage().length()) { messages.add(new CommitValidationMessage("(W) " + id.name() + ": commit subject >65 characters; use shorter first paragraph", false)); } int longLineCnt = 0, nonEmptyCnt = 0; for (String line : commit.getFullMessage().split("\n")) { if (!line.trim().isEmpty()) { nonEmptyCnt++; } } return messages; } } // Install breakpoint on the expected line logWriter.println("Install breakpoint in " + BreakpointOnCatchDebuggee.BREAKPOINT_METHOD_NAME); int requestID = installBreakpointOnCatch(classID, methodID); // execute the breakpoint synchronizer.sendMessage(JPDADebuggeeSynchronizer.SGNL_CONTINUE); CommandPacket event = debuggeeWrapper.vmMirror.receiveCertainEvent(JDWPConstants.EventKind.BREAKPOINT); ParsedEvent[] parsedEvents = ParsedEvent.parseEventPacket(event); assertEquals("Invalid number of events:", 1, parsedEvents.length); assertEquals("Invalid request ID:", requestID, parsedEvents[0].getRequestID()); long eventThreadID = ((EventThread) parsedEvents[0]).getThreadID(); checkThreadState(eventThreadID, JDWPConstants.ThreadStatus.RUNNING, JDWPConstants.SuspendStatus.SUSPEND_STATUS_SUSPENDED); logWriter.println("Successfully suspended on a catch statement"); logWriter.println("testBreakpointOnCatch done"); } // ACCEPT cases: 1. Notify, no verify; 2. no notify, no verify; // 3. privacy override. if (!notif.needVerify || notif.privacyOverride) {
import javax.servlet.http.HttpServletResponse; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class RestApiRateLimiter extends AllRequestFilter { private static final Logger log = LoggerFactory.getLogger(RestApiRateLimiter.class); private static final int SECONDS_PER_HOUR = 3600; static final int SC_TOO_MANY_REQUESTS = 429; private final Provider<CurrentUser> user; private final LoadingCache<Account.Id, Holder> limitsPerAccount; private final LoadingCache<String, Holder> limitsPerRemoteHost; private final Pattern servletPath = Pattern.compile("^/(?:a/)?" + "(access|accounts|changes|config|groups|plugins|projects|Documentation|tools)/(.*)$"); private final String limitExceededMsg; @Inject RestApiRateLimiter(Provider<CurrentUser> user, @Named(HttpModule.CACHE_NAME_RESTAPI_ACCOUNTID) LoadingCache<Account.Id, Holder> limitsPerAccount, @Named(HttpModule.CACHE_NAME_RESTAPI_REMOTEHOST) LoadingCache<String, Holder> limitsPerRemoteHost, @Named(RateMsgHelper.RESTAPI_CONFIGURABLE_MSG_ANNOTATION) String limitExceededMsg) { this.user = user; this.limitsPerAccount = limitsPerAccount; this.limitsPerRemoteHost = limitsPerRemoteHost; this.limitExceededMsg = limitExceededMsg; } }
public class ExampleClass { private Self self; private PermissionBackend permissionBackend; private RestView<TopLevelResource> listCheckers; private Checkers checkers; private DynamicMap<RestView<CheckerResource>> views; private AdministrateCheckersPermission permission; public ExampleClass(Self self, PermissionBackend permissionBackend, RestView<TopLevelResource> listCheckers, Checkers checkers, DynamicMap<RestView<CheckerResource>> views, AdministrateCheckersPermission permission) { this.self = self; this.permissionBackend = permissionBackend; this.listCheckers = listCheckers; this.checkers = checkers; this.views = views; this.permission = permission; } @Override public RestView<TopLevelResource> list() throws RestApiException { return listCheckers; } @Override public CheckerResource parse(TopLevelResource parent, IdString id) throws AuthException, ResourceNotFoundException, PermissionBackendException, IOException, ConfigInvalidException { if (!self.get().isIdentifiedUser()) { throw new AuthException("Authentication required"); } permissionBackend.currentUser().check(permission); Checker checker = checkers.getChecker(id.get()).orElseThrow(() -> new ResourceNotFoundException(id)); return new CheckerResource(checker); } @Override public DynamicMap<RestView<CheckerResource>> views() { return views; } }
import com.google.common.collect.ImmutableList; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectIdRef; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.Storage; import java.util.List; public interface RefUtils { Ref newRef(String refName, ObjectId objectId); default Ref newRef(String refName, ObjectId objectId, Storage storage) { return new ObjectIdRef.Unpeeled(storage, refName, objectId); } default Ref newRef(String refName, ObjectId objectId, ObjectId peeledObjectId, Storage storage) { return new ObjectIdRef.PeeledNonTag(storage, refName, objectId, peeledObjectId); } default Ref newRef(String refName, ObjectId objectId, ObjectId peeledObjectId) { return newRef(refName, objectId, peeledObjectId, Storage.LOOSE); } default Ref newRef(String refName, ObjectId objectId, Storage storage, boolean isPeeled) { if (isPeeled) { return newRef(refName, objectId, storage); } else { return new ObjectIdRef.Unpeeled(storage, refName, objectId); } } default Ref newRef(String refName, ObjectId objectId, ObjectId peeledObjectId, Storage storage, boolean isPeeled) { if (isPeeled) { return newRef(refName, objectId, peeledObjectId, storage); } else { return newRef(refName, objectId, storage); } } default List<String> getRefsToIgnoreInSharedDb() { return ImmutableList.of("refs/draft-comments/.*", "refs/changes/[0-9]+/[0-9]+/[0-9]+"); } default Ref newRef(String project, String newRef) { return newRef(project, newRef, Storage.LOOSE); } }
Refactor: ```java boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); return refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } ```
@Inject public ZkSharedRefDatabase(CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { if (newRef != NULL_REF && ignoreRefInSharedDb(newRef)) { return true; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } catch (Exception e) { throw new IOException(e); } }
static final ObjectId AN_OBJECT_ID_2 = new ObjectId(1, 2, 3, 4, 6); static final ObjectId AN_OBJECT_ID_3 = new ObjectId(1, 2, 3, 4, 7); static final String A_TEST_REF_NAME = "refs/heads/master"; default String aBranchRef() { return RefNames.REFS_HEADS + testBranch(); } default Ref newRef(String refName, ObjectId objectId) { return new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, refName, objectId); } String testBranch();
boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); }
CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } catch (Exception e) { logger.atWarning().withCause(e).log("Failed to compare and put reference"); return false; } }
new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); @After public void cleanup() { zookeeperContainer.cleanup(); } @Test public void shouldCompareAndCreateSuccessfully() throws Exception { Ref ref = refOf(AN_OBJECT_ID_1); assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue(); String data = zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref).getName(); assertThat(data).isEqualTo(ref.getObjectId().getName()); } @Test public void shouldCompareAndPutSuccessfully() throws Exception { Ref oldRef = refOf(AN_OBJECT_ID_1); Ref newRef = refOf(AN_OBJECT_ID_2); String projectName = A_TEST_PROJECT_NAME; zookeeperContainer.createRefInZk(projectName, oldRef); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, newRef)).isTrue(); } @Test public void shouldCompareAndPutWithNullOldRefSuccessfully() throws Exception { Ref oldRef = refOf(null); Ref newRef = refOf(AN_OBJECT_ID_2);
private final AtomicReference<Command> atomicCmd; private final DynamicSet<SshCommandPreExecutionFilter> commandFilters; @Argument(index = 0, required = false, metaVar = "COMMAND", handler = SubcommandHandler.class) private String commandName; @Argument(index = 1, multiValued = true, metaVar = "ARG") private List<String> args = new ArrayList<>(); @Inject DispatchCommand(PermissionBackend permissionBackend, @Assisted Map<String, CommandProvider> all, DynamicSet<SshCommandPreExecutionFilter> commandFilters) { this.permissionBackend = permissionBackend; commands = all; atomicCmd = Atomics.newReference(); this.commandFilters = commandFilters; } Map<String, CommandProvider> getMap() { return commands; } @Override public void start(Environment env) throws IOException { try { parseCommandLine(); if (Strings.isNullOrEmpty(commandName)) { StringWriter msg = new StringWriter(); msg.write(usage()); throw die(msg.toString()); } final CommandProvider p = commands.get(commandName); if (p == null) { String msg = "git-upload-pack: '" + commandName + "' is not a git command. See 'git --help'."; throw die(msg); } final Command cmd = p.get(); atomicCmd.set(cmd); cmd.setArguments(args); cmd.setInputStream(env.getInputStream()); cmd.setOutputStream(env.getOutputStream()); cmd.setErrorStream(env.getErrorStream()); cmd.setEnvironment(env); cmd.setRepository(repoManager.openRepository(env, getProjectName())); cmd.setPermissionBackend(permissionBackend); cmd.setCommandFilters(commandFilters); cmd.execute(); } catch (UnloggedFailure e) { throw die(e.getMessage(), e); } catch (Die e) { throw die(e.getMessage(), e); } catch (Exception e) { throw die("fatal: internal server error", e); } }
Optional<ExternalId> other = null; try { other = externalIds.get(key); } catch (IOException | ConfigInvalidException e) { throw new IllegalArgumentException("Internal error while fetching username='" + username + "'"); } try { accountsUpdateProvider.get().update("Set Username from GitHub", accountId, u -> u.addExternalId(ExternalId.create(key, accountId, null, null))); } catch (OrmDuplicateKeyException dupeErr) { if (!other.isPresent() || !other.get().accountId().equals(accountId)) { throw new IllegalArgumentException("username " + username + " already in use"); } } catch (Exception e) { throw new IllegalArgumentException("Internal error while trying to set username='" + username + "'"); } log.debug("Account {} updated with preferredEmail = {}, fullName = {}, username = {}", accountId, email, fullName, username);
import java.util.Collections; import java.util.List; import java.util.Objects; import java.util.Set; import java.util.function.Predicate; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.URIish; /** Collection of Git repositories destinations for replication. */ public class DestinationsCollection { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final ReplicationConfig replicationConfig; private final Destination.Factory destinationFactory; private final List<Destination> allDestinations; @Inject DestinationsCollection(ReplicationConfig replicationConfig, Destination.Factory destinationFactory) { this.replicationConfig = replicationConfig; this.destinationFactory = destinationFactory; this.allDestinations = Collections.emptyList(); } /** * Get all destinations matching the specified type. * * @param filterType type of destination. * @return list of destinations matching the specified filter type. */ public List<Destination> getAll(FilterType filterType) { if (replicationConfig.reloadIfNeeded()) { try { load(); } catch (ConfigInvalidException e) { // Handle exception } } return Collections.unmodifiableList(allDestinations); } }
import java.util.Objects; import java.util.Set; import java.util.function.Predicate; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.URIish; /** * Collection of Git repositories destinations for replication. */ public class DestinationsCollection { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final ReplicationConfig replicationConfig; private final Destination.Factory destinationFactory; private List<Destination> allDestinations = Collections.emptyList(); @Inject DestinationsCollection(ReplicationConfig replicationConfig, Destination.Factory destinationFactory) { this.replicationConfig = replicationConfig; this.destinationFactory = destinationFactory; } /** * Get all destinations matching the specified type. * * @param filterType type of destination. * @return list of destinations matching the specified filter type. */ public List<Destination> getAll(FilterType filterType) { if (replicationConfig.reloadIfNeeded()) { try { load(); } catch (ConfigInvalidException e) { logger.atSevere().withCause(e).log("Cannot load replication destinations"); } } return allDestinations.stream() .filter(filterType.getPredicate()) .collect(toImmutableList()); } /** * Load the destinations from the replication configuration. * * @throws ConfigInvalidException if the configuration is invalid. */ public void load() throws ConfigInvalidException { List<Destination> destinations = new ArrayList<>(); Config cfg = replicationConfig.getConfig(); Set<String> remoteNames = cfg.getSubsections(REMOTE_SECTION); for (String remoteName : remoteNames) { RemoteConfig remoteConfig = new RemoteConfig(cfg, remoteName); List<URIish> uris = remoteConfig.getURIs(); for (URIish uri : uris) { destinations.add(destinationFactory.create(remoteName, uri)); } } allDestinations = Collections.unmodifiableList(destinations); } }
CheckerUuid checkerUuid = createCheckerInServer(createArbitraryCheckerInput()); boolean exists = checkerOperations.checker(checkerUuid).exists(); assertThat(exists).isTrue(); @Test public void notExistingCheckerCanBeCheckedForExistence() throws Exception { String notExistingCheckerUuid = "test:not-existing-checker"; boolean exists = checkerOperations.checker(notExistingCheckerUuid).exists(); assertThat(exists).isFalse(); } @Test public void retrievingCheckerForInvalidUuidFails() throws Exception { exception.expect(IllegalArgumentException.class); checkerOperations.checker(CheckerTestData.INVALID_UUID).get(); } @Test public void retrievingNotExistingCheckerFails() throws Exception { String notExistingCheckerUuid = "foo:bar"; exception.expect(IllegalStateException.class); checkerOperations.checker(notExistingCheckerUuid).get(); } @Test public void checkerNotCreatedByTestApiCanBeRetrieved() throws Exception { CheckerInput input = createArbitraryCheckerInput(); input.uuid = "test:unique-checker-not-created-via-test-API"; CheckerUuid checkerUuid = createCheckerInServer(input); }
@Override public Check get() throws Exception { return checks .getCheck(key, GetCheckOptions.defaults()) .orElseThrow(() -> new IllegalStateException("Tried to get non-existing test check")); } @Override public ImmutableMap<RevId, String> notesAsText() throws Exception { try (Repository repo = repoManager.openRepository(key.repository()); RevWalk rw = new RevWalk(repo); ObjectReader reader = repo.newObjectReader()) { Ref checkRef = repo.getRefDatabase().exactRef(CheckerRef.checksRef(key.patchSet().changeId)); checkNotNull(checkRef); NoteMap notes = NoteMap.read(reader, rw.parseCommit(checkRef.getObjectId())); ImmutableMap.Builder<RevId, String> raw = ImmutableMap.builder(); for (Note note : notes) { raw.put(new RevId(note.name()), new String(notes.getCachedBytes(note.toObjectId(), Integer.MAX_VALUE))); } return raw.build(); } } @Override public CheckInfo asInfo(ListChecksOption... options) throws Exception { // Implementation }
Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/heads/stable-2.16", AN_OBJECT_ID_1); assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse(); @Test public void compareAndPutShouldAlwaysIngoreIgnoredRefs() throws Exception { Ref existingRef = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_1); Ref oldRefToIgnore = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_2); Ref newRef = SharedRefDatabase.NULL_REF; String projectName = A_TEST_PROJECT_NAME; assertThat(zkSharedRefDatabase.compareAndPut(A_TEST_PROJECT_NAME, existingRef, SharedRefDatabase.NULL_REF)).isTrue(); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRefToIgnore, newRef)).isTrue(); } @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); }
@Test public void compareAndPutShouldAlwaysIngoreIgnoredRefs() throws Exception { Ref existingRef = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_1); Ref oldRefToIgnore = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_2); Ref newRef = SharedRefDatabase.NULL_REF; String projectName = A_TEST_PROJECT_NAME; assertThat(zkSharedRefDatabase.compareAndPut(A_TEST_PROJECT_NAME, existingRef, SharedRefDatabase.NULL_REF)) .isTrue(); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRefToIgnore, newRef)) .isTrue(); } @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); }
private List<ChangeData> executeIndexQueryWithRetry(RetryHelper retryHelper, Provider<ChangeQueryProcessor> changeQueryProcessorProvider, Predicate<ChangeData> predicate) throws OrmException { try { return retryHelper.execute(ActionType.INDEX_QUERY, () -> changeQueryProcessorProvider.get().query(predicate).entities(), OrmException.class::isInstance); } catch (Exception e) { Throwables.throwIfUnchecked(e); Throwables.throwIfInstanceOf(e, OrmException.class); throw new OrmException(e); } }
@Deprecated public static int forkSystemServer(int uid, int gid, int[] gids, boolean enableDebugger, int[][] rlimits) { int debugFlags = enableDebugger ? DEBUG_ENABLE_DEBUGGER : 0; return forkAndSpecialize(uid, gid, gids, debugFlags, rlimits, null, null); } native public static int nativeForkSystemServer(int uid, int gid, int[] gids, int debugFlags, int[][] rlimits, long permittedCapabilities, long effectiveCapabilities); /** * Executes "/system/bin/sh -c <command>" using the exec() system call. * This method throws a runtime exception if exec() failed, otherwise, this * method never returns. * * @param command The shell command to execute. */ public static void execShell(String command) { nativeExecShell(command); } /** * Appends quotes shell arguments to the specified string builder. * The arguments are quoted using single-quotes, escaped if necessary, * prefixed with a space, and appended to the command. * * @param command A string builder for the shell command being constructed. */ public static void appendQuotedShellArguments(StringBuilder command, String... args) { for (String arg : args) { command.append(' '); command.append('\''); command.append(escapeSingleQuotes(arg)); command.append('\''); } } public boolean checkIfYDescriptorValid(IDataChartDescriptor<?, ?> desc, @Nullable IDataChartDescriptor<?, ?> filter) { DescriptorTypeVisitor visitor = new DescriptorTypeVisitor(); desc.accept(visitor); if (visitor.isIndividualType(DescriptorType.STRING)) { return false; } // Only allow descriptors of the same type, that will mean the same // thing. It is hard to compare durations to timestamps for instance return IChartTypeDefinition.filterSameDescriptor(desc, filter); } /** * An implementation of BaseConfig specifically for sending as part of the Android model * through the Gradle tooling API. */ abstract class BaseConfigImpl implements BaseConfig, Serializable { private static final long serialVersionUID = 1L; @NonNull private final Map<String, String> mManifestPlaceholders; @NonNull private final Map<String, ClassField> mBuildConfigFields; @NonNull private final Map<String, ClassField> mResValues; protected BaseConfigImpl(@NonNull BaseConfig
try { UrlValidator.clean(CheckerTestData.INVALID_URL); assert_().fail("expected BadRequestException"); } catch (BadRequestException e) { assertMessage(e, "only http/https URLs supported", CheckerTestData.INVALID_URL); } @Test public void verifyTestQueries() throws Exception { assertInvalidQuery(CheckerTestData.QUERY_WITH_UNSUPPORTED_OPERATOR, "unsupported operator", CheckerTestData.UNSUPPORTED_OPERATOR); assertInvalidQuery(CheckerTestData.INVALID_QUERY, "invalid", CheckerTestData.INVALID_QUERY); } private static void assertInvalidQuery(String query, String... expectedMessageParts) { try { CheckerQuery.clean(query); assert_().fail("expected ConfigInvalidException"); } catch (ConfigInvalidException e) { assertMessage(e, expectedMessageParts); } } private static void assertMessage(Exception e, String... expectedMessageParts) { for (String expectedMessagePart : expectedMessageParts) { assertThat(e).hasMessageThat().ignoringCase().contains(expectedMessagePart); } }
private void queueEvaluationIfNecessary(String repositoryPath) { if (lastCheckExpired(repositoryPath)) { EvaluationTask evaluationTask = evaluationTaskFactory.create(repositoryPath); if (queuedEvaluationTasks.add(evaluationTask)) { Future<?> future = executor.submit(evaluationTask); addTaskListener(future, evaluationTask); timestamps.put(repositoryPath, System.currentTimeMillis()); } } }
private void addTaskListener(Future<?> future, EvaluationTask evaluationTask) { ListenableFuture<?> listenableFuture = JdkFutureAdapters.listenInPoolThread(future); listenableFuture.addListener( new Runnable() { public void run() { queuedEvaluationTasks.remove(evaluationTask); } }, MoreExecutors.directExecutor() ); }
private void addTaskListener(Future<?> future, EvaluationTask evaluationTask) { ListenableFuture<?> listenableFuture = JdkFutureAdapters.listenInPoolThread(future); listenableFuture.addListener( new Runnable() { public void run() { queuedEvaluationTasks.remove(evaluationTask); } }, MoreExecutors.directExecutor() ); }
public void createEvaluator() { when(event.getProjectName()).thenReturn(NAME_KEY.get()); when(config.getExpireTimeRecheck()).thenReturn(0L); when(gerritConfig.getInt("receive", null, "threadPoolSize", Runtime.getRuntime().availableProcessors())) .thenReturn(1); when(repository.getDirectory()).thenReturn(new File(REPOSITORY_PATH)); when(repositoryOther.getDirectory()).thenReturn(new File(REPOSITORY_PATH_OTHER)); taskSamePathCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH); taskSamePathNotCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH); taskDifferentPath = new EvaluationTask(null, null, null, REPOSITORY_PATH_OTHER); Factory eventTaskFactory = mock(Factory.class); when(eventTaskFactory.create(REPOSITORY_PATH)) .thenReturn(taskSamePathNotCompleted) .thenReturn(taskSamePathCompleted); when(eventTaskFactory.create(REPOSITORY_PATH_OTHER)).thenReturn(taskDifferentPath); when(executor.submit(taskSamePathCompleted)).thenReturn(CompletableFuture.completedFuture(null)); }
taskDifferentPath = new EvaluationTask(null, null, null, REPOSITORY_PATH_OTHER); /** Task factory */ Factory eventTaskFactory = mock(Factory.class); when(eventTaskFactory.create(REPOSITORY_PATH)) .thenReturn(taskSamePathNotCompleted) .thenReturn(taskSamePathCompleted); when(eventTaskFactory.create(REPOSITORY_PATH_OTHER)).thenReturn(taskDifferentPath); /** Executor */ when(executor.submit(taskSamePathCompleted)) .thenReturn(CompletableFuture.completedFuture(null)); when(executor.submit(taskSamePathNotCompleted)).thenReturn(new CompletableFuture<>()); when(executor.submit(taskDifferentPath)).thenReturn(CompletableFuture.completedFuture(null)); evaluator = new Evaluator(executor, eventTaskFactory, repoManager, config, gerritConfig);
public static final String GLOBAL_CAPABILITIES = "GLOBAL_CAPABILITIES"; public static final String ALL = "refs/*"; public static final String HEADS = "refs/heads/*"; public static final String REGEX_PREFIX = "^"; private String name; private List<Permission> permissions; public AccessSection(String name) { this.name = name; this.permissions = new ArrayList<>(); } public static boolean isValidRefSectionName(String name) { return name.startsWith("refs/") || name.startsWith("^refs/"); } public String getName() { return name; } public ImmutableList<Permission> getPermissions() { // implementation }
public static final String GLOBAL_CAPABILITIES = "GLOBAL_CAPABILITIES"; /** Pattern that matches all references in a project. */ public static final String ALL = "refs/*"; /** Pattern that matches all branches in a project. */ public static final String HEADS = "refs/heads/*"; /** Prefix that triggers a regular expression pattern. */ public static final String REGEX_PREFIX = "^"; /** Name of the ref pattern or access section. */ private String refPattern; private List<Permission> permissions; public AccessSection(String refPattern) { this.refPattern = refPattern; this.permissions = new ArrayList<>(); } /** @return true if the ref pattern is likely to be a valid reference section name. */ public static boolean isValidRefSectionName(String refPattern) { return refPattern.startsWith("refs/") || refPattern.startsWith("^refs/"); } public String getRefPattern() { return refPattern; } public ImmutableList<Permission> getPermissions() { // implementation }
public AccessSection(String name) { this.name = name; this.permissions = new ArrayList<>(); }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.ConfigInvalidException; /** * Listener of the configuration loading events. */ public interface ReplicationConfigListener { /** * Invoked just before replication.config is about to be loaded. */ void beforeLoad(); /** * Invoked just after replication.config is loaded into memory. * * @throws ConfigInvalidException if the loaded configuration is not valid */ }
Fixed Code: private void innerTest() throws Exception { try { outer(); fail("should throw"); } catch (IllegalStateException e) { StackTraceElement[] trimmed = SuperManifestRefUpdatedListener.trimStack(e.getStackTrace(), Thread.currentThread().getStackTrace()[1]); String str = Arrays.toString(trimmed); assertThat(str).doesNotContain("trimStackTrace"); assertThat(str).contains("innerTest"); }
// Project name is scoped by test, so we need to get it from our initial change Project.NameKey projectNameKey = initialResult.getChange().project(); String projectName = projectNameKey.get(); createBranch(new Branch.NameKey(projectName, "ds_one")); createBranch(new Branch.NameKey(projectName, "ds_two")); initialResult.assertOkStatus(); // Create normalUserGroup, containing current user, and contextUserGroup, containing contextUser String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get(); gApi.groups().id(normalUserGroup).addMembers(user.id().toString()); AccountApi contextUserApi = gApi.accounts().create("someContextUser"); String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get(); gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name); // Grant exclusive +2 to context user grantLabel("Code-Review", -2, 2, projectNameKey, "refs/heads/ds_one", false,
// Project name is scoped by test, so we need to get it from our initial change Project.NameKey projectNameKey = initialResult.getChange().project(); String projectName = projectNameKey.get(); createBranch(new Branch.NameKey(projectName, "ds_one")); createBranch(new Branch.NameKey(projectName, "ds_two")); initialResult.assertOkStatus(); // Create normalUserGroup, containing current user, and contextUserGroup, containing contextUser String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get(); gApi.groups().id(normalUserGroup).addMembers(user.id().toString()); AccountApi contextUserApi = gApi.accounts().create("randomContextUser"); String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get(); gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name); // Grant +2 to context user, since it doesn't have it by default grantLabel("Code-Review", -2, 2, projectNameKey, "refs/heads/*", false);
private final PermissionBackend permissionBackend; private final Map<String, CommandProvider> commands; private final AtomicReference<Command> atomicCmd; private final DynamicSet<SshExecuteCommandInterceptor> commandInterceptors; @Argument(index = 0, required = false, metaVar = "COMMAND", handler = SubcommandHandler.class) private String commandName; @Argument(index = 1, multiValued = true, metaVar = "ARG") private List<String> args = new ArrayList<>(); @Inject DispatchCommand(PermissionBackend permissionBackend, Map<String, CommandProvider> all, DynamicSet<SshExecuteCommandInterceptor> commandInterceptors) { this.permissionBackend = permissionBackend; this.commandInterceptors = commandInterceptors; commands = all; atomicCmd = Atomics.newReference(); } Map<String, CommandProvider> getMap() { return commands; } @Override public void start(Environment env) throws IOException { try { parseCommandLine(); if (Strings.isNullOrEmpty(commandName)) { StringWriter msg = new StringWriter(); msg.write(usage()); throw die(msg.toString()); } // rest of the code }
public void mouseMove(MouseEvent e) { getShell().setCursor(new Cursor(getDisplay(), SWT.CURSOR_CROSS)); if (mModel != null) { int x = getInverseScaledSize(e.x - mDx); int y = getInverseScaledSize(e.y - mDy); coordinateLabel.setText(String.format("(%d,%d)", x, y)); if (mModel.isExploreMode()) { BasicTreeNode node = mModel.updateSelectionForCoordinates(x, y); if (node != null) { updateTreeSelection(node); } } } } import javax.servlet.http.HttpServletResponse; import com.google.gerrit.httpd.HtmlDomUtil; import com.google.inject.Singleton; @Singleton public class HelloWorldServlet extends HttpServlet { private static final long serialVersionUID = 1L; @Override protected void doGet(final HttpServletRequest req, final HttpServletResponse rsp) throws IOException, ServletException { doPost(req, rsp); } @Override protected void doPost(final HttpServletRequest req, final HttpServletResponse rsp) throws IOException, ServletException { rsp.setContentType("text/html"); rsp.setCharacterEncoding("UTF-8"); final Writer out = rsp.getWriter(); out.write("<html>"); out.write("<body>"); out.write("<h2>Hello world!</h2>"); out.write("</body>"); out.write("</html>"); out.close(); } } choseSubmitTypeFrom = cd; } else if (st != submitType) { commitStatus.problem(changeId, String.format( "Change has submit type %s, but previously chose submit type %s " + "from change %s in the same batch", st, submitType, choseSubmitTypeFrom.getId())); continue; } if (chg.currentPatchSetId() == null) { String msg = "Missing current patch set on change"; logger.atSevere().log("%s %s", msg, changeId); commitStatus.problem(changeId, msg); continue; } PatchSet ps; Branch.NameKey destBranch = chg.getDest(); try { ps = cd.currentPatchSet(); } catch (OrmException e) { commitStatus.logProblem(changeId, e); continue; } if (ps == null || ps.getRevision() == null || ps.getRevision().get() == null) { commitStatus.logProblem(changeId, "Missing patch set or revision on change
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.sshd; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; @ExtensionPoint public interface SshExecuteCommandInterceptor { /** * Check the command and return false if this command must not be run. * * @param command the command * @param arguments the list of arguments * @return whether or not this command with this arguments can be executed */ boolean accept(String command, List<String> arguments); default String name() { return this.getClass().getSimpleName(); } }
private void setAccount() throws OrmException, IOException, UnloggedFailure { user = genericUserFactory.create(id); rsrc = new AccountResource(user); try { for (String email : addEmails) { addEmail(email); } for (String email : deleteEmails) { deleteEmail(email); } if (preferredEmail != null) { if (isRegistered(preferredEmail)) { putPreferred(preferredEmail); } else { System.err.println("WARNING: preferred email not set, " + preferredEmail + " not registered"); } } if (fullName != null) { PutName.Input in = new PutName.Input(); in.name = fullName; putName.apply(rsrc, in); } if (httpPassword != null || clearHttpPassword) { PutHttpPassword.Input in = new PutHttpPassword.Input(); in.httpPassword = httpPassword; putHttpPassword.apply(rsrc, in); } if (active) { putActive.apply(rsrc, null); } else if (inactive) { try { deleteActive.apply(rsrc, null); } catch (UnloggedFailure e) { String msg = e.getMessage(); if (!msg.endsWith("\n")) { msg += "\n"; } err.write(msg.getBytes(ENC)); err.flush(); onExit(e.exitCode); } } } catch (UnloggedFailure e) { String msg = e.getMessage(); if (!msg.endsWith("\n")) { msg += "\n"; } err.write(msg.getBytes(ENC)); err.flush(); onExit(e.exitCode); } } // key both send an escape sequence (due to this method) and switch focus // to the Workbench File menu (forcing the user to click in the Terminal // view again to continue entering text). This fixes that. event.doit = false; char character = event.character; int modifierKeys = event.stateMask & SWT.MODIFIER_MASK; boolean ctrlKeyPressed = (event.stateMask & SWT.CTRL) != 0; boolean onlyCtrlKeyPressed = modifierKeys == SWT.CTRL; boolean macCmdKeyPressed = (event.stateMask & SWT.COMMAND) != 0; // To fix SPR 110341, we consider the Alt key to be pressed only when the // Control key is
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.sshd; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; @ExtensionPoint public interface SshExecuteCommandInterceptor { /** * Check the command and return false if this command must not be run. * * @param command the command * @param arguments the list of arguments * @return whether or not this command with these arguments can be executed */ boolean accept(String command, List<String> arguments); default String name() { return this.getClass().getSimpleName(); } }
RevisionCreatedListener.Event event, Map<String, ImmutableList<Match>> findings) throws RestApiException { long startNanos = System.nanoTime(); metrics.reviewCount.increment(); metrics.reviewCountByProject.increment(project); try { boolean tpAllowed = scannerConfig.isThirdPartyAllowed(project); boolean reviewRequired = false; boolean hasAlwaysReview = false; for (Map.Entry<String, ImmutableList<Match>> entry : findings.entrySet()) { if (entry.getValue() == ALWAYS_REVIEW) { reviewRequired = true; hasAlwaysReview = true; break; } PartyType pt = partyType(entry.getValue()); if (pt.compareTo(THIRD_PARTY) > 0) { reviewRequired = true; break; } if (pt == THIRD_PARTY && !tpAllowed) { reviewRequired = true; break; } } ChangeResource change = getChange(event, scannerConfig.fromAccountId); ReviewInput ri = new ReviewInput() .message("Copyright scan") .label(scannerConfig.reviewLabel, reviewRequired ? -1 : +2); if (reviewRequired) { // Set the review flag ri.setReviewFlag(true); } changeApi.revision(change.getId()).review(ri); } catch (Exception e) { // Handle exception } long elapsedNanos = System.nanoTime() - startNanos; metrics.reviewTime.record(elapsedNanos, TimeUnit.NANOSECONDS); }
public String toString() { return "FlatFile WebSession Cleaner"; }
batchUpdate.addCommand(new ReceiveCommand(ref.getObjectId(), ObjectId.zeroId(), refName)); } batchUpdate.execute(rw, NullProgressMonitor.INSTANCE); for (ReceiveCommand command : batchUpdate.getCommands()) { if (command.getResult() != ReceiveCommand.Result.OK) { throw new IOException( String.format("Unstar change %d failed, ref %s could not be deleted: %s", changeId.get(), command.getRefName(), command.getResult())); } } indexer.index(project, changeId); } catch (IOException e) { throw new OrmException(String.format("Unstar change %d failed", changeId.get()), e); }
void execute(PersonIdent refLogIdent, String refLogMessage, PushCertificate pushCert) { if (allUsersRepo == null || allUsersRepo.cmds.isEmpty()) { return; } canCloseEarly = false; @SuppressWarnings("unused") Future<?> possiblyIgnoredError = executor.submit(() -> { try { allUsersRepo.flush(); BatchRefUpdate bru = allUsersRepo.repo.getRefDatabase().newBatchUpdate(); bru.setPushCertificate(pushCert); if (refLogMessage != null) { bru.setRefLogMessage(refLogMessage, false); } else { bru.setRefLogMessage(firstNonNull(NoteDbUtil.guessRestApiHandler(), "Update NoteDb refs"), false); } bru.setRefLogIdent(refLogIdent != null ? refLogIdent : serverIdent.get()); bru.setAtomic(true); allUsersRepo.cmds.addTo(bru); bru.setAllowNonFastForwards(true); RefUpdateUtil.executeChecked(bru, allUsersRepo.rw); } catch (IOException e) { log.error("Error executing batch ref update", e); } finally { allUsersRepo.close(); allUsersRepo.deleteComments(); } }); }
import com.google.gerrit.server.config.AllProjectsName; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.inject.Inject; import com.google.inject.Singleton; /** * Schema upgrade implementation. * * <p>Implementations must have a single non-private constructor with no arguments (e.g. the default * constructor). */ interface NoteDbSchemaVersion { @Singleton class Arguments { final GitRepositoryManager repoManager; final AllProjectsName allProjects; final AllUsersName allUsers; @Inject Arguments(GitRepositoryManager repoManager, AllProjectsName allProjects, AllUsersName allUsers) { this.repoManager = repoManager; this.allProjects = allProjects; this.allUsers = allUsers; } } void upgrade(Arguments args, UpdateUI ui) throws Exception; }
protected boolean shouldSendMessage() { if (sshKey == null && gpgKeys == null) { // Don't email if no keys were added. return false; } if (user.equals(callingUser)) { // Send email if the user self-added a key; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly added. return true; } try { // Don't email if an administrator added a key on behalf of the user. permissionBackend.user(callingUser).check(GlobalPermission.ADMINISTRATE_SERVER); return false; } catch (AuthException | PermissionBackendException e) { // Send email if a non-administrator modified the keys, e.g. by MODIFY_ACCOUNT. return true; } }
@Use(SourceInfoFactory.class) @Filter(TypeWithoutPrebuiltFilter.class) public class CfgBuilder implements RunnableSchedulable<JMethod> { @Nonnull public static final StatisticId<Counter> CREATED_BASIC_BLOCK = new StatisticId<>("jack.cfg.create-basic-block", "Basic block created", CounterImpl.class, Counter.class); @Nonnull public static final StatisticId<Counter> REMOVED_BASIC_BLOCK = new StatisticId<>("jack.cfg.removed-basic-blocks", "Basic blocks removed", CounterImpl.class, Counter.class); @Nonnull private final com.android.jack.util.filter.Filter<JMethod> filter = ThreadConfig.get(Options.METHOD_FILTER); @Nonnull private final Tracer tracer = TracerFactory.getTracer(); private final JSession session = Jack.getSession(); private static class JCaseStatementComparator implements Comparator<JCaseStatement>, Serializable { private static final long serialVersionUID = 1L; @Override public int compare(JCaseStatement case1, JCaseStatement case2) { JLiteral lit1 = case1.getExpr(); JLiteral lit2 = case2.getExpr(); assert lit1 instanceof JValueLiteral; // TODO: Implement the comparison logic return 0; } } } protected void initModel(String projectName, String modelName, Bundle bundle) throws CoreException, IOException { project = ProjectUtils.createProject(projectName); diModelFile = PapyrusProjectUtils.copyPapyrusModel(project, bundle, getSourcePath(), modelName); } protected String getSourcePath() { return "models/"; } protected Bundle getBundle() { return Activator.getDefault().getBundle(); } public ICellEditor getICellEditor(Table table, Object axisElement, ITableAxisElementProvider elementProvider) { super.getICellEditor(table, axisElement, elementProvider); AbstractPapyrusStyledTextCellEditor editor = new UMLReferenceTextWithCompletionCellEditor(table, axisElement, elementProvider); AbstractOpenDialogCellEditorButtonAction openDialog = getCellEditorWithDialogToOpen(axisElement, elementProvider); editor.setOpenDialogCellEditorButtonAction(openDialog); openDialog.setText("..."); openDialog.setTooltipText(Messages.UMLReferenceCellEditorConfiguration_OpenDialogToChooseTheValue); return editor; } protected boolean shouldSendMessage() { if (sshKey == null && gpgKeys
@Override public Response<?> apply(AccountResource.SshKey rsrc, Input input) throws AuthException, OrmException, RepositoryNotFoundException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.user(self).check(GlobalPermission.ADMINISTRATE_SERVER); } IdentifiedUser user = rsrc.getUser(); authorizedKeys.deleteKey(user.getAccountId(), rsrc.getSshKey().getKey().get()); try { deleteKeyFactory.create(user, "SSH").send(); } catch (EmailException e) { log.error("Cannot send SSH key deletion message to " + user.getAccount().getPreferredEmail(), e); } sshKeyCache.evict(user.getUserName()); return Response.none(); }
if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.user(self).check(GlobalPermission.ADMINISTRATE_SERVER); } IdentifiedUser user = rsrc.getUser(); authorizedKeys.deleteKey(user.getAccountId(), rsrc.getSshKey().getKey().get()); try { deleteKeyFactory.create(rsrc.getUser(), "SSH").send(); } catch (EmailException e) { log.error("Cannot send SSH key deletion message to {}", user.getAccount().getPreferredEmail(), e); } sshKeyCache.evict(user.getUserName()); return Response.none();
import java.util.List; import java.util.stream.Collectors; import java.util.stream.Stream; import org.eclipse.jgit.lib.BatchRefUpdate; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.transport.ReceiveCommand.Result; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final BatchRefUpdate batchRefUpdate; private final RefDatabase refDb; private final SharedRefDatabase<? extends AutoCloseable> sharedRefDb; private final String projectName; public static class RefPair { public final Ref oldRef; public final Ref newRef; public final Exception exception; RefPair(Ref oldRef, Ref newRef) { this.oldRef = oldRef; this.newRef = newRef; this.exception = null; } } }
@Override public BatchRefUpdate addProposedTimestamp(ProposedTimestamp ts) { return batchRefUpdate.addProposedTimestamp(ts); } @Override public void execute(RevWalk walk, ProgressMonitor monitor, List<String> options) throws IOException { executeWrapper(walk, monitor, options); } @Override public void execute(RevWalk walk, ProgressMonitor monitor) throws IOException { executeWrapper(walk, monitor, Collections.EMPTY_LIST); } @Override public String toString() { return batchRefUpdate.toString(); } private void updateSharedRefDb(Stream<RefPair> oldRefs, RevWalk walk, ProgressMonitor monitor, List<String> options) throws Exception { List<RefPair> refsToUpdate = oldRefs.sorted(comparing(RefPair::hasFailed).reversed()).collect(Collectors.toList()); if (refsToUpdate.isEmpty()) { return; } if (refsToUpdate.get(0).hasFailed()) { RefPair failedRef = refsToUpdate.get(0); throw new IOException("Failed to fetch ref entries" + failedRef.newRef.getName(), failedRef.exception); } }
try (CloseableSet<AutoCloseable> locks = new CloseableSet()) { assertBatchCommandsAreInSync(refsToUpdate, locks); if (options.isEmpty()) { batchRefUpdate.execute(walk, monitor); } else { batchRefUpdate.execute(walk, monitor, options); } updateSharedDBForSuccessfulCommands(batchRefUpdate.getCommands().stream()); } catch (Exception e) { logger.atWarning().log("Failed to apply full batch %s", e.getMessage()); throw e; } private void updateSharedDBForSuccessfulCommands(Stream<ReceiveCommand> commandStream) throws IOException { List<RefPair> successfulRefPairs = commandStream .filter(cmd -> cmd.getResult() == Result.OK) .map(cmd -> new RefPair( cmd.getOldId() == null ? sharedRefDb.NULL_REF : sharedRefDb.newRef(cmd.getRefName(), cmd.getOldId()), sharedRefDb.newRef(cmd.getRefName(), cmd.getNewId()))) .collect(Collectors.toList()); for (RefPair successfulRefPair : successfulRefPairs) { // Update shared DB } }
logger.atWarning().log("Failed to apply full batch %s", e.getMessage()); throw e; } private void updateSharedDBForSuccessfulCommands(Stream<ReceiveCommand> commandStream) throws IOException { List<RefPair> successfulRefPairs = commandStream .filter(cmd -> cmd.getResult() == Result.OK) .map(cmd -> new RefPair( cmd.getOldId() == null ? sharedRefDb.NULL_REF : sharedRefDb.newRef(cmd.getRefName(), cmd.getOldId()), sharedRefDb.newRef(cmd.getRefName(), cmd.getNewId()))) .collect(Collectors.toList()); for (RefPair successfulRefPair : successfulRefPairs) { sharedRefDb.compareAndPut(projectName, successfulRefPair.oldRef, successfulRefPair.newRef); } } private void assertBatchCommandsAreInSync(List<RefPair> refsToUpdate, CloseableSet<AutoCloseable> locks) throws Exception { for (RefPair refPair : refsToUpdate) { Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null ? sharedRefDb.exactRef(refPair.newRef.getName()) : sharedRefDb.exactRef(refPair.oldRef.getName()); if (nonNullRef == null) { throw new IOException("Ref " + refPair.newRef.getName() + " does not exist"); } try (AutoCloseable lock = locks.acquire(nonNullRef.getName())) { RefUpdate.Result result = updateRef(refPair.newRef, nonNullRef); if (result != RefUpdate.Result.FORCED && result != RefUpdate.Result.NEW) { throw new IOException("Failed to update ref " + refPair.newRef.getName() + ": " + result.name()); } } } }
} } private void assertBatchCommandsAreInSync(List<RefPair> refsToUpdate, CloseableSet<AutoCloseable> locks) throws Exception { for (RefPair refPair : refsToUpdate) { Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null ? refPair.newRef : refPair.oldRef; String resourceLockKey = String.format("%s-%s", projectName, nonNullRef.getName()); locks.addResourceIfNotExist(resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); boolean isInnSync; if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInnSync = sharedRefDb.isMostRecentRefVersion(projectName, refPair.oldRef); } else { isInnSync = !sharedRefDb.isPresent(projectName, refPair.getName()); } if (!isInnSync) { String errorMessage = String.format(
Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null ? refPair.newRef : refPair.oldRef; String resourceLockKey = String.format("%s-%s", projectName, nonNullRef.getName()); locks.addResourceIfNotExist(resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); boolean isInSync; if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInSync = sharedRefDb.isMostRecentRefVersion(projectName, refPair.oldRef); } else { isInSync = !sharedRefDb.isPresent(projectName, refPair.getName()); } if (!isInSync) { String errorMessage = String.format("Ref %s not in sync with sharedDb, aborting batch", refPair.oldRef.getName()); logger.atWarning().log(errorMessage); throw new Exception(errorMessage); }
private static NumberFormat getInstance(Locale desiredLocale, int choice) { DecimalFormatSymbols symbols = new DecimalFormatSymbols(desiredLocale); String pattern = ""; switch (choice) { case CURRENCYSTYLE: pattern = LocaleData.get(desiredLocale).currencyPattern; break; case INTEGERSTYLE: pattern = LocaleData.get(desiredLocale).integerPattern; break; case PERCENTSTYLE: pattern = LocaleData.get(desiredLocale).percentPattern; break; case NUMBERSTYLE: pattern = LocaleData.get(desiredLocale).numberPattern; break; default: throw new IllegalArgumentException("Unknown Choice: " + choice); } return new DecimalFormat(pattern, symbols); }
private void addReplacedMessage(ReplaceRequest u, boolean edit, Boolean isPrivate, Boolean wip) { String subject; if (edit) { try { subject = receivePack.getRevWalk().parseCommit(u.newCommitId).getShortMessage(); } catch (IOException e) { logger.atWarning().withCause(e).log("failed to get subject for edit patch set"); subject = u.notes.getChange().getSubject(); } } else { subject = u.info.getSubject(); } if (isPrivate == null) { isPrivate = u.notes.getChange().isPrivate(); } if (wip == null) { wip = u.notes.getChange().isWorkInProgress(); } ChangeReportFormatter.Input input = ChangeReportFormatter.Input.builder() .setChange(u.notes.getChange()) .setSubject(subject) .setIsEdit(edit) .setIsPrivate(isPrivate) .setIsWorkInProgress(wip) .build(); addMessage(changeFormatter.changeUpdated(input)); } private void parseMagicBranch(ReceiveCommand cmd) throws PermissionBackendException { logger.atFine().log("Found magic branch %s", cmd.getRefName()); MagicBranchInput magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration); logDebug("Found magic branch %s", cmd.getRefName()); magicBranch = new MagicBranchInput(user, cmd, labelTypes, notesMigration); magicBranch.reviewer.addAll(extraReviewers.get(ReviewerStateInternal.REVIEWER)); magicBranch.cc.addAll(extraReviewers.get(ReviewerStateInternal.CC)); String ref; magicBranch.cmdLineParser = optionParserFactory.create(magicBranch); try { ref = magicBranch.parse(repo, receivePack.getAdvertisedRefs().keySet(), pushOptions); } catch (CmdLineException e) { if (!magicBranch.cmdLineParser.wasHelpRequestedByOption()) { logger.atFine().log("Invalid branch syntax"); reject(cmd, e.getMessage()); return; } ref = null; // never happens } if (magicBranch.topic != null && magicBranch.topic.length() > ChangeUtil.TOPIC_MAX_LENGTH) { reject(cmd, "topic length exceeds the maximum limit"); return; } magicBranch.dest = new Branch.NameKey(project.getName
// changes (weighted 1d). Map<Account.Id, MutableDouble> reviewers = new LinkedHashMap<>(); if (candidates.size() == 0) { return reviewers; } List<Predicate<ChangeData>> predicates = new ArrayList<>(); for (Account.Id id : candidates) { try { Predicate<ChangeData> projectQuery = changeQueryBuilder.project(projectControl.getProject().getName()); // Get all labels for this project and create a compound OR query to // fetch all changes where users have applied one of these labels Predicate<ChangeData> compoundLabelPredicate = null; for (LabelType type : projectControl.getLabelTypes().getLabelTypes()) { Predicate<ChangeData> labelPredicate = changeQueryBuilder.label(type.getName() + ",user=" + id); if (compoundLabelPredicate == null) { compoundLabelPredicate = labelPredicate; } else { compoundLabelPredicate = Predicate.or(compoundLabelPredicate, labelPredicate); } } Predicate<ChangeData> reviewerQuery = Predicate.and(projectQuery, compoundLabelPredicate); Predicate<ChangeData> ownerQuery = Predicate.and(projectQuery, ownerPredicate); predicates.add(reviewerQuery); predicates.add(ownerQuery); } catch (Exception e) { // Handle exception } } // Rest of the code... protected void configure() { DynamicMap.mapOf(binder(), IMAGE_KIND); bind(ImagesCollection.class); child(PROJECT_KIND, "images").to(ImagesCollection.class); delete(IMAGE_KIND).to(DeleteImage.class); postOnCollection(IMAGE_KIND).to(PostImage.class); } super(config, uriInfo, context, dataClient, validator); this.routerId = routerId; } /** * Handler for creating a router route. * * @param route Route object. * @throws StateAccessException Data access error. * @return Response object with 201 status code set if successful. */ @POST @RolesAllowed({ AuthRole.ADMIN, AuthRole.TENANT_ADMIN }) @Consumes({ VendorMediaType.APPLICATION_ROUTE_JSON, MediaType.APPLICATION_JSON }) public Response create(Route route) throws StateAccessException, SerializationException { route.routerId = routerId; validate(route); throwIfNextPortNotValid(route); authoriser.tryAuthoriseRouter(routerId, "add route to this router"); UUID id = dataClient.routesCreate(RouteDataConverter.toData(route)); routerEvent.routeCreate(router
boolean compareAndRemove(String project, Ref oldRef) throws IOException; default boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); }
public ZkSharedRefDatabase(CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return ignoreRefInSharedDb(oldRef) || compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { if (newRef != NULL_REF && ignoreRefInSharedDb(newRef)) { return true; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } catch (Exception e) { throw new IOException("Failed to compare and put ref", e); } }
// When validation of status fails doReturn(false).when(sharedRefDb).isMostRecentRefVersion(A_TEST_PROJECT_NAME, oldRef); RefUpdate refUpdate = RefFixture.RefUpdateStub.forSuccessfulUpdate(oldRef, newRef.getObjectId()); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, A_TEST_PROJECT_NAME, refUpdate); multiSiteRefUpdate.update(); @Test(expected = Exception.class) public void newUpdateShouldFailIfSharedDBUpdateFailsLeavingSystemInInconsistentStatus() throws Exception { // When validation succeeds doReturn(true).when(sharedRefDb).isMostRecentRefVersion(A_TEST_PROJECT_NAME, oldRef); // When compareAndPut fails doReturn(false).when(sharedRefDb).compareAndPut(A_TEST_PROJECT_NAME, oldRef, newRef); RefUpdate refUpdate = RefFixture.RefUpdateStub.forSuccessfulUpdate(oldRef, newRef.getObjectId()); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, A_TEST_PROJECT_NAME, refUpdate); multiSiteRefUpdate.update(); } @Test public void deleteShouldValidateAndSucceed() throws Exception { // When validation succeeds doReturn(true).when(sharedRefDb).isMostRecentRefVersion(A_TEST_PROJECT_NAME, oldRef); // When compareAndPut succeeds doReturn(true).when(sharedRefDb).compareAndPut(A_TEST_PROJECT_NAME, oldRef, newRef); RefUpdate refUpdate = RefFixture.RefUpdateStub.forSuccessfulUpdate(oldRef, newRef.getObjectId()); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, A_TEST_PROJECT_NAME, refUpdate); multiSiteRefUpdate.update(); }
protected int getStackFrameIndex(IStackFrame stackFrame) { int stackFrameIndex = 0; if (((IJavaDebugTarget) fDebugTarget).supportsMonitorInformation()) { IThread thread = stackFrame.getThread(); IDebugElement[] ownedMonitors = JavaDebugUtils.getOwnedMonitors(thread); stackFrameIndex += ownedMonitors.length; IDebugElement contendedMonitor = JavaDebugUtils.getContendedMonitor(thread); if (contendedMonitor != null) { ++stackFrameIndex; } } return stackFrameIndex; } public void lineBreak() { assertOpenBlock(); try { if (currentBlock instanceof MarkdownBlock) { ((MarkdownBlock) currentBlock).lineBreak(); } else { currentBlock.write("\n"); //$NON-NLS-1$ } } catch (IOException e) { throw new RuntimeException(e); } } return; Object value = myAttributesTable.getValueAt(selectedRow, selectedColumn); if (value == null || !(value instanceof EditedStyleItem)) { return; } Component cellComponent = myAttributesTable.getCellRenderer(selectedRow, selectedColumn) .getTableCellRendererComponent(myAttributesTable, selectedItem, false, false, selectedRow, selectedColumn); if (!(cellComponent instanceof JComponent)) { // Doesn't have a tooltip. return; } EditedStyleItem item = (EditedStyleItem)value; Project project = e.getProject(); DocumentationManager documentationManager = DocumentationManager.getInstance(project); final DocumentationComponent docComponent = new DocumentationComponent(documentationManager); docComponent.setText(((JComponent)cellComponent).getToolTipText(), e.getData(CommonDataKeys.PSI_FILE), true); JBPopup hint = JBPopupFactory.getInstance().createComponentPopupBuilder(docComponent, docComponent).setProject(project) .setDimensionServiceKey(project, DocumentationManager.JAVADOC_LOCATION_AND_SIZE, false).setResizable(true).setMovable(true) .setRequestFocus(true).setTitle(item.getName()).setCancelCallback(new Computable<Boolean>() { @Override public Boolean compute() { return true; } }); // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package
public void setup() { zookeeperContainer = new ZookeeperTestContainerSupport(false); zkSharedRefDatabase = new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); }
protected boolean shouldSendMessage() { if (user.equals(callingUser)) { return true; } try { permissionBackend.user(callingUser).check(GlobalPermission.ADMINISTRATE_SERVER); return false; } catch (AuthException | PermissionBackendException e) { return true; } }
if (extId == null) { throw new ResourceNotFoundException(); } ExternalId newExtId = ExternalId.createWithPassword(extId.key(), extId.accountId(), extId.email(), newPassword); externalIdsUpdate.create().upsert(newExtId); try { httpPasswordSenderFactory.create(user).send(); } catch (EmailException e) { log.error("Cannot send HttpPassword added or changed message to {}", user.getAccount().getPreferredEmail(), e); } return Strings.isNullOrEmpty(newPassword) ? Response.<String>none() : Response.ok(newPassword); public static String generate() { byte[] rand = new byte[LEN]; rng.nextBytes(rand); byte[] enc = Base64.encodeBase64(rand, false); StringBuilder r = new StringBuilder(enc.length); for (int i = 0; i < enc.length; i++) { if (enc[i] == '=') { break; } r.append((char) enc[i]); } return r.toString(); }
protected String subject; protected String message; protected UserIdentity author; protected UserIdentity committer; protected List<ParentInfo> parents; protected ObjectId commitId; protected String description; protected PatchSetInfo() {} public PatchSetInfo(PatchSet.Id k) { key = k; } public PatchSet.Id getKey() { return key; } public String getSubject() { return subject; } public void setSubject(String s) { if (s != null && s.length() > 255) { subject = s.substring(0, 255); } else { subject = s; } }
public String message; public String parentUuid; public Range range; public String tag; private String revId; public String serverId; public boolean unresolved; public transient boolean legacyFormat; public Comment(Comment c) { this(new Key(c.key), c.author.getId(), new Timestamp(c.writtenOn.getTime()), c.side, c.message, c.serverId, c.unresolved); this.lineNbr = c.lineNbr; this.realAuthor = c.realAuthor; }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.reviewdb.converter; import com.google.gerrit.proto.Entities; import com.google.protobuf.Parser; import org.eclipse.jgit.lib.ObjectId; /** * Proto converter for {@code ObjectId}s. * * <p>This converter uses the hex representation of object IDs embedded in a wrapper proto type, * rather than a more parsimonious implementation (e.g. a raw byte array), for two reasons: * * <ul> * <li>It allows for easier integration with existing protobuf-based APIs. * <li>It provides a more human-readable representation when inspecting the database. * </ul> */ public class ObjectIdProtoConverter extends ProtoConverter<ObjectId, Entities.ObjectId> { @Override protected ObjectId fromProto(Entities.ObjectId proto) { return ObjectId.fromString(proto.getId()); } @Override protected Entities.ObjectId toProto(ObjectId objectId) { return Entities.ObjectId.newBuilder().setId(objectId.name()).build(); } @Override protected Parser<Entities.ObjectId> getParser() { return Entities.ObjectId.parser(); } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.reviewdb.converter; import static com.google.common.truth.Truth.assertThat; import static com.google.gerrit.proto.testing.SerializedClassSubject.assertThatSerializedClass; import com.google.common.collect.ImmutableMap; import com.google.gerrit.proto.Entities; import com.google.gerrit.proto.testing.SerializedClassSubject; import com.google.protobuf.Parser; import org.eclipse.jgit.lib.ObjectId; import org.junit.Test; public class ObjectIdProtoConverterTest { // Test code goes here }
public static String abbreviateName(AnyObjectId id) { return abbreviateName(id, ABBREVIATED_STRING_LENGTH); }
// Abbreviate an ID's hex string representation to 7 chars. public static String abbreviateName(AnyObjectId id) { return abbreviateName(id, 7); } // Abbreviate an ID's hex string representation to n chars. public static String abbreviateName(AnyObjectId id, int n) { checkValidLength(n); return requireNonNull(id).abbreviate(n).name(); } // Abbreviate an ID's hex string representation uniquely to at least 7 chars. public static String abbreviateName(AnyObjectId id, ObjectReader reader) { return abbreviateName(id, reader, 7); } // Abbreviate an ID's hex string representation uniquely to at least n chars. public static String abbreviateName(AnyObjectId id, ObjectReader reader, int n) { checkValidLength(n); return requireNonNull(id).abbreviate(reader, n).name(); }
public static String abbreviateName(AnyObjectId id, int n) { checkValidLength(n); return requireNonNull(id).abbreviate(n).name(); } public static String abbreviateName(AnyObjectId id, ObjectReader reader) throws IOException { return abbreviateName(id, ABBREVIATED_STRING_LENGTH, reader); }
// avoid conficts. TODO: Remove this when Kudu supports databases. // 2. The user may specify a table name using the 'kudu.table_name' table property. private String kuduTableName_; // Comma separated list of Kudu master hosts with optional ports. private String kuduMasters_; // Primary key column names. private final List<String> primaryKeyColumnNames_ = Lists.newArrayList(); // Distribution schemes of this Kudu table. Both range and hash-based distributions are supported. private final List<DistributeParam> distributeBy_ = Lists.newArrayList(); protected KuduTable(TableId id, org.apache.hadoop.hive.metastore.api.Table msTable, Db db, String name, String owner) { super(id, msTable, db, name, owner); kuduTableName_ = getKuduTableNameFromTblProperties(msTable); kuduMasters_ = getKuduMasterAddrsFromTblProperties(msTable); } @Override public TCatalogObjectType getCatalogObjectType() { return TCatalogObjectType.TABLE; } @Override public String getStorageHandlerClassName() { return KUDU_STORAGE_HANDLER; } private PatchLineComment update(PatchLineComment e, Input in) { if (in.side != null) { e.setSide(in.side == Side.PARENT ? (short) 0 : (short) 1); } if (in.line != null) { e.setLine(in.line); } if (in.inReplyTo != null) { e.setParentUuid(Url.decode(in.inReplyTo)); } e.setMessage(in.message.trim()); e.updated(); return e; } public static CommentInfo createRange(String path, Side side, int line, String in_reply_to, String message, CommentRange range) { CommentInfo info = createFile(path, side, in_reply_to, message); info.setRange(range); return info; } /** * Abbreviate an ID's hex string representation uniquely to at least {@code n} chars. * * @param id object ID. * @param n minimum number of hex chars. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least {@code n} chars. */ public static String abbreviateName(AnyObjectId id, int n, ObjectReader reader) throws IOException { checkValidLength(n); return reader
import org.bouncycastle.crypto.generators.BCrypt; import org.bouncycastle.util.Arrays; /** * HashedPassword holds logic for salted, hashed passwords. It uses BCrypt from BouncyCastle, which * truncates passwords at 72 bytes. */ public class HashedPassword { private static final String ALGORITHM = "bcrypt"; private static SecureRandom secureRandom = new SecureRandom(); private static Base64 codec = new Base64(-1); /** * The decode method decodes a hashed password encoded with {@link #encode}. It throws * DecoderException for malformed input. */ public static HashedPassword decode(String encoded) { Preconditions.checkState(encoded.startsWith(ALGORITHM + ":")); String[] fields = encoded.split(":"); Preconditions.checkState(fields.length == 4); int cost = Integer.parseInt(fields[1]); return new HashedPassword(codec.decodeBase64(fields[3]), codec.decodeBase64(fields[2]), cost); } private static byte[] hashPassword(String password, byte[] salt, int cost) { byte pwBytes[] = password.getBytes(StandardCharsets.UTF_8); } } TmfCpuAspect.class, event); if (cpu == null) { return null; } /* Find the analysis module for the trace */ TidAnalysisModule analysis = TmfTraceUtils.getAnalysisModuleOfClass(event.getTrace(), TidAnalysisModule.class, TidAnalysisModule.ID); if (analysis == null) { return null; } long ts = event.getTimestamp().toNanos(); while (block && !analysis.isQueryable(ts) && !monitor.isCanceled()) { Thread.sleep(100); } return analysis.getThreadOnCpuAtTime(cpu, ts); } /** * This is used to acquire an <code>InputStream</code> for the * part. Acquiring the stream allows the content of the part to * be consumed by reading the stream. Each invocation of this * method will produce a new stream starting from the first byte. * * @return this returns the stream for this part object */ private String getContent(ContentType type) throws IOException { String charset = type.getCharset(); if (charset == null) { charset = "ISO-8859-1"; } return body.getContent(charset); } /** * Abbreviate an ID's hex string representation uniquely to at least {@code n
private static String implicitMergeOf(ObjectId commit) { return "implicit merge of " + abbreviateName(commit, 7); }
} @FunctionalInterface private interface Func { void call() throws Exception; } private static void assertRuntimeException(Func func) throws Exception { try { func.call(); assert_().fail("Expected RuntimeException"); } catch (RuntimeException e) { // Expected. } } private static ObjectReader newReaderWithAmbiguousIds() throws Exception { // Recipe for creating ambiguous IDs courtesy of t1512-rev-parse-disambiguation.sh in git core. TestRepository<?> tr = new TestRepository<>(new InMemoryRepository(new DfsRepositoryDescription("repo"))); String blobData = "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nb1rwzyc3\n"; RevBlob blob = tr.blob(blobData); assertThat(blob.name()).isEqualTo(AMBIGUOUS_BLOB_ID.name()); assertThat(tr.tree(tr.file("a0blgqsjc", blob)).name()).isEqualTo(AMBIGUOUS_TREE_ID.name()); return tr.getRevWalk().getObjectReader(); }
private static String implicitMergeOf(ObjectId commit) { return "implicit merge of " + abbreviateName(commit, 7); }
import com.googlesource.gerrit.plugins.lfs.LfsConfigurationFactory; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; @Singleton public class LfsFsDataDirectoryManager { private static final String KEY_DIRECTORY = "directory"; private final LfsConfigurationFactory configFactory; private final Path defaultDataDir; @Inject LfsFsDataDirectoryManager(LfsConfigurationFactory configFactory, @PluginData Path defaultDataDir) { this.configFactory = configFactory; this.defaultDataDir = defaultDataDir; } public Path getForBackend(LfsBackend backend, boolean ensure) throws IOException { String dataDir = configFactory.getGlobalConfig().getString(backend.type.name(), backend.name, KEY_DIRECTORY); if (Strings.isNullOrEmpty(dataDir)) { return defaultDataDir; } if (ensure) { Path ensured = Files.createDirectories(Paths.get(dataDir.toString())); return ensured; } else { return Paths.get(dataDir.toString()); } } }
public Path getForBackend(LfsBackend backend, boolean ensure) throws IOException { String dataDir = configFactory.getGlobalConfig().getString(backend.type.name(), backend.name, KEY_DIRECTORY); if (Strings.isNullOrEmpty(dataDir)) { return defaultDataDir; } if (ensure) { Path ensured = Files.createDirectories(Paths.get(dataDir.toString())); if (!Files.isReadable(ensured)) { throw new IOException("Path '" + ensured.toAbsolutePath() + "' cannot be accessed"); } return ensured; } return Paths.get(dataDir); }
Integer id = Ints.tryParse(email.substring(0, at)); if (id != null) { return Optional.of(Account.id(id)); } } } return Optional.empty(); } public static String formatTime(PersonIdent ident, Timestamp t) { GitDateFormatter dateFormatter = new GitDateFormatter(Format.DEFAULT); PersonIdent newIdent = new PersonIdent(ident, t); return dateFormatter.formatDate(newIdent); } static String guessRestApiHandler() { StackTraceElement[] trace = Thread.currentThread().getStackTrace(); int i = findRestApiServlet(trace); if (i < 0) { return null; } try { for (i--; i >= 0; i--) { String cn = trace[i].getClassName(); Class<?> cls = Class.forName(cn); if (RestModifyView.class.isAssignableFrom(cls) && cls != RetryingRestModifyView.class) { return viewName(cn); } } return null; }
Future<?> possiblyIgnoredError = executor.submit(() -> { try (OpenRepo allUsersRepo = OpenRepo.open(repoManager, allUsersName)) { allUsersRepo.addUpdates(draftUpdates); allUsersRepo.flush(); BatchRefUpdate bru = allUsersRepo.repo.getRefDatabase().newBatchUpdate(); bru.setPushCertificate(pushCert); if (refLogMessage != null) { bru.setRefLogMessage(refLogMessage, false); } else { bru.setRefLogMessage(firstNonNull(NoteDbUtil.guessRestApiHandler(), "Update NoteDb refs"), false); } bru.setRefLogIdent(refLogIdent != null ? refLogIdent : serverIdent.get()); bru.setAtomic(true); allUsersRepo.cmds.addTo(bru); bru.setAllowNonFastForwards(true); RefUpdateUtil.executeChecked(bru, allUsersRepo.rw); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to delete draft comments asynchronously after publishing them"); } });
private void deletePublishedComment(Comment c) { verifyComment(c); delete.put(key(c), DeleteReason.PUBLISHED); }
private void addCommands() throws IOException { changeRepo.addUpdates(changeUpdates, Optional.of(maxUpdates)); if (!draftUpdates.isEmpty()) { boolean publishOnly = draftUpdates.values().stream().anyMatch(ChangeDraftUpdate::isPublishOnly); if (publishOnly) { updateAllUsersAsync.setDraftUpdates(draftUpdates); } else { allUsersRepo.addUpdates(draftUpdates); } } if (!robotCommentUpdates.isEmpty()) { changeRepo.addUpdates(robotCommentUpdates); } if (!rewriters.isEmpty()) { addRewrites(rewriters, changeRepo); } for (Change.Id id : toDelete) { doDelete(id); } }
import com.google.gerrit.common.errors.EmailException; import com.google.gerrit.extensions.api.changes.RecipientType; import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; public class HttpPasswordUpdateSender extends OutgoingEmail { public interface Factory { HttpPasswordUpdateSender create(IdentifiedUser user); } private final IdentifiedUser callingUser; private final IdentifiedUser user; @AssistedInject public HttpPasswordUpdateSender(EmailArguments ea, IdentifiedUser callingUser, @Assisted IdentifiedUser user) { super(ea, "HttpPasswordUpdate"); this.callingUser = callingUser; this.user = user; } @Override protected void init() throws EmailException { super.init(); setHeader("Subject", "[Gerrit Code Review] HTTP password was either added, changed or deleted"); add(RecipientType.TO, new Address(getEmail())); } @Override protected boolean shouldSendMessage() { return true; } }
package com.google.gerrit.extensions.api.config; import com.google.gerrit.extensions.client.DiffPreferencesInfo; import com.google.gerrit.extensions.client.EditPreferencesInfo; import com.google.gerrit.extensions.client.GeneralPreferencesInfo; import com.google.gerrit.extensions.common.ServerInfo; import com.google.gerrit.extensions.restapi.NotImplementedException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.webui.TopMenu; import java.util.List; public interface Server { String getVersion() throws RestApiException; ServerInfo getInfo() throws RestApiException; GeneralPreferencesInfo getDefaultPreferences() throws RestApiException; GeneralPreferencesInfo setDefaultPreferences(GeneralPreferencesInfo in) throws RestApiException; DiffPreferencesInfo getDefaultDiffPreferences() throws RestApiException; DiffPreferencesInfo setDefaultDiffPreferences(DiffPreferencesInfo in) throws RestApiException; EditPreferencesInfo getDefaultEditPreferences() throws RestApiException; EditPreferencesInfo setDefaultEditPreferences(EditPreferencesInfo in) throws RestApiException; }
throws RestApiException { throw new NotImplementedException(); } @Override public EditPreferencesInfo getDefaultEditPreferences() throws RestApiException { throw new NotImplementedException(); } @Override public EditPreferencesInfo setDefaultEditPreferences(EditPreferencesInfo in) throws RestApiException { throw new NotImplementedException(); } @Override public ConsistencyCheckInfo checkConsistency(ConsistencyCheckInput in) throws RestApiException { throw new NotImplementedException(); } @Override public List<TopMenu.MenuEntry> topMenus() throws RestApiException { throw new NotImplementedException(); }
ChangeCheckerImpl.Factory changeCheckerFactory) { super(configuration.index().numStripedLocks()); this.indexer = indexer; this.indexExecutor = indexExecutor; this.oneOffCtx = oneOffCtx; this.changeCheckerFactory = changeCheckerFactory; Index indexConfig = configuration.index(); this.retryInterval = indexConfig != null ? indexConfig.retryInterval() : 0; this.maxTries = indexConfig != null ? indexConfig.maxTries() : 0; } @Override protected void doIndex(String id, Optional<ChangeIndexEvent> indexEvent) throws IOException { doIndex(id, indexEvent, 0); } private void doIndex(String id, Optional<ChangeIndexEvent> indexEvent, int retryCount) throws IOException { try { ChangeChecker checker = changeCheckerFactory.create(id); Optional<ChangeNotes> changeNotes = checker.getChangeNotes(); if (changeNotes.isPresent()) { ChangeNotes notes = changeNotes.get(); reindex(notes); if (checker.isChangeUpToDate(indexEvent)) { if (retryCount > 0) { return; } retryCount++; try { Thread.sleep(retryInterval); } catch (InterruptedException e) { throw new IOException("Interrupted while waiting to retry indexing", e); } doIndex(id, indexEvent, retryCount); } } } catch (StorageException e) { throw new IOException("Failed to index change " + id, e); } }
ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns(colsProto.toBuilder()) .setOriginalSubject("The first patch set") .setHasOriginalSubject(true) .build()); @Test public void serializeOriginalSubject() throws Exception { assertRoundTrip( newBuilder() .columns(cols.toBuilder().originalSubject("The first patch set").build()) .build(), ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns(colsProto.toBuilder() .setOriginalSubject("The first patch set") .setHasOriginalSubject(true)) .build()); } @Test public void serializeSubmissionId() throws Exception { assertRoundTrip( newBuilder().columns(cols.toBuilder().submissionId("xyz").build()).build(), ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns(colsProto.toBuilder() .setSubmissionId("xyz") .setHasSubmissionId(true)) .build()); } @Test public void serializeAssignee() throws Exception { // code for serializeAssignee test }
public void onProjectDeleted(Event event) { String projectName = event.getProjectName(); logger.atInfo().log("Deleting project '%s'. Will perform a cleanup in Shared-Ref database.", projectName); try { sharedDb.removeProject(projectName); } catch (IOException e) { logger.atSevere().log(String.format("Project '%s' deleted from GIT but it was not able to fully cleanup from Shared-Ref database", projectName), e); } }
public void addChange(String id, Map<Change.Id, ChangeResource> changes) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { addChange(id, changes, null); } public void addChange(String id, Map<Change.Id, ChangeResource> changes, ProjectState projectState) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { addChange(id, changes, projectState, true); } public void addChange(String id, Map<Change.Id, ChangeResource> changes, @Nullable ProjectState projectState, boolean useIndex) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { List<ChangeNotes> matched = useIndex ? changeFinder.find(id) : changeFromNotesFactory(id); List<ChangeNotes> toAdd = new ArrayList<>(changes.size()); boolean canMaintainServer; try { permissionBackend.currentUser().check(GlobalPermission.MAINTAIN_SERVER); canMaintainServer = true; } catch (AuthException | PermissionBackendException e) { canMaintainServer = false; } for (ChangeNotes notes : matched) { if (!changes.containsKey(notes.getChangeId())) { continue; } ChangeResource changeResource = changes.get(notes.getChangeId()); if (projectState != null && !projectState.statePermitsRead()) { continue; } if (!canMaintainServer && !changeResource.getChange().isPrivate()) { continue; } toAdd.add(notes); } addChange(toAdd); }
import java.io.IOException; import java.util.concurrent.ExecutionException; import java.util.concurrent.TimeUnit; @Singleton public class CombinedCheckStateCache { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String NAME = "combined_check_state"; public static Module module() { return new CacheModule() { @Override public void configure() { persist(NAME, CombinedCheckStateCacheKeyProto.class, CombinedCheckState.class) .version(1) .maximumWeight(10000) .diskLimit(-1) .keySerializer(new ProtobufSerializer<>(CombinedCheckStateCacheKeyProto.parser())) .valueSerializer(new EnumCacheSerializer<>(CombinedCheckState.class)) .loader(Loader.class); } }; } @Singleton static class Metrics { // Metrics implementation } }
// Pair of metric and manual counters, to work around the fact that metric classes have no getters. private final Timer1<Boolean> reloadLatency; private final AtomicLongMap<Boolean> reloadCount; @Inject Metrics(MetricMaker metricMaker) { reloadLatency = metricMaker.newTimer( "checks/reload_combined_check_state", new Description("Latency for reloading combined check state") .setCumulative() .setUnit(Units.MILLISECONDS), Field.ofBoolean("updated", "whether reloading resulted in updating the cached value") ); reloadCount = AtomicLongMap.create(); } void recordReload(boolean updated, long elapsed, TimeUnit timeUnit) { reloadLatency.record(updated, elapsed, timeUnit); reloadCount.incrementAndGet(updated); } long getReloadCount(boolean updated) { return reloadCount.get(updated); } private final LoadingCache<CombinedCheckStateCacheKeyProto, CombinedCheckState> cache; private final Loader loader; private final Metrics metrics; @Inject CombinedCheckStateCache( @Named(NAME) LoadingCache<CombinedCheckStateCacheKeyProto, CombinedCheckState> cache, Loader loader, Metrics metrics ) { this.cache = cache; this.loader = loader; this.metrics = metrics; }
void recordReload(boolean dirty, Duration elapsed) { reloadLatency.record(dirty, elapsed.toNanos(), TimeUnit.NANOSECONDS); reloadCount.incrementAndGet(dirty); }
CombinedCheckState newState = loader.load(key); CombinedCheckState oldState = cache.getIfPresent(key); boolean dirty; if (newState != oldState) { dirty = true; cache.put(key, newState); } else { dirty = false; } return newState; finally { if (dirty == null) { dirty = true; } metrics.recordReload(dirty, sw.elapsed(NANOSECONDS), NANOSECONDS); }
assertThat(cache.getStats()).since(start).hasHitCount(1); assertThat(cache.getStats()).since(start).hasMissCount(0); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(0); // Set non-required checker to FAILED, updating combined check state to WARNING. checkOperations.newCheck(CheckKey.create(project, psId, checkerUuid)) .state(CheckState.FAILED) .upsert(); // Incurs reload after updating check state. assertThat(cache.getStats()).since(start).hasHitCount(2); assertThat(cache.getStats()).since(start).hasMissCount(0); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(1); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.WARNING)); assertThat(cache.getStats()).since(start).hasHitCount(3); assertThat(cache.getStats()).since(start).hasMissCount(0);
import org.easymock.EasyMock; import org.junit.Test; public class ChecksSubmitRuleTest extends GerritBaseTests { @Test public void loadingCurrentPatchSetFails() throws Exception { ChecksSubmitRule checksSubmitRule = new ChecksSubmitRule(EasyMock.createStrictMock(CombinedCheckStateCache.class)); ChangeData cd = EasyMock.createStrictMock(ChangeData.class); expect(cd.project()).andReturn(new Project.NameKey("My-Project")); expect(cd.getId()).andReturn(new Change.Id(1)); expect(cd.currentPatchSet()).andThrow(new OrmException("Fail for test")); replay(cd); Collection<SubmitRecord> submitRecords = checksSubmitRule.evaluate(cd, SubmitRuleOptions.defaults()); assertErrorRecord(submitRecords, "failed to load the current patch set of change 1"); } @Test public void getCombinedCheckStateFails() throws Exception { CombinedCheckStateCache cache = EasyMock.createStrictMock(CombinedCheckStateCache.class); expect(cache.reload(anyObject(), anyObject())).andThrow(new OrmException("Fail for test")); replay(cache); ChecksSubmitRule checksSubmitRule = new ChecksSubmitRule(cache); } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.events; import com.google.gson.Gson; import com.google.gson.TypeAdapter; import com.google.gson.TypeAdapterFactory; import com.google.gson.reflect.TypeToken; public final class AutoValueAdapterFactory implements TypeAdapterFactory { @SuppressWarnings("unchecked") @Override public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) { Class<? super T> rawType = type.getRawType(); // TODO: Implement the logic for creating the TypeAdapter return null; } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.events; import com.google.common.base.Supplier; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.inject.Provider; public class GsonEventDeserializerProvider implements Provider<Gson> { @Override public Gson get() { return new GsonBuilder() .registerTypeAdapter(Event.class, new EventDeserializer()) .registerTypeAdapter(Supplier.class, new SupplierSerializer()) .registerTypeAdapter(Supplier.class, new SupplierDeserializer()) .create(); } }
private Change newChange(String changeKey) { Change change = new Change( Change.key(changeKey), Change.id(1000), Account.id(1000), Branch.nameKey(Project.nameKey("myproject"), "mybranch"), new Timestamp(System.currentTimeMillis()) ); return change; }
private static final String REF_NAME = "refs/heads/master"; private static final String SUBMITTER_EMAIL = "some.user@domain.com"; public void refUpdatedEvent() { RefUpdatedEvent event = new RefUpdatedEvent(); RefUpdateAttribute refUpdatedAttribute = new RefUpdateAttribute(); refUpdatedAttribute.refName = REF_NAME; event.refUpdate = createSupplier(refUpdatedAttribute); AccountAttribute accountAttribute = new AccountAttribute(); accountAttribute.email = SUBMITTER_EMAIL; event.submitter = createSupplier(accountAttribute); assertThatJsonMap(event) .containsExactly( "submitter", ImmutableMap.of("email", SUBMITTER_EMAIL), "refUpdate", ImmutableMap.of("refName", REF_NAME), "type", "ref-updated", "eventCreatedOn", 1.2543444E9 ); }
public static CombinedCheckState combine(ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { CheckStateCount checkStateCount = CheckStateCount.create(statesAndRequired); return combine(checkStateCount); } private static CombinedCheckState combine(CheckStateCount checkStateCount) { if (checkStateCount.failedRequiredCount() > 0) { return FAILED; } if (checkStateCount.inProgressOptionalCount() > 0 || checkStateCount.inProgressRequiredCount() > 0) { return IN_PROGRESS; } if (checkStateCount.failedOptionalCount() > 0) { return WARNING; } if (checkStateCount.successfulCount() > 0) { return SUCCESSFUL; } return NOT_RELEVANT; }
public boolean isPassing() { return passing; } @AutoValue public abstract static class CheckStateCount { public static CheckStateCount create(ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { int failedRequiredCount = 0; int failedOptionalCount = 0; int inProgressRequiredCount = 0; int inProgressOptionalCount = 0; int successfulCount = 0; for (Map.Entry<CheckState, Boolean> e : statesAndRequired.entries()) { CheckState state = e.getKey(); if (state.isInProgress()) { if (e.getValue()) { inProgressRequiredCount++; } else { inProgressOptionalCount++; } } else if (state.isFailed()) { if (e.getValue()) { failedRequiredCount++; } else { failedOptionalCount++; } } else if (state.isSuccessful()) { successfulCount++; } } return new AutoValue_CheckStateCount( failedRequiredCount, failedOptionalCount, inProgressRequiredCount, inProgressOptionalCount, successfulCount ); } public abstract int getFailedRequiredCount(); public abstract int getFailedOptionalCount(); public abstract int getInProgressRequiredCount(); public abstract int getInProgressOptionalCount(); public abstract int getSuccessfulCount(); }
public static CheckStateCount create(ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { int failedRequiredCount = 0; int failedOptionalCount = 0; int inProgressRequiredCount = 0; int inProgressOptionalCount = 0; int successfulCount = 0; for (Map.Entry<CheckState, Boolean> entry : statesAndRequired.entries()) { CheckState state = entry.getKey(); if (state.isInProgress()) { if (entry.getValue()) { inProgressRequiredCount++; } else { inProgressOptionalCount++; } } else if (state == CheckState.FAILED) { if (entry.getValue()) { failedRequiredCount++; } else { failedOptionalCount++; } } else if (state == CheckState.SUCCESSFUL) { successfulCount++; } } return new CheckStateCount( failedRequiredCount, failedOptionalCount, inProgressRequiredCount, inProgressOptionalCount, successfulCount ); }
import java.io.IOException; import java.util.Collection; import java.util.Map; import com.google.common.collect.ImmutableMap; import com.google.gerrit.extensions.api.changes.SubmitRuleOptions; import com.google.gerrit.extensions.common.CheckInfo; import com.google.gerrit.extensions.common.SubmitRecord; import com.google.gerrit.server.change.ChangeData; import com.google.gerrit.server.change.SubmitRuleEvaluator; import com.google.gerrit.server.change.SubmitRuleEvaluator.Result; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleEvaluationException; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleEvaluator; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult.Status; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult.Type; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult.Value; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult.Value.Type; import com.google.gerrit.server.change.SubmitRuleEvaluator.RuleResult.Value.ValueCase; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change.SubmitRuleOptions; import com.google.gerrit.server.change
public EnforcePolicy getPolicy(String projectName, String refName); public EnforcePolicy getPolicy(String projectName); default boolean doesRefNeedClusterSynchronisation(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); }
Module sitePathModule = new AbstractModule() { @Override protected void configure() { bind(Path.class).annotatedWith(SitePath.class).toInstance(sitePath); } }; modules.add(sitePathModule); Module configModule = new GerritServerConfigModule(); modules.add(configModule); modules.add(new DropWizardMetricMaker.ApiModule()); return Guice.createInjector(PRODUCTION, LibModuleLoader.loadModules(cfgInjector, LibModuleType.DB_MODULE));
// You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server; /** * Loadable module type for the different Gerrit server injectors. */ public enum LibModuleType { /** * Module for the sysInjector. */ SYS_MODULE("Module"), /** * Module for the dbInjector. */ DB_MODULE("DbModule"); private final String configKey; LibModuleType(String configKey) { this.configKey = configKey; } /** * Returns the module type for loading from gerrit.config. * * @return module type string */ public String getConfigKey() { return configKey; } }
package com.google.gerrit.server; public enum LibModuleType { SYS_MODULE("Module"), DB_MODULE("DbModule"); private final String configKey; LibModuleType(String configKey) { this.configKey = configKey; } public String getConfigKey() { return configKey; } }
@Singleton public class ForwardedIndexAccountHandler extends ForwardedIndexingHandler<Account.Id> { private final AccountIndexer indexer; @Inject ForwardedIndexAccountHandler(AccountIndexer indexer, Configuration config) { super(config.index()); this.indexer = indexer; } @Override protected void doIndex(Account.Id id, Optional<IndexEvent> indexEvent) throws IOException { indexer.index(id); log.atFine().log("Account %s successfully indexed", id); } @Override protected void doDelete(Account.Id id, Optional<IndexEvent> indexEvent) { throw new UnsupportedOperationException("Delete from account index not supported"); } }
import com.google.gerrit.testing.TestTimeUtil; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.gson.reflect.TypeToken; import java.util.Map; import java.util.concurrent.TimeUnit; import org.junit.Before; import org.junit.Test; public class EventJsonTest extends GerritBaseTests { private static final String BRANCH = "mybranch"; private static final String CHANGE_ID = "Ideadbeefdeadbeefdeadbeefdeadbeefdeadbeef"; private static final int CHANGE_NUM = 1000; private static final double CHANGE_NUM_DOUBLE = CHANGE_NUM; private static final String COMMIT_MESSAGE = "This is a test commit message"; private static final String PROJECT = "myproject"; private static final String REF = "refs/heads/" + BRANCH; private static final double TS1 = 1.2543444E9; private static final double TS2 = 1.254344401E9; private static final String URL = "http://somewhere.com"; private final Gson gson = new GsonBuilder() .setPrettyPrinting() .registerTypeAdapter(new TypeToken<Map<String, Object>>() {}.getType(), new StreamEvents.MapDeserializer()) .create(); @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); } @Test public void testEventJson() { // Test code here } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb; import com.google.common.base.MoreObjects; import com.google.common.collect.ImmutableMap; import com.google.common.flogger.FluentLogger; import java.util.HashMap; import java.util.List; import java.util.Map; public class CustomSharedRefEnforcementByProject implements SharedRefEnforcement { private static final String ALL = ".*"; private final Map<String, Map<String, EnforcePolicy>> PREDEF_ENFORCEMENTS; private final FluentLogger logger = FluentLogger.forEnclosingClass(); public CustomSharedRefEnforcementByProject(List<String> enforcementRules) { logger.atInfo().log( String.format("Running with Custom Shared Ref-Db Enforcement Policy with following rules %s", enforcementRules.toString())); this.PREDEF_ENFORCEMENTS = parseDryRunEnforcementsToMap(enforcementRules); } private Map<String, Map<String, EnforcePolicy>> parseDryRunEnforcementsToMap(List<String> dryRunRefEnforcement) { // Implementation details } }
assert (refAndPolicy.length == 2); String refName = refAndPolicy[0].trim().isEmpty() ? ALL : refAndPolicy[0].trim(); Map<String, EnforcePolicy> existingOrDefaultRef = projectAndRefsEnforcements.getOrDefault(projectName, new HashMap<>()); existingOrDefaultRef.put(refName, EnforcePolicy.valueOf(refAndPolicy[1].trim().toUpperCase())); projectAndRefsEnforcements.put(projectName, existingOrDefaultRef); } catch (AssertionError e) { throw e; } return projectAndRefsEnforcements; } @Override public EnforcePolicy getPolicy(String projectName, String refName) { if (isRefToBeIgnoredBySharedRefDb(refName)) { return EnforcePolicy.IGNORED; } return getRefEnforcePolicy(projectName, refName); } private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { if (!PREDEF_ENFORCEMENTS.containsKey(projectName) && PREDEF_ENFORCEMENTS.containsKey(ALL)) { return PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED); } EnforcePolicy policyFromProjectRefOrProjectAllRefs =
private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { if (!PREDEF_ENFORCEMENTS.containsKey(projectName) && PREDEF_ENFORCEMENTS.containsKey(ALL)) { return PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED); } EnforcePolicy policyFromProjectRefOrProjectAllRefs = PREDEF_ENFORCEMENTS.get(projectName).get(refName); if (policyFromProjectRefOrProjectAllRefs == null) { policyFromProjectRefOrProjectAllRefs = PREDEF_ENFORCEMENTS.get(projectName).get(ALL); } return MoreObjects.firstNonNull(policyFromProjectRefOrProjectAllRefs, EnforcePolicy.REQUIRED); }
private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { return Optional.ofNullable(PREDEF_ENFORCEMENTS.get(projectName)) .map(enforcements -> enforcements.getOrDefault(refName, PREDEF_ENFORCEMENTS.get(ALL).get(refName))) .orElse(PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED)); }
boolean isUpToDate(String project, Ref ref) throws IOException { return compareAndCreate(project, ref); } boolean isMostRecentRefVersion(String project, Ref ref) throws IOException { // implementation here } boolean compareAndCreate(String project, Ref newRef) throws IOException { return compareAndPut(project, NULL_REF, newRef); } boolean compareAndPut(String project, Ref oldRef, Ref newRef) throws IOException { // implementation here }
/** * Compare a reference, and delete if it matches. * * @param project project name of the ref * @param oldRef the old reference information that was previously read. * @return true if the remove was successful; false otherwise. * @throws java.io.IOException the reference could not be removed due to a system error. */ boolean compareAndRemove(String project, Ref oldRef) throws IOException; /** * Acquires a lock on the specified reference. * * @param projectName the name of the project * @param ref the reference to lock * @return an AutoCloseable object representing the lock * @throws IOException if an I/O error occurs while acquiring the lock */ AutoCloseable lockRef(String projectName, Ref ref) throws IOException; /** * Determines if a reference should be ignored in the SharedRefDatabase. * * @param refName the name of the reference * @return true if the reference should be ignored; false otherwise */ default boolean ignoreRefInSharedDb(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } /** * Verifies if the DB contains a value for the specific project and ref name. * * @param project the name of the project * @param refName the name of the reference * @return true if the DB contains a value for the project and ref name; false otherwise */ boolean contains(String project, String refName);
boolean compareAndRemove(String projectName, Ref oldRef) throws IOException; AutoCloseable lockRef(String projectName, Ref ref) throws IOException; default boolean ignoreRefInSharedDb(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } boolean containsValue(String projectName, String refName);
import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.recipes.atomic.AtomicValue; import org.apache.curator.framework.recipes.atomic.DistributedAtomicValue; import org.apache.curator.framework.recipes.locks.InterProcessMutex; import org.apache.curator.framework.recipes.locks.Locker; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; public class ZkSharedRefDatabase implements SharedRefDatabase { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CuratorFramework client; private final RetryPolicy retryPolicy; private final SharedRefEnforcement refEnforcement; private final Long transactionLockTimeOut; @Inject public ZkSharedRefDatabase( CuratorFramework client, ZkConnectionConfig connConfig, SharedRefEnforcement refEnforcement) { this.client = client; this.retryPolicy = connConfig.curatorRetryPolicy; this.transactionLockTimeOut = connConfig.transactionLockTimeout; this.refEnforcement = refEnforcement; } @Override public boolean isMostRecentRefVersion(String project, Ref ref) throws IOException { if (!exists(project, ref.getName())) { logger.atWarning().log( "Ref %s does not exist in project %s", ref.getName(), project); return false; } try (Locker locker = new InterProcessMutex(client, getLockPath(project, ref.getName()))) { if (!locker.acquire(transactionLockTimeOut, TimeUnit.MILLISECONDS)) { logger.atWarning().log( "Failed to acquire lock for ref %s in project %s", ref.getName(), project); return false; } ObjectId currentRefObjectId = getObjectId(project, ref.getName()); ObjectId refObjectId = ref.getObjectId(); return currentRefObjectId != null && currentRefObjectId.equals(refObjectId); } catch (Exception e) { logger.atSevere().withCause(e).log( "Failed to check if ref %s is most recent in project %s", ref.getName(), project); return false; } } }
public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } public boolean exists(String projectName, String refName) throws IOException { try { String path = pathFor(projectName, refName); byte[] valueInZk = client.getData().forPath(path); return valueInZk != null; } catch (Exception e) { throw new IOException(String.format("Unable to read data for path %s", pathFor(projectName, refName)), e); } } public boolean isMostRecentRef(Ref ref) throws IOException { if (!sharedDbExists()) { return true; } String path = pathFor(ref.getProject(), ref.getName()); if (!client.checkExists().forPath(path)) { return true; } byte[] valueInZk = client.getData().forPath(path); if (valueInZk == null) { return false; } ObjectId objectIdInZk = readObjectId(valueInZk); return objectIdInZk.equals(ref.getObjectId()); }
@Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean exists(String projectName, String refName) throws IOException { try { return client.checkExists().forPath(pathFor(projectName, refName)) != null; } catch (Exception e) { throw new IOException("Failed to check if path exists in Zookeeper", e); } } public Locker lockRef(String projectName, Ref ref) throws IOException { InterProcessMutex refPathMutex = new InterProcessMutex(client, "/locks" + pathFor(projectName, ref.getName())); try { return new Locker(refPathMutex, transactionLockTimeOut, MILLISECONDS); } catch (Exception e) { throw new IOException("Failed to create lock in ZK", e); } } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { EnforcePolicy enforcementPolicy = refEnforcement.getPolicy(...); // implementation details }
} catch (Exception e) { throw new LockException("Failed to create lock in ZK", e); }
import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate; private final String project; private final RefUpdateValidator.Factory batchRefValidatorFactory; private final RefDatabase refDb; public static interface Factory { MultiSiteBatchRefUpdate create(String project, RefDatabase refDb); } @Inject public MultiSiteBatchRefUpdate( RefUpdateValidator.Factory batchRefValidatorFactory, @Assisted String project, @Assisted RefDatabase refDb) { super(refDb); this.refDb = refDb; this.project = project; this.batchRefUpdate = refDb.newBatchUpdate(); this.batchRefValidatorFactory = batchRefValidatorFactory; } @Override public int hashCode() { return batchRefUpdate.hashCode(); } @Override public boolean equals(Object obj) { return batchRefUpdate.equals(obj); } @Override public void addCommand(ReceiveCommand cmd, ProgressMonitor monitor) { batchRefUpdate.addCommand(cmd, monitor); } @Override public void addCommand(ReceiveCommand cmd, ProgressMonitor monitor, ProposedTimestamp timestamp) { batchRefUpdate.addCommand(cmd, monitor, timestamp); } // Other methods... }
* All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * wim.jongman@remainsoftware.com - initial API and implementation *******************************************************************************/ package org.eclipse.tips.ui.internal; import org.eclipse.swt.widgets.Slider; import org.eclipse.tips.core.TipProvider; /** * Interface for TipProvider listeners. */ @FunctionalInterface public interface ProviderSelectionListener { /** * Is called when the provider is selected in the {@link Slider}. * * @param pProvider the {@link TipProvider} that was selected */ public void selected(TipProvider pProvider); } createCheckManifestTask(tasks, variantScope); // Add a task to create the res values ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_GENERATE_RES_VALUES_TASK, new Recorder.Block<Void>() { @Override public Void call() throws Exception { createGenerateResValuesTask(tasks, variantScope); return null; } }); // Add a task to process the manifest(s) ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_MERGE_MANIFEST_TASK, new Recorder.Block<Object>() { @Override public Void call() throws Exception { createMergeLibManifestsTask(tasks, variantScope); return null; } }); // Add a task to compile renderscript files. ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_CREATE_RENDERSCRIPT_TASK, new Recorder.Block<Void>() { @Override public Void call() throws Exception { createRenderscriptTask(tasks, variantScope); return null; } }); AndroidTask<MergeResources> packageRes = ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_MERGE_RESOURCES_TASK, createCheckManifestTask(tasks, variantScope); // Add a task to create the res values ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_GENERATE_RES_VALUES_TASK, new Recorder.Block<Void>() { @Override public Void call() throws Exception { createGenerateResValuesTask(tasks, variantScope); return null; } }); // Add a task to process the manifest(s) ThreadRecorder.get().record(ExecutionType.LIB_TASK_MANAGER_CREATE_MERGE_MANIFEST_TASK
throws IOException { batchRefValidatorFactory.create(projectName, refDb) .executeBatchUpdateWithValidation(batchRefUpdate, () -> { batchRefUpdate.execute(walk, monitor, options); return null; }); } @Override public void execute(RevWalk walk, ProgressMonitor monitor) throws IOException { batchRefValidatorFactory.create(projectName, refDb) .executeBatchUpdateWithValidation(batchRefUpdate, () -> { batchRefUpdate.execute(walk, monitor); return null; }); } @Override public String toString() { return batchRefUpdate.toString(); }
public RefUpdateValidator(SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; }
} public String getName() { return MoreObjects.firstNonNull(oldRef == null ? null : oldRef.getName(), newRef == null ? null : newRef.getName()); } public boolean hasFailed() { return exception != null; } } protected void executeBatchUpdateWithPolicy(String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy(String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException {
String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { // If ignored we just do the GIT update if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy(String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException { // If ignored we just do the GIT update if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { return gitUpdateFun.apply(); } try { return delegateValidation.apply(gitUpdateFun, refUpdate); } catch (IOException e) { if (e.getClass() == SharedDbSplitBrainException.class) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } }
return; try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy( String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { return gitUpdateFun.apply(); } try { return delegateValidation.apply(gitUpdateFun, refUpdate); } catch (IOException e) { if (e.getClass() == SharedDbSplitBrainException.class) { validationMetrics.incrementSplitBrain(); } logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } return null; }
List<RefPair> refsToUpdate = getRefsPairs(commands) .sorted(comparing(RefPair::hasFailed).reversed()) .collect(Collectors.toList()); if (refsToUpdate.isEmpty()) { return; } if (refsToUpdate.get(0).hasFailed()) { RefPair failedRef = refsToUpdate.get(0); logger.atWarning().withCause(failedRef.exception).log("Failed to fetch ref entries"); throw new IOException("Failed to fetch ref entries" + failedRef.newRef.getName(), failedRef.exception); } Map<ObjectId, Ref> oldRefsMap = refsToUpdate.stream() .collect(Collectors.toMap(refPair -> refPair.newRef.getObjectId(), refPair -> refPair.oldRef)); try (CloseableSet<AutoCloseable> locks = new CloseableSet()) { assertRefPairsAreInSyncWithSharedDb(refsToUpdate, locks); delegateUpdate.apply(); updateSharedRefDbForSuccessfulCommands(batchRefUpdate.getCommands().stream(), oldRefsMap); }
protected RefPair newRefPairFrom(RefUpdate refUpdate) { return new RefPair(refUpdate.getRef(), sharedRefDb.newRef(refUpdate.getName(), refUpdate.getOldObjectId())); }
protected RefPair newRefPairFrom(RefUpdate refUpdate) { return new RefPair(refUpdate.getRef(), refUpdate.getRef()); }
public BatchRefUpdateValidator(SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, String projectName, RefDatabase refDb) { super(sharedRefDb, validationMetrics, refEnforcement, projectName, refDb); }
public RefUpdateValidator(SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; }
public static interface Factory { RefUpdateValidator create(String projectName, RefDatabase refDb); } @Inject public RefUpdateValidator(SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; } protected final SharedRefEnforcement refEnforcement; protected void executeBatchUpdateWithPolicy(String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } public static int calculateGroupByTableCardinality(long memoryBudgetByteSize, int numberOfGroupByColumns, int frameSize) { int tupleByteSize = 4 + 8 * numberOfGroupByColumns; int maxNumberOfTuplesInDataTable = memoryBudgetInBytes / tupleByteSize; int numberOfBits = Math.min(61, numberOfGroupByColumns * 4 * 8); long possibleNumberOfHashEntries = (long) 2 << numberOfBits; return Math.min(maxNumberOfTuplesInDataTable, possibleNumberOfHashEntries); } void join(IFrameTupleAccessor accessorProbe, int tid, IFrameWriter writer) throws HyracksDataException { this.accessorProbe = accessorProbe; boolean matchFound = false; if (tableSize != 0) { int entry = tpcProbe.partition(accessorProbe, tid, tableSize); int offset = 0; do { table.getTuplePointer(entry, offset++, storedTuplePointer); if (storedTuplePointer.frameIndex < 0) break; int bIndex = storedTuplePointer.frameIndex; int tIndex = storedTuplePointer.tupleIndex; accessorBuild.reset(buffers.get(bIndex)); int c =
public Builder setOldRevision(Revision revision) { switch (type) { case DIFF: case LOG: this.oldRevision = revision; break; default: throw new IllegalStateException(String.format("cannot set old revision on %s view", type)); } return this; } public RefUpdateValidator create(String projectName, RefDatabase refDb); @Inject public RefUpdateValidator(SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; } protected void executeBatchUpdateWithPolicy(String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy(String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { return refUpdate.update(); } try { return delegateValidation.apply(refUpdate); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } return RefUpdate.Result.LOCK_FAILURE; } }
try { locks.addResourceIfNotExist(resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); } catch (Exception e) { throw new IOException(String.format("Unable to prepare locks for project %s and reference %s", projectName, nonNullRef.getName()), e); } boolean isInSync; if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInSync = sharedRefDb.isUpToDate(projectName, refPair.oldRef); } else { isInSync = !sharedRefDb.exists(projectName, refPair.getName()); } if (!isInSync) { failWith(new IOException(String.format("Ref '%s' for project '%s' not in sync with shared Ref-Db. Trying to change the Ref-Db from oldRefId '%s' to newRefId '%s'. Aborting batch update.", refPair.getName(), projectName, refPair.oldRef.getObjectId(), refPair.newRef.getObjectId()))); }
import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.RefUpdateStub; import java.io.IOException; import org.eclipse.jgit.lib.ObjectIdRef; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.lib.RefUpdate; import org.eclipse.jgit.lib.RefUpdate.Result; import org.junit.Before; import org.junit.Rule; import org.junit.Test; import org.junit.rules.TestName; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.junit.MockitoJUnitRunner; @RunWith(MockitoJUnitRunner.class) public class MultiSiteRefUpdateTest implements RefFixture { @Mock SharedRefDatabase sharedRefDb; @Mock ValidationMetrics validationMetrics; private final Ref oldRef = new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, A_TEST_REF_NAME, AN_OBJECT_ID_1); private final Ref newRef = new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, A_TEST_REF_NAME, AN_OBJECT_ID_2); @Rule public TestName nameRule = new TestName(); @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); } @Before public void setUp() { // TODO: Add setup code here } @Test public void testRefUpdate() { // TODO: Add test code here } }
if (policy == EnforcePolicy.REQUIRED) { throw e; } } protected RefUpdate.Result doExecuteRefUpdate(RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> refUpdateFunction) throws IOException { try (CloseableSet<AutoCloseable> locks = new CloseableSet<>()) { RefPair refPair = newRefPairFrom(refUpdate); checkIfLocalRefIsUpToDateWithSharedRefDb(refPair.getName(), locks); RefUpdate.Result result = refUpdateFunction.invoke(); if (isSuccessful(result)) { updateSharedDbOrThrowExceptionFor(refPair); } return result; } } protected void updateSharedDbOrThrowExceptionFor(RefPair refPair) throws IOException { // We are not checking refs that should be ignored final EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refPair.getName()); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return; } String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been " + "successfully applied to the local ref '%s' but not to the shared refdb.", projectName, refPair.getName(), refPair.getName()); throw new IOException(errorMessage); }
assertThat(created.ref).isEqualTo(branch.branch()); private void assertCreateFails(BranchNameKey branch, Class<? extends RestApiException> errType, String errMsg) throws Exception { assertCreateFails(branch, null, errType, errMsg); } private void assertCreateFails(BranchNameKey branch, String revision, Class<? extends RestApiException> errType, String errMsg) throws Exception { BranchInput in = new BranchInput(); in.revision = revision; if (errMsg != null) { assertThrows(errType, () -> branch(branch).create(in)); } } private void assertCreateFails(BranchNameKey branch, Class<? extends RestApiException> errType) throws Exception { assertCreateFails(branch, errType, null); }
@Test public void customLabel_DisallowPostSubmit() throws Exception { label.setFunction(NO_OP); label.setAllowPostSubmit(false); P.setFunction(NO_OP); saveLabelConfig(); PushOneCommit.Result r = createChange(); revision(r).review(ReviewInput.approve()); revision(r).submit(); ChangeInfo info = getWithLabels(r); assertPermitted(info, "Code-Review", 2); assertPermitted(info, P.getName(), 0, 1); assertPermitted(info, label.getName()); ReviewInput preSubmitReview = new ReviewInput(); preSubmitReview.label(P.getName(), P.getMax().getValue()); revision(r).review(preSubmitReview); ReviewInput postSubmitReview = new ReviewInput(); postSubmitReview.label(label.getName(), label.getMax().getValue()); ResourceConflictException thrown = assertThrows(ResourceConflictException.class, () -> revision(r).review(postSubmitReview)); assertThat(thrown) .hasMessageThat() .contains("Voting on labels disallowed after submit: " + label.getName()); } @Test public void customLabelWithUserPermissionChange() throws Exception { // Test code here }
staticPath = cdnPath; } else if (canonicalPath != null) { staticPath = canonicalPath; } SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer.ordainAsSafe( staticPath, SanitizedContent.ContentKind.TRUSTED_RESOURCE_URI); Map<String, Object> data = new HashMap<>(); data.put("canonicalPath", canonicalPath); data.put("staticResourcePath", sanitizedStaticPath); data.put("faviconPath", faviconPath); return data; }
String staticPath = ""; if (cdnPath != null) { staticPath = cdnPath; } else if (canonicalPath != null) { staticPath = canonicalPath; } Map<String, Object> data = new HashMap<>(); data.put("canonicalPath", canonicalPath); data.put("staticResourcePath", staticPath); data.put("faviconPath", faviconPath); return data;
// implied. // See the License for the specific language governing permissions and // limitations under the License. package com.vmware.gerrit.owners.common; import static org.junit.Assert.assertEquals; import com.google.gerrit.acceptance.LightweightPluginDaemonTest; import com.google.gerrit.acceptance.Sandboxed; import com.google.gerrit.acceptance.TestPlugin; import com.google.gerrit.extensions.events.GitReferenceUpdatedListener; import com.google.gerrit.reviewdb.client.RefNames; import com.google.inject.AbstractModule; import org.eclipse.jgit.transport.ReceiveCommand.Type; import org.junit.Test; @Sandboxed @TestPlugin( name = "owners-autoassign", sysModule = "com.vmware.gerrit.owners.common.GitRefListenerIT$TestModule") public class GitRefListenerIT extends LightweightPluginDaemonTest { public static class TestModule extends AbstractModule { @Override protected void configure() { bind(GitReferenceUpdatedListener.class).to(TestGitRefListener.class); } } @Test public void shouldNotProcessNoteDbOnlyRefs() { TestGitRefListener gitRefListener = getPluginInstance(TestGitRefListener.class); String aRefChange = RefNames.REFS_CHANGES + "01/01" + RefNames.META_SUFFIX; // Test code goes here } }
public PatchSet fromProto(Entities.PatchSet proto) { PatchSet.Builder builder = PatchSet.builder().id(patchSetIdConverter.fromProto(proto.getId())); builder.setGroups(proto.hasGroups() ? PatchSet.splitGroups(proto.getGroups()) : ImmutableList.of()); builder.setPushCertificate(proto.hasPushCertificate() ? proto.getPushCertificate() : null); builder.setDescription(proto.hasDescription() ? proto.getDescription() : null); // The following fields used to theoretically be nullable in PatchSet, but in practice no // production codepath should have ever serialized an instance that was missing one of these // fields. // // However, since some protos may theoretically be missing these fields, we need to support // them. Populate specific sentinel values for each field as documented in the PatchSet javadoc. return builder.build(); }
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.manager; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.manager.GerritVersionBranch.getBranch; import org.junit.Test; public class GerritVersionBranchTest { @Test public void getBranchReturnsCorrectBranchForVersion() throws Exception { // Regular 2.x versions assertBranch("2.13", "stable-2.13"); assertBranch("2.14", "stable-2.14"); assertBranch("2.15", "stable-2.15"); assertBranch("2.16", "stable-2.16"); // 2.x.y version assertBranch("2.16.10", "stable-2.16"); // 2.x-rcx version assertBranch("2.16-rc1", "stable-2.16"); // 3.0.0 version assertBranch("3.0.0", "stable-3.0"); } }
public void remove(AccessSection section, Permission permission) { if (section != null) { AccessSection a = accessSections.get(section.getName()); a.remove(permission); if (a.getPermissions().size() == 0) { remove(a); } } } return obj; } for (Field f : fields) { if (f.getAnnotation(DefaultInput.class) != null && f.getType() == String.class) { f.setAccessible(true); f.set(obj, value); return obj; } } throw new BadRequestException("Expected JSON object"); } private static Object createInstance(Type type) throws NoSuchMethodException, InstantiationException, IllegalAccessException, InvocationTargetException { if (type instanceof Class) { @SuppressWarnings("unchecked") Class<Object> clazz = (Class<Object>) type; Constructor<Object> c = clazz.getDeclaredConstructor(); c.setAccessible(true); return c.newInstance(); } throw new InstantiationException("Cannot make " + type); } public static long replyJson(@Nullable HttpServletRequest req, HttpServletResponse res, ListMultimap<String, String> config, Object result) throws IOException { TemporaryBuffer.Heap buf = heap(HEAP_EST_SIZE, Integer.MAX_VALUE); buf.write(JSON_MAGIC); Writer w = new BufferedWriter(new OutputStreamWriter(buf, UTF_8)); // Rest of the code... } public void doFilter(HttpServletRequest req, HttpServletResponse res, FilterChain chain) throws IOException, ServletException { try { delegate.doFilter(req, res, chain); } catch (MyRequestFailureException e) { res.setHeader(DefaultErrorHandlingFilter.GITILES_ERROR, e.getReason().toString()); res.sendError(e.getReason().getHttpStatusCode()); } }
protected void initDragAndDrop() { Transfer[] transfers = new Transfer[] { FileTransfer.getInstance() }; DropTarget dropTarget = new DropTarget(viewer, DND.DROP_COPY | DND.DROP_DEFAULT); dropTarget.setTransfer(transfers); dropTarget.addDropListener(new WebBrowserViewDropAdapter(viewer)); } private final static Logger LOG = LoggerFactory.getLogger(PartitionStatsUtil.class); public static TPartitionStats partStatsFromCompressedBytes(byte[] compressedStats, FeFsPartition part) throws ImpalaException { if (compressedStats == null) return null; TCompactProtocol.Factory protocolFactory = new TCompactProtocol.Factory(); TPartitionStats ret = new TPartitionStats(); byte[] decompressed = CompressionUtil.deflateDecompress(compressedStats); if (decompressed == null) { LOG.warn("Error decompressing partition stats for partition: " + part.getPartitionName()); return null; } JniUtil.deserializeThrift(protocolFactory, ret, decompressed); return ret; } private PatchSet getCurrentPatchSet(String changeId) throws Exception { return db.patchSets().get(getChange(changeId).currentPatchSetId()); } private static byte[] toBytes(BinaryResult content) throws Exception { ByteArrayOutputStream os = new ByteArrayOutputStream(); content.writeTo(os); return os.toByteArray(); } private String url() { return "/changes/" + change.getChangeId() + "/edit"; } private EditInfo toEditInfo() throws IOException { RestResponse r = session.get(url()); assertEquals(HttpStatus.SC_OK, r.getStatusCode()); return newGson().fromJson(r.getReader(), EditInfo.class); } protected enum ErrorCode { BLAME_REGION_NOT_FOUND(SC_NOT_FOUND), CANNOT_PARSE_GITILES_VIEW(SC_NOT_FOUND), INCORRECT_PARAMETER(SC_BAD_REQUEST), INCORRECT_OBJECT_TYPE(SC_NOT_FOUND), MARKDOWN_NOT_ENABLED(SC_NOT_FOUND), NOT_AUTHORIZED(SC_UNAUTHORIZED), OBJECT_NOT_FOUND(SC_NOT_FOUND), OBJECT_TOO_LARGE(SC_INTERNAL_SERVER_ERROR), REPOSITORY_NOT_FOUND(SC_NOT_FOUND), SERVICE_NOT_ENABLED(SC_FORBIDDEN), UNSUPPORTED_GITWEB_URL(SC_GONE); private final int statusCode; private ErrorCode(int statusCode) { this.statusCode = statusCode; } public int getStatusCode() { return statusCode; } }
// you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // https://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gitiles; public class MoreAssert { private MoreAssert() {} /** * Simple version of assertThrows that will be introduced in JUnit 4.13. */ public static <T extends Throwable> T assertThrows(Class<T> expected, ThrowingRunnable r) { try { r.run(); throw new AssertionError("Expected " + expected.getSimpleName() + " to be thrown"); } catch (Throwable actual) { if (expected.isAssignableFrom(actual.getClass())) { return (T) actual; } throw new AssertionError("Expected " + expected.getSimpleName() + " to be thrown, but got " + actual.getClass().getSimpleName()); } } }
factory(MultiSiteBatchRefUpdate.Factory.class); factory(RefUpdateValidator.Factory.class); factory(BatchRefUpdateValidator.Factory.class); if (!disableGitRepositoryValidation) { bind(GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); } if (cfg.getZookeeperConfig().getEnforcementRules().isEmpty()) { bind(SharedRefEnforcement.class).to(DefaultSharedRefEnforcement.class).in(Scopes.SINGLETON); } else { bind(SharedRefEnforcement.class).to(CustomSharedRefEnforcementByProject.class).in(Scopes.SINGLETON); } install(new ZkValidationModule(cfg));
private String resolveUrl(URI uri, String link) { String url = cfg.getString("gerrit", null, "canonicalWebUrl"); if (Strings.isNullOrEmpty(url)) { url = uri.toString(); } if (!url.endsWith("/")) { url += "/"; } if (!Strings.isNullOrEmpty(link)) { url += "#" + link; } return url; } void setPluginName(String name) { if (!Strings.isNullOrEmpty(name)) { this.pluginName = name; } } if (!id.isScheme(AccountExternalId.SCHEME_USERNAME) || !username.equals(id.getSchemeRest())) { continue; } String hashedStr = id.getHashedPassword(); if (hashedStr != null && !hashedStr.isEmpty()) { try { return HashedPassword.decode(hashedStr).checkPassword(password); } catch (DecoderException e) { return false; } } String want = id.getPassword(); if (!Strings.isNullOrEmpty(want)) { byte wantBytes[] = want.getBytes(); byte gotBytes[] = password.getBytes(); // Constant-time comparison. return Arrays.areEqual(wantBytes, gotBytes); } return false; // and then query the secondary index for each user but this way is less // efficient. queryPredicate = Predicate.or(AccountPredicates.isActive(), AccountPredicates.isNotActive()); for (AccountState accountState : accountQueryProvider.get().query(queryPredicate)) { Account account = accountState.getAccount(); String out = new StringBuilder() .append(account.getId().toString()) .append(" |") .append(accountState.getUserName().isPresent() ? " " + accountState.getUserName().get() : "") .append(" |") .append(Strings.isNullOrEmpty(account.getFullName()) ? "" : " " + account.getFullName()) .append(" |") .append(Strings.isNullOrEmpty(account.getPreferredEmail()) ? "" : " " + account.getPreferredEmail()) .append(" |") .append(account.isActive() ? " active" : " inactive") .toString(); }
if (args.getSchema().hasField(ChangeField.EXTENSION)) { FileExtensionPredicate extensionPredicate = new FileExtensionPredicate(ext); if (ext.isEmpty()) { RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^.{0}$"); return emptyExtPredicate; } return extensionPredicate; } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException("'onlyextensions' operator is not supported by change index version"); }
Buggy Code: private String getHostPICCoreImagePath() { return androidHostOut + "/framework/core-optimizing-pic.art"; } public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log( "Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } if (mandatoryPlugins.contains(name)) { logger.atInfo().log("Mandatory plugin %s cannot be disabled", name); continue; } logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin"); // In theory we could still unload the plugin even if the rename // failed. However, it would be reloaded on the next server startup, // so we don't bother trying to unload it. continue; } unload(active); } } } Refactored Code: private String getHostCoreImagePathNoArch() { return androidHostOut + "/framework/core.art"; } public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log( "Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } if (mandatoryPlugins.contains(name)) { logger.atInfo().log("Mandatory plugin %s cannot be disabled", name); continue; } logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin
.state(CheckState.FAILED) .upsert(); assertThat(getChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.FAILED)); } @Test public void combinedCheckStateViaQuery() throws Exception { CacheStats start = cloneStats(cache.getStats()); long startReloadsFalse = cache.getReloadCount(false); long startReloadsTrue = cache.getReloadCount(true); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.NOT_RELEVANT)); // Cache hasn't yet populated during update. assertThat(cache.getStats()).since(start).hasHitCount(0); assertThat(cache.getStats()).since(start).hasMissCount(1); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(0); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.NOT_RELEVANT)); assertThat(cache.getStats()).since(start).hasHitCount(1); assertThat(cache.getStats()).since(start).hasMissCount(1); // TODO: Adjust behavior change in the commit message. }
} return EqualsFilePredicate.create(args, file); } @Operator public Predicate<ChangeData> path(String path) { if (path.startsWith("^")) { return new RegexPathPredicate(path); } return new EqualsPathPredicate(FIELD_PATH, path); } @Operator public Predicate<ChangeData> ext(String ext) throws QueryParseException { return extension(ext); } @Operator public Predicate<ChangeData> extension(String ext) throws QueryParseException { if (args.getSchema().hasField(ChangeField.EXTENSION)) { return new FileExtensionPredicate(ext); } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException( "'onlyextensions' operator is not supported by change index version"); }
public MissingMandatoryPluginsException(Collection<String> pluginNames) { super(getMessage(pluginNames)); }
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.plugins; import java.util.Set; /** * Raised when one or more mandatory plugins are missing. */ public class MissingMandatoryPluginsException extends RuntimeException { private static final long serialVersionUID = 1L; public MissingMandatoryPluginsException(Set<String> pluginNames) { super(getMessage(pluginNames)); } public MissingMandatoryPluginsException(Set<String> pluginNames, Throwable why) { super(getMessage(pluginNames), why); } private static String getMessage(Set<String> pluginNames) { return String.format("Cannot find or load the following mandatory plugins: %s", pluginNames); } }
"%s plugin %s, version %s", active == null ? "Loaded" : "Reloaded", loadedPlugin.getName(), loadedPlugin.getVersion()); } } catch (PluginInstallException e) { logger.atWarning().withCause(e.getCause()).log("Cannot load plugin %s", name); } } } Set<String> missingMandatory = Sets.difference(mandatoryPlugins, loadedPlugins); if (!missingMandatory.isEmpty()) { throw new PluginLoaderException("Failed to load mandatory plugins: " + missingMandatory, e); } cleanInBackground(); } private void addAllEntries(Map<String, Path> from, TreeSet<Map.Entry<String, Path>> to) { Iterator<Map.Entry<String, Path>> it = from.entrySet().iterator(); while (it.hasNext()) { Map.Entry<String, Path> entry = it.next(); to.add(new AbstractMap.SimpleImmutableEntry<>(entry.getKey(), entry.getValue())); } } private TreeSet<Map.Entry<String, Path>> jarsFirstSortedPluginsSet( Map<String, Path> activePlugins) {
public void batchAbandon(BatchUpdate.Factory updateFactory, Project.NameKey project, CurrentUser user, Collection<ChangeData> changes, String msgTxt, boolean cleanupAccountPatchReview, NotifyResolver.Result notify) throws RestApiException, UpdateException { if (changes.isEmpty()) { return; } AccountState accountState = user.isIdentifiedUser() ? user.asIdentifiedUser().state() : null; try (BatchUpdate u = updateFactory.create(project, user, TimeUtil.nowTs())) { u.setNotify(notify); for (ChangeData change : changes) { if (!project.equals(change.project())) { throw new ResourceConflictException( String.format("Project name \"%s\" doesn't match \"%s\"", project.get(), change.project().get())); } Change.Id changeId = change.getId(); ChangeUpdate update = u.getChangeUpdate(changeId); update.setChangeMessage(msgTxt); update.setStatus(Change.Status.ABANDONED); if (cleanupAccountPatchReview) { update.setPatchSets(PatchSetUtil.EMPTY); update.setReviewers(Collections.emptySet()); update.setPendingReviewers(Collections.emptySet()); update.setReviewerUpdates(Collections.emptySet()); } if (accountState != null) { update.setAccountState(accountState); } } u.execute(); } }
public static IndexType getIndexType(Injector injector) { Config cfg = injector.getInstance(Key.get(Config.class, GerritServerConfig.class)); return cfg.getEnum("index", null, "type", IndexType.LUCENE); } Refactored Code: return injector.getInstance(Key.get(Config.class, GerritServerConfig.class)).getEnum("index", null, "type", IndexType.LUCENE);
public static IndexType getIndexType(@Nullable Config cfg) { if (cfg == null) { return IndexType.LUCENE; } return cfg.getEnum("index", null, "type", IndexType.LUCENE); }
import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.After; import org.junit.Before; import org.junit.Test; import java.io.ByteArrayOutputStream; import java.io.IOException; import java.sql.Timestamp; import java.util.Collections; import java.util.List; public abstract class AbstractSubmit extends AbstractDaemonTest { @Inject private ChangeNotes.Factory notesFactory; @Inject private ApprovalsUtil approvalsUtil; @Inject private IdentifiedUser.GenericFactory factory; @Inject ChangeHooks hooks; @Before public void setUp() throws Exception { CurrentUser listenerUser = factory.create(user.id); hooks.addChangeListener(new ChangeListener() { @Override public void onChangeEvent(ChangeEvent event) { if (event instanceof ChangeMergedEvent) { setLatestMergeResult(((ChangeMergedEvent)event).mergeResult.revision); } } }, listenerUser); project = new Project.NameKey("p2"); } @After public void cleanup() { db.close(); } } Boolean isPrivate = null; Boolean wip = null; if (!updated.isEmpty()) { edit = getEditValue(); isPrivate = getPrivateValue(); wip = getWipValue(); } for (String commit : commitSequence) { if (created.get(commit) != null) { addCreatedMessage(created.get(commit), " *NEW*"); } else if (updated.get(commit) != null) { addReplacedMessage(updated.get(commit), edit, isPrivate, wip); } } addMessage(""); private void addCreatedMessage(CreateRequest c) { addMessage(changeFormatter.newChange(ChangeReportFormatter.Input.builder().setChange(c.change).build()) + suffix); } private void addReplacedMessage(ReplaceRequest u, boolean edit, Boolean isPrivate, Boolean wip) { String subject; if (edit) { try { subject = receivePack.getRevWalk().parseCommit(u.newCommitId).getShortMessage(); } catch (IOException e) { // Log and fall back to original change subject } } } try (Repository repo = new FileRepository(uri.getPath())) { repo.create(true /* bare */); if (head !=
import com.google.inject.Provides; import com.google.inject.ProvisionException; import com.google.inject.Singleton; import org.eclipse.jgit.lib.Config; import java.util.Collection; import java.util.Set; /** * Module for non-indexer-specific secondary index setup. * <p> * This module should not be used directly except by specific secondary indexer * implementations (e.g. Lucene). */ public class IndexModule extends LifecycleModule { public enum IndexType { LUCENE } public static final ImmutableCollection<SchemaDefinitions<?>> ALL_SCHEMA_DEFS = ImmutableList.<SchemaDefinitions<?>>of( AccountSchemaDefinitions.INSTANCE, ChangeSchemaDefinitions.INSTANCE, GroupSchemaDefinitions.INSTANCE); /** * Type of secondary index. */ public static IndexType getIndexType(Injector injector) { Config cfg = injector.getInstance(Key.get(Config.class, GerritServerConfig.class)); return cfg.getEnum("index", null, "type", IndexType.LUCENE); } private final int threads; private final ListeningExecutorService interactiveExecutor; private final ListeningExecutorService batchExecutor; public IndexModule(int threads) { this.threads = threads; this.interactiveExecutor = null; this.batchExecutor = null; } @Override protected void configure() { bind(ChangeIndexCollection.class).in(Singleton.class); bind(ChangeIndexer.class).in(Singleton.class); bind(IndexRewriter.class).in(Singleton.class); } @Provides @Singleton public ChangeIndexDefintion provideChangeIndexDefinition() { return new ChangeIndexDefintion(); } @Provides @Singleton public Set<ChangeIndexDefintion> provideChangeIndexDefinitions(ChangeIndexDefintion changeIndexDefintion) { return ImmutableSet.of(changeIndexDefintion); } @Provides @Singleton public ChangeIndexCollection provideChangeIndexCollection(Set<ChangeIndexDefintion> changeIndexDefinitions) { return new ChangeIndexCollection(changeIndexDefinitions); } @Provides @Singleton public ChangeIndexer provideChangeIndexer(ChangeIndexCollection changeIndexCollection) { return changeIndexCollection.getSearchIndex(); } @Provides @Singleton public IndexRewriter provideIndexRewriter(ChangeIndexCollection changeIndexCollection) { return changeIndexCollection.getIndexRewriter(); } }
private final DynamicItem<UrlFormatter> urlFormatter; private final Optional<Schedule> schedule; private final long abandonAfter; private final boolean abandonIfMergeable; private final String abandonMessage; @Inject ChangeCleanupConfig(@GerritServerConfig Config cfg, DynamicItem<UrlFormatter> urlFormatter) { this.urlFormatter = urlFormatter; schedule = ScheduleConfig.createSchedule(cfg, SECTION); abandonAfter = readAbandonAfter(cfg); abandonIfMergeable = cfg.getBoolean(SECTION, null, KEY_ABANDON_IF_MERGEABLE, true); abandonMessage = readAbandonMessage(cfg); } private long readAbandonAfter(Config cfg) { long abandonAfter = ConfigUtil.getTimeUnit(cfg, SECTION, null, KEY_ABANDON_AFTER, 0, TimeUnit.MILLISECONDS); return abandonAfter >= 0 ? abandonAfter : 0; } private String readAbandonMessage(Config cfg) { String abandonMessage = cfg.getString(SECTION, null, KEY_ABANDON_MESSAGE); return Strings.isNullOrEmpty(abandonMessage) ? DEFAULT_ABANDON_MESSAGE : abandonMessage; } public Optional<Schedule> getSchedule() { return schedule; } public long getAbandonAfter() { return abandonAfter; }
Project.NameKey key = projectOperations.newProject().create(); ProjectConfig projectConfig = projectOperations.project(key).getProjectConfig(); ProjectState cachedProjectState1 = projectCache.checkedGet(key); assertThat(cachedProjectState1).isNotNull(); assertThat(cachedProjectState1.getProject().getDescription()).isEmpty(); assertThat(projectConfig.getProject().getDescription()).isEmpty(); projectConfig.getProject().setDescription("my fancy project"); ProjectState cachedProjectState2 = projectCache.checkedGet(key); assertThat(cachedProjectState2).isSameInstanceAs(cachedProjectState1); assertThat(cachedProjectState2.getProject().getDescription()).isEmpty(); @Test public void getProjectConfigNoRefsMetaConfig() throws Exception { Project.NameKey key = projectOperations.newProject().create(); deleteRefsMetaConfig(key); ProjectConfig projectConfig = projectOperations.project(key).getProjectConfig(); assertThat(projectConfig.getName()).isEqualTo(key); assertThat(projectConfig.getRevision()).isNull(); } @Test public void getConfig() throws Exception { Project.NameKey key = projectOperations.newProject().create(); }
public IterableSubject sections() { isNotNull(); return check("getSections()").that(config.getSections()); }
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.common; import static java.lang.annotation.ElementType.FIELD; import static java.lang.annotation.ElementType.METHOD; import static java.lang.annotation.ElementType.TYPE; import static java.lang.annotation.RetentionPolicy.RUNTIME; import java.lang.annotation.Retention; import java.lang.annotation.Target; /** * A marker to say a method/type/field is added or public solely because it is called from inside a * project or an organisation using Gerrit. */ @Target({METHOD, TYPE, FIELD}) @Retention(RUNTIME) public @interface UsedAt { /** * Enumeration of projects that call a method/type/field. */ enum Project { GOOGLE, PLUGIN_CHECKS, PLUGIN_DELETE_PROJECT, PLUGIN_SERVICEUSER, PLUGINS_ALL // Use this project if a method/type is generally made available to all plugins. } /** Reference to the project that uses the method annotated with this annotation. */ Project value(); }
public int compare(RevisionInfo a, RevisionInfo b) { return num(a) - num(b); } final ReviewResult result = new ReviewResult(); final PatchSet patch = db.patchSets().get(patchSetId); final Change.Id changeId = patchSetId.getParentKey(); final ChangeControl control = changeControlFactory.validateFor(changeId); result.setChangeId(changeId); if (patch == null) { throw new NoSuchChangeException(changeId); } List<SubmitRecord> submitResult = control.canSubmit(db, patchSetId); if (submitResult.isEmpty()) { throw new IllegalStateException("ChangeControl.canSubmit returned empty list"); } for (SubmitRecord submitRecord : submitResult) { switch (submitRecord.status) { case OK: if (!control.getRefControl().canSubmit()) { result.addError(new ReviewResult.Error(ReviewResult.Error.Type.SUBMIT_NOT_PERMITTED)); } break; case NOT_READY: StringBuilder errMsg = new StringBuilder(); for (SubmitRecord.Label lbl : submitRecord.labels) { switch (lbl.status) { case OK: break; case REJECT: // Handle reject case break; } } break; } } public void run() { try { final SharedLockResponse response = requestHandler.handleRequest(request); log.handle(Priority.INFO, "response = " + response.toString()); if (response.isSucessful()) { log.handle(Priority.INFO, requestType + " was successfull"); } else { log.handle(Priority.INFO, requestType + " is not successfull"); } String responseString = Helper.toJson(response); asyncResponse.resume(Response.ok(responseString, MediaType.APPLICATION_JSON).build()); } catch (Exception e) { log.error("handleRequest Exception", e); asyncResponse.resume(Response.ok("handleRequest Exception", MediaType.APPLICATION_JSON).build()); } } // Other code... boolean requestRunway(PushOne op) { synchronized (stateLock) { if (op.wasCanceled()) { return false; } pending.remove(op.getURI()); if (inFlight.containsKey(op.getURI())) { return false; } inFlight.put(op.getURI(), op); } return true; } void notifyFinished(PushOne op) { synchronized (stateLock) { inFlight.remove(op.getURI());
public class DeleteGpgKey implements RestModifyView<GpgKey, Input> { private static final Logger log = LoggerFactory.getLogger(DeleteGpgKey.class); public static class Input {} private final Provider<PersonIdent> serverIdent; private final Provider<PublicKeyStore> storeProvider; private final ExternalIdsUpdate.User externalIdsUpdateFactory; private final DeleteKeySender.Factory deleteKeySenderFactory; @Inject DeleteGpgKey( @GerritPersonIdent Provider<PersonIdent> serverIdent, Provider<PublicKeyStore> storeProvider, ExternalIdsUpdate.User externalIdsUpdateFactory, DeleteKeySender.Factory deleteKeySenderFactory) { this.serverIdent = serverIdent; this.storeProvider = storeProvider; this.externalIdsUpdateFactory = externalIdsUpdateFactory; this.deleteKeySenderFactory = deleteKeySenderFactory; } @Override public Response<?> apply(GpgKey rsrc, Input input) throws ResourceConflictException, PGPException, OrmException, IOException, ConfigInvalidException { PGPPublicKey key = rsrc.getKeyRing().getPublicKey(); externalIdsUpdateFactory .create() .delete( rsrc.getUser().getAccountId(), ExternalId.Key.create( SCHEME_GPGKEY, BaseEncoding.base16().encode(key.getFingerprint()))); // Rest of the method implementation } }
import org.slf4j.LoggerFactory; @Singleton public class PostGpgKeys implements RestModifyView<AccountResource, Input> { public static class Input { public List<String> add; public List<String> delete; } private final Logger log = LoggerFactory.getLogger(getClass()); private final Provider<PersonIdent> serverIdent; private final Provider<CurrentUser> self; private final Provider<PublicKeyStore> storeProvider; private final GerritPublicKeyChecker.Factory checkerFactory; private final AddKeySender.Factory addKeyFactory; private final DeleteKeySender.Factory deleteKeyFactory; private final Provider<InternalAccountQuery> accountQueryProvider; private final ExternalIds externalIds; private final ExternalIdsUpdate.User externalIdsUpdateFactory; @Inject PostGpgKeys( @GerritPersonIdent Provider<PersonIdent> serverIdent, Provider<CurrentUser> self, Provider<PublicKeyStore> storeProvider, GerritPublicKeyChecker.Factory checkerFactory, AddKeySender.Factory addKeyFactory, DeleteKeySender.Factory deleteKeyFactory, Provider<InternalAccountQuery> accountQueryProvider, ExternalIds externalIds, ExternalIdsUpdate.User externalIdsUpdateFactory) { this.serverIdent = serverIdent; this.self = self; this.storeProvider = storeProvider; this.checkerFactory = checkerFactory; this.addKeyFactory = addKeyFactory; this.deleteKeyFactory = deleteKeyFactory; this.accountQueryProvider = accountQueryProvider; this.externalIds = externalIds; this.externalIdsUpdateFactory = externalIdsUpdateFactory; } }
case NEW: case FAST_FORWARD: case FORCED: if (!addedKeys.isEmpty()) { try { addKeyFactory.create(user, addedKeys).send(); } catch (EmailException e) { log.error( "Cannot send GPG key added message to " + user.getAccount().getPreferredEmail(), e); } } if (!toRemove.isEmpty()) { try { deleteKeyFactory.create(user, toRemove.stream().map(Fingerprint::toString).collect(toList())).send(); } catch (EmailException e) { log.error( "Cannot send GPG key deleted message to " + user.getAccount().getPreferredEmail(), e); } } break; case NO_CHANGE: break; case IO_FAILURE: case LOCK_FAILURE: case NOT_ATTEMPTED: case REJECTED: case REJECTED_CURRENT_BRANCH: case RENAMED: case REJECTED_MISSING_OBJECT: case REJECTED_OTHER_REASON: default: // TODO(dborowitz): Backoff and retry on LOCK_FAILURE.
import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.errors.RepositoryNotFoundException; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class DeleteSshKey implements RestModifyView<AccountResource.SshKey, Input> { private static final Logger log = LoggerFactory.getLogger(DeleteSshKey.class); public static class Input {} private final Provider<CurrentUser> self; private final PermissionBackend permissionBackend; private final VersionedAuthorizedKeys.Accessor authorizedKeys; private final SshKeyCache sshKeyCache; private final DeleteKeySender.Factory deleteKeyFactory; @Inject DeleteSshKey( Provider<CurrentUser> self, PermissionBackend permissionBackend, VersionedAuthorizedKeys.Accessor authorizedKeys, SshKeyCache sshKeyCache, DeleteKeySender.Factory deleteKeyFactory) { this.self = self; this.permissionBackend = permissionBackend; this.authorizedKeys = authorizedKeys; this.sshKeyCache = sshKeyCache; this.deleteKeyFactory = deleteKeyFactory; } @Override public Response<?> apply(AccountResource.SshKey rsrc, Input input) throws AuthException, OrmException, RepositoryNotFoundException, IOException, ConfigInvalidException, PermissionBackendException { // Implementation goes here } }
import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.reviewdb.client.AccountSshKey; import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import java.util.List; public class DeleteKeySender extends OutgoingEmail { public interface Factory { DeleteKeySender create(IdentifiedUser user, AccountSshKey sshKey); DeleteKeySender create(IdentifiedUser user, List<String> gpgKeys); } private final PermissionBackend permissionBackend; private final IdentifiedUser callingUser; private final IdentifiedUser user; private final AccountSshKey sshKey; private final List<String> gpgKeys; @AssistedInject public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.sshKey = sshKey; } }
import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import java.util.List; public class DeleteKeySender extends OutgoingEmail { public interface Factory { DeleteKeySender create(IdentifiedUser user, AccountSshKey sshKey); DeleteKeySender create(IdentifiedUser user, List<String> gpgKeyFingerprints); } private final PermissionBackend permissionBackend; private final IdentifiedUser callingUser; private final IdentifiedUser user; private final AccountSshKey sshKey; private final List<String> gpgKeyFingerprints; @AssistedInject public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeyFingerprints = null; this.sshKey = sshKey; } @AssistedInject public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted List<String> gpgKeyFingerprints) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeyFingerprints = gpgKeyFingerprints; this.sshKey = null; } }
public DeleteKeySender(EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeys = Collections.emptyList(); this.sshKey = sshKey; }
public DeleteKeySender(EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted List<String> gpgKeys) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeys = gpgKeys; this.sshKey = null; }
public DeleteKeySender(EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted List<String> gpgKeys) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeys = gpgKeys; this.sshKey = null; }
public String getKeyType() { if (sshKey != null) { return "SSH"; } else if (gpgKeys != null) { return "GPG"; } throw new IllegalArgumentException("Unknown key type"); }
public String getGpgKeys() { if (gpgKeys != null) { return Joiner.on("\n").join(gpgKeys); } return null; }
return TestPermission.builder().name(name).action(PermissionRule.Action.ALLOW); } /** Start a builder for denying a permission. */ public static TestPermission.Builder deny(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.DENY); } /** Start a builder for blocking a permission. */ public static TestPermission.Builder block(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.BLOCK); } /** * Records a permission to be updated. * * <p>Not used for permissions that have ranges (label permissions) or global capabilities. */ @AutoValue public abstract static class TestPermission { private static Builder builder() { return new AutoValue_TestProjectUpdate_TestPermission.Builder().force(false); } abstract String name(); abstract String ref(); abstract AccountGroup.UUID group(); abstract PermissionRule.Action action(); abstract boolean force(); /** Builder for {@link TestPermission}. */ @AutoValue.Builder public abstract static class Builder {
@AutoValue public abstract static class TestPermission { private static Builder builder() { return new AutoValue_TestProjectUpdate_TestPermission.Builder().force(false); } abstract String name(); abstract String ref(); abstract AccountGroup.UUID group(); abstract PermissionRule.Action action(); abstract boolean force(); @AutoValue.Builder public abstract static class Builder { public abstract Builder name(String name); public abstract Builder ref(String ref); public abstract Builder group(AccountGroup.UUID groupUuid); abstract Builder action(PermissionRule.Action action); public abstract Builder force(boolean force); public abstract TestPermission build(); } }
public void deleteUserBranch_Conflict() throws Exception { projectOperations .project(allUsers) .forUpdate() .add(TestProjectUpdate.allow(Permission.CREATE) .ref(RefNames.REFS_USERS + "*") .group(REGISTERED_USERS)) .add(TestProjectUpdate.allow(Permission.PUSH) .ref(RefNames.REFS_USERS + "*") .group(REGISTERED_USERS)) .update(); ResourceConflictException thrown = assertThrows(ResourceConflictException.class, () -> branch(BranchNameKey.create(allUsers, RefNames.refsUsers(admin.id()))).delete()); assertThat(thrown).hasMessageThat().contains("Not allowed to delete user branch."); } @Test public void deleteGroupBranch_Conflict() throws Exception { allow(allUsers, RefNames.REFS_GROUPS + "*", Permission.CREATE, REGISTERED_USERS); allow(allUsers, RefNames.REFS_GROUPS + "*", Permission.PUSH, REGISTERED_USERS); ResourceConflictException thrown = assertThrows(ResourceConflictException.class, () -> branch(BranchNameKey.create(allUsers, RefNames.refsGroups(admin.id()))).delete()); assertThat(thrown).hasMessageThat().contains("Not allowed to delete group branch."); }
@NoHttpd public class PluginLoaderIT extends AbstractDaemonTest { Description testDescription; @Override protected void beforeTest(Description description) throws Exception { this.testDescription = description; } @Override protected void afterTest() throws Exception {} @Test(expected = MissingMandatoryPluginsException.class) @GerritConfig(name = "plugins.mandatory", value = "my-mandatory-plugin") public void shouldFailToStartGerritWhenMandatoryPluginsAreMissing() throws Exception { super.beforeTest(testDescription); } }
public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log("Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } if (mandatoryPlugins.contains(name)) { logger.atInfo().log("Mandatory plugin %s cannot be disabled", name); continue; } logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin"); // In theory we could still unload the plugin even if the rename // failed. However, it would be reloaded on the next server startup, } } } }
/*******************************************************************************/ package org.eclipse.egit.gitflow.ui.internal; import java.net.MalformedURLException; import java.net.URL; import org.eclipse.egit.ui.Activator; import org.eclipse.jface.resource.ImageDescriptor; /** * Icons for Gitflow integration. */ public class UIIcons { /** Decoration for initialized Gitflow repository. */ public final static ImageDescriptor OVR_GITFLOW; /** base URL */ public final static URL base; static { base = init(); OVR_GITFLOW = map("ovr/git-flow.gif"); //$NON-NLS-1$ } private static ImageDescriptor map(final String icon) { if (base != null) try { return ImageDescriptor.createFromURL(new URL(base, icon)); } catch (MalformedURLException mux) { Activator.logError(UIText.UIIcons_errorLoadingPluginImage, mux); } return ImageDescriptor.getMissingImageDescriptor(); } private static URL init() { try { return new URL(Activator.getDefault().getBundle().getEntry("/"), //$NON-NLS-1$ "icons/"); //$NON-NLS-1$ } catch (MalformedURLException mux) { Activator.logError(UIText.UIIcons_errorLoadingPluginImage, mux); } return null; } }
public void setUp() { globalPluginConfig = new Config(); replicationConfig = new Config(); } private Configuration getConfiguration() { return new Configuration(globalPluginConfig, replicationConfig); } @Test public void testGetIndexThreadPoolSize() throws Exception { assertThat(getConfiguration().index().threadPoolSize()).isEqualTo(DEFAULT_THREAD_POOL_SIZE); globalPluginConfig.setInt(INDEX_SECTION, null, THREAD_POOL_SIZE_KEY, THREAD_POOL_SIZE); assertThat(getConfiguration().index().threadPoolSize()).isEqualTo(THREAD_POOL_SIZE); } @Test public void testGetIndexSynchronize() throws Exception { assertThat(getConfiguration().index().synchronize()).isEqualTo(DEFAULT_SYNCHRONIZE); globalPluginConfig.setBoolean(INDEX_SECTION, null, SYNCHRONIZE_KEY, false); assertThat(getConfiguration().index().synchronize()).isFalse(); globalPluginConfig.setBoolean(INDEX_SECTION, null, SYNCHRONIZE_KEY, true); assertThat(getConfiguration().index().synchronize()).isTrue(); } @Test public void testGetCacheThreadPoolSize() throws Exception { // Add assertions for cache thread pool size here }
drainQueue(droppedEventsQueue); ChangeData change = createChange().getChange(); String project = change.project().get(); int changeNum = change.getId().get(); String changeNotesRef = change.notes().getRefName(); int patchsetNum = change.currentPatchSet().getPatchSetId(); String patchsetRevision = change.currentPatchSet().getRevision().get(); String patchsetRef = change.currentPatchSet().getRefName(); Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue); assertThat(eventsByType.get("change-index")) .containsExactly(createChangeIndexEvent(project, changeNum, getParentCommit(change))); assertThat(eventsByType.get("ref-updated") .stream() .map(e -> ((RefUpdatedEvent) e).getRefName()) .collect(toSet())) .containsAllOf(changeNotesRef, patchsetRef); // 'refs/sequences/changes' not always updated thus not checked List<Event> patchSetCreatedEvents = eventsByType.get("patchset-created"); assertThat(patchSetCreatedEvents).hasSize(1); assertPatchSetAttributes(patchSetCreatedEvents.get(0), project, changeNum, patchsetNum, patchsetRevision, patchsetRef);
import java.util.Arrays; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.commons.lang.StringUtils; import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Configuration { private static final Logger log = LoggerFactory.getLogger(Configuration.class); public static final String PLUGIN_NAME = "multi-site"; static final String INSTANCE_ID_FILE = "instanceId.data"; // common parameters to cache and index sections static final String THREAD_POOL_SIZE_KEY = "threadPoolSize"; static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000; }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.base.Suppliers.memoize; import static com.googlesource.gerrit.plugins.multisite.ConfigurationHelper.getString; import com.google.common.annotations.VisibleForTesting; import com.google.common.base.CaseFormat; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.HashMap;
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.multisite.Configuration.ENABLE_KEY; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KAFKA_PROPERTY_PREFIX; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KAFKA_SECTION; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaPublisher.KAFKA_PUBLISHER_SUBSECTION; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaSubscriber.KAFKA_SUBSCRIBER_SUBSECTION; import org.eclipse.jgit.lib.Config;
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.acceptance.testsuite.project; import com.google.auto.value.AutoValue; import com.google.common.collect.ImmutableList; import com.google.gerrit.acceptance.testsuite.ThrowingConsumer; import com.google.gerrit.common.data.PermissionRule; import com.google.gerrit.reviewdb.client.AccountGroup; @AutoValue public abstract class TestProjectUpdate { /** * Starts a builder for allowing a capability. */ public static TestPermission.Builder allow(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.ALLOW); } /** * Starts a builder for denying a permission. */ public static TestPermission.Builder deny(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.DENY); } /** * Starts a builder for blocking a permission. */ public static TestPermission.Builder block(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.BLOCK); } // Rest of the code... }
import com.google.gerrit.extensions.annotations.Listen; import com.google.gerrit.server.events.CommitReceivedEvent; import com.google.gerrit.server.git.validators.CommitValidationException; import com.google.gerrit.server.git.validators.CommitValidationListener; import com.google.gerrit.server.git.validators.CommitValidationMessage; import com.google.inject.Singleton; @Listen @Singleton public class CommitMessageLengthValidation implements CommitValidationListener { @Override public List<CommitValidationMessage> onCommitReceived(CommitReceivedEvent receiveEvent) throws CommitValidationException { final RevCommit commit = receiveEvent.commit; final AbbreviatedObjectId id = commit.abbreviate(7); List<CommitValidationMessage> messages = new ArrayList<CommitValidationMessage>(); if (65 < commit.getShortMessage().length()) { messages.add(new CommitValidationMessage("(W) " + id.name() + ": commit subject >65 characters; use shorter first paragraph", false)); } int longLineCnt = 0, nonEmptyCnt = 0; for (String line : commit.getFullMessage().split("\n")) { if (!line.trim().isEmpty()) { nonEmptyCnt++; } } return messages; } } assertSubmitter(change3); // Also check submitters for changes submitted via the topic relationship. assertSubmitter(change1); assertSubmitter(change2); } private void assertSubmitter(PushOneCommit.Result change) throws Exception { ChangeInfo info = get(change.getChangeId(), ListChangesOption.MESSAGES); assertThat(info.messages).isNotNull(); Iterable<String> messages = Iterables.transform(info.messages, new Function<ChangeMessageInfo, String>() { @Override public String apply(ChangeMessageInfo in) { return in.message; } }); assertThat(messages).hasSize(3); String last = Iterables.getLast(messages); if (getSubmitType() == SubmitType.CHERRY_PICK) { assertThat(Iterables.getLast(info.messages).message).startsWith("Change has been successfully cherry-picked as "); } else { assertThat(last).isEqualTo("Change has been successfully merged by Administrator"); } } @Override protected void updateProjectInput(ProjectInput in) { in.submitType = getSubmitType(); if (in.useContentMerge == InheritableBoolean.INHERIT) { in.useContentMerge = InheritableBoolean.FALSE; }
import com.google.gerrit.reviewdb.client.RefNames; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.GerritPersonIdent; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import java.io.IOException; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import java.sql.Timestamp; import java.util.HashMap; import java.util.Map; import import java.util.logging.Logger; import org.eclipse.jgit.lib.CommitBuilder; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectInserter; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefUpdate; import org.eclipse.jgit.lib.RefUpdate.Result; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevSort; import org.eclipse.jgit.revwalk.RevWalk; public class MyClass { // Class implementation goes here }
String refName = RefNames.refsUsers(e.getKey()); Ref ref = repo.exactRef(refName); if (ref != null) { rewriteUserBranch(repo, rw, oi, emptyTree, ref, e.getValue()); } else { createUserBranch(repo, oi, emptyTree, e.getKey(), e.getValue()); } i++; if (i % 100 == 0) { LOG.info(String.format("Migrated %d users to schema 146", i)); } } catch (IOException e) { throw new OrmException("Failed to rewrite user branches.", e); } private void rewriteUserBranch(Repository repo, RevWalk rw, ObjectInserter oi, ObjectId emptyTree, Ref ref, Timestamp registeredOn) throws IOException { ObjectId current = createInitialEmptyCommit(oi, emptyTree, registeredOn); rw.reset(); rw.sort(RevSort.TOPO); rw.sort(RevSort.REVERSE, true); rw.markStart(rw.parseCommit(ref.getObjectId())); RevCommit c;
// and the start() methods of each such listener are executed in the // order they are declared. // Makes sure that PluginLoader.start() is executed before the // LuceneIndexModule.start() so that plugins get loaded and the respective // Guice modules installed so that the on-line reindexing will happen // with the proper classes (e.g. group backends, custom Prolog // predicates) and the associated rules ready to be evaluated. modules.add(new PluginModule()); modules.add(new RestApiModule()); modules.add(new GpgModule(config)); modules.add(new StartupChecks.Module()); modules.add(createIndexModule()); modules.add(new WorkQueue.Module()); modules.add(new GerritInstanceNameModule()); modules.add(new CanonicalWebUrlModule() { @Override protected Class<? extends Provider<String>> provider() { return HttpCanonicalWebUrlProvider.class; } });
try { u = new URL(p.substring(0, p.indexOf('!'))); } catch (MalformedURLException e) { FileNotFoundException fnfe = new FileNotFoundException("Not a valid jar file: " + u); fnfe.initCause(e); throw fnfe; } if (!"file".equals(u.getProtocol())) { throw new FileNotFoundException("Cannot extract path from " + u); } // Pop up to the top-level source folder by looking for .buckconfig. dir = Paths.get(u.getPath()); while (!Files.isRegularFile(dir.resolve("WORKSPACE"))) { Path parent = dir.getParent(); if (parent == null) { throw new FileNotFoundException("Cannot find source root from " + u); } dir = parent; } Path ret = dir.resolve(name); if (!Files.exists(ret)) { throw new FileNotFoundException(name + " not found in source root " + dir); } return ret;
protected String getDeleteActions(Id c) { if (!client.adapter().useType()) { return delete(client.adapter().getType(""), c); } return delete(OPEN_CHANGES, c) + delete(CLOSED_CHANGES, c); }
private final boolean useV6Type; private final boolean omitTypeFromSearch; private final String searchFilteringName; private final String indicesExistParam; private final String exactFieldType; private final String stringFieldType; private final String indexProperty; private final String versionDiscoveryUrl; private final String includeTypeNameParam; ElasticQueryAdapter(ElasticVersion version) { this.ignoreUnmapped = false; this.useType = !version.isV6OrLater(); this.useV6Type = version.isV6(); this.omitTypeFromSearch = version.isV7OrLater(); this.versionDiscoveryUrl = version.isV6OrLater() ? "/%s*" : "/%s*/_aliases"; this.searchFilteringName = "_source"; this.indicesExistParam = "?allow_no_indices=false"; this.exactFieldType = "keyword"; this.stringFieldType = "text"; this.indexProperty = "true"; this.includeTypeNameParam = version.isV6() ? "?include_type_name=true" : ""; } public boolean isUseV6Type() { return useV6Type; } public boolean isOmitTypeFromSearch() { return omitTypeFromSearch; } public String getSearchFilteringName() { return searchFilteringName; } public String getIndicesExistParam() { return indicesExistParam; } public String getExactFieldType() { return exactFieldType; } public String getStringFieldType() { return stringFieldType; } public String getIndexProperty() { return indexProperty; } public String getVersionDiscoveryUrl() { return versionDiscoveryUrl; } public String getIncludeTypeNameParam() { return includeTypeNameParam; }
public class ElasticVersion { private String version; public ElasticVersion(String version) { this.version = version; } public static String supportedVersions() { return Joiner.on(", ").join(ElasticVersion.values()); } public boolean isV6() { return isVersion(6); } public boolean isV6OrLater() { return isAtLeastVersion(6); } public boolean isV7OrLater() { return isAtLeastVersion(7); } private boolean isAtLeastVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) >= v; } private boolean isVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) == v; } @Override public String toString() { return version; } }
RawInputUtil.create(HTML_PLUGIN.getBytes(UTF_8)); private static final ImmutableList<String> PLUGINS = ImmutableList.of( "plugin-a.js", "plugin-b.html", "plugin-c.js", "plugin-d.html", "plugin_e.js" ); @Inject private RequestScopeOperations requestScopeOperations; @Inject private MandatoryPluginsCollection mandatoryPluginsCollection; @Test @GerritConfig(name = "plugins.allowRemoteAdmin", value = "true") public void pluginManagement() throws Exception { // No plugins are loaded assertThat(list().get()).isEmpty(); assertThat(list().all().get()).isEmpty(); PluginApi api; // Install all the plugins InstallPluginInput input = new InstallPluginInput(); for (String plugin : PLUGINS) { input.raw = plugin.endsWith(".js") ? JS_PLUGIN_CONTENT : HTML_PLUGIN_CONTENT; api = gApi.plugins().install(plugin, input); assertThat(api).isNotNull(); PluginInfo info = api.get(); // Perform assertions on the installed plugin } }
public TestLabelPermission build() { TestLabelPermission result = autoBuild(); checkLabelName(result.name()); return result; }
"queryLimit", "+0..+" + DEFAULT_MAX_QUERY_LIMIT + " group global:Registered-Users"); } @Test public void removePermission() throws Exception { Project.NameKey key = projectOperations.newProject().create(); projectOperations .project(key) .forUpdate() .add(TestProjectUpdate.allow(Permission.ABANDON).ref("refs/foo").group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .containsKey("abandon"); projectOperations .project(key) .forUpdate() .remove(TestProjectUpdate.permissionKey(Permission.ABANDON).ref("refs/foo").group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .doesNotContainKey("abandon"); } @Test public void removeLabelPermission() throws Exception { Project.NameKey key = projectOperations.newProject().create(); projectOperations .project(key) .forUpdate() .add(TestProjectUpdate.allowLabel("Code-Review").ref("refs/foo").group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .containsKey("label-Code-Review"); projectOperations .project(key) .forUpdate() .remove(TestProjectUpdate.permissionKey("label-Code-Review").ref("refs/foo").group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .doesNotContainKey("label-Code-Review"); }
private void rcpt(@Nullable RecipientType type, String email, boolean expected) { if (recipients.get(type).contains(email) != expected) { failWithoutActual(fact(expected ? "should notify" : "shouldn't notify", type + ": " + users.emailToName(email))); } if (expected) { accountedFor.add(email); } }
private static String formatDate(PersonIdent author) { SimpleDateFormat df = new SimpleDateFormat("EEE, dd MMM yyyy HH:mm:ss Z", Locale.US); df.setCalendar(Calendar.getInstance(author.getTimeZone(), Locale.US)); return df.format(author.getWhen()); } private boolean isFullMatch(Account.Id id, String nameOrEmail) { Optional<AccountState> account = byId.get(id); return account.isPresent() && Objects.toString(account.get().getAccount().getFullName(), "") .trim() .equalsIgnoreCase(nameOrEmail) || account.get() .getExternalIds() .stream() .anyMatch(extId -> getSchemeRest(extId.key().scheme(), extId.key().get()) .trim() .equalsIgnoreCase(nameOrEmail)); } // of C Git's format-patch .append("From: ").append(author.getName()).append(" <") .append(author.getEmailAddress()).append(">\n") .append("Date: ").append(formatDate(author)).append('\n') .append("Subject: [PATCH] ").append(subject).append('\n') .append('\n').append(msg); if (!msg.endsWith("\n")) { b.append('\n'); } return b.append("---\n\n").toString(); r.assertNoContent(); assertThat(projectDir.exists()).isFalse(); @Test @UseLocalDisk public void testSshDeleteProjectWithoutOptions() throws Exception { createChange(); String cmd = Joiner.on(" ").join(PLUGIN, "delete", project.get()); String expected = String.format( "Really delete '%s'?\n" + "This is an operation which permanently deletes data. This cannot be undone!\n" + "If you are sure you wish to delete this project, re-run with the --yes-really-delete flag.\n\n", project.get()); adminSshSession.exec(cmd); assertThat(projectDir.exists()).isTrue(); assertThat(adminSshSession.getError()).isEqualTo(expected); } @Test @UseLocalDisk public void testSshDeleteProjYesReallyDelete() throws Exception { createChange(); String cmd = createDeleteCommand(project.get()); String expected = String.format( "Project '%s' has open changes. - To really delete '%s', re-run with the --force", project.get(), project.get()); adminSshSession.exec(cmd); assertThat(adminSshSession.getError()).isEqualTo(expected); }
// // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.schema; import com.google.common.collect.Iterables; import com.google.common.collect.Sets; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.client.RefNames; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.GerritPersonIdent; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import java.io.IOException; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import java.sql.Timestamp; import java.time.Duration; import java.time.Instant; import java.util.Date; import java.util.HashMap; import java.util.List; public class SchemaUpdater { @Inject public SchemaUpdater(Provider<ReviewDb> dbProvider, GitRepositoryManager repoManager, AllUsersName allUsersName, GerritPersonIdent gerritIdent) { this.dbProvider = dbProvider; this.repoManager = repoManager; this.allUsersName = allUsersName; this.gerritIdent = gerritIdent; } public void update() throws OrmException, IOException, SQLException { try (ReviewDb db = dbProvider.get(); Statement stmt = ((JdbcSchema) db).getConnection().createStatement()) { // Update account IDs updateAccountIds(db, stmt); } } private void updateAccountIds(ReviewDb db, Statement stmt) throws SQLException { ResultSet rs = stmt.executeQuery("SELECT account_id FROM accounts"); HashMap<Account.Id, Account.Id> accountIds = new HashMap<>(); while (rs.next()) { Account.Id oldId = new Account.Id(rs.getInt(1)); Account.Id newId = Account.Id.create(); accountIds.put(oldId, newId); } rs.close(); for (Account.Id oldId : accountIds.keySet()) { Account.Id newId = accountIds.get(oldId); stmt.executeUpdate("UPDATE accounts SET account_id = " + newId.get() + " WHERE account_id = " + oldId.get()); stmt.executeUpdate("UPDATE account_external
assertThat(accountState.getAccount().getFullName()).isEqualTo(fullName); AccountInfo info = gApi.accounts().id(accountId.get()).get(); assertThat(info.name).isEqualTo(fullName); List<EmailInfo> emails = gApi.accounts().id(accountId.get()).getEmails(); assertThat(emails.stream().map(e -> e.email).collect(toSet())).containsExactly(extId.email()); RevCommit commitUserBranch = projectOperations.project(allUsers).getHead(RefNames.refsUsers(accountId)); RevCommit commitRefsMetaExternalIds = projectOperations.project(allUsers).getHead(RefNames.REFS_EXTERNAL_IDS); assertThat(commitUserBranch.getCommitTime()) .isEqualTo(commitRefsMetaExternalIds.getCommitTime()); } finally { TestTimeUtil.useSystemTime(); } } @Test public void updateNonExistingAccount() throws Exception { Account.Id nonExistingAccountId = Account.id(999999); AtomicBoolean consumerCalled = new AtomicBoolean(); Optional<AccountState> accountState = accountsUpdateProvider .get() .update(nonExistingAccountId, account -> consumerCalled.set(true)); assertThat(accountState).isEmpty(); assertThat(consumerCalled).isFalse(); }
private int populateCombo() { int width = 0; String lastResourceClassId = getDialogSettings().get("resourceClass"); //$NON-NLS-1$ int index = -1; int i = 0; GC gc = new GC(fResourceClassCombo); for (i = 0; i < resourceClasses.length; ++i) { String description = resourceClasses[i].getHumanDescription(); width = Math.max(width, gc.textExtent(description).x); fResourceClassCombo.add(description); if (resourceClasses[i].getId().equals(lastResourceClassId)) index = i; } if (index != -1) { fResourceClassId = lastResourceClassId; fResourceClassCombo.select(index); } if (width == 0) { width = gc.textExtent("Shared memory regions").x; //$NON-NLS-1$ } }
import com.google.gwt.event.shared.HandlerRegistration; import com.google.gwt.user.client.DOM; import com.google.gwt.user.client.Window; import com.google.gwt.user.client.ui.FlowPanel; import net.codemirror.lib.CodeMirror; import net.codemirror.lib.Configuration; import net.codemirror.lib.ModeInjector; import java.util.ArrayList; import java.util.List; public class CodeMirrorDemo extends Screen { private static final int HEADER_FOOTER = 60 + 15 * 2 + 38; private final PatchSet.Id base; private final PatchSet.Id revision; private final String path; private DiffTable diffTable; private CodeMirror cmA; private CodeMirror cmB; private HandlerRegistration resizeHandler; public CodeMirrorDemo(PatchSet.Id base, PatchSet.Id revision, String path) { this.base = base; this.revision = revision; this.path = path; } @Override protected void onInitUI() { super.onInitUI(); add(editorContainer = new FlowPanel()); } @Override protected void onLoad() { super.onLoad(); } }
metaRef3, "refs/heads/master", "refs/tags/master-tag", "refs/users/00/1000000/edit-" + cd3.getId() + "/1", "refs/users/01/1000001/edit-" + cd3.getId() + "/1"); } @Test public void uploadPackSubsetOfRefsVisibleWithAccessDatabase() throws Exception { projectOperations .project(allProjects) .forUpdate() .add(allowCapability(GlobalCapability.ACCESS_DATABASE).group(REGISTERED_USERS)) .add(deny(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(admin.id()); gApi.changes().id(cd3.getId().get()).edit().create(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( // Change 1 is visible due to accessDatabase capability, even though // refs/heads/master is not. psRef1, metaRef1, psRef2, metaRef2, psRef3, metaRef3, psRef4, metaRef4,
ProjectConfig allProjectsConfig = projectConfigFactory.create(allProjectsName); allProjectsConfig.load(md); LabelType cr = Util.codeReview(); allProjectsConfig.getLabelSections().put(cr.getName(), cr); allProjectsConfig.commit(md); repoManager.createRepository(parentKey).close(); repoManager.createRepository(localKey).close(); try (MetaDataUpdate md = metaDataUpdateFactory.create(localKey)) { ProjectConfig newLocal = projectConfigFactory.create(localKey); newLocal.load(md); newLocal.getProject().setParentName(parentKey); newLocal.commit(md); } requestContext.setContext(() -> null); } @After public void tearDown() throws Exception { requestContext.setContext(null); } @Test public void ownerProject() throws Exception { projectOperations .project(localKey) .forUpdate() .add(allow(OWNER).ref("refs/*").group(ADMIN)) .update(); assertAdminsAreOwnersAndDevsAreNot(); } @Test public void denyOwnerProject() throws Exception { projectOperations .project(localKey) .forUpdate()
projectOperations.project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .update(); ProjectControl u = user(localKey, DEVS); assertCannotUpdate("refs/heads/master", u); @Test public void unblockMoreSpecificRefInLocal_Fails() throws Exception { projectOperations.project(parentKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .update(); ProjectControl u = user(localKey, DEVS); assertCannotUpdate("refs/heads/master", u); } @Test public void unblockMoreSpecificRefWithExclusiveFlag() throws Exception { projectOperations.project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .setExclusiveGroup(permissionKey(PUSH).ref("refs/heads/master"), true) .update();
private final PerformCreateProject.Factory createProjectFactory; private final Provider<ProjectsCollection> projectsCollection; private final Provider<GroupsCollection> groupsCollection; private final ProjectJson json; private final String name; @Inject CreateProject(PerformCreateProject.Factory performCreateProjectFactory, Provider<ProjectsCollection> projectsCollection, Provider<GroupsCollection> groupsCollection, ProjectJson json, @Assisted String name) { this.createProjectFactory = performCreateProjectFactory; this.projectsCollection = projectsCollection; this.groupsCollection = groupsCollection; this.json = json; this.name = name; } @Override public Object apply(TopLevelResource resource, Input input) throws BadRequestException, UnprocessableEntityException, ProjectCreationFailedException { if (input == null) { input = new Input(); } if (input.name != null && !name.equals(input.name)) { throw new BadRequestException("name must match URL"); } final CreateProjectArgs args = new CreateProjectArgs(); args.setProjectName(name); if (!Strings.isNullOrEmpty(input.parent)) { args.newParent = projectsCollection.get().parse(input.parent).getProject(); } args.createEmptyCommit = input.createEmptyCommit; args.permissionsOnly = input.permissionsOnly; args.projectDescription = input.projectDescription; args.projectState = input.projectState; args.pluginConfigValues = input.pluginConfigValues; args.submitType = input.submitType; args.branch = input.branch; args.branches = input.branches; args.contributorAgreements = input.contributorAgreements; args.signedOffBy = input.signedOffBy; args.contentMerge = input.contentMerge; args.changeIdRequired = input.changeIdRequired; args.maxObjectSizeLimit = input.maxObjectSizeLimit; args.submitType = input.submitType; args.useContributorAgreements = input.useContributorAgreements; args.useContentMerge = input.useContentMerge; args.useSignedOffBy = input.useSignedOffBy; args.useContentMerge = input.useContentMerge; args.useSignedOffBy = input.useSignedOffBy; args.useContributorAgreements = input.useContributorAgreements; args.useSignedOffBy = input.useSignedOffBy; args.useContentMerge = input.useContentMerge; args.useContributorAgreements = input.useContributorAgreements;
package com.google.gerrit.index.query; import static com.google.common.base.Preconditions.checkNotNull; import com.google.common.collect.ImmutableList; import java.util.Iterator; import java.util.function.Supplier; /** * Result set that allows for asynchronous execution of the actual query. Callers should dispatch * the query and call the constructor of this class with a supplier that fetches the result and * blocks on it if necessary. * <p> * If the execution is synchronous or the results are known a-priori, consider using {@link * ListResultSet}. */ public class LazyResultSet<T> implements ResultSet<T> { private final Supplier<ImmutableList<T>> resultsCallback; private boolean resultsReturned = false; public LazyResultSet(Supplier<ImmutableList<T>> r) { resultsCallback = checkNotNull(r, "results can't be null"); } @Override public Iterator<T> iterator() { return toList().iterator(); } @Override public ImmutableList<T> toList() { if (resultsReturned) { throw new IllegalStateException("Results already obtained"); } resultsReturned = true; return resultsCallback.get(); } }
public LazyResultSet(Supplier<ImmutableList<T>> r) { resultsCallback = requireNonNull(r, "results can't be null"); }
public ListResultSet(List<T> r) { results = ImmutableList.copyOf(Objects.requireNonNull(r, "results can't be null")); }
@Test public void testCapabilityAllowsZeroRangeOnCapabilityThatHasRange() throws Exception { TestCapability c = allowCapability(QUERY_LIMIT) .group(REGISTERED_USERS) .range(0, 0) .build(); assertThat(c.min()).isEqualTo(0); assertThat(c.max()).isEqualTo(0); } @Test public void testCapabilityDisallowsInvertedRange() throws Exception { assertThrows(RuntimeException.class, () -> allowCapability(ADMINISTRATE_SERVER) .group(REGISTERED_USERS) .range(1, 0) .build()); } @Test public void testCapabilityDisallowsRangeIfCapabilityDoesNotSupportRange() throws Exception { assertThrows(RuntimeException.class, () -> allowCapability(ADMINISTRATE_SERVER) .group(REGISTERED_USERS) .range(-1, 1) .build()); } @Test public void testCapabilityRangeIsZeroIfCapabilityDoesNotSupportRange() throws Exception { TestCapability c = allowCapability(ADMINISTRATE_SERVER) .group(REGISTERED_USERS) .build(); assertThat(c.min()).isEqualTo(0); assertThat(c.max()).isEqualTo(0); } @Test public void testCapabilityUsesDefaultRangeIfUnspecified() throws Exception { // Test code here }
// limitations under the License. package com.ericsson.gerrit.plugins.highavailability.forwarder.rest; import com.ericsson.gerrit.plugins.highavailability.cache.Constants; import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gerrit.server.events.Event; import com.google.gerrit.server.events.EventDeserializer; import com.google.gerrit.server.events.SupplierDeserializer; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.inject.Singleton; @Singleton final class GsonParser { private final Gson gson = new GsonBuilder() .registerTypeAdapter(Event.class, new EventDeserializer()) .registerTypeAdapter(Supplier.class, new SupplierDeserializer()) .create(); public Gson gson() { return gson; } Object fromJson(String cacheName, String json) { Object key; // Need to add a case for 'adv_bases' switch (cacheName) { case Constants.ACCOUNTS: key = gson.fromJson(Strings.nullToEmpty(json).trim(), Account.Id.class); break; case Constants.GROUPS: key = gson.fromJson(Strings.nullToEmpty(json).trim(), AccountGroup.UUID.class); break; default: throw new IllegalArgumentException("Unknown cache name: " + cacheName); } return key; } }
public class BranchCommitValidator { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CommitValidators.Factory commitValidatorsFactory; private final IdentifiedUser user; private final PermissionBackend.ForProject permissions; private final Project project; private final BranchNameKey branch; private final SshInfo sshInfo; interface Factory { BranchCommitValidator create(ProjectState projectState, BranchNameKey branch, IdentifiedUser user); } public static class Result { static Result create(boolean isValid, List<CommitValidationMessage> messages) { return new Result(isValid, messages); } private final boolean isValid; private final List<CommitValidationMessage> messages; private Result(boolean isValid, List<CommitValidationMessage> messages) { this.isValid = isValid; this.messages = messages; } public boolean isValid() { return isValid; } public List<CommitValidationMessage> messages() { return messages; } } @Inject public BranchCommitValidator(CommitValidators.Factory commitValidatorsFactory, PermissionBackend permissionBackend, SshInfo sshInfo) { this.commitValidatorsFactory = commitValidatorsFactory; this.user = user; this.permissions = permissions; this.project = project; this.branch = branch; this.sshInfo = sshInfo; } }
static Result create(boolean isValid, List<CommitValidationMessage> messages) { return new AutoValue_BranchCommitValidator_Result(isValid, ImmutableList.copyOf(messages)); }
@AutoValue public static abstract class Result { static Result create(boolean isValid, List<CommitValidationMessage> messages) { return new AutoValue_BranchCommitValidator_Result(isValid, messages); } /** Whether the commit is valid. */ abstract boolean isValid(); /** A list of messages related to the validation. Messages may be present regardless of the {@link #isValid()} status. */ abstract List<CommitValidationMessage> messages(); } @Inject BranchCommitValidator( CommitValidators.Factory commitValidatorsFactory, PermissionBackend permissionBackend, SshInfo sshInfo, @Assisted ProjectState projectState, @Assisted BranchNameKey branch, @Assisted IdentifiedUser user) { this.sshInfo = sshInfo; this.user = user; this.branch = branch; this.commitValidatorsFactory = commitValidatorsFactory; project = projectState.getProject(); permissions = permissionBackend.user(user).project(project.getNameKey()); } /** * Validates a single commit. If the commit does not validate, the command is rejected. */
if (args.getSchema().hasField(ChangeField.EXTENSION)) { FileExtensionPredicate extensionPredicate = new FileExtensionPredicate(ext); if (ext.isEmpty()) { RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^.{0}$"); return emptyExtPredicate; } return extensionPredicate; } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException("'onlyextensions' operator is not supported by change index version"); } @Operator
ChecksCollection(Checks checks, DynamicMap<RestView<CheckResource>> views, ListChecks listChecks) { this.checks = checks; this.views = views; this.listChecks = listChecks; } @Override public RestReadView<RevisionResource> list() throws RestApiException { return listChecks; } @Override public CheckResource parse(RevisionResource parent, IdString id) throws RestApiException, PermissionBackendException, IOException, StorageException { if (parent.getEdit().isPresent()) { throw new ResourceConflictException("checks are not supported on edit"); } CheckerUuid checkerUuid = CheckerUuid.tryParse(id.get()) .orElseThrow(() -> new BadRequestException(String.format("invalid checker UUID: %s", id.get()))); CheckKey checkKey = CheckKey.create(parent.getProject(), parent.getPatchSet().id(), checkerUuid); Optional<Check> check = checks.getCheck(checkKey, GetCheckOptions.withBackfilling()); return new CheckResource(parent, check.orElseThrow(() -> new ResourceNotFoundException( String.format("check not found for checker UUID: %s", id.get())))); }
@Inject Schema_146(Provider<Schema_145> prior, GitRepositoryManager repoManager, AllUsersName allUsersName, @GerritPersonIdent PersonIdent serverIdent) { super(prior); this.repoManager = repoManager; this.allUsersName = allUsersName; this.serverIdent = serverIdent; } @Override protected void migrateData(ReviewDb db, UpdateUI ui) throws OrmException, SQLException { ui.message("Migrating accounts"); gc(ui); Set<Entry<Account.Id, Timestamp>> accounts = scanAccounts(db, ui).entrySet(); Set<List<Entry<Account.Id, Timestamp>>> batches = Sets.newHashSet(Iterables.partition(accounts, 500)); ExecutorService pool = createExecutor(ui); try { batches.stream().forEach(batch -> pool.submit(() -> processBatch(batch, ui))); pool.shutdown(); pool.awaitTermination(Long.MAX_VALUE, TimeUnit.DAYS); } catch (InterruptedException e) { throw new RuntimeException(e); } ui.message(String.format("... (%.3f s) Migrated all %d accounts to schema 146", elapsed(), i.get())); }
import com.google.common.cache.CacheBuilder; import com.google.common.cache.Cache; import java.util.concurrent.TimeUnit; public class VisibilityCache { private final Cache<Object, Object> cache; public VisibilityCache(boolean topoSort) { this(topoSort, defaultBuilder()); } public VisibilityCache(boolean topoSort, CacheBuilder<Object, Object> builder) { this(new VisibilityChecker(topoSort), builder); } public VisibilityCache(VisibilityChecker checker) { this(checker, defaultBuilder()); } public VisibilityCache(VisibilityChecker checker, CacheBuilder<Object, Object> builder) { this.cache = builder.build(); } public static CacheBuilder<Object, Object> defaultBuilder() { return CacheBuilder.newBuilder().maximumSize(1 << 10).expireAfterWrite(30, TimeUnit.MINUTES); } }
import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevSort; import org.eclipse.jgit.revwalk.RevWalk; /** * Checks for object visibility * * <p>Objects are visible if they are reachable from any of the references visible to the user. */ public class VisibilityChecker { private boolean topoSort; /** * Constructs a VisibilityChecker. * * @param topoSort whether to use a more thorough reachability check by sorting in topological order */ public VisibilityChecker(boolean topoSort) { this.topoSort = topoSort; } /** * Check if any of the refs in {@code refDb} points to the object {@code id}. * * @param refDb a reference database * @param id object we are looking for * @return true if any of the references in the db points directly to the id * @throws IOException if the reference space cannot be accessed */ public boolean checkVisibility(RefDatabase refDb, ObjectId id) throws IOException { RevWalk revWalk = new RevWalk(refDb.getRepository()); revWalk.setRevFilter(RevSort.TOPO); revWalk.markStart(revWalk.parseCommit(id)); for (Ref ref : refDb.getRefs()) { RevCommit commit = revWalk.parseCommit(ref.getObjectId()); if (revWalk.isMergedInto(commit, revWalk.parseCommit(id))) { return true; } } return false; } }
import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.JUnit4; @RunWith(JUnit4.class) public class VisibilityCacheTest { private InMemoryRepository repo; private GitilesAccess access = new FakeGitilesAccess(); private RevCommit baseCommit; private RevCommit commit1; private RevCommit commit2; private RevCommit commitA; private RevCommit commitB; private RevCommit commitC; private VisibilityCache visibilityCache; private RevWalk walk; @Before public void setUp() throws Exception { repo = new InMemoryRepository(new DfsRepositoryDescription()); TestRepository<InMemoryRepository> git = new TestRepository<>(repo); baseCommit = git.commit().message("baseCommit").create(); commit1 = git.commit().parent(baseCommit).message("commit1").create(); commit2 = git.commit().parent(commit1).message("commit2").create(); commitA = git.commit().parent(baseCommit).message("commitA").create(); commitB = git.commit().parent(commitA).message("commitB").create(); commitC = git.commit().parent(commitB).message("commitC").create(); } }
private final byte reserved3; private final int itemflags; private int itemexpiry; private final int vbucketstate; private final byte[] key; private final byte[] value; private final byte[] revid; /** * Creates a ResponseMessage from binary data. * @param buffer The binary data sent from the tap stream server. */ public ResponseMessage(byte[] b) { super(b); if (!opcode.equals(TapOpcode.NOOP)) { engineprivate = decodeShort(b, ENGINE_PRIVATE_OFFSET); flags = TapFlag.getFlags(decodeShort(b, FLAGS_OFFSET)); ttl = b[TTL_OFFSET]; reserved1 = b[RESERVED1_OFFSET]; reserved2 = b[RESERVED2_OFFSET]; reserved3 = b[RESERVED3_OFFSET]; } else { engineprivate = 0; flags = new LinkedList<TapFlag>(); ttl = 0; reserved1 = 0; reserved2 = 0; reserved3 = 0; } } for (String line : lines) { int c = line.indexOf(": "); if (c < 0) { rec = new SubmitRecord(); submitRecords.add(rec); int s = line.indexOf(' '); String statusStr = s >= 0 ? line.substring(0, s) : line; Optional<SubmitRecord.Status> status = Enums.getIfPresent(SubmitRecord.Status.class, statusStr); checkFooter(status.isPresent(), FOOTER_SUBMITTED_WITH, line); rec.status = status.get(); if (s >= 0) { rec.errorMessage = line.substring(s); } } else { checkFooter(rec != null, FOOTER_SUBMITTED_WITH, line); SubmitRecord.Label label = new SubmitRecord.Label(); if (rec.labels == null) { rec.labels = Lists.newArrayList(); } rec.labels.add(label); Optional<SubmitRecord.Label.Status> status = Enums.getIfPresent( SubmitRecord.Label.Status.class, line.substring(0, c)); checkFooter(status.isPresent(), FOOTER_SUBMITTED_WITH, line); } } public boolean provides(IOperation operation) { CreateEditPoliciesOperation epOperation = (CreateEditPoliciesOperation) operation; if (!(epOperation.getEditPart() instanceof IGraphicalEditPart)) { return false; } IGraphicalEditPart gep = (IGraphicalEdit
static void call(final Button b, final String project) { b.setEnabled(false); ChangeApi.createChange(project, "refs/meta/config", Util.C.editConfigMessage(), null, new GerritCallback<ChangeInfo>() { @Override public void onSuccess(ChangeInfo result) { Gerrit.display(Dispatcher.toEditScreen(new PatchSet.Id(result.legacy_id(), 1), "project.config")); } @Override public void onFailure(Throwable caught) { b.setEnabled(true); super.onFailure(caught); } }); } private Injector createSysInjector() { final List<Module> modules = new ArrayList<>(); modules.add(SchemaVersionCheck.module()); modules.add(new DropWizardMetricMaker.RestModule()); modules.add(new LogFileCompressor.Module()); if (onlineReindexMode) { modules.add(new PluginModule()); } } public NameAlreadyUsedException(String name) { super(MESSAGE + ": " + name); } package com.ericsson.gerrit.plugins.highavailability.forwarder.rest; import com.ericsson.gerrit.plugins.highavailability.cache.Constants; import com.google.common.base.Strings; import com.google.gerrit.reviewdb.client.Account; import com.google.gson.Gson; import com.google.gson.JsonElement; import com.google.gson.JsonObject; import com.google.inject.Inject; import com.google.inject.Singleton; @Singleton class GsonParser { private final Gson gson; @Inject GsonParser(GsonProvider gson) { this.gson = gson.get(); } public Object fromJson(String cacheName, String jsonString) { JsonElement json = gson.fromJson(Strings.nullToEmpty(jsonString), JsonElement.class); Object key; if (!json.isJsonObject()) { return json.getAsString(); } JsonObject asJsonObject = json.getAsJsonObject(); switch (cacheName) { case Constants.ACCOUNTS: key = asJsonObject.has("id") ? Account.id(asJsonObject.get("id").getAsInt()) : null; break; // other cases... } // other code... } }
import java.io.File; import java.util.ArrayList; import java.util.Arrays; import java.util.List; public class CheckConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String toolName = "check_new_config"; private static final String ACCESS = "access"; private static final String LABEL = "label"; private static final String PLUGIN = "plugin"; private static final int BUFFER_SIZE = 2048; private String pluginName; private Config configProject; private ScannerConfig scannerConfig; public CheckConfig(String pluginName, String projectConfigContents) throws ConfigInvalidException { this.pluginName = pluginName; configProject = new Config(); configProject.fromText(projectConfigContents); Config config = new Config(); for (String name : configProject.getNames(PLUGIN, pluginName)) { config.setStringList(PLUGIN, pluginName, name, Arrays.asList(configProject.getStringList(PLUGIN, pluginName, name))); } PluginConfig pluginConfig = new PluginConfig(pluginName, config); } public void checkFile(File file) { char[] buffer = new char[BUFFER_SIZE]; // perform file checking using the buffer } }
public class CheckConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String toolName = "check_new_config"; private static final String ACCESS = "access"; private static final String LABEL = "label"; private static final String PLUGIN = "plugin"; private static final int BUFFER_SIZE = 2048; private static final char[] BUFFER = new char[BUFFER_SIZE]; private String pluginName; private Config configProject; ScannerConfig scannerConfig; public CheckConfig(String pluginName, String projectConfigContents) throws ConfigInvalidException { this.pluginName = pluginName; configProject = new Config(); configProject.fromText(projectConfigContents); Config config = new Config(); for (String name : configProject.getNames(PLUGIN, pluginName)) { config.setStringList(PLUGIN, pluginName, name, Arrays.asList(configProject.getStringList(PLUGIN, pluginName, name))); } PluginConfig pluginConfig = new PluginConfig(pluginName, config); } }
public class MDNSFilterPlugin { private String mName; private CharSequence mPackageName; private List<String> mMDNSNames; private MDNSFilteredDiscovery mMDNSFilteredDiscovery; public MDNSFilterPlugin(@NonNull Context context, @NonNull String name, @NonNull CharSequence packageName, @NonNull List<String> mDNSNames) { mName = context.getResources().getIdentifier(name, null, "com.android.printservice.recommendation"); mPackageName = packageName; mMDNSNames = mDNSNames; mMDNSFilteredDiscovery = new MDNSFilteredDiscovery(context, PRINTER_SERVICE_TYPES, new VendorNameFilter(new HashSet<>(mMDNSNames))); } } public class SomeClass { private Set<LogicalVariable> findFDHeaderVariables(IOptimizationContext context, ILogicalOperator operator) throws AlgebricksException { PhysicalOptimizationsUtil.computeFDsAndEquivalenceClasses((AbstractLogicalOperator) operator, context); List<FunctionalDependency> fds = context.getFDList(operator); context.clearAllFDAndEquivalenceClasses(); Set<LogicalVariable> liveVars = new HashSet<>(); VariableUtilities.getSubplanLocalLiveVariables(operator, liveVars); Set<LogicalVariable> key = new HashSet<>(); Set<LogicalVariable> cover = new HashSet<>(); for (FunctionalDependency fd : fds) { // process functional dependencies } // return the set of covering variables return cover; } } public class SomeOtherClass { private List<Finding> scanCommitMessage(String commitMessage) { List<Finding> findings = new ArrayList<>(); // scan the commit message for copied texts // add findings to the list return findings; } }
import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectLoader; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevTree; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.treewalk.TreeWalk; @Singleton class CopyrightConfig implements CommitValidationListener, RevisionCreatedListener, GitReferenceUpdatedListener { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final long DEFAULT_MAX_ELAPSED_SECONDS = 8; private final Metrics metrics; private final AllProjectsName allProjectsName; private final String pluginName; private final GitRepositoryManager repoManager; private final ProjectCache projectCache; private final PluginConfigFactory pluginConfigFactory; private final CopyrightReviewApi reviewApi; private PluginConfig gerritConfig; private CheckConfig checkConfig; static AbstractModule module() { return new AbstractModule() { @Override protected void configure() { DynamicSet.bind(binder(), CommitValidationListener.class).to(CopyrightConfig.class); } }; } }
if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { clearConfig(); checkConfig = readConfig(event.getNewObjectId()); } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); checkConfig = null; return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); }
private void logError(String message) { logger.atSevere().log(message); } ... String errorMessage = String.format("%s plugin revision %s: error posting review: %s", pluginName, event.getChange().currentRevision, result.error); logError(errorMessage); for (Map.Entry<String, AddReviewerResult> entry : result.reviewers.entrySet()) { AddReviewerResult arr = entry.getValue(); if (!Strings.isNullOrEmpty(arr.error)) { String error = String.format("%s plugin revision %s: error adding reviewer %s: %s", pluginName, event.getChange().currentRevision, entry.getKey(), arr.error); logError(error); } }
private ReviewResult review(ChangeResource change, ReviewInput ri) throws RestApiException { try { PatchSet ps = psUtil.current(change.getNotes()); if (ps == null) { throw new ResourceNotFoundException(IdString.fromDecoded("current")); } RevisionResource revision = RevisionResource.createNonCacheable(change, ps); return revisionApi.review(revision.getPatchSet().getId().get(), ri); } catch (Exception e) { Throwables.throwIfUnchecked(e); throw e instanceof RestApiException ? (RestApiException) e : new RestApiException("Cannot post review", e); } }
private void scanRevision(String project, String branch, RevisionCreatedListener.Event event) throws IOException, RestApiException { Map<String, ImmutableList<Match>> findings = new HashMap<>(); ArrayList<String> containedPaths = new ArrayList<>(); long scanStart = System.nanoTime(); metrics.scanCount.increment(); metrics.scanCountByProject.increment(project); metrics.scanCountByBranch.increment(branch); try (Repository repo = repoManager.openRepository(Project.nameKey(project)); RevWalk revWalk = new RevWalk(repo); TreeWalk tw = new TreeWalk(revWalk.getObjectReader())) { RevCommit commit = repo.parseCommit(ObjectId.fromString(event.getRevision().commit.commit)); tw.setRecursive(true); tw.setFilter(TreeFilter.ANY_DIFF); tw.addTree(commit.getTree()); if (commit.getParentCount() > 0) { // rest of the code } } }
import com.google.gerrit.server.git.validators.ValidationMessage; import com.google.gerrit.server.project.ProjectConfig; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightPatterns; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightPatterns.UnknownPatternName; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightScanner; import java.util.ArrayList; import java.util.Collection; import java.util.LinkedHashSet; import java.util.Objects; import java.util.function.Consumer; import java.util.regex.Pattern; import java.util.regex.PatternSyntaxException; class ScannerConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String KEY_ENABLE = "enable"; static final String KEY_TIME_TEST_MAX = "timeTestMax"; static final String DEFAULT_REVIEW_LABEL = "Copyright-Review"; static final String KEY_REVIEWER = "reviewer"; static final String KEY_CC = "cc"; static final String KEY_FROM = "fromAccountId"; static final String KEY_REVIEW_LABEL = "reviewLabel"; static final String KEY_EXCLUDE = "exclude"; }
} public boolean isV6() { return isVersion(6); } public boolean isV6OrLater() { return isAtLeastVersion(6); } public boolean isV7OrLater() { return isAtLeastVersion(7); } private boolean isAtLeastVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) >= v; } private boolean isVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) == v; } @Override public String toString() { return version; } }
boolean oldForceLogging = loggingCtx.isLoggingForced(); boolean oldPerformanceLogging = loggingCtx.isPerformanceLogging(); ImmutableList<PerformanceLogRecord> oldPerformanceLogRecords = loggingCtx.getPerformanceLogEntries(); loggingCtx.setTags(tags); loggingCtx.forceLogging(forceLogging); loggingCtx.performanceLogging(performanceLogging); loggingCtx.setPerformanceLogEntries(performanceLogRecords); try { runnable.run(); } finally { loggingCtx.setTags(oldTags); loggingCtx.forceLogging(oldForceLogging); loggingCtx.performanceLogging(oldPerformanceLogging); loggingCtx.setPerformanceLogEntries(oldPerformanceLogRecords); }
public void close() { if (LoggingContext.getInstance().isPerformanceLogging()) { runEach(performanceLoggers, LoggingContext.getInstance().getPerformanceLogEntries()); } LoggingContext.getInstance().performanceLogging(oldPerformanceLogging); LoggingContext.getInstance().setPerformanceLogEntries(oldPerformanceLogRecords); }
private byte[] stringToByte(String mediaId) { if (!mHmap.containsValue(mediaId)) { int uid = mHmap.size() + 1; mHmap.put(uid, mediaId); return intToByteArray(uid); } else { for (int key : mHmap.keySet()) { if (mHmap.get(key).equals(mediaId)) { return intToByteArray(key); } } } return null; } return OpenSSLX509Certificate.fromX509PemInputStream(is); } public void test_deletingCTPoisonExtension() throws Exception { OpenSSLX509Certificate cert = loadTestCertificate("cert.pem"); OpenSSLX509Certificate certPoisoned = loadTestCertificate("cert-ct-poisoned.pem"); assertEqualByteArrays( certPoisoned.withDeletedExtension(CT_POISON_EXTENSION).getTBSCertificate(), cert.getTBSCertificate() ); } public void test_deleteExtensionMakesCopy() throws Exception { OpenSSLX509Certificate certPoisoned = loadTestCertificate("cert-ct-poisoned.pem"); assertTrue(certPoisoned.getCriticalExtensionOIDs().contains(CT_POISON_EXTENSION)); OpenSSLX509Certificate certWithoutExtension = certPoisoned.withDeletedExtension(CT_POISON_EXTENSION); assertFalse(certWithoutExtension.getCriticalExtensionOIDs().contains(CT_POISON_EXTENSION)); } .forUpdate() .add(allow(Permission.READ).ref("refs/*").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref(RefNames.REFS_CONFIG).group(REGISTERED_USERS)) .update(); assertUploadPackRefs( "HEAD", psRef1, metaRef1, psRef2, metaRef2, psRef3, metaRef3, psRef4, metaRef4, "refs/heads/branch", "refs/heads/master", RefNames.REFS_CONFIG, "refs/tags/branch-tag", "refs/tags/master-tag" ); @Test public void uploadPackSubsetOfBranchesVisibleIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(allow(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(deny(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update();
@Test public void uploadPackSubsetOfBranchesVisibleIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(allow(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(deny(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( "HEAD", psRef1, metaRef1, psRef3, metaRef3, "refs/heads/master", "refs/tags/master-tag"); } @Test public void uploadPackSubsetOfBranchesVisibleNotIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(deny(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs(psRef2, metaRef2); }
// Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.readonly; import static com.google.common.truth.Truth.assertThat; import com.google.gerrit.acceptance.RestResponse; import com.google.gerrit.server.config.GerritServerConfig; import com.google.gerrit.testutil.ConfigSuite; import com.google.inject.Inject; import org.eclipse.jgit.lib.Config; public class ReadOnlyByHttpIT extends AbstractReadOnlyTest { @ConfigSuite.Default public static Config withPluginNamePrefix() { Config cfg = new Config(); cfg.setString("readonly", "test", "endpoint", "readonly~readonly"); return cfg; } @ConfigSuite.Config public static Config withoutPluginNamePrefix() { Config cfg = new Config(); cfg.setString("readonly", "test", "endpoint", "readonly"); return cfg; } }
} else if (input.httpPassword == null) { newPassword = null; } else { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); newPassword = input.httpPassword; } return apply(rsrc.getUser(), newPassword); public Response<String> apply(IdentifiedUser user, String newPassword) throws ResourceNotFoundException, ResourceConflictException, OrmException, IOException, ConfigInvalidException { String userName = user.getUserName().orElseThrow(() -> new ResourceConflictException("username must be set")); Optional<ExternalId> optionalExtId = externalIds.get(ExternalId.Key.create(SCHEME_USERNAME, userName)); ExternalId extId = optionalExtId.orElseThrow(ResourceNotFoundException::new); accountsUpdateProvider .get() .update("Set HTTP Password via API", extId.accountId(), u -> u.updateExternalId(ExternalId.createWithPassword( extId.key(), extId.accountId(), extId.email(), newPassword))); return Response.ok("Password updated"); }
// included: pA:d2/OWNERS, pA:d2/../f1, pA:d1/f1 // inherited: pA:OWNERS String owners = "owners:[ " + concat(ownerJson("pAd1f1@g"), ", ") + concat(ownerJson("pAd2@g"), ", ") + concat(ownerJson("pAf1@g"), ", ") + concat(ownerJson("pA@g", 0, 1, 0), " ]"); assertThat(getOwnersResponse(c1)).contains(owners);
private void handleGitReferenceUpdatedAsUser(Event event, Account.Id updaterAccountId) { try (ManualRequestContext ctx = oneOffReqCtx.openAs(updaterAccountId)) { handleGitReferenceUpdated(event); } catch (OrmException e) { logger.warn("Unable to process event {} on project {}", event, event.getProjectName(), e); } }
public void onGitReferenceUpdated(Event event) { AccountInfo updaterAccountInfo = event.getUpdater(); CurrentUser currentUser = currentUserProvider.get(); if (currentUser.isIdentifiedUser()) { handleGitReferenceUpdated(event); } else if (updaterAccountInfo != null) { handleGitReferenceUpdatedAsUser(event, new Account.Id(updaterAccountInfo._accountId)); } else { // Handle null case here } }
// For the performance log records, use a thread-safe list instance from the logging context of the calling // thread in the logging context of the new thread. This way, performance log records that are // created from the new thread are available from the logging context of the calling thread. // This is important since performance log records are processed only at the end of the request // and performance log records that are created in another thread should not get lost. loggingCtx.setMutablePerformanceLogRecordList(Collections.synchronizedList(mutablePerformanceLogRecords)); try { return callable.call(); } finally { loggingCtx.setTags(oldTags); loggingCtx.forceLogging(oldForceLogging); loggingCtx.performanceLogging(oldPerformanceLogging); loggingCtx.setPerformanceLogRecords(oldPerformanceLogRecords); }
Fixed Code: ```java @Inject CopyrightConfig( Metrics metrics, AllProjectsName allProjectsName, @PluginName String pluginName, GitRepositoryManager repoManager, ProjectCache projectCache, PluginConfigFactory pluginConfigFactory, CopyrightReviewApi reviewApi ) throws IOException, ConfigInvalidException { this.metrics = metrics; this.allProjectsName = allProjectsName; this.pluginName = pluginName; this.repoManager = repoManager; this.projectCache = projectCache; this.pluginConfigFactory = pluginConfigFactory; this.reviewApi = reviewApi; long nanoStart = System.nanoTime(); try { checkConfig = readConfig(projectCache.getAllProjects().getProject().getConfigRefState()); } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); } } ``` Review: Doing work in a constructor is strongly discouraged. Doing work which throws exceptions such as these and additionally having Guice for DI might cause serious issues (e.g. server can't even start if one of the exceptions is thrown). Please find a different way or tell me if you need further ideas.
throws ConfigInvalidException { metrics = new Metrics(metricMaker); allProjectsName = new AllProjectsName("All-Projects"); pluginName = "copyright"; repoManager = null; projectCache = null; pluginConfigFactory = null; this.reviewApi = reviewApi; checkConfig = new CheckConfig(pluginName, projectConfigContents); } @VisibleForTesting static CopyrightConfig createTestInstance( MetricMaker metricMaker, CopyrightReviewApi reviewApi, String projectConfigContents) throws ConfigInvalidException { return new CopyrightConfig(metricMaker, reviewApi, projectConfigContents); } ScannerConfig getScannerConfig() { return checkConfig.scannerConfig; } @Override public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { // ... } catch (IOException | ConfigInvalidException e) { // ... } }
public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { logger.log(Level.SEVERE, "\n\nonGitRefUpdated\n\n"); checkConfig = readConfig(event.getNewObjectId()); logger.log(Level.SEVERE, "\n\nonGitRefUpdated: '{0}'\n\n", checkConfig); } catch (IOException | ConfigInvalidException e) { logger.log(Level.SEVERE, "{0} plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); } }
public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { logger.atSevere().log("onGitRefUpdated"); checkConfig = readConfig(event.getNewObjectId()); logger.atSevere().log("onGitRefUpdated: '%s'", checkConfig); } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); } }
throw new CmlpDataSrcException("Please provide a predictor", 400); if (!(codeCloudAuthorization != null) && !(codeCloudAuthorization.isEmpty())) { throw new CmlpDataSrcException("Please provide CodeCloudAuthorization header", 400); } if (!(objCatalog.getPublisherUrl() != null) && objCatalog.getPublisherUrl().isEmpty()) { throw new CmlpDataSrcException("Please provide a publisher URL", 400); } try { log.info("RestCatalogServiceImpl::updateCatalog()::intiating update request."); String responseCatalogKey = aCatalogService.updateCatalog(user, authorization, codeCloudAuthorization, catalogKey, objCatalog); log.info("RestCatalogServiceImpl::updateCatalog()::update completed for key: " + responseCatalogKey); URI location = new URI(url + objCatalog.getCatalogKey()); } catch (Exception e) { log.error("Exception in RestCatalogServiceImpl:updateCatalog" + e.getMessage()); aResponseMessage.setCode(500); aResponseMessage.setMessage(e.getMessage()); return Response.status(Status.BAD_REQUEST).entity(aResponseMessage).build(); } import org.eclipse.mylyn.wikitext.parser.builder.HtmlDocumentBuilder; import org.junit.Before; /** * Test base for asciidoc language tests. provides base set-up functionalities, like parsing markup to html * * @author Max Rydahl Andersen */ public abstract class AsciiDocLanguageTestBase { private MarkupParser parser; @Before public void setUp() throws Exception { parser = new MarkupParser(new AsciiDocLanguage()); } public String parseToHtml(String markup) { return parseAsciiDocToHtml(markup, parser); } protected static String parseAsciiDocToHtml(String markup, MarkupParser parser) { StringWriter out = new StringWriter(); HtmlDocumentBuilder builder = new HtmlDocumentBuilder(out); builder.setEmitAsDocument(false); parser.setBuilder(builder); parser.parse(markup); return out.toString(); } } public void set(int index, byte value) { if (index >= len) { throw new IndexOutOfBoundsException(String.format("index: %s, len: %s", index, len)); } data[index] = value; } public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return;
private static class DbsMetadata { public List<String> dbs = Lists.newArrayList(); public List<List<String>> tableNames = Lists.newArrayList(); public List<List<String>> comments = Lists.newArrayList(); public List<List<List<Column>>> columns = Lists.newArrayList(); public List<List<Function>> functions = Lists.newArrayList(); } public void shutdown() { shuttingDown = true; if (process != null) { process.destroy(); log.info("Process stopped"); } } public String cstString() { throw new UnsupportedOperationException("Not supported."); } public String cstComment() { throw new UnsupportedOperationException("Not supported."); } CommentInfo draftInfo = Iterables.getOnlyElement(drafts.get(draft.path)); ReviewInput reviewInput = new ReviewInput(); reviewInput.drafts = DraftHandling.KEEP; reviewInput.message = "foo"; CommentInput comment = newComment(file, Side.REVISION, 0, "comment", false); comment.id = draftInfo.id; reviewInput.comments = new HashMap<>(); reviewInput.comments.put(comment.path, ImmutableList.of(comment)); revision(r).review(reviewInput); drafts = getDraftComments(changeId, revId); assertThat(drafts).isEmpty(); @Test public void listComments() throws Exception { String file = "file"; PushOneCommit push = pushFactory.create(admin.newIdent(), testRepo, "first subject", file, "contents"); PushOneCommit.Result r = push.to("refs/for/master"); String changeId = r.getChangeId(); String revId = r.getCommit().getName(); assertThat(getPublishedComments(changeId, revId)).isEmpty(); }
(metadata, value) -> elementAssertThatFunction.apply(value); return assertThat(optional, valueSubjectFactory); } public static <S extends Subject, T> OptionalSubject<S, T> assertThat(Optional<T> optional, Subject.Factory<S, T> valueSubjectFactory) { return assertAbout(optionals()).thatCustom(optional, valueSubjectFactory); } public static OptionalSubject<Subject, ?> assertThat(Optional<?> optional) { return assertAbout(optionals()) .that(optional, StandardSubjectBuilder::that); } public static CustomSubjectBuilder.Factory<OptionalSubjectBuilder> optionals() { return OptionalSubjectBuilder::new; } private OptionalSubject(FailureMetadata failureMetadata, Optional<T> optional, BiFunction<StandardSubjectBuilder, ? super T, ? extends S> valueSubjectCreator) { super(failureMetadata, optional); this.optional = optional; this.valueSubjectCreator = valueSubjectCreator; } public void isPresent() { isNotNull(); if (!optional.isPresent()) { failWithoutActual(fact("expected to have", "value")); } } public void isAbsent() { isNotNull(); if (optional.isPresent()) { failWithoutActual(fact("expected to be", "absent")); } }
private boolean isAddAccessEnabled() { boolean returnValue; try { if (!SystemGroup.OseeAccessAdmin.isCurrentUserMember() && policyTableViewer.getAccessControlList().size() > 0) { returnValue = AccessControlManager.hasPermission(accessControlledObject, PermissionEnum.FULLACCESS); } else { returnValue = true; } } catch (OseeCoreException ex) { OseeLog.log(Activator.class, Level.SEVERE, ex); returnValue = false; } return returnValue; } gApi.accounts().id(admin.getId().toString()).setPreferences(i); @Test public void userReceivesHtmlAndPlaintextEmail() throws Exception { PushOneCommit.Result r = createChange(); setApiUser(user); gApi.changes() .id(r.getChangeId()) .revision(r.getCommit().name()) .review(ReviewInput.recommend()); assertThat(sender.getMessages()).hasSize(1); FakeEmailSender.Message m = sender.getMessages().get(0); assertThat(m.body()).isNotNull(); assertThat(m.htmlBody()).isNotNull(); assertMailReplyTo(m, admin.email); assertMailReplyTo(m, user.email); } public GeneralPreferencesInfo setDefaultPreferences(GeneralPreferencesInfo in) { throw new NotImplementedException(); } @Override public DiffPreferencesInfo getDefaultDiffPreferences() { throw new NotImplementedException(); } @Override public DiffPreferencesInfo setDefaultDiffPreferences(DiffPreferencesInfo in) { throw new NotImplementedException(); } @Override public ConsistencyCheckInfo checkConsistency(ConsistencyCheckInput in) { throw new NotImplementedException(); } @Override public AccessCheckInfo checkAccess(AccessCheckInput in) throws RestApiException { throw new NotImplementedException(); } public static class OptionalSubjectBuilder extends CustomSubjectBuilder { OptionalSubjectBuilder(FailureMetadata failureMetadata) { super(failureMetadata); } public <S extends Subject, T> OptionalSubject<S, T> thatCustom( Optional<T> optional, Subject.Factory<S, T> valueSubjectFactory) { return that(optional, (builder, value) -> builder.about(valueSubjectFactory).that(value)); } public OptionalSubject<Subject, ?> that(Optional<?> optional) { return that(optional, (builder, value) -> (DefaultSubject) builder.that(value)); } public <S extends Subject, T> OptionalSubject<S
private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final long DEFAULT_MAX_ELAPSED_SECONDS = 8; private final Metrics metrics; private final AllProjectsName allProjectsName; private final String pluginName; private final GitRepositoryManager repoManager; private final ProjectCache projectCache; private final PluginConfigFactory pluginConfigFactory; private final CopyrightReviewApi reviewApi; private @Nullable PluginConfig gerritConfig; private @Nullable CheckConfig checkConfig; static AbstractModule module() { return new AbstractModule() { @Override protected void configure() { DynamicSet.bind(binder(), CommitValidationListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), LifecycleListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), RevisionCreatedListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(CopyrightConfig.class); } }; } @Inject CopyrightConfig( Metrics metrics, AllProjectsName allProjectsName, @PluginName String pluginName, GitRepositoryManager repoManager, ProjectCache projectCache, PluginConfigFactory pluginConfigFactory, CopyrightReviewApi reviewApi ) { this.metrics = metrics; this.allProjectsName = allProjectsName; this.pluginName = pluginName; this.repoManager = repoManager; this.projectCache = projectCache; this.pluginConfigFactory = pluginConfigFactory; this.reviewApi = reviewApi; }
protected boolean showUserInReview; @Column(id = 12) protected boolean relativeDateInChangeTable; @Column(id = 13, length = 20, notNull = false) protected String commentVisibilityStrategy; @Column(id = 14, length = 20, notNull = false) protected String diffView; @Column(id = 15, length = 20, notNull = false) protected String changeScreen; @Column(id = 16) protected boolean sizeBarInChangeTable; @Column(id = 17) protected boolean legacyCIDInChangeTable; public AccountGeneralPreferences() { } public short getMaximumPageSize() { return maximumPageSize; } public void setMaximumPageSize(final short s) { maximumPageSize = s; } public boolean isShowSiteHeader() { return showSiteHeader; } public void setShowSiteHeader(final boolean b) { showSiteHeader = b; } public boolean isUseFlashClipboard() { return useFlashClipboard; } public void setUseFlashClipboard(final boolean b) { useFlashClipboard = b; }
@Nullable private CheckConfig readConfig(String projectConfigObjectId) throws IOException, ConfigInvalidException { CheckConfig checkConfig = null; // new All-Projects project.config not yet in cache -- read from repository ObjectId id = ObjectId.fromString(projectConfigObjectId); if (ObjectId.zeroId().equals(id)) { return checkConfig; } try (Repository repo = repoManager.openRepository(allProjectsName)) { checkConfig = new CheckConfig(pluginName, readFileContents(repo, id, ProjectConfig.PROJECT_CONFIG)); } gerritConfig = pluginConfigFactory.getFromGerritConfig(pluginName, true); return checkConfig; }
Buggy Code: ```java // new All-Projects project.config not yet in cache -- read from repository ObjectId id = ObjectId.fromString(projectConfigObjectId); if (ObjectId.zeroId().equals(id)) { return checkConfig; } try (Repository repo = repoManager.openRepository(allProjectsName)) { checkConfig = new CheckConfig(pluginName, readFileContents(repo, id, ProjectConfig.PROJECT_CONFIG)); } gerritConfig = pluginConfigFactory.getFromGerritConfig(pluginName, true); if (gerritConfig == null) { // throw IllegalStateException? RestApiException? checkConfig.scannerConfig.messages.add( ScannerConfig.hintMessage("missing [plugin \"" + pluginName + "\"] section in gerrit.config")); } else { checkConfig.scannerConfig.defaultEnable = gerritConfig.getBoolean(ScannerConfig.KEY_ENABLE, false); } return checkConfig; } private void logReviewResultErrors(RevisionCreatedListener.Event event, ReviewResult result) { if (!Strings.isNullOrEmpty(result.error)) { logger.atSevere().log(result.error); } } ``` Fixed Code: ```java // new All-Projects project.config not yet in cache -- read from repository ObjectId id = ObjectId.fromString(projectConfigObjectId); if (ObjectId.zeroId().equals(id)) { return checkConfig; } try (Repository repo = repoManager.openRepository(allProjectsName)) { checkConfig = new CheckConfig(pluginName, readFileContents(repo, id, ProjectConfig.PROJECT_CONFIG)); } gerritConfig = pluginConfigFactory.getFromGerritConfig(pluginName, true); if (gerritConfig == null) { throw new RestApiException( HttpStatus.SC_INTERNAL_SERVER_ERROR, "missing [plugin \"" + pluginName + "\"] section in gerrit.config" ); } else { checkConfig.scannerConfig.defaultEnable = gerritConfig.getBoolean(ScannerConfig.KEY_ENABLE, false); } return checkConfig; } private void logReviewResultErrors(RevisionCreatedListener.Event event, ReviewResult result) { if (!Strings.isNullOrEmpty(result.error)) { throw new RestApiException(HttpStatus.SC_INTERNAL_SERVER_ERROR, result.error); } } ```
AddReviewerResult arr = entry.getValue(); if (!Strings.isNullOrEmpty(arr.error)) { logger.atSevere().log( "revision %s: error adding reviewer %s: %s", event.getChange().currentRevision, entry.getKey(), arr.error ); metrics.addReviewerErrors.increment(event.getChange().project); metrics.errors.increment(); } } private String readFileContents(Repository repo, ObjectId objectId, String filename) throws IOException { try (RevWalk rw = new RevWalk(repo)) { RevTree tree = rw.parseTree(objectId); try (TreeWalk tw = TreeWalk.forPath(rw.getObjectReader(), filename, tree)) { ObjectLoader loader = repo.open(tw.getObjectId(0), Constants.OBJ_BLOB); return new String(loader.getCachedBytes(), UTF_8); } } }
private String readFileContents(Repository repo, ObjectId objectId, String filename) throws IOException { RevWalk rw = new RevWalk(repo); RevTree tree = rw.parseTree(objectId); try (TreeWalk tw = TreeWalk.forPath(rw.getObjectReader(), filename, tree)) { if (tw != null) { ObjectLoader loader = repo.open(tw.getObjectId(0), Constants.OBJ_BLOB); return new String(loader.getCachedBytes(), UTF_8); } } return null; }
import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.ZkValidationModule; import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; import java.util.Collection; import java.util.UUID; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class Module extends LifecycleModule { private static final Logger log = LoggerFactory.getLogger(Module.class); private Configuration config; private NoteDbStatus noteDb; private final boolean disableGitRepositoryValidation; @Inject public Module(Configuration config, NoteDbStatus noteDb) { this(config, noteDb, false); } // TODO: It is not possible to properly test the libModules in Gerrit. // Disable the Git repository validation during integration test and then build the necessary // support // in Gerrit for it. @VisibleForTesting public Module( Configuration config, NoteDbStatus noteDb, boolean disableGitRepositoryValidation) { this.config = config; this.noteDb = noteDb; this.disableGitRepositoryValidation = disableGitRepositoryValidation; } }
install(new IndexModule()); if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } install(new MultiSiteValidationModule(config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); if (config.getSharedRefDb().isEnabled()) { install(new ZkValidationModule(config.getSharedRefDb().getZkConfig())); } bind(Gson.class) .annotatedWith(BrokerGson.class) .toProvider(GsonProvider.class) .in(Singleton.class);
import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class ZookeeperConfig { private static final Logger log = LoggerFactory.getLogger(ZookeeperConfig.class); public static final String ZOOKEEPER_MS_CONFIG = "multi-site.config"; public static final int defaultSessionTimeoutMs; public static final int defaultConnectionTimeoutMs; public static final String DEFAULT_ZK_CONNECT = "localhost:2181"; private final int DEFAULT_RETRY_POLICY_BASE_SLEEP_TIME_MS = 1000; private final int DEFAULT_RETRY_POLICY_MAX_SLEEP_TIME_MS = 3000; private final int DEFAULT_RETRY_POLICY_MAX_RETRIES = 3; private final int DEFAULT_CAS_RETRY_POLICY_BASE_SLEEP_TIME_MS = 100; private final int DEFAULT_CAS_RETRY_POLICY_MAX_SLEEP_TIME_MS = 300; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3; }
public ZkValidationModule(ZookeeperConfig cfg) { this.cfg = cfg; this.multiSiteConfig = MultiSiteConfig.getInstance(); }
static { System.setProperty("gerrit.notedb", "ON"); } public static class KafkaTestContainerModule extends LifecycleModule { public static class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) { this.kafka = kafka; } @Override public void stop() { kafka.stop(); } @Override public void start() { // Do nothing } } private final FileBasedConfig multiSiteConfig; private final FileBasedConfig sharedRefConfig; private final Module multiSiteModule; @Inject public KafkaTestContainerModule(SitePaths sitePaths, NoteDbStatus noteDb) { this.multiSiteConfig = new FileBasedConfig( sitePaths.etc_dir.resolve(Configuration.MULTI_SITE_CONFIG).toFile(), FS.DETECTED); this.sharedRefConfig = new FileBasedConfig( sitePaths.etc_dir.resolve(ZookeeperConfig.ZOOKEEPER_MS_CONFIG).toFile(), FS.DETECTED); this.multiSiteModule = new Module( new Configuration(multiSiteConfig, new Config()), new ZookeeperConfig(sharedRefConfig), new KafkaConfig()); } }
import com.google.gerrit.server.change.ChangeResource; import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.update.CommentsRejectedException; import com.google.gerrit.server.update.UpdateException; import com.google.inject.Inject; import com.google.inject.Module; import com.google.inject.Provider; import java.sql.Timestamp; import org.junit.Before; import org.junit.Test; /** * Tests for comment validation in {@link PostReview}. */ @NoHttpd public class PostReviewIT extends AbstractDaemonTest { @Inject private Provider<ChangesCollection> changes; @Inject private Provider<PostReview> postReview; @Inject private RequestScopeOperations requestScopeOperations; @Override public Module createModule() { return new FactoryModule() { @Override public void configure() { bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); } }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception { gApi.changes().id(<the id you want>).current().review(in); } }
import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.update.CommentsRejectedException; import com.google.gerrit.server.update.UpdateException; import com.google.inject.Inject; import com.google.inject.Module; import com.google.inject.Provider; import java.sql.Timestamp; import org.junit.Before; import org.junit.Test; /** Tests for comment validation in {@link PostReview}. */ @NoHttpd public class PostReviewIT extends AbstractDaemonTest { @Inject private Provider<ChangesCollection> changes; @Inject private Provider<PostReview> postReview; @Inject private RequestScopeOperations requestScopeOperations; @Override public Module createModule() { return new FactoryModule() { @Override public void configure() { bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); } }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception { String file = "file"; gApi.changes().id(someid).current().review(ent); } }
public void configure() { bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); }
} }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception { String file = "file"; PushOneCommit.Result r = createChange(); String changeId = r.getChange().changeId; String revId = r.getCommit().getName(); ReviewInput input = new ReviewInput(); ChangeResource changeResource = changes.get().parse(TopLevelResource.INSTANCE, IdString.fromDecoded(changeId)); RevisionResource revisionResource = revisions.parse(changeResource, IdString.fromDecoded(revId)); assertThat(getPublishedComments(changeId)).isEmpty();
private UUID tryToLoadSavedInstanceId(String serverIdFile) { if (Files.exists(Paths.get(serverIdFile))) { try (BufferedReader br = new BufferedReader(new FileReader(serverIdFile))) { return UUID.fromString(br.readLine()); } catch (IOException e) { multisiteLog.warn(String.format("Cannot read instance ID from path '%s', deleting the old file and generating a new ID: (%s)", serverIdFile, e.getMessage())); try { Files.delete(Paths.get(serverIdFile)); } catch (IOException e1) { multisiteLog.warn(String.format("Cannot delete old instance ID file at path '%s' with instance ID while generating a new one: (%s)", serverIdFile, e1.getMessage())); } } } return null; }
protected void configure() { bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getZookeeperConfig().buildCurator()); bind(ZkConnectionConfig.class) .toInstance(new ZkConnectionConfig(cfg.getZookeeperConfig().buildCasRetryPolicy(), cfg.getZookeeperConfig().getZkInterProcessLockTimeOut())); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ProjectDeletedSharedDbCleanup.class); }
Throwable t = e.getCause(); if (t instanceof LockFailureException) { logger.atSevere().withCause(t).log("Error in %s %s", req.getMethod(), uriForLogging(req)); responseBytes = replyError(req, res, status = SC_SERVICE_UNAVAILABLE, messageOr(t, "Lock failure"), e); } else if (t instanceof CommentsRejectedException) { responseBytes = replyError(req, res, status = SC_BAD_REQUEST, messageOr(t, "Comments rejected"), e); } else { status = SC_INTERNAL_SERVER_ERROR; responseBytes = handleException(e, req, res); } } catch (QuotaException e) { responseBytes = replyError(req, res, status = 429, messageOr(e, "Quota limit reached"), e.caching(), e); } catch (Exception e) { status = SC_INTERNAL_SERVER_ERROR; responseBytes = handleException(e, req, res); } finally { String metric = viewData != null && viewData.view != null ? globals.metrics.view(viewData) : "_unknown";
public static List<CommentValidationFailure> findInvalidComments(PluginSetContext<CommentValidator> commentValidators, ImmutableList<CommentForValidation> commentsForValidation) { List<CommentValidationFailure> commentValidationFailures = new ArrayList<>(); commentValidators.runEach(listener -> commentValidationFailures.addAll(listener.validateComments(commentsForValidation))); return Collections.unmodifiableList(commentValidationFailures); }
comments.addAll(toPublish); return !toPublish.isEmpty(); } private boolean insertRobotComments(ChangeContext ctx) throws OrmException, PatchListNotAvailableException { if (in.robotComments == null) { return false; } List<RobotComment> newRobotComments = getNewRobotComments(ctx); commentsUtil.putRobotComments(ctx.getUpdate(psId), newRobotComments); comments.addAll(newRobotComments); return !newRobotComments.isEmpty(); } private List<RobotComment> getNewRobotComments(ChangeContext ctx) throws OrmException, PatchListNotAvailableException { List<RobotComment> toAdd = new ArrayList<>(in.robotComments.size()); Set<CommentSetEntry> existingIds = in.omitDuplicateComments ? readExistingRobotComments(ctx) : Collections.emptySet(); for (Map.Entry<String, List<RobotCommentInput>> ent : in.robotComments.entrySet()) { String path = ent.getKey(); for (RobotCommentInput c : ent.getValue()) { RobotComment e = createRobotCommentFromInput(ctx, path, c); if (existingIds.contains(CommentSetEntry.create(e))) { continue; } toAdd.add(e); } } validateComments(toAdd); return toAdd; }
import java.util.concurrent.locks.ReentrantLock; import com.google.common.collect.ImmutableList; import com.google.common.collect.Iterables; import com.google.common.util.concurrent.Retryer; public class SequenceGenerator { private final String refName; private final long seed; private final long floor; private final int batchSize; private final Runnable afterReadRef; private final Retryer<?> retryer; private final ReentrantLock counterLock; private long counter; private long limit; public SequenceGenerator(String name, long seed, long floor, int batchSize, Runnable afterReadRef, Retryer<?> retryer) { this.refName = RefNames.REFS_SEQUENCES + name; this.seed = seed; this.floor = floor; checkArgument(batchSize > 0, "expected batchSize > 0, got: %s", batchSize); this.batchSize = batchSize; this.afterReadRef = requireNonNull(afterReadRef, "afterReadRef"); this.retryer = requireNonNull(retryer, "retryer"); counterLock = new ReentrantLock(true); } /** * Generates the next sequence number. * * @return the next sequence number */ public int next() { return Iterables.getOnlyElement(next(1)); } /** * Generates the next sequence numbers. * * @param count the number of sequence numbers to generate * @return a list of generated sequence numbers */ public ImmutableList<Integer> next(int count) { if (count == 0) { return ImmutableList.of(); } checkArgument(count > 0, "count is negative: %s", count); try { return retryer.call(() -> { counterLock.lock(); try { if (count == 1) { if (counter >= limit) { acquire(batchSize); } return ImmutableList.of((int) counter++); } List<Integer> ids = new ArrayList<>(count); while (counter < limit) { ids.add((int) counter++); if (ids.size() == count) { return ImmutableList.copyOf(ids); } } acquire(batchSize); return ImmutableList.copyOf(ids); } finally { counterLock.unlock(); } }); } catch (Exception e) { throw new RuntimeException("Failed to generate sequence numbers
// from the sequence. Creating an ID requires the RepoSequence.counterLock, if it's not free // (because we forgot to release it before blocking) the call in the other thread would hang and // the test would time out. // We can set the runnable that consumes the ID from another thread only after RepoSequence was // created, because we need the RepoSequence instance to get the next ID. BlockStrategyThatTriggersRunnable blockStrategy = new BlockStrategyThatTriggersRunnable(); // Use batch size = 1 to make each call go to NoteDb. RepoSequence s = newSequence("id", 1, 1, bgUpdate, RepoSequence.retryerBuilder().withBlockStrategy(blockStrategy).build()); blockStrategy.runOnBlock = () -> { try { Executors.newFixedThreadPool(1) .submit(() -> { // This call hangs if we don't release the RepoSequence.counterLock while we // are blocking until the next try. If this happens we block until the test // times out. }); } catch (Exception e) { // Handle exception } };
assertThat(getEmails()).containsExactly(previous); assertThat(gApi.accounts().self().get().email).isNull(); } @Test @Sandboxed public void deleteAllEmails() throws Exception { EmailInput input = new EmailInput(); input.email = "foo.bar@example.com"; input.noConfirmation = true; gApi.accounts().self().addEmail(input); resetCurrentApiUser(); Set<String> allEmails = getEmails(); assertThat(allEmails).hasSize(2); accountIndexedCounter.clear(); for (String email : allEmails) { gApi.accounts().self().deleteEmail(email); } resetCurrentApiUser(); assertThat(getEmails()).isEmpty(); assertThat(gApi.accounts().self().get().email).isNull(); } @Test public void deleteEmailFromCustomExternalIdSchemes() throws Exception { String email = "foo.bar@example.com"; String extId1 = "foo:bar"; String extId2 = "foo:baz"; List<ExternalId> extIds = ImmutableList.of( // rest of the code }
public void deleteInstanceIdFile(String serverIdFile) { try { Files.delete(Paths.get(serverIdFile)); } catch (IOException e) { multisiteLog.warn(String.format("Cannot delete old instance ID file at path '%s' while generating a new one: (%s)", serverIdFile, e.getMessage())); } }
/** * Wraps a {@link Callable} and provides logging context awareness. */ class LoggingContextAwareCallable<T> implements Callable<T> { private final Callable<T> callable; private final Thread callingThread; private final ImmutableSetMultimap<String, String> tags; private final boolean forceLogging; private final boolean performanceLogging; private final MutablePerformanceLogRecords mutablePerformanceLogRecords; LoggingContextAwareCallable(Callable<T> callable, MutablePerformanceLogRecords mutablePerformanceLogRecords) { this.callable = callable; this.callingThread = Thread.currentThread(); this.tags = LoggingContext.getInstance().getTagsAsMap(); this.forceLogging = LoggingContext.getInstance().isLoggingForced(); this.performanceLogging = LoggingContext.getInstance().isPerformanceLogging(); this.mutablePerformanceLogRecords = mutablePerformanceLogRecords; } @Override public T call() throws Exception { try { LoggingContext.getInstance().setTags(tags); LoggingContext.getInstance().setLoggingForced(forceLogging); LoggingContext.getInstance().setPerformanceLogging(performanceLogging); LoggingContext.getInstance().setPerformanceLogRecords(mutablePerformanceLogRecords); return callable.call(); } finally { LoggingContext.getInstance().clear(); } } }
import static org.junit.Assert.*; import static org.mockito.Mockito.*; import org.easymock.EasyMock; import org.junit.Rule; import org.junit.Test; import org.junit.rules.ExpectedException; import com.google.common.collect.ImmutableList; import com.google.common.collect.ImmutableMap; import com.google.gerrit.extensions.api.changes.ReviewInput; import com.google.gerrit.extensions.common.CommentInput; import com.google.gerrit.extensions.common.CommentInfo; import com.google.gerrit.extensions.common.CommentRange; import com.google.gerrit.extensions.common.CommentRange.Range; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.server.CommentsRejectedException; import com.google.gerrit.server.change.ChangeResource; import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.change.TestCommentUtil; import com.google.gerrit.server.change.TestCommentUtil.CommentForValidation; import com.google.gerrit.server.change.TestCommentUtil.CommentValidationMessage; import com.google.gerrit.server.change.TestCommentUtil.CommentValidationMessage.Type; import com.google.gerrit.server.change.TestCommentUtil.CommentValidationMessageFormatter; import com.google.gerrit.server.change.TestCommentUtil.CommentValidationMessageFormatterImpl; import com.google.gerrit.server.change.TestCommentUtil.CommentValidator; import com.google.gerrit.server.change.TestCommentUtil.CommentValidatorImpl; import com.google.gerrit.server.change.TestCommentUtil.TestComment; import com.google.gerrit.server.change.TestCommentUtil.TestCommentFormatter; import com.google.gerrit.server.change.TestCommentUtil.TestCommentFormatterImpl; import com.google.gerrit.server.change.TestCommentUtil.TestCommentValidator; import com.google.gerrit.server.change.TestCommentUtil.TestCommentValidatorImpl; import com.google.gerrit.server.change.TestCommentUtil.ValidationResult; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultImpl; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatter; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatterImpl; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatterImpl.Format; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatterImpl.FormatOptions; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatterImpl.FormatOptionsImpl; import com.google.gerrit.server.change.TestCommentUtil.ValidationResultFormatterImpl.FormatOptionsImpl.Builder; import com.google.gerrit.server
public OrmException convertError(String op, SQLException err) { switch (getSQLStateInt(err)) { case 23000: return new OrmDuplicateKeyException("ACCOUNT_PATCH_REVIEWS", err); default: if (err.getCause() == null && err.getNextException() != null) { err.initCause(err.getNextException()); } return new OrmException(op + " failure on ACCOUNT_PATCH_REVIEWS", err); } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.base.Preconditions.checkArgument; import static com.google.common.base.Suppliers.memoize; import static com.google.common.base.Suppliers.ofInstance; import com.google.common.annotations.VisibleForTesting; import com.google.common.base.CaseFormat; import com.google.common.base.Strings; import com.google.common.collect.ImmutableList; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.google.inject.Singleton; import com.google.inject.spi.Message; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.io.IOException; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.commons.lang.StringUtils; import org.apache.curator.RetryPolicy; public class Main { public static void main(String[] args) { // Main method implementation } }
private final boolean enabled; private final Map<EventFamily, Boolean> eventsEnabled; private KafkaPublisher(Supplier<Config> cfg) { enabled = cfg.get().getBoolean(KAFKA_SECTION, KAFKA_PUBLISHER_SUBSECTION, ENABLE_KEY, DEFAULT_BROKER_ENABLED); eventsEnabled = eventsEnabled(cfg, KAFKA_PUBLISHER_SUBSECTION); if (enabled) { setDefaults(); applyKafkaConfig(cfg, KAFKA_PUBLISHER_SUBSECTION, this); } }
import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import com.google.common.base.CaseFormat; import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String KAFKA_CONFIG = "multi-site.config"; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; public KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = lazyLoad(kafkaConfig); // Rest of the code } }
ProvisionException pe = new ProvisionException("error opening ReviewDb"); pe.initCause(e); throw pe; } dbRef.set(db); } return db; } @Override public CurrentUser getUser() { throw new OutOfScopeException("No user during ChangeIndexer"); } RequestContext oldCtx = context.setContext(newCtx); try { if (this instanceof IndexTask) { queuedIndexTasks.remove(this); } else if (this instanceof ReindexIfStaleTask) { queuedReindexIfStaleTasks.remove(this); } return callImpl(newCtx.getReviewDbProvider()); } finally { context.setContext(oldCtx); Provider<ReviewDb> db = dbRef.get(); if (db != null) { db.get().close(); } } } catch (Exception e) { log.error("Failed to execute " + this, e); throw e; }
bind(PersonIdent.class) // .annotatedWith(GerritPersonIdent.class) // .toProvider(GerritPersonIdentProvider.class); bind(AllProjectsName.class).toInstance(new AllProjectsName("All-Projects")); bind(AllUsersName.class).toInstance(new AllUsersName("All-Users")); bind(GitRepositoryManager.class).toInstance(new InMemoryRepositoryManager()); bind(String.class) // .annotatedWith(AnonymousCowardName.class) // .toProvider(AnonymousCowardNameProvider.class); bind(DataSourceType.class).to(InMemoryH2Type.class); install(new ConfigNotesMigration.Module()); admin = accountCreator.admin(); user = accountCreator.user(); // Evict and reindex accounts in case tests modify them. evictAndReindexAccount(admin.getId()); evictAndReindexAccount(user.getId()); adminRestSession = new RestSession(server, admin); userRestSession = new RestSession(server, user); anonymousRestSession = new RestSession(server, null); initSsh(); resourcePrefix = UNSAFE_PROJECT_NAME.matcher(description.getClassName() + "_" + description.getMethodName() + "_") .replaceAll(""); Context ctx = newRequestContext(admin); atrScope.set(ctx); ProjectInput in = projectInput(description); gApi.projects().create(in); project = new Project.NameKey(in.name); testRepo = cloneProject(project, getCloneAsAccount(description)); public Module createModule() { return null; } protected void initSsh() throws Exception { if (testRequiresSsh && SshMode.useSsh() && (adminSshSession == null || userSshSession == null)) { protected void configure() { install(SchemaVersionCheck.module()); bind(ApprovalTypes.class).toProvider(ApprovalTypesProvider.class).in(Scopes.SINGLETON); bind(String.class).annotatedWith(CanonicalWebUrl.class) .toProvider(CanonicalWebUrlProvider.class).in(Scopes.SINGLETON); install(AccountCacheImpl.module()); install(GroupCacheImpl.module()); install(new EhcachePoolImpl.Module()); install(new FactoryModule() { @Override protected void configure() { factory(CreateCodeReviewNotes.Factory.class); factory(NotesBranchUtil.Factory.class); } }); install(new LifecycleModule() { @Override protected void configure() { listener().to(LocalDiskRepositoryManager.Lifecycle.class); }
import com.android.tools.idea.tests.gui.framework.GuiTestCase; import com.android.tools.idea.tests.gui.framework.IdeGuiTest; import com.android.tools.idea.tests.gui.framework.fixture.IdeFrameFixture; import com.android.tools.idea.tests.gui.framework.fixture.RenameRefactoringDialogFixture; import com.android.tools.idea.tests.gui.framework.fixture.ThemeSelectionDialogFixture; import com.android.tools.idea.tests.gui.framework.fixture.theme.ThemeEditorFixture; import com.google.common.collect.ImmutableList; import org.fest.swing.fixture.JComboBoxFixture; import org.fest.swing.fixture.JListFixture; import org.fest.swing.fixture.JTreeFixture; import org.junit.BeforeClass; import org.junit.Test; import java.io.IOException; import java.util.List; import static com.android.tools.idea.tests.gui.framework.TestGroup.THEME; import static com.android.tools.idea.tests.gui.theme.ThemeEditorTest.openThemeEditor; import static org.fest.assertions.Assertions.assertThat; import static org.junit.Assert.assertEquals; @BelongsToTestGroups({THEME}) public class ThemeSelectorTest extends GuiTestCase { @BeforeClass public static void setUp() throws IOException { IdeGuiTest.setUp(); } @Test public void testThemeSelector() throws IOException { IdeFrameFixture ideFrameFixture = openThemeEditor(myProject); ThemeEditorFixture themeEditorFixture = ideFrameFixture.getThemeEditor(); ThemeSelectionDialogFixture themeSelectionDialogFixture = themeEditorFixture.openThemeSelectionDialog(); JComboBoxFixture themeComboBoxFixture = themeSelectionDialogFixture.getThemeComboBox(); JListFixture themeListFixture = themeComboBoxFixture.dropDown(); List<String> themes = themeListFixture.contents(); assertThat(themes).contains("AppTheme", "Theme.Material.Light"); themeListFixture.clickItem(Index.atIndex(1)); themeSelectionDialogFixture.clickOk(); assertEquals("Theme.Material.Light", themeComboBoxFixture.selectedItem()); } }
import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.HashMap; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String PLUGIN_NAME = "kafka"; public static final String KAFKA_CONFIG = PLUGIN_NAME + ".config"; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject public KafkaConfiguration(Supplier<KafkaSubscriber> subscriber, Supplier<Kafka> kafka, Supplier<KafkaPublisher> publisher) { this.subscriber = subscriber; this.kafka = kafka; this.publisher = publisher; } }
import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String PLUGIN_NAME = "kafka"; public static final String KAFKA_CONFIG = PLUGIN_NAME + ".config"; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); } }
import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String PLUGIN_NAME = "kafka"; public static final String KAFKA_CONFIG = MultiSiteConfig.MULTI_SITE_CONFIG; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); } @VisibleForTesting public KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = ConfigurationHelper.lazyLoad(kafkaConfig); } }
import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.InstanceId; import com.googlesource.gerrit.plugins.multisite.KafkaConfiguration; import com.googlesource.gerrit.plugins.multisite.broker.BrokerSession; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.UUID; public class KafkaSession implements BrokerSession { private static final Logger LOGGER = LoggerFactory.getLogger(KafkaSession.class); private KafkaConfiguration kafkaConfig; private final UUID instanceId; private volatile Producer<String, String> producer; @Inject public KafkaSession(KafkaConfiguration kafkaConfig, @InstanceId UUID instanceId) { this.kafkaConfig = kafkaConfig; this.instanceId = instanceId; } @Override public boolean isOpen() { return producer != null; } @Override public void connect() { if (isOpen()) { LOGGER.debug("Already connected."); return; } // Connect to Kafka } // Other methods }
package com.googlesource.gerrit.plugins.multisite.kafka.consumer; import java.util.concurrent.Executor; import java.util.concurrent.Executors; import org.apache.kafka.common.serialization.ByteArrayDeserializer; import org.apache.kafka.common.serialization.Deserializer; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.lifecycle.LifecycleModule; import com.google.inject.TypeLiteral; import com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaSubscriber; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import com.googlesource.gerrit.plugins.multisite.forwarder.events.MultiSiteEvent; public class KafkaConsumerModule extends LifecycleModule { private final KafkaSubscriber kafkaSubscriber; public KafkaConsumerModule(KafkaSubscriber kafkaSubscriber) { this.kafkaSubscriber = kafkaSubscriber; } @Override protected void configure() { MultiSiteEvent.registerEventTypes(); bind(new TypeLiteral<DynamicSet<MultiSiteEvent.Listener>>() {}) .toProvider(KafkaSubscriberProvider.class); bind(KafkaSubscriber.class).toInstance(kafkaSubscriber); bind(Executor.class).annotatedWith(EventFamily.class) .toInstance(Executors.newSingleThreadExecutor()); bind(new TypeLiteral<Deserializer<byte[]>>() {}) .to(ByteArrayDeserializer.class); } }
package com.googlesource.gerrit.plugins.multisite; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.multisite.Configuration.DEFAULT_THREAD_POOL_SIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.THREAD_POOL_SIZE_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.CACHE_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.PATTERN_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Event.EVENT_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.DEFAULT_SYNCHRONIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.SYNCHRONIZE_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Index.INDEX_SECTION; import org.eclipse.jgit.lib.Config; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.junit.MockitoJUnitRunner; import static com.googlesource.gerrit.plugins.multisite.Configuration.DEFAULT_THREAD_POOL_SIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.THREAD_POOL_SIZE_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.CACHE_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.PATTERN_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Event.EVENT_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.DEFAULT_SYNCHRONIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.SYNCHRONIZE_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Index.INDEX_SECTION; import static com.google.common.truth.Truth.assertThat; @RunWith(MockitoJUnitRunner.class) public class MultiSiteConfigurationTest { private MultiSiteConfiguration multiSiteConfig; @Before public void setUp() { multiSiteConfig = new MultiSiteConfiguration(); } @Test public void testDefaultThreadPoolSize() { Config config = new Config(); int defaultThreadPoolSize = multiSiteConfig.getDefaultThreadPoolSize(config); assertThat(defaultThreadPoolSize).isEqualTo(DEFAULT_THREAD_POOL_SIZE); } @Test
static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000; static final int DEFAULT_THREAD_POOL_SIZE = 4; static final String NUM_STRIPED_LOCKS = "numStripedLocks"; static final int DEFAULT_NUM_STRIPED_LOCKS = 10; static final String ENABLE_KEY = "enabled"; private final Supplier<Cache> cache; private final Supplier<Event> event; private final Supplier<Index> index; private final Supplier<Collection<Message>> replicationConfigValidation; @Inject Configuration(SitePaths sitePaths) { this(getConfigFile(sitePaths, MULTI_SITE_CONFIG), getConfigFile(sitePaths, REPLICATION_CONFIG)); } @VisibleForTesting public Configuration(Config multiSiteConfig, Config replicationConfig) { Supplier<Config> lazyMultiSiteCfg = lazyLoad(multiSiteConfig); replicationConfigValidation = lazyValidateReplicatioConfig(replicationConfig); cache = memoize(() -> new Cache(lazyMultiSiteCfg)); event = memoize(() -> new Event(lazyMultiSiteCfg)); index = memoize(() -> new Index(lazyMultiSiteCfg)); } public Cache cache() { return cache.get(); }
private final int threadPoolSize; private final List<String> patterns; private Cache(Supplier<Config> cfg) { super(cfg, CACHE_SECTION); threadPoolSize = getInt(cfg, CACHE_SECTION, null, THREAD_POOL_SIZE_KEY, DEFAULT_THREAD_POOL_SIZE); patterns = getList(cfg, CACHE_SECTION, null, PATTERN_KEY); }
import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; private static final String KAFKA_CONFIG = Configuration.KAFKA_CONFIG; private static final String ENABLE_KEY = "enabled"; private static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; private static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); } @VisibleForTesting KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = lazyLoad(kafkaConfig); // rest of the code } }
public void init(IWorkbench workbench) { // TODO Auto-generated method stub } public void testTypeErasure() { List<Integer> list = new ArrayList<>(); list.add(1); IEclipseContext context = EclipseContextFactory.create(); context.set(List.class, list); TestNamedObject userObject = new TestNamedObject(); ContextInjectionFactory.inject(userObject, context); assertEquals(list, userObject.field); userObject.combineIt(); } // Set new parent ProjectAccessInput accessInput = newProjectAccessInput(); accessInput.parent = newParentProjectName; setApiUser(user); exception.expect(AuthException.class); exception.expectMessage("not administrator"); gApi.projects().name(newProjectName).access(accessInput); @Test public void updateParentAsAdministrator() throws Exception { String newParentProjectName = createProject(PROJECT_NAME + "PA").get(); ProjectAccessInput accessInput = newProjectAccessInput(); accessInput.parent = newParentProjectName; gApi.projects().name(newProjectName).access(accessInput); assertThat(pApi.access().inheritsFrom.name).isEqualTo(newParentProjectName); } @Test public void addGlobalCapabilityAsUser() throws Exception { ProjectAccessInput accessInput = newProjectAccessInput(); AccessSectionInfo accessSectionInfo = createDefaultGlobalCapabilitiesAccessSectionInfo(); accessInput.additions.put(AccessSection.GLOBAL_CAPABILITIES, accessSectionInfo); setApiUser(user); exception.expect(AuthException.class); gApi.projects().name(allProjects.get()).access(accessInput); } projectOperations.allProjectsForUpdate() .add(allow(Permission.READ).ref("refs/*").group(admins)) .update(); try (ProjectConfigUpdate u = updateProject(allUsers)) { for (AccessSection sec : u.getConfig().getAccessSections()) { sec.removePermission(Permission.READ); } u.save(); } private void setUpChanges() throws Exception { gApi.projects().name(project.get()).branch("branch").create(new BranchInput()); projectOperations.project(project) .forUpdate() .add(allow(Permission.SUBMIT).ref("refs/for/refs/heads/*").group(admins)) .update(); PushOneCommit.Result mr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/master%submit"); mr.assertOkStatus(); cd1 = mr
// Remove all read permissions on All-Users. try (ProjectConfigUpdate u = updateProject(allUsers)) { for (AccessSection sec : u.getConfig().getAccessSections()) { sec.removePermission(Permission.READ); } u.save(); } private void setUpChanges() throws Exception { gApi.projects().name(project.get()).branch("branch").create(new BranchInput()); // First 2 changes are merged, which means the tags pointing to them are visible. projectOperations .project(project) .forUpdate() .add(allow(Permission.SUBMIT).ref("refs/for/refs/heads/*").group(admins)) .update(); PushOneCommit.Result mr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/master%submit"); mr.assertOkStatus(); cd1 = mr.getChange(); rc1 = mr.getCommit(); psRef1 = cd1.currentPatchSet().id().toRefName(); metaRef1 = RefNames.changeMetaRef(cd1.getId()); PushOneCommit.Result br = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/branch%submit"); br.assertOkStatus(); cd2 = br.getChange(); rc2 = br.getCommit(); psRef2 = cd2.currentPatchSet().id().toRefName(); metaRef2 = RefNames.changeMetaRef(cd2.getId()); PushOneCommit.Result cr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/refs/changes/01/1%submit"); cr.assertOkStatus(); cd3 = cr.getChange(); rc3 = cr.getCommit(); psRef3 = cd3.currentPatchSet().id().toRefName(); metaRef3 = RefNames.changeMetaRef(cd3.getId()); PushOneCommit.Result dr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/refs/changes/02/2%submit"); dr.assertOkStatus(); cd4 = dr.getChange(); rc4 = dr.getCommit(); psRef4 = cd4.currentPatchSet().id().toRefName(); metaRef4 = RefNames.changeMetaRef(cd4.getId()); }
/** * .haves}. This is a heuristical approach that aims at scaling down the number of unnecessary * objects that client sends to the server. Unnecessary here refers to objects that the server * already has. * * <p>For some code paths in {@link com.google.gerrit.server.git.DefaultAdvertiseRefsHook}, we * already removed refs/changes, so the logic to skip these in this class become a no-op. * * <p>TODO(hiesel): Instrument this heuristic and proof its value. */ public class ReceiveCommitsAdvertiseRefsHook implements AdvertiseRefsHook { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final Provider<InternalChangeQuery> queryProvider; private final Project.NameKey projectName; public ReceiveCommitsAdvertiseRefsHook( Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName) { this.queryProvider = queryProvider; this.projectName = projectName; } @Override public void advertiseRefs(UploadPack us) { throw new UnsupportedOperationException( "ReceiveCommitsAdvertiseRefsHook cannot be used for UploadPack"); } @Override public void advertiseRefs(ReceivePack rp) { throw new UnsupportedOperationException( "ReceiveCommitsAdvertiseRefsHook cannot be used for ReceivePack"); } }
@VisibleForTesting public static AdvertiseRefsHook createForTest( PermissionBackend.ForProject perm, Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName) { return create(new AllRefsWatcher(), perm, queryProvider, projectName, true); } private static AdvertiseRefsHook create( AllRefsWatcher allRefsWatcher, PermissionBackend.ForProject perm, Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName, boolean skipHackPushNegotiateHook) { List<AdvertiseRefsHook> advHooks = new ArrayList<>(); advHooks.add(allRefsWatcher); advHooks.add(/* ... */); // ... return new ChainAdvertiseRefsHook(advHooks); }
/** Returns the URL for viewing a comment in a file in a given patch set of a change. */ default Optional<String> getInlineCommentView(Change change, int patchsetId, String filename, short side, int startLine) { return getPatchFileView(change, patchsetId, filename) .map(url -> url + String.format("@%s%d", side == 0 ? "a" : "", startLine)); } /** * Returns a URL pointing to the settings page. */ default Optional<String> getSettingsUrl(@Nullable String section) { return getWebUrl() .map(url -> url + "settings" + (Strings.isNullOrEmpty(section) ? "" : "#" + section)); } /** Returns a URL pointing to a documentation page, at a given named anchor. */ default Optional<String> getDocUrl(String page, String anchor) { return getWebUrl().map(url -> url + "Documentation/" + page + "#" + anchor); }
public void connect() { if (isOpen()) { multisiteLog.debug("Already connected."); return; } multisiteLog.info("Connect to {}...", properties.getKafka().getBootstrapServers()); /* Need to make sure that the thread of the running connection uses * the correct class loader otherwise you can end up with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader(); producer = new KafkaProducer<>(properties.kafkaPublisher()); multisiteLog.info("Connection established."); }
public void connect() { if (isOpen()) { LOGGER.debug("Already connected."); return; } setConnectionClassLoader(); producer = producerProvider.get(); LOGGER.info("Connection established."); }
private static final String ERROR_MESSAGE_NEGATIVE_VALUE = "Invalid value: function %1$s expects" + " its %2$s input parameter to be a non-negative value, but gets %3$s"; private static final String ERROR_MESSAGE_OUT_OF_BOUND = "Index out of bound in %1$s: %2$s"; private static final String ERROR_MESSAGE_COERCION = "Invalid implicit scalar to collection coercion in %1$s"; private static final String ERROR_MESSAGE_DUPLICATE_FIELD = "Duplicate field name \"%1$s\""; private static final String ERROR_MESSAGE_INVALID_EXPRESSION = "Invalid expression: function %1$s expects" + " its %2$s input parameter to be a %3$s expression, but the actual expression is %4$s"; private static final String ERROR_MESSAGE_INVALID_PARAMETER_NUMBER = "Invalid parameter number: function %1$s " + "cannot take %2$s parameters"; private static Map<Integer, String> errorMessageMap = new HashMap<>(); static { // runtime errors errorMessageMap.put(1, ERROR_MESSAGE_NEGATIVE_VALUE); errorMessageMap.put(2, ERROR_MESSAGE_OUT_OF_BOUND); errorMessageMap.put(3, ERROR_MESSAGE_COERCION); errorMessageMap.put(4, ERROR_MESSAGE_DUPLICATE_FIELD); errorMessageMap.put(5, ERROR_MESSAGE_INVALID_EXPRESSION); errorMessageMap.put(6, ERROR_MESSAGE_INVALID_PARAMETER_NUMBER); } private List<File> mSourcePaths; private List<File> mJarPaths; private File mOutputDir; private String mPackage; private List<File> mLocalProguardFiles; private List<File> mSdkProguardFiles; private List<EclipseProject> mAllLibraries; private EclipseProject(@NonNull GradleImport importer, @NonNull File dir) throws IOException { mImporter = importer; mDir = dir; mCanonicalDir = dir.getCanonicalFile(); mImporter.registerProject(this); File file = getClassPathFile(); mClassPathDoc = GradleImport.getXmlDocument(file, false); initProjectName(); initAndroidProject(); initLanguageLevel(); if (isAndroidProject()) { Properties properties = getProjectProperties(); initProguard(properties); initVersion(properties); initLibraries(properties); initLibrary(properties); initPackage(); initMinSdkVersion(); } else { mDirectLibraries = new ArrayList<EclipseProject>(4); } initClassPathEntries(); initPathVariables(); }
out.hashtags = cd.hashtags(); out.changeId = in.getKey().get(); if (in.isNew()) { SubmitTypeRecord str = cd.submitTypeRecord(); if (str.isOk()) { out.submitType = str.type; } if (!excludeMergeableInChangeInfo && !has(SKIP_MERGEABLE)) { out.mergeable = cd.isMergeable(); } if (has(SUBMITTABLE)) { out.submittable = submittable(cd); } } if (!has(SKIP_INSERT_DELETE)) { Optional<ChangedLines> changedLines = cd.changedLines(); if (changedLines.isPresent()) { out.insertions = changedLines.get().insertions; out.deletions = changedLines.get().deletions; } } out.isPrivate = in.isPrivate() ? true : null; out.workInProgress = in.isWorkInProgress() ? true : null; out.hasReviewStarted = in.hasReviewStarted(); out.subject = in.getSubject(); out.status = in.getStatus().asChangeStatus(); out.owner = accountLoader.get(in.getOwner());
if (pr.getAction() == PermissionRule.Action.ALLOW && projectControl.match(pr, isChangeOwner)) { voteMin = Math.min(voteMin, pr.getMin()); voteMax = Math.max(voteMax, pr.getMax()); } voteMin = Math.max(voteMin, blockAllowMin); voteMax = Math.min(voteMax, blockAllowMax); if (voteMin > voteMax) { voteMin = 0; voteMax = 0; } return new PermissionRange(permissionName, voteMin, voteMax);
public TestRefValidator(ReceiveCommand.Type rejectType) { this.rejectType = rejectType; this.rejectRef = TEST_REF; this.handle = validators.add(this); }
protected static TestGroup FailedGroup; public static void setUp() throws Exception { System.out.println("Starting setup"); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Starting setup"); } System.setProperty(GlobalConfig.CONFIG_FILE_PROPERTY, TEST_CONFIG_FILE_NAME); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("initializing pseudo cluster"); } AsterixHyracksIntegrationUtil.init(true); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("initializing HDFS"); } HDFSCluster.getInstance().setup(); System.setProperty(ExternalDataConstants.NODE_RESOLVER_FACTORY_PROPERTY, IdentitiyResolverFactory.class.getName()); FailedGroup = new TestGroup(); FailedGroup.setName("failed"); } private static void validateBufferCacheState() { for (NodeControllerService nc : AsterixHyracksIntegrationUtil.ncs) { IAsterixAppRuntimeContext appCtx = (IAsterixAppRuntimeContext) nc.getApplicationContext().getApplicationObject(); } } @Override public void setParams(ListMultimap<String, String> params) throws BadRequestException { this.hasQuery = params.containsKey("query"); } @Override public RestView<TopLevelResource> list() { if (hasQuery) { return queryProjects.get(); } return list.get().setFormat(OutputFormat.JSON); } @Override public ProjectResource parse(TopLevelResource parent, IdString id) throws RestApiException, IOException, PermissionBackendException { ProjectResource rsrc = _parse(id.get(), true); if (rsrc == null) { throw new ResourceNotFoundException(id); } return rsrc; } fmt.addStyleName(row, i, Gerrit.RESOURCES.css().dataCell()); fmt.addStyleName(row, C_SUBJECT, Gerrit.RESOURCES.css().cSUBJECT()); fmt.addStyleName(row, C_STATUS, Gerrit.RESOURCES.css().cSTATUS()); fmt.addStyleName(row, C_OWNER, Gerrit.RESOURCES.css().cOWNER()); fmt.addStyleName(row, C_LAST_UPDATE, Gerrit.RESOURCES.css().cLastUpdate()); if (!Gerrit.isSignedIn() || (!Gerrit.getUserAccount().getGeneralPreferences().isLegacycidInChangeTable())) { fmt.addStyleName(row, C_ID, Gerrit.RESOURCES.css().dataCellHidden()); } int i = C_SIZE; if (use
private Function<T, String> formatter; public abstract String name(); public abstract Class<T> valueType(); public abstract Optional<String> description(); public Function<T, String> formatter() { if (formatter == null) { formatter = initFormatter(valueType()); } return formatter; } private static <T> Function<T, String> initFormatter(Class<T> valueType) { if (valueType == String.class) { return s -> (String) s; } else if (valueType == Integer.class || valueType == Boolean.class) { return Object::toString; } else if (Enum.class.isAssignableFrom(valueType)) { return in -> ((Enum<?>) in).name(); } throw new IllegalStateException("unsupported type " + valueType.getName()); } @AutoValue.Builder
reject(cmd, "not valid ref"); return; } if (RefNames.isNoteDbMetaRef(cmd.getRefName())) { // Reject pushes to NoteDb refs without a special option and permission. Note that this // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will // migrate to NoteDb eventually, and we don't want garbage data waiting there when the // migration finishes. logger.atFine().log("%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption); if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) { // Only reject this command, not the whole push. This supports the use case of "git clone // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone // or mirror the NoteDb data; there is no single refspec that describes all refs *except* // NoteDb refs. reject(cmd, "NoteDb refs require special option and permission"); } }
public Context start(F1 f1) { return new Context(this, f1); }
.valueType(Boolean.class) .formatter(Object::toString) .name(name); } public static <E extends Enum<E>> Field.Builder<E> ofEnum(Class<E> enumType, String name) { return new AutoValue_Field.Builder<E>() .valueType(enumType) .formatter(Enum::name) .name(name); } public static Field.Builder<Integer> ofInteger(String name) { return new AutoValue_Field.Builder<Integer>() .valueType(Integer.class) .formatter(Object::toString) .name(name); }
public RequestMetrics(MetricMaker metricMaker) { Field<Integer> statusCodeField = Field.ofInteger("status", metadataBuilder::httpStatus) .description("HTTP status code") .build(); errors = metricMaker.newCounter("http/server/error_count", new Description("Rate of REST API error responses").setRate().setUnit("errors"), statusCodeField); successes = metricMaker.newCounter("http/server/success_count", new Description("Rate of REST API success responses").setRate().setUnit("successes"), statusCodeField); }
package com.google.gerrit.metrics; import static com.google.common.base.Preconditions.checkArgument; import com.google.auto.value.AutoValue; import java.util.Optional; import java.util.function.Function; /** * Describes a bucketing field used by a metric. * * @param <T> type of field */ @AutoValue public abstract class Field<T> { /** * Break down metrics by boolean true/false. * * @param name field name * @return builder for the boolean field */ public static Field.Builder<Boolean> ofBoolean(String name) { return new AutoValue_Field.Builder<Boolean>() .valueType(Boolean.class) .formatter(Object::toString) .name(name); } /** * Break down metrics by cases of an enum. * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static <E extends Enum<E>> Field.Builder<E> ofEnum(Class<E> enumType, String name) { return new AutoValue_Field.Builder<E>() .valueType(enumType) .formatter(Enum::name) .name(name); } // Builder class public abstract static class Builder<T> { public abstract Builder<T> valueType(Class<T> valueType); public abstract Builder<T> formatter(Function<T, String> formatter); public abstract Builder<T> name(String name); public abstract Field<T> build(); } }
public abstract Class<T> valueType(); /** * Returns the description text for the field explaining its range of values. * * @return the description text for the field */ public abstract Optional<String> description(); /** * Returns the formatter to format field values. * * @return the formatter to format field values */ public abstract Function<T, String> formatter(); @AutoValue.Builder public abstract static class Builder<T> { abstract Builder<T> name(String name); abstract Builder<T> valueType(Class<T> type); abstract Builder<T> formatter(Function<T, String> formatter); /** * Sets the description for the field. * * @param description the description for the field * @return the builder instance */ public abstract Builder<T> description(String description); abstract Field<T> autoBuild(); /** * Builds the field object. * * @return the built field object */ public Field<T> build() { Field<T> field = autoBuild(); checkArgument(field.name().matches("^[a-z_]+$"), "name must match [a-z_]"); return field; } } }
@Singleton public class UploadPackMetricsHook implements PostUploadHook { enum Operation { CLONE, FETCH; } private final Counter1<Operation> requestCount; private final Timer1<Operation> counting; private final Timer1<Operation> compressing; private final Timer1<Operation> writing; private final Histogram1<Operation> packBytes; @Inject UploadPackMetricsHook(MetricMaker metricMaker) { Field<Operation> operationField = Field.ofEnum(Operation.class, "operation", (metadataBuilder, fieldValue) -> metadataBuilder.gitOperation(fieldValue.name())).build(); requestCount = metricMaker.newCounter("git/upload-pack/request_count", new Description("Total number of git-upload-pack requests") .setRate() .setUnit("requests"), operationField); counting = metricMaker.newTimer("git/upload-pack/phase_counting", new Description("Time spent in the 'Counting...' phase") .setCumulative() .setUnit(Units.MILLISECONDS), operationField); compressing = metricMaker.newTimer("git/upload-pack/phase_compressing", new Description("Time spent in the 'Compressing...' phase") .setCumulative() .setUnit(Units.MILLISECONDS), operationField); writing = metricMaker.newTimer("git/upload-pack/phase_writing", new Description("Time spent in the 'Writing...' phase") .setCumulative() .setUnit(Units.MILLISECONDS), operationField); packBytes = metricMaker.newHistogram("git/upload-pack/pack_bytes", new Description("Size of the pack file in bytes") .setCumulative() .setUnit(Units.BYTES), operationField); } }
public abstract Optional<String> branchName(); public abstract Optional<String> cacheKey(); public abstract Optional<String> cacheName(); public abstract Optional<String> className(); public abstract Optional<Integer> changeId(); public abstract Optional<String> changeIdType(); public abstract Optional<String> eventType(); public abstract Optional<String> exportName(); public abstract Optional<String> garbageCollectorName(); public abstract Optional<String> gitOperation(); public abstract Optional<Integer> groupId(); public abstract Optional<String> groupName();
public abstract Optional<String> cacheName(); public abstract Optional<String> className(); public abstract Optional<Integer> changeId(); public abstract Optional<String> changeIdType(); public abstract Optional<String> eventType(); public abstract Optional<String> pluginExtensionName(); public abstract Optional<String> garbageCollectorName(); public abstract Optional<String> gitOperation(); public abstract Optional<Integer> groupId(); public abstract Optional<String> groupName(); public abstract Optional<String> groupUuid(); public abstract Optional<Integer> httpStatus(); public abstract Optional<String> secondaryIndexName();
public abstract Optional<Integer> groupId(); public abstract Optional<String> groupName(); public abstract Optional<String> groupUuid(); public abstract Optional<Integer> httpStatus(); public abstract Optional<String> indexName(); public abstract Optional<Integer> indexVersion(); public abstract Optional<String> authDomainName(); public abstract Optional<String> methodName(); public abstract Optional<Boolean> multiple(); public abstract Optional<String> noteDbFileName(); public abstract Optional<String> noteDbRefName(); public abstract Optional<String> noteDbSequenceType();
public abstract Optional<String> restViewName(); public abstract Optional<String> revision(); public abstract Optional<String> username(); public static Metadata.Builder builder() { return new AutoValue_Metadata.Builder(); } public static Metadata empty() { return builder().build(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder accountId(int accountId); public abstract Builder actionType(@Nullable String actionType); public abstract Builder branchName(@Nullable String branchName); public abstract Builder cacheKey(@Nullable String cacheKey); public abstract Builder cacheName(@Nullable String cacheName); public abstract Builder className(@Nullable String className); public abstract Builder changeId(int changeId); public abstract Builder changeIdType(@Nullable String changeIdType); public abstract Builder eventType(@Nullable String eventType); public abstract Builder exportName(@Nullable String exportName); public abstract Builder garbageCollectorName(@Nullable String garbageCollectorName); public abstract Builder gitOperation(@Nullable String gitOperation); }
package com.google.gerrit.server.logging; import static java.util.Objects.requireNonNull; import com.google.auto.value.AutoValue; import com.google.gerrit.common.Nullable; /** * The record of an operation for which the execution time was measured. * Meta data is stored in separate key/value fields to avoid expensive instantiations of Map objects. */ @AutoValue public abstract class PerformanceLogRecord { /** * Creates a performance log record without meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs) { return new AutoValue_PerformanceLogRecord(operation, durationMs, null); } /** * Creates a performance log record with meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @param metaData the meta data associated with the operation * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs, @Nullable MetaData metaData) { return new AutoValue_PerformanceLogRecord(operation, durationMs, metaData); } /** * Returns the name of the operation. * * @return the name of the operation */ public abstract String getOperation(); /** * Returns the execution time in milliseconds. * * @return the execution time in milliseconds */ public abstract long getDurationMs(); /** * Returns the meta data associated with the operation. * * @return the meta data associated with the operation */ @Nullable public abstract MetaData getMetaData(); /** * Meta data associated with a performance log record. */ @AutoValue public abstract static class MetaData { /** * Creates a meta data object. * * @param key the key of the meta data * @param value the value of the meta data * @return the meta data object */ public static MetaData create(String key, String value) { return new AutoValue_PerformanceLogRecord_MetaData(key, value); } /** * Returns the key of the meta data. * * @return the key
} /** * Creates a performance log record with meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @param metadata metadata * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs, Metadata metadata) { return new AutoValue_PerformanceLogRecord(operation, durationMs, requireNonNull(metadata)); } public abstract String operation(); public abstract long durationMs(); @Nullable public abstract Metadata metadata(); void writeTo(PerformanceLogger performanceLogger) { if (metadata() != null) { performanceLogger.log(operation(), durationMs(), metadata()); } else { performanceLogger.log(operation(), durationMs()); } }
if (refEnforcementPolicy == EnforcePolicy.IGNORED) return; String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been " + "persisted locally but not in SharedRef the value %s", projectName, refPair.getName(), refPair.putValue); boolean succeeded; try { succeeded = sharedRefDb.compareAndPut(projectName, getLatestLocalRef(refPair), refPair.putValue); } catch (IOException e) { throw new SharedDbSplitBrainException(errorMessage, e); } if (!succeeded) { throw new SharedDbSplitBrainException(errorMessage); } } protected void checkIfLocalRefIsUpToDateWithSharedRefDb( RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return; }
private void updateSharedRefDb(Stream<ReceiveCommand> commandStream, List<RefPair> refsToUpdate) throws IOException { if (commandStream.anyMatch(cmd -> cmd.getResult() != ReceiveCommand.Result.OK)) { return; } List<RefPair> updatedRefPairs = refsToUpdate.stream() .filter(distinctByKey(BatchRefUpdateValidator::getName)) .map(p -> { try { Ref current = getLatestLocalRef(p); return new RefPair(p.compareRef, current.getObjectId()); } catch (IOException e) { throw new RuntimeException(e); } }) .collect(Collectors.toList()); for (RefPair refPair : updatedRefPairs) { updateSharedDbOrThrowExceptionFor(refPair); } } public static String getName(RefPair p) { return p.compareRef.getName(); } public static <T> Predicate<T> distinctByKey(Function<? super T, ?> keyExtractor) { Set<Object> seen = ConcurrentHashMap.newKeySet(); return t -> seen.add(keyExtractor.apply(t)); }
import java.util.Arrays; import java.util.EnumSet; import java.util.List; public interface ChangeApi { ChangeInfo get(List<ListChangesOption> options) throws RestApiException; default ChangeInfo get(ListChangesOption... options) throws RestApiException { return get(Arrays.asList(options)); } default ChangeInfo get() throws RestApiException { return get(EnumSet.complementOf(EnumSet.of(ListChangesOption.CHECK, ListChangesOption.SKIP_MERGEABLE, ListChangesOption.SKIP_DIFFSTAT))); } default ChangeInfo info() throws RestApiException { return get(EnumSet.noneOf(ListChangesOption.class)); } @Deprecated default ChangeEditApi edit() throws RestApiException { return new ChangeEditApi(this); } }
private static void runOneBenchmark(@NonNull CtfTestTrace testTrace, String testName, RunMethod method, Dimension dimension) { Performance perf = Performance.getDefault(); PerformanceMeter pm = perf.createPerformanceMeter(TEST_ID + testName); perf.tagAsSummary(pm, "Execution graph " + testName, dimension); for (int i = 0; i < LOOP_COUNT; i++) { LttngKernelTrace trace = null; IAnalysisModule module = null; String path = CtfTmfTestTraceUtils.getTrace(testTrace).getPath(); try { trace = new LttngKernelTrace(); module = new LttngKernelExecutionGraph(); module.setId("test"); trace.initTrace(null, path, CtfTmfEvent.class); module.setTrace(trace); method.execute(pm, module); /* Delete the supplementary files, so that the next iteration rebuilds the state system. */ File suppDir = new File(TmfTraceManager.getSupplementaryFileDir(trace)); for (File file : suppDir.listFiles()) { file.delete(); } } catch (TmfAnalysisException | TmfTraceException e) { // Handle exception } } } public void removeMember(UUID memberId) { if (members == null) { members = new ArrayList<>(); return; } members.remove(memberId); } bind(AccountCreator.class); factory(PushOneCommit.Factory.class); }; return sysInjector.createChildInjector(module); } @SuppressWarnings("unchecked") private static <T> T get(Object obj, String field) throws SecurityException, NoSuchFieldException, IllegalArgumentException, IllegalAccessException { Field f = obj.getClass().getDeclaredField(field); f.setAccessible(true); return (T) f.get(obj); } private static InetAddress getLocalHost() throws UnknownHostException { return InetAddress.getLoopbackAddress(); } private Daemon daemon; private ExecutorService daemonService; private Injector testInjector; private String url; private InetSocketAddress sshdAddress; private InetSocketAddress httpAddress; private GerritServer(File sitePath, Injector testInjector, Daemon daemon, ExecutorService daemonService) throws IOException, ConfigInvalidException { this.sitePath = sitePath; this.testInjector = testInjector; this.daemon = daemon; this.daemonService = daemonService; Config cfg = testInjector.getInstance(Key.get(Config.class, GerritServerConfig.class
protected RefPair getRefPairToUpdate(RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist( String.format("%s-%s", projectName, refName), () -> sharedRefDb.lockRef(projectName, refName) ); RefPair latestRefPair = getLatestLocalRef(refPair); boolean isInSync = latestRefPair.compareRef.equals(refPair.compareRef); if (!isInSync) { throw new OutOfSyncException( String.format("The local ref %s in project %s is out of sync with the shared ref database", refName, projectName) ); } return latestRefPair; }
info = getPatchSetInfo(ctx); ChangeUpdate update = ctx.getUpdate(psId); Change.Status status = change.getStatus(); if (status == Change.Status.MERGED) { return true; } change.setCurrentPatchSet(info); change.setStatus(Change.Status.MERGED); update.fixStatus(Change.Status.MERGED); update.setCurrentPatchSet(); if (change.isWorkInProgress()) { change.setWorkInProgress(false); update.setWorkInProgress(false); } StringBuilder msgBuf = new StringBuilder(); msgBuf.append("Change has been successfully pushed"); if (!refName.equals(change.getDest().get())) { msgBuf.append(" into "); if (refName.startsWith(Constants.R_HEADS)) { msgBuf.append("branch "); msgBuf.append(Repository.shortenRefName(refName)); } else { msgBuf.append(refName); } } msgBuf.append("."); ChangeMessage msg = ChangeMessagesUtil.newMessage(
public Result render(long timeout, boolean forceMeasure) { return NOT_IMPLEMENTED.createResult(); } public Result render() { return render(RenderParams.DEFAULT_TIMEOUT); } import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.osee.framework.jdk.core.type.Pair; @Path("word") public interface WordUpdateEndpoint { @POST @Consumes({MediaType.APPLICATION_JSON}) @Produces({MediaType.APPLICATION_JSON}) @Path("update") WordUpdateChange updateWordArtifacts(WordUpdateData data); @POST @Consumes({MediaType.APPLICATION_JSON}) @Produces({MediaType.APPLICATION_JSON}) @Path("render") Pair<String, Set<String>> renderWordTemplateContent(WordTemplateContentData data); } import java.util.Map; public class MenuLayoutParserFactory extends LayoutPullParserFactory { private static final String FRAME_LAYOUT_XML = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n" + "<FrameLayout\n" + " xmlns:android=\"http://schemas.android.com/apk/res/android\"\n" + " android:layout_width=\"match_parent\"\n" + " android:layout_height=\"match_parent\" />\n"; private final RenderService myRenderService; public MenuLayoutParserFactory(RenderService renderService) { assert renderService.supportsCapability(Capability.ACTION_BAR) : "Action Bar not supported."; this.myRenderService = renderService; } fields = config.getBoolean("logFormat", pretty, "verbose", false) ? VERBOSE_FIELDS : FIELDS; variant = firstNonNull(config.getString("logFormat", pretty, "variant"), pretty); } public void renderStreaming(Paginator paginator, @Nullable String revision, Renderer renderer, Writer out, DateFormatter df, FooterBehavior footerBehavior) throws IOException { out.write(renderer .newRenderer("gitiles.logEntriesHeader") .setData(toHeaderSoyData(paginator, revision)) .render() .get()); SoySauce.Renderer entryRenderer = renderer.newRenderer("gitiles.logEntryWrapper"); boolean renderedEntries = false; for (RevCommit c : paginator) { out.write(entryRenderer.setData(toEntrySoyData(paginator, c, df)).render().get()); out.flush(); renderedEntries = true; } if (!renderedEntries) {
private boolean isInternalRef(String refName) { return RefNames.isGerritRef(refName) || RefNames.isNoteDbMetaRef(refName); }
private boolean isInternalRef(String refName) { return refName.startsWith(RefNames.REFS_STARRED_CHANGES) || refName.startsWith(RefNames.REFS_SEQUENCES); }
EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist(String.format("%s-%s", projectName, refName), () -> sharedRefDb.lockRef(projectName, refName)); Ref localRef = getLatestLocalRef(refPair); boolean isInSync = (localRef != null) ? sharedRefDb.isUpToDate(projectName, localRef) : !sharedRefDb.exists(projectName, refName); if (!isInSync) { validationMetrics.incrementSplitBrainPrevention(); softFailBasedOnEnforcement(new OutOfSyncException(projectName, localRef), refEnforcementPolicy); } return new RefPair(localRef == null ? nullRef(refName) : localRef, refPair.putValue); private Ref getLatestLocalRef(RefPair refPair) throws IOException { return refDb.exactRef(refPair.getName()); } protected boolean isSuccessful(RefUpdate.Result result) { switch (result) { case NEW: case FORCED: case FAST_FORWARD: case NO_CHANGE: return true; default: return false; } }
HttpServletResponse res, int statusCode, String msg, CacheControl c, @Nullable Throwable err) throws IOException { if (err != null) { RequestUtil.setErrorTraceAttribute(req, err); } configureCaching(req, res, null, null, c); checkArgument(statusCode >= 400, "non-error status: %s", statusCode); res.setStatus(statusCode); logger.atWarning().withCause(err).log("REST call failed: %d", statusCode); return replyText(req, res, true, msg); } /** * Sets a text reply on the given HTTP servlet response. * * @param req the HTTP servlet request * @param res the HTTP servlet response on which the reply should be set * @param allowTracing whether it is allowed to log the reply if tracing is enabled, must not be * set to {@code true} if the reply may contain sensitive data * @param text the text reply */
} return Optional.empty(); } private Optional<Project.NameKey> getProjectNameForChangeId(String changeId) { Optional<Project.NameKey> projectName = extractProjectNameFromChangeId(changeId); if (projectName.isPresent()) { return projectName; } try { List<ChangeData> changeData = globals .queryProvider .get() .setRequestedFields(ChangeField.PROJECT) .setLimit(1) .query(globals.changeQueryBuilder.change(changeId)); if (changeData.isEmpty()) { return Optional.empty(); } return Optional.of(changeData.get(0).project()); } catch (QueryParseException e) { return Optional.empty(); } } @VisibleForTesting static Optional<Project.NameKey> extractProjectNameFromChangeId(String changeId) { int projectEndPosition = changeId.indexOf('~'); if (projectEndPosition <= 0) { return Optional.empty(); } return Optional.of( Project.nameKey(IdString.fromUrl(changeId.substring(0, projectEndPosition)).get())); } private boolean isDelete(HttpServletRequest req)
package com.google.gerrit.server; import com.google.auto.value.AutoValue; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.logging.TraceContext; import java.util.Optional; /** Information about a request that was received from a user. */ @AutoValue public abstract class RequestInfo { public enum RequestType { GIT_RECEIVE, GIT_UPLOAD, REST, SSH } /** Type of the request, telling through which channel the request was coming in (REST, Git receive, git upload, SSH). */ public abstract RequestType getRequestType(); /** The user that has sent the request. */ public abstract CurrentUser getCallingUser(); /** The trace context of the request. */ public abstract TraceContext getTraceContext(); /** * The name of the project for which the request is being done. Only available if the request is * tied to a project or change. If a project is available it's not guaranteed that it actually * exists. */ public abstract Optional<Project.NameKey> getProjectName(); }
import com.google.common.hash.Hashing; import com.google.gerrit.common.data.GroupReference; import com.google.gerrit.extensions.annotations.PluginCanonicalWebUrl; import com.google.gerrit.extensions.annotations.PluginName; import com.google.gerrit.extensions.api.groups.Groups; import com.google.gerrit.extensions.common.GroupInfo; import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.ResourceConflictException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.reviewdb.client.Project.NameKey; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.account.GroupMembership; import com.google.gerrit.server.config.AllProjectsNameProvider; import com.google.gerrit.server.config.PluginConfigFactory; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.gerrit.server.permissions.ProjectPermission; import com.google.gerrit.server.project.CreateProjectArgs; import com.google.gerrit.server.project.NoSuchProjectException; import com.google.gerrit.server.validators.ProjectCreationValidationListener; import com.google.gerrit.server.validators.ValidationException;
private boolean isOwner(Project.NameKey project) { try { permissionBackend.user(self.get()).project(project).check(ProjectPermission.WRITE_CONFIG); } catch (AuthException | PermissionBackendException noWriter) { try { permissionBackend.user(self.get()).check(GlobalPermission.ADMINISTRATE_SERVER); } catch (AuthException | PermissionBackendException noAdmin) { return false; } } return true; }
/** * Returns the result of {@link #get(ListChangesOption...)} with all options included, except for the following: * - {@code CHECK} is omitted, to skip consistency checks. * - {@code SKIP_MERGEABLE} is omitted, so the {@code mergeable} bit is set. * - {@code SKIP_DIFFSTAT} is omitted to skip diffstat calculations. */ default ChangeInfo get() throws RestApiException { return get(EnumSet.complementOf(EnumSet.of( ListChangesOption.CHECK, ListChangesOption.SKIP_MERGEABLE, ListChangesOption.SKIP_DIFFSTAT))); } /** * Returns the result of {@link #get(ListChangesOption...)} with no options included. */ default ChangeInfo info() throws RestApiException { return get(EnumSet.noneOf(ListChangesOption.class)); } /** * Retrieves the change edit when it exists. * * @deprecated Replaced by {@link ChangeApi#edit()} in combination with {@link * ChangeApi#getEdit()}. */ default EditApi getEdit() throws RestApiException { return changeApi().edit(); }
import org.eclipse.jgit.revwalk.RevCommit; /** * Allows to modify message for new commits generated by submit strategies. * * Invoked by Gerrit when all information about new commit is already known such * as parent(s), tree hash, etc, but commit's message can still be modified. */ @ExtensionPoint public interface ChangeMessageModifier { /** * @param newCommitMessage * @param original * @param mergeTip * @param ctl * @return */ String onCommitBeingCreated(String newCommitMessage, RevCommit original, RevCommit mergeTip, ChangeControl ctl); } import org.eclipse.jgit.revwalk.RevCommit; /** * Allows to modify message for new commits generated by submit strategies. * * Invoked by Gerrit when all information about new commit is already known such * as parent(s), tree hash, etc, but commit's message can still be modified. */ @ExtensionPoint public interface ChangeMessageModifier { /** * @param newCommitMessage * @param original * @param mergeTip * @param ctl * @return */ String onSubmit(String newCommitMessage, RevCommit original, RevCommit mergeTip, Branch.NameKey destination); } } } throw new IllegalStateException(); } private void checkSubmitRulesAndState(ChangeSet cs) throws ResourceConflictException, OrmException { StringBuilder msgbuf = new StringBuilder(); List<Change.Id> problemChanges = new ArrayList<>(); for (PatchSet.Id id : cs.patchIds()) { try { ChangeData cd = changeDataFactory.create(db, id.getParentKey()); if (!cd.change().currentPatchSetId().equals(id)) { throw new ResourceConflictException( "Submission depends on revision " + id.get() + " of Change " + id.getParentKey().get() + ", but latest revision is " + cd.change().currentPatchSetId().get()); } if (cd.change().getStatus() != Change.Status.NEW) { throw new ResourceConflictException("Change " + cd.change().getChangeId() + " is in state " + cd.change().getStatus()); } else { records.put(cd.change().getId(), checkSubmitRule(cd)); } } catch (ResourceConflictException e) { } } throw new IllegalStateException(); } private void checkSubmitRulesAndState(ChangeSet cs) throws ResourceConflictException, OrmException { StringBuilder msgbuf =
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api.changes; import java.util.List; /** * Detailed information about who should be notified about an update. */ public class NotifyInfo { public List<String> accounts; /** * @param accounts may be either just a list of: account IDs, Full names, usernames, or emails. * It can also be a list of those in the format "Full name <email@example.com>" * or "Full name (<ID>)" */ public NotifyInfo(List<String> accounts) { this.accounts = accounts; } }
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api.changes; import java.util.List; /** * Detailed information about who should be notified about an update. */ public class NotifyInfo { public List<String> accounts; /** * @param accounts a list of account IDs, full names, or usernames. It can also be a list of * "Full name <email@example.com>" or "Full name (<ID>)" */ public NotifyInfo(List<String> accounts) { this.accounts = accounts; } }
addDraft(changeId, revId, comment); assertThat(gApi.changes().query("change:" + changeId + " has:draft").get()).hasSize(1); } @Test public void publishCommentsAllRevisions() throws Exception { PushOneCommit.Result result = createChange(); String changeId = result.getChangeId(); pushFactory .create(db, admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "initial content\n", changeId) .to("refs/heads/master"); PushOneCommit.Result r1 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "old boring content\n") .to("refs/for/master"); PushOneCommit.Result r2 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "new interesting\ncntent\n", r1.getChangeId()) .to("refs/for/master"); addDraft(r1.getChangeId(), r1.getCommit().getName(), comment); assertThat(gApi.changes().query("change:" + changeId + " has:draft").get()).hasSize(1); }
@Test public void publishCommentsAllRevisions() throws Exception { PushOneCommit.Result result = createChange(); String changeId = result.getChangeId(); pushFactory .create(db, admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "initial content\n", changeId) .to("refs/heads/master"); PushOneCommit.Result r1 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "old boring content\n") .to("refs/for/master"); PushOneCommit.Result r2 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "new interesting\ncntent\n", r1.getChangeId()) .to("refs/for/master"); addDraft(r1.getChangeId(), r1.getCommit().getName(), comment); assertThat(gApi.changes().query("change:" + changeId + " has:draft").get()).hasSize(1); }
protected void configure() { if (!noteDb.enabled()) { throw new ProvisionException("Gerrit is still running on ReviewDb: please migrate to NoteDb and then reload the multi-site plugin."); } Collection<Message> validationErrors = config.validate(); if (!validationErrors.isEmpty()) { throw new CreationException(validationErrors); } listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); DynamicItem.itemOf(binder(), BrokerSession.class); DynamicItem.bind(binder(), BrokerSession.class).to(BrokerSessionNoOp.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } install(kafkaForwardedEventRouterModule); install(kafkaBrokerForwarderModule); install(new ValidationModule(config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); }
import java.io.IOException; import java.util.Properties; /** * Wrapper around data passed from the installer. */ public class InstallerData { @VisibleForTesting static final ScopedStateStore.Key<InstallerData> CONTEXT_KEY = ScopedStateStore.createKey("installer.handoff.data", ScopedStateStore.Scope.WIZARD, InstallerData.class); public static final String PATH_FIRST_RUN_PROPERTIES = FileUtil.join("studio", "installer", "firstrun.properties"); @VisibleForTesting InstallerData(@Nullable String javaDir, @Nullable String androidSrc, @Nullable String androidDest) { myJavaDir = javaDir; myAndroidSrc = androidSrc; myAndroidDest = androidDest; } private static InstallerData parse() { Properties properties = readProperties(); return new InstallerData(getIfExists(properties, "jdk.dir"), getIfExists(properties, "androidsdk.repo"), properties.getProperty("androidsdk.dir")); } private static Properties readProperties() { Properties properties = new Properties(); try { // Read properties from file } catch (IOException e) { // Handle exception } return properties; } public void testEncode() { assertEquals("ab%2F$%C4%82%2512", CODEC.encode("ab/$\u0102%12", StandardCharsets.UTF_8)); } public void setGameField(int xPos, int yPos, int color) { if (field[xPos][yPos] == EMPTY) { if (color == WHITE_PLAYER) { field[xPos][yPos] = WHITE; } if (color == BLACK_PLAYER) { field[xPos][yPos] = BLACK; } } } public void someMethod() { try { // Kafka consumer subscribing to topic consumer.subscribe(Collections.singleton(topic)); while (!closed.get()) { ConsumerRecords<byte[], byte[]> consumerRecords = consumer.poll(Duration.ofMillis(configuration.kafkaSubscriber().getPollingInterval())); consumerRecords.forEach(this::processRecord); } } catch (WakeupException e) { // Ignore exception if closing if (!closed.get()) { throw e; } } catch (KafkaException e) { subscriberMetrics.incrementSubscriberFailedToPollMessages(); throw e; } finally { consumer.close(); } } }
subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (IOException e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (PermissionBackendException | OrmException e) { logger.atSevere().withCause(e).log( "Cannot handle message %s: [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } } catch (Exception e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", new String(consumerRecord.value(), UTF_8)); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); }
for (String src : delta) { Ref r = local.get(src); if (r != null) { n.put(src, r); } } local = n; } local = forProject.filter(local, git, RefFilterOptions.builder().setFilterMeta(true).build()); List<RemoteRefUpdate> remoteUpdatesList = pushAllRefs ? doPushAll(tn, local) : doPushDelta(local); ReplicationPushFilter pushFilter = replicationPushFilter.get(); remoteUpdatesList = pushFilter == null ? remoteUpdatesList : pushFilter.filter(projectName.get(), remoteUpdatesList); return remoteUpdatesList; } private List<RemoteRefUpdate> doPushAll(Transport tn, Map<String, Ref> local) throws NotSupportedException, TransportException, IOException { List<RemoteRefUpdate> cmds = new ArrayList<>(); boolean noPerms = !pool.isReplicatePermissions(); Map<String, Ref> remote = listRemote(tn); for (Ref src : local.values()) { if (!canPushRef(src.getName(), noPerms)) { continue; } // rest of the code } // rest of the code }
protected void configure() { DynamicItem.itemOf(binder(), BeforeReplicationPushFilter.class); DynamicItem.bind(binder(), BeforeReplicationPushFilter.class).to(BeforeReplicationPushFilterNoOP.class); }
return java.nio.file.Files.createTempDirectory(prefix); } @Test public void shouldLoadNotEmptyInitialReplicationConfig() throws Exception { FileBasedConfig replicationConfig = newReplicationConfig(); replicationConfig.setString("remote", "foo", "url", "ssh://git@git.somewhere.com/${name}"); replicationConfig.save(); autoReloadConfig = new AutoReloadConfigDecorator( sitePaths, destinationFactoryMock, Providers.of(replicationQueueMock), pluginDataPath, "replication", workQueueMock); assertThat(autoReloadConfig.getDestinations(FilterType.ALL)).isNotEmpty(); } @Test public void shouldAutoReloadReplicationConfig() throws Exception { FileBasedConfig replicationConfig = newReplicationConfig(); replicationConfig.setBoolean("gerrit", null, "autoReload", true); replicationConfig.setString("remote", "foo", "url", "ssh://git@git.foo.com/${name}"); replicationConfig.save(); autoReloadConfig = new AutoReloadConfigDecorator( sitePaths, destinationFactoryMock, Providers.of(replicationQueueMock), pluginDataPath, "replication", workQueueMock); autoReloadConfig.startup(workQueueMock); }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.index; import java.util.Optional; public class OnlineReindexMode { private static ThreadLocal<Boolean> isOnlineReindex = new ThreadLocal<>(); public static boolean get() { return Optional.ofNullable(isOnlineReindex.get()).orElse(Boolean.FALSE); } public static void begin() { isOnlineReindex.set(Boolean.TRUE); } public static void end() { isOnlineReindex.set(Boolean.FALSE); } }
public static boolean isActive() { return Optional.ofNullable(isOnlineReindex.get()).orElse(Boolean.FALSE); }
import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class JgitWrapper { private static final Logger log = LoggerFactory.getLogger(JgitWrapper.class); public static Optional<byte[]> getBlobAsBytes(Repository repository, String revision, String path) throws IOException { ObjectId objectId = repository.resolve(revision); if (objectId == null) { return Optional.empty(); } try (final TreeWalk w = TreeWalk.forPath(repository, path, parseCommit(repository, objectId).getTree())) { return Optional.ofNullable(w) .filter(walk -> (walk.getRawMode(0) & TYPE_MASK) == TYPE_FILE) .map(walk -> walk.getObjectId(0)) .flatMap(id -> readBlob(repository, id)); } } private static RevCommit parseCommit(Repository repository, ObjectId commit) throws IOException { try (final RevWalk walk = new RevWalk(repository)) { walk.setRetainBody(true); return walk.parseCommit(commit); } } private static Optional<byte[]> readBlob(Repository repository, ObjectId id) { // implementation } }
// You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.quota; public class QuotaGroupDefinitions { public static final String REPOSITORY_SIZE_GROUP = "/repository:size"; private QuotaGroupDefinitions() {} }
private static boolean isContentTooLargeForDisplay(String content) { int lines = 0; int nl = -1; while (true) { nl = nextLineBreak(content, nl + 1, content.length()); if (nl < 0) { return false; } else if (++lines == MAX_LINE_COUNT) { return true; } } }
private static boolean isContentTooLargeForDisplay(String content) { Matcher m = Pattern.compile("\r\n|\r|\n").matcher(content); int lines = 0; while (m.find() && lines < MAX_LINE_COUNT) { lines++; } return lines >= MAX_LINE_COUNT; }
at, Duration.ofMillis(cfg.getTimeUnit("retry", at.name(), "timeout", SECONDS.toMillis(defaultTimeout.getSeconds()), MILLISECONDS))); this.waitStrategy = WaitStrategies.join( WaitStrategies.exponentialWait( cfg.getTimeUnit("retry", null, "maxWait", SECONDS.toMillis(5), MILLISECONDS), MILLISECONDS), WaitStrategies.randomWait(50, MILLISECONDS)); this.overwriteDefaultRetryerStrategySetup = overwriteDefaultRetryerStrategySetup; this.retryWithTraceOnFailure = cfg.getBoolean("retry", "retryWithTraceOnFailure", false);
package com.google.gerrit.server.logging; import com.google.auto.value.AutoValue; import java.util.Optional; /** * The record of an operation for which the execution time was measured. * Metadata to provide additional context can be included by provided a {@link Metadata} instance. */ @AutoValue public abstract class PerformanceLogRecord { /** * Creates a performance log record without meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs) { return new AutoValue_PerformanceLogRecord(operation, durationMs, Optional.empty()); } /** * Creates a performance log record with meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @param metadata the metadata to provide additional context * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs, Metadata metadata) { return new AutoValue_PerformanceLogRecord(operation, durationMs, Optional.of(metadata)); } /** * Returns the name of the operation. * * @return the operation name */ public abstract String getOperation(); /** * Returns the execution time in milliseconds. * * @return the execution time */ public abstract long getDurationMs(); /** * Returns the metadata associated with the performance log record. * * @return the metadata */ public abstract Optional<Metadata> getMetadata(); /** * Metadata to provide additional context for the performance log record. */ @AutoValue public abstract static class Metadata { /** * Creates a metadata instance. * * @param key the metadata key * @param value the metadata value * @return the metadata instance */ public static Metadata create(String key, String value) { return new AutoValue_PerformanceLogRecord_Metadata(key, value); } /** * Returns the metadata key. * * @return the metadata key */ public abstract String getKey(); /** * Returns the metadata value. * * @return the metadata value */ public abstract String getValue
public abstract static class Builder { public abstract Builder listener(RetryListener listener); public abstract Builder timeout(Duration timeout); public abstract Options build(); } @VisibleForTesting @Singleton public static class Metrics { final Counter1<ActionType> attemptCounts; final Counter1<ActionType> timeoutCount; @Inject Metrics(MetricMaker metricMaker) { Field<ActionType> actionTypeField = Field.ofEnum( ActionType.class, "action_type", (metadataBuilder, fieldValue) -> metadataBuilder.actionType(fieldValue.name()) ).build(); attemptCounts = metricMaker.newCounter( "action/retry_attempt_count", new Description("Number of retry attempts made by RetryHelper to execute an action" + " (0 == single attempt, no retry)") .setCumulative() .setUnit("attempts"), actionTypeField ); timeoutCount = metricMaker.newCounter( "action/retry_timeout_count", new Description("Number of action executions of RetryHelper that ultimately timed out") .setCumulative() .setUnit("attempts"), actionTypeField ); } }
public void setup() { projectCreationListener = new TraceValidatingProjectCreationValidationListener(); projectCreationListenerRegistrationHandle = projectCreationValidationListeners.add("gerrit", projectCreationListener); commitValidationListener = new TraceValidatingCommitValidationListener(); commitValidationRegistrationHandle = commitValidationListeners.add("gerrit", commitValidationListener); changeIndexedListener = new TraceChangeIndexedListener(); changeIndexedListenerRegistrationHandle = changeIndexedListeners.add("gerrit", changeIndexedListener); testPerformanceLogger = new TestPerformanceLogger(); performanceLoggerRegistrationHandle = performanceLoggers.add("gerrit", testPerformanceLogger); }
package com.google.gerrit.util.cli; import java.util.Optional; /** * Classes that define command-line options by using the {@link org.kohsuke.args4j.Option} * annotation can implement this class to accept and handle unknown options. * * <p>If a user specifies an unknown option and this unknown options doesn't get accepted, the * parsing of the command-line options fails and the user gets an error (this is the default * behavior if classes do not implement this interface). */ public interface UnknownOptionHandler { /** * Whether an unknown option should be accepted. * * <p>If an unknown option is not accepted, the parsing of the command-line options fails and the * user gets an error. * * <p>This method can be used to ignore unknown options (without failure for the user) or to * handle them in a custom way. * * @param option the unknown option * @return {@code true} if the unknown option should be accepted, {@code false} otherwise */ boolean acceptUnknownOption(String option); }
boolean accept(String name, String value);
.buildRepeatable(a -> { if (a.getAccount().getMetaId() == null) { return ImmutableList.of(); } return ImmutableList.of( RefState.create( RefNames.refsUsers(a.getAccount().getId()), ObjectId.fromString(a.getAccount().getMetaId()) ) .toByteArray(new AllUsersName(AllUsersNameProvider.DEFAULT)) ); }); /** * All note values of all external IDs that were used in the course of indexing this document. * * <p>Emitted as UTF-8 encoded strings of the form {@code [hex sha of external ID]:[hex sha of * note blob]}, or with other words {@code [note ID]:[note data ID]}. */
Ref ref = repo.exactRef(RefNames.refsUsers(id)); return ref != null; } for (Map.Entry<Project.NameKey, RefState> e : RefState.parseStates(result.get().getValue(AccountField.REF_STATE)).entries()) { Project.NameKey repoName = e.getKey().get().equals(AllUsersNameProvider.DEFAULT) ? allUsersName : e.getKey(); try (Repository repo = repoManager.openRepository(repoName)) { if (!e.getValue().match(repo)) { return true; } } } Set<ExternalId> extIds = externalIds.byAccount(id); ListMultimap<ObjectId, ObjectId> extIdStates = parseExternalIdStates(result.get().getValue(AccountField.EXTERNAL_ID_STATE)); if (extIdStates.size() != extIds.size()) {
stateLog.error(String.format("source project %s not available", project), err, state); return; } } synchronized (stateLock) { PushOne e = pending.get(uri); if (e == null) { e = opFactory.create(project, uri); addRef(e, ref); e.addState(ref, state); pool.schedule(e, now ? 0 : config.getDelay(), TimeUnit.SECONDS); pending.put(uri, e); eventsStorage.persist(project.get(), ref, e.getURI()); } else if (!e.getRefs().contains(ref)) { addRef(e, ref); e.addState(ref, state); } state.increasePushTaskCount(project.get(), ref); repLog.info("scheduled {}:{} => {} to run after {}s", project, ref, e, config.getDelay()); }
private static Node processNodeWithoutAttributes(Node node, Document doc) { Node localNode = node; Element elem = null; String URI = Strings.nullToEmpty(node.getNamespaceURI()); String name = node.getNodeName().toLowerCase(); if (name.equals("#text")) { localNode = processTextNode(node, doc); } else if (name.length() == 1) { switch (name.charAt(0)) { case 'b': try { localNode = doc.renameNode(localNode, URI, "strong"); } catch (DOMException ex) { // do nothing cannot rename this node type (text node) } break; case 'i': try { localNode = doc.renameNode(localNode, URI, "em"); } catch (DOMException ex) { // do nothing cannot rename this node type (text node) } break; case 'u': if (localNode instanceof Element) { try { localNode = doc.renameNode(localNode, URI, "u"); } catch (DOMException ex) { // do nothing cannot rename this node type (text node) } } break; } } return localNode; } public boolean isRepresentationsResource() { boolean isRepresentationsResource = false; try { URI uri = resource.getURI(); isRepresentationsResource = uri != null && new FileQuery(uri.fileExtension()).isSessionResourceFile(); } catch (IllegalStateException e) { // Silent catch: if an issue occurred while getting this Resource's // URI, then it will not be considered as a representation resource } isRepresentationsResource = isRepresentationsResource || resource instanceof AirdResource; if (!isRepresentationsResource && !resource.getContents().isEmpty()) { for (EObject contentEObject : resource.getContents()) { if (contentEObject instanceof DAnalysis) { isRepresentationsResource = true; break; } } } return isRepresentationsResource; } if (null == selectedFile) { monitor.worked(1); result.add(new Status(IStatus.ERROR, Activator.PLUGIN_ID, Messages.DeployCreationMenuModelHandler_ElementNotAFile + selectedElement.toString())); } else { String fileName = selectedFile.getFullPath().removeFileExtension().lastSegment(); monitor
public void delete(String project, String ref, URIish uri) { String eventKey = getEventKey(getEventJson(project, ref, uri)); try { logger.atFiner().log("**DELETE** %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); } }
if (watchedTypes.contains(type)) { matching.bcc.accounts.add(accountId); } logger.atFine().log("Added account %s as watcher", accountId); return true; } catch (QueryParseException e) { logger.atWarning().withCause(e).log("Account %s has invalid filter in project watch %s: %s", accountId, key, e.getMessage()); } return false;
@VisibleForTesting private ImmutableList<RefUpdatedEvent> getRefUpdatedEvents(String project, String refName, int expectedSize) { String key = refEventKey(RefUpdatedEvent.TYPE, project, refName); if (expectedSize == 0) { assertThat(recordedEvents).doesNotContainKey(key); return ImmutableList.of(); } assertThat(recordedEvents).containsKey(key); ImmutableList<RefUpdatedEvent> events = FluentIterable.from(recordedEvents.get(key)) .transform(RefUpdatedEvent.class::cast) .toList(); assertThat(events).hasSize(expectedSize); return events; } @VisibleForTesting public ImmutableList<ChangeMergedEvent> getChangeMergedEvents(String project, String branch, int expectedSize) { String key = refEventKey(ChangeMergedEvent.TYPE, project, branch); if (expectedSize == 0) { assertThat(recordedEvents).doesNotContainKey(key); return ImmutableList.of(); } assertThat(recordedEvents).containsKey(key); ImmutableList<ChangeMergedEvent> events = FluentIterable.from(recordedEvents.get(key)) .transform(ChangeMergedEvent.class::cast) .toList(); assertThat(events).hasSize(expectedSize); return events; }
assertThat(cd.change().getStatus()).isEqualTo(Change.Status.MERGED); assertSubmitApproval(psId); assertThat(cd.patchSets()).hasSize(1); assertThat(cd.patchSet(psId).getRevision().get()).isEqualTo(c.name()); @Test public void correctNewRevOnMergeByPushToBranch() throws Exception { grant(project, "refs/heads/master", Permission.PUSH); PushOneCommit.Result r1 = push("refs/for/master", PushOneCommit.SUBJECT, "one.txt", "One"); PushOneCommit.Result r2 = push("refs/for/master", PushOneCommit.SUBJECT, "two.txt", "Two"); startEventRecorder(); git().push().setRefSpecs(new RefSpec(r2.getCommit().name() + ":refs/heads/master")).call(); List<ChangeMergedEvent> changeMergedEvents = eventRecorder.getChangeMergedEvents(project.get(), "refs/heads/master", 2); assertThat(changeMergedEvents.get(0).newRev).isEqualTo(r2.getPatchSet().getRevision().get()); }
import org.eclipse.jdt.core.IJavaProject; import org.eclipse.jdt.core.IModuleDescription; import org.eclipse.jdt.internal.launching.LaunchingMessages; import org.eclipse.jdt.launching.sourcelookup.advanced.AdvancedJavaLaunchDelegate; import org.eclipse.osgi.util.NLS; /** * A launch delegate for launching local Java applications. * <p> * Clients may subclass and instantiate this class. * </p> * * @see AdvancedJavaLaunchDelegate * @since 3.1 */ public class JavaLaunchDelegate extends AbstractJavaLaunchConfigurationDelegate { /* (non-Javadoc) * @see org.eclipse.debug.core.model.ILaunchConfigurationDelegate#launch(org.eclipse.debug.core.ILaunchConfiguration, java.lang.String, org.eclipse.debug.core.ILaunch, org.eclipse.core.runtime.IProgressMonitor) */ @Override public void launch(ILaunchConfiguration configuration, String mode, ILaunch launch, IProgressMonitor monitor) throws CoreException { if (monitor == null) { monitor = new NullProgressMonitor(); } } } public void test_getRootDirectories() { Iterable<Path> rootDirectories = fileSystem.getRootDirectories(); Map<Path, Boolean> pathMap = new HashMap<>(); rootDirectories.forEach(path -> pathMap.put(path, true)); assertEquals(1, pathMap.size()); assertTrue(pathMap.get(Paths.get("/"))); } private void handleEvent(RefEvent refEvent) { Set<Map<String, String>> properties = propertyExtractor.extractFrom(refEvent); for (Map<String, String> propertiesMap : properties) { Collection<ActionRequest> actions = ruleBase.actionRequestsFor(propertiesMap); if (!actions.isEmpty()) { actionExecutor.execute(actions, propertiesMap); } } } uri); } else { if (canceledWhileRunning.get()) { logCanceledWhileRunningException(e); } else { repLog.error("Cannot replicate to {}", uri, e); pool.reschedule(this, Destination.RetryReason.TRANSPORT_ERROR); } } } catch (IOException e) { stateLog.error("Cannot replicate to " + uri, e, getStatesAsArray()); } catch (PermissionBackendException | RuntimeException | Error e) { stateLog.error("Unexpected error during replication to " + uri, e, getStatesAsArray()); } finally { pool.notifyFinished(this); if (git != null) { git
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; import org.eclipse.jgit.transport.RemoteRefUpdate; /** * Filter that is invoked before list of remote ref updates is pushed to remote instance. It can be * used to filter out unwanted updates. */ @ExtensionPoint public interface ReplicationPushFilter { public List<RemoteRefUpdate> filter(String projectName, List<RemoteRefUpdate> remoteUpdatesList); }
import java.util.Set; import javax.servlet.http.HttpServletRequest; class AccountSecurityImpl extends BaseServiceImplementation implements AccountSecurity { private final Logger log = LoggerFactory.getLogger(getClass()); private final GerritServer server; private final ContactStore contactStore; private final RegisterNewEmailSender.Factory emailSenderFactory; @Inject AccountSecurityImpl(final SchemaFactory<ReviewDb> sf, final GerritServer gs, final ContactStore cs, final RegisterNewEmailSender.Factory esf) { super(sf); server = gs; contactStore = cs; emailSenderFactory = esf; } public void mySshKeys(final AsyncCallback<List<AccountSshKey>> callback) { run(callback, new Action<List<AccountSshKey>>() { public List<AccountSshKey> run(ReviewDb db) throws OrmException { return db.accountSshKeys().byAccount(Common.getAccountId()).toList(); } }); } public void addSshKey(final String keyText, final AsyncCallback<AccountSshKey> callback) { run(callback, new Action<AccountSshKey>() { public AccountSshKey run(final ReviewDb db) throws OrmException, Failure { // implementation } }); } }
private Renderer renderer(String templateName) { return args.soySauce .renderTemplate("com.google.gerrit.server.mail.template." + templateName) .setData(soyContext); }
// limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.server.util.SystemLog; import com.google.inject.Inject; import com.google.inject.Singleton; import org.apache.log4j.PatternLayout; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Log4jSharedRefLogger extends LibModuleLogFile implements SharedRefLogger { private static final String LOG_NAME = "sharedref_log"; private final Logger sharedRefDBLog; @Inject public Log4jSharedRefLogger(SystemLog systemLog) { super(systemLog, LOG_NAME, new PatternLayout("[%d{ISO8601}] [%t] %-5p : %m%n")); sharedRefDBLog = LoggerFactory.getLogger(LOG_NAME); } @Override public void log(String project, Ref currRef, ObjectId newRefValue) { sharedRefDBLog.info( "project:{}|ref:{}|oldId:{}|newId:{}", project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName()); } }
public void logRefUpdate(String project, Ref currRef, ObjectId newRefValue) { sharedRefDBLog.info("project:{}|ref:{}|oldId:{}|newId:{}", project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName()); }
public void logProjectDelete(String project) { sharedRefDBLog.info("project:{}|DELETED", project); }
public void onProjectDeleted(Event event) { String projectName = event.getProjectName(); logger.atInfo().log("Deleting project '%s'. Will perform a cleanup in Shared-Ref database.", projectName); try { sharedDb.removeProject(projectName); sharedRefLogger.logDeletion(projectName); } catch (IOException e) { validationMetrics.incrementSplitBrain(); logger.atSevere().withCause(e).log("Project '%s' deleted from GIT but it was not able to cleanup from Shared-Ref database", projectName); } }
String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been " + "persisted locally but not in SharedRef the value %s", projectName, refPair.getName(), refPair.putValue); boolean succeeded; try { succeeded = sharedRefDb.compareAndPut(projectName, refPair.compareRef, refPair.putValue); sharedRefLogger.log(projectName, refPair.compareRef, refPair.putValue); } catch (IOException e) { throw new SharedDbSplitBrainException(errorMessage, e); } if (!succeeded) { throw new SharedDbSplitBrainException(errorMessage); } protected RefPair compareAndGetLatestLocalRef(RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist( new SharedLock(projectName, refName, refEnforcementPolicy, sharedRefDb)); RefPair latestRefPair = sharedRefDb.get(projectName, refName); if (latestRefPair == null) { throw new OutOfSyncException( String.format("The ref '%s' does not exist in SharedRef", refName)); } if (!latestRefPair.compareRef.equals(refPair.compareRef)) { throw new OutOfSyncException( String.format("The ref '%s' is out of sync in SharedRef", refName)); } return latestRefPair; }
private String replaceInUrl(String placeholder, String url, String replacement, boolean lowerCase) { if (url == null || replacement == null || !url.contains(placeholder)) { return url; } if (lowerCase) { replacement = replacement.toLowerCase(); } // as we can't assume anything of 'replacement', we're URL encoding it return url.replace(placeholder, Url.encode(replacement)); }
public void cancel() { repLog.info("Replication [{}] to {} was canceled", IdGenerator.format(id), getURI()); canceledByReplication(); pool.pushWasCanceled(this); }
public void setCanceledWhileRunning() { repLog.info("Replication [{}] to {} was canceled while being executed", IdGenerator.format(id), getURI()); canceledWhileRunning.set(true); }
public void logRefUpdate(String project, Ref currRef, ObjectId newRefValue) { try (Repository repository = gitRepositoryManager.openRepository(new Project.NameKey(project))) { RevWalk walk = new RevWalk(repository); if (!ObjectId.zeroId().equals(newRefValue)) { RevCommit commit = walk.parseCommit(newRefValue); sharedRefDBLog.info(gson.toJson(new SharedRefLogEntry.UpdateRef( project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName(), CommonConverters.toGitPerson(commit.getCommitterIdent()), commit.getFullMessage()))); } else { sharedRefDBLog.info(gson.toJson(new SharedRefLogEntry.DeleteRef( project, currRef.getName(), currRef.getObjectId().getName()))); } } catch (IOException e) { logger.atSevere().withCause(e).log( "Cannot log sharedRefDB interaction for ref %s on project %s", currRef.getName(), project); } }
String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } public static class DeleteProject extends SharedRefLogEntry { public String refName; public String oldId; DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } }
private int getInt(PluginConfig cfg, String name, int defaultValue) { try { return cfg.getInt(name, defaultValue); } catch (IllegalArgumentException e) { log.error(String.format("invalid value for %s; using default value %d", name, defaultValue)); return defaultValue; } } replicateAllOnPluginStart = config.getBoolean("gerrit", "replicateOnStartup", true); defaultForceUpdate = config.getBoolean("gerrit", "defaultForceUpdate", false); sshCommandTimeout = (int) ConfigUtil.getTimeUnit(config, "gerrit", null, "sshCommandTimeout", 30, SECONDS); sshConnectionTimeout = (int) SECONDS.toMillis(ConfigUtil.getTimeUnit(config, "gerrit", null, "sshConnectionTimeout", 120, SECONDS)); ImmutableList.Builder<Destination> dest = ImmutableList.builder(); for (RemoteConfig c : allRemotes(config)) { if (c.getURIs().isEmpty()) { continue; } for (RefSpec ref : c.getPushRefSpecs()) { if (ref.getDestination() == null) { ref.setDestination(ref.getSource()); } } if (c.getPushRefSpecs().isEmpty()) { c.addPushRefSpec( new RefSpec() .setSourceDestination("refs/*", "refs/*") .setForceUpdate(defaultForceUpdate) ); } }
private ImmutableSet<String> parseRequestTypes(String traceId) { return ImmutableSet.copyOf(cfg.getStringList("tracing", traceId, "requestType")); } private ImmutableSet<Account.Id> parseAccounts(String traceId) { ImmutableSet.Builder<Account.Id> accountIds = ImmutableSet.builder(); String[] accounts = cfg.getStringList("tracing", traceId, "account"); for (String account : accounts) { Optional<Account.Id> accountId = Account.Id.tryParse(account); if (!accountId.isPresent()) { throw new IllegalArgumentException( String.format("Invalid tracing config ('tracing.%s.account = %s'): invalid account ID", traceId, account)); } accountIds.add(accountId.get()); } return accountIds.build(); } private ImmutableSet<Pattern> parseProjectPatterns(String traceId) { ImmutableSet.Builder<Pattern> projectPatterns = ImmutableSet.builder(); String[] projectPatternRegExs = cfg.getStringList("tracing", traceId, "projectPattern"); for (String projectPatternRegEx : projectPatternRegExs) { try { Pattern pattern = Pattern.compile(projectPatternRegEx); projectPatterns.add(pattern); } catch (PatternSyntaxException e) { throw new IllegalArgumentException( String.format("Invalid tracing config ('tracing.%s.projectPattern = %s'): invalid regex", traceId, projectPatternRegEx)); } } return projectPatterns.build(); }
boolean matches(RequestInfo requestInfo) { if (requestTypes().stream().noneMatch(type -> type.equalsIgnoreCase(requestInfo.requestType()))) { return false; } if (!accountIds().isEmpty()) { try { if (accountIds().stream().noneMatch(id -> id.equals(requestInfo.callingUser().getAccountId()))) { return false; } } catch (UnsupportedOperationException e) { // calling user is not logged in return false; } } if (!projectPatterns().isEmpty()) { if (!requestInfo.project().isPresent()) { // request is not for a project return false; } if (projectPatterns().stream().noneMatch(p -> p.matcher(requestInfo.project().get().get()).matches())) { return false; } } return true; }
/** Java API to interact with single {@code Check}s. */ public interface CheckApi { /** Returns a {@link CheckInfo} for the scoped resource with the given options. */ CheckInfo get(ListChecksOption... options) throws RestApiException; /** Updates a check and returns the {@link CheckInfo} for the updated resource. */ CheckInfo update(CheckInput input) throws RestApiException; /** Reruns the check and returns the {@link CheckInfo} for the updated check. Input ignores "state". */ CheckInfo rerun(CheckInput input) throws RestApiException; /** * A default implementation which allows source compatibility when adding new methods to the * interface. */ class NotImplemented implements CheckApi { @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo update(CheckInput input) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo rerun(CheckInput input) throws RestApiException { throw new NotImplementedException(); } } }
try (MetaDataUpdate md = metaDataUpdateUser.create(rsrc.getNameKey())) { ProjectConfig config = ProjectConfig.read(md); setAccess.validateChanges(config, removals, additions); setAccess.applyChanges(config, removals, additions); try { setAccess.setParentName(identifiedUser.get(), config, rsrc.getNameKey(), newParentProjectName, false); } catch (AuthException e) { throw new IllegalStateException(e); } md.setMessage("Review access change"); md.setInsertChangeId(true); Change.Id changeId = new Change.Id(seq.nextChangeId()); RevCommit commit = config.commitToNewRef(md, new PatchSet.Id(changeId, Change.INITIAL_PATCH_SET_ID).toRefName()); try (ObjectInserter objInserter = md.getRepository().newObjectInserter(); ObjectReader objReader = objInserter.newReader(); RevWalk rw = new RevWalk(objReader); BatchUpdate bu = updateFactory.create(db.get(), config.getProject().getNameKey(), projectControl.getUser(),
import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.ConfigInvalidException; @Singleton public class RerunCheck implements RestModifyView<CheckResource, CheckInput> { private final PostCheck postCheck; @Inject RerunCheck(PostCheck postCheck) { this.postCheck = postCheck; } @Override public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().get(); } else if (!checkResource.getCheckerUuid().get().equals(input.checkerUuid)) { throw new BadRequestException( String.format( "checker UUID in input must either be null or the same as on the resource:\n" + "input: %s\n" + "resource: %s", input.checkerUuid, checkResource.getCheckerUuid().get())); } return postCheck.apply(checkResource, input); } }
import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckInput; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.testing.TestTimeUtil; import com.google.inject.Inject; import java.sql.Timestamp; import java.time.Instant; import java.util.concurrent.TimeUnit; import org.junit.After; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void testRerunCheck() { // Test code goes here } }
import com.google.gerrit.testing.TestTimeUtil; import com.google.inject.Inject; import java.sql.Timestamp; import java.time.Instant; import java.util.concurrent.TimeUnit; import org.junit.After; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; // Test code continues... } }
public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } }
@Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void rerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); }
CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); @Test public void rerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); }
Fixed Code: ```java PermissionBackend permissionBackend; ExternalIds externalIds; @ServerInitiated Provider<AccountsUpdate> accountsUpdateProvider; SshKeyCache sshKeyCache; Realm realm; public MyClass(Self self, PermissionBackend permissionBackend, ExternalIds externalIds, @ServerInitiated Provider<AccountsUpdate> accountsUpdateProvider, SshKeyCache sshKeyCache, Realm realm) { this.self = self; this.permissionBackend = permissionBackend; this.externalIds = externalIds; this.accountsUpdateProvider = accountsUpdateProvider; this.sshKeyCache = sshKeyCache; this.realm = realm; } @Override public String apply(AccountResource rsrc, UsernameInput input) throws RestApiException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } if (!realm.allowsEdit(AccountFieldName.USER_NAME)) { throw new MethodNotAllowedException("realm does not allow editing username"); } Account.Id accountId = rsrc.getUser().getAccountId(); if (!externalIds.byAccount(accountId, SCHEME_USERNAME).isEmpty()) { throw new MethodNotAllowedException("Username cannot be changed."); } // rest of the code } ```
public String apply(AccountResource rsrc, UsernameInput input) throws AuthException, MethodNotAllowedException, UnprocessableEntityException, ResourceConflictException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } if (!realm.allowsEdit(AccountFieldName.USER_NAME)) { throw new MethodNotAllowedException("realm does not allow editing username"); } if (input == null) { input = new UsernameInput(); } Account.Id accountId = rsrc.getUser().getAccountId(); if (!externalIds.byAccount(accountId, SCHEME_USERNAME).isEmpty()) { throw new MethodNotAllowedException("Username cannot be changed."); } if (Strings.isNullOrEmpty(input.username)) { return input.username; } if (!ExternalId.isValidUsername(input.username)) { throw new UnprocessableEntityException("Invalid username."); } // Rest of the code... }
@Nullable public Timestamp finished; /** Timestamp of when this check was created. */ public Timestamp created; /** Timestamp of when this check was last updated. */ public Timestamp updated; /** Name of the checker that produced this check. */ public String checkerName; /** Status of the checker that produced this check. */ public CheckerStatus checkerStatus; /** Blocking conditions that apply to this check. */ public Set<BlockingCondition> blocking; /** Description of the checker that produced this check */ public String description; @Override public boolean equals(Object o) { if (!(o instanceof CheckInfo)) { return false; } CheckInfo other = (CheckInfo) o; return Objects.equals(other.repository, repository) && Objects.equals(other.changeNumber, changeNumber) && Objects.equals(other.patchSetId, patchSetId) && Objects.equals(other.checkerUuid, checkerUuid) && Objects.equals(other.state, state) && Objects.equals(other.message, message) && Objects.equals(other.url, url) && Objects.equals(other.started, started) && Objects.equals(other.finished, finished) && Objects.equals(other.created, created) && Objects.equals(other.updated, updated) && Objects.equals(other.checkerName, checkerName) && Objects.equals(other.checkerStatus, checkerStatus) && Objects.equals(other.blocking, blocking) && Objects.equals(other.description, description); }
String name = paths[i].replaceAll("\\*", ".*"); //$NON-NLS-1$ //$NON-NLS-2$ for (int relativeQuark : quarks) { try { for (int quark : fStateSystem.getSubAttributes(relativeQuark, false, name)) { subQuarks.add(quark); } } catch (AttributeNotFoundException e) { /** Nothing to do */ } } quarks = subQuarks; i++; } return quarks; } public XmlXYViewer(@Nullable Composite parent, XmlViewInfo viewInfo) { super(parent, Messages.XmlXYViewer_DefaultViewerTitle, Messages.XmlXYViewer_DefaultXAxis, Messages.XmlXYViewer_DefaultYAxis); fViewInfo = viewInfo; } @Override protected void updateData(long start, long end, int nb, @Nullable IProgressMonitor monitor) { ITmfXmlStateAttribute display = fDisplay; ITmfXmlStateAttribute seriesName = fSeriesName; OrmException, IOException, ConfigInvalidException { if (input == null) { input = new AccountInput(); } if (input.username != null && !username.equals(input.username)) { throw new BadRequestException("username must match URL"); } if (!username.matches(Account.USER_NAME_PATTERN)) { throw new BadRequestException("Username '" + username + "' must comply with [" + USER_NAME_PATTERN + "] pattern."); } Set<AccountGroup.Id> groups = parseGroups(input.groups); Account.Id id = new Account.Id(db.nextAccountId()); ExternalId extUser = ExternalId.createUsername(username, id, input.httpPassword); if (db.accountExternalIds().get(extUser.key().asAccountExternalIdKey()) != null) { throw new ResourceConflictException("username '" + username + "' already exists"); } if (input.email != null) { if (db.accountExternalIds() .get(ExternalId.Key.create(SCHEME_MAILTO, input.email).asAccountExternalIdKey()) != null) { throw new ResourceConflictException("email '" + input.email + "' already exists"); } } Account account = new Account(id, TimeUtil.nowTs()); account.setFullName(input.name); account.setPreferredEmail(input.email); account.setUserName(username); account.setActive(true); account.setExternalIds(ImmutableList.of(extUser)); account.setGroups(groups
} if (options.contains(FillOptions.STATUS)) { info.status = account.getStatus(); } if (options.contains(FillOptions.AVATARS)) { AvatarProvider ap = avatar.get(); if (ap != null) { info.avatars = new ArrayList<>(); IdentifiedUser user = userFactory.create(account.getId()); addAvatar(ap, info, user, AvatarInfo.DEFAULT_SIZE); if (!info.avatars.isEmpty()) { addAvatar(ap, info, user, 56); addAvatar(ap, info, user, 100); addAvatar(ap, info, user, 120); } } }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.NotSupportedException; import org.eclipse.jgit.errors.TransportException; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; public interface TransportFactory { Transport open(Repository local, URIish uri) throws NotSupportedException, TransportException; }
Copyright (C) 2019 The Android Open Source Project // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.NotSupportedException; import org.eclipse.jgit.errors.TransportException; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; public class TransportFactoryImpl implements TransportFactory { @Override public Transport open(Repository git, URIish uri) throws NotSupportedException, TransportException { return Transport.open(git, uri); } }
import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.transport.FetchConnection; import org.eclipse.jgit.transport.PushConnection; import org.eclipse.jgit.transport.PushResult; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.RemoteRefUpdate; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; import org.eclipse.jgit.util.FS; import org.junit.Before; import org.junit.Test; public class PushOneTest { private GitRepositoryManager gitRepositoryManagerMock; private Repository repositoryMock; private PermissionBackend permissionBackendMock; private PermissionBackend.WithUser withUserMock; private PermissionBackend.ForProject forProjectMock; private Destination destinationMock; private RemoteConfig remoteConfigMock; private RefSpec refSpecMock; private CredentialsFactory credentialsFactory; private PerThreadRequestScope.Scoper threadRequestScoperMock; private ReplicationQueue replicationQueueMock; private IdGenerator idGeneratorMock; private ReplicationStateListeners replicationStateListenersMock; private ReplicationMetrics replicationMetricsMock; private Timer1.Context timerContextMock; private ProjectCache projectCacheMock; private RunwayStatus statusMock; private TransportFactory transportFactoryMock; private Transport transportMock; private FetchConnection fetchConnection; private PushConnection pushConnection; private ProjectState projectStateMock; }
verify(transportMock); } private PushOne createPushOne(DynamicItem<ReplicationPushFilter> replicationPushFilter) { PushOne push = new PushOne( gitRepositoryManagerMock, permissionBackendMock, destinationMock, remoteConfigMock, credentialsFactory, threadRequestScoperMock, replicationQueueMock, idGeneratorMock, replicationStateListenersMock, replicationMetricsMock, projectCacheMock, transportFactoryMock, projectNameKey, urish); push.setReplicationPushFilter(replicationPushFilter); return push; } private void waitUntilFinished() throws InterruptedException { while (!isCallFinished.get()) { Thread.sleep(100); } } private void setupProjectCacheMock() throws IOException { projectCacheMock = createNiceMock(ProjectCache.class); expect(projectCacheMock.checkedGet(projectNameKey)).andReturn(projectStateMock); } private void setupTransportMock() throws NotSupportedException, TransportException { transportMock = createNiceMock(Transport.class); expect(transportMock.openFetch()).andReturn(fetchConnection); transportFactoryMock = createNiceMock(TransportFactory.class); expect(transportFactoryMock.open(repositoryMock, urish)).andReturn(transportMock).anyTimes(); } private void setupReplicationMetricsMock() { replicationMetricsMock = createNiceMock(ReplicationMetrics.class); }
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.client.admin; import com.google.gerrit.client.Gerrit; import com.google.gerrit.client.ui.Hyperlink; import com.google.gerrit.reviewdb.client.Project; import com.google.gwt.http.client.URL; abstract class PaginatedProjectScreen extends ProjectScreen { protected int pageSize; protected String match; protected int start; public PaginatedProjectScreen(Project.NameKey toShow) { super(toShow); pageSize = Gerrit.getUserPreferences().changesPerPage(); } protected void parseToken(String token) { for (String kvPair : token.split("[,;&/?]")) { String[] kv = kvPair.split("=", 2); if (kv.length != 2 || kv[0].isEmpty()) { continue; } if ("filter".equals(kv[0])) { match = URL.decodeQueryString(kv[1]); } } } } class PluginUtils { public static String getGerritPluginName(File srcFile) { String fileName = srcFile.getName(); if (isJarPlugin(fileName)) { JarFile jarFile = new JarFile(srcFile); try { return jarFile.getManifest().getMainAttributes().getValue("Gerrit-PluginName"); } finally { jarFile.close(); } } if (isJsPlugin(fileName)) { return fileName.substring(0, fileName.length() - 3); } return null; } public static Multimap<String, File> asMultimap(List<File> plugins) throws IOException { Multimap<String, File> map = LinkedHashMultimap.create(); for (File srcFile : plugins) { map.put(Objects.firstNonNull(getGerritPluginName(srcFile), nameOf(srcFile)), srcFile); } return map; } private static boolean isJarPlugin(String name) { return isPlugin(name, "jar"); } private static boolean isJsPlugin(String name) { return isPlugin(name, "js"); } private static boolean isPlugin(String name, String extension) { return name.toLowerCase().endsWith("." + extension);
private boolean compareField(Object obj, Object expectedObj) { return obj != null ? obj.equals(expectedObj) : expectedObj == null; }
public GitPerson committer; public String comment; UpdateRef(String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } public static class DeleteProject extends SharedRefLogEntry { public String refName; public String oldId; DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } }
public String comment; public UpdateRef(String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } public static class DeleteProject extends SharedRefLogEntry { public String refName; public String oldId; DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } }
// limitations under the License. package com.google.gerrit.plugins.checks.api; import com.google.gerrit.exceptions.StorageException; import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.ConfigInvalidException; @Singleton public class RerunCheck implements RestModifyView<CheckResource, CheckInput> { private final PostCheck postCheck; @Inject RerunCheck(PostCheck postCheck) { this.postCheck = postCheck; } @Override public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().get(); } else if (!checkResource.getCheckerUuid().get().equals(input.checkerUuid)) { throw new BadRequestException("Invalid checker UUID"); } return postCheck.apply(checkResource, input); } }
import org.eclipse.jgit.diff.DiffEntry; import org.eclipse.jgit.diff.DiffFormatter; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectReader; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.util.io.DisabledOutputStream; public class ExternalIdCacheLoader extends CacheLoader<ObjectId, AllExternalIds> { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final int MAX_HISTORY_LOOKBACK = 10; private static final int MAX_DIFFERENTIAL_CHANGES = 100; public ExternalIdCacheLoader() { } @Override public AllExternalIds load(ObjectId key) throws Exception { try (Repository repo = openRepository()) { RevWalk walk = new RevWalk(repo); RevCommit commit = walk.parseCommit(key); walk.markStart(commit); AllExternalIds externalIds = new AllExternalIds(); for (RevCommit revCommit : walk) { if (externalIds.isFull()) { break; } externalIds.updateFromCommit(revCommit); } if (!externalIds.isFull()) { externalIds.updateFromFullReload(repo); } return externalIds; } } private Repository openRepository() throws IOException { // Open the repository // ... } }
import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.util.io.DisabledOutputStream; public class ExternalIdCacheLoader extends CacheLoader<ObjectId, AllExternalIds> { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final int MAX_HISTORY_LOOKBACK = 10; private static final int MAX_DIFF_UPDATES = 50; private final ExternalIdReader externalIdReader; private final Provider<Cache<ObjectId, AllExternalIds>> externalIdCache; private final GitRepositoryManager gitRepositoryManager; private final AllUsersName allUsersName; private final Counter1<Boolean> reloadCounter; private final Timer0 reloadDifferential; }
import new Description("Total number of external ID cache reloads from Git.") .setRate() .setUnit("updates"), Field.ofBoolean("partial", Metadata.Builder::partial).build()); this.reloadDifferential = metricMaker.newTimer( "notedb/external_id_partial_read_latency", new Description("Latency for generating a new external ID cache state from a prior state.") .setCumulative() .setUnit(Units.MILLISECONDS)); this.enablePartialReloads = config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", true); @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log("Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } // We failed to load the requested value from both the in-memory cache (hence, this loader was } Refactored Code: import new Description("Total number of external ID cache reloads from Git.") .setRate() .setUnit("updates"); Field<Boolean> partialField = Field.ofBoolean("partial", Metadata.Builder::partial).build(); this.reloadDifferential = metricMaker.newTimer( "notedb/external_id_partial_read_latency", new Description("Latency for generating a new external ID cache state from a prior state.") .setCumulative() .setUnit(Units.MILLISECONDS)); this.enablePartialReloads = config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", true); @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log("Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } // We failed to load the requested value from both the in-memory cache (hence, this loader was }
import com.googlesource.gerrit.plugins.renameproject.monitor.ProgressMonitor; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.List; import org.kohsuke.args4j.Argument; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @CommandMetaData(name = "rename", description = "Rename project") public final class RenameCommand extends SshCommand { @Argument(index = 0, required = true, metaVar = "OLDPROJECT", usage = "project to rename") private String existingProjectName; @Argument(index = 1, required = true, metaVar = "NEWNAME", usage = "new name for the project") private String newProjectName; private static final Logger log = LoggerFactory.getLogger(RenameCommand.class); private final RenameProject renameProject; private final ProjectCache projectCache; private final Provider<CurrentUser> self; @Inject protected RenameCommand(RenameProject renameProject, ProjectCache projectCache, Provider<CurrentUser> self) { this.renameProject = renameProject; this.projectCache = projectCache; this.self = self; } @Override public void run() throws UnloggedFailure, Failure, Exception { ProgressMonitor monitor = new ProgressMonitor(); try { renameProject.rename(existingProjectName, newProjectName, monitor); } catch (IOException e) { log.error("Failed to rename project", e); throw new UnloggedFailure(1, "Failed to rename project"); } projectCache.evict(existingProjectName); projectCache.evict(newProjectName); log.info("Project renamed successfully"); } }
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); public abstract Builder setStarted(@Nullable Timestamp started); public abstract Builder setFinished(@Nullable Timestamp finished); public abstract CheckUpdate build(); }
import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.transport.BundleWriter; import org.eclipse.jgit.transport.ReceiveCommand; import org.kohsuke.args4j.Option; import java.io.ByteArrayOutputStream; import java.io.IOException; import java.io.OutputStream; import java.util.Collection; import java.util.Set; @Singleton public class PreviewSubmit implements RestReadView<RevisionResource> { private final Provider<ReviewDb> dbProvider; private final Provider<MergeOp> mergeOpProvider; private final AllowedFormats allowedFormats; private String format; @Option(name = "--format") public void setFormat(String f) { this.format = f; } @Inject PreviewSubmit(Provider<ReviewDb> dbProvider, Provider<MergeOp> mergeOpProvider, AllowedFormats allowedFormats) { this.dbProvider = dbProvider; this.mergeOpProvider = mergeOpProvider; this.allowedFormats = allowedFormats; } @Override public BinaryResult apply(RevisionResource rsrc) throws RestApiException { if (Strings.isNullOrEmpty(format)) { // Review: Should this be configurable? } // Rest of the code } } public LazyArrayListStore() { fUniqueId = TraceCompassLogUtils.traceObjectCreation(LOGGER, Level.FINE, this); } // Rest of the code // Rest of the code private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final int MAX_HISTORY_LOOKBACK = 10; private static final int MAX_DIFF_UPDATES = 50; private final ExternalIdReader externalIdReader; private final Provider<Cache<ObjectId, AllExternalIds>> externalIdCache; private final GitRepositoryManager gitRepositoryManager; private final AllUsersName allUsersName; private final Counter1<Boolean> reloadCounter; private final Timer0 reloadDifferential; private final boolean enablePartialReloads; @Inject ExternalIdCacheLoader(GitRepositoryManager gitRepositoryManager, AllUsersName allUsersName, ExternalIdReader externalIdReader, @Named(ExternalIdCacheImpl.CACHE_NAME) Provider<Cache<ObjectId, AllExternalIds>> externalIdCache, MetricMaker metricMaker) { this.gitRepositoryManager = gitRepositoryManager; this.allUsersName = allUsersName; this.externalIdReader = externalIdReader; this.externalIdCache = externalIdCache; this.reloadCounter = metricMaker
try (Repository repo = gitRepositoryManager.openRepository(allUsersName)) { long start = System.nanoTime(); Ref extId = repo.exactRef(RefNames.REFS_EXTERNAL_IDS); if (extId == null) { logger.atInfo().log(RefNames.REFS_EXTERNAL_IDS + " not initialized, falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } try (RevWalk rw = new RevWalk(repo)) { RevCommit currentCommit = rw.parseCommit(extId.getObjectId()); rw.markStart(currentCommit); RevCommit parentWithCacheValue = null; AllExternalIds oldExternalIds = null; for (int i = 0; i < MAX_HISTORY_LOOKBACK; i++) { parentWithCacheValue = rw.next(); oldExternalIds = externalIdCache.get().getIfPresent(parentWithCacheValue.getId()); if (oldExternalIds != null) { break; } if (parentWithCacheValue.getParentCount() != 1) { logger.atWarning().log("External IDs cache not found in parent commit history."); return reloadAllExternalIdsAndCachePersistently(notesRev); } } if (oldExternalIds == null) { logger.atWarning().log("External IDs cache not found in commit history."); return reloadAllExternalIdsAndCachePersistently(notesRev); } return oldExternalIds; } }
logger.atInfo().log(RefNames.REFS_EXTERNAL_IDS + " not initialized, falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); RevWalk rw = new RevWalk(repo); RevCommit currentCommit = rw.parseCommit(extId.getObjectId()); rw.markStart(currentCommit); RevCommit parentWithCacheValue = null; AllExternalIds oldExternalIds = null; for (int i = 0; i < MAX_HISTORY_LOOKBACK; i++) { parentWithCacheValue = rw.next(); oldExternalIds = externalIdCache.get().getIfPresent(parentWithCacheValue.getId()); if (oldExternalIds != null) { break; } if (parentWithCacheValue.getParentCount() != 1) { logger.atWarning().log("Unable to find an old ExternalId cache state because %s doesn't have exactly one parent, falling back to full reload", parentWithCacheValue); return reloadAllExternalIdsAndCachePersistently(notesRev); } } if (oldExternalIds == null) { logger.atWarning().log("Unable to find an old ExternalId cache state, falling back to full reload"); return reloadAllExternalIdsAndCachePersistently(notesRev); }
nameToBlob.getValue()); } catch (ConfigInvalidException | RuntimeException e) { logger.atSevere().withCause(e).log( "Ignoring invalid external ID note %s", nameToBlob.getKey().name()); continue; } byAccount.put(parsedExternalId.accountId(), parsedExternalId); if (parsedExternalId.email() != null) { byEmail.put(parsedExternalId.email(), parsedExternalId); } reloadCounter.increment(true); reloadDifferential.start(); return new AutoValue_AllExternalIds(byAccount.build(), byEmail.build()); } } private static ObjectId fileNameToObjectId(String path) { int lastSlash = path.lastIndexOf('/'); return ObjectId.fromString(lastSlash > 0 ? path.substring(lastSlash) : path); } private AllExternalIds reloadAllExternalIdsAndCachePersistently(ObjectId notesRev) throws IOException, ConfigInvalidException { try (TraceTimer ignored = TraceContext.newTimer("Loading external IDs from scratch")) { long start = System.nanoTime(); Map<Account.Id, ExternalId> byAccount = new HashMap<>(); Map<String, ExternalId> byEmail = new HashMap<>(); for (Map.Entry<ExternalId.Key, ObjectId> nameToBlob : externalIdNotes.getNoteMap(notesRev).entrySet()) { ExternalId parsedExternalId; try { parsedExternalId = ExternalId.parse(nameToBlob.getKey().name(), nameToBlob.getValue()); } catch (ConfigInvalidException | RuntimeException e) { logger.atSevere().withCause(e).log( "Ignoring invalid external ID note %s", nameToBlob.getKey().name()); continue; } byAccount.put(parsedExternalId.accountId(), parsedExternalId); if (parsedExternalId.email() != null) { byEmail.put(parsedExternalId.email(), parsedExternalId); } } reloadCounter.increment(true); reloadDifferential.start(); return new AutoValue_AllExternalIds(byAccount.build(), byEmail.build()); } }
private static ObjectId fileNameToObjectId(String path) { int lastSlash = path.lastIndexOf('/'); return ObjectId.fromString(path.replaceAll("/", "")); }
private AllExternalIds reloadAllExternalIdsAndCachePersistently(ObjectId notesRev) throws IOException, ConfigInvalidException { try (TraceTimer ignored = TraceContext.newTimer("Loading external IDs from scratch", Metadata.builder().revision(notesRev.name()).build())) { ImmutableSet<ExternalId> externalIds = externalIdReader.all(notesRev); externalIds.forEach(ExternalId::checkThatBlobIdIsSet); AllExternalIds allExternalIds = AllExternalIds.create(externalIds); externalIdCache.get().put(notesRev, allExternalIds); reloadCounter.increment(false); return allExternalIds; } }
public abstract Optional<String> groupUuid(); public abstract Optional<Integer> httpStatus(); public abstract Optional<String> indexName(); public abstract Optional<Integer> indexVersion(); public abstract Optional<String> methodName(); public abstract Optional<Boolean> multiple(); public abstract Optional<Boolean> partial(); public abstract Optional<String> noteDbFilePath(); public abstract Optional<String> noteDbRefName(); public abstract Optional<String> noteDbSequenceType(); public abstract Optional<String> noteDbTable(); public abstract Optional<String> patchSetId();
package com.google.gerrit.server.config; import com.google.inject.Inject; import com.google.inject.Singleton; import org.eclipse.jgit.lib.Config; @Singleton public class ThreadSettingsConfig { private final int sshdThreads; private final int httpdMaxThreads; private final int sshdBatchThreads; private final int databasePoolLimit; @Inject ThreadSettingsConfig(@GerritServerConfig Config cfg) { int cores = Runtime.getRuntime().availableProcessors(); sshdThreads = cfg.getInt("sshd", "threads", Math.min(4, 2 * cores)); httpdMaxThreads = cfg.getInt("httpd", "maxThreads", 25); int defaultDatabasePoolLimit = sshdThreads + httpdMaxThreads + 2; databasePoolLimit = cfg.getInt("database", "poolLimit", defaultDatabasePoolLimit); sshdBatchThreads = cores == 1 ? 1 : 2; } public int getDatabasePoolLimit() { return databasePoolLimit; } public int getHttpdMaxThreads() { return httpdMaxThreads; } public int getSshdThreads() { return sshdThreads; } public int getSshdBatchTreads() { return sshdBatchThreads; } }
import org.eclipse.jgit.lib.RefUpdate.Result; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.lib.RepositoryCache.FileKey; import org.eclipse.jgit.util.FS; public class AccountsOnInit { private final InitFlags flags; private final SitePaths site; private final String allUsers; @Inject public AccountsOnInit(InitFlags flags, SitePaths site, AllUsersNameOnInitProvider allUsers) { this.flags = flags; this.site = site; this.allUsers = allUsers.get(); } public Account insert(Account.Builder account) throws IOException { File path = getPath(); if (path != null) { try (Repository repo = new FileRepository(path); ObjectInserter oi = repo.newObjectInserter()) { PersonIdent ident = new PersonIdent(new GerritPersonIdentProvider(flags.cfg).get(), account.registeredOn()); Config accountConfig = new Config(); AccountProperties.writeToAccountConfig( InternalAccountUpdate.builder() .setActive(account.isActive()) .setFullName(account.fullName()) .setPreferredEmail(account.preferredEmail()) .setStatus(account.status()) .build(), accountConfig, oi, ident); Account.Id accountId = account.id(); FileKey fileKey = FileKey.exact(path, FS.DETECTED); try (RepositoryCache.FileKeyRepositoryCache repoCache = new RepositoryCache.FileKeyRepositoryCache(fileKey, repo)) { AccountConfig accountCfg = new AccountConfig(accountId, repo); accountCfg.setAccountConfig(accountConfig); accountCfg.commit(ident, oi); } return account.build(); } } return null; } }
AllUsersName allUsersName = new AllUsersName(AllUsersNameProvider.DEFAULT); Account.Builder account = Account.builder(Account.id(1), TimeUtil.nowTs()); String metaId = "0e39795bb25dc914118224995c53c5c36923a461"; account.setMetaId(metaId); List<String> values = toStrings(AccountField.REF_STATE.get(AccountState.forAccount(account.build()))); assertThat(values).hasSize(1); String expectedValue = allUsersName.get() + ":" + RefNames.refsUsers(Account.id(1)) + ":" + metaId; assertThat(Iterables.getOnlyElement(values)).isEqualTo(expectedValue); @Test public void externalIdStateFieldValues() throws Exception { Account.Id id = Account.id(1); Account account = Account.create(id, TimeUtil.nowTs()); ExternalId extId1 = ExternalId.create( ExternalId.Key.create(ExternalId.SCHEME_MAILTO, "foo.bar@example.com"), id, "foo.bar@example.com", null, ObjectId.fromString("1b9a0cf038ea38a0ab08617c39aa8e28413a27ca") ); ExternalId extId2 = ExternalId.create( ExternalId.Key.create(ExternalId.SCHEME_USERNAME, "foo"), id, "foo", null, ObjectId.fromString("1b9a0cf038ea38a0ab08617c39aa8e28413a27cb") ); ExternalId extId3 = ExternalId.create( ExternalId.Key.create(ExternalId.SCHEME_USERNAME, "bar"), id, "bar", null, ObjectId.fromString("1b9a0cf038ea38a0ab08617c39aa8e28413a27cc") ); account.setExternalIds(ImmutableList.of(extId1, extId2, extId3)); List<String> values = toStrings(AccountField.REF_STATE.get(AccountState.forAccount(account))); assertThat(values).containsExactly( "externalId:" + extId1.key().get(), "externalId:" + extId2.key().get(), "externalId:" + extId3.key().get() ); }
@CommandMetaData(name = "rename", description = "Rename project") public final class RenameCommand extends SshCommand { @Argument(index = 0, required = true, metaVar = "OLDPROJECT", usage = "project to rename") private String projectControl; @Argument(index = 1, required = true, metaVar = "NEWNAME", usage = "new name for the project") private String newProjectName; private static final Logger log = LoggerFactory.getLogger(RenameCommand.class); private final RenameProject renameProject; private final Provider<ProjectCache> projectCache; private final Provider<CurrentUser> self; @Inject protected RenameCommand(RenameProject renameProject, Provider<ProjectCache> projectCache, Provider<CurrentUser> self) { this.renameProject = renameProject; this.projectCache = projectCache; this.self = self; } @Override public void run() throws Exception { try { RenameProject.Input input = new RenameProject.Input(); input.name = newProjectName; ProjectResource rsrc = new ProjectResource(projectCache.get().get(new Project.NameKey(projectControl)), self.get()); renameProject.apply(rsrc, input); } catch (ResourceNotFoundException e) { throw new UnloggedFailure(1, "project \"" + projectControl + "\" not found"); } } }
&& Objects.equals(other.checkerUuid, checkerUuid) && Objects.equals(other.state, state) && Objects.equals(other.message, message) && Objects.equals(other.url, url) && Objects.equals(other.started, started) && Objects.equals(other.finished, finished) && Objects.equals(other.created, created) && Objects.equals(other.updated, updated) && Objects.equals(other.checkerName, checkerName) && Objects.equals(other.checkerStatus, checkerStatus) && Objects.equals(other.blocking, blocking) && Objects.equals(other.description, description);
public abstract Optional<Timestamp> started(); public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** * Set the time the check started. Time can be reset to "null" if passed new Timestamp(0). */ public abstract Builder setStarted(Timestamp started); /** * Set the time the check finished. Time can be reset to "null" if passed new Timestamp(0). */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } }
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** * Set the time the check started. Time can be reset to "null" if passed new Timestamp(0). */ public abstract Builder setStarted(Timestamp started); /** * Set the time the check finished. Time can be reset to "null" if passed new Timestamp(0). */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); }
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); public abstract Builder setStarted(Timestamp started); public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); }
String email = readEmail(sshKey); List<ExternalId> extIds = new ArrayList<>(2); extIds.add(ExternalId.createUsername(username, id, httpPassword)); if (email != null) { extIds.add(ExternalId.createEmail(id, email)); } externalIds.insert("Add external IDs for initial admin user", extIds); Account.Builder a = Account.builder(id, TimeUtil.nowTs()) .setFullName(name) .setPreferredEmail(email); Account persistedAccount = a.build(); accounts.insert(a); // Only two groups should exist at this point in time and hence iterating over all of them // is cheap. Optional<GroupReference> adminGroupReference = groupsOnInit .getAllGroupReferences() .filter(group -> group.getName().equals("Administrators")) .findAny(); if (!adminGroupReference.isPresent()) { throw new NoSuchGroupException("Administrators"); } GroupReference adminGroup = adminGroupReference.get(); groupsOnInit.addGroupMember(adminGroup.getUUID(), persistedAccount); if (sshKey != null) { // ... (remaining code) ... }
public String refactorCode(boolean requireChangeId, RevCommit revCommit, String currentChangeId) { String newCommitMessage = CommitMessageUtil.checkAndSanitizeCommitMessage(revCommit.getShortMessage()); List<String> changeIdFooters = revCommit.getFooterLines(FooterConstants.CHANGE_ID); if (!changeIdFooters.isEmpty() && !changeIdFooters.get(0).equals(currentChangeId)) { throw new ResourceConflictException("wrong Change-Id footer"); } if (revCommit.getFooterLines().isEmpty()) { newCommitMessage += "\n"; } if (requireChangeId && changeIdFooters.isEmpty()) { newCommitMessage += FooterConstants.CHANGE_ID.getName() + ": " + currentChangeId + "\n"; } else if (changeIdFooters.size() > 1) { throw new ResourceConflictException("multiple Change-Id footers"); } return newCommitMessage; }
import com.google.gerrit.server.checker.CheckerName; import com.google.gerrit.server.checker.CheckerUpdate; import com.google.gerrit.server.checker.CheckersUpdate; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.Inject; import com.google.inject.Provider; import java.io.IOException; import javax.inject.Singleton; import org.eclipse.jgit.errors.ConfigInvalidException; @Singleton public class UpdateChecker implements RestModifyView<CheckerResource, CheckerInput> { private final GlobalChecksConfig globalChecksConfig; private final PermissionBackend permissionBackend; private final Provider<CheckersUpdate> checkersUpdate; private final CheckerJson checkerJson; @Inject public UpdateChecker( GlobalChecksConfig globalChecksConfig, PermissionBackend permissionBackend, @UserInitiated Provider<CheckersUpdate> checkersUpdate, CheckerJson checkerJson) { this.globalChecksConfig = globalChecksConfig; this.permissionBackend = permissionBackend; this.checkersUpdate = checkersUpdate; this.checkerJson = checkerJson; } @Override public CheckerInfo apply( CheckerResource resource, CheckerInput input) throws RestApiException, PermissionBackendException, NoSuchCheckerException, IOException { // Implementation code here } }
private final Checks checks; private final Provider<ChecksUpdate> checksUpdate; private final CheckJson.Factory checkJsonFactory; @Inject RerunCheck(Provider<CurrentUser> self, PermissionBackend permissionBackend, AdministrateCheckersPermission permission, Checks checks, @UserInitiated Provider<ChecksUpdate> checksUpdate, CheckJson.Factory checkJsonFactory) { this.self = self; this.permissionBackend = permissionBackend; this.permission = permission; this.checks = checks; this.checksUpdate = checksUpdate; this.checkJsonFactory = checkJsonFactory; } @Override public CheckInfo apply(CheckResource checkResource, Input input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (!self.get().isIdentifiedUser()) { throw new AuthException("Authentication required"); } permissionBackend.currentUser().check(permission); if (checkResource.getRevisionResource().getEdit().isPresent()) { throw new ResourceConflictException("checks are not supported on a change edit"); } CheckKey key = CheckKey.create(checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getChange().get()); ChecksUpdate update = checksUpdate.get(); update.setCheckKey(key); update.setCheckState(CheckState.RUNNING); update.setCheckInput(input); checksUpdate.get().update(update); CheckJson checkJson = checkJsonFactory.create(checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getChange().get()); return checkJson.format(checks.getCheck(key)); }
import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.UnprocessableEntityException; import com.google.gerrit.plugins.checks.CheckKey; import com.google.gerrit.plugins.checks.CheckerUuid; import com.google.gerrit.plugins.checks.acceptance.AbstractCheckersTest; import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.inject.Inject; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); } }
import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.NOT_STARTED).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunNotExistingCheckThrowsError() throws Exception { assertThrows(Exception.class, () -> { checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); }); } }
@Test public void rerunNotExistingCheckThrowsError() throws Exception { assertThrows(UnprocessableEntityException.class, () -> checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun()); }
.add("repository", repository) .add("changeNumber", changeNumber) .add("patchSetId", patchSetId) .add("checkerUuid", checkerUuid) .add("state", state) .add("message", message) .add("url", url) .add("started", started) .add("finished", finished) .add("created", created) .add("updated", updated) .add("checkerName", checkerName) .add("checkerStatus", checkerStatus) .add("blocking", blocking) .add("description", checkerDescription) .toString();
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); public abstract Builder setStarted(Timestamp started); public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); public Builder setStartedToNull() { return setStarted(new Timestamp(0)); } public Builder setFinishedToNull() { return setFinished(new Timestamp(0)); } }
@Test public void testBuildAndMergeNormalFrameInMem() throws HyracksDataException { int tableSize = 101; int numFrames = 50; int frameSize = 256; int minDataSize = frameSize; int minRecordSize = 20; int maxRecordSize = 50; testBuildAndMerge(tableSize, numFrames, frameSize, minDataSize, minRecordSize, maxRecordSize, null); } @Test public void testBuildAndMergeNormalFrameSpill() throws HyracksDataException { int tableSize = 101; int numFrames = 50; int frameSize = 256; int minDataSize = frameSize * 4; int minRecordSize = 20; int maxRecordSize = 50; testBuildAndMerge(tableSize, numFrames, frameSize, minDataSize, minRecordSize, maxRecordSize, null); } @Test public void testBuildAndMergeBigObj() throws HyracksDataException { int tableSize = 101; int numFrames = 50; int frameSize = 256; int minDataSize = frameSize * 80; int minRecordSize = 20; int maxRecordSize = 50; testBuildAndMerge(tableSize, numFrames, frameSize, minDataSize, minRecordSize, maxRecordSize, null); } } for (int i = 0; i < splitRow.size(); ++i) { LiteralExpr expr = splitRow.get(i); ColumnDef colDef = pkColumnDefByName_.get(colNames_.get(i)); org.apache.impala.catalog.Type colType = colDef.getType(); Preconditions.checkState(KuduUtil.isSupportedKeyType(colType)); expr.analyze(analyzer); org.apache.impala.catalog.Type exprType = expr.getType(); if (exprType.isNull()) { throw new AnalysisException("Split values cannot be NULL. Split row: " + splitRowToString(splitRow)); } if (!org.apache.impala.catalog.Type.isImplicitlyCastable(exprType, colType, true)) { throw new AnalysisException(String.format("Split value %s (type: %s) is " + "not type compatible with column '%s' (type: %s).", expr.toSql(), exprType, colDef
Fixed Code: ```java import static com.google.common.truth.Truth.assertThat; public void emptyStringIsDeserializedToMagicTimestamp() { Timestamp timestamp = deserializer.deserialize(new JsonPrimitive(""), Timestamp.class, null); assertThat(timestamp).isEqualTo(TimeUtil.never()); } ```
private void queueSuccessMessages(List<CreateRequest> newChanges) { // adjacency list for commit => parent Map<String, String> adjList = new HashMap<>(); List<String> outOfOrderCommits = new ArrayList<>(); for (CreateRequest cr : newChanges) { String parent = cr.commit.getParentCount() < 1 ? start : cr.commit.getParent(0).name(); adjList.put(parent, cr.commit.name()); } for (ReplaceRequest rr : replaceByChange.values()) { try { RevCommit revCommit = receivePack.getRevWalk().parseCommit(rr.newCommitId); String parent = revCommit.getParentCount() < 1 ? start : revCommit.getParent(0).name(); adjList.put(parent, rr.newCommitId.name()); } catch (IOException e) { logger.atWarning().withCause(e).log("failed to parse commit %s for success message.", rr.newCommitId.name()); outOfOrderCommits.add(rr.newCommitId.name()); } } if (adjList.get(start) == null) { // Handle the case when the start commit is not found in the adjacency list } } private List<SubmitRecord> getSubmitRecords(ChangeData cd) { if (projectState == null || projectState.hasPrologRules()) { return Collections.emptyList(); } SubmitRecord submitRecord = new SubmitRecord(); submitRecord.status = SubmitRecord.Status.OK; List<LabelType> labelTypes; List<PatchSetApproval> approvals; try { labelTypes = cd.getLabelTypes().getLabelTypes(); approvals = cd.currentApprovals(); } catch (OrmException e) { log.error("Unable to fetch labels and approvals for change {}: {}", cd.getId(), e); submitRecord.errorMessage = "Unable to fetch labels and approvals for the change"; submitRecord.status = SubmitRecord.Status.RULE_ERROR; return Collections.singletonList(submitRecord); } submitRecord.labels = new ArrayList<>(labelTypes.size()); for (LabelType t : labelTypes) { LabelFunction labelFunction = t.getFunction(); if (labelFunction == null) { log.error("Unable to find the LabelFunction for label {}, change {}", t.getName(), cd.getId()); // Handle the case when the LabelFunction is not found } } // Process the submit records and
// from the cache. Extend the cache size by 1 to cover this case, but expire the extra // object after a short period of time, since it may be a potentially large amount of // memory. // When loading a new value because the primary data advanced, we want to leverage the old // cache state to recompute only what changed. This doesn't affect cache size though as // Guava calls the loader first and evicts later on. .maximumWeight(2) .expireFromMemoryAfterAccess(Duration.ofMinutes(5)) .loader(ExternalIdCacheLoader.class) .diskLimit(-1) .version(1) .keySerializer(ObjectIdCacheSerializer.INSTANCE) .valueSerializer(AllExternalIds.Serializer.INSTANCE); bind(ExternalIdCacheImpl.class); bind(ExternalIdCache.class).to(ExternalIdCacheImpl.class);
public HashtagsInput(Set<String> add, Set<String> remove) { this.add = add; this.remove = remove; } public HashtagsInput(Set<String> add) { this(add, new HashSet<>()); }
CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.NOT_STARTED).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertSuccessfulRerun(info); assertThat(info.updated).isGreaterThan(info.created); } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertSuccessfulRerun(info); assertThat(info.updated).isGreaterThan(info.created); } @Test public void rerunCheckNotExistingButBackfilled() throws Exception { CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertSuccessfulRerun(info); } @Test
private final String variant; private CommitSoyData csd; public LogSoyData(HttpServletRequest req, GitilesAccess access, String pretty) throws IOException { this.req = checkNotNull(req); this.view = checkNotNull(ViewFilter.getView(req)); checkNotNull(pretty); Config config = access.getConfig(); fields = config.getBoolean("logFormat", pretty, "verbose", false) ? VERBOSE_FIELDS : FIELDS; variant = firstNonNull(config.getString("logFormat", pretty, "variant"), pretty); } private static class LogSoyDataAppendable implements AdvisingAppendable { private final Writer writer; LogSoyDataAppendable(Writer writer) { this.writer = writer; } @Override public AdvisingAppendable append(CharSequence csq) throws IOException { writer.append(csq); return this; } @Override public AdvisingAppendable append(CharSequence csq, int start, int end) throws IOException { writer.append(csq, start, end); return this; } @Override public AdvisingAppendable append(char c) throws IOException { writer.append(c); return this; } @Override public void advise(Object advice) { if (advice instanceof SoyMsgBundle) { try { ((SoyMsgBundle) advice).writeExternal(writer); } catch (IOException e) { throw new RuntimeException(e); } } } }
// don't do something with the result, so just wrap it in a dummy method. } public void renderStreaming(Paginator paginator, @Nullable String revision, Renderer renderer, Writer writer, DateFormatter df, FooterBehavior footerBehavior) throws IOException { LogSoyDataAppendable out = new LogSoyDataAppendable(writer); swallowResult(renderer.newRenderer("gitiles.logEntriesHeader") .setData(toHeaderSoyData(paginator, revision)) .renderHtml(out)); SoySauce.Renderer entryRenderer = renderer.newRenderer("gitiles.logEntryWrapper"); boolean renderedEntries = false; for (RevCommit c : paginator) { swallowResult(entryRenderer.setData(toEntrySoyData(paginator, c, df)).renderHtml(out)); out.flush(); renderedEntries = true; } if (!renderedEntries) { swallowResult(renderer.newRenderer("gitiles.emptyLog").renderHtml(out)); } swallowResult(renderer.newRenderer("gitiles.logEntriesFooter") .setData(toFooterSoyData(paginator, revision, footerBehavior)) .renderHtml(out)); }
checkState(u != null, "Missing Soy template %s", soyFile); Hasher h = Hashing.murmur3_128().newHasher(); try (InputStream is = u.openStream(); OutputStream os = Funnels.asOutputStream(h)) { ByteStreams.copy(is, os); } catch (IOException e) { throw new IllegalStateException("Missing Soy template " + soyFile, e); } return h.hash(); public String renderHtml(String templateName, Map<String, ?> soyData) { return newRenderer(templateName).setData(soyData).renderHtml().get().toString(); } void render(HttpServletRequest req, HttpServletResponse res, String templateName, Map<String, ?> soyData) throws IOException { res.setContentType("text/html"); res.setCharacterEncoding("UTF-8"); byte[] data = newRenderer(templateName).setData(soyData).renderHtml().get().toString().getBytes(UTF_8); if (BaseServlet.acceptsGzipEncoding(req)) { res.addHeader(HttpHeaders.VARY, HttpHeaders.ACCEPT_ENCODING); } res.setContentLength(data.length); res.getOutputStream().write(data); }
```java o.write(tail); } SoySauce.Renderer newRenderer(String templateName) { ImmutableMap.Builder<String, Object> staticUrls = ImmutableMap.builder(); for (String key : STATIC_URL_GLOBALS.keySet()) { staticUrls.put( key.replaceFirst("^gitiles\\.", ""), LegacyConversions.riskilyAssumeTrustedResourceUrl(globals.get(key)) ); } return getSauce() .renderTemplate(templateName) .setIj(ImmutableMap.of("staticUrls", staticUrls.build())); } protected abstract SoySauce getSauce(); ```
config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", false); @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log("Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIds(notesRev); } // We didn't find the requested value in the cache, so we try to create it from a past value using minimal Git operations to reduce latency. // First, try to find the most recent state in the persistent cache. We check the last 10 states and if nothing is found, we load the value from scratch. // ... }
import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.OutputFormat; import com.google.gerrit.server.util.SystemLog; import com.google.inject.Inject; import com.google.inject.Singleton; import org.apache.log4j.Level; import org.apache.log4j.LogManager; import org.apache.log4j.Logger; import org.apache.log4j.spi.LoggingEvent; @Singleton class DeleteLog implements LifecycleListener { private static final String DELETE_LOG_NAME = "delete_log"; private static final Logger log = LogManager.getLogger(DELETE_LOG_NAME); public static String ACCOUNT_ID = "accountId"; public static String USER_NAME = "userName"; public static String PROJECT_NAME = "projectName"; public static String OPTIONS = "options"; public static String ERROR = "error"; private final SystemLog systemLog; private final ServerInformation serverInfo; private static boolean started; @Inject public DeleteLog(SystemLog systemLog, ServerInformation serverInfo) { this.systemLog = systemLog; this.serverInfo = serverInfo; } public void onDelete(IdentifiedUser user, Project.NameKey project, ...) { // implementation } } private void initNoteDb() { ui.message( "Use experimental NoteDb for change metadata?\n" + "NoteDb is not recommended for production servers." + "Please familiarize yourself with the documentation:\n" + "https://gerrit-review.googlesource.com/Documentation/dev-note-db.html\n" ); if (!ui.yesno(false, "Enable")) { return; } Config defaultConfig = ConfigNotesMigration.allEnabledConfig(); for (String name : defaultConfig.getNames(SECTION_NOTE_DB, CHANGES.key())) { noteDbChanges.set( name, defaultConfig.getString(SECTION_NOTE_DB, CHANGES.key(), name) ); } } /** * Scans the plugin for declared public annotated classes * * @param pluginName the plugin name * @param annotations annotations declared by the plugin classes * @return map of annotations and associated plugin classes found * @throws InvalidPluginException if the plugin is not valid or corrupted */ Map<Class<? extends Annotation>, Iterable<ExtensionMetaData>> scan( String pluginName, Iterable<Class<? extends Annotation>> annotations ) throws InvalidPluginException; /** * Return the plugin resource
private static AllExternalIds buildAllExternalIds(Repository repo, AllExternalIds oldExternalIds, Map<ObjectId, ObjectId> additions, Set<ObjectId> removals) throws IOException { ImmutableSetMultimap.Builder<Account.Id, ExternalId> byAccount = ImmutableSetMultimap.builder(); ImmutableSetMultimap.Builder<String, ExternalId> byEmail = ImmutableSetMultimap.builder(); // Copy over old ExternalIds but exclude deleted ones for (ExternalId externalId : oldExternalIds.byAccount().values()) { if (removals.contains(externalId.blobId())) { continue; } byAccount.put(externalId.accountId(), externalId); if (externalId.email() != null) { byEmail.put(externalId.email(), externalId); } } // Add new ExternalIds for (Map.Entry<ObjectId, ObjectId> entry : additions.entrySet()) { ExternalId externalId = ExternalId.create(entry.getKey(), entry.getValue()); byAccount.put(externalId.accountId(), externalId); if (externalId.email() != null) { byEmail.put(externalId.email(), externalId); } } return new AllExternalIds(byAccount.build(), byEmail.build()); }
import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.treewalk.TreeWalk; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.Mockito; import org.mockito.junit.MockitoJUnitRunner; @RunWith(MockitoJUnitRunner.class) public class ExternalIDCacheLoaderTest { private static AllUsersName ALL_USERS = AllUsersNameProvider.DEFAULT; @Mock Cache<ObjectId, AllExternalIds> externalIdCache; private ExternalIdCacheLoader loader; private GitRepositoryManager repoManager = new InMemoryRepositoryManager(); private ExternalIdReader externalIdReader; private ExternalIdReader externalIdReaderSpy; @Before public void setUp() throws Exception { repoManager.createRepository(ALL_USERS).close(); externalIdReader = new ExternalIdReader(repoManager, ALL_USERS, new DisabledMetricMaker()); externalIdReaderSpy = Mockito.spy(externalIdReader); loader = createLoader(true); } @Test public void worksOnSingleCommit() throws Exception { // Test code here } }
private final TypeAdapter<T> defaultEnumAdapter; public EnumTypeAdapter(TypeAdapter<T> defaultEnumAdapter) { this.defaultEnumAdapter = defaultEnumAdapter; } @Override public T read(JsonReader in) throws IOException { if (in.peek() == JsonToken.NULL) { in.nextNull(); return null; } T enumValue = defaultEnumAdapter.read(in); if (enumValue == null) { throw new JsonSyntaxException(String.format("Invalid value '%s' for enum %s", in.nextString(), defaultEnumAdapter.getClass().getSimpleName())); } return enumValue; } @Override public void write(JsonWriter out, T value) throws IOException { defaultEnumAdapter.write(out, value); }
public void emptyEnumValueIsRejectedOnParse() { try { gson.fromJson("{\"value\":\"\"}", TestData.class); fail("Expected JsonSyntaxException to be thrown"); } catch (JsonSyntaxException e) { // Log the exception logger.error("Failed to parse empty enum value", e); // Handle the exception based on the severity if (isCriticalError(e)) { // Trigger a fire drill and rollback triggerFireDrillAndRollback(); } else { // Log a warning and continue processing logger.warn("Empty enum value encountered, but not critical"); } } }
private void waitUntilFinished() throws InterruptedException { while (!isCallFinished.get()) { Thread.sleep(100); } }
/** * Deletes a child resource. * * The returned response usually does not have any value (status code 204 No Content). * If a value in the returned response is set, it is automatically converted to JSON unless it is a BinaryResult. * * Further properties like caching behavior (see CacheControl) can be optionally set on the returned response. * * Throwing a subclass of RestApiException results in a 4XX response to the client. For any other exception, the client will get a 500 Internal Server Error response. * * @param parentResource the parent resource of the resource that should be deleted * @param id the ID of the child resource that should be deleted * @param input the input after parsing from the request * @return the response to return to the client * @throws RestApiException if the resource deletion is rejected */ public Response deleteChildResource(ParentResource parentResource, String id, Input input) throws RestApiException { // implementation goes here }
/** * RestCollectionModifyViews this is usually {code 200 OK}, but other 2XX or 3XX status codes are * also possible (e.g. {code 201 Created} if a resource was created, {code 202 Accepted} if a * background task was scheduled, {@code 204 No Content} if no content is returned, {@code 302 * Found} for a redirect). * <p>Further properties like caching behavior (see {@link CacheControl}) can be optionally set on * the returned response. * <p>Throwing a subclass of {@link RestApiException} results in a 4XX response to the client. For * any other exception the client will get a {@code 500 Internal Server Error} response. * * @param parentResource the collection resource on which the modification is done * @return response to return to the client * @throws Exception the implementation of the view failed. The exception will be logged and HTTP * 500 Internal Server Error will be returned to the client. * @throws UnsupportedOperationException if the response type does not support this operation */
throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } Map<ProjectWatchKey, Set<NotifyType>> projectWatches = asMap(input); accountsUpdateProvider .get() .update( "Update Project Watches via API", rsrc.getUser().getAccountId(), u -> u.updateProjectWatches(projectWatches)); return Response.ok(getWatchedProjects.apply(rsrc).value()); } private Map<ProjectWatchKey, Set<NotifyType>> asMap(List<ProjectWatchInfo> input) throws RestApiException, IOException, PermissionBackendException { Map<ProjectWatchKey, Set<NotifyType>> m = new HashMap<>(); for (ProjectWatchInfo info : input) { if (info.project == null) { throw new BadRequestException("project name must be specified"); } ProjectWatchKey key = ProjectWatchKey.create(projectsCollection.parse(info.project).getNameKey(), info.filter); if (m.containsKey(key)) { throw new BadRequestException("duplicate project watch key"); } m.put(key, info.notify); } return m; }
public void notifyChanged(Notification notification) { super.notifyChanged(notification); if (notification.getFeature() == VTablePackage.eINSTANCE.getTableDomainModelReference_ColumnDomainModelReferences()) { viewer.refresh(); parent.layout(); } if (VTableDomainModelReference.class.isInstance(notification.getNotifier())) { updateSetting(); viewer.refresh(); parent.layout(); } if (VTableControl.class.isInstance(notification.getNotifier()) && VTableDomainModelReference.class.isInstance(notification.getNewValue())) { updateSetting(); viewer.refresh(); parent.layout(); } } private static List<Rule> getRules(VElement renderable) { final HashMap<Class<? extends Rule>, Rule> rules = new HashMap<Class<? extends Rule>, Rule>(); for (final VAttachment attachment : renderable.getAttachments()) { if (Rule.class.isInstance(attachment)) { final Rule rule = (Rule) attachment; if (!rules.containsKey(rule.getClass())) { rules.put(rule.getClass(), rule); } } } return rules.values(); } List<SlotId> equivSlotIds = Lists.newArrayList(analyzer.getEquivSlots(slotId)); Iterator<SlotId> iter = equivSlotIds.iterator(); while (iter.hasNext()) { SlotId equivSlotId = iter.next(); if (equivSlotId.equals(slotId)) continue; TupleDescriptor tupleDesc = analyzer.getSlotDesc(equivSlotId).getParent(); if (tupleDesc.getTable() == null || !analyzer.hasValueTransfer(slotId, equivSlotId)) { continue; } List<SlotId> sids = slotsByTid.get(tupleDesc.getId()); if (sids == null) { sids = Lists.newArrayList(); slotsByTid.put(tupleDesc.getId(), sids); } sids.add(equivSlotId); } return slotsByTid; this.self = self; this.changes = changes; } @Override @SuppressWarnings("unchecked") public Response<List<ChangeInfo>> apply(AccountResource rsrc) throws BadRequestException, AuthException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { throw new AuthException("not allowed to list stars of another account"); } QueryChanges query = changes.list(); query.addQuery("has:stars"); return Response.ok((List<ChangeInfo>) query.apply(TopLevelResource.INSTANCE).value());
public Response<?> apply(ProjectResource rsrc, Input input) { Project.NameKey project = rsrc.getNameKey(); if (input.async) { return applyAsync(project, input); } return Response.ok(applySync(project, input)); }
private final String DEFAULT_DASHBOARD_MESSAGE = "Changed default dashboard to %s.\n"; public Response<DashboardInfo> setDefaultDashboard(ChangeResource rsrc, Input input) throws RestApiException { try { String msg = String.format(DEFAULT_DASHBOARD_MESSAGE, input.id); if (!msg.endsWith("\n")) { msg += "\n"; } md.setAuthor(rsrc.getUser().asIdentifiedUser()); md.setMessage(msg); config.commit(md); cache.evict(rsrc.getProjectState().getProject()); if (target != null) { DashboardInfo info = get.get().apply(target).value(); info.isDefault = true; return Response.ok(info); } return Response.none(); } catch (RepositoryNotFoundException notFound) { throw new ResourceNotFoundException(rsrc.getProjectState().getProject().getName()); } catch (ConfigInvalidException e) { throw new ResourceConflictException(String.format("invalid project.config: %s", e.getMessage())); } }
// limitations under the License. package com.google.gerrit.acceptance.testsuite.project; import static com.google.common.truth.Truth.assertThat; import static java.util.stream.Collectors.toList; import com.google.common.collect.ImmutableList; import com.google.gerrit.acceptance.AbstractDaemonTest; import com.google.gerrit.extensions.api.projects.BranchInfo; import com.google.gerrit.reviewdb.client.Project; import com.google.inject.Inject; import java.util.List; import org.junit.Test; public class ProjectOperationsImplTest extends AbstractDaemonTest { @Inject private ProjectOperations projectOperations; @Test public void defaultName() throws Exception { Project.NameKey name = projectOperations.newProject().create(); gApi.projects().name(name.get()); Project.NameKey name2 = projectOperations.newProject().create(); assertThat(name2).isNotEqualTo(name); } @Test public void specifiedName() throws Exception { String name = "somename"; Project.NameKey key = projectOperations.newProject().name(name).create(); assertThat(key.get()).isEqualTo(name); } @Test public void emptyCommit() throws Exception { // Test code here } } import org.eclipse.osee.orcs.data.ArtifactReadable; /** * @author Donald G. Dunne * @author David W. Miller */ @Path("program") public class ProgramResource extends AbstractConfigResource { @Context private UriInfo uriInfo; public void setUriInfo(UriInfo uriInfo) { this.uriInfo = uriInfo; } public ProgramResource(IAtsServer atsServer) { super(AtsArtifactTypes.Program, atsServer); } @GET @Path("{uuid}/insertion") @Produces(MediaType.APPLICATION_JSON) public Response getProgramInsertions(@PathParam("uuid") long uuid) throws Exception { ArtifactReadable programArt = atsServer.getArtifactByUuid(uuid); if (programArt == null) { throw new OseeCoreException("Given uuid not found"); } if (!programArt.getArtifactType().equals(AtsArtifactTypes.Program)) { throw new OseeCoreException("Given uuid not program type"); } // get the insertions related to the given program ResultSet<ArtifactReadable> results = programArt.getRelated(AtsRelationTypes.ProgramToInsertion_Insertion);
private void savePluginSections(Config rc, Set<AccountGroup.UUID> keepGroups) { unsetSection(rc, PLUGIN); List<String> existing = new ArrayList<>(rc.getSubsections(PLUGIN)); for (Map.Entry<String, Config> e : pluginConfigs.entrySet()) { String plugin = e.getKey(); Config pluginConfig = e.getValue(); for (String name : pluginConfig.getNames(PLUGIN, plugin)) { String value = pluginConfig.getString(PLUGIN, plugin, name); String groupName = GroupReference.extractGroupName(value); if (groupName != null) { GroupReference ref = groupsByName.get(groupName); if (ref != null && ref.getUUID() != null) { keepGroups.add(ref.getUUID()); pluginConfig.setString(PLUGIN, plugin, name, "group " + ref.getName()); } } rc.setStringList(PLUGIN, plugin, name, Arrays.asList(pluginConfig.getStringList(PLUGIN, plugin, name))); } } }
this.accountInfoFactory = infoFactory; this.projectCache = projectCache; this.prologRule = prologRule; @Override public Response<List<TestSubmitRuleInfo>> apply(RevisionResource rsrc, TestSubmitRuleInput input) throws AuthException, PermissionBackendException, BadRequestException { if (input == null) { input = new TestSubmitRuleInput(); } if (input.rule == null) { throw new BadRequestException("rule is required"); } if (!rules.isProjectRulesEnabled()) { throw new AuthException("project rules are disabled"); } input.filters = MoreObjects.firstNonNull(input.filters, filters); SubmitRuleOptions opts = SubmitRuleOptions.builder() .skipFilters(input.filters == Filters.SKIP) .rule(input.rule) .logErrors(false) .build(); ProjectState projectState = projectCache.get(rsrc.getProject()); if (projectState == null) { throw new BadRequestException("project not found"); } }
// http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.gerrit.extensions.registration.DynamicItem; import com.google.inject.AbstractModule; /** * Module for the Replication extension point. */ public class ReplicationExtensionPointModule extends AbstractModule { @Override protected void configure() { DynamicItem.itemOf(binder(), ReplicationPushFilter.class); } }
import org.junit.Test; import java.io.IOException; import java.util.List; import java.util.concurrent.TimeUnit; import java.util.stream.Collectors; import static org.easymock.EasyMock.*; import static org.junit.Assert.*; import static org.powermock.api.easymock.PowerMock.*; public class DialectEditorsOpeningWithFailingSessionOpeningTests extends SiriusTestCase { private IMemento memento; private IElementFactory elementFactory; private SessionOpeningFailureListener sessionOpeningFailureListener; private IEditorPart openedEditor; @Override protected void setUp() throws Exception { super.setUp(); closeWelcomePage(); } @Test public void shouldPushAllRefsWhenNoFiltersSetup() throws InterruptedException, IOException { List<RemoteRefUpdate> expectedUpdates = localRefs.values().stream() .map(ref -> { try { return new RemoteRefUpdate(repositoryMock, ref.getName(), ref.getObjectId(), "fooProject", false, "fooProject", null); } catch (IOException e) { throw new RuntimeException(e); } }) .collect(Collectors.toList()); PushResult pushResult = new PushResult(); expect(transportMock.push(anyObject(), compareRemoteRef(expectedUpdates))) .andReturn(pushResult) .once(); replay(transportMock); PushOne pushOne = createPushOne(replicationPushFilter); pushOne.addRef(PushOne.ALL_REFS); pushOne.run(); isCallFinished.await(10, TimeUnit.SECONDS); verify(transportMock); } }
throw new RuntimeException(e); }) .collect(Collectors.toList()); PushResult pushResult = new PushResult(); expect(transportMock.push(anyObject(), compareRemoteRef(expectedUpdates))) .andReturn(pushResult) .once(); replay(transportMock); PushOne pushOne = createPushOne(null); pushOne.addRef(PushOne.ALL_REFS); pushOne.run(); isCallFinished.await(10, TimeUnit.SECONDS); verify(transportMock); } @Test public void shouldNotApplyReplicationPushFilter() throws InterruptedException, IOException { DynamicItem<ReplicationPushFilter> replicationPushFilter = DynamicItem.itemOf( ReplicationPushFilter.class, new ReplicationPushFilter() { @Override public List<RemoteRefUpdate> filter( String projectName, List<RemoteRefUpdate> remoteUpdatesList) { return remoteUpdatesList; } }); // easymock way to check if method was never called expect(transportMock.push(anyObject(), anyObject())) .andThrow(new AssertionFailedError()) .anyTimes(); replay(transportMock); PushOne pushOne = createPushOne(replicationPushFilter); }
public List<RemoteRefUpdate> filter(String projectName, List<RemoteRefUpdate> remoteUpdatesList) { return Collections.emptyList(); }
private CommentFormatter createCommentFormatter() { return commentJson.get() .setFillAccounts(includeAuthorInfo()) .setFillPatchSet(true) .newCommentFormatter(); } throw new AuthException("Authentication required"); } return commentJson.get() .setFillAccounts(includeAuthorInfo()) .setFillPatchSet(true) .format(listComments(rsrc)); public List<CommentInfo> getComments(ChangeResource rsrc) throws AuthException, OrmException { if (requireAuthentication() && !rsrc.getUser().isIdentifiedUser()) { throw new AuthException("Authentication required"); } return createCommentFormatter().formatAsList(listComments(rsrc)); }
static final String MAX_CACHE_AGE = "maxCacheAge"; // seconds to stay in cache static final String MAX_CACHE_SIZE = "maxCacheSize"; // number of OwnersDb in cache static final String MIN_OWNER_VOTE_LEVEL = "minOwnerVoteLevel"; // default +1 static final String REPORT_SYNTAX_ERROR = "reportSyntaxError"; // only for tests // "alwaysShowButton" is obsolete, new UI design always shows the [Find Owners] button // Name of config parameters that can be defined in project.config or gerrit.confg: static final String OWNERS_FILE_NAME = "ownersFileName"; // config key for file name static final String REJECT_ERROR_IN_OWNERS = "rejectErrorInOwners"; // enable upload validator static final String OWNERS = "OWNERS"; // default OWNERS file name // Name of plugin and namespace. static final String PLUGIN_NAME = "find-owners"; static final String PROLOG_NAMESPACE = "find_owners"; private final PluginConfigFactory configFactory; // Each call to API entry point creates one new Config and parses gerrit.config.
String getOwnersFileName(Project project) { String defaultName = getDefaultOwnersFileName(); try { String name = getProjectConfig(project).getString(OWNERS_FILE_NAME, defaultName); if (name.trim().isEmpty()) { logger.atSevere().log("Project %s has empty %s", project, OWNERS_FILE_NAME); return defaultName; } return name; } catch (NoSuchProjectException e) { logger.atSevere().withCause(e).log("Exception in getOwnersFileName for %s", project.getName()); return defaultName; } }
public ImmutableSet<Account.Id> getAccountFor(String email) throws IOException { ImmutableSet<Account.Id> accounts = externalIds.byEmail(email) .stream() .map(ExternalId::accountId) .collect(toImmutableSet()); if (!accounts.isEmpty()) { return accounts; } return executeIndexQuery(() -> queryProvider.get().byPreferredEmail(email) .stream() .map(a -> a.getAccount().id()) .collect(toImmutableSet())); }
package com.google.gerrit.server.account; import static com.google.common.collect.ImmutableList.toImmutableList; import static com.google.common.collect.ImmutableSet.toImmutableSet; import com.google.common.base.Throwables; import com.google.common.collect.ImmutableSet; import com.google.common.collect.ImmutableSetMultimap; import com.google.common.collect.MultimapBuilder; import com.google.common.collect.SetMultimap; import com.google.gerrit.exceptions.StorageException; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.server.account.externalids.ExternalId; import com.google.gerrit.server.account.externalids.ExternalIds; import com.google.gerrit.server.query.account.InternalAccountQuery; import com.google.gerrit.server.update.RetryHelper; import com.google.gerrit.server.update.RetryHelper.Action; import com.google.gerrit.server.update.RetryHelper.ActionType; import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.Singleton; import java.io.IOException; import java.util.Arrays; import java.util.List; /** * Class to access accounts by email. */ @Singleton public class Emails { private final ExternalIds externalIds; private final Provider<InternalAccountQuery> accountQueryProvider; private final RetryHelper retryHelper; @Inject public Emails(ExternalIds externalIds, Provider<InternalAccountQuery> accountQueryProvider, RetryHelper retryHelper) { this.externalIds = externalIds; this.accountQueryProvider = accountQueryProvider; this.retryHelper = retryHelper; } public ImmutableSet<Account.Id> getAccountFor(String email) throws IOException { try { return retryHelper.execute(ActionType.ACCOUNTS_BY_EMAIL, new Action<ImmutableSet<Account.Id>>() { @Override public ImmutableSet<Account.Id> execute() throws IOException { return doGetAccountFor(email); } }); } catch (StorageException e) { Throwables.throwIfInstanceOf(e.getCause(), IOException.class); throw new IOException(e); } } private ImmutableSet<Account.Id> doGetAccountFor(String email) throws IOException { SetMultimap<String, Account.Id> byEmail = MultimapBuilder.hashKeys().hashSetValues().build(); ImmutableSetMultimap.Builder<Account.Id, ExternalId.Key> byAccount = ImmutableSetMultimap.builder(); externalIds.byEmail(email).forEach(externalId -> { byEmail.put(email,
// http://www.apache.org/licenses/LICENSE-2.0 // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.extensions.common.GitPerson; public class SharedRefLogEntry { public enum Type { UPDATE_REF, DELETE_REF, DELETE_PROJECT } public String projectName; public Type type; public static class UpdateRef extends SharedRefLogEntry { public String refName; public String oldId; public String newId; public GitPerson committer; public String comment; UpdateRef(String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } } }
public SharedRefDatabaseWrapper(DynamicItem<SharedRefDatabase> sharedRefDatabase, SharedRefLogger sharedRefLogger) { this.sharedRefDb = sharedRefDatabase.get(); this.sharedRefLogger = sharedRefLogger; }
public SharedRefDatabaseWrapper(DynamicItem<SharedRefDatabase> sharedRefDatabase, SharedRefLogger sharedRefLogger) { this.sharedRefDatabase = sharedRefDatabase; this.sharedRefLogger = sharedRefLogger; } // In runtime, use sharedRefDatabase.get() to access the actual SharedRefDatabase instance.
logger.atFiner().log("Create new OwnersDb, key=%s", key); return new OwnersDb(permissionBackend, projectState, accountCache, emails, key, repoManager, config, changeData, branch, files); } try { logger.atFiner().log("Get from cache %s, key=%s, cache size=%d", dbCache, key, dbCache.size()); logger.atFine().log("FindOwnersCacheStats: " + dbCache.stats()); return dbCache.get(key, new Callable<OwnersDb>() { @Override public OwnersDb call() { logger.atFiner().log("Create new OwnersDb, key=%s", key); return new OwnersDb(permissionBackend, projectState, accountCache, emails, key, repoManager, config, changeData, branch, files); } }); } catch (ExecutionException e) { logger.atSevere().withCause(e).log("Error getting OwnersDb from cache: " + e.getMessage()); throw new RuntimeException("Error getting OwnersDb from cache", e); }
.create(); update(rev); ProjectConfig cfg = read(rev); cfg.getAccountsSection().setSameGroupVisibility(ImmutableList.of()); rev = commit(cfg); assertThat(text(rev, "project.config")) .isEqualTo("[commentlink \"bugzilla\"]\n\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n"); } @Test public void contributorSectionIsUnsetIfNoPermissionsAreSet() throws Exception { RevCommit rev = tr.commit() .add("project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[contributor-agreement \"Individual\"]\n" + " accepted = group Developers\n" + " accepted = group Staff\n") .create(); update(rev); ProjectConfig cfg = read(rev); ContributorAgreement section = cfg.getContributorAgreement("Individual");
.create(); update(rev); ProjectConfig cfg = read(rev); ContributorAgreement section = cfg.getContributorAgreement("Individual"); section.setAccepted(ImmutableList.of()); rev = commit(cfg); assertThat(text(rev, "project.config")) .isEqualTo( "[commentlink \"bugzilla\"]\n\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n"); } @Test public void notifySectionIsUnsetIfNoPermissionsAreSet() throws Exception { RevCommit rev = tr.commit() .add( "project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[notify \"name\"]\n" + " email = example@example.com\n") .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getNotifyConfigs().clear(); rev = commit(cfg);
@Test public void commentLinkSectionIsUnsetIfNoPermissionsAreSet() throws Exception { RevCommit rev = tr.commit() .add("project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[notify \"name\"]\n" + " email = example@example.com\n") .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getCommentLinkSections().clear(); rev = commit(cfg); }
@NoHttpd public class NoUnresolvedCommentsRuleIT extends LightweightPluginDaemonTest { private static final String FILENAME = "my.file"; @Before public void enableRuleBeforeTest() throws Exception { enableRule(true); } @Test public void blocksWithUnresolvedComments() throws Exception { ReviewInput.CommentInput comment = newFileComment(); comment.unresolved = true; PushOneCommit.Result r = createChangeWithComment(comment); Optional<SubmitRecord> submitRecords = evaluate(r.getChange()); assertThat(submitRecords).isPresent(); SubmitRecord result = submitRecords.get(); assertThat(result.status).isEqualTo(SubmitRecord.Status.NOT_READY); assertThat(result.labels).isNull(); assertThat(result.requirements).hasSize(1); } @Test public void doesNotBlockWithNoComments() throws Exception { PushOneCommit.Result r = createChange(); Optional<SubmitRecord> submitRecords = evaluate(r.getChange()); assertThat(submitRecords).isPresent(); SubmitRecord result = submitRecords.get(); assertThat(result.status).isEqualTo(SubmitRecord.Status.OK); assertThat(result.labels).isNull(); assertThat(result.requirements).isNull(); } }
package com.google.gerrit.server.rules; import com.google.gerrit.common.data.SubmitRecord; import com.google.gerrit.extensions.annotations.ExtensionPoint; import com.google.gerrit.server.query.change.ChangeData; import java.util.Optional; /** * Allows plugins to decide whether a change is ready to be submitted or not. * * <p>For a given {@link ChangeData}, each plugin is called and returns a {@link Optional} of {@link SubmitRecord}. * This collection can be empty, or contain one or several values. * * <p>A Change can only be submitted if all the plugins give their consent. * * <p>Each {@link SubmitRecord} represents a decision made by the plugin. If the plugin rejects a * change, it should hold valuable information to help the end user understand and correct the * blocking points. * * <p>It should be noted that each plugin can handle rules inheritance. * * <p>This interface should be used to write pre-submit validation rules. This includes both simple */ @ExtensionPoint public interface SubmitRule { /** * Evaluates the submit rule for the given change. * * @param changeData the change data * @return an optional submit record */ Optional<SubmitRecord> evaluate(ChangeData changeData); }
import java.util.Map; import java.util.Optional; import org.eclipse.jgit.internal.storage.dfs.InMemoryRepository; import org.eclipse.jgit.junit.TestRepository; import org.junit.Test; @NoHttpd public class IgnoreSelfApprovalRuleIT extends AbstractDaemonTest { @Inject private IgnoreSelfApprovalRule rule; @Test public void blocksWhenUploaderIsOnlyApprover() throws Exception { enableRule("Code-Review", true); PushOneCommit.Result r = createChange(); approve(r.getChangeId()); Optional<SubmitRecord> submitRecord = rule.evaluate(r.getChange()); assertThat(submitRecord.isPresent()).isTrue(); SubmitRecord result = submitRecord.get(); assertThat(result.status).isEqualTo(SubmitRecord.Status.NOT_READY); assertThat(result.labels).isNotEmpty(); assertThat(result.requirements) .containsExactly( SubmitRequirement.builder() .setFallbackText("Approval from non-uploader required") .setType("non_uploader_approval") .build()); } @Test public void allowsSubmissionWhenChangeHasNonUploaderApproval() throws Exception { enableRule("Code-Review", true); // Create change as user } }
import org.eclipse.jgit.api.errors.GitAPIException; import org.junit.Test; import java.io.IOException; import java.util.List; public class GetRelatedIT extends AbstractDaemonTest { @Inject private ChangeEditUtil editUtil; @Inject private ChangeEditModifier editModifier; @Test public void getRelatedNoResult() throws GitAPIException, IOException, Exception { PushOneCommit push = pushFactory.create(db, admin.getIdent()); PatchSet.Id ps = push.to(git, "refs/for/master").getPatchSetId(); List<ChangeAndCommit> related = getRelated(ps); assertThat(related).isEmpty(); } @Test public void getRelatedLinear() throws GitAPIException, IOException, Exception { add(git, "a.txt", "1"); Commit c1 = createCommit(git, admin.getIdent(), "subject: 1"); add(git, "b.txt", "2"); Commit c2 = createCommit(git, admin.getIdent(), "subject: 2"); pushHead(git, "refs/for/master", false); for (Commit c : ImmutableList.of(c2, c1)) { // code logic here } } @Test public void allowsSubmissionWhenChangeHasNonUploaderApproval() throws Exception { enableRule("Code-Review", true); TestRepository<InMemoryRepository> userTestRepo = cloneProject(project, user); PushOneCommit push = pushFactory.create(user.newIdent(), userTestRepo); PushOneCommit.Result r = push.to("refs/for/master"); approve(r.getChangeId()); Optional<SubmitRecord> submitRecords = rule.evaluate(r.getChange()); assertThat(submitRecords).isEmpty(); } @Test public void doesNothingByDefault() throws Exception { enableRule("Code-Review", false); PushOneCommit.Result r = createChange(); approve(r.getChangeId()); Optional<SubmitRecord> submitRecords = rule.evaluate(r.getChange()); assertThat(submitRecords).isEmpty(); } private void enableRule(String labelName, boolean newState) throws Exception { try (ProjectConfigUpdate u = updateProject(project)) { Map<String, LabelType> localLabelSections = u.getConfig().getLabelSections(); // code logic here } } }
public void convertsPrologToSubmitRecord() { PrologRuleEvaluator evaluator = makeEvaluator(); StructureTerm verifiedLabel = makeLabel("Verified", "may"); StructureTerm labels = new StructureTerm("label", verifiedLabel); List<Term> terms = ImmutableList.of(makeTerm("ok", labels)); Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); assertThat(record).isPresent(); }
terms.add(makeTerm("ok", makeLabels(label2))); terms.add(makeTerm("not_ready", makeLabels(label3))); Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); SubmitRecord expectedRecord = new SubmitRecord(); expectedRecord.status = SubmitRecord.Status.OK; expectedRecord.labels = new ArrayList<>(); expectedRecord.labels.add(submitRecordLabel2); expectedRecord.labels.add(submitRecordLabel3); assertThat(record).isPresent(); assertThat(record.get()).isEqualTo(expectedRecord);
terms.add(makeTerm("ok", makeLabels(label2))); terms.add(makeTerm("not_ready", makeLabels(label3))); Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); SubmitRecord expectedRecord = new SubmitRecord(); expectedRecord.status = SubmitRecord.Status.OK; expectedRecord.labels = new ArrayList<>(); expectedRecord.labels.add(submitRecordLabel2); expectedRecord.labels.add(submitRecordLabel3); assertThat(record).isPresent(); assertThat(record.get()).isEqualTo(expectedRecord);
protected void configure() { if (config.getSharedRefDb().isEnabled()) { DynamicSet.bind(binder(), ProjectDeletedListener.class) .to(ProjectDeletedSharedDbCleanup.class); } install(new ValidationModule(config)); }
protected void configure() { bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getZookeeperConfig().buildCurator()); bind(ZkConnectionConfig.class) .toInstance(new ZkConnectionConfig(cfg.getZookeeperConfig().buildCasRetryPolicy(), cfg.getZookeeperConfig().getZkInterProcessLockTimeOut())); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ProjectDeletedSharedDbCleanup.class); }
metadataBuilder.addPluginMetadata( PluginMetadata.create(PUBLISHER_SUCCESS_COUNTER, fieldValue) ) .description("Broker message published count") .build(); this.brokerPublisherFailureCounter = metricMaker.newCounter( "multi_site/broker/broker_message_publisher_failure_counter", new Description("Number of messages failed to publish by the broker publisher") .setRate() .setUnit("errors"), Field.ofString( PUBLISHER_FAILURE_COUNTER, (metadataBuilder, fieldValue) -> metadataBuilder.addPluginMetadata( PluginMetadata.create(PUBLISHER_FAILURE_COUNTER, fieldValue) ) ) .description("Broker failed to publish message count") .build() );
new Description("Number of messages failed to publish by the broker publisher") .setRate() .setUnit("errors"), Field.ofString(PUBLISHER_FAILURE_COUNTER, metadataMapper(PUBLISHER_FAILURE_COUNTER)) .description("Broker failed to publish message count") .build()); public void incrementBrokerPublishedMessage() { brokerPublisherSuccessCounter.increment(PUBLISHER_SUCCESS_COUNTER); } public void incrementBrokerFailedToPublishMessage() { brokerPublisherFailureCounter.increment(PUBLISHER_FAILURE_COUNTER); } private BiConsumer<Metadata.Builder, String> metadataMapper(String metadataKey) { return (metadataBuilder, fieldValue) -> metadataBuilder.addPluginMetadata(PluginMetadata.create(metadataKey, fieldValue)); }
"Kafka consumer subscribing to topic [%s] for event family [%s]", topic, getEventFamily()); consumer.subscribe(Collections.singleton(topic)); while (!closed.get()) { ConsumerRecords<byte[], byte[]> consumerRecords = consumer.poll(Duration.ofMillis(configuration.kafkaSubscriber().getPollingInterval())); consumerRecords.forEach(this::processRecord); } } catch (WakeupException e) { // Ignore exception if closing if (!closed.get()) { throw e; } } catch (Exception e) { subscriberMetrics.incrementSubscriberFailedToPollMessages(); throw e; } finally { consumer.close(); }
eventRouter.route(event.getEventBody(gson)); subscriberMetrics.incrementSubscriberConsumedMessage(); } catch (IOException e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (PermissionBackendException | OrmException e) { logger.atSevere().withCause(e).log( "Cannot handle message %s: [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (Exception e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", new String(consumerRecord.value(), UTF_8)); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); }
public IndexEventSubscriber(KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, IndexEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gsonProvider, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super(configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gsonProvider, instanceId, oneOffCtx, msgLog, subscriberMetrics); }
public KafkaCacheEvictionEventSubscriber(KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, StreamEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gsonProvider, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super(configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gsonProvider, instanceId, oneOffCtx, msgLog, subscriberMetrics); }
public ProjectUpdateEventSubscriber(KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, ProjectListUpdateRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gson, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super(configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gson, instanceId, oneOffCtx, msgLog, subscriberMetrics); }
public StreamEventSubscriber(KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, StreamEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gson, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super(configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gson, instanceId, oneOffCtx, msgLog, subscriberMetrics); }
private String replaceInUrl(String placeholder, String url, String replacement, boolean lowerCase) { if (url == null || replacement == null || !url.contains(placeholder)) { return url; } if (lowerCase) { replacement = replacement.toLowerCase(); } return url.replace(placeholder, Url.encode(replacement)); }
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.broker; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public interface BrokerSession { boolean isOpen(); void connect(); void disconnect(); boolean publishEvent(EventFamily eventFamily, String payload); boolean publishEventToTopic(String topic, String payload); }
CheckUpdate.Builder builder = CheckUpdate.builder(); builder.setState(CheckState.NOT_STARTED) .unsetFinished() .unsetStarted() .setMessage("") .setUrl(""); Check updatedCheck; if (!check.isPresent()) { Checker checker = checkers.getChecker(checkerUuid) .orElseThrow(() -> new ResourceNotFoundException(String.format("checker %s not found", checkerUuid))); updatedCheck = Check.newBackfilledCheck( checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getPatchSet(), checker); } else { updatedCheck = checksUpdate.get().updateCheck(key, builder.build()); } return checkJsonFactory.noOptions().format(updatedCheck); }
CheckUpdate.Builder builder = CheckUpdate.builder(); builder.setState(CheckState.NOT_STARTED) .unsetFinished() .unsetStarted() .setMessage("") .setUrl(""); Check updatedCheck; if (!check.isPresent()) { Checker checker = checkers.getChecker(checkerUuid) .orElseThrow(() -> new ResourceNotFoundException(String.format("checker %s not found", checkerUuid))); updatedCheck = Check.newBackfilledCheck( checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getPatchSet(), checker ); } else { updatedCheck = checksUpdate.get().updateCheck(key, builder.build()); } return checkJsonFactory.noOptions().format(updatedCheck);
Fixed Code: ``` assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); assertThat(info.updated).isGreaterThan(info.created); } @Test public void rerunCheckNotExistingButBackfilled() throws Exception { CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunExistingCheckWithCheckerNotAppliedToChange() throws Exception { Project.NameKey otherProject = createProjectOverAPI("other", null, true, null); checkerOperations.checker(checkKey.checkerUuid()).forUpdate().repository(otherProject).update(); checkOperations.newCheck(checkKey).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunNonExistingCheckWithCheckerNotAppliedToChange() throws Exception { Project.NameKey otherProject = createProjectOverAPI("other", null, true, null); checkerOperations.checker(checkKey.checkerUuid()).forUpdate().repository(otherProject).update(); assertThrows(ResourceNotFoundException.class, () -> { checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); }); } ```
// // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.inject.Inject; import com.google.inject.Singleton; import java.util.Optional; import org.eclipse.jgit.transport.URIish; /** * Factory for creating AdminApi instances. */ public interface AdminApiFactory { Optional<AdminApi> create(URIish uri); @Singleton static class DefaultAdminApiFactory implements AdminApiFactory { protected final SshHelper sshHelper; @Inject public DefaultAdminApiFactory(SshHelper sshHelper) { this.sshHelper = sshHelper; } @Override public Optional<AdminApi> create(URIish uri) { if (isGerrit(uri)) { return Optional.of(new GerritSshApi(sshHelper, uri)); } else if (!uri.isRemote()) { return Optional.of(new LocalFS(uri)); } return Optional.empty(); } /** * Checks if the given URIish is a Gerrit URI. * * @param uri the URIish to check * @return true if the URIish is a Gerrit URI, false otherwise */ private boolean isGerrit(URIish uri) { // implementation goes here } } }
if (destRef == null) { throw new ResourceConflictException("Can't rebase onto tip of branch " + destRefKey.get() + "; branch doesn't exist"); } return destRef.getObjectId(); Base base = rebaseUtil.parseBase(rsrc, str); if (base == null) { throw new ResourceConflictException("Base revision is missing from the destination branch: " + str); } PatchSet.Id baseId = base.patchSet().getId(); if (change.getId().equals(baseId.getParentKey())) { throw new ResourceConflictException("Cannot rebase change onto itself"); } permissionBackend .user(rsrc.getUser()) .database(dbProvider) .change(base.notes()) .check(ChangePermission.READ); Change baseChange = base.notes().getChange(); if (!baseChange.getProject().equals(change.getProject())) { throw new ResourceConflictException("Base change is in wrong project: " + baseChange.getProject()); } else if (!baseChange.getDest().equals(change.getDest())) { throw new ResourceConflictException("Base change is in wrong destination branch: " + baseChange.getDest()); }
package com.googlesource.gerrit.plugins.multisite.kafka; import com.google.gerrit.server.events.Event; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.broker.BrokerApi; import com.googlesource.gerrit.plugins.multisite.broker.kafka.BrokerPublisher; import com.googlesource.gerrit.plugins.multisite.consumer.SourceAwareEventWrapper; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventTopic; import com.googlesource.gerrit.plugins.multisite.kafka.consumer.KafkaEventSubscriber; import java.util.function.Consumer; public class KafkaBrokerApi implements BrokerApi { private final BrokerPublisher publisher; private final KafkaEventSubscriber subscriber; @Inject public KafkaBrokerApi(BrokerPublisher publisher, KafkaEventSubscriber subscriber) { this.publisher = publisher; this.subscriber = subscriber; } @Override public boolean send(String topic, Event event) { return publisher.publish(topic, event); } @Override public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { subscriber.subscribe(EventTopic.of(topic), eventConsumer); } }
public void receiveAsync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { subscriber.subscribe(EventTopic.of(topic), eventConsumer); }
} listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } install(new BrokerModule()); DynamicItem.bind(binder(), BrokerApi.class).to(KafkaBrokerApi.class); install(kafkaForwardedEventRouterModule); install(kafkaBrokerForwarderModule); install(new ValidationModule(config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); bind(Gson.class) .annotatedWith(BrokerGson.class) .toProvider(GsonProvider.class) .in(Singleton.class);
public void receiveAsync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { apiDelegate.get().receiveAsync(topic, eventConsumer); }
public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { KafkaEventSubscriber subscriber = subscriberProvider.get(); synchronized (subscribers) { subscribers.add(subscriber); } subscriber.subscribe(EventTopic.of(topic), eventConsumer); }
import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.config.SitePaths; import com.google.gerrit.server.util.ManualRequestContext; import com.google.gerrit.server.util.OneOffRequestContext; import com.google.gerrit.server.util.RequestContext; import com.google.gerrit.testing.ConfigSuite; import com.google.inject.Injector; import com.google.inject.Module; import com.google.inject.Provider; import java.io.File; import java.io.IOException; import java.util.Arrays; import java.util.Collections; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.StoredConfig; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.eclipse.jgit.util.SystemReader; import org.junit.Rule; import org.junit.rules.RuleChain; import org.junit.rules.TemporaryFolder; import org.junit.rules.TestRule; import org.junit.runner.Description; import org.junit.runner.RunWith; import org.junit.runners.model.Statement; @RunWith(ConfigSuite.class) @UseLocalDisk public abstract class StandaloneSiteTest { // code goes here }
return new FileBasedConfig(parent, new File(tempDir, "user.config"), FS.detect()); } @Override public FileBasedConfig openSystemConfig(Config parent, FS fs) { return new FileBasedConfig(parent, new File(tempDir, "system.config"), FS.detect()); } @Override public long getCurrentTime() { return oldSystemReader.getCurrentTime(); } @Override public int getTimezone(long when) { return oldSystemReader.getTimezone(when); } @Override public StoredConfig getUserConfig() throws IOException, ConfigInvalidException { return oldSystemReader.getUserConfig(); } @Override public StoredConfig getSystemConfig() throws IOException, ConfigInvalidException { return oldSystemReader.getSystemConfig(); }
private final Map<URIish, PushOne> pending = new HashMap<>(); private final Map<URIish, PushOne> inFlight = new HashMap<>(); private final PushOne.Factory opFactory; private final GitRepositoryManager gitManager; private final PermissionBackend permissionBackend; private final Provider<CurrentUser> userProvider; private final ProjectCache projectCache; private volatile ScheduledExecutorService pool; private final PerThreadRequestScope.Scoper threadScoper; private final DestinationConfiguration config; private final DynamicItem<EventDispatcher> eventDispatcher; private final ReplicationTasksStorage replicationTasksStorage; protected enum RetryReason { TRANSPORT_ERROR, COLLISION, REPOSITORY_MISSING; } public static class QueueInfo { public final Map<URIish, PushOne> pending; public final Map<URIish, PushOne> inFlight; public QueueInfo(Map<URIish, PushOne> pending, Map<URIish, PushOne> inFlight) { this.pending = ImmutableMap.copyOf(pending); this.inFlight = ImmutableMap.copyOf(inFlight); } } @Inject protected Destination( Injector injector, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, ScheduledExecutorService pool, PerThreadRequestScope.Scoper threadScoper, DestinationConfiguration config, DynamicItem<EventDispatcher> eventDispatcher, ReplicationTasksStorage replicationTasksStorage) { this.opFactory = injector.getInstance(PushOne.Factory.class); this.gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.pool = pool; this.threadScoper = threadScoper; this.config = config; this.eventDispatcher = eventDispatcher; this.replicationTasksStorage = replicationTasksStorage; }
protected Destination(Injector injector, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, GroupBackend groupBackend, ReplicationStateListeners stateLog, GroupIncludeCache groupIncludeCache, DynamicItem<EventDispatcher> eventDispatcher, ReplicationTasksStorage rts, @Assisted DestinationConfiguration cfg) { this.eventDispatcher = eventDispatcher; gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.stateLog = stateLog; this.eventsStorage = rts; config = cfg; CurrentUser remoteUser; if (!cfg.getAuthGroupNames().isEmpty()) { ImmutableSet.Builder<AccountGroup.UUID> builder = ImmutableSet.builder(); for (String name : cfg.getAuthGroupNames()) { GroupReference g = GroupBackends.findExactSuggestion(groupBackend, name); if (g != null) { builder.add(g.getUUID()); addRecursiveParents(g.getUUID(), builder, groupIncludeCache); } else {
return; } } } synchronized (stateLock) { PushOne e = getPendingPush(uri); if (e == null) { e = opFactory.create(project, uri); addRef(e, ref); e.addState(ref, state); @SuppressWarnings("unused") ScheduledFuture<?> ignored = pool.schedule(e, now ? 0 : config.getDelay(), TimeUnit.SECONDS); pending.put(uri, e); eventsStorage.persist(project.get(), ref, e.getURI(), getRemoteConfigName()); } else if (!e.getRefs().contains(ref)) { addRef(e, ref); e.addState(ref, state); } state.increasePushTaskCount(project.get(), ref); repLog.info("scheduled {}:{} => {} to run after {}s", project, ref, e, config.getDelay()); }
void notifyFinished(PushOne op) { synchronized (stateLock) { inFlight.remove(op.getURI()); if (!op.wasCanceled()) { for (String ref : op.getRefs()) { if (!refHasPendingPush(op.getURI(), ref)) { eventsStorage.delete(op.getProjectNameKey().get(), ref, op.getURI(), getRemoteConfigName()); } } } } }
String key = "${name}"; int n = in.indexOf(key); if (0 <= n) { return in.substring(0, n) + name + in.substring(n + key.length()); } if (keyIsOptional) { return in; } return null; } private final WorkQueue workQueue; private final DynamicItem<EventDispatcher> dispatcher; private final ReplicationConfig config; private final AdminApiFactory adminApiFactory; private final ReplicationState.Factory replicationStateFactory; private final ReplicationTasksStorage replicationTasksStorage; private volatile boolean running; private volatile boolean replaying; @Inject ReplicationQueue(WorkQueue wq, AdminApiFactory aaf, ReplicationConfig rc, DynamicItem<EventDispatcher> dis, ReplicationStateListeners sl, ReplicationState.Factory rsf, ReplicationTasksStorage es) { workQueue = wq; dispatcher = dis; config = rc; stateLog = sl; adminApiFactory = aaf; replicationStateFactory = rsf; replicationTasksStorage = es; } @Override public void start() { if (!running) { config.startup(workQueue); running = true; } }
return in; } return null; } private final WorkQueue workQueue; private final DynamicItem<EventDispatcher> dispatcher; private final ReplicationConfig config; private final AdminApiFactory adminApiFactory; private final ReplicationState.Factory replicationStateFactory; private final ReplicationTasksStorage eventsStorage; private volatile boolean running; private volatile boolean replaying; @Inject ReplicationQueue(WorkQueue wq, AdminApiFactory aaf, ReplicationConfig rc, DynamicItem<EventDispatcher> dis, ReplicationStateListeners sl, ReplicationState.Factory rsf, ReplicationTasksStorage storage) { workQueue = wq; dispatcher = dis; config = rc; stateLog = sl; adminApiFactory = aaf; replicationStateFactory = rsf; eventsStorage = storage; } @Override public void start() { if (!running) { config.startup(workQueue); running = true; firePendingEvents(); } } @Override public void stop() { running = false; int discarded = config.shutdown(); if (discarded > 0) { log.warn("Discarded {} replication tasks during shutdown", discarded); } }
private void firePendingEvents() { try { Set<String> eventsReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate e : eventsStorage.list()) { String eventKey = String.format("%s:%s", e.project, e.ref); if (!eventsReplayed.contains(eventKey)) { repLog.info("Firing pending event {}", eventKey); onGitReferenceUpdated(e.project, e.ref); eventsReplayed.add(eventKey); } } } finally { replaying = false; } }
import java.util.List; import java.util.Map; import java.util.Set; class ReplayInlineCommentsStep { interface Factory { ReplayInlineCommentsStep create(Change change, ChangeInfo changeInfo, GerritApi api, boolean resume); } private static final Logger log = LoggerFactory.getLogger(ReplayInlineCommentsStep.class); private final AccountUtil accountUtil; private final ReviewDb db; private final IdentifiedUser.GenericFactory genericUserFactory; private final ChangeControl.GenericFactory changeControlFactory; private final ChangeUpdate.Factory updateFactory; private final CommentsUtil commentsUtil; private final PatchListCache patchListCache; private final PatchSetUtil psUtil; private final String serverId; private final Change change; private final ChangeInfo changeInfo; private final GerritApi api; private final boolean resume; @Inject public ReplayInlineCommentsStep(AccountUtil accountUtil, ReviewDb db, IdentifiedUser.GenericFactory genericUserFactory, ChangeControl.GenericFactory changeControlFactory, ChangeUpdate.Factory updateFactory, CommentsUtil commentsUtil, PatchListCache patchListCache, PatchSetUtil psUtil, @GerritServerId String serverId, @Assisted Change change, @Assisted ChangeInfo changeInfo, @Assisted GerritApi api, @Assisted boolean resume) { this.accountUtil = accountUtil; this.db = db; this.genericUserFactory = genericUserFactory; this.changeControlFactory = changeControlFactory; this.updateFactory = updateFactory; this.commentsUtil = commentsUtil; this.patchListCache = patchListCache; this.psUtil = psUtil; this.serverId = serverId; this.change = change; this.changeInfo = changeInfo; this.api = api; this.resume = resume; } }
void notifyFinished(PushOne op) { synchronized (stateLock) { inFlight.remove(op.getURI()); if (!op.wasCanceled()) { for (String ref : op.getRefs()) { if (!refHasPendingPush(op.getURI(), ref)) { replicationTasksStorage.delete(op.getProjectNameKey().get(), ref, op.getURI(), getRemoteConfigName()); } } } } }
public void delete(String project, String ref, URIish uri, String remote) { ReplicateRefUpdate r = new ReplicateRefUpdate(); r.project = project; r.ref = ref; r.uri = uri.toASCIIString(); r.remote = remote; String eventJson = GSON.toJson(r) + "\n"; String eventKey = sha1(eventJson).name(); try { logger.atFiner().log("DELETE %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); } }
public void delete(String project, String ref, URIish uri, String remote) { ReplicateRefUpdate r = new ReplicateRefUpdate(); r.project = project; r.ref = ref; r.uri = uri.toASCIIString(); r.remote = remote; String eventJson = GSON.toJson(r) + "\n"; String eventKey = sha1(eventJson).name(); try { logger.atFiner().log("DELETE %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); } }
if (!running) { stateLog.warn("Replication plugin did not finish startup before event", state); return; } Project.NameKey project = new Project.NameKey(projectName); for (Destination cfg : config.getDestinations(FilterType.ALL)) { if (cfg.wouldPushProject(project) && cfg.wouldPushRef(refName)) { for (URIish uri : cfg.getURIs(project, null)) { replicationTasksStorage.persist(projectName, refName, uri, cfg.getRemoteConfigName()); cfg.schedule(project, refName, uri, state); } } } state.markAllPushTasksScheduled();
private void firePendingTasks() { try { Set<String> tasksReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate t : replicationTasksStorage.list()) { String taskKey = String.format("%s:%s", t.project, t.ref); if (!tasksReplayed.contains(taskKey)) { repLog.info("Firing pending task {}", taskKey); onGitReferenceUpdated(t.project, t.ref); tasksReplayed.add(taskKey); } } } finally { replaying = false; } }
private void firePendingEvents() { try { Set<String> tasksReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate t : replicationTasksStorage.list()) { String taskKey = String.format("%s:%s", t.project, t.ref); if (!tasksReplayed.contains(taskKey)) { repLog.info("Firing pending task {}", taskKey); onGitReferenceUpdated(t.project, t.ref); tasksReplayed.add(taskKey); } } } finally { replaying = false; } }
public String persist(ReplicateRefUpdate replicateRefUpdate) { String json = GSON.toJson(replicateRefUpdate) + "\n"; String eventKey = sha1(json).name(); Path file = refUpdates().resolve(eventKey); if (Files.exists(file)) { return eventKey; } try { logger.atFine().log("CREATE %s:%s => %s", replicateRefUpdate.project, replicateRefUpdate.ref, replicateRefUpdate.uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().log("Couldn't persist event %s", json, e); } return eventKey; }
String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path file = refUpdates().resolve(eventKey); if (Files.exists(file)) { return eventKey; } try { logger.atFine().log("CREATE %s:%s => %s", project, ref, uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey;
import com.google.common.collect.HashBasedTable; import com.google.common.collect.Table; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import java.util.concurrent.CountDownLatch; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; import org.eclipse.jgit.transport.RemoteRefUpdate; import org.eclipse.jgit.transport.URIish; import org.slf4j.Logger; public class ReplicationState { private static final Logger repLog = ReplicationQueue.repLog; public interface Factory { ReplicationState create(PushResultProcessing processing); } private boolean allScheduled; private final EventsStorage eventsStorage; private final PushResultProcessing pushResultProcessing; private final Lock countingLock = new ReentrantLock(); private final CountDownLatch allPushTasksFinished = new CountDownLatch(1); private static class RefReplicationStatus { private final String project; private final String ref; private int nodesToReplicateCount; private int replicatedNodesCount; RefReplicationStatus(String project, String ref) { this.project = project; this.ref = ref; } public boolean allDone() { // implementation } } } private String getOutgoingConnectorKind() { TaskRepository repository = getOutgoingRepository(); if (repository != null) { return repository.getConnectorKind(); } else if (task != null) { return task.getConnectorKind(); } } private static final String DATA_UNIT_DIR = "/data/unit/refresh/roundedCorner/"; private static final String SEMANTIC_RESOURCE_FILENAME = "VP-2700.ecore"; private static final String SESSION_RESOURCE_FILENAME = "VP-2700.aird"; private static final String MODELER_RESOURCE_FILENAME = "VP-2700.odesign"; private static final String REPRESENTATION_INSTANCE_NAME = "new VP-2700_Diagram"; private static final String REPRESENTATION_NAME = "VP-2700_Diagram"; private List<SWTBotGefEditPart> dNodeContainerEditPartBots; private Resource modelerResource; private List<ContainerMapping> containerMappings; private void initializeContainerStyleDescriptions() { ResourceSet resourceSet = new ResourceSetImpl(); Viewpoint viewpoint = localSession.getOpenedSession().getSelectedViewpoints(false).iterator().next(); URI modelerResourceURI = viewpoint.e
import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.junit.Test; @UseLocalDisk @TestPlugin(name = "replication", sysModule = "com.googlesource.gerrit.plugins.replication.ReplicationModule") public class ReplicationIT extends LightweightPluginDaemonTest { private static final int TEST_REPLICATION_DELAY = 2; private static final Duration TEST_TIMEMOUT = Duration.ofSeconds(TEST_REPLICATION_DELAY * 10); @Inject private SitePaths sitePaths; private Path pluginDataDir; private Path gitPath; private Path storagePath; private FileBasedConfig config; @Override public void setUpTestPlugin() throws Exception { config = new FileBasedConfig(sitePaths.etc_dir.resolve("replication.config").toFile(), FS.DETECTED); config.save(); gitPath = sitePaths.site_path.resolve("git"); super.setUpTestPlugin(); pluginDataDir = plugin.getSysInjector().getInstance(Key.get(Path.class, PluginData.class)); storagePath = pluginDataDir.resolve("ref-updates"); } @Test public void testReplication() { // Test code goes here } }
import static java.util.stream.Collectors.toList; e.printStackTrace(); return null; } private void setReplicationDestination(String remoteName, String replicaSuffix, int replicationDelay) throws IOException { setReplicationDestination(remoteName, Arrays.asList(replicaSuffix), replicationDelay); } private void setReplicationDestination(String remoteName, List<String> replicaSuffixes, int replicationDelay) throws IOException { List<String> replicaUrls = replicaSuffixes.stream() .map(suffix -> gitPath.resolve("${name}" + suffix + ".git").toString()) .collect(toList()); config.setStringList("remote", remoteName, "url", replicaUrls); config.setInt("remote", remoteName, "replicationDelay", replicationDelay); config.save(); reloadConfig(); } private void waitUntil(Supplier<Boolean> waitCondition) throws InterruptedException { Stopwatch stopwatch = Stopwatch.createStarted(); while (!waitCondition.get() && stopwatch.elapsed().compareTo(TEST_TIMEMOUT) < 0) { TimeUnit.SECONDS.sleep(1); } } private void reloadConfig() { plugin.getSysInjector().getInstance(AutoReloadConfigDecorator.class).forceReload(); }
private static class RefReplicationStatus { private final String project; private final String ref; private int nodesToReplicateCount; private int replicatedNodesCount; RefReplicationStatus(String project, String ref) { this.project = project; this.ref = ref; } public boolean allDone() { return replicatedNodesCount == nodesToReplicateCount; } } private final Table<String, String, RefReplicationStatus> statusByProjectRef; private int totalPushTasksCount; private int finishedPushTasksCount; @AssistedInject ReplicationState(@Assisted PushResultProcessing processing) { pushResultProcessing = processing; statusByProjectRef = HashBasedTable.create(); } public void increasePushTaskCount(String project, String ref) { countingLock.lock(); try { getRefStatus(project, ref).nodesToReplicateCount++; totalPushTasksCount++; } finally { countingLock.unlock(); } } public boolean hasPushTask() { return totalPushTasksCount != 0; } public void notifyRefReplicated(String project, String ref, URIish uri, RefPushResult status, @Nullable Throwable error) { countingLock.lock(); try { RefReplicationStatus refStatus = getRefStatus(project, ref); refStatus.replicatedNodesCount++; finishedPushTasksCount++; if (refStatus.allDone()) { statusByProjectRef.remove(project, ref); } } finally { countingLock.unlock(); } pushResultProcessing.processPushResult(project, ref, uri, status, error); }
super(retryHelper); this.opFactory = opFactory; this.editUtil = editUtil; @Override protected Response<Object> applyImpl(BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException, IOException { if (!isChangeDeletable(rsrc)) { throw new MethodNotAllowedException("delete not permitted"); } rsrc.permissions().check(ChangePermission.DELETE); Optional<ChangeEdit> edit = editUtil.byChange(rsrc.getNotes(), rsrc.getUser()); try (BatchUpdate bu = updateFactory.create(rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) { Change.Id id = rsrc.getChange().getId(); bu.addOp(id, opFactory.create(id)); if (edit.isPresent()) { bu.addOp(id, new BatchUpdateOp() { @Override public boolean updateChange(ChangeContext ctx) throws Exception { editUtil.delete(edit.get()); return true; } }); } bu.execute(); } return Response.none(); } @Override
public Optional<Change> getUpdatedChange() { return Optional.ofNullable(updatedChange); }
Project.NameKey key = new Project.NameKey(projectName); try (Repository repository = repoManager.openRepository(key)) { RepositoryCache.close(repository); } cleanCache(key); FileUtils.deleteDirectory(gitDirectory); projectCache.remove(key); sendProjectDeletedEvent(projectName); return true; } catch (IOException e) { LOG.error("Cannot clean-up output Git directory " + gitDirectory); return false; } private void cleanCache(Project.NameKey key) throws IOException { Repository repository = repoManager.openRepository(key); repository.close(); RepositoryCache.close(repository); } private void sendProjectDeletedEvent(String projectName) { ProjectDeletedListener.Event event = new ProjectDeletedListener.Event() { @Override public String getProjectName() { return projectName; } @Override public NotifyHandling getNotify() { return NotifyHandling.NONE; } }; for (ProjectDeletedListener l : deletedListeners) { try { l.onProjectDeleted(event); } catch (RuntimeException e) { LOG.warn("Failure in ProjectDeletedListener", e); } } }
public boolean rollback() { File gitDirectory = destinationDirectory; if (!gitDirectory.exists()) { return false; } try { String projectName = organisation + "/" + repository; Project.NameKey key = new Project.NameKey(projectName); cleanJGitCache(key); FileUtils.deleteDirectory(gitDirectory); projectCache.remove(key); sendProjectDeletedEvent(projectName); return true; } catch (IOException e) { LOG.error("Cannot clean-up output Git directory " + gitDirectory); return false; } }
private static final String CAP_BOOLEAN_FALSE = "false"; private final IObjectPool<IARecordBuilder, ATypeTag> recordBuilderPool = new ListObjectPool<>(new RecordBuilderFactory()); private final IObjectPool<IAsterixListBuilder, ATypeTag> listBuilderPool = new ListObjectPool<>(new ListBuilderFactory()); private final IObjectPool<IMutableValueStorage, ATypeTag> abvsBuilderPool = new ListObjectPool<>(new AbvsBuilderFactory()); private ARecordType recordType; private SAXParserFactory capMessageSAXParserFactory; private SAXParser capMessageSAXParser; private ComplexBuilder complexBuilder; private ArrayList<ComplexBuilder> builderList; private ListElementHandler listElementHandler; private CAPMessageHandler capMessageHandler; private HashMap<String, Integer> listElementNames; private SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd'T'hh:mm:ss"); public CAPMessageParser(ARecordType recordType) throws HyracksDataException { this.recordType = recordType; bufferList = new ArrayList<>(); rbList = new ArrayList<>(); listElementNames = new HashMap<>(); fieldNameBuffer = getTempBuffer(); }
public void configureServlets() { for (String p : POLYGERRIT_INDEX_PATHS) { if (!options.enableGwtUi() || !p.equals("/")) { filter(p).through(XsrfCookieFilter.class); } } filter("/*").through(PolyGerritFilter.class); }
public ReplicateRefUpdate(String project, String ref, URIish uri, String remote) { this.project = project; this.ref = ref; this.uri = uri.toASCIIString(); this.remote = remote; }
public String persist(ReplicateRefUpdate r) { String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path path = refUpdates().resolve(eventKey); if (Files.exists(path)) { return eventKey; } try { logger.atFine().log("CREATE %s (%s)", path, r); Files.write(path, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey; }
public String persist(ReplicateRefUpdate r) { String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path path = refUpdates().resolve(eventKey); if (Files.exists(path)) { return eventKey; } try { logger.atFine().log("CREATE %s (%s)", path, r.toString()); Files.write(path, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey; }
public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); Path file = refUpdates().resolve(taskKey); try { logger.atFine().log("DELETE %s (%s)", file, r); Files.delete(file); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); } }
public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); Path path = refUpdates().resolve(taskKey); try { logger.atFine().log("DELETE %s (%s)", path, r); Files.delete(refUpdates().resolve(taskKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); } }
public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); Path path = refUpdates().resolve(taskKey); try { logger.atFine().log("DELETE %s (%s)", path, r); Files.delete(path); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); } }
package com.google.gerrit.pgm; import static com.google.common.base.MoreObjects.firstNonNull; import static java.nio.charset.StandardCharsets.UTF_8; import static java.util.stream.Collectors.joining; import static java.util.stream.Collectors.toList; import com.google.common.collect.ImmutableList; import com.google.gerrit.extensions.config.FactoryModule; import com.google.gerrit.lifecycle.LifecycleManager; import com.google.gerrit.pgm.util.BatchProgramModule; import com.google.gerrit.pgm.util.RuntimeShutdown; import com.google.gerrit.pgm.util.SiteProgram; import com.google.gerrit.reviewdb.client.Change; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.change.ChangeResource; import com.google.gerrit.server.git.GarbageCollection; import com.google.gerrit.server.index.DummyIndexModule; import com.google.gerrit.server.index.change.ChangeSchemaDefinitions; import com.google.gerrit.server.notedb.rebuild.GcAllUsers; import com.google.gerrit.server.notedb.rebuild.NoteDbMigrator; import com.google.gerrit.server.plugins.PluginGuiceEnvironment; import com.google.inject.Inject; import com.google.inject.Injector; import com.google.inject.Provider; import java.io.OutputStreamWriter; public class Main { public static void main(String[] args) throws Exception { Injector injector = createInjector(); try { SiteProgram program = injector.getInstance(SiteProgram.class); program.run(); } finally { LifecycleManager lifecycle = injector.getInstance(LifecycleManager.class); lifecycle.stop(); } } private static Injector createInjector() { return Guice.createInjector( new FactoryModule(), new BatchProgramModule(), new DummyIndexModule(ChangeSchemaDefinitions.INSTANCE), new PluginGuiceEnvironment(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(), new FactoryModule(),
} return fileConfig; }); } return ofInstance(config); } public static class Kafka { private final Map<EventTopic, String> eventTopics; private final String bootstrapServers; Kafka(Supplier<Config> config) { this.bootstrapServers = getString( config, KAFKA_SECTION, null, "bootstrapServers", DEFAULT_KAFKA_BOOTSTRAP_SERVERS); this.eventTopics = new HashMap<>(); for (EventTopic eventTopic : EventTopic.values()) { String topicConfigKey = eventTopic.topicAliasKey(); eventTopics.put( eventTopic, getString(config, KAFKA_SECTION, null, topicConfigKey, eventTopic.topic())); } } public String getTopicAlias(EventTopic topic) { return eventTopics.get(topic); } public String getBootstrapServers() { return bootstrapServers; } private static String getString( Supplier<Config> cfg, String section, String subsection, String name, String defaultValue) { String value = cfg.get().getString(section, subsection, name); if (!Strings.isNullOrEmpty(value)) { return value; } return defaultValue; }
reloadConfig(); waitForEmptyTasks(); Project.NameKey targetProject = createProject("projectreplica"); String newBranch = "refs/heads/mybranch"; String master = "refs/heads/master"; BranchInput input = new BranchInput(); input.revision = master; gApi.projects().name(project.get()).branch(newBranch).create(input); assertThat(listReplicationTasks("refs/heads/(mybranch|master)")).hasSize(2); try (Repository repo = repoManager.openRepository(targetProject); Repository sourceRepo = repoManager.openRepository(project)) { waitUntil(() -> checkedGetRef(repo, newBranch) != null); Ref masterRef = getRef(sourceRepo, master); Ref targetBranchRef = getRef(repo, newBranch); assertThat(targetBranchRef).isNotNull(); assertThat(targetBranchRef.getObjectId()).isEqualTo(masterRef.getObjectId()); } } @Test public void shouldReplicateNewBranchToTwoRemotes() throws Exception { Project.NameKey targetProject1 = createProject("projectreplica1"); Project.NameKey targetProject2 = createProject("projectreplica2"); }
Change updatedChange = op.merge(change, submitter, true, input, false); if (updatedChange.isMerged()) { return change; } String errorMessage = String.format("change %s unexpectedly had status %s after submit attempt", updatedChange.getId(), updatedChange.getStatus()); logger.atWarning().log(errorMessage); throw new RestApiException(errorMessage);
config.save(); super.setUpTestPlugin(); pluginDataDir = plugin.getSysInjector().getInstance(Key.get(Path.class, PluginData.class)); storagePath = pluginDataDir.resolve("ref-updates"); @Test public void shouldReplicateNewProject() throws Exception { setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Project.NameKey sourceProject = createProject("foo"); assertThat(listReplicationTasks("refs/meta/config")).hasSize(1); waitUntil(() -> gitPath.resolve(sourceProject + "replica.git").toFile().isDirectory()); ProjectInfo replicaProject = gApi.projects().name(sourceProject + "replica").get(); assertThat(replicaProject).isNotNull(); } @Test public void shouldReplicateNewChangeRef() throws Exception { Project.NameKey targetProject = createProject("projectreplica"); setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Result pushResult = createChange(); RevCommit sourceCommit = pushResult.getCommit(); }
@Test public void shouldReplicateNewProject() throws Exception { setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Project.NameKey sourceProject = createProject("foo"); assertThat(listReplicationTasks("refs/meta/config")).hasSize(1); waitUntil(() -> projectExists(new Project.NameKey(sourceProject + "replica.git"))); ProjectInfo replicaProject = gApi.projects().name(sourceProject + "replica").get(); assertThat(replicaProject).isNotNull(); } @Test public void shouldReplicateNewChangeRef() throws Exception { Project.NameKey targetProject = createProject("projectreplica"); setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Result pushResult = createChange(); RevCommit sourceCommit = pushResult.getCommit(); String sourceRef = pushResult.getPatchSet().getRefName(); assertThat(listReplicationTasks("refs/changes/\\d*/\\d*/\\d*")).hasSize(1); try (Repository repo = repoManager.openRepository(targetProject)) { // ... } }
private static final String CONFIG_FILE_PATH = "/data/local/tmp/"; private static final String CLOUD_PROPERTY_FILE = "cloud.properties"; private static boolean s_mIsCbInvoked = CALLBACK_NOT_INVOKED; private enum CloudAuth { SIGNUP, SIGNIN, SIGNOUT }; private enum LogLevel { INFO, ERROR, DEBUG }; private static Properties s_mProps; private static String s_mFilePath; private static String s_mFileName; private static File s_mFile; public static CloudAuth s_mMethodName; public static String s_mCloudUid; public static String s_mCloudAccessToken; public static String s_mAuthCode; public static String s_mErrorMessage; public static void init(String fileDir) { s_mProps = new Properties(); ReadConfigPropFile.readConfigFile(CONFIG_FILE_PATH); s_mFile = new File(fileDir + CLOUD_PROPERTY_FILE); if (!s_mFile.exists()) { getAuthCode(); } } private static void getAuthCode() { Log.d(TAG, "getAuthCode IN"); GetAuthCode getContent = new GetAuthCode(); try { // code implementation } catch (Exception e) { // exception handling } }
public class OcAccountManagerHelper implements OcAccountManager.OnPostListener, IConfiguration { private static final String TAG = "OcAccountManagerHelper"; private static final String CONFIG_FILE_PATH = "/data/local/tmp/"; private static final String CLOUD_PROPERTY_FILE = "cloud.properties"; private static boolean s_mIsCbInvoked = CALLBACK_NOT_INVOKED; private enum CloudAuth { SIGNUP, SIGNIN, SIGNOUT }; private enum LogLevel { INFO, ERROR, DEBUG }; private static Properties s_mProps; private static String s_mFilePath; private static String s_mFileName; private static File s_mFile; public static CloudAuth s_mMethodName; public static String s_mCloudUid; public static String s_mCloudAccesstoken; public static String s_mAuthCode; public static String s_mErrorMessage; public static String s_CloudUid; public static String s_CloudAccesstoken; public static String authCode; public static String mErrorMessage; public static void init(String fileDir) { s_mProps = new Properties(); ReadConfigPropFile.readConfigFile(CONFIG_FILE_PATH); s_mFile = new File(fileDir + CLOUD_PROPERTY_FILE); if (!s_mFile.exists()) { getAuthCode(); } } private static void getAuthCode() { Log.d(TAG, "getAuthCode IN"); GetAuthCode getContent = new GetAuthCode(); try { OcAccountManagerHelper.authCode = getContent.execute().get(); // Rest of the code } catch (Exception e) { Log.e(TAG, "getAuthCode: Exception occurred: " + e.getMessage()); } } }
private static final String START_PRE_CONFIG_SERVER_01 = "./iotivity_pm_server " + PRECONFIG_SERVER_UNOWNED_CBOR_01 + " 3"; private static final String START_RE_SERVER = "./iotivity_re_server"; private static final String PROVISION_DB_FILE = "./Pdm.db"; private static final String DEVICE_PROP_CBOR_FILE = "./device_properties.dat"; private TestBroadCast mTestBroadCast; protected RIHelperCommon(IoTivityTc iotivityTcObj) { s_helperContext = iotivityTcObj.getInstrumentation().getTargetContext(); s_filePath = s_helperContext.getFilesDir().getPath(); s_sqLPath = s_helperContext.getFilesDir().getAbsolutePath().replace(FILES, DATABASES) + File.separator; mTestBroadCast = new TestBroadCast(s_helperContext); } public boolean configClientServerPlatform() { PlatformConfig cfg = new PlatformConfig(s_helperContext, ServiceType.IN_PROC, ModeType.CLIENT_SERVER, "0.0.0.0", 0, QualityOfService.HIGH); OcPlatform.Configure(cfg); }
package org.iotivity.testcase; import android.util.Log; public class IoTivityLog { public static void v(String tag, String format) { Log.v(tag, format); } public static void d(String tag, String format) { Log.d(tag, format); } public static void i(String tag, String format) { Log.i(tag, format); } public static void w(String tag, String format) { Log.w(tag, format); } public static void e(String tag, String format) { Log.e(tag, format); } }
package org.iotivity.testcase; import java.util.logging.Logger; public class IoTivityLog { public static void v(String tag, String format) { System.out.println(tag + " : " + format); } public static void d(String tag, String format) { System.out.println(tag + " : " + format); } public static void i(String tag, String format) { System.out.println(tag + " : " + format); } public static void w(String tag, String format) { System.out.println(tag + " : " + format); } public static void e(String tag, String format) { System.out.println(tag + " : " + format); } }
public void testConfigureServerInProc_SRC_P() { try { PlatformConfig cfg = new PlatformConfig(ServiceType.IN_PROC, ModeType.SERVER, "0.0.0.0", 0, QualityOfService.HIGH); OcPlatform.Configure(cfg); } catch (Exception e) { e.printStackTrace(); fail("Exception occurred"); } }
import org.iotivity.base.QualityOfService; import org.iotivity.base.RequestHandlerFlag; import org.iotivity.base.RequestType; import org.iotivity.base.ResourceProperty; import org.iotivity.base.ServiceType; import org.iotivity.base.OcRepresentation; import org.iotivity.base.OcResource; import org.iotivity.base.OcResource.OnObserveListener; import org.iotivity.base.OcResourceHandle; import org.iotivity.testcase.IoTivityLog; import org.iotivity.testcase.IoTivityTc; import org.iotivity.test.ri.common.RIHelperCommon; public class RIHelper extends RIHelperCommon implements IRIConstants { private static RIHelper s_riHelperInstance = null; private final String LOG_TAG = this.getClass().getSimpleName(); private OcResourceHandle m_resourceHandle = null; public EnumSet<ResourceProperty> m_resourceProperty; public static final String TEMPERATURE_RESOURCE_QUERY = OcPlatform.WELL_KNOWN_QUERY + "?rt=" + RESOURCE_TYPE_TEMPERATURE; private OcRepresentation m_representation = null; public int m_temp; public int m_hour; public static boolean s_isServerOk; public static String s_errorMsg; }
Map<String, String> queryParamsMap, OnPostListener onPostListener, QualityOfService qualityOfService) @test_data 1. resourceUri "/test/ri/android/temperature" 2. resourceTypeName "oic.r.temperature" 3. resourceInterface DEFAULT_INTERFACE 4. entityHandler entity handler 5. resourcePropertySet indicates property of the resource 6. representation representation to set 7. queryParamsMap map with query paramter and value 8. onPostListener event handler 9. qualityOfService High @pre_condition Configure platform for client server mode @procedure 1. Perform registerResource() API 2. Perform findResource() API with resource type in query 3. Check if callback is called 4. Check if temperature resource is found 5. Perform post() API(with qos) on the found temperature resource 6. Check if server can get the post request and send response correctly
public void onReceive(Context context, Intent intent) { Log.d(TAG, "BroadcastReceiver Invoked"); Log.d(TAG, "Recieved Braodcasted MSG : " + intent.getStringExtra("key")); if (mTcpClient != null) { mTcpClient.sendMessage(intent.getStringExtra("key")); } else { Log.e(TAG, "TCP Client is not initialized"); } }
(byte) 0x66, (byte) 0x11, (byte) 0xa5, (byte) 0x84, (byte) 0x99, (byte) 0x8d, (byte) 0x0d, (byte) 0xbd, (byte) 0xb1, (byte) 0x54, (byte) 0xbb, (byte) 0xc5, (byte) 0x4f, (byte) 0xed, (byte) 0x86, (byte) 0x9a, (byte) 0x66, (byte) 0x11 }; PMConstants.mErrorMessage = PMConstants.EMPTY_STRING; mPMHelper.clearAll(); mPMHelper.stopServers(); mPMHelper.startSecuredServer(mPMHelper.START_JUSTWORKS_SERVER_01); mPMHelper.startSecuredServer(mPMHelper.START_JUSTWORKS_SERVER_02); PMHelper.delay(5); mPMHelper.copyCborFromAsset(PMConstants.OIC_CLIENT_CBOR_DB_FILE); mPMHelper.configClientServerPlatform(PMConstants.OIC_CLIENT_CBOR_DB_FILE); mPMHelper.initOICStack(PMHelper.s_sqLPath, PMConstants.OIC_SQL_DB_FILE); } protected void tearDown() throws Exception { mPMHelper.stopServers(); mPMHelper.clearAll(); super.tearDown(); }
public static final String OIC_JWSERVER_CBOR_DB_FILE_2 = "oic_svr_db_server.dat"; public static final String OIC_DP_CLIENT_CBOR_DB_FILE = "oic_svr_db_client_directpairing.dat"; public static final String OIC_CLOUD_CLIENT = "cloud.dat"; public static final String OIC_SQL_DB_FILE = "Pdm.db"; public static final String OIC_MOT_SQL_DB_FILE = "MOT_Pdm.db"; public static final String SERVER_SQL_DB_FILE = "ServerPdm.db"; public static final String CERT_SERIAL_ONE = "1"; public static final String DEFAULT_ROWNER_ID = "61646d69-6e44-6576-6963-655555494430"; public static final String DEFAULT_RESOURCES = "*"; public static final String HREF_RESOURCES_1A = "/a/device1a"; public static final String HREF_RESOURCES_1B = "/a/device1b"; public static final String HREF_RESOURCES_2A = "/a/device2a"; public static final String HREF_RESOURCES_2B = "/a/device2b";
try { m_resource.put(m_rep, qpMap, onPut); } catch (Exception e) { e.printStackTrace(); fail("Exception occurred"); }
protected void initModel(String projectName, String modelName, Bundle bundle) throws CoreException, IOException { project = ProjectUtils.createProject(projectName); diModelFile = PapyrusProjectUtils.copyPapyrusModel(project, bundle, getSourcePath(), modelName); } protected String getSourcePath() { return "models/"; } protected Bundle getBundle() { return Activator.getDefault().getBundle(); } public ICellEditor getICellEditor(Table table, Object axisElement, ITableAxisElementProvider elementProvider) { super.getICellEditor(table, axisElement, elementProvider); AbstractPapyrusStyledTextCellEditor editor = new UMLReferenceTextWithCompletionCellEditor(table, axisElement, elementProvider); AbstractOpenDialogCellEditorButtonAction openDialog = getCellEditorWithDialogToOpen(axisElement, elementProvider); editor.setOpenDialogCellEditorButtonAction(openDialog); openDialog.setText("..."); //$NON-NLS-1$ openDialog.setTooltipText(Messages.UMLReferenceCellEditorConfiguration_OpenDialogToChooseTheValue); return editor; } public void apply(String value) { if (!label.isDisposed() && !(label.getText() != null && label.getText().equals(value))) { label.setText(Objects.firstNonNull(value, "")); //$NON-NLS-1$ EEFWidgetStyle style = getWidgetStyle(); List<EEFConditionalStyle> conditionalStyles = getWidgetConditionalStyles(); if (conditionalStyles != null && !conditionalStyles.isEmpty()) { style = getConditionalStyle(conditionalStyles); } if (style != null) { setLabelFontStyle(style); } } } public void testConfigureServerNon_SRC_P() { try { PlatformConfig cfg = new PlatformConfig(ServiceType.IN_PROC, ModeType.SERVER, "0.0.0.0", 0, QualityOfService.LOW); OcPlatform.Configure(cfg); } catch (Exception e) { e.printStackTrace(); fail("Exception occured"); } }
String DEVICE_TYPE_AC = "AirCondition"; String RESOURCE_URI_TEMPERATURE = "/test/ri/android/temperature"; String RESOURCE_TYPE_TEMPERATURE = "oic.r.temperature"; String RESOURCE_URI_LIGHT = "/a/light"; String RESOURCE_TYPE_LIGHT = "core.light"; String RESOURCE_URI_FAN = "/a/fan"; String RESOURCE_TYPE_FAN = "core.fan"; String HOST = "coap://192.168.1.2:5000"; int INT_ZERO = 0; int INT_ONE = 1; int INT_TWO = 2; int INT_MINUS_ONE = -1; int CALLBACK_WAIT_DEFAULT = 5; int CALLBACK_WAIT_MAX = 10; int CALLBACK_WAIT_MIN = 1; int SUCCESS_RESPONSE = 0; int COAP_RESPONSE_CODE_SUCCESS = 205; int COAP_RESPONSE_CODE_CREATED = 201; int COAP_RESPONSE_CODE_DELETED = 202;
public static RIHelper getInstance(IoTivityTc iotivityTcObj) { new OcRepresentation(); Lock mutex = new ReentrantLock(); if (s_mRiHelperInstance == null) { mutex.lock(); if (s_mRiHelperInstance == null) { IoTivityLog.i("RIHelper", "Inside Helper"); s_mRiHelperInstance = new RIHelper(iotivityTcObj); } mutex.unlock(); } return s_mRiHelperInstance; }
* //****************************************************************** * // Copyright 2018 Intel Corporation All Rights Reserved. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import org.iotivity.base.OcException;
//***************************************************************************** // Copyright 2018 Intel Corporation All Rights Reserved. // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. //***************************************************************************** package org.iotivity.base.examples; import org.iotivity.base.OcException;
Fixed Code: * //****************************************************************** * // Copyright 2018 Intel Corporation All Rights Reserved. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import android.graphics.Bitmap;
Fixed Code: ```java //****************************************************************** // Copyright 2016-2018 Intel Corporation All Rights Reserved. // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. // //****************************************************************** package org.iotivity.base.examples; import org.iotivity.base.OcException; ``` Note: The fixed code assumes that the copyright year should be updated to the current year (2018).
public class MediaControl extends Service { public static final String OIC_TYPE_MEDIA_CONTROL = "oic.r.media.control"; public static final String OCF_OIC_URI_PREFIX_MEDIA_CONTROL = "/ocf/media-control/"; public static final String UPNP_OIC_URI_PREFIX_MEDIA_CONTROL = "/upnp/media-control/"; public static final String STATE_KEY = "playState"; public static final boolean DEFAULT_STATE = false; public static final String SPEED_KEY = "mediaSpeed"; public static final double DEFAULT_SPEED = 1.0; public static final String LOCATION_KEY = "mediaLocation"; public static final String DEFAULT_LOCATION = "0"; public static final String LAST_ACTION_KEY = "lastAction"; public static final String DEFAULT_LAST_ACTION = "stop"; public static final String ACTIONS_KEY = "actions"; private boolean mPlayState; }
Refactored Code: ***************************************************************************** * Copyright (c) 2016-2018 Intel Corporation. All Rights Reserved. * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package org.iotivity.base.examples; import android.app.Activity;
package org.iotivity.base.examples; import org.iotivity.base.OcException; import org.iotivity.base.OcPlatform; import org.iotivity.base.PayloadType; public class Light { static public final String RESOURCE_TYPE = "oic.d.light"; static public final String DEVICE_RESOURCE_TYPE = "oic.wk.d"; private Switch switchRes; private Brightness brightnessRes; private String deviceName; public Light(String name, String uuid, boolean powerOn, int brightness, LightControlPanel ui) { deviceName = name; switchRes = new Switch(uuid); switchRes.setValue(powerOn); switchRes.addObserver(ui); ui.addObserver(switchRes); OcfLightServer.msg("Created switch resource: " + switchRes); brightnessRes = new Brightness(uuid); brightnessRes.setBrightness(brightness); brightnessRes.addObserver(ui); ui.addObserver(brightnessRes); } }
public void updateBrightness(boolean powerOn, int brightness) { setBrightness(brightness); notifyObservers(null); }
public void testUri() { OCResource r = new OCResource(); assertNotNull(r); r.setUri("/foo/bar"); assertEquals("/foo/bar", r.getUri()); } @Test public void testTypes() { OCResource r = new OCResource(); assertNotNull(r); //TODO properly encode/decode the OCResource oc_string_array_t types. //r.setTypes(value); // failure purposely done till the setTypes/getProperties methods are updated with non SWIG type values. fail("Not yet implemented"); } @Test public void testInterfaces() { OCResource r = new OCResource(); assertNotNull(r); r.setInterfaces(OCInterfaceMask.RW); assertEquals(OCInterfaceMask.RW, r.getInterfaces()); } @Test public void testDefaultInterface() { OCResource r = new OCResource(); assertNotNull(r); r.setDefaultInterface(OCInterfaceMask.BASELINE); assertEquals(OCInterfaceMask.BASELINE, r.getDefaultInterface()); } @Test public void testProperties(){ OCResource r = new OCResource(); assertNotNull(r); }
} else if (response.getCode() == OCStatus.OC_STATUS_CREATED) { System.out.println("\tPUT
private void eventLoop() { while (!quit) { long nextEvent = OCMain.mainPoll(); lock.lock(); try { if (nextEvent == 0) { cv.await(); } else { long timeToWait = nextEvent - OCClock.clockTime(); cv.awaitNanos(timeToWait); } } catch (InterruptedException e) { Log.d(TAG, e.getMessage()); } finally { lock.unlock(); } } }
public int initialize() { Log.d(TAG, "inside MyInitHandler.initialize()"); int ret = OCMain.initPlatform("Android"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "Kishen's Android Phone", "ocf.1.0.0", "ocf.res.1.0.0"); return ret; }
public void testValueObject() { OCMain.repNewBuffer(1024); CborEncoder root = OCMain.repBeginRootObject(); assertEquals(0, OCMain.repGetCborErrno()); CborEncoder myObject = OCMain.repOpenObject(root, "my_object"); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetInt(myObject, "a", 1); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetBoolean(myObject, "b", false); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetTextString(myObject, "c", "three"); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repCloseObject(root, myObject); OCMain.repEndRootObject(); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetPool(new OCMemoryBuffer()); OCRepresentation rep = OCMain.repGetOCRepresentaionFromRootObject(); assertNotNull(rep); OCValue v = new OCValue(); assertNotNull(v); }
public int initialize() { System.out.println("inside ObtInitHandler.initialize()"); int ret = OCMain.initPlatform("OCF"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "OBT", "ocf.1.0.0", "ocf.res.1.0.0"); return ret; }
System.out.println("################################################"); System.out.println("\nSelect option: "); } private static void discoverUnownedDevices() { System.out.println("Discovering un-owned devices"); appSyncLock.lock(); if (OCObt.discoverUnownedDevices(unownedDeviceHandler) < 0) { System.err.println("ERROR discovering un-owned Devices."); } appSyncLock.unlock(); } private static void discoverOwnedDevices() { appSyncLock.lock(); if (OCObt.discoverOwnedDevices(ownedDeviceHandler) > 0) { System.err.println("ERROR discovering owned Devices."); } appSyncLock.unlock(); } public static void main(String[] args) { quit = false; mainThread = Thread.currentThread(); Runtime.getRuntime().addShutdownHook(shutdownHook); String osName = System.getProperty("os.name"); boolean isLinux = (osName != null) && osName.toLowerCase().contains("linux"); System.out.println("OS Name = " + osName + ", isLinux = " + isLinux); String creds_path = "./onboarding_tool_creds/";
break; case 3: OCObt.aceResourceSetWc(res, OCAceWildcard.OC_ACE_WC_ALL_NON_DISCOVERABLE); break; default: break; } } System.out.print("Enter number of resource types [0-None]: "); c = scanner.nextInt(); if (c > 0 && c <= MAX_NUM_RT) { OCObt.aceResoruceSetNumRt(res, c); int j = 0; while (j < c) { System.out.print("Enter resource type : " + (j + 1)); String rt = scanner.next(); if (rt.length() > 127) { rt = rt.substring(0, 127); } OCObt.aceResoruceBindRt(res, rt); j++; } } System.out.print("Enter number of interfaces [0-None] : "); c = scanner.nextInt(); if (c > 0 && c <= 7) { int j = 0; while (j < c) { int k; System.out.println("\n[1]: oic.if.baseline");
public int initialize() { System.out.println("inside ObtInitHandler.initialize()"); int ret = OCMain.initPlatform("OCF"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "OBT", "ocf.1.0.0", "ocf.res.1.0.0"); return ret; }
public void handler(OCUuid uuid, int status, Object userData) { ObtMain.ownedDevices.remove(uuid); if (status >= 0) { System.out.println("\nSuccessfully performed hard RESET to device " + OCUuidUtil.uuidToString(uuid)); } else { System.out.println("\nERROR performing hard RESET to device " + OCUuidUtil.uuidToString(uuid)); } }
private void eventLoop() { while (!quit) { long nextEvent = OCMain.mainPoll(); lock.lock(); try { if (nextEvent == 0) { cv.await(); } else { long now = OCClock.clockTime(); long timeToWait = (NANOS_PER_SECOND / OCClock.clockSeconds()) * (nextEvent - now); cv.awaitNanos(timeToWait); } } catch (InterruptedException e) { Log.d(TAG, e.getMessage()); } finally { lock.unlock(); } } }
public void handler(OCRequest request, int interfaces) { Log.d(TAG, "inside Put Light Request Handler"); new PostLightRequestHandler(activity).handler(request, interfaces, userData); }
private Light light; OCMain.resourceSetRequestHandler(resource, OCMethod.OC_POST, new PostLightRequestHandler(activity, light)); OCMain.addResource(resource); @Override public void requestEntry() { Log.d(TAG, "inside MyInitHandler.requestEntry()"); } @Override public void signalEventLoop() { Log.d(TAG, "inside MyInitHandler.signalEventLoop()"); activity.lock.lock(); try { activity.cv.signalAll(); } finally { activity.lock.unlock(); } }
String creds_path = "./simpleserver_creds/"; java.io.File directory = new java.io.File(creds_path); if (!directory.exists()) { directory.mkdir(); } System.out.println("Storage Config PATH : " + directory.getPath()); if (0 != OCStorage.storageConfig(directory.getPath())) { System.err.println("Failed to setup Storage Config."); } OcUtils.setFactoryPresetsHandler(new FactoryPresetsHandler()); MyInitHandler handler = new MyInitHandler(platform); platform.systemInit(handler); try { Thread.sleep(Long.MAX_VALUE); } catch (InterruptedException e) { System.err.println(e); } System.exit(0);
if (!directory.exists()) { directory.mkdir(); } System.out.println("Storage Config PATH : " + directory.getPath()); if (0 != OCStorage.storageConfig(directory.getPath())) { System.err.println("Failed to setup Storage Config."); } OcUtils.setFactoryPresetsHandler(new FactoryPresetsHandler()); MyInitHandler handler = new MyInitHandler(platform); platform.systemInit(handler); try { Thread.sleep(Long.MAX_VALUE); } catch (InterruptedException e) { System.err.println(e); } System.exit(0);
public void getOwnedDeviceNameResponseHandler(OCClientResponse response) { OCRepresentation rep = response.getPayload(); String deviceName = null; String deviceId = null; while (rep != null) { switch (rep.getType()) { case OC_REP_STRING: if ("n".equals(rep.getName())) { deviceName = rep.getValue().getString(); } if ("di".equals(rep.getName())) { deviceId = rep.getValue().getString(); } break; default: break; } rep = rep.getNext(); } if (deviceId != null) { ObtMain.ownedDevices.add(new OCFDeviceInfo(OCUuidUtil.stringToUuid(deviceId), deviceName)); } }
public void handler(OCClientResponse response) { System.out.println("Get Unowned Device Name Handler:"); OCRepresentation rep = response.getPayload(); String n = null; String di = null; while (rep != null) { switch (rep.getType()) { case OC_REP_STRING: if ("n".equals(rep.getName())) { n = rep.getValue().getString(); } if ("di".equals(rep.getName())) { di = rep.getValue().getString(); } break; default: break; } rep = rep.getNext(); } if (di != null) { ObtMain.unownedDevices.add(new OCFDeviceInfo(OCUuidUtil.stringToUuid(di), n)); } }
public class IntraLineDiffKey implements Serializable { public static final long serialVersionUID = 5L; private transient Whitespace whitespace; private transient ObjectId aId; private transient ObjectId bId; public IntraLineDiffKey(ObjectId aId, ObjectId bId, Whitespace whitespace) { this.aId = aId; this.bId = bId; this.whitespace = whitespace; } public ObjectId getBlobA() { return aId; } public ObjectId getBlobB() { return bId; } public Whitespace getWhitespace() { return whitespace; } @Override public int hashCode() { int h = 0; h = h * 31 + aId.hashCode(); h = h * 31 + bId.hashCode(); h = h * 31 + whitespace.hashCode(); return h; } @Override public boolean equals(final Object o) { if (o instanceof IntraLineDiffKey) { final IntraLineDiffKey k = (IntraLineDiffKey) o; return aId.equals(k.aId) && bId.equals(k.bId) && whitespace.equals(k.whitespace); } return false; } } // ... public class MyClass { // ... public boolean isRebaseTransparent() { return isRebaseTransparent; } // ... public boolean getBoolean() throws OcCborException { Boolean returnValue = getValue().getBool(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean"); } // ... }
return long not Long see comment on getBoolean bellow. public Long getLong() throws OcCborException { Long returnValue = getValue().getInteger(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get long"); }
public Boolean getBoolean() throws OcCborException { Boolean returnValue = getValue().getBool(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean"); } public Long getLong() throws OcCborException { Long returnValue = getValue().getInteger(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get long"); } public double getDouble() throws OcCborException { double returnValue = getValue().getDouble(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get double"); } public String getString() throws OcCborException { String returnValue = getValue().getString(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get string"); } public OCArray getArray() throws OcCborException { OCArray returnValue = getValue().getArray(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get array"); }
OCRepresentation nativeRep = getValue().getObject(); if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object"); public OcRepresentation getObjectArray() throws OcCborException { OCRepresentation nativeRep = getValue().getObjectArray(); if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object array"); } public OCValue getValue() throws OcCborException { OCValue returnValue = nativeRepresentation.getValue(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get value"); } public Boolean getBoolean(String key) throws OcCborException { Boolean returnValue = OCRep.getBoolean(nativeRepresentation, key); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); }
if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object array"); } public OCValue getValue() throws OcCborException { OCRep.clearCborErrno(); OCValue returnValue = nativeRepresentation.getValue(); if (returnValue != null && OCRep.getCborErrno() == 0) { return returnValue; } throw new OcCborException("Failed to get value"); } public boolean getBoolean(String key) throws OcCborException { OCRep.clearCborErrno(); boolean returnValue = OCRep.getBoolean(nativeRepresentation, key); if (returnValue && OCRep.getCborErrno() == 0) { return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); } public Long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); Long returnValue = OCRep.getLong(nativeRepresentation, key); if (returnValue != null && OCRep.getCborErrno() == 0) { return returnValue; } throw new OcCborException("Failed to get long for key " + key); }
return long not Long see comments on getBoolean Fixed Code: return long not Long see comments on getBoolean public long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); long returnValue = OCRep.getLong(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get long for key " + key); }
return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); } public Long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); Long returnValue = OCRep.getLong(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get long for key " + key); } public Double getDouble(String key) throws OcCborException { OCRep.clearCborErrno(); Double returnValue = OCRep.getDouble(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get double for key " + key); } public String getString(String key) throws OcCborException { OCRep.clearCborErrno(); String returnValue = OCRep.getString(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; }
static public OcRepresentation createOcRepresentaionFromRoot() throws OcCborException { OCRep.clearCborErrno(); OCRepresentation nativeRep = OCRep.getOCRepresentaionFromRootObject(); if (null != nativeRep && OCRep.getCborErrno() == 0) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to create OcRepresentation from root object"); }
case R.id.radio_recovery: mRebootMode = 2; Settings.System.putInt(mContext.getContentResolver(), Settings.System.STATUS_BAR_LAST_NOTIFICATION_STYLE, mRebootMode); mTileMode = 2; refreshState(); break; case R.id.radio_bootloader: mRebootMode = 3; Settings.System.putInt(mContext.getContentResolver(), Settings.System.STATUS_BAR_LAST_NOTIFICATION_STYLE, mRebootMode); mTileMode = 2; refreshState(); break; default: refreshState(); break;
public void update() { int showNavBar = Settings.System.getIntForUser(mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_SHOW, -1, mCurrentUserId); int qsQuickPulldownValue = Settings.System.getInt(mContext.getContentResolver(), Settings.System.STATUS_BAR_QUICK_QS_PULLDOWN, 0); if (showNavBar != -1) { boolean showNavBarBool = showNavBar == 1; if (showNavBarBool != mShowNavBar) { updateNavigationBar(); } } mRecentsStyle = Settings.System.getIntForUser(mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_RECENTS, 0, mCurrentUserId); mOmniSwitchRecents = mRecentsStyle == 1; mLongPressOnAppSwitchBehavior = Settings.System.getIntForUser(mContext.getContentResolver(), Settings.System.BUTTON_LONG_PRESS_RECENTS, 0, mCurrentUserId); if (mStatusBarWindow != null) { mStatusBarWindow.updateSettings(); } if (mNavigationBar != null) { mNavigationBar.setRecentsOptions(mRecentsStyle, mLongPressOnAppSwitchBehavior); } if (mStatusBarWindowManager != null) { // rest of the code } }
public void update() { int showNavBar = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_SHOW, -1, mCurrentUserId ); int qsQuickPulldownValue = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.STATUS_BAR_QUICK_QS_PULLDOWN, 0, UserHandle.USER_CURRENT ); if (showNavBar != -1) { boolean showNavBarBool = showNavBar == 1; if (showNavBarBool != mShowNavBar) { updateNavigationBar(); } } mRecentsStyle = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_RECENTS, 0, mCurrentUserId ); mOmniSwitchRecents = mRecentsStyle == 1; mLongPressOnAppSwitchBehavior = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.BUTTON_LONG_PRESS_RECENTS, 0, mCurrentUserId ); if (mStatusBarWindow != null) { mStatusBarWindow.updateSettings(); } if (mNavigationBar != null) { mNavigationBar.setRecentsOptions(mRecentsStyle, mLongPressOnAppSwitchBehavior); } }
public void onBindViewHolder(PreferenceViewHolder holder) { super.onBindViewHolder(holder); LinearLayout linearLayout = (LinearLayout) holder.findViewById(R.id.selected_apps); if (linearLayout.getChildCount() > 0) { linearLayout.removeAllViews(); } for (String value : mValues) { try { ImageView v = new ImageView(mContext); ComponentName componentName = ComponentName.unflattenFromString(value); Drawable icon = mPm.getActivityIcon(componentName); v.setImageDrawable(icon); v.setPadding(0, 0, 15, 0); v.setScaleType(ImageView.ScaleType.CENTER_CROP); linearLayout.addView(v); } catch (PackageManager.NameNotFoundException e) { Log.e(TAG, "Set app icon", e); } } }
public void onKeyguardShowingChanged() { mShowIndicator = Settings.Secure.getIntForUser(mContext.getContentResolver(), Settings.Secure.LOCK_HIDE_INDICATOR_DISPLAY, 0, UserHandle.USER_CURRENT) == 0; updateLeftAffordance(); updateRightAffordance(); inflateCameraPreview(); mIndicationController.setVisibleOverwrite(mShowIndicator); }
private void updateSettings() { int mQsBackGroundAlpha = Settings.System.getIntForUser(getContext().getContentResolver(), Settings.System.QS_PANEL_BG_ALPHA, 255, UserHandle.USER_CURRENT); mQsBackGround.setAlpha(mQsBackGroundAlpha); setBackground(mQsBackGround); }
mMusicActive.setOnPreferenceChangeListener(this); mAutorun = (SwitchPreference) findPreference(EVENT_AUTORUN_SINGLE); mAutorun.setChecked(getPrefs().getBoolean(EventServiceSettings.EVENT_AUTORUN_SINGLE, true)); mAutorun.setOnPreferenceChangeListener(this); mChooserTimeout = (SeekBarPreference) findPreference(APP_CHOOSER_TIMEOUT); mChooserTimeout.setValue(getPrefs().getInt(EventServiceSettings.APP_CHOOSER_TIMEOUT, 15)); mChooserTimeout.setOnPreferenceChangeListener(this); boolean locationDisabled = Settings.Secure.getInt(getActivity().getContentResolver(), Settings.Secure.LOCATION_MODE, -1) == 0; mDisableWifi = (SeekBarPreference) findPreference(DISABLE_WIFI_THRESHOLD); mDisableWifi.setValue(getPrefs().getInt(EventServiceSettings.DISABLE_WIFI_THRESHOLD, 0)); mDisableWifi.setOnPreferenceChangeListener(this); mDisableWifi.setEnabled(!locationDisabled); homeWifi = findPreference(HOME_WIFI_PREFERENCE_SCREEN); homeWifi.setEnabled(!locationDisabled); workWifi = findPreference(WORK_WIFI_PREFERENCE_SCREEN); workWifi.setEnabled(!locationDisabled); if (locationDisabled) { mDisableWifi.setSummary(R.string.wifi_location_disabled); homeWifi.setSummary(R.string.wifi_location_disabled); }
public void onReceive(Context context, Intent intent) { String action = intent.getAction(); mWakeLock.acquire(); try { if (DEBUG) Log.d(TAG, "onReceive " + action); boolean disableIfMusicActive = getPrefs(context).getBoolean("media_player_music_active", false); boolean autoRun = getPrefs(context).getBoolean("media_player_autorun_single", true); boolean closeApp = getPrefs(context).getBoolean("media_player_disconnect_headset_or_a2dp", false); switch (action) { case BluetoothAdapter.ACTION_STATE_CHANGED: if (intent.getIntExtra(BluetoothAdapter.EXTRA_STATE, -1) == BluetoothAdapter.STATE_OFF) { mA2DPConnected = false; } break; case BluetoothA2dp.ACTION_CONNECTION_STATE_CHANGED: int state = intent.getIntExtra(BluetoothProfile.EXTRA_STATE, BluetoothProfile.STATE_CONNECTED); if (state == BluetoothProfile.STATE_CONNECTED && !mA2DPConnected) { mA2DPConnected = true; if (DEBUG) Log.d(TAG, "BluetoothProfile.STATE_CONNECTED = true"); } break; // other cases... } } finally { mWakeLock.release(); } }
private static final int KEY_MASK_BACK = 0x02; private static final int KEY_MASK_MENU = 0x04; private static final int KEY_MASK_ASSIST = 0x08; private static final int KEY_MASK_APP_SWITCH = 0x10; private CheckBoxPreference mVolumeWake; private CheckBoxPreference mSwapVolumeButtons; private SwitchPreference mEnableCustomBindings; private ListPreference mBackPressAction; private ListPreference mBackLongPressAction; private ListPreference mHomePressAction; private ListPreference mHomeLongPressAction; private ListPreference mHomeDoubleTapAction; private CheckBoxPreference mHomeAnswerCall; private ListPreference mMenuPressAction; private ListPreference mMenuLongPressAction; private ListPreference mAssistPressAction; private ListPreference mAssistLongPressAction; private ListPreference mAppSwitchPressAction; private ListPreference mAppSwitchLongPressAction; private Map<String, Integer> mKeySettings = new HashMap<String, Integer>();
mGestureButtonHandler.sendEmptyMessageDelayed(MSG_SEND_SWITCH_KEY, (long) GESTURE_KEY_DISTANCE_TIMEOUT); } } mLastX = rawX; mLastY = rawY; break; } else if (mLongClick && mPreparedKeycode == 3) { mGestureButtonHandler.removeMessages(MSG_SEND_SWITCH_KEY); mGestureButtonHandler.sendEmptyMessageDelayed(MSG_SEND_SWITCH_KEY, (long) GESTURE_KEY_DISTANCE_TIMEOUT); mPreparedKeycode = 0; mLongClick = false; } break; case 3: break; default: break; } }
/** * The animation property used for the icon when its isolation ends. * This animates the translation back to the right position. */ private static final AnimationProperties UNISOLATION_PROPERTY = new AnimationProperties() { private AnimationFilter mAnimationFilter = new AnimationFilter().animateX(); @Override public AnimationFilter getAnimationFilter() { return mAnimationFilter; } }.setDuration(CONTENT_FADE_DURATION); private int MAX_VISIBLE_ICONS_WHEN_DARK = 5; private int MAX_STATIC_ICONS = 4; private static final int MAX_DOTS = 1; private boolean mIsStaticLayout = true; private final HashMap<View, IconState> mIconStates = new HashMap<>(); private int mDotPadding; private int mMaxVisibleIconsWhenDark; private int mMaxStaticIcons; private int mStaticDotRadius; private int mStaticDotDiameter; private int mOverflowWidth; private int mActualLayoutWidth = NO_VALUE; private float mActualPaddingEnd = NO_VALUE; private float mActualPaddingStart = NO_VALUE; private boolean mDark;
private static final AnimationProperties UNISOLATION_PROPERTY = new AnimationProperties() { private AnimationFilter mAnimationFilter = new AnimationFilter().animateX(); @Override public AnimationFilter getAnimationFilter() { return mAnimationFilter; } }.setDuration(CONTENT_FADE_DURATION); public final int MAX_VISIBLE_ICONS_WHEN_DARK; public final int MAX_STATIC_ICONS; private static final int MAX_DOTS = 1; private boolean mIsStaticLayout = true; private final HashMap<View, IconState> mIconStates = new HashMap<>(); private int mDotPadding; private int mStaticDotRadius; private int mStaticDotDiameter; private int mOverflowWidth; private int mActualLayoutWidth = NO_VALUE; private float mActualPaddingEnd = NO_VALUE; private float mActualPaddingStart = NO_VALUE; private boolean mDark; private boolean mChangingViewPositions; private int mAddAnimationStartIndex = -1; private void initDimens() { MAX_VISIBLE_ICONS_WHEN_DARK = getResources().getInteger(R.integer.config_maxVisibleNotificationIconsWhenDark); MAX_STATIC_ICONS = getResources().getInteger(R.integer.config_maxVisibleNotificationIcons); }
private void initDimens() { public final int MAX_VISIBLE_ICONS_WHEN_DARK = getResources().getInteger(R.integer.config_maxVisibleNotificationIconsWhenDark); public final int MAX_STATIC_ICONS = getResources().getInteger(R.integer.config_maxVisibleNotificationIcons); private static final int MAX_DOTS = 1; }
toastText = com.android.internal.R.string.volume_dialog_ringer_guidance_silent_no_media; break; case VOLUME_HUSH_VIBRATE: effect = VibrationEffect.get(VibrationEffect.EFFECT_HEAVY_CLICK); ringerMode = AudioManager.RINGER_MODE_VIBRATE; toastText = com.android.internal.R.string.volume_dialog_ringer_guidance_vibrate; break; } maybeVibrate(effect); setRingerModeInternal(ringerMode, reason); Toast.makeText(ActivityThread.currentActivityThread().getSystemUiContext(), toastText, Toast.LENGTH_SHORT).show();
boolean result = false; try { logger.info("provisionONT begin"); AddOntMessage request = AddOntMessage.newBuilder() .setCLLI(clli) .setPortNumber(portNumber) .setSlotNumber(slotNumber) .setOntNumber(ontNumber) .setSerialNumber(serialNumber) .build(); AddOntReturn response = blockingStub.provisionOnt(request); result = response.getSuccess(); logger.info("provisionONT with device id : {} success : {}", serialNumber, result); } catch (RuntimeException e) { logger.log(Level.WARNING, "provisionONT RPC failed", e); } return result;
private static final Logger logger = Logger.getLogger(AbstractOLTServer.class.getName()); @Override public void echo(EchoMessage request, StreamObserver<EchoReplyMessage> responseObserver) { } @Override public void createChassis(AddChassisMessage request, StreamObserver<AddChassisReturn> responseObserver) { AddChassisReturn response = AddChassisReturn.newBuilder() .setDeviceID(request.getCLLI()) .build(); responseObserver.onNext(response); responseObserver.onCompleted(); logger.info("createChassis with clli : {}", request.getCLLI()); } @Override public void createOLTChassis(AddOLTChassisMessage request, StreamObserver<AddOLTChassisReturn> responseObserver) { AddOLTChassisReturn response = AddOLTChassisReturn.newBuilder() .setDeviceID(UUID.randomUUID().toString()) .setChassisDeviceID(request.getCLLI()) .build(); responseObserver.onNext(response); responseObserver.onCompleted(); logger.info("createOLTChassis with clli : {}", request.getCLLI()); } @Override public void provisionOnt(AddOntMessage request, StreamObserver<AddOntReturn> responseObserver) { AddOntReturn response = AddOntReturn.newBuilder() .setSuccess(true) .build(); responseObserver.onNext(response); responseObserver.onCompleted(); }
public void removeSubscriber(ConnectPoint port) { AccessDeviceData olt = oltData.get(port.deviceId()); if (olt == null) { log.warn("No data found for OLT device {}", port.deviceId()); return; } VlanId subscriberVlan = subscribers.remove(port); if (subscriberVlan == null) { log.warn("Unknown subscriber at location {}", port); return; } if (enableDhcpIgmpOnProvisioning) { processDhcpFilteringObjectives(olt.deviceId(), port.port(), false); } unprovisionSubscriber(olt.deviceId(), olt.uplink(), port.port(), subscriberVlan, olt.vlan(), olt.defaultVlan()); if (enableDhcpIgmpOnProvisioning) { processIgmpFilteringObjectives(olt.deviceId(), port.port(), false); } }
public void testPopulateExtendedModules() { XmlAnalysisModuleSource source = new XmlAnalysisModuleSource(); Iterable<IAnalysisModuleHelper> modules = source.getAnalysisModules(); assertNull("Module not present", findModule(modules, MY_MODULE)); /* use the valid extended XML test file */ File testXmlFile = TmfXmlTestFiles.VALID_FILE_EXTENDED.getFile(); if ((testXmlFile == null) || !testXmlFile.exists()) { fail("XML test file does not exist"); } XmlUtils.addXmlFile(testXmlFile); XmlAnalysisModuleSource.notifyModuleChange(); modules = source.getAnalysisModules(); assertTrue("Modules available from source", modules.iterator().hasNext()); assertNotNull("'My' module present", findModule(modules, MY_MODULE)); assertNotNull("'abc' module present", findModule(modules, ABC_MODULE)); } if (!(type_.isDecimal() && t1.isDecimal())) castChild(1, type_); t0 = getChild(0).getType(); t1 = getChild(1).getType(); // Use MATH_MOD function operator for floating-point modulo. // TODO remove this when we have operators implemented using the UDF interface // and we can resolve this just using function overloading. if ((t0.isFloatingPointType() || t1.isFloatingPointType()) && op_ == ArithmeticExpr.Operator.MOD) { fnName = "fmod"; } fn_ = getBuiltinFunction(analyzer, fnName, collectChildReturnTypes(), CompareMode.IS_IDENTICAL); if (fn_ == null) { Preconditions.checkState(false, String.format("No match " + "for '%s' with operand types %s and %s", toSql(), t0, t1)); } Preconditions.checkState(type_.matchesType(fn_.getReturnType())); @Override case 13: return "API 13: Android 3.2 (Honeycomb)"; case 14: return "API 14: Android 4.0 (IceCreamSandwich)"; case 15: return "API 15: Android 4.0.3 (IceCreamSandwich)"; case 16: return "API 16: Android 4.1 (Jelly Bean)"; case 17: return "API 17: Android 4.2 (Jelly Bean)"; // If you add more versions here, also update #getBuildCodes and #H
import org.polarsys.capella.core.model.handler.command.CapellaResourceHelper; /** * An {@link ECrossReferenceAdapter} that only takes capella resources into account. */ public class CapellaECrossReferenceAdapter extends SiriusCrossReferenceAdapter { class CapellaInverseCrossReferencer extends InverseCrossReferencer { private static final long serialVersionUID = -3473829340961544993L; @Override protected void addProxy(EObject proxy, EObject context) { // Do nothing to avoid keeping EObjects turn into proxies during the whole application life. } @Override protected boolean resolve() { return CapellaECrossReferenceAdapter.this.resolve(); } } WeakReference<EditingDomain> _editingDomain; public CapellaECrossReferenceAdapter(EditingDomain editingDomain, Session session, ResourceSet set) { super(set, (DAnalysisSessionImpl) session); _editingDomain = new WeakReference<EditingDomain>(editingDomain); } /** * Adapt all references of specified object against the inverse cross referencer. */ public void adaptAll(Notifier notifier) { if (notifier instanceof EObject) { EObject eObject = (EObject) notifier; if (CapellaResourceHelper.isCapellaResource(eObject.eResource())) { eObject.eAdapters().add(this); for (EObject content : eObject.eContents()) { adaptAll(content); } } } } }
private static final String MIGRATED_FITLER_EXT = ".filter"; private static final String FRAGMENT_SEPARATOR = "\\@"; private static final String FILTER_SEPARATOR = "\\'"; private static final String FRAGMENT_FILTER_KEY = "filters"; private static final String PLUGIN_TYPE = "plugin"; private static final String VALID_PLUGIN = "org.polarsys.capella.core.sirius.analysis"; private static final String DESCRIPTION_TYPE = "description"; private Map<DiagramDescription, Set<String>> validFilterNames; private Map<String, String> filterNameExceptions; public FilterMigrationContribution() { validFilterNames = new HashMap<>(); filterNameExceptions = new HashMap<>(); filterNameExceptions.put("ShowEIExchangeContext", "show.ei.exchange.context.filter"); filterNameExceptions.put("CEParam", "show.ce.param.filter"); filterNameExceptions.put("CEEIParam", "show.ce.ei.param.filter"); filterNameExceptions.put("ShowFEExchangeContex", "show.fe.exchange.context.filter"); filterNameExceptions.put("ShowCEExchangeContext", "show.ce.exchange.context.filter"); } @Override public void initialize() { filterNameExceptions = new HashMap<>(); filterNameExceptions.put("ShowEIExchangeContext", "show.ei.exchange.context.filter"); filterNameExceptions.put("CEParam", "show.ce.param.filter"); filterNameExceptions.put("CEEIParam", "show.ce.ei.param.filter"); filterNameExceptions.put("ShowFEExchangeContex", "show.fe.exchange.context.filter"); filterNameExceptions.put("ShowCEExchangeContext", "show.ce.exchange.context.filter"); } public static String getValidFilterNameCandidate(String filterName) { return filterNameExceptions.get(filterName); }
import org.polarsys.capella.core.model.helpers.BlockArchitectureExt; import org.polarsys.capella.core.model.helpers.ComponentExt; import org.polarsys.capella.core.ui.properties.fields.AbstractSemanticField; import org.polarsys.capella.core.ui.properties.fields.MultipleSemanticField; public abstract class ComponentSection extends GeneralizableElementSection { private boolean showIsHuman; private boolean showIsActor; private boolean showImplementedInterfaces; private boolean showUsedInterfaces; private boolean showAllocatedFunctions; protected IsHumanPropertiesCheckbox isHumanCheckbox; protected IsActorPropertiesCheckbox isActorCheckbox; private MultipleSemanticField implementedInterfaces; private MultipleSemanticField usedInterfaces; protected MultipleSemanticField allocatedFunctions; public ComponentSection() { this(true, true, true, true, true, true, true); } public ComponentSection(boolean showImplementedInterfaces, boolean showUsedInterfaces, boolean showAllocatedFunctions, boolean showSuperTypes, boolean showIsAbstract) { this.showImplementedInterfaces = showImplementedInterfaces; this.showUsedInterfaces = showUsedInterfaces; this.showAllocatedFunctions = showAllocatedFunctions; this.showSuperTypes = showSuperTypes; this.showIsAbstract = showIsAbstract; } }
if (null != propertiesCheckbox) { propertiesCheckbox.setEnabled(component.isActor()); } if (null != isHumanCheckbox) { isHumanCheckbox.loadData(component); boolean isOperationalEntity = block instanceof OperationalAnalysis && !component.isActor(); boolean isSystem = component == block.getSystem(); boolean isComposite = ComponentExt.isComposite(component); if (isHumanCheckbox.isEnabled() && (isOperationalEntity || isSystem || isComposite)) { isHumanCheckbox.setEnabled(false); } } if (null != isActorCheckbox) { isActorCheckbox.loadData(component); boolean isSystemAnalysis = block instanceof SystemAnalysis; boolean isSAComponent = component.isInSA(); boolean isActorWithoutContainer = component.isActor() && !component.canHaveComponent(); boolean isComponentWithoutActor = component.isComponent() && !component.canHaveActor(); if (isActorCheckbox.isEnabled() && (isSAComponent || isSystemAnalysis || isActorWithoutContainer || isComponentWithoutActor)) { isActorCheckbox.setEnabled(false); } }
boolean condition1 = block instanceof SystemAnalysis; boolean condition2 = component == block.getSystem(); boolean condition3 = component.isActor() && !ComponentExt.canCreateABComponent(component.eContainer()); boolean condition4 = !component.isActor() && !ComponentExt.canCreateABActor(component.eContainer()); if (isActorCheckbox.isEnabled() && (condition1 || condition2 || condition3 || condition4)) { isActorCheckbox.setEnabled(false); } if (null != implementedInterfaces) { implementedInterfaces.loadData(component, CsPackage.Literals.COMPONENT__OWNED_INTERFACE_IMPLEMENTATIONS); } if (null != usedInterfaces) { usedInterfaces.loadData(component, CsPackage.Literals.COMPONENT__OWNED_INTERFACE_USES); } if (null != allocatedFunctions) { allocatedFunctions.loadData(component, FaPackage.Literals.ABSTRACT_FUNCTIONAL_BLOCK__OWNED_FUNCTIONAL_ALLOCATION); }
/***************************************************************************** * Copyright (c) 2006, 2018 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util.pattern.helper; import java.util.ArrayList; import java.util.Collection; import org.polarsys.capella.core.data.fa.FunctionalExchange; import org.polarsys.capella.core.data.oa.CommunicationMean; import org.polarsys.capella.core.data.oa.Entity; import org.polarsys.capella.common.data.modellingcore.AbstractInformationFlow; import org.polarsys.capella.common.data.modellingcore.InformationsExchanger; import org.polarsys.capella.docgen.util.CapellaServices; import org.polarsys.capella.docgen.util.StringUtil; public class CapellaEntityHelper { public static Collection<String> getIncomingCommunicationMeansLines(Entity entity, String projectName, String outputFolder) { Collection<String> ret = new ArrayList<String>(); // implementation here return ret; } }
/***************************************************************************** * Copyright (c) 2006, 2019 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.Iterator; import java.util.List; import java.util.Set; import org.eclipse.emf.common.util.EList; import org.eclipse.emf.ecore.EObject; import org.polarsys.capella.core.data.cs.Component; import org.polarsys.capella.core.data.cs.Interface; import org.polarsys.capella.core.data.fa.AbstractFunction; import org.polarsys.capella.core.data.fa.ComponentExchange; import org.polarsys.capella.core.data.fa.ComponentExchangeEnd; import org.polarsys.capella.core.data.fa.ComponentExchangeKind; import org.polarsys.capella.core.data.fa.ComponentPort; import org.polarsys.capella.core.data.fa.FunctionalExchange;
/***************************************************************************** * Copyright (c) 2006, 2018 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util.pattern.helper; import java.util.ArrayList; import java.util.Collection; import java.util.HashMap; import java.util.Map; import org.polarsys.capella.common.data.modellingcore.ModelElement; import org.polarsys.capella.core.data.cs.Interface; import org.polarsys.capella.core.data.fa.ComponentExchange; import org.polarsys.capella.core.data.fa.ComponentExchangeKind; import org.polarsys.capella.core.data.fa.ComponentPort; import org.polarsys.capella.core.data.information.ExchangeItem; import org.polarsys.capella.docgen.util.CapellaServices; import org.polarsys.capella.docgen.util.StringUtil; public class CapellaComponentPortHelper { 	/** 	 * Get the provided interfaces of a ComponentPort as html 	 * 	 * @param port 	 * the ComponentPort 	 * @return the provided interfaces as html 	 */ 	public static String getProvidedInterfaces(ComponentPort port) { 		Collection<Interface> providedInterfaces = new ArrayList<Interface>(); 		for (ComponentExchange exchange : port.getOutgoingComponentExchangeRealizations()) { 			if (exchange.getKind() == ComponentExchangeKind.PROVIDES) { 				providedInterfaces.add(exchange.getInterface()); 			} 		} 		return StringUtil.join(providedInterfaces, ", ", new StringUtil.Function<Interface>() { 			public String apply(Interface input) { 				return CapellaServices.getService().getHyperlinkFromElement(input); 			} 		}); 	} 	/** 	 * Get the required interfaces of a ComponentPort as html 	 * 	 * @param port 	 * the ComponentPort 	 * @return the required interfaces as html 	 */ 	public static String getRequiredInterfaces(ComponentPort port) { 		Collection<Interface> requiredInterfaces = new ArrayList<Interface>(); 		for (ComponentExchange exchange : port.getIncomingComponentExchangeRealizations()) { 			if (exchange.getKind() == ComponentExchangeKind.RE
EList<EObject> objects = new BasicEList<EObject>(); objects.add(repTarget); if (repTarget instanceof Part) { objects.addAll(resolveReferencedElements(((Part) repTarget).getAbstractType())); } if (repTarget instanceof InstanceRole) { objects.addAll(resolveReferencedElements(((InstanceRole) repTarget).getRepresentedInstance())); } if (repTarget instanceof StateFragment) { objects.addAll(resolveReferencedElements(((StateFragment) repTarget).getRelatedAbstractFunction())); } return objects; public static Collection<DDiagram> getAllInterestedRepresentationsFor(EObject semanticElement) { <<<<<<< HEAD Scrutinize all EOI (element of interest: See {@link org.polarsys.capella.core.diagram.helpers.naming.DAnnotationSourceConstants.CAPELLA_ELEMENT_OF_INTEREST}) annotation of all representation descriptors to find all representations which are interested by the semantic element @param semanticElement to find all representation interested by it @return a collection of representations interested by semantic element. If there are no representation, empty collection is returned >>>>>>> }

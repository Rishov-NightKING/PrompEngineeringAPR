sample no,Ground Truth,GT abs or modified,PLBART prediction,score1,score2,CodeT5 prediction,score1,score2,zero shot gpt prediction,score1,score2,few shot gpt prediction,score1,score2,codeDaVinci edit prediction,score1,score2
1,"mMaxNumWhitelistSsid = - 1 ; if ( mFirmwareRoamingSupported ) { WifiNative . RoamingCapabilities roamingCap = new WifiNative . RoamingCapabilities ( ) ; if ( mWifiNative . getRoamingCapabilities ( roamingCap ) ) { mMaxNumBlacklistBssid = roamingCap . maxBlacklistSize ; mMaxNumWhitelistSsid = roamingCap . maxWhitelistSize ; Log . d ( TAG , ""Firmware roaming capabilities : max num blacklist bssid = "" + mMaxNumBlacklistBssid + "" max num whitelist ssid = "" + mMaxNumWhitelistSsid ) ; } else { Log . e ( TAG , ""Failed to get firmware roaming capabilities"" ) ; } if ( fallbackToFrameworkRoaming ) { Log . e ( TAG , ""Fall back to framework roaming"" ) ; mFirmwareRoamingSupported = false ; return false ; } }
","} if ( fallbackToFrameworkRoaming ) { Log . e ( TAG , ""Fall back to framework roaming"" ) ; mFirmwareRoamingSupported = false ; return false ; }
","} Log.d(TAG, ""Firmware roaming capabilities: max num blacklist bssid="" + mMaxNumBlacklistBssid + "" max num whitelist ssid="" + mMaxNumWhitelistSsid);
",,,"} mMaxNumBlacklistBssid = -1; mMaxNumWhitelistSsid = -1; Log.d(TAG, ""Firmware roaming capabilities: max num blacklist bssid="" + mMaxNumBlacklistBssid + "" max num whitelist ssid="" + mMaxNumWhitelistSsid);
",,,"int maxNumWhitelistSsid = - 1 ; if ( mFirmwareRoamingSupported ) { WifiNative . RoamingCapabilities roamingCap = new WifiNative . RoamingCapabilities ( ) ; if ( mWifiNative . getRoamingCapabilities ( roamingCap ) ) { mMaxNumBlacklistBssid = roamingCap . maxBlacklistSize ; maxNumWhitelistSsid = roamingCap . maxWhitelistSize ; Log . d ( TAG , ""Firmware roaming capabilities : max num blacklist bssid = "" + mMaxNumBlacklistBssid + "" max num whitelist ssid = "" + maxNumWhitelistSsid ) ; } else { Log . e ( TAG , ""Failed to get firmware roaming capabilities"" ) ; // Report that firmware roaming is not supported so the framework code can do the roams instead of relying on faulty firmware mFirmwareRoamingSupported = false ; // Restart the wifi service mWifiService . restart ( ) ; } } mMaxNumWhitelistSsid = maxNumWhitelistSsid ;
",,,"/* * @hide */ public static final int WIFI_FEATURE_MKEEP_ALIVE = 0x100000 ; // Wifi mkeep_alive /* * @hide */ public static final int WIFI_FEATURE_CONFIG_NDO = 0x200000 ; // ND offload configure /* * @hide */ public static final int WIFI_FEATURE_TRANSMIT_POWER = 0x400000 ; // Capture Tx transmit power levels /* * @hide */ public static final int WIFI_FEATURE_CONTROL_ROAMING = 0x800000 ; // Enable / Disable firmware roaming /* * @hide */ public static final int WIFI_FEATURE_IE_WHITELIST = 0x1000000 ; // Probe IE white listing /* * @hide */ public static final int WIFI_FEATURE_SCAN_RAND = 0x2000000 ; // Support MAC & Probe Sequence Number randomization private int getSupportedFeatures ( ) { try { return mService . getSupportedFeatures ( ) ; } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } } private boolean isFeatureSupported ( int feature ) { return ( getSupportedFeatures ( ) & feature ) == feature ; } public void verifyFirmwareRoamingCapabilityWithSuccessfulNativeCall ( ) { mWifiConnectivityHelper . getFirmwareRoamingInfo ( ) ; assertTrue ( mWifiConnectivityHelper . isFirmwareRoamingSupported ( ) ) ; assertEquals ( MAX_BSSID_BLACKLIST_SIZE , mWifiConnectivityHelper . getMaxNumBlacklistBssid ( ) ) ; assertEquals ( MAX_SSID_WHITELIST_SIZE , mWifiConnectivityHelper . getMaxNumWhitelistSsid ( ) ) ; } public int getMaxNumBlacklistBssid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumBlacklistBssid ; } else { Log . e ( TAG , ""Firmware roaming is not supported"" ) ; return - 1 ; } } mMaxNumWhitelistSsid = - 1 ; if ( mFirmwareRoamingSupported ) { WifiNative . RoamingCapabilities roamingCap = new WifiNative . RoamingCapabilities ( ) ; if ( mWifiNative . getRoamingCapabilities ( roamingCap ) ) { mMaxNumBlacklistBssid = roamingCap . maxBlacklistSize ; mMaxNumWhitelistSsid = roamingCap . maxWhitelistSize ; Log . d ( TAG , ""Firmware roaming capabilities : max num blacklist bssid = "" + mMaxNumBlacklistBssid + "" max num whitelist ssid = "" + mMaxNumWhitelistSsid ) ;
",,,"mMaxNumWhitelistSsid = - 1 ; if ( mFirmwareRoamingSupported ) { WifiNative . RoamingCapabilities roamingCap = new WifiNative . RoamingCapabilities ( ) ; if ( mWifiNative . getRoamingCapabilities ( roamingCap ) ) { mMaxNumBlacklistBssid = roamingCap . maxBlacklistSize ; mMaxNumWhitelistSsid = roamingCap . maxWhitelistSize ; Log . d ( TAG , ""Firmware roaming capabilities : max num blacklist bssid = "" + mMaxNumBlacklistBssid + "" max num whitelist ssid = "" + mMaxNumWhitelistSsid ) ; } else { Log . e ( TAG , ""Failed to get firmware roaming capabilities"" ) ; < |startfocus| > } < |endfocus| > } else { Log . d ( TAG , ""Firmware roaming is not supported"" ) ; }
",,
3,"public int getMaxNumBlacklistBssid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumBlacklistBssid ; } else { Log . e ( TAG , ""getMaxNumBlacklistBssid : Firmware roaming is not supported"" ) ; return INVALID_LIST_SIZE ; }
","Log . e ( TAG , ""getMaxNumBlacklistBssid : Firmware roaming is not supported"" ) ; return INVALID_LIST_SIZE ;
","return mMaxNumBlacklistBssid;
",,,"Log.e(TAG, ""Firmware roaming is not supported""); return -1; } else { Log.e(TAG, ""Firmware roaming is not supported""); return mMaxNumBlacklistBssid;
",,,"public int getMaxNumBlacklistBssid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumBlacklistBssid ; } Log . e ( TAG , ""Firmware roaming is not supported"" ) ; return - 1 ; }
",,,"public int getMaxNumBlacklistBssid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumBlacklistBssid ; } Log . e ( TAG , ""Firmware roaming is not supported"" ) ; return - 1 ; }
",,,"public int getMaxNumBlacklistBssid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumBlacklistBssid ; } < |startfocus| > Log . e ( TAG , ""Firmware roaming is not supported"" ) ; return - 1 ; < |endfocus| > }
",,
11,"boolean waitForCallback ( int callback ) { synchronized ( mLocalLock ) { boolean found = mCallbackQueue . remove ( callback ) ; if ( found ) { return true ; } mCurrentWaitForCallback = callback ; mBlocker = new CountDownLatch ( 1 ) ; } try { return mBlocker . await ( WAIT_FOR_AWARE_CHANGE_SECS , TimeUnit . SECONDS ) ; } catch ( InterruptedException e ) { return false ; }
","boolean found = mCallbackQueue . remove ( callback ) ; if ( found ) { return true ;
","mCallbackQueue.remove();
",,,"if (mCallbackQueue.remove(callback)) { return true;
",,,"boolean waitForCallback ( int callback ) { synchronized ( mLocalLock ) { Iterator < Integer > it = mCallbackQueue . iterator ( ) ; while ( it . hasNext ( ) ) { if ( it . next ( ) == callback ) { mCallbackQueue . remove ( callback ) ; return true ; } } mCurrentWaitForCallback = callback ; mBlocker = new CountDownLatch ( 1 ) ; } try { return mBlocker . await ( WAIT_FOR_AWARE_CHANGE_SECS , TimeUnit . SECONDS ) ; } catch ( InterruptedException e ) { return false ; } }
",,,"boolean waitForCallback ( int callback ) { synchronized ( mLocalLock ) { Iterator < Integer > it = mCallbackQueue . iterator ( ) ; while ( it . hasNext ( ) ) { if ( it . next ( ) == callback ) { it . remove ( ) ; return true ; } } mCurrentWaitForCallback = callback ; mBlocker = new CountDownLatch ( 1 ) ; } try { return mBlocker . await ( WAIT_FOR_AWARE_CHANGE_SECS , TimeUnit . SECONDS ) ; } catch ( InterruptedException e ) { return false ; } }
",,,"boolean waitForCallback ( int callback ) { synchronized ( mLocalLock ) { < |startfocus| > Iterator < Integer > it = mCallbackQueue . iterator ( ) ; while ( it . hasNext ( ) ) { if ( it . next ( ) == callback ) { it . remove ( ) ; return true ; } } < |endfocus| > mCurrentWaitForCallback = callback ; mBlocker = new CountDownLatch ( 1 ) ; } try { return mBlocker . await ( WAIT_FOR_AWARE_CHANGE_SECS , TimeUnit . SECONDS ) ; } catch ( InterruptedException e ) { return false ; }
",,
13,"public void testSubscribeDiscoverySuccess ( ) { if ( ! TestUtils . shouldTestWifiAware ( getContext ( ) ) ) { return ; } final String serviceName = ""ValidName"" ; WifiAwareSession session = attachAndGetSession ( ) ; SubscribeConfig subscribeConfig = new SubscribeConfig . Builder ( ) . setServiceName ( serviceName ) . build ( ) ; DiscoverySessionCallbackTest discoveryCb = new DiscoverySessionCallbackTest ( ) ; // 1 . subscribe session . subscribe ( subscribeConfig , discoveryCb , null ) ; assertTrue ( ""Subscribe started"" , discoveryCb . waitForCallback ( DiscoverySessionCallbackTest . ON_SUBSCRIBE_STARTED ) ) ; SubscribeDiscoverySession discoverySession = discoveryCb . getSubscribeDiscoverySession ( ) ; assertNotNull ( ""Subscribe session"" , discoverySession ) ; // 2 . update - subscribe subscribeConfig = new SubscribeConfig . Builder ( ) . setServiceName ( serviceName ) . setServiceSpecificInfo ( ""extras"" . getBytes ( ) ) . build ( ) ; discoverySession . updateSubscribe ( subscribeConfig ) ; assertTrue ( ""Subscribe update"" , discoveryCb . waitForCallback ( DiscoverySessionCallbackTest . ON_SESSION_CONFIG_UPDATED ) ) ; // 3 . destroy assertFalse ( ""Subscribe not terminated"" , discoveryCb . hasCallbackAlreadyHappened ( DiscoverySessionCallbackTest . ON_SESSION_TERMINATED ) ) ; discoverySession . destroy ( ) ;
","// 1 . subscribe
","// 1. subscribe
",,,"// 1. subscribe
",,,"public void testSubscribeDiscoverySuccess ( ) { if ( ! TestUtils . shouldTestWifiAware ( getContext ( ) ) ) { return ; } final String serviceName = ""ValidName"" ; WifiAwareSession session = attachAndGetSession ( ) ; SubscribeConfig subscribeConfig = new SubscribeConfig . Builder ( ) . setServiceName ( serviceName ) . build ( ) ; DiscoverySessionCallbackTest discoveryCb = new DiscoverySessionCallbackTest ( ) ; session . subscribe ( subscribeConfig , discoveryCb , null ) ; assertTrue ( discoveryCb . waitForCallback ( DiscoverySessionCallbackTest . ON_SUBSCRIBE_STARTED ) ) ; SubscribeDiscoverySession discoverySession = discoveryCb . getSubscribeDiscoverySession ( ) ; assertNotNull ( discoverySession ) ; subscribeConfig = new SubscribeConfig . Builder ( ) . setServiceName ( serviceName ) . setServiceSpecificInfo ( ""extras"" . getBytes ( ) ) . build ( ) ; discoverySession . updateSubscribe ( subscribeConfig ) ; assertTrue ( discoveryCb . waitForCallback ( DiscoverySessionCallbackTest . ON_SESSION_CONFIG_UPDATED ) ) ; assertFalse ( discoveryCb . hasCallbackAlreadyHappened ( DiscoverySessionCallbackTest . ON_SESSION_TERMINATED ) ) ; discoverySession . destroy ( ) ; }
",,,"public void testSubscribeDiscoverySuccess ( ) { if ( ! TestUtils . shouldTestWifiAware ( getContext ( ) ) ) { return ; } final String serviceName = ""ValidName"" ; WifiAwareSession session = attachAndGetSession ( ) ; SubscribeConfig subscribeConfig = new SubscribeConfig . Builder ( ) . setServiceName ( serviceName ) . build ( ) ; DiscoverySessionCallbackTest discoveryCb = new DiscoverySessionCallbackTest ( ) ; session . subscribe ( subscribeConfig , discoveryCb , null ) ; assertTrue ( discoveryCb . waitForCallback ( DiscoverySessionCallbackTest . ON_SUBSCRIBE_STARTED ) ) ; SubscribeDiscoverySession discoverySession = discoveryCb . getSubscribeDiscoverySession ( ) ; assertNotNull ( discoverySession ) ; subscribeConfig = new SubscribeConfig . Builder ( ) . setServiceName ( serviceName ) . setServiceSpecificInfo ( ""extras"" . getBytes ( ) ) . build ( ) ; discoverySession . updateSubscribe ( subscribeConfig ) ; assertTrue ( discoveryCb . waitForCallback ( DiscoverySessionCallbackTest . ON_SESSION_CONFIG_UPDATED ) ) ; assertFalse ( discoveryCb . hasCallbackAlreadyHappened ( DiscoverySessionCallbackTest . ON_SESSION_TERMINATED ) ) ; discoverySession . destroy ( ) ; }
",,,"public void testSubscribeDiscoverySuccess ( ) { if ( ! TestUtils . shouldTestWifiAware ( getContext ( ) ) ) { return ; } final String serviceName = ""ValidName"" ; WifiAwareSession session = attachAndGetSession ( ) ; SubscribeConfig subscribeConfig = new SubscribeConfig . Builder ( ) . setServiceName ( serviceName ) . build ( ) ; DiscoverySessionCallbackTest discoveryCb = new DiscoverySessionCallbackTest ( ) ; < |startfocus| > // 1 . subscribe < |endfocus| > session . subscribe ( subscribeConfig , discoveryCb , null ) ; assertTrue ( ""Subscribe started"" , discoveryCb . waitForCallback ( DiscoverySessionCallbackTest . ON_SUBSCRIBE_STARTED ) ) ; SubscribeDiscoverySession discoverySession = discoveryCb . getSubscribeDiscoverySession ( ) ; assertNotNull ( ""Subscribe session"" , discoverySession ) ; // 2 . update - subscribe subscribeConfig = new SubscribeConfig . Builder ( ) . setServiceName ( serviceName ) . setServiceSpecificInfo ( ""extras"" . getBytes ( ) ) . build ( ) ; discoverySession . updateSubscribe ( subscribeConfig ) ; assertTrue ( ""Subscribe update"" , discoveryCb . waitForCallback ( DiscoverySessionCallbackTest . ON_SESSION_CONFIG_UPDATED ) ) ; // 3 . destroy assertFalse ( ""Subscribe not terminated"" , discoveryCb . hasCallbackAlreadyHappened ( DiscoverySessionCallbackTest . ON_SESSION_TERMINATED ) ) ; discoverySession . destroy ( ) ;
",,
17,"mMediaRecorder . setVideoEncoder ( MediaRecorder . VideoEncoder . DEFAULT ) ; mMediaRecorder . setPreviewDisplay ( mActivity . getSurfaceHolder ( ) . getSurface ( ) ) ; mMediaRecorder . setVideoSize ( mVideoWidth , mVideoHeight ) ; FileOutputStream fos = new FileOutputStream ( OUTPUT_PATH2 ) ; FileDescriptor fd = fos . getFD ( ) ; mMediaRecorder . setOutputFile ( fd ) ; long maxFileSize = MAX_FILE_SIZE * 10 ; recordMedia ( maxFileSize , mOutFile2 ) ; assertFalse ( checkLocationInFile ( OUTPUT_PATH2 ) ) ; fos . close ( ) ; } public void testRecordingAudioInRawFormats ( ) throws Exception { int testsRun = 0 ; if ( hasAmrNb ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AMR_NB , MediaRecorder . AudioEncoder . AMR_NB ) ; } if ( hasAmrWb ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AMR_WB , MediaRecorder . AudioEncoder . AMR_WB ) ; } if ( hasAac ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AAC_ADTS , MediaRecorder . AudioEncoder . AAC ) ; }
","< |del| > mCamera . release ( ) ; mCamera = null ;
","<|del|>
",,,"<|del|>
",,,"mMediaRecorder . setVideoEncoder ( MediaRecorder . VideoEncoder . DEFAULT ) ; mMediaRecorder . setPreviewDisplay ( mActivity . getSurfaceHolder ( ) . getSurface ( ) ) ; mMediaRecorder . setVideoSize ( mVideoWidth , mVideoHeight ) ; FileOutputStream fos = new FileOutputStream ( OUTPUT_PATH2 ) ; FileDescriptor fd = fos . getFD ( ) ; mMediaRecorder . setOutputFile ( fd ) ; long maxFileSize = MAX_FILE_SIZE * 10 ; recordMedia ( maxFileSize , mOutFile2 ) ; assertFalse ( checkLocationInFile ( OUTPUT_PATH2 ) ) ; fos . close ( ) ; mCamera = null ; public void testRecordingAudioInRawFormats ( ) throws Exception { int testsRun = 0 ; if ( hasAmrNb ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AMR_NB , MediaRecorder . AudioEncoder . AMR_NB ) ; } if ( hasAmrWb ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AMR_WB , MediaRecorder . AudioEncoder . AMR_WB ) ; } if ( hasAac ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AAC_ADTS , MediaRecorder . AudioEncoder . AAC ) ; } }
",,,"mMediaRecorder . setVideoEncoder ( MediaRecorder . VideoEncoder . DEFAULT ) ; mMediaRecorder . setPreviewDisplay ( mActivity . getSurfaceHolder ( ) . getSurface ( ) ) ; mMediaRecorder . setVideoSize ( mVideoWidth , mVideoHeight ) ; FileOutputStream fos = new FileOutputStream ( OUTPUT_PATH2 ) ; FileDescriptor fd = fos . getFD ( ) ; mMediaRecorder . setOutputFile ( fd ) ; long maxFileSize = MAX_FILE_SIZE * 10 ; recordMedia ( maxFileSize , mOutFile2 ) ; assertFalse ( checkLocationInFile ( OUTPUT_PATH2 ) ) ; fos . close ( ) ; mCamera . release ( ) ; mCamera = null ; public void testRecordingAudioInRawFormats ( ) throws Exception { int testsRun = 0 ; if ( hasAmrNb ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AMR_NB , MediaRecorder . AudioEncoder . AMR_NB ) ; } if ( hasAmrWb ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AMR_WB , MediaRecorder . AudioEncoder . AMR_WB ) ; } if ( hasAac ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AAC_ADTS , MediaRecorder . AudioEncoder . AAC ) ; } }
",,,"mMediaRecorder . setVideoEncoder ( MediaRecorder . VideoEncoder . DEFAULT ) ; mMediaRecorder . setPreviewDisplay ( mActivity . getSurfaceHolder ( ) . getSurface ( ) ) ; mMediaRecorder . setVideoSize ( mVideoWidth , mVideoHeight ) ; FileOutputStream fos = new FileOutputStream ( OUTPUT_PATH2 ) ; FileDescriptor fd = fos . getFD ( ) ; mMediaRecorder . setOutputFile ( fd ) ; long maxFileSize = MAX_FILE_SIZE * 10 ; recordMedia ( maxFileSize , mOutFile2 ) ; assertFalse ( checkLocationInFile ( OUTPUT_PATH2 ) ) ; fos . close ( ) ; < |startfocus| > mCamera . release ( ) ; < |endfocus| > } public void testRecordingAudioInRawFormats ( ) throws Exception { int testsRun = 0 ; if ( hasAmrNb ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AMR_NB , MediaRecorder . AudioEncoder . AMR_NB ) ; } if ( hasAmrWb ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AMR_WB , MediaRecorder . AudioEncoder . AMR_WB ) ; } if ( hasAac ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AAC_ADTS , MediaRecorder . AudioEncoder . AAC ) ; }
",,
21,"private int getRegStateFromHalRegState ( int regState ) { switch ( regState ) { case RegState . NOT_REG_MT_NOT_SEARCHING_OP : return ServiceState . RIL_REG_STATE_NOT_REG ; case RegState . REG_HOME : return ServiceState . RIL_REG_STATE_HOME ; case RegState . NOT_REG_MT_SEARCHING_OP : return ServiceState . RIL_REG_STATE_SEARCHING ; case RegState . REG_DENIED : return ServiceState . RIL_REG_STATE_DENIED ; case RegState . UNKNOWN : return ServiceState . RIL_REG_STATE_UNKNOWN ; case RegState . REG_ROAMING : return ServiceState . RIL_REG_STATE_ROAMING ; case RegState . NOT_REG_MT_NOT_SEARCHING_OP_EM : return ServiceState . RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED ; case RegState . NOT_REG_MT_SEARCHING_OP_EM : return ServiceState . RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED ; case RegState . REG_DENIED_EM : return ServiceState . RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED ; case RegState . UNKNOWN_EM : return ServiceState . RIL_REG_STATE_UNKNOWN_EMERGENCY_CALL_ENABLED ; default : return ServiceState . REGISTRATION_STATE_NOT_REGISTERED_AND_NOT_SEARCHING ; }
","private int getRegStateFromHalRegState ( int regState ) {
","private int convertRegStateToServiceState(int regState) {
",,,"private int convertRegStateToServiceState(int regState) {
",,,"private int convertRegStateToServiceState ( int regState ) { switch ( regState ) { case RegState . NOT_REG_MT_NOT_SEARCHING_OP : return ServiceState . RIL_REG_STATE_NOT_REG ; case RegState . REG_HOME : return ServiceState . RIL_REG_STATE_HOME ; case RegState . NOT_REG_MT_SEARCHING_OP : return ServiceState . RIL_REG_STATE_SEARCHING ; case RegState . REG_DENIED : return ServiceState . RIL_REG_STATE_DENIED ; case RegState . UNKNOWN : return ServiceState . RIL_REG_STATE_UNKNOWN ; case RegState . REG_ROAMING : return ServiceState . RIL_REG_STATE_ROAMING ; case RegState . NOT_REG_MT_NOT_SEARCHING_OP_EM : return ServiceState . RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED ; case RegState . NOT_REG_MT_SEARCHING_OP_EM : return ServiceState . RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED ; case RegState . REG_DENIED_EM : return ServiceState . RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED ; case RegState . UNKNOWN_EM : return ServiceState . RIL_REG_STATE_UNKNOWN_EMERGENCY_CALL_ENABLED ; default : return ServiceState . REGISTRATION_STATE_NOT_REGISTERED_AND_NOT_SEARCHING ; } }
",,,"private int convertHalRegStateToServiceState ( int regState ) { switch ( regState ) { case RegState . NOT_REG_MT_NOT_SEARCHING_OP : return ServiceState . RIL_REG_STATE_NOT_REG ; case RegState . REG_HOME : return ServiceState . RIL_REG_STATE_HOME ; case RegState . NOT_REG_MT_SEARCHING_OP : return ServiceState . RIL_REG_STATE_SEARCHING ; case RegState . REG_DENIED : return ServiceState . RIL_REG_STATE_DENIED ; case RegState . UNKNOWN : return ServiceState . RIL_REG_STATE_UNKNOWN ; case RegState . REG_ROAMING : return ServiceState . RIL_REG_STATE_ROAMING ; case RegState . NOT_REG_MT_NOT_SEARCHING_OP_EM : return ServiceState . RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED ; case RegState . NOT_REG_MT_SEARCHING_OP_EM : return ServiceState . RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED ; case RegState . REG_DENIED_EM : return ServiceState . RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED ; case RegState . UNKNOWN_EM : return ServiceState . RIL_REG_STATE_UNKNOWN_EMERGENCY_CALL_ENABLED ; default : return ServiceState . REGISTRATION_STATE_NOT_REGISTERED_AND_NOT_SEARCHING ; } }
",,,"< |startfocus| > private int convertHalRegStateToServiceState ( int halRegState ) { < |endfocus| > switch ( halRegState ) { case RegState . NOT_REG_MT_NOT_SEARCHING_OP : return ServiceState . RIL_REG_STATE_NOT_REG ; case RegState . REG_HOME : return ServiceState . RIL_REG_STATE_HOME ; case RegState . NOT_REG_MT_SEARCHING_OP : return ServiceState . RIL_REG_STATE_SEARCHING ; case RegState . REG_DENIED : return ServiceState . RIL_REG_STATE_DENIED ; case RegState . UNKNOWN : return ServiceState . RIL_REG_STATE_UNKNOWN ; case RegState . REG_ROAMING : return ServiceState . RIL_REG_STATE_ROAMING ; case RegState . NOT_REG_MT_NOT_SEARCHING_OP_EM : return ServiceState . RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED ; case RegState . NOT_REG_MT_SEARCHING_OP_EM : return ServiceState . RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED ; case RegState . REG_DENIED_EM : return ServiceState . RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED ; case RegState . UNKNOWN_EM : return ServiceState . RIL_REG_STATE_UNKNOWN_EMERGENCY_CALL_ENABLED ; default : return ServiceState . REGISTRATION_STATE_NOT_REGISTERED_AND_NOT_SEARCHING ; }
",,
40,"void onWifiAlert ( int errorCode , byte [ ] buffer ) ; } public boolean setLoggingEventHandler ( WifiLoggerEventHandler handler ) { return mWifiVendorHal . setLoggingEventHandler ( handler ) ; } public boolean startLoggingRingBuffer ( int verboseLevel , int flags , int maxInterval , int minDataSize , String ringName ) { return mWifiVendorHal . startLoggingRingBuffer ( verboseLevel , flags , maxInterval , minDataSize , ringName ) ; } public int getSupportedLoggerFeatureSet ( ) { return mWifiVendorHal . getSupportedLoggerFeatureSet ( ) ; } /* * * Stops all logging and resets the logger callback . * This stops both the alerts and ring buffer data collection . */ public boolean resetLogHandler ( ) { return mWifiVendorHal . resetLogHandler ( ) ; } public String getDriverVersion ( ) { return mWifiVendorHal . getDriverVersion ( ) ; } public String getFirmwareVersion ( ) { return mWifiVendorHal . getFirmwareVersion ( ) ; } public static class RingBufferStatus { String name ; int flag ; int ringBufferId ; int ringBufferByteSize ; int verboseLevel ; int writtenBytes ; int readBytes ; int writtenRecords ; // Bit masks for interpreting |flag| public static final int HAS_BINARY_ENTRIES = ( 1 < < 0 ) ;
","/* * * Stops all logging and resets the logger callback . * This stops both the alerts and ring buffer data collection . */
","<|del|>
",,,"/** * Reset the log handler and returns true if the ring buffer has already been reset, false otherwise. */
",,,"public boolean setLoggingEventHandler ( WifiLoggerEventHandler handler ) { return mWifiVendorHal . setLoggingEventHandler ( handler ) ; } public boolean startLoggingRingBuffer ( int verboseLevel , int flags , int maxInterval , int minDataSize , String ringName ) { return mWifiVendorHal . startLoggingRingBuffer ( verboseLevel , flags , maxInterval , minDataSize , ringName ) ; } public int getSupportedLoggerFeatureSet ( ) { return mWifiVendorHal . getSupportedLoggerFeatureSet ( ) ; } public boolean resetLogHandler ( ) { return mWifiVendorHal . resetLogHandler ( ) ; } public String getDriverVersion ( ) { return mWifiVendorHal . getDriverVersion ( ) ; } public String getFirmwareVersion ( ) { return mWifiVendorHal . getFirmwareVersion ( ) ; } public static class RingBufferStatus { String name ; int flag ; int ringBufferId ; int ringBufferByteSize ; int verboseLevel ; int writtenBytes ; int readBytes ; int writtenRecords ; // Bit masks for interpreting |flag| public static final int HAS_BINARY_ENTRIES = ( 1 < < 0 ) ; }
",,,"void onWifiAlert ( int errorCode , byte [ ] buffer ) ; public boolean setLoggingEventHandler ( WifiLoggerEventHandler handler ) { return mWifiVendorHal . setLoggingEventHandler ( handler ) ; } public boolean startLoggingRingBuffer ( int verboseLevel , int flags , int maxInterval , int minDataSize , String ringName ) { return mWifiVendorHal . startLoggingRingBuffer ( verboseLevel , flags , maxInterval , minDataSize , ringName ) ; } public int getSupportedLoggerFeatureSet ( ) { return mWifiVendorHal . getSupportedLoggerFeatureSet ( ) ; } public boolean resetLogHandler ( ) { return mWifiVendorHal . resetLogHandler ( ) ; } public String getDriverVersion ( ) { return mWifiVendorHal . getDriverVersion ( ) ; } public String getFirmwareVersion ( ) { return mWifiVendorHal . getFirmwareVersion ( ) ; } public static class RingBufferStatus { String name ; int flag ; int ringBufferId ; int ringBufferByteSize ; int verboseLevel ; int writtenBytes ; int readBytes ; int writtenRecords ; // Bit masks for interpreting |flag| public static final int HAS_BINARY_ENTRIES = ( 1 < < 0 ) ; }
",,,"public boolean startLoggingRingBuffer ( int verboseLevel , int flags , int maxInterval , int minDataSize , String ringName ) { return mWifiVendorHal . startLoggingRingBuffer ( verboseLevel , flags , maxInterval , minDataSize , ringName ) ; } public int getSupportedLoggerFeatureSet ( ) { return mWifiVendorHal . getSupportedLoggerFeatureSet ( ) ; } < |startfocus| > < |endfocus| > public boolean resetLogHandler ( ) { return mWifiVendorHal . resetLogHandler ( ) ; } public String getDriverVersion ( ) { return mWifiVendorHal . getDriverVersion ( ) ; } public String getFirmwareVersion ( ) { return mWifiVendorHal . getFirmwareVersion ( ) ; } public static class RingBufferStatus { String name ; int flag ; int ringBufferId ; int ringBufferByteSize ; int verboseLevel ; int writtenBytes ; int readBytes ; int writtenRecords ; // Bit masks for interpreting |flag| public static final int HAS_BINARY_ENTRIES = ( 1 < < 0 ) ;
",,
45,"* limitations under the License . */ package com . android . server . wifi . scanner ; import android . content . Context ; import android . net . wifi . WifiScanner ; import android . os . Handler ; import android . os . Looper ; import android . os . Message ; import android . util . Log ; import com . android . server . wifi . Clock ; import com . android . server . wifi . WifiMonitor ; import com . android . server . wifi . WifiNative ; /* * * WifiScanner implementation that takes advantage of the gscan HAL API * The gscan API is used to perform background scans and wificond is used for oneshot scans . * @see com . android . server . wifi . scanner . WifiScannerImpl for more details on each method . */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler . Callback { private static final String TAG = ""HalWifiScannerImpl"" ; private static final boolean DBG = false ; private final WifiNative mWifiNative ; private final ChannelHelper mChannelHelper ; private final WificondScannerImpl mWificondScannerDelegate ; private final boolean mHalBasedPnoSupported ; public HalWifiScannerImpl ( Context context , WifiNative wifiNative , WifiMonitor wifiMonitor , Looper looper , Clock clock ) {
","* The gscan API is used to perform background scans and wificond is used for oneshot scans .
","* The gscan API is used to perform background scans and wificond is used for onehot scans.
",,,"* The gscan API is used to perform background scans and wifi is used for onehot scans.
",,,"package com . android . server . wifi . scanner ; import android . content . Context ; import android . net . wifi . WifiScanner ; import android . os . Handler ; import android . os . Looper ; import android . os . Message ; import android . util . Log ; import com . android . server . wifi . Clock ; import com . android . server . wifi . WifiMonitor ; import com . android . server . wifi . WifiNative ; /* * * WifiScanner implementation that takes advantage of the gscan HAL API * The gscan API is used to perform background scans and wificond is used for onehot scans . * @see com . android . server . wifi . scanner . WifiScannerImpl for more details on each method . */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler . Callback { private static final String TAG = ""HalWifiScannerImpl"" ; private static final boolean DBG = false ; private final WifiNative mWifiNative ; private final ChannelHelper mChannelHelper ; private final WificondScannerImpl mWificondScannerDelegate ; private final boolean mHalBasedPnoSupported ; public HalWifiScannerImpl ( Context context , WifiNative wifiNative , WifiMonitor wifiMonitor , Looper looper , Clock clock ) { super ( context , wifiMonitor , looper , clock ) ; mWifiNative = wifiNative ; mChannelHelper = new HalChannelHelper ( mWifiNative ) ; mWificondScannerDelegate = new WificondScannerImpl ( context , wifiNative , wifiMonitor , looper , clock ) ; mHalBasedPnoSupported = mWifiNative . isHalPnoSupported ( ) ; } @Override public void cleanup ( ) { mWificondScannerDelegate . cleanup ( ) ; } @Override public boolean getScanCapabilities ( WifiScanner . ScanCapabilities capabilities ) { capabilities . max_scan_cache_size = 0 ; capabilities . max_scan_buckets = mChannelHelper . getMaxNumScanBuckets ( ) ; capabilities . max_ap_cache_per_scan = mChannelHelper . getMaxNumScanCacheEntries ( ) ; capabilities . max_scan_reporting_threshold = mWifiNative . getBgScanCapabilities ( ) . max_scan_reporting_threshold ; capabilities . supported_random_mac_oui = mWifiNative . getSupportedFeatureSet ( ) ; capabilities . max_hotlist_bssids = mWifiNative . getBgScanCapabilities ( ) . max_hotlist_bssids ; capabilities . max_significant_wifi_change_aps = mWifiNative . getBgScanCapabilities ( ) . max_significant_wifi_change_aps ; capabilities . max_b
",,,"private static final String R_ATTR = ""R"" ; // $NON - NLS - 1$ private static final String G_ATTR = ""G"" ; // $NON - NLS - 1$ private static final String B_ATTR = ""B"" ; // $NON - NLS - 1$ private static final String TICK_TAG = ""TICK"" ; // $NON - NLS - 1$ private static final String FILTER_TAG = ""FILTER"" ; // $NON - NLS - 1$ /* * * Saves the given color settings to file . * * @param pathName A file name with path * @param colorSettings An array of color settings to save . */ public static void save ( String pathName , ColorSetting [ ] colorSettings ) { try { DocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactory . newInstance ( ) ; DocumentBuilder documentBuilder = documentBuilderFactory . newDocumentBuilder ( ) ; Document document = documentBuilder . newDocument ( ) ; Element rootElement = document . createElement ( COLOR_SETTINGS_TAG ) ; document . appendChild ( rootElement ) ; for ( ColorSetting colorSetting : colorSettings ) { Element colorSettingElement = document . createElement ( COLOR_SETTING_TAG ) ; // code to add color setting to the document } // code to save the document to file } catch ( Exception e ) { e . printStackTrace ( ) ; } } private static void waitForShadowProjectUpdated ( String parentProjectName ) { for ( int i = 1 ; i < 5000 && ( TmfProjectModelHelper . getShadowProject ( parentProjectName ) . exists ( ) ) ; i *= 2 ) { delay ( i ) ; } } /* * * Step for FirstRunWizard for selecting a color scheme . */ public class SelectThemeStep extends FirstRunWizardStep { private final CustomizeUIThemeStepPanel themePanel ; private final ScopedStateStore . Key < Boolean > myKeyCustomInstall ; public SelectThemeStep ( @NotNull ScopedStateStore . Key < Boolean > keyCustomInstall ) { super ( ""Select UI Theme"" ) ; this . myKeyCustomInstall = keyCustomInstall ; this . themePanel = new CustomizeUIThemeStepPanel ( ) ; } // code for the rest of the class } /* * * WifiScanner implementation that takes advantage of the gscan HAL API * The gscan API is used to perform background scans and wificond is used for onehot scans . * @see com . android . server . wifi . scanner . WifiScannerImpl for more details on each method . */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler . Callback { private static final String TAG = ""HalWifiScanner
",,,"* limitations under the License . */ package com . android . server . wifi . scanner ; import android . content . Context ; import android . net . wifi . WifiScanner ; import android . os . Handler ; import android . os . Looper ; import android . os . Message ; import android . util . Log ; import com . android . server . wifi . Clock ; import com . android . server . wifi . WifiMonitor ; import com . android . server . wifi . WifiNative ; /* * * WifiScanner implementation that takes advantage of the gscan HAL API * The gscan API is used to perform background scans and wificond is used for onehot scans . * @see com . android . server . wifi . scanner . WifiScannerImpl for more details on each method . */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler . Callback { private static final String TAG = ""HalWifiScannerImpl"" ; private static final boolean DBG = false ; private final WifiNative mWifiNative ; private final ChannelHelper mChannelHelper ; private final WificondScannerImpl mWificondScannerDelegate ; private final boolean mHalBasedPnoSupported ; public HalWifiScannerImpl ( Context context , WifiNative wifiNative , WifiMonitor wifiMonitor , Looper looper , Clock clock ) {
",,
54,"public void setLteRsrpBoost ( int lteRsrpBoost ) { mLteRsrpBoost = lteRsrpBoost ;
","public void setLteRsrpBoost ( int lteRsrpBoost ) { mLteRsrpBoost = lteRsrpBoost ;
","public voidsetStringteRsrpOffset(int lteOffset) { mLteRsrpOffset = lteOffset;
",,,"public void setLteRsrpOffset(int lteRsrpOffset) { mLteRsrpOffset = lteRsrpOffset;
",,,"public void setLteRsrpOffset ( int lteRsrpOffset ) { mLteRsrpOffset = lteRsrpOffset ; }
",,,"public void setLteRsrpOffset ( int lteRsrpOffset ) { mLteRsrpOffset = lteRsrpOffset ; }
",,,"< |startfocus| > public void setLteRsrpOffset ( int lteRsrpOffset ) { mLteRsrpOffset = lteRsrpOffset ; < |endfocus| >
",,
58,"public void getFirmwareRoamingInfo ( ) { reset ( mWifiConnectivityHelper ) ; // WifiConnectivityManager is on by default mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ;
","reset ( mWifiConnectivityHelper ) ; // WifiConnectivityManager is on by default
","reset(mWifiConnectivityHelper); verifyGetFirmwareRoamingInfoIsCalledWhenWifiEnabled();
",,,"reset(mWifiConnectivityHelper); verifyGetFirmwareRoamingInfoIsCalledWhenWifiEnabled();
",,,"public void verifyGetFirmwareRoamingInfoIsCalledWhenWifiEnabled ( ) { reset ( mWifiConnectivityHelper ) ; mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ; }
",,,"public void verifyGetFirmwareRoamingInfoIsCalledWhenWifiEnabled ( ) { reset ( mWifiConnectivityHelper ) ; mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ; }
",,,"public void verifyGetFirmwareRoamingInfoIsCalledWhenWifiEnabled ( ) { < |startfocus| > reset ( mWifiConnectivityHelper ) ; < |endfocus| > mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ;
",,
72,"void run ( INetd netd ) throws RemoteException ; } /* * * Blocks until an INetd instance is availabe , and retries until either * the command succeeds or a ServiceSpecificError is thrown . */
","void run ( INetd netd ) throws RemoteException ;
","void run(INetd netd) throws RemoteException;
",,,"void run(INetd netd) throws RemoteException;
",,,"void run ( INetd netd ) throws RemoteException { /* * * Blocks until an INetd instance is available , and retries until either * the command succeeds or a ServiceSpecificError is thrown . */ }
",,,"void run ( INetd netd ) throws RemoteException ; } /* * * Blocks until an INetd instance is availabe , and retries until either * the command succeeds or a ServiceSpecificError is thrown . */
",,,"< |startfocus| > void run ( INetd netd ) throws RemoteException ; < |endfocus| > } /* * * Blocks until an INetd instance is availabe , and retries until either * the command succeeds or a ServiceSpecificError is thrown . */
",,
82,"public void stopLocalOnlyWifiHotspot ( ) { if ( mMode != Mode . LOCAL_HOTSPOT ) { if ( VDBG ) { Log . e ( TAG , ""Local hotspot not running . "" ) ; } return ; } setWifiTethering ( null , false ) ;
","Log . e ( TAG , ""Local hotspot not running . "" ) ;
","Log.e(TAG, ""Attempt to stopLocalOnlyWifiHotspot not running corresponding start."");
",,,"Log.e(TAG, ""Attempt to stopLocalOnlyWifiHotspot not running."");
",,,"public void stopLocalOnlyWifiHotspot ( ) { if ( mMode != Mode . LOCAL_HOTSPOT ) { if ( VDBG ) { Log . e ( TAG , ""Local hotspot not running"" ) ; } return ; } setWifiTethering ( null , false ) ; }
",,,"public void stopLocalOnlyWifiHotspot ( ) { if ( mMode != Mode . LOCAL_HOTSPOT ) { Log . e ( TAG , ""Local hotspot not running . Attempt to stopLocalOnlyWifiHotspot absent corresponding start . "" ) ; return ; } setWifiTethering ( null , false ) ; }
",,,"public void stopLocalOnlyWifiHotspot ( ) { if ( mMode != Mode . LOCAL_HOTSPOT ) { if ( VDBG ) { < |startfocus| > Log . e ( TAG , ""Local hotspot not running ? "" ) ; < |endfocus| > } return ; } setWifiTethering ( null , false ) ;
",,
98,"public static final int ILLEGAL_ARGUMENT = 1200 ; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201 ; // IMS service internal error public static final int INTERNAL_ERROR = 1202 ; // IMS service goes down ( service connection is lost ) public static final int IMS_SERVICE_DOWN = 1203 ; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204 ; // Service unavailable ; by power off public static final int LOCAL_POWER_OFF = 1205 ; // Service unavailable ; by low battery public static final int LOW_BATTERY = 1206 ; // Service unavailable ; by out of service ( data service state ) public static final int NETWORK_NO_SERVICE = 1207 ; /* Service unavailable ; by no LTE coverage * ( VoLTE is not supported even though IMS is registered ) */ public static final int NETWORK_NO_LTE_COVERAGE = 1208 ; /* * Service unavailable ; by located in roaming area */ public static final int NETWORK_ROAMING = 1209 ;
","public static final int LOCAL_POWER_OFF = 1205 ;
","<|del|>
",,,"public static final int POWER_OFF = 1205;
",,,"public static final int LOCAL_ILLEGAL_ARGUMENT = 1200 ; public static final int LOCAL_ILLEGAL_STATE = 1201 ; public static final int LOCAL_INTERNAL_ERROR = 1202 ; public static final int LOCAL_IMS_SERVICE_DOWN = 1203 ; public static final int LOCAL_NO_PENDING_CALL = 1204 ; public static final int LOCAL_POWER_OFF = 1205 ; public static final int LOCAL_LOW_BATTERY = 1206 ; public static final int LOCAL_NETWORK_NO_SERVICE = 1207 ; public static final int LOCAL_NETWORK_NO_LTE_COVERAGE = 1208 ; public static final int LOCAL_NETWORK_ROAMING = 1209 ;
",,,"public static final int ILLEGAL_ARGUMENT = 1200 ; public static final int ILLEGAL_STATE = 1201 ; public static final int INTERNAL_ERROR = 1202 ; public static final int IMS_SERVICE_DOWN = 1203 ; public static final int NO_PENDING_CALL = 1204 ; public static final int POWER_OFF = 1205 ; public static final int LOW_BATTERY = 1206 ; public static final int NETWORK_NO_SERVICE = 1207 ; public static final int NETWORK_NO_LTE_COVERAGE = 1208 ; public static final int NETWORK_ROAMING = 1209 ;
",,,"public static final int ILLEGAL_ARGUMENT = 1200 ; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201 ; // IMS service internal error public static final int INTERNAL_ERROR = 1202 ; // IMS service goes down ( service connection is lost ) public static final int IMS_SERVICE_DOWN = 1203 ; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204 ; // Service unavailable ; by power off < |startfocus| > public static final int LOCAL_POWER_OFF = 1205 ; < |endfocus| > // Service unavailable ; by low battery public static final int LOCAL_LOW_BATTERY = 1206 ; // Service unavailable ; by out of service ( data service state ) public static final int LOCAL_NETWORK_NO_SERVICE = 1207 ; /* Service unavailable ; by no LTE coverage * ( VoLTE is not supported even though IMS is registered ) */ public static final int LOCAL_NETWORK_NO_LTE_COVERAGE = 1208 ; /* * Service unavailable ; by located in roaming area */ public static final int LOCAL_NETWORK_ROAMING = 1209 ;
",,
106,"List < X509Certificate > certPathList ) throws GeneralSecurityException { if ( debug != null ) { debug . println ( ""ForwardBuilder . verifyCert ( SN : "" + Debug . toHexString ( cert . getSerialNumber ( ) ) + ""\n Issuer : "" + cert . getIssuerX500Principal ( ) + "" ) "" + ""\n Subject : "" + cert . getSubjectX500Principal ( ) + "" ) "" ) ; } ForwardState currState = ( ForwardState ) currentState ; // BEGIN Android - removed : Certificate checking // Android doesn't use this mechanism for checking untrusted certificates . // // Don't bother to verify untrusted certificate more . // currState . untrustedChecker . check ( cert , Collections . < String > emptySet ( ) ) ; // END Android - removed : Android doesn't use this mechanism for checking untrusted certificates . /* * check for looping - abort a loop if we encounter the same * certificate twice */ if ( certPathList != null ) { for ( X509Certificate cpListCert : certPathList ) { if ( cert . equals ( cpListCert ) ) { if ( debug != null ) { debug . println ( ""loop detected ! ! "" ) ; }
","// BEGIN Android - removed : Certificate checking // Android doesn't use this mechanism for checking untrusted certificates .
","// BEGIN Android-removed: Android doesn't use this mechanism for checking untrusted certificates.
",,,"// BEGIN Android-removed: Android doesn't use this mechanism for checking untrusted certificates.
",,,"List < X509Certificate > certPathList ) throws GeneralSecurityException { ForwardState currState = ( ForwardState ) currentState ; currState . untrustedChecker . check ( cert , Collections . < String > emptySet ( ) ) ; if ( certPathList != null ) { for ( X509Certificate cpListCert : certPathList ) { if ( cert . equals ( cpListCert ) ) { if ( debug != null ) { debug . println ( ""loop detected ! ! "" ) ; } } } } }
",,,"List < X509Certificate > certPathList ) throws GeneralSecurityException { if ( debug != null ) { debug . println ( ""ForwardBuilder . verifyCert ( SN : "" + Debug . toHexString ( cert . getSerialNumber ( ) ) + ""\n Issuer : "" + cert . getIssuerX500Principal ( ) + "" ) "" + ""\n Subject : "" + cert . getSubjectX500Principal ( ) + "" ) "" ) ; } ForwardState currState = ( ForwardState ) currentState ; currState . untrustedChecker . check ( cert , Collections . < String > emptySet ( ) ) ; if ( certPathList != null ) { for ( X509Certificate cpListCert : certPathList ) { if ( cert . equals ( cpListCert ) ) { if ( debug != null ) { debug . println ( ""loop detected ! ! "" ) ; } throw new CertPathValidatorException ( ""loop detected"" ) ; } } } // rest of the code }
",,,"List < X509Certificate > certPathList ) throws GeneralSecurityException { if ( debug != null ) { debug . println ( ""ForwardBuilder . verifyCert ( SN : "" + Debug . toHexString ( cert . getSerialNumber ( ) ) + ""\n Issuer : "" + cert . getIssuerX500Principal ( ) + "" ) "" + ""\n Subject : "" + cert . getSubjectX500Principal ( ) + "" ) "" ) ; } ForwardState currState = ( ForwardState ) currentState ; < |startfocus| > // BEGIN Android - removed : Android doesn't use this mechanism for checking untrusted certificates . < |endfocus| > // // Don't bother to verify untrusted certificate more . // currState . untrustedChecker . check ( cert , Collections . < String > emptySet ( ) ) ; // END Android - removed : Android doesn't use this mechanism for checking untrusted certificates . /* * check for looping - abort a loop if we encounter the same * certificate twice */ if ( certPathList != null ) { for ( X509Certificate cpListCert : certPathList ) { if ( cert . equals ( cpListCert ) ) { if ( debug != null ) { debug . println ( ""loop detected ! ! "" ) ; }
",,
107,"} public void testScreenLayout ( ) throws Exception { int expectedScreenLayout = computeScreenLayout ( ) ; int expectedSize = expectedScreenLayout & Configuration . SCREENLAYOUT_SIZE_MASK ; int expectedLong = expectedScreenLayout & Configuration . SCREENLAYOUT_LONG_MASK ; // Check that all four orientations report the same configuration value . for ( int i = 0 ; i < ORIENTATIONS . length ; i ++ ) { Activity activity = startOrientationActivity ( ORIENTATIONS [ i ] ) ; if ( activity . isInMultiWindowMode ( ) ) { // activity . setRequestedOrientation has no effect in multiwindow mode . tearDown ( ) ; return ; } Configuration mConfig = activity . getResources ( ) . getConfiguration ( ) ; int actualSize = mConfig . screenLayout & Configuration . SCREENLAYOUT_SIZE_MASK ; int actualLong = mConfig . screenLayout & Configuration . SCREENLAYOUT_LONG_MASK ; assertEquals ( ""Expected screen size value of "" + expectedSize + "" but got "" + actualSize + "" for orientation "" + ORIENTATIONS [ i ] , expectedSize , actualSize ) ; assertEquals ( ""Expected screen long value of "" + expectedLong + "" but got "" + actualLong
","tearDown ( ) ; return ;
","<|del|>
",,,"continue; } else { assertEquals(""Expected screen size value of "" + expectedSize + "" but got "" + actualSize + "" for orientation "" + ORIENTATIONS[i], expectedSize, actualSize);
",,,"public void testScreenLayout ( ) throws Exception { int expectedScreenLayout = computeScreenLayout ( ) ; int expectedSize = expectedScreenLayout & Configuration . SCREENLAYOUT_SIZE_MASK ; int expectedLong = expectedScreenLayout & Configuration . SCREENLAYOUT_LONG_MASK ; for ( int i = 0 ; i < ORIENTATIONS . length ; i ++ ) { Activity activity = startOrientationActivity ( ORIENTATIONS [ i ] ) ; if ( activity . isInMultiWindowMode ( ) ) { teardown ( ) ; return ; } Configuration mConfig = activity . getResources ( ) . getConfiguration ( ) ; int actualSize = mConfig . screenLayout & Configuration . SCREENLAYOUT_SIZE_MASK ; int actualLong = mConfig . screenLayout & Configuration . SCREENLAYOUT_LONG_MASK ; assertEquals ( ""Expected screen size value of "" + expectedSize + "" but got "" + actualSize + "" for orientation "" + ORIENTATIONS [ i ] , expectedSize , actualSize ) ; assertEquals ( ""Expected screen long value of "" + expectedLong + "" but got "" + actualLong , expectedLong , actualLong ) ; } }
",,,"public void testScreenLayout ( ) throws Exception { int expectedScreenLayout = computeScreenLayout ( ) ; int expectedSize = expectedScreenLayout & Configuration . SCREENLAYOUT_SIZE_MASK ; int expectedLong = expectedScreenLayout & Configuration . SCREENLAYOUT_LONG_MASK ; // Check that all four orientations report the same configuration value . for ( int i = 0 ; i < ORIENTATIONS . length ; i ++ ) { Activity activity = startOrientationActivity ( ORIENTATIONS [ i ] ) ; if ( activity . isInMultiWindowMode ( ) ) { // activity . setRequestedOrientation has no effect in multiwindow mode . teardown ( ) ; return ; } Configuration mConfig = activity . getResources ( ) . getConfiguration ( ) ; int actualSize = mConfig . screenLayout & Configuration . SCREENLAYOUT_SIZE_MASK ; int actualLong = mConfig . screenLayout & Configuration . SCREENLAYOUT_LONG_MASK ; assertEquals ( ""Expected screen size value of "" + expectedSize + "" but got "" + actualSize + "" for orientation "" + ORIENTATIONS [ i ] , expectedSize , actualSize ) ; assertEquals ( ""Expected screen long value of "" + expectedLong + "" but got "" + actualLong , expectedLong , actualLong ) ; } assertNoErrors ( ) ; }
",,,"public void testScreenLayout ( ) throws Exception { int expectedScreenLayout = computeScreenLayout ( ) ; int expectedSize = expectedScreenLayout & Configuration . SCREENLAYOUT_SIZE_MASK ; int expectedLong = expectedScreenLayout & Configuration . SCREENLAYOUT_LONG_MASK ; // Check that all four orientations report the same configuration value . for ( int i = 0 ; i < ORIENTATIONS . length ; i ++ ) { Activity activity = startOrientationActivity ( ORIENTATIONS [ i ] ) ; if ( activity . isInMultiWindowMode ( ) ) { // activity . setRequestedOrientation has no effect in multiwindow mode . < |startfocus| > continue ; < |endfocus| > } Configuration mConfig = activity . getResources ( ) . getConfiguration ( ) ; int actualSize = mConfig . screenLayout & Configuration . SCREENLAYOUT_SIZE_MASK ; int actualLong = mConfig . screenLayout & Configuration . SCREENLAYOUT_LONG_MASK ; assertEquals ( ""Expected screen size value of "" + expectedSize + "" but got "" + actualSize + "" for orientation "" + ORIENTATIONS [ i ] , expectedSize , actualSize ) ; assertEquals ( ""Expected screen long value of "" + expectedLong + "" but got "" + actualLong
",,
110,"int connectionState = mStateMachine . getConnectionState ( device ) ; if ( connectionState != BluetoothProfile . STATE_CONNECTED && connectionState != BluetoothProfile . STATE_CONNECTING ) { return false ; } mStateMachine . sendMessage ( HeadsetStateMachine . DISCONNECT , device ) ; return true ; } public List < BluetoothDevice > getConnectedDevices ( ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getConnectedDevices ( ) ; } private List < BluetoothDevice > getDevicesMatchingConnectionStates ( int [ ] states ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getDevicesMatchingConnectionStates ( states ) ; } public int getConnectionState ( BluetoothDevice device ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getConnectionState ( device ) ; } public boolean setPriority ( BluetoothDevice device , int priority ) { enforceCallingOrSelfPermission ( BLUETOOTH_ADMIN_PERM , ""Need BLUETOOTH_ADMIN permission"" ) ; Settings . Global . putInt ( getContentResolver ( ) ,
","< |del| > public BluetoothDevice getCurrentDevice ( ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getCurrentDevice ( ) ; }
","<|del|>
",,,"<|del|>
",,,"int connectionState = mStateMachine . getConnectionState ( device ) ; if ( connectionState == BluetoothProfile . STATE_CONNECTED || connectionState == BluetoothProfile . STATE_CONNECTING ) { mStateMachine . sendMessage ( HeadsetStateMachine . DISCONNECT , device ) ; return true ; } return false ; public List < BluetoothDevice > getConnectedDevices ( ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getConnectedDevices ( ) ; } public BluetoothDevice getCurrentDevice ( ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getCurrentDevice ( ) ; } private List < BluetoothDevice > getDevicesMatchingConnectionStates ( int [ ] states ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getDevicesMatchingConnectionStates ( states ) ; } public int getConnectionState ( BluetoothDevice device ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getConnectionState ( device ) ; } public boolean setPriority ( BluetoothDevice device , int priority ) { enforceCallingOrSelfPermission ( BLUETOOTH_ADMIN_PERM , ""Need BLUETOOTH_ADMIN permission"" ) ; Settings . Global . putInt ( getContentResolver ( ) , . . . ) }
",,,"int connectionState = mStateMachine . getConnectionState ( device ) ; if ( connectionState != BluetoothProfile . STATE_CONNECTED && connectionState != BluetoothProfile . STATE_CONNECTING ) { return false ; } mStateMachine . sendMessage ( HeadsetStateMachine . DISCONNECT , device ) ; return true ; } public List < BluetoothDevice > getConnectedDevices ( ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getConnectedDevices ( ) ; } public BluetoothDevice getCurrentDevice ( ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getCurrentDevice ( ) ; } private List < BluetoothDevice > getDevicesMatchingConnectionStates ( int [ ] states ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getDevicesMatchingConnectionStates ( states ) ; } public int getConnectionState ( BluetoothDevice device ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getConnectionState ( device ) ; } public boolean setPriority ( BluetoothDevice device , int priority ) { enforceCallingOrSelfPermission ( BLUETOOTH_ADMIN_PERM , ""Need BLUETOOTH_ADMIN permission"" ) ; Settings . Global . putInt ( getContentResolver ( ) ,
",,,"int connectionState = mStateMachine . getConnectionState ( device ) ; if ( connectionState != BluetoothProfile . STATE_CONNECTED && connectionState != BluetoothProfile . STATE_CONNECTING ) { return false ; } mStateMachine . sendMessage ( HeadsetStateMachine . DISCONNECT , device ) ; return true ; } public List < BluetoothDevice > getConnectedDevices ( ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getConnectedDevices ( ) ; } < |startfocus| > public BluetoothDevice getCurrentDevice ( ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getCurrentDevice ( ) ; } < |endfocus| > private List < BluetoothDevice > getDevicesMatchingConnectionStates ( int [ ] states ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getDevicesMatchingConnectionStates ( states ) ; } public int getConnectionState ( BluetoothDevice device ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , ""Need BLUETOOTH permission"" ) ; return mStateMachine . getConnectionState ( device ) ; } public boolean setPriority ( BluetoothDevice device , int priority ) { enforceCallingOrSelfPermission ( BLUETOOTH_ADMIN_PERM , ""Need BLUETOOTH_ADMIN permission"" ) ; Settings . Global . putInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) ,
",,
123,"protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; final int dialogType = getIntent ( ) . getIntExtra ( DIALOG_TYPE_KEY , INVALID_PICK ) ; switch ( dialogType ) { case DATA_PICK : case CALLS_PICK : case SMS_PICK : createDialog ( this , dialogType ) . show ( ) ; break ; case PREFERRED_PICK : displayPreferredDialog ( extras . getInt ( PREFERRED_SIM ) ) ; break ; default : throw new IllegalArgumentException ( ""Invalid dialog type "" + dialogType + "" sent . "" ) ; }
","final int dialogType = getIntent ( ) . getIntExtra ( DIALOG_TYPE_KEY , INVALID_PICK ) ;
","final int dialogType = getIntent().getIntExtra(DIALOG_TYPE_KEY, INVALID_PICK);
",,,"final int dialogType = getIntent().getIntExtra(DIALOG_TYPE_KEY, INVALID_PICK);
",,,"protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; final int dialogType = getIntent ( ) . getIntExtra ( DIALOG_TYPE_KEY , INVALID_PICK ) ; switch ( dialogType ) { case DATA_PICK : case CALLS_PICK : case SMS_PICK : createDialog ( this , dialogType ) . show ( ) ; break ; case PREFERRED_PICK : displayPreferredDialog ( getIntent ( ) . getIntExtra ( PREFERRED_SIM , 0 ) ) ; break ; default : throw new IllegalArgumentException ( ""Invalid dialog type "" + dialogType + "" sent . "" ) ; } }
",,,"protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; final int dialogType = getIntent ( ) . getIntExtra ( DIALOG_TYPE_KEY , INVALID_PICK ) ; switch ( dialogType ) { case DATA_PICK : case CALLS_PICK : case SMS_PICK : createDialog ( this , dialogType ) . show ( ) ; break ; case PREFERRED_PICK : displayPreferredDialog ( getIntent ( ) . getIntExtra ( PREFERRED_SIM , 0 ) ) ; break ; default : throw new IllegalArgumentException ( ""Invalid dialog type "" + dialogType + "" sent . "" ) ; } }
",,,"protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; < |startfocus| > final int dialogType = getIntent ( ) . getIntExtra ( DIALOG_TYPE_KEY , INVALID_PICK ) ; < |endfocus| > switch ( dialogType ) { case DATA_PICK : case CALLS_PICK : case SMS_PICK : createDialog ( this , dialogType ) . show ( ) ; break ; case PREFERRED_PICK : displayPreferredDialog ( extras . getInt ( PREFERRED_SIM ) ) ; break ; default : throw new IllegalArgumentException ( ""Invalid dialog type "" + dialogType + "" sent . "" ) ; }
",,
128,"public boolean processMessage ( Message message ) { logStateAndMessage ( message , this ) ; switch ( message . what ) { case WifiMonitor . WPS_SUCCESS_EVENT : // Ignore intermediate success , wait for full connection break ; case WifiMonitor . NETWORK_CONNECTION_EVENT : if ( loadNetworksFromSupplicantAfterWps ( ) ) { replyToMessage ( mSourceMessage , WifiManager . WPS_COMPLETED ) ; } else { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . ERROR ) ; } mSourceMessage . recycle ( ) ; mSourceMessage = null ; deferMessage ( message ) ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_OVERLAP_EVENT : replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . WPS_OVERLAP_ERROR ) ; mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_FAIL_EVENT : // Arg1 has the reason for the failure if ( ( message . arg1 != WifiManager . ERROR ) || ( message . arg2 != 0 ) ) { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , message . arg1 ) ;
","< |del| > mWifiConnectivityManager . forceConnectivityScan ( ) ;
","mWifiConnectivityManager.forceConnectivityScan(); transitionTo(mDisconnectedState);
",,,"<|del|>
",,,"public boolean processMessage ( Message message ) { logStateAndMessage ( message , this ) ; switch ( message . what ) { case WifiMonitor . WPS_SUCCESS_EVENT : // Ignore intermediate success , wait for full connection break ; case WifiMonitor . NETWORK_CONNECTION_EVENT : if ( loadNetworksFromSupplicantAfterWps ( ) ) { replyToMessage ( mSourceMessage , WifiManager . WPS_COMPLETED ) ; mWifiConnectivityManager . forceConnectivityScan ( ) ; } else { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . ERROR ) ; } mSourceMessage . recycle ( ) ; mSourceMessage = null ; deferMessage ( message ) ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_OVERLAP_EVENT : replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . WPS_OVERLAP_ERROR ) ; mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_FAIL_EVENT : // Arg1 has the reason for the failure if ( ( message . arg1 != WifiManager . ERROR ) || ( message . arg2 != 0 ) ) { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , message . arg1 ) ; } mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; } return HANDLED ; }
",,,"public boolean processMessage ( Message message ) { logStateAndMessage ( message , this ) ; switch ( message . what ) { case WifiMonitor . WPS_SUCCESS_EVENT : // Ignore intermediate success , wait for full connection break ; case WifiMonitor . NETWORK_CONNECTION_EVENT : if ( loadNetworksFromSupplicantAfterWps ( ) ) { replyToMessage ( mSourceMessage , WifiManager . WPS_COMPLETED ) ; mWifiConnectivityManager . forceConnectivityScan ( ) ; } else { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . ERROR ) ; } mSourceMessage . recycle ( ) ; mSourceMessage = null ; deferMessage ( message ) ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_OVERLAP_EVENT : replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . WPS_OVERLAP_ERROR ) ; mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_FAIL_EVENT : // Arg1 has the reason for the failure if ( ( message . arg1 != WifiManager . ERROR ) || ( message . arg2 != 0 ) ) { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , message . arg1 ) ; } mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; } }
",,,"public boolean processMessage ( Message message ) { logStateAndMessage ( message , this ) ; switch ( message . what ) { case WifiMonitor . WPS_SUCCESS_EVENT : // Ignore intermediate success , wait for full connection break ; case WifiMonitor . NETWORK_CONNECTION_EVENT : if ( loadNetworksFromSupplicantAfterWps ( ) ) { replyToMessage ( mSourceMessage , WifiManager . WPS_COMPLETED ) ; < |startfocus| > mWifiConnectivityManager . forceConnectivityScan ( ) ; < |endfocus| > } else { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . ERROR ) ; } mSourceMessage . recycle ( ) ; mSourceMessage = null ; deferMessage ( message ) ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_OVERLAP_EVENT : replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . WPS_OVERLAP_ERROR ) ; mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_FAIL_EVENT : // Arg1 has the reason for the failure if ( ( message . arg1 != WifiManager . ERROR ) || ( message . arg2 != 0 ) ) { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , message . arg1 ) ; } else { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . ERROR ) ; } mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_TIMEOUT_EVENT : replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . ERROR ) ; mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; default : return NOT_HANDLED ; } return HANDLED ; }
",,
132,"} public boolean isConnected ( ) { return sc . isConnected ( ) ; } public boolean isBound ( ) { return sc . localAddress ( ) != null ; } public boolean isClosed ( ) { return ! sc . isOpen ( ) ; } public boolean isInputShutdown ( ) { return ! sc . isInputOpen ( ) ; } public boolean isOutputShutdown ( ) { return ! sc . isOutputOpen ( ) ; } /* * * Android - added : for testing and internal use . */ @Override public FileDescriptor getFileDescriptor$ ( ) { return sc . getFD ( ) ; } }
","< |del| >* * @hide internal use only
","<|del|>
",,,"<|del|>
",,,"public boolean isConnected ( ) { return sc . isConnected ( ) ; } public boolean isBound ( ) { return sc . localAddress ( ) != null ; } public boolean isClosed ( ) { return ! sc . isOpen ( ) ; } public boolean isInputShutdown ( ) { return ! sc . isInputOpen ( ) ; } public boolean isOutputShutdown ( ) { return ! sc . isOutputOpen ( ) ; } @Override public FileDescriptor getFileDescriptor$ ( ) { return sc . getFD ( ) ; }
",,,"public boolean isConnected ( ) { return sc . isConnected ( ) ; } public boolean isBound ( ) { return sc . localAddress ( ) != null ; } public boolean isClosed ( ) { return ! sc . isOpen ( ) ; } public boolean isInputShutdown ( ) { return ! sc . isInputOpen ( ) ; } public boolean isOutputShutdown ( ) { return ! sc . isOutputOpen ( ) ; } @Override public FileDescriptor getFileDescriptor$ ( ) { return sc . getFD ( ) ; }
",,,"} public boolean isConnected ( ) { return sc . isConnected ( ) ; } public boolean isBound ( ) { return sc . localAddress ( ) != null ; } public boolean isClosed ( ) { return ! sc . isOpen ( ) ; } public boolean isInputShutdown ( ) { return ! sc . isInputOpen ( ) ; } public boolean isOutputShutdown ( ) { return ! sc . isOutputOpen ( ) ; } /* * * Android - added : for testing and internal use . < |startfocus| > * * internal use only < |endfocus| > */ @Override public FileDescriptor getFileDescriptor$ ( ) { return sc . getFD ( ) ; } }
",,
133,"kage libcore . java . nio . file . spi ; import org . junit . Test ; import java . nio . file . Paths ; import java . nio . file . spi . FileTypeDetector ; import static org . junit . Assert . assertEquals ; public class FileTypeDetectorTest { @Test public void test_probeFileType ( ) throws Exception { FileTypeDetector defaultFileTypeDetector = sun . nio . fs . DefaultFileTypeDetector . create ( ) ; // The method uses file extensions to deduce mime type , therefore , it doesn't check for // file existence . assertEquals ( ""text / plain"" , defaultFileTypeDetector . probeContentType ( Paths . get ( ""file . txt"" ) ) ) ; assertEquals ( ""text / x - java"" , defaultFileTypeDetector . probeContentType ( Paths . get ( ""file . java"" ) ) ) ; } }
","FileTypeDetector defaultFileTypeDetector = sun . nio . fs . DefaultFileTypeDetector . create ( ) ; // The method uses file extensions to deduce mime type , therefore , it doesn't check for // file existence .
","FileTypeDetector defaultFileTypeDetector = sun.nio.fs.DefaultFileTypeDetector.create(); // this works without actual files because it uses the extensions to deduce mime type
",,,"FileTypeDetector defaultFileTypeDetector = FileTypeDetector.create(Paths.get(""file.txt""), FileTypeDetector.MIME_TYPE_TEXT, FileTypeDetector.MIME_TYPE_JAVA);
",,,"import org . junit . Test ; import java . nio . file . Paths ; import java . nio . file . spi . FileTypeDetector ; import static org . junit . Assert . assertEquals ; public class FileTypeDetectorTest { /* * * This test works without actual files because it uses their extensions to deduce mime type */ @Test public void test_probeFileType ( ) throws Exception { FileTypeDetector defaultFileTypeDetector = sun . nio . fs . DefaultFileTypeDetector . create ( ) ; assertEquals ( ""text / plain"" , defaultFileTypeDetector . probeContentType ( Paths . get ( ""file . txt"" ) ) ) ; assertEquals ( ""text / x - java"" , defaultFileTypeDetector . probeContentType ( Paths . get ( ""file . java"" ) ) ) ; } }
",,,"package libcore . java . nio . file . spi ; import org . junit . Test ; import java . nio . file . Paths ; import java . nio . file . spi . FileTypeDetector ; import static org . junit . Assert . assertEquals ; public class FileTypeDetectorTest { @Test public void test_probeFileType ( ) throws Exception { FileTypeDetector defaultFileTypeDetector = sun . nio . fs . DefaultFileTypeDetector . create ( ) ; assertEquals ( ""text / plain"" , defaultFileTypeDetector . probeContentType ( Paths . get ( ""file . txt"" ) ) ) ; assertEquals ( ""text / x - java"" , defaultFileTypeDetector . probeContentType ( Paths . get ( ""file . java"" ) ) ) ; } }
",,,"package libcore . java . nio . file . spi ; import org . junit . Test ; import java . nio . file . Paths ; import java . nio . file . spi . FileTypeDetector ; import static org . junit . Assert . assertEquals ; public class FileTypeDetectorTest { @Test public void test_probeFileType ( ) throws Exception { < |startfocus| > FileTypeDetector defaultFileTypeDetector = sun . nio . fs . DefaultFileTypeDetector . create ( ) ; < |endfocus| > assertEquals ( ""text / plain"" , defaultFileTypeDetector . probeContentType ( Paths . get ( ""file . txt"" ) ) ) ; assertEquals ( ""text / x - java"" , defaultFileTypeDetector . probeContentType ( Paths . get ( ""file . java"" ) ) ) ; } }
",,
137,"when ( mClock . getElapsedSinceBootMillis ( ) ) . thenReturn ( SystemClock . elapsedRealtime ( ) + WifiConnectivityManager . BSSID_BLACKLIST_EXPIRE_TIME_MS ) ; mWifiConnectivityManager . forceConnectivityScan ( ) ; assertFalse ( mWifiConnectivityManager . isBssidDisabled ( bssid ) ) ; } /* * * When WifiConnectivityManager is on and Wifi client mode is enabled , framework * queries firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability . * * Expected behavior : WifiConnectivityManager#setWifiEnabled calls into * WifiConnectivityHelper#getFirmwareRoamingInfo */ @Test public void verifyGetFirmwareRoamingInfoIsCalledWhenEnableWiFiAndWcmOn ( ) { reset ( mWifiConnectivityHelper ) ; // WifiConnectivityManager is on by default mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ; } /* * * When WifiConnectivityManager is off , verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode . * * Expected behavior : WifiConnectivityManager#setWifiEnabled does not call into * WifiConnectivityHelper#getFirmwareRoamingIinfo
","* WifiConnectivityHelper#getFirmwareRoamingInfo
","* WifiConnectivityHelper#getFirmwareRoamingIinfo
",,,"* WifiConnectivityHelper#getFirmwareRoamingInfo
",,,"when ( mClock . getElapsedSinceBootMillis ( ) ) . thenReturn ( SystemClock . elapsedRealtime ( ) + WifiConnectivityManager . BSSID_BLACKLIST_EXPIRE_TIME_MS ) ; mWifiConnectivityManager . forceConnectivityScan ( ) ; assertFalse ( mWifiConnectivityManager . isBssidDisabled ( bssid ) ) ; @Test public void verifyGetFirmwareRoamingInfoIsCalledWhenEnableWiFiAndWcmOn ( ) { reset ( mWifiConnectivityHelper ) ; mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ; } @Test public void verifyFirmwareRoamingInfoNotCalledWhenWcmOff ( ) { reset ( mWifiConnectivityHelper ) ; mWifiConnectivityManager . setWifiEnabled ( false ) ; verify ( mWifiConnectivityHelper , never ( ) ) . getFirmwareRoamingInfo ( ) ; }
",,,"when ( mClock . getElapsedSinceBootMillis ( ) ) . thenReturn ( SystemClock . elapsedRealtime ( ) + WifiConnectivityManager . BSSID_BLACKLIST_EXPIRE_TIME_MS ) ; mWifiConnectivityManager . forceConnectivityScan ( ) ; assertFalse ( mWifiConnectivityManager . isBssidDisabled ( bssid ) ) ; } /* * * When WifiConnectivityManager is on and Wifi client mode is enabled , framework * queries firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability . * * Expected behavior : WifiConnectivityManager#setWifiEnabled calls into * WifiConnectivityHelper#getFirmwareRoamingInfo */ @Test public void verifyGetFirmwareRoamingInfoIsCalledWhenEnableWiFiAndWcmOn ( ) { reset ( mWifiConnectivityHelper ) ; // WifiConnectivityManager is on by default mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ; } /* * * When WifiConnectivityManager is off , verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode . * * Expected behavior : WifiConnectivityManager#setWifiEnabled does not call into * WifiConnectivityHelper#getFirmwareRoamingIinfo */ @Test public void verifyGetFirmwareRoamingInfoIsNotCalledWhenEnableWiFiAndWcmOff ( ) { reset ( mWifiConnectivityHelper ) ; mWifiConnectivityManager . setWifiEnabled ( false ) ; verify ( mWifiConnectivityHelper , never ( ) ) . getFirmwareRoamingInfo ( ) ; }
",,,"when ( mClock . getElapsedSinceBootMillis ( ) ) . thenReturn ( SystemClock . elapsedRealtime ( ) + WifiConnectivityManager . BSSID_BLACKLIST_EXPIRE_TIME_MS ) ; mWifiConnectivityManager . forceConnectivityScan ( ) ; assertFalse ( mWifiConnectivityManager . isBssidDisabled ( bssid ) ) ; } /* * * When WifiConnectivityManager is on and Wifi client mode is enabled , framework * queries firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability . * * Expected behavior : WifiConnectivityManager#setWifiEnabled calls into < |startfocus| > * WifiConnectivityHelper#getFirmwareRoamingInfo < |endfocus| > */ @Test public void verifyGetFirmwareRoamingInfoIsCalledWhenEnableWiFiAndWcmOn ( ) { reset ( mWifiConnectivityHelper ) ; // WifiConnectivityManager is on by default mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ; } /* * * When WifiConnectivityManager is off , verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode . * * Expected behavior : WifiConnectivityManager#setWifiEnabled does not call into * WifiConnectivityHelper#getFirmwareRoamingInfo
",,
155,"* * All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID . Ie calling * getPhoneId ( DEFAULT_SUB_ID ) will return the same as getPhoneId ( getDefaultSubId ( ) ) . * * Finally , any getters which perform the mapping between subscriptions , slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID . All other getters * will fail and return the appropriate error value . Ie calling getSlotIndex ( INVALID_SUBSCRIPTION_ID ) * will return INVALID_SLOT_ID and calling getSubInfoForSubscriber ( INVALID_SUBSCRIPTION_ID ) * will return null . * */ public class SubscriptionController extends ISub . Stub { static final String LOG_TAG = ""SubscriptionController"" ; static final boolean DBG = true ; static final boolean VDBG = false ; static final int MAX_LOCAL_LOG_LINES = 500 ; // TODO : Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog ( MAX_LOCAL_LOG_LINES ) ; /* * * Copied from android . util . LocalLog with flush ( ) adding flush and line number
","* will fail and return the appropriate error value . Ie calling getSlotIndex ( INVALID_SUBSCRIPTION_ID )
","* will fail and return the appropriate error value. Ie calling getS SlotIndex(INVALID_SUBSCRIPTION_ID)
",,,"* will fail and return the appropriate error value. Ie calling getSlotIndex(INVALID_SUBSCRIPTION_ID)
",,,"public class SubscriptionController extends ISub . Stub { static final String LOG_TAG = ""SubscriptionController"" ; static final boolean DBG = true ; static final boolean VDBG = false ; static final int MAX_LOCAL_LOG_LINES = 500 ; private ScLocalLog mLocalLog = new ScLocalLog ( MAX_LOCAL_LOG_LINES ) ; /* * * All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID . * I . e . calling getPhoneId ( DEFAULT_SUB_ID ) will return the same as getPhoneId ( getDefaultSubId ( ) ) . * Finally , any getters which perform the mapping between subscriptions , slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID . All other getters * will fail and return the appropriate error value . I . e . calling getSlotId ( INVALID_SUBSCRIPTION_ID ) * will return INVALID_SLOT_ID and calling getSubInfoForSubscriber ( INVALID_SUBSCRIPTION_ID ) * will return null . */ public int getSlotIndex ( int slotId ) { if ( slotId == SubscriptionManager . DEFAULT_SLOT_ID ) { return getDefaultSlotIndex ( ) ; } else if ( slotId == SubscriptionManager . INVALID_SLOT_ID ) { return SubscriptionManager . INVALID_SLOT_INDEX ; } else { return getSlotIndexInternal ( slotId ) ; } } private int getSlotIndexInternal ( int slotId ) { int [ ] allSlots = getAllSlots ( ) ; for ( int i = 0 ; i < allSlots . length ; i ++ ) { if ( allSlots [ i ] == slotId ) { return i ; } } return SubscriptionManager . INVALID_SLOT_INDEX ; } public int getPhoneId ( int subId ) { if ( subId == SubscriptionManager . DEFAULT_SUBSCRIPTION_ID ) { return getDefaultPhoneId ( ) ; } else if ( subId == SubscriptionManager . INVALID_SUBSCRIPTION_ID ) { return SubscriptionManager . INVALID_PHONE_INDEX ; } else { return getPhoneIdInternal ( subId ) ; } } private int getPhoneIdInternal ( int subId ) { int slotId = getSlotId ( subId ) ; if ( slotId == SubscriptionManager . INVALID_SLOT_ID ) { return SubscriptionManager . INVALID_PHONE_INDEX ; } else { return getPhoneIdFromSlot ( slotId ) ; } } public SubscriptionInfo getActiveSubscriptionInfo ( int subId ) { if ( subId == Subscription
",,,"* All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID . Ie calling getPhoneId ( DEFAULT_SUB_ID ) will return the same as getPhoneId ( getDefaultSubId ( ) ) . * Finally , any getters which perform the mapping between subscriptions , slots and phones will return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID . All other getters will fail and return the appropriate error value . Ie calling getSlotId ( INVALID_SUBSCRIPTION_ID ) will return INVALID_SLOT_ID and calling getSubInfoForSubscriber ( INVALID_SUBSCRIPTION_ID ) will return null . */ public class SubscriptionController extends ISub . Stub { static final String LOG_TAG = ""SubscriptionController"" ; static final boolean DBG = true ; static final boolean VDBG = false ; static final int MAX_LOCAL_LOG_LINES = 500 ; // TODO : Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog ( MAX_LOCAL_LOG_LINES ) ; /* * * Copied from android . util . LocalLog with flush ( ) adding flush and line number */ public class ScLocalLog { // implementation details } // Rest of the code }
",,,"* * All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID . Ie calling * getPhoneId ( DEFAULT_SUB_ID ) will return the same as getPhoneId ( getDefaultSubId ( ) ) . * * Finally , any getters which perform the mapping between subscriptions , slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID . All other getters < |startfocus| > * will fail and return the appropriate error value . Ie calling getSlotId ( INVALID_SUBSCRIPTION_ID ) < |endfocus| > * will return INVALID_SLOT_ID and calling getSubInfoForSubscriber ( INVALID_SUBSCRIPTION_ID ) * will return null . * */ public class SubscriptionController extends ISub . Stub { static final String LOG_TAG = ""SubscriptionController"" ; static final boolean DBG = true ; static final boolean VDBG = false ; static final int MAX_LOCAL_LOG_LINES = 500 ; // TODO : Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog ( MAX_LOCAL_LOG_LINES ) ; /* * * Copied from android . util . LocalLog with flush ( ) adding flush and line number * * @hide */ private static class ScLocalLog { private ArrayList < String > mLines = new ArrayList < String > ( ) ; private int mMaxLines = MAX_LOCAL_LOG_LINES ;
",,
170,"private boolean isInvalidSlotId ( int slotIndex ) { if ( slotIndex < 0 || slotIndex >= mSlotIndexToSubId . length ) return true ; return false ;
","private boolean isInvalidSlotId ( int slotIndex ) { if ( slotIndex < 0 || slotIndex >= mSlotIndexToSubId . length ) return true ;
","private boolean isInvalidSlotId(int slotIdx) { if (slotIdx < 0 || slotIdx >= mSlotIdxToSubId.length) return true;
",,,"private boolean isInvalidSlotId(int slotIdx) { if (slotIdx < 0 || slotIdx >= mSlotIdxToSubId.length) return true;
",,,"private boolean isSlotIndexInvalid ( int slotIndex ) { if ( slotIndex < 0 || slotIndex >= mSlotIndexToSubId . length ) { return true ; } return false ; }
",,,"private boolean isInvalidSlotId ( int slotIdx ) { if ( slotIdx < 0 || slotIdx >= mSlotIdxToSubId . length ) return true ; return false ; }
",,,"< |startfocus| > private boolean isInvalidSlotId ( int slotIdx ) { if ( slotIdx < 0 || slotIdx >= mSlotIdxToSubId . length ) return true ; return false ; < |endfocus| >
",,
173,"* * @param subId The subscription ID * @return true if the network for the subscription is roaming , false otherwise */ public boolean isNetworkRoaming ( int subId ) { final int phoneId = getPhoneId ( subId ) ; if ( phoneId < 0 ) { // What else can we do ? return false ; } return TelephonyManager . getDefault ( ) . isNetworkRoaming ( subId ) ; } /* * * Returns a constant indicating the state of sim for the slot index . * * @param slotIndex * * { @See TelephonyManager#SIM_STATE_UNKNOWN } * { @See TelephonyManager#SIM_STATE_ABSENT } * { @See TelephonyManager#SIM_STATE_PIN_REQUIRED } * { @See TelephonyManager#SIM_STATE_PUK_REQUIRED } * { @See TelephonyManager#SIM_STATE_NETWORK_LOCKED } * { @See TelephonyManager#SIM_STATE_READY } * { @See TelephonyManager#SIM_STATE_NOT_READY } * { @See TelephonyManager#SIM_STATE_PERM_DISABLED } * { @See TelephonyManager#SIM_STATE_CARD_IO_ERROR } * * { @hide } */
","* Returns a constant indicating the state of sim for the slot index .
","* Returns a constant indicating the state of sim for the slot idx.
",,,"* Returns a constant indicating the state of sim for the slot idx.
",,,"public boolean isSubscriptionNetworkRoaming ( int subscriptionId ) { final int phoneId = getPhoneId ( subscriptionId ) ; if ( phoneId < 0 ) { return false ; } return TelephonyManager . getDefault ( ) . isNetworkRoaming ( subscriptionId ) ; } /* * * Returns a constant indicating the state of the SIM card for the given slot index . * * @param slotIndex The slot index of the SIM card . * @return One of the following constants : * { @link TelephonyManager#SIM_STATE_UNKNOWN } , * { @link TelephonyManager#SIM_STATE_ABSENT } , * { @link TelephonyManager#SIM_STATE_PIN_REQUIRED } , * { @link TelephonyManager#SIM_STATE_PUK_REQUIRED } , * { @link TelephonyManager#SIM_STATE_NETWORK_LOCKED } , * { @link TelephonyManager#SIM_STATE_READY } , * { @link TelephonyManager#SIM_STATE_NOT_READY } , * { @link TelephonyManager#SIM_STATE_PERM_DISABLED } , * { @link TelephonyManager#SIM_STATE_CARD_IO_ERROR } . * @hide */
",,,"public boolean isNetworkRoaming ( int subId ) { final int phoneId = getPhoneId ( subId ) ; if ( phoneId < 0 ) { return false ; } return TelephonyManager . getDefault ( ) . isNetworkRoaming ( subId ) ; } public int getSimState ( int slotIndex ) { return TelephonyManager . getDefault ( ) . getSimState ( slotIndex ) ; }
",,,"* * @param subId The subscription ID * @return true if the network for the subscription is roaming , false otherwise */ public boolean isNetworkRoaming ( int subId ) { final int phoneId = getPhoneId ( subId ) ; if ( phoneId < 0 ) { // What else can we do ? return false ; } return TelephonyManager . getDefault ( ) . isNetworkRoaming ( subId ) ; } /* * < |startfocus| > * Returns a constant indicating the state of sim for the slot idx . < |endfocus| > * * @param slotIndex * * { @See TelephonyManager#SIM_STATE_UNKNOWN } * { @See TelephonyManager#SIM_STATE_ABSENT } * { @See TelephonyManager#SIM_STATE_PIN_REQUIRED } * { @See TelephonyManager#SIM_STATE_PUK_REQUIRED } * { @See TelephonyManager#SIM_STATE_NETWORK_LOCKED } * { @See TelephonyManager#SIM_STATE_READY } * { @See TelephonyManager#SIM_STATE_NOT_READY } * { @See TelephonyManager#SIM_STATE_PERM_DISABLED } * { @See TelephonyManager#SIM_STATE_CARD_IO_ERROR } * * { @hide } */
",,
176,"MESSAGE_FORMAT , MESSAGE_PRIORITY , ETWS_WARNING_TYPE , CMAS_MESSAGE_CLASS , CMAS_CATEGORY , CMAS_RESPONSE_TYPE , CMAS_SEVERITY , CMAS_URGENCY , CMAS_CERTAINTY } ; } /* * * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri . parse ( ""content :/ / service - state / "" ) ; /* * * Used to push and receive updates to a field in the ServiceState for a given subId * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId ( String field , int subId ) {
","< |del| >/ ** * The MIME - type of { @link #CONTENT_URI } . */ public static final String CONTENT_TYPE = ""vnd . android . cursor . dir / service_state"" ;
","<|del|>
",,,"<|del|>
",,,"public class Constants { public static final String [ ] MESSAGE_FORMAT = { ""3gpp"" , ""3gpp2"" , ""emergency"" , ""etws"" , ""default"" } ; public static final String [ ] MESSAGE_PRIORITY = { ""emergency"" , ""high"" , ""normal"" , ""low"" } ; public static final String [ ] ETWS_WARNING_TYPE = { ""earthquake"" , ""tsunami"" , ""earthquake_and_tsunami"" , ""test"" , ""other"" } ; public static final String [ ] CMAS_MESSAGE_CLASS = { ""class1"" , ""class2"" , ""class3"" , ""class4"" } ; public static final String [ ] CMAS_CATEGORY = { ""geo"" , ""met"" , ""safety"" , ""security"" , ""rescue"" , ""fire"" , ""health"" , ""env"" , ""transport"" , ""infrastructure"" , ""other"" } ; public static final String [ ] CMAS_RESPONSE_TYPE = { ""shelter"" , ""evacuate"" , ""prepare"" , ""execute"" , ""monitor"" , ""assess"" , ""none"" } ; public static final String [ ] CMAS_SEVERITY = { ""extreme"" , ""severe"" , ""moderate"" , ""minor"" , ""unknown"" } ; public static final String [ ] CMAS_URGENCY = { ""immediate"" , ""expected"" , ""future"" , ""past"" , ""unknown"" } ; public static final String [ ] CMAS_CERTAINTY = { ""observed"" , ""likely"" , ""unlikely"" , ""unknown"" } ; /* * * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri . parse ( ""content :/ / service - state / "" ) ; /* * * The MIME - type of { @link #CONTENT_URI } . */ public static final String CONTENT_TYPE = ""vnd . android . cursor . dir / service_state"" ; /* * * Used to push and receive updates to a field in the ServiceState for a given subId * * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId ( String field , int subId ) { return CONTENT_URI . buildUpon ( ) . appendPath ( field ) . appendPath ( Integer . toString ( subId ) ) . build ( ) ; } } }
",,,"public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri . parse ( ""content :/ / service - state / "" ) ; public static final String CONTENT_TYPE = ""vnd . android . cursor . dir / service_state"" ; public static Uri getUriForSubId ( String field , int subId ) { // Used to push and receive updates to a field in the ServiceState for a given subId return Uri . withAppendedPath ( CONTENT_URI , field + "" / "" + subId ) ; } }
",,,"MESSAGE_FORMAT , MESSAGE_PRIORITY , ETWS_WARNING_TYPE , CMAS_MESSAGE_CLASS , CMAS_CATEGORY , CMAS_RESPONSE_TYPE , CMAS_SEVERITY , CMAS_URGENCY , CMAS_CERTAINTY } ; } /* * * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri . parse ( ""content :/ / service - state / "" ) ; < |startfocus| > /* * * The MIME - type of { @link #CONTENT_URI } . */ public static final String CONTENT_TYPE = ""vnd . android . cursor . dir / service_state"" ; < |endfocus| > /* * * Used to push and receive updates to a field in the ServiceState for a given subId * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId ( String field , int subId ) {
",,
177,"CMAS_RESPONSE_TYPE , CMAS_SEVERITY , CMAS_URGENCY , CMAS_CERTAINTY } ; } /* * * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri . parse ( ""content :/ / service - state / "" ) ; /* * * Used to push and receive updates to a field in the ServiceState for a given subId * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId ( String field , int subId ) { return CONTENT_URI . buildUpon ( ) . appendEncodedPath ( String . valueOf ( subId ) ) . appendEncodedPath ( field ) . build ( ) ; }
","< |del| >/ ** * The MIME - type of { @link #CONTENT_URI } . */ public static final String CONTENT_TYPE = ""vnd . android . cursor . dir / service_state"" ;
","<|del|>
",,,"<|del|>
",,,"public static final class CmasTable { public static final Uri CONTENT_URI = Uri . parse ( ""content :/ / cmas / "" ) ; public static final String CONTENT_TYPE = ""vnd . android . cursor . dir / cmas"" ; public static final String CMAS_RESPONSE_TYPE = ""response_type"" ; public static final String CMAS_SEVERITY = ""severity"" ; public static final String CMAS_URGENCY = ""urgency"" ; public static final String CMAS_CERTAINTY = ""certainty"" ; } public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri . parse ( ""content :/ / service - state / "" ) ; public static final String CONTENT_TYPE = ""vnd . android . cursor . dir / service_state"" ; public static Uri getUriForSubId ( String field , int subId ) { return CONTENT_URI . buildUpon ( ) . appendEncodedPath ( String . valueOf ( subId ) ) . appendEncodedPath ( field ) . build ( ) ; } }
",,,"CMAS_RESPONSE_TYPE , CMAS_SEVERITY , CMAS_URGENCY , CMAS_CERTAINTY } ; } public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri . parse ( ""content :/ / service - state / "" ) ; public static final String CONTENT_TYPE = ""vnd . android . cursor . dir / service_state"" ; public static Uri getUriForSubId ( String field , int subId ) { return CONTENT_URI . buildUpon ( ) . appendEncodedPath ( String . valueOf ( subId ) ) . appendEncodedPath ( field ) . build ( ) ; }
",,,"CMAS_RESPONSE_TYPE , CMAS_SEVERITY , CMAS_URGENCY , CMAS_CERTAINTY } ; } /* * * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri . parse ( ""content :/ / service - state / "" ) ; /* * * The MIME - type of { @link #CONTENT_URI } . */ public static final String CONTENT_TYPE = ""vnd . android . cursor . dir / service_state"" ; /* * * Used to push and receive updates to a field in the ServiceState for a given subId * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId ( String field , int subId ) { return CONTENT_URI . buildUpon ( ) . appendEncodedPath ( String . valueOf ( subId ) ) . appendEncodedPath ( field ) . build ( ) ; }
",,
179,"+ something . getClass ( ) . getName ( ) + "" to byte array ! "" ) ; } } public AdvertiseData buildAdvData ( JSONObject params ) throws Exception { AdvertiseData . Builder builder = new AdvertiseData . Builder ( ) ; Iterator < String > keys = params . keys ( ) ; while ( keys . hasNext ( ) ) { String key = keys . next ( ) ; /* * Python doesn't have multi map , if advertise data should repeat use * serviceUuid , serviceUuid2 , serviceUuid3 . . . . For that use ""startsWith"" */ if ( key . startsWith ( ""manufacturerData"" ) ) { JSONArray manuf = params . getJSONArray ( key ) ; int manufId = manuf . getInt ( 0 ) ; byte [ ] data = somethingToByteArray ( manuf . get ( 1 ) ) ; builder . addManufacturerData ( manufId , data ) ; } else if ( key . startsWith ( ""serviceData"" ) ) { JSONArray serDat = params . getJSONArray ( key ) ; ParcelUuid uuid = ParcelUuid . fromString ( serDat . getString ( 0 ) ) ; byte [ ] data = somethingToByteArray ( serDat . get ( 1 ) ) ; builder . addServiceData ( uuid , data ) ; } else if ( key . startsWith ( ""serviceUuid"" ) ) {
","/* * Python doesn't have multi map , if advertise data should repeat use * serviceUuid , serviceUuid2 , serviceUuid3 . . . . For that use ""startsWith"" */
","/** * python don't have multi map, if advertise data should repeat use serviceUuid, * serviceUuid2, serviceUuid3... . For that use ""startsWith"" */
",,,"/** * python don't have multi map, if advertise data should repeat use serviceUuid, * serviceUuid2, serviceUuid3... . For that use ""startsWith"" */
",,,"public AdvertiseData buildAdvData ( JSONObject params ) throws Exception { AdvertiseData . Builder builder = new AdvertiseData . Builder ( ) ; Iterator < String > keys = params . keys ( ) ; while ( keys . hasNext ( ) ) { String key = keys . next ( ) ; if ( key . startsWith ( ""manufacturerData"" ) ) { JSONArray manuf = params . getJSONArray ( key ) ; int manufId = manuf . getInt ( 0 ) ; byte [ ] data = somethingToByteArray ( manuf . get ( 1 ) ) ; builder . addManufacturerData ( manufId , data ) ; } else if ( key . startsWith ( ""serviceData"" ) ) { JSONArray serDat = params . getJSONArray ( key ) ; ParcelUuid uuid = ParcelUuid . fromString ( serDat . getString ( 0 ) ) ; byte [ ] data = somethingToByteArray ( serDat . get ( 1 ) ) ; builder . addServiceData ( uuid , data ) ; } else if ( key . startsWith ( ""serviceUuid"" ) ) { /* python don't have multi map , if advertise data should repeat use serviceUuid , * serviceUuid2 , serviceUuid3 . . . . For that use ""startsWith"" */ ParcelUuid uuid = ParcelUuid . fromString ( params . getString ( key ) ) ; builder . addServiceUuid ( uuid ) ; } } return builder . build ( ) ; }
",,,"+ something . getClass ( ) . getName ( ) + "" to byte array ! "" ) ; } } public AdvertiseData buildAdvData ( JSONObject params ) throws Exception { AdvertiseData . Builder builder = new AdvertiseData . Builder ( ) ; Iterator < String > keys = params . keys ( ) ; while ( keys . hasNext ( ) ) { String key = keys . next ( ) ; if ( key . startsWith ( ""manufacturerData"" ) ) { JSONArray manuf = params . getJSONArray ( key ) ; int manufId = manuf . getInt ( 0 ) ; byte [ ] data = somethingToByteArray ( manuf . get ( 1 ) ) ; builder . addManufacturerData ( manufId , data ) ; } else if ( key . startsWith ( ""serviceData"" ) ) { JSONArray serDat = params . getJSONArray ( key ) ; ParcelUuid uuid = ParcelUuid . fromString ( serDat . getString ( 0 ) ) ; byte [ ] data = somethingToByteArray ( serDat . get ( 1 ) ) ; builder . addServiceData ( uuid , data ) ; } else if ( key . startsWith ( ""serviceUuid"" ) ) {
",,,"+ something . getClass ( ) . getName ( ) + "" to byte array ! "" ) ; } } public AdvertiseData buildAdvData ( JSONObject params ) throws Exception { AdvertiseData . Builder builder = new AdvertiseData . Builder ( ) ; Iterator < String > keys = params . keys ( ) ; while ( keys . hasNext ( ) ) { String key = keys . next ( ) ; < |startfocus| > /* * python don't have multi map , if advertise data should repeat use serviceUuid , * serviceUuid2 , serviceUuid3 . . . . For that use ""startsWith"" */ < |endfocus| > if ( key . startsWith ( ""manufacturerData"" ) ) { JSONArray manuf = params . getJSONArray ( key ) ; int manufId = manuf . getInt ( 0 ) ; byte [ ] data = somethingToByteArray ( manuf . get ( 1 ) ) ; builder . addManufacturerData ( manufId , data ) ; } else if ( key . startsWith ( ""serviceData"" ) ) { JSONArray serDat = params . getJSONArray ( key ) ; ParcelUuid uuid = ParcelUuid . fromString ( serDat . getString ( 0 ) ) ; byte [ ] data = somethingToByteArray ( serDat . get ( 1 ) ) ; builder . addServiceData ( uuid , data ) ; } else if ( key . startsWith ( ""serviceUuid"" ) ) { < |startfocus| > /* * python don't have multi map , if advertise data should repeat use serviceUuid , * serviceUuid2 , serviceUuid3 . . . . For that use ""startsWith"" */ < |endfocus| >
",,
193,"// Mock the HeadsetService when ( mockServiceFactory . getHeadsetService ( ) ) . thenReturn ( mockHeadsetService ) ; when ( mockHeadsetService . getPriority ( device ) ) . thenReturn ( BluetoothProfile . PRIORITY_UNDEFINED ) ; // Mock the A2DP service when ( mockServiceFactory . getA2dpService ( ) ) . thenReturn ( mockA2dpService ) ; when ( mockA2dpService . getPriority ( device ) ) . thenReturn ( BluetoothProfile . PRIORITY_UNDEFINED ) ; // Mock the looper when ( mockAdapterService . getMainLooper ( ) ) . thenReturn ( mHandlerThread . getLooper ( ) ) ; // Tell the AdapterService that it is a mock ( see isMock documentation ) when ( mockAdapterService . isMock ( ) ) . thenReturn ( true ) ; PhonePolicy phPol = new PhonePolicy ( mockAdapterService , mockServiceFactory ) ; // Get the broadcast receiver to inject events . BroadcastReceiver injector = phPol . getBroadcastReceiver ( ) ; // Inject an event for UUIDs updated for a remote device with only HFP enabled Intent intent = new Intent ( BluetoothDevice . ACTION_UUID ) ; intent . putExtra ( BluetoothDevice . EXTRA_DEVICE , device ) ; ParcelUuid [ ] uuids = new ParcelUuid [ 2 ] ; uuids [ 0 ] = BluetoothUuid . Handsfree ; uuids [ 1 ] = BluetoothUuid . AudioSink ;
","// Tell the AdapterService that it is a mock ( see isMock documentation )
","// Tell the adapterservice that it is a mock (see isMock documentation)
",,,"// Tell the adapterservice that it is a mock (see isMock documentation)
",,,"// Mock the HeadsetService when ( mockServiceFactory . getHeadsetService ( ) ) . thenReturn ( mockHeadsetService ) ; when ( mockHeadsetService . getPriority ( device ) ) . thenReturn ( BluetoothProfile . PRIORITY_UNDEFINED ) ; // Mock the A2DP service when ( mockServiceFactory . getA2dpService ( ) ) . thenReturn ( mockA2dpService ) ; when ( mockA2dpService . getPriority ( device ) ) . thenReturn ( BluetoothProfile . PRIORITY_UNDEFINED ) ; // Mock the looper when ( mockAdapterService . getMainLooper ( ) ) . thenReturn ( mHandlerThread . getLooper ( ) ) ; // Tell the AdapterService that it is a mock ( see isMock documentation ) when ( mockAdapterService . isMock ( ) ) . thenReturn ( true ) ; PhonePolicy phonePolicy = new PhonePolicy ( mockAdapterService , mockServiceFactory ) ; // Get the broadcast receiver to inject events . BroadcastReceiver injector = phonePolicy . getBroadcastReceiver ( ) ; // Inject an event for UUIDs updated for a remote device with only HFP enabled Intent intent = new Intent ( BluetoothDevice . ACTION_UUID ) ; intent . putExtra ( BluetoothDevice . EXTRA_DEVICE , device ) ; ParcelUuid [ ] uuids = new ParcelUuid [ 2 ] ; uuids [ 0 ] = BluetoothUuid . Handsfree ; uuids [ 1 ] = BluetoothUuid . AudioSink ;
",,,"// Mock the HeadsetService when ( mockServiceFactory . getHeadsetService ( ) ) . thenReturn ( mockHeadsetService ) ; when ( mockHeadsetService . getPriority ( device ) ) . thenReturn ( BluetoothProfile . PRIORITY_UNDEFINED ) ; // Mock the A2DP service when ( mockServiceFactory . getA2dpService ( ) ) . thenReturn ( mockA2dpService ) ; when ( mockA2dpService . getPriority ( device ) ) . thenReturn ( BluetoothProfile . PRIORITY_UNDEFINED ) ; // Mock the looper when ( mockAdapterService . getMainLooper ( ) ) . thenReturn ( mHandlerThread . getLooper ( ) ) ; // Tell the AdapterService that it is a mock ( see isMock documentation ) when ( mockAdapterService . isMock ( ) ) . thenReturn ( true ) ; PhonePolicy phonePolicy = new PhonePolicy ( mockAdapterService , mockServiceFactory ) ; // Get the broadcast receiver to inject events BroadcastReceiver injector = phonePolicy . getBroadcastReceiver ( ) ; // Inject an event for UUIDs updated for a remote device with only HFP enabled Intent intent = new Intent ( BluetoothDevice . ACTION_UUID ) ; intent . putExtra ( BluetoothDevice . EXTRA_DEVICE , device ) ; ParcelUuid [ ] uuids = new ParcelUuid [ 2 ] ; uuids [ 0 ] = BluetoothUuid . Handsfree ; uuids [ 1 ] = BluetoothUuid . AudioSink ;
",,,"// Mock the HeadsetService when ( mockServiceFactory . getHeadsetService ( ) ) . thenReturn ( mockHeadsetService ) ; when ( mockHeadsetService . getPriority ( device ) ) . thenReturn ( BluetoothProfile . PRIORITY_UNDEFINED ) ; // Mock the A2DP service when ( mockServiceFactory . getA2dpService ( ) ) . thenReturn ( mockA2dpService ) ; when ( mockA2dpService . getPriority ( device ) ) . thenReturn ( BluetoothProfile . PRIORITY_UNDEFINED ) ; // Mock the looper when ( mockAdapterService . getMainLooper ( ) ) . thenReturn ( mHandlerThread . getLooper ( ) ) ; < |startfocus| > // Tell the adapterservice that it is a mock ( see isMock documentation ) < |endfocus| > when ( mockAdapterService . isMock ( ) ) . thenReturn ( true ) ; PhonePolicy phPol = new PhonePolicy ( mockAdapterService , mockServiceFactory ) ; // Get the broadcast receiver to inject events . BroadcastReceiver injector = phPol . getBroadcastReceiver ( ) ; // Inject an event for UUIDs updated for a remote device with only HFP enabled Intent intent = new Intent ( BluetoothDevice . ACTION_UUID ) ; intent . putExtra ( BluetoothDevice . EXTRA_DEVICE , device ) ; ParcelUuid [ ] uuids = new ParcelUuid [ 2 ] ; uuids [ 0 ] = BluetoothUuid . Handsfree ; uuids [ 1 ] = BluetoothUuid . AudioSink ; intent . putExtra ( BluetoothDevice . EXTRA_UUID , uuids ) ;
",,
196,"anyBoolean ( ) , anyBoolean ( ) ) ) . thenReturn ( candidate ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , WifiStateMachine . SUPPLICANT_BSSID_ANY ) ; } /* * Firmware does not support controlled roaming . * Connect to a network which doesn't have a config specified BSSID . * * Expected behavior : WifiConnectivityManager calls * WifiStateMachine . startConnectToNetwork ( ) with the expected candidate network ID , * and the BSSID value should be the candidate scan result specified . */ @Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified ( ) { // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine , atLeastOnce ( ) ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , CANDIDATE_BSSID ) ; } /*
","* Firmware does not support controlled roaming . * Connect to a network which doesn't have a config specified BSSID .
","* Firmware does not support controlled roaming. * Connect to a network which doesn't have a config specified BSSID.
",,,"* Firmware does not support controlled roaming. Connect to a network which doesn't have a config specified BSSID.
",,,"@Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified ( ) { when ( mWifiConfigManager . getConfiguredNetwork ( CANDIDATE_NETWORK_ID ) ) . thenReturn ( candidate ) ; when ( mWifiConfigManager . getScanDetailCacheForNetwork ( CANDIDATE_NETWORK_ID ) ) . thenReturn ( mScanDetailCache ) ; when ( mScanDetailCache . getScanDetail ( CANDIDATE_BSSID ) ) . thenReturn ( mScanDetail ) ; when ( mWifiInfo . getBSSID ( ) ) . thenReturn ( null ) ; when ( mWifiInfo . getNetworkId ( ) ) . thenReturn ( WifiConfiguration . INVALID_NETWORK_ID ) ; when ( mWifiNetworkSelector . selectNetwork ( any ( ) , anyBoolean ( ) , anyBoolean ( ) , anyBoolean ( ) ) ) . thenReturn ( candidate ) ; mWifiConnectivityManager . handleScreenStateChanged ( true ) ; mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , WifiStateMachine . SUPPLICANT_BSSID_ANY ) ; } with comments @Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified ( ) { // Mock the required objects and their methods when ( mWifiConfigManager . getConfiguredNetwork ( CANDIDATE_NETWORK_ID ) ) . thenReturn ( candidate ) ; when ( mWifiConfigManager . getScanDetailCacheForNetwork ( CANDIDATE_NETWORK_ID ) ) . thenReturn ( mScanDetailCache ) ; when ( mScanDetailCache . getScanDetail ( CANDIDATE_BSSID ) ) . thenReturn ( mScanDetail ) ; when ( mWifiInfo . getBSSID ( ) ) . thenReturn ( null ) ; when ( mWifiInfo . getNetworkId ( ) ) . thenReturn ( WifiConfiguration . INVALID_NETWORK_ID ) ; when ( mWifiNetworkSelector . selectNetwork ( any ( ) , anyBoolean ( ) , anyBoolean ( ) , anyBoolean ( ) ) ) . thenReturn ( candidate ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; // Verify that WifiStateMachine . startConnectToNetwork ( ) is called with the expected arguments verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , WifiStateMachine . SUPPLICANT_BSSID_ANY ) ; }
",,,"anyBoolean ( ) , anyBoolean ( ) ) ) . thenReturn ( candidate ) ; mWifiConnectivityManager . handleScreenStateChanged ( true ) ; mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , WifiStateMachine . SUPPLICANT_BSSID_ANY ) ; } @Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified ( ) { mWifiConnectivityManager . handleScreenStateChanged ( true ) ; mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine , atLeastOnce ( ) ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , CANDIDATE_BSSID ) ; }
",,,"anyBoolean ( ) , anyBoolean ( ) ) ) . thenReturn ( candidate ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , WifiStateMachine . SUPPLICANT_BSSID_ANY ) ; } /* < |startfocus| > * Firmware does not support controlled roaming . * Connect to a network which doesn't have a config specified BSSID . < |endfocus| > * * Expected behavior : WifiConnectivityManager calls * WifiStateMachine . startConnectToNetwork ( ) with the expected candidate network ID , * and the BSSID value should be the candidate scan result specified . */ @Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified ( ) { // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine , atLeastOnce ( ) ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , CANDIDATE_BSSID ) ; } /*
",,
202,"private void setVpnForcedLocked ( boolean enforce ) { final List < String > exemptedPackages = isNullOrLegacyVpn ( mPackage ) ? null : Collections . singletonList ( mPackage ) ; setVpnForcedWithExemptionsLocked ( enforce , exemptedPackages ) ;
","final List < String > exemptedPackages = isNullOrLegacyVpn ( mPackage ) ? null : Collections . singletonList ( mPackage ) ; setVpnForcedWithExemptionsLocked ( enforce , exemptedPackages ) ;
","setVpnForcedWithExemptionsLocked(enforce, Collections.singletonList(mPackage));
",,,"setVpnForcedWithExemptionsLocked(enforce, Collections.singletonList(mPackage));
",,,"private void setVpnForcedLocked ( boolean enforce ) { List < String > exemptedPackages = null ; if ( ! isNullOrLegacyVpn ( mPackage ) ) { exemptedPackages = Collections . singletonList ( mPackage ) ; } setVpnForcedWithExemptionsLocked ( enforce , exemptedPackages ) ; }
",,,"private void setVpnForcedLocked ( boolean enforce ) { List < String > exemptedPackages = null ; if ( isNullOrLegacyVpn ( mPackage ) ) { setVpnForcedWithExemptionsLocked ( enforce , exemptedPackages ) ; } else { exemptedPackages = Collections . singletonList ( mPackage ) ; setVpnForcedWithExemptionsLocked ( enforce , exemptedPackages ) ; } }
",,,"private void setVpnForcedLocked ( boolean enforce ) { < |startfocus| > setVpnForcedWithExemptionsLocked ( enforce , isNullOrLegacyVpn ( mPackage ) ? null : Collections . singletonList ( mPackage ) ) ; < |endfocus| >
",,
234,"/* * * The connect message can contain a network id passed as arg1 on message or * or a config passed as obj on message . * For a new network , a config is passed to create and connect . * For an existing network , a network id is passed */ netId = message . arg1 ; config = ( WifiConfiguration ) message . obj ; mWifiConnectionStatistics . numWifiManagerJoinAttempt ++ ; boolean hasCredentialChanged = false ; // New network addition . if ( config != null ) { result = mWifiConfigManager . addOrUpdateNetwork ( config , message . sendingUid ) ; if ( ! result . isSuccess ( ) ) { loge ( ""CONNECT_NETWORK adding / updating config = "" + config + "" failed"" ) ; messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED , WifiManager . ERROR ) ; break ; } netId = result . getNetworkId ( ) ; } if ( ! connectToUserSelectNetwork ( netId , message . sendingUid ) ) { messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED ,
","mWifiConnectionStatistics . numWifiManagerJoinAttempt ++ ; boolean hasCredentialChanged = false ;
","<|del|>
",,,"<|del|>
",,,"netId = message . arg1 ; config = ( WifiConfiguration ) message . obj ; mWifiConnectionStatistics . numWifiManagerJoinAttempt ++ ; if ( config != null ) { result = mWifiConfigManager . addOrUpdateNetwork ( config , message . sendingUid ) ; if ( ! result . isSuccess ( ) ) { loge ( ""CONNECT_NETWORK adding / updating config = "" + config + "" failed"" ) ; messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED , WifiManager . ERROR ) ; break ; } netId = result . getNetworkId ( ) ; } if ( ! connectToUserSelectNetwork ( netId , message . sendingUid ) ) { messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED , WifiManager . ERROR ) ; }
",,,"netId = message . arg1 ; config = ( WifiConfiguration ) message . obj ; mWifiConnectionStatistics . numWifiManagerJoinAttempt ++ ; // New network addition . if ( config != null ) { result = mWifiConfigManager . addOrUpdateNetwork ( config , message . sendingUid ) ; if ( ! result . isSuccess ( ) ) { loge ( ""CONNECT_NETWORK adding / updating config = "" + config + "" failed"" ) ; messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED , WifiManager . ERROR ) ; break ; } netId = result . getNetworkId ( ) ; } if ( ! connectToUserSelectNetwork ( netId , message . sendingUid ) ) { messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED , WifiManager . ERROR ) ; break ; }
",,,"/* * * The connect message can contain a network id passed as arg1 on message or * or a config passed as obj on message . * For a new network , a config is passed to create and connect . * For an existing network , a network id is passed */ netId = message . arg1 ; config = ( WifiConfiguration ) message . obj ; < |startfocus| > mWifiConnectionStatistics . numWifiManagerJoinAttempt ++ ; < |endfocus| > // New network addition . if ( config != null ) { result = mWifiConfigManager . addOrUpdateNetwork ( config , message . sendingUid ) ; if ( ! result . isSuccess ( ) ) { loge ( ""CONNECT_NETWORK adding / updating config = "" + config + "" failed"" ) ; messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED , WifiManager . ERROR ) ; break ; } netId = result . getNetworkId ( ) ; } if ( ! connectToUserSelectNetwork ( netId , message . sendingUid ) ) { messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED , WifiManager . ERROR ) ; break ; }
",,
236,"public ISap getSapProxy ( ) { synchronized ( mSapProxyLock ) { if ( mSapProxy != null ) { mSapProxy . linkToDeath ( mSapProxyDeathRecipient , mSapProxyCookie . incrementAndGet ( ) ) ; mSapProxy . setCallback ( mSapCallback ) ; } else { Log . e ( TAG , ""getSapProxy : mSapProxy == null"" ) ; } } catch ( RemoteException | RuntimeException e ) { mSapProxy = null ; Log . e ( TAG , ""getSapProxy : exception : "" + e ) ; } if ( mSapProxy == null ) { // if service is not up , treat it like death notification to try to get service again mSapServerMsgHandler . sendMessageDelayed ( mSapServerMsgHandler . obtainMessage ( SapServer . SAP_PROXY_DEAD , mSapProxyCookie . get ( ) ) , SapServer . ISAP_GET_SERVICE_DELAY_MILLIS ) ; } return mSapProxy ;
","synchronized ( mSapProxyLock ) {
","try { mSapProxy = ISap.getService(SOCKET_NAME_RIL_BT);
",,,"try { mSapProxy = ISap.getService(SOCKET_NAME_RIL_BT); } catch (RemoteException e) { Log.e(TAG, ""getSapProxy: exception: "" + e); }
",,,"public ISap getSapProxyLocked ( ) { if ( mSapProxy != null ) { return mSapProxy ; } try { mSapProxy = ISap . getService ( SOCKET_NAME_RIL_BT ) ; if ( mSapProxy != null ) { mSapProxy . linkToDeath ( mSapProxyDeathRecipient , mSapProxyCookie . incrementAndGet ( ) ) ; mSapProxy . setCallback ( mSapCallback ) ; } else { Log . e ( TAG , ""getSapProxy : mSapProxy == null"" ) ; } } catch ( RemoteException | RuntimeException e ) { mSapProxy = null ; Log . e ( TAG , ""getSapProxy : exception : "" + e ) ; } if ( mSapProxy == null ) { mSapServerMsgHandler . sendMessageDelayed ( mSapServerMsgHandler . obtainMessage ( SapServer . SAP_PROXY_DEAD , mSapProxyCookie . get ( ) ) , SapServer . ISAP_GET_SERVICE_DELAY_MILLIS ) ; } return mSapProxy ; }
",,,"public ISap getSapProxy ( ) { if ( mSapProxy != null ) { return mSapProxy ; } try { mSapProxy = ISap . getService ( SOCKET_NAME_RIL_BT ) ; if ( mSapProxy != null ) { mSapProxy . linkToDeath ( mSapProxyDeathRecipient , mSapProxyCookie . incrementAndGet ( ) ) ; mSapProxy . setCallback ( mSapCallback ) ; } else { Log . e ( TAG , ""getSapProxy : mSapProxy == null"" ) ; } } catch ( RemoteException | RuntimeException e ) { mSapProxy = null ; Log . e ( TAG , ""getSapProxy : exception : "" + e ) ; } if ( mSapProxy == null ) { // if service is not up , treat it like death notification to try to get service again mSapServerMsgHandler . sendMessageDelayed ( mSapServerMsgHandler . obtainMessage ( SapServer . SAP_PROXY_DEAD , mSapProxyCookie . get ( ) ) , SapServer . ISAP_GET_SERVICE_DELAY_MILLIS ) ; } return mSapProxy ; }
",,,"public ISap getSapProxy ( ) { < |startfocus| > if ( mSapProxy != null ) { return mSapProxy ; } try { mSapProxy = ISap . getService ( SOCKET_NAME_RIL_BT ) ; < |endfocus| > if ( mSapProxy != null ) { mSapProxy . linkToDeath ( mSapProxyDeathRecipient , mSapProxyCookie . incrementAndGet ( ) ) ; mSapProxy . setCallback ( mSapCallback ) ; } else { Log . e ( TAG , ""getSapProxy : mSapProxy == null"" ) ; } } catch ( RemoteException | RuntimeException e ) { mSapProxy = null ; Log . e ( TAG , ""getSapProxy : exception : "" + e ) ; } if ( mSapProxy == null ) { // if service is not up , treat it like death notification to try to get service again mSapServerMsgHandler . sendMessageDelayed ( mSapServerMsgHandler . obtainMessage ( SapServer . SAP_PROXY_DEAD , mSapProxyCookie . get ( ) ) , SapServer . ISAP_GET_SERVICE_DELAY_MILLIS ) ; } return mSapProxy ; }
",,
241,"public void systemReady ( ) { if ( isNetdAlive ( ) ) { Slog . d ( TAG , ""IpSecService is ready"" ) ; } else { prepareNativeDaemon ( ) ; }
","if ( isNetdAlive ( ) ) { Slog . d ( TAG , ""IpSecService is ready"" ) ;
","prepareNativeDaemon(); final long delta = System.currentTimeMillis() - start; Log.d(TAG, ""Prepared in "" + delta + ""ms""); return;
",,,"if (DBG) { final long start = System.currentTimeMillis(); prepareNativeDaemon(); final long delta = System.currentTimeMillis() - start; Log.d(TAG, ""Prepared in "" + delta + ""ms"");
",,,"public void systemReady ( ) { final long start = System . currentTimeMillis ( ) ; prepareNativeDaemon ( ) ; final long delta = System . currentTimeMillis ( ) - start ; Log . d ( TAG , ""Prepared in "" + delta + ""ms"" ) ; }
",,,"public void systemReady ( ) { if ( DBG ) { final long start = System . currentTimeMillis ( ) ; prepareNativeDaemon ( ) ; final long delta = System . currentTimeMillis ( ) - start ; Log . d ( TAG , ""Prepared in "" + delta + ""ms"" ) ; return ; } else { prepareNativeDaemon ( ) ; } }
",,,"public void systemReady ( ) { < |startfocus| > if ( DBG ) { final long start = System . currentTimeMillis ( ) ; prepareNativeDaemon ( ) ; final long delta = System . currentTimeMillis ( ) - start ; Log . d ( TAG , ""Prepared in "" + delta + ""ms"" ) ; < |endfocus| > } else { prepareNativeDaemon ( ) ; }
",,
248,"import android . util . Slog ; import java . io . FileDescriptor ; import java . io . PrintWriter ; /* * @hide */ public class IpSecService extends IIpSecService . Stub { private static final String TAG = ""IpSecService"" ; private static final boolean DBG = Log . isLoggable ( TAG , Log . DEBUG ) ; private static final String NETD_SERVICE_NAME = ""netd"" ; /* * Binder context for this service */ private final Context mContext ; private Object mLock = new Object ( ) ; private static final int NETD_FETCH_TIMEOUT = 5000 ; // ms /* * * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService ( Context context , String socket ) { mContext = context ; } static IpSecService create ( Context context , String socket ) throws InterruptedException { final IpSecService service = new IpSecService ( context , socket ) ; service . connectNativeNetdService ( ) ; return service ; } public static IpSecService create ( Context context ) throws InterruptedException { return create ( context , NETD_SERVICE_NAME ) ; }
","private static final int NETD_FETCH_TIMEOUT = 5000 ; // ms
","<|del|>
",,,"<|del|>
",,,"import android . content . Context ; import android . util . Log ; import java . io . FileDescriptor ; import java . io . PrintWriter ; public class IpSecService extends IIpSecService . Stub { private static final String TAG = ""IpSecService"" ; private static final boolean DBG = Log . isLoggable ( TAG , Log . DEBUG ) ; private static final String NETD_SERVICE_NAME = ""netd"" ; private final Context mContext ; private final Object mLock = new Object ( ) ; private static final int NETD_FETCH_TIMEOUT = 1000 ; private IpSecService ( Context context , String socket ) { mContext = context ; } static IpSecService create ( Context context , String socket ) throws InterruptedException { final IpSecService service = new IpSecService ( context , socket ) ; service . connectNativeNetdService ( ) ; return service ; } public static IpSecService create ( Context context ) throws InterruptedException { return create ( context , NETD_SERVICE_NAME ) ; } private void connectNativeNetdService ( ) throws InterruptedException { synchronized ( mLock ) { // Connect to netd via JNI } } }
",,,"import android . util . Slog ; import java . io . FileDescriptor ; import java . io . PrintWriter ; public class IpSecService extends IIpSecService . Stub { private static final String TAG = ""IpSecService"" ; private static final boolean DBG = Log . isLoggable ( TAG , Log . DEBUG ) ; private static final String NETD_SERVICE_NAME = ""netd"" ; private final Context mContext ; private Object mLock = new Object ( ) ; private static final int NETD_FETCH_TIMEOUT = 1000 ; // ms private IpSecService ( Context context , String socket ) { mContext = context ; } static IpSecService create ( Context context , String socket ) throws InterruptedException { final IpSecService service = new IpSecService ( context , socket ) ; service . connectNativeNetdService ( ) ; return service ; } public static IpSecService create ( Context context ) throws InterruptedException { return create ( context , NETD_SERVICE_NAME ) ; } }
",,,"import android . util . Slog ; import java . io . FileDescriptor ; import java . io . PrintWriter ; /* * @hide */ public class IpSecService extends IIpSecService . Stub { private static final String TAG = ""IpSecService"" ; private static final boolean DBG = Log . isLoggable ( TAG , Log . DEBUG ) ; private static final String NETD_SERVICE_NAME = ""netd"" ; /* * Binder context for this service */ private final Context mContext ; private Object mLock = new Object ( ) ; < |startfocus| > private static final int NETD_FETCH_TIMEOUT = 1000 ; // ms < |endfocus| > /* * * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService ( Context context , String socket ) { mContext = context ; } static IpSecService create ( Context context , String socket ) throws InterruptedException { final IpSecService service = new IpSecService ( context , socket ) ; service . connectNativeNetdService ( ) ; return service ; } public static IpSecService create ( Context context ) throws InterruptedException { return create ( context , NETD_SERVICE_NAME ) ; } private void connectNativeNetdService ( ) throws InterruptedException { synchronized ( mLock ) { if ( mNetdService == null ) { mNetdService = INetd . Stub . asInterface ( ServiceManager . getService ( NETD_SERVICE_NAME ) ) ; } } if ( mNetdService == null ) { throw new InterruptedException ( ""Failed to fetch Netd Service"" ) ; } }
",,
250,"* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . example . android . toyvpn ; import android . app . Activity ; import android . content . Intent ; import android . content . SharedPreferences ; import android . net . VpnService ; import android . os . Bundle ; import android . widget . TextView ; public class ToyVpnClient extends Activity { public interface Prefs { String NAME = ""connection"" ; String SERVER_ADDRESS = ""server . address"" ; String SERVER_PORT = ""server . port"" ; String SHARED_SECRET = ""shared . secret"" ; } @Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( R . layout . form ) ; final TextView serverAddress = ( TextView ) findViewById ( R . id . address ) ; final TextView serverPort = ( TextView ) findViewById ( R . id . port ) ; final TextView sharedSecret = ( TextView ) findViewById ( R . id . secret ) ;
","public interface Prefs { String NAME = ""connection"" ; String SERVER_ADDRESS = ""server . address"" ; String SERVER_PORT = ""server . port"" ; String SHARED_SECRET = ""shared . secret"" ;
","interface Prefs { String NAME = ""connection""; String SERVER_ADDRESS = ""server.address""; String SERVER_PORT = ""server.port""; String shared_Secret = ""shared.Secret"";
",,,"public static final String NAME = ""connection""; public static final String SERVER_ADDRESS = ""server.address""; public static final String SERVER_PORT = ""server.port""; public static final String SHARED_SECRET = ""shared.secret"";
",,,"/* * Copyright 2017 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an ""AS IS"" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . example . android . toyvpn ; import android . app . Activity ; import android . content . Intent ; import android . content . SharedPreferences ; import android . net . VpnService ; import android . os . Bundle ; import android . widget . TextView ; public class ToyVpnClient extends Activity { public interface Prefs { String NAME = ""connection"" ; String SERVER_ADDRESS = ""server . address"" ; String SERVER_PORT = ""server . port"" ; String SHARED_SECRET = ""shared . secret"" ; } @Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( R . layout . form ) ; final TextView serverAddress = findViewById ( R . id . address ) ; final TextView serverPort = findViewById ( R . id . port ) ; final TextView sharedSecret = findViewById ( R . id . secret ) ; } }
",,,"package com . example . android . toyvpn ; import android . app . Activity ; import android . content . Intent ; import android . content . SharedPreferences ; import android . net . VpnService ; import android . os . Bundle ; import android . widget . TextView ; public class ToyVpnClient extends Activity { public interface Prefs { String NAME = ""connection"" ; String SERVER_ADDRESS = ""server . address"" ; String SERVER_PORT = ""server . port"" ; String SHARED_SECRET = ""shared . secret"" ; } @Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( R . layout . form ) ; final TextView serverAddress = findViewById ( R . id . address ) ; final TextView serverPort = findViewById ( R . id . port ) ; final TextView sharedSecret = findViewById ( R . id . secret ) ; } }
",,,"* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . example . android . toyvpn ; import android . app . Activity ; import android . content . Intent ; import android . content . SharedPreferences ; import android . net . VpnService ; import android . os . Bundle ; import android . widget . TextView ; public class ToyVpnClient extends Activity { < |startfocus| > public interface Prefs { String NAME = ""connection"" ; String SERVER_ADDRESS = ""server . address"" ; String SERVER_PORT = ""server . port"" ; String SHARED_SECRET = ""shared . secret"" ; < |endfocus| > } @Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( R . layout . form ) ; final TextView serverAddress = ( TextView ) findViewById ( R . id . address ) ; final TextView serverPort = ( TextView ) findViewById ( R . id . port ) ; final TextView sharedSecret = ( TextView ) findViewById ( R . id . secret ) ;
",,
253,"packet . position ( 0 ) ; tunnel . write ( packet ) ; } packet . clear ( ) ; // Wait for the parameters within a limited time . for ( int i = 0 ; i < MAX_HANDSHAKE_ATTEMPTS ; ++ i ) { Thread . sleep ( IDLE_INTERVAL_MS ) ; // Normally we should not receive random packets . int length = tunnel . read ( packet ) ; if ( length > 0 && packet . get ( 0 ) == 0 ) { return configure ( new String ( packet . array ( ) , 1 , length - 1 , US_ASCII ) . trim ( ) ) ; } } throw new IllegalStateException ( ""Timed out"" ) ; } private ParcelFileDescriptor configure ( String parameters ) throws Exception { // Configure a builder while parsing the parameters . VpnService . Builder builder = mService . new Builder ( ) ; for ( String parameter : parameters . split ( "" "" ) ) { String [ ] fields = parameter . split ( "" , "" ) ; try { switch ( fields [ 0 ] . charAt ( 0 ) ) { case 'm' : builder . setMtu ( Short . parseShort ( fields [ 1 ] ) ) ; break ; case 'a' : builder . addAddress ( fields [ 1 ] , Integer . parseInt ( fields [ 2 ] ) ) ;
","return configure ( new String ( packet . array ( ) , 1 , length - 1 , US_ASCII ) . trim ( ) ) ;
","return configure(new String(packet.array(), 1, length - 1).trim());
",,,"return configure(packet.array(), 1, length - 1).trim());
",,,"packet . position ( 0 ) ; tunnel . write ( packet ) ; packet . clear ( ) ; for ( int i = 0 ; i < MAX_HANDSHAKE_ATTEMPTS ; ++ i ) { Thread . sleep ( IDLE_INTERVAL_MS ) ; int length = tunnel . read ( packet ) ; if ( length > 0 && packet . get ( 0 ) == 0 ) { return configure ( new String ( packet . array ( ) , 1 , length - 1 ) . trim ( ) ) ; } } throw new IllegalStateException ( ""Timed out"" ) ; private ParcelFileDescriptor configure ( String parameters ) throws Exception { VpnService . Builder builder = mService . new Builder ( ) ; for ( String parameter : parameters . split ( "" "" ) ) { String [ ] fields = parameter . split ( "" , "" ) ; switch ( fields [ 0 ] . charAt ( 0 ) ) { case 'm' : builder . setMtu ( Short . parseShort ( fields [ 1 ] ) ) ; break ; case 'a' : builder . addAddress ( fields [ 1 ] , Integer . parseInt ( fields [ 2 ] ) ) ; break ; case 'r' : builder . addRoute ( fields [ 1 ] , Integer . parseInt ( fields [ 2 ] ) ) ; break ; case 'd' : builder . addDnsServer ( fields [ 1 ] ) ; break ; } } return builder . establish ( ) ; }
",,,"public void sendDataToTunnel ( SocketChannel tunnel , ByteBuffer packet ) throws IOException , InterruptedException { packet . position ( 0 ) ; tunnel . write ( packet ) ; packet . clear ( ) ; for ( int i = 0 ; i < MAX_HANDSHAKE_ATTEMPTS ; ++ i ) { Thread . sleep ( IDLE_INTERVAL_MS ) ; int length = tunnel . read ( packet ) ; if ( length > 0 && packet . get ( 0 ) == 0 ) { return configure ( new String ( packet . array ( ) , 1 , length - 1 ) . trim ( ) ) ; } } throw new IllegalStateException ( ""Timed out"" ) ; } private ParcelFileDescriptor configure ( String parameters ) throws Exception { VpnService . Builder builder = mService . new Builder ( ) ; for ( String parameter : parameters . split ( "" "" ) ) { String [ ] fields = parameter . split ( "" , "" ) ; switch ( fields [ 0 ] . charAt ( 0 ) ) { case 'm' : builder . setMtu ( Short . parseShort ( fields [ 1 ] ) ) ; break ; case 'a' : builder . addAddress ( fields [ 1 ] , Integer . parseInt ( fields [ 2 ] ) ) ; break ; // add other cases for configuring the builder } } // configure other settings and return the ParcelFileDescriptor }
",,,"packet . position ( 0 ) ; tunnel . write ( packet ) ; } packet . clear ( ) ; // Wait for the parameters within a limited time . for ( int i = 0 ; i < MAX_HANDSHAKE_ATTEMPTS ; ++ i ) { Thread . sleep ( IDLE_INTERVAL_MS ) ; // Normally we should not receive random packets . int length = tunnel . read ( packet ) ; if ( length > 0 && packet . get ( 0 ) == 0 ) { < |startfocus| > return configure ( new String ( packet . array ( ) , 1 , length - 1 ) . trim ( ) ) ; < |endfocus| > } } throw new IllegalStateException ( ""Timed out"" ) ; } private ParcelFileDescriptor configure ( String parameters ) throws Exception { // Configure a builder while parsing the parameters . VpnService . Builder builder = mService . new Builder ( ) ; for ( String parameter : parameters . split ( "" "" ) ) { String [ ] fields = parameter . split ( "" , "" ) ; try { switch ( fields [ 0 ] . charAt ( 0 ) ) { case 'm' : builder . setMtu ( Short . parseShort ( fields [ 1 ] ) ) ; break ; case 'a' : builder . addAddress ( fields [ 1 ] , Integer . parseInt ( fields [ 2 ] ) ) ; break ; case 'r' : builder . addRoute ( fields [ 1 ] , Integer . parseInt ( fields [ 2 ] ) ) ; break ; case 'd' : builder . addDnsServer ( fields [ 1 ] ) ; break ; case 's' : builder . addSearchDomain ( fields [ 1 ] ) ; break ; } } catch ( Exception e ) { throw new IllegalArgumentException ( ""Bad parameter : "" + parameter ) ; } } // Close the old interface since the parameters have been changed .
",,
260,"setAndBroadcastNetworkSetTime ( mSavedTime + ( currTime - mSavedAtTime ) ) ; } } private void revertToNitzTimeZone ( ) { if ( Settings . Global . getInt ( mCr , Settings . Global . AUTO_TIME_ZONE , 0 ) == 0 ) { return ; } String tmpLog = ""Reverting to NITZ TimeZone : tz = "" + mSavedTimeZone ; if ( DBG ) log ( tmpLog ) ; mTimeZoneLog . log ( tmpLog ) ; if ( mSavedTimeZone != null ) { setAndBroadcastNetworkSetTimeZone ( mSavedTimeZone ) ; } } /* * * Post a notification to NotificationManager for restricted state and * rejection cause for cs registration * * @param notifyType is one state of * PS / CS_ * _ENABLE / DISABLE / * CS_REJECT_CAUSE_ENABLED / CS_REJECT_CAUSE_DISABLED */ @VisibleForTesting public void setNotification ( int notifyType ) { if ( DBG ) log ( ""setNotification : create notification "" + notifyType ) ; // Needed because sprout RIL sends these when they shouldn't ? boolean isSetNotification = mPhone . getContext ( ) . getResources ( ) . getBoolean ( com . android . internal . R . bool . config_user_notification_of_restrictied_mobile_access ) ;
","* @param notifyType is one state of * PS / CS_ * _ENABLE / DISABLE / * CS_REJECT_CAUSE_ENABLED / CS_REJECT_CAUSE_DISABLED
","* @param notifyType is one state of PS/CS_*_ENABLE/DISABLE
",,,"* @param notifyType is one state of PS/CS_*_ENABLE/DISABLE
",,,"void setAndBroadcastNetworkSetTime ( long time ) { if ( DBG ) log ( ""setAndBroadcastNetworkSetTime : time = "" + time + ""ms"" ) ; SystemClock . setCurrentTimeMillis ( time ) ; Intent intent = new Intent ( TelephonyIntents . ACTION_NETWORK_SET_TIME ) ; intent . putExtra ( ""time"" , time ) ; mPhone . getContext ( ) . sendBroadcast ( intent ) ; } void revertToNitzTimeZone ( ) { if ( Settings . Global . getInt ( mCr , Settings . Global . AUTO_TIME_ZONE , 0 ) == 0 ) { return ; } String tmpLog = ""Reverting to NITZ TimeZone : tz = "" + mSavedTimeZone ; if ( DBG ) log ( tmpLog ) ; mTimeZoneLog . log ( tmpLog ) ; if ( mSavedTimeZone != null ) { setAndBroadcastNetworkSetTimeZone ( mSavedTimeZone ) ; } } @VisibleForTesting public void setNotification ( int notifyType ) { if ( DBG ) log ( ""setNotification : create notification "" + notifyType ) ; boolean isSetNotification = mPhone . getContext ( ) . getResources ( ) . getBoolean ( com . android . internal . R . bool . config_user_notification_of_restrictied_mobile_access ) ; }
",,,"setAndBroadcastNetworkSetTime ( mSavedTime + ( currTime - mSavedAtTime ) ) ; } private void revertToNitzTimeZone ( ) { if ( Settings . Global . getInt ( mCr , Settings . Global . AUTO_TIME_ZONE , 0 ) == 0 ) { return ; } String tmpLog = ""Reverting to NITZ TimeZone : tz = "" + mSavedTimeZone ; if ( DBG ) log ( tmpLog ) ; mTimeZoneLog . log ( tmpLog ) ; if ( mSavedTimeZone != null ) { setAndBroadcastNetworkSetTimeZone ( mSavedTimeZone ) ; } } @VisibleForTesting public void setNotification ( int notifyType ) { if ( DBG ) log ( ""setNotification : create notification "" + notifyType ) ; boolean isSetNotification = mPhone . getContext ( ) . getResources ( ) . getBoolean ( com . android . internal . R . bool . config_user_notification_of_restrictied_mobile_access ) ; }
",,,"setAndBroadcastNetworkSetTime ( mSavedTime + ( currTime - mSavedAtTime ) ) ; } } private void revertToNitzTimeZone ( ) { if ( Settings . Global . getInt ( mCr , Settings . Global . AUTO_TIME_ZONE , 0 ) == 0 ) { return ; } String tmpLog = ""Reverting to NITZ TimeZone : tz = "" + mSavedTimeZone ; if ( DBG ) log ( tmpLog ) ; mTimeZoneLog . log ( tmpLog ) ; if ( mSavedTimeZone != null ) { setAndBroadcastNetworkSetTimeZone ( mSavedTimeZone ) ; } } /* * * Post a notification to NotificationManager for restricted state and * rejection cause for cs registration * < |startfocus| > * @param notifyType is one state of PS / CS_ * _ENABLE / DISABLE < |endfocus| > */ @VisibleForTesting public void setNotification ( int notifyType ) { if ( DBG ) log ( ""setNotification : create notification "" + notifyType ) ; // Needed because sprout RIL sends these when they shouldn't ? boolean isSetNotification = mPhone . getContext ( ) . getResources ( ) . getBoolean ( com . android . internal . R . bool . config_user_notification_of_restrictied_mobile_access ) ;
",,
268,"Jack . getSession ( ) . getReporter ( ) . report ( Severity . FATAL , new BadBoostLockedRegionPriorityConfigurationException ( prop , e ) ) ; Jack . getSession ( ) . abortEventually ( ) ; return null ; } } @Override public void run ( @Nonnull JMethod method ) { if ( method . isNative ( ) || method . isAbstract ( ) || ! filter . accept ( this . getClass ( ) , method ) ) { return ; } if ( lockClass . length == 0 ) { return ; } TransformationRequest tr = new TransformationRequest ( method ) ; Visitor visitor = new Visitor ( method , tr ) ; visitor . accept ( method ) ; tr . commit ( ) ; } private class Visitor extends JVisitor { @Nonnull private final JMethod method ; @Nonnull private final TransformationRequest tr ; public Visitor ( @Nonnull JMethod method , @Nonnull TransformationRequest tr ) { this . method = method ; this . tr = tr ; } @Override public void endVisit ( @Nonnull JLock jLock ) { assert lockClass != null ; int lockIndex = - 1 ;
","if ( lockClass . length == 0 ) {
","if (lockClass == null || requestClass == null || resetClass == null || requestMethodId == null || resetMethodId == null) {
",,,"if (requestClass == null || resetClass == null || requestMethodId == null || resetMethodId == null || lockClass.lenth == 0) {
",,,"Jack . getSession ( ) . getReporter ( ) . report ( Severity . FATAL , new BadBoostLockedRegionPriorityConfigurationException ( prop , e ) ) ; Jack . getSession ( ) . abortEventually ( ) ; return null ; } } @Override public void run ( @Nonnull JMethod method ) { if ( method . isNative ( ) || method . isAbstract ( ) || ! filter . accept ( this . getClass ( ) , method ) ) { return ; } if ( lockClass . length == 0 || requestClass . length == 0 || resetClass . length == 0 || requestMethodId . length == 0 || resetMethodId . length == 0 ) { return ; } TransformationRequest tr = new TransformationRequest ( method ) ; Visitor visitor = new Visitor ( method , tr ) ; visitor . accept ( method ) ; tr . commit ( ) ; } private class Visitor extends JVisitor { @Nonnull private final JMethod method ; @Nonnull private final TransformationRequest tr ; public Visitor ( @Nonnull JMethod method , @Nonnull TransformationRequest tr ) { this . method = method ; this . tr = tr ; } @Override public void endVisit ( @Nonnull JLock jLock ) { assert lockClass != null ; int lockIndex = - 1 ;
",,,"Jack . getSession ( ) . getReporter ( ) . report ( Severity . FATAL , new BadBoostLockedRegionPriorityConfigurationException ( prop , e ) ) ; Jack . getSession ( ) . abortEventually ( ) ; return null ; } @Override public void run ( @Nonnull JMethod method ) { if ( method . isNative ( ) || method . isAbstract ( ) || ! filter . accept ( this . getClass ( ) , method ) ) { return ; } if ( lockClass == null || requestClass == null || resetClass == null || requestMethodId == null || resetMethodId == null ) { return ; } TransformationRequest tr = new TransformationRequest ( method ) ; Visitor visitor = new Visitor ( method , tr ) ; visitor . accept ( method ) ; tr . commit ( ) ; } private class Visitor extends JVisitor { @Nonnull private final JMethod method ; @Nonnull private final TransformationRequest tr ; public Visitor ( @Nonnull JMethod method , @Nonnull TransformationRequest tr ) { this . method = method ; this . tr = tr ; } @Override public void endVisit ( @Nonnull JLock jLock ) { assert lockClass != null ; int lockIndex = - 1 ; // rest of the code } }
",,,"Jack . getSession ( ) . getReporter ( ) . report ( Severity . FATAL , new BadBoostLockedRegionPriorityConfigurationException ( prop , e ) ) ; Jack . getSession ( ) . abortEventually ( ) ; return null ; } } @Override public void run ( @Nonnull JMethod method ) { if ( method . isNative ( ) || method . isAbstract ( ) || ! filter . accept ( this . getClass ( ) , method ) ) { return ; } < |startfocus| > if ( lockClass . length == 0 || requestClass == null || resetClass == null || requestMethodId == null || resetMethodId == null ) { < |endfocus| > return ; } TransformationRequest tr = new TransformationRequest ( method ) ; Visitor visitor = new Visitor ( method , tr ) ; visitor . accept ( method ) ; tr . commit ( ) ; } private class Visitor extends JVisitor { @Nonnull private final JMethod method ; @Nonnull private final TransformationRequest tr ; public Visitor ( @Nonnull JMethod method , @Nonnull TransformationRequest tr ) { this . method = method ; this . tr = tr ; } @Override public void endVisit ( @Nonnull JLock jLock ) { assert lockClass != null ; int lockIndex = - 1 ;
",,
269,"* Two objects of HIDL types are considered equal if : * 1 . Both null * 2 . Both non - null , and of the same class , and : * 2 . 1 Both are primitive arrays / enum arrays , elements are equal using == check * 2 . 2 Both are object arrays , elements are checked recursively * 2 . 3 Both are Lists , elements are checked recursively * 2 . 4 ( If both are collections other than lists or maps , undefined behavior ) * 2 . 5 lft . equals ( rgt ) returns true */ public static boolean deepEquals ( Object lft , Object rgt ) { if ( lft == rgt ) { return true ; } if ( lft == null || rgt == null ) { return false ; } Class < ? > lftClazz = lft . getClass ( ) ; Class < ? > rgtClazz = rgt . getClass ( ) ; if ( lftClazz != rgtClazz ) { return false ; } if ( lftClazz . isArray ( ) ) { Class < ? > lftElementType = lftClazz . getComponentType ( ) ; if ( lftElementType != rgtClazz . getComponentType ( ) ) { return false ; }
","* 2 . 5 lft . equals ( rgt ) returns true
","<|del|>
",,,"<|del|>
",,,"public static boolean deepEquals ( Object lft , Object rgt ) { if ( lft == rgt ) { return true ; } if ( lft == null || rgt == null ) { return false ; } Class < ? > lftClazz = lft . getClass ( ) ; Class < ? > rgtClazz = rgt . getClass ( ) ; if ( lftClazz != rgtClazz ) { return false ; } if ( lftClazz . isArray ( ) ) { Class < ? > lftElementType = lftClazz . getComponentType ( ) ; if ( lftElementType != rgtClazz . getComponentType ( ) ) { return false ; } if ( lftElementType . isPrimitive ( ) ) { return Arrays . equals ( ( Object [ ] ) lft , ( Object [ ] ) rgt ) ; } else { Object [ ] lftArray = ( Object [ ] ) lft ; Object [ ] rgtArray = ( Object [ ] ) rgt ; if ( lftArray . length != rgtArray . length ) { return false ; } for ( int i = 0 ; i < lftArray . length ; i ++ ) { if ( ! deepEquals ( lftArray [ i ] , rgtArray [ i ] ) ) { return false ; } } return true ; } } if ( lft instanceof List ) { List < ? > lftList = ( List < ? > ) lft ; List < ? > rgtList = ( List < ? > ) rgt ; if ( lftList . size ( ) != rgtList . size ( ) ) { return false ; } for ( int i = 0 ; i < lftList . size ( ) ; i ++ ) { if ( ! deepEquals ( lftList . get ( i ) , rgtList . get ( i ) ) ) { return false ; } } return true ; } return lft . equals ( rgt ) ; }
",,,"public static boolean deepEquals ( Object lft , Object rgt ) { if ( lft == rgt ) { return true ; } if ( lft == null || rgt == null ) { return false ; } Class < ? > lftClazz = lft . getClass ( ) ; Class < ? > rgtClazz = rgt . getClass ( ) ; if ( lftClazz != rgtClazz ) { return false ; } if ( lftClazz . isArray ( ) ) { Class < ? > lftElementType = lftClazz . getComponentType ( ) ; if ( lftElementType != rgtClazz . getComponentType ( ) ) { return false ; } if ( lftElementType . isPrimitive ( ) ) { if ( lftElementType == boolean . class ) { return Arrays . equals ( ( boolean [ ] ) lft , ( boolean [ ] ) rgt ) ; } else if ( lftElementType == byte . class ) { return Arrays . equals ( ( byte [ ] ) lft , ( byte [ ] ) rgt ) ; } else if ( lftElementType == char . class ) { return Arrays . equals ( ( char [ ] ) lft , ( char [ ] ) rgt ) ; } else if ( lftElementType == short . class ) { return Arrays . equals ( ( short [ ] ) lft , ( short [ ] ) rgt ) ; } else if ( lftElementType == int . class ) { return Arrays . equals ( ( int [ ] ) lft , ( int [ ] ) rgt ) ; } else if ( lftElementType == long . class ) { return Arrays . equals ( ( long [ ] ) lft , ( long [ ] ) rgt ) ; } else if ( lftElementType == float . class ) { return Arrays . equals ( ( float [ ] ) lft , ( float [ ] ) rgt ) ; } else if ( lftElementType == double . class ) { return Arrays . equals ( ( double [ ] ) lft , ( double [ ] ) rgt ) ; } } else { Object [ ] lftArray = ( Object [ ] ) lft ; Object [ ] rgtArray = ( Object [ ] ) rgt ; if ( lftArray . length != rgtArray . length ) { return false ; } for ( int i = 0 ; i < lftArray . length ; i ++ ) { if ( ! deepEquals ( lftArray [ i ] , rgtArray [ i ] ) ) { return false ; } } return true ; } } else if ( lft instanceof List && rgt instanceof List ) { List < ? > lftList = ( List < ? > )
",,,"* Two objects of HIDL types are considered equal if : * 1 . Both null * 2 . Both non - null , and of the same class , and : * 2 . 1 Both are primitive arrays / enum arrays , elements are equal using == check * 2 . 2 Both are object arrays , elements are checked recursively * 2 . 3 Both are Lists , elements are checked recursively * 2 . 4 ( If both are collections other than lists or maps , undefined behavior ) < |startfocus| > * 2 . 5 . equals return true < |endfocus| > */ public static boolean deepEquals ( Object lft , Object rgt ) { if ( lft == rgt ) { return true ; } if ( lft == null || rgt == null ) { return false ; } Class < ? > lftClazz = lft . getClass ( ) ; Class < ? > rgtClazz = rgt . getClass ( ) ; if ( lftClazz != rgtClazz ) { return false ; } if ( lftClazz . isArray ( ) ) { Class < ? > lftElementType = lftClazz . getComponentType ( ) ; if ( lftElementType != rgtClazz . getComponentType ( ) ) { return false ; } if ( lftElementType . isPrimitive ( ) ) { if ( lftElementType == int . class ) { return Arrays . equals ( ( int [ ] ) lft , ( int [ ] ) rgt ) ; } else if ( lftElementType == long . class ) { return Arrays . equals ( ( long [ ] ) lft , ( long [ ] ) rgt ) ; } else if ( lftElementType == boolean . class ) { return Arrays . equals ( ( boolean [ ] ) lft , ( boolean [ ] ) rgt ) ; } else if ( lftElementType == byte . class ) { return Arrays . equals ( ( byte [ ] ) lft , ( byte [ ] ) rgt ) ; } else if ( lftElementType == char . class ) { return Arrays . equals ( ( char [ ] ) lft , ( char [ ] ) rgt ) ; } else if ( lftElementType == float . class ) { return Arrays . equals ( ( float [ ] ) lft , ( float [ ] ) rgt ) ; } else if ( lftElementType == double . class ) { return Arrays . equals ( ( double [ ] ) lft , ( double [ ] ) rgt ) ; } else if ( lftElementType == short . class ) { return Arrays . equals ( ( short [ ] ) lft , ( short [ ] ) rgt ) ; } else { throw new UnsupportedOperationException ( ""Unsupported primitive type : "" + lftElementType ) ; } } else { return Arrays . deepEquals ( ( Object [ ] ) lft , ( Object [ ] ) rgt ) ; } } else if ( lft instanceof List ) { List < ? > lftList = ( List < ? > ) lft ; List < ? > rgtList = ( List < ? > ) rgt ; if ( lftList . size ( ) != rgtList . size ( ) ) { return false ; } for ( int i = 0 ; i < lftList . size ( ) ; ++ i ) { if ( ! deepEquals ( lftList . get ( i ) , rgtList . get ( i ) ) ) { return false ; } } return true ; } else { return lft . equals ( rgt ) ; } }
",,
281,"( mLinkUpBandwidthKbps * 11 ) + ( mLinkDownBandwidthKbps * 13 ) + Objects . hashCode ( mNetworkSpecifier ) * 17 + ( mSignalStrength * 19 ) ) ; } @Override public int describeContents ( ) { return 0 ; } @Override public void writeToParcel ( Parcel dest , int flags ) { dest . writeLong ( mNetworkCapabilities ) ; dest . writeLong ( mTransportTypes ) ; dest . writeInt ( mLinkUpBandwidthKbps ) ; dest . writeInt ( mLinkDownBandwidthKbps ) ; if ( mNetworkSpecifier != null && ! NetworkSpecifier . isWhitelistedNetworkSpecifier ( mNetworkSpecifier ) ) { throw new IllegalStateException ( ""Invalid network specifier"" ) ; } dest . writeParcelable ( ( Parcelable ) mNetworkSpecifier , flags ) ; dest . writeInt ( mSignalStrength ) ; } public static final Creator < NetworkCapabilities > CREATOR = new Creator < NetworkCapabilities > ( ) { @Override public NetworkCapabilities createFromParcel ( Parcel in ) { NetworkCapabilities netCap = new NetworkCapabilities ( ) ; netCap . mNetworkCapabilities = in . readLong ( ) ; netCap . mTransportTypes = in . readLong ( ) ; netCap . mLinkUpBandwidthKbps = in . readInt ( ) ; netCap . mLinkDownBandwidthKbps = in . readInt ( ) ; netCap . mNetworkSpecifier = in . readParcelable ( null ) ; netCap . mSignalStrength = in . readInt ( ) ; return netCap ; } @Override
","if ( mNetworkSpecifier != null && ! NetworkSpecifier . isWhitelistedNetworkSpecifier ( mNetworkSpecifier ) ) { throw new IllegalStateException ( ""Invalid network specifier"" ) ; } dest . writeParcelable ( ( Parcelable ) mNetworkSpecifier , flags ) ;
","dest.writeParcelable(mNetworkSpecifier, 0);
",,,"dest.writeParcelable(mNetworkSpecifier, 0);
",,,"( mLinkUpBandwidthKbps * 11 ) + ( mLinkDownBandwidthKbps * 13 ) + Objects . hashCode ( mNetworkSpecifier ) * 17 + ( mSignalStrength * 19 ) ) ; @Override public int describeContents ( ) { return 0 ; } @Override public void writeToParcel ( Parcel dest , int flags ) { dest . writeLong ( mNetworkCapabilities ) ; dest . writeLong ( mTransportTypes ) ; dest . writeInt ( mLinkUpBandwidthKbps ) ; dest . writeInt ( mLinkDownBandwidthKbps ) ; dest . writeParcelable ( mNetworkSpecifier , 0 ) ; dest . writeInt ( mSignalStrength ) ; } public static final Creator < NetworkCapabilities > CREATOR = new Creator < NetworkCapabilities > ( ) { @Override public NetworkCapabilities createFromParcel ( Parcel in ) { NetworkCapabilities netCap = new NetworkCapabilities ( ) ; netCap . mNetworkCapabilities = in . readLong ( ) ; netCap . mTransportTypes = in . readLong ( ) ; netCap . mLinkUpBandwidthKbps = in . readInt ( ) ; netCap . mLinkDownBandwidthKbps = in . readInt ( ) ; netCap . mNetworkSpecifier = in . readParcelable ( null ) ; netCap . mSignalStrength = in . readInt ( ) ; return netCap ; } @Override public NetworkCapabilities [ ] newArray ( int size ) { return new NetworkCapabilities [ size ] ; } } ;
",,,"public LSMInvertedIndexDiskComponent ( IInvertedIndex invIndex , BTree deletedKeysBTree , BloomFilter bloomFilter , ILSMComponentFilter filter ) { super ( invIndex . getMainIndex ( ) . getPageManager ( ) , filter ) ; this . invIndex = invIndex ; this . deletedKeysBTree = deletedKeysBTree ; this . bloomFilter = bloomFilter ; } public void testCouchbaseBean ( ) { final String key = ""SpringCouchbase"" + System . currentTimeMillis ( ) ; final String value = ""Spring / Couchbase"" ; BeanFactory beanFactory = new ClassPathXmlApplicationContext ( ""cbGenerate . xml"" ) ; CouchbaseClient c = beanFactory . getBean ( ""couchbaseClient"" , CouchbaseClient . class ) ; c . set ( key , 0 , value ) ; assertEquals ( value , c . get ( key ) ) ; c . delete ( key ) ; c . shutdown ( 3 , TimeUnit . SECONDS ) ; } // override by higher priority values . // In the case of a platform with override values from the user , the skin value might // already be there , but it's ok . HashMap < String , String > finalHardwareValues = new HashMap < String , String > ( ) ; File targetHardwareFile = new File ( target . getLocation ( ) , AvdManager . HARDWARE_INI ) ; if ( targetHardwareFile . isFile ( ) ) { Map < String , String > targetHardwareConfig = ProjectProperties . parsePropertyFile ( new FileWrapper ( targetHardwareFile ) , log ) ; if ( targetHardwareConfig != null ) { finalHardwareValues . putAll ( targetHardwareConfig ) ; values . putAll ( targetHardwareConfig ) ; } } // get the hardware properties for this skin File skinFolder = getSkinPath ( skinName , target ) ; File skinHardwareFile = new File ( skinFolder , AvdManager . HARDWARE_INI ) ; if ( skinHardwareFile . isFile ( ) ) { Map < String , String > skinHardwareConfig = ProjectProperties . parsePropertyFile ( new FileWrapper ( skinHardwareFile ) , log ) ; if ( skinHardwareConfig != null ) { finalHardwareValues . putAll ( skinHardwareConfig ) ; } } ( mLinkUpBandwidthKbps * 11 ) + ( mLinkDownBandwidthKbps * 13 ) + Objects . hashCode ( mNetworkSpecifier ) * 17 + ( mSignalStrength * 19 ) ) ; @Override public int describeContents ( ) { return 0 ; } @Override public void writeToParcel ( Parcel dest , int flags ) { dest . writeLong ( mNetworkCapabilities ) ; dest . writeLong ( mTransportTypes ) ; dest
",,,"( mLinkUpBandwidthKbps * 11 ) + ( mLinkDownBandwidthKbps * 13 ) + Objects . hashCode ( mNetworkSpecifier ) * 17 + ( mSignalStrength * 19 ) ) ; } @Override public int describeContents ( ) { return 0 ; } @Override public void writeToParcel ( Parcel dest , int flags ) { dest . writeLong ( mNetworkCapabilities ) ; dest . writeLong ( mTransportTypes ) ; dest . writeInt ( mLinkUpBandwidthKbps ) ; dest . writeInt ( mLinkDownBandwidthKbps ) ; < |startfocus| > dest . writeParcelable ( mNetworkSpecifier , 0 ) ; < |endfocus| > dest . writeInt ( mSignalStrength ) ; } public static final Creator < NetworkCapabilities > CREATOR = new Creator < NetworkCapabilities > ( ) { @Override public NetworkCapabilities createFromParcel ( Parcel in ) { NetworkCapabilities netCap = new NetworkCapabilities ( ) ; netCap . mNetworkCapabilities = in . readLong ( ) ; netCap . mTransportTypes = in . readLong ( ) ; netCap . mLinkUpBandwidthKbps = in . readInt ( ) ; netCap . mLinkDownBandwidthKbps = in . readInt ( ) ; netCap . mNetworkSpecifier = in . readParcelable ( null ) ; netCap . mSignalStrength = in . readInt ( ) ; return netCap ; } @Override
",,
293,"public Bundle createTransportModeTransform ( IpSecConfig c , IBinder binder ) { int resourceId = mNextTransformId . getAndIncrement ( ) ; for ( int direction : DIRECTIONS ) { IpSecAlgorithm auth = c . getAuthentication ( direction ) ; IpSecAlgorithm crypt = c . getEncryption ( direction ) ; try { int result = getNetdInstance ( ) . ipSecAddSecurityAssociation ( resourceId , c . getMode ( ) , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : """" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : """" , ( c . getNetwork ( ) != null ) ? c . getNetwork ( ) . getNetworkHandle ( ) : 0 , c . getSpi ( direction ) , ( auth != null ) ? auth . getName ( ) : """" , ( auth != null ) ? auth . getKey ( ) : null , ( auth != null ) ? auth . getTruncationLengthBits ( ) : 0 ,
","for ( int direction : DIRECTIONS ) {
","for (int direction : new int[] { IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) {
",,,"for (int direction : DIRECTIONS) {
",,,"public Bundle createTransportModeTransform ( IpSecConfig c , IBinder binder ) { int resourceId = mNextTransformId . getAndIncrement ( ) ; for ( int direction : DIRECTIONS ) { IpSecAlgorithm auth = c . getAuthentication ( direction ) ; IpSecAlgorithm crypt = c . getEncryption ( direction ) ; try { int result = getNetdInstance ( ) . ipSecAddSecurityAssociation ( resourceId , c . getMode ( ) , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : """" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : """" , ( c . getNetwork ( ) != null ) ? c . getNetwork ( ) . getNetworkHandle ( ) : 0 , c . getSpi ( direction ) , ( auth != null ) ? auth . getName ( ) : """" , ( auth != null ) ? auth . getKey ( ) : null , ( auth != null ) ? auth . getTruncationLengthBits ( ) : 0 , ( crypt != null ) ? crypt . getName ( ) : """" , ( crypt != null ) ? crypt . getKey ( ) : null , ( crypt != null ) ? crypt . getTruncationLengthBits ( ) : 0 , binder ) ; return makeIpSecTransformResponseBundle ( resourceId , result ) ; } catch ( ServiceSpecificException e ) { Log . e ( TAG , ""Failed to communicate with IPsec service"" , e ) ; return null ; } } return null ; } private static final int [ ] DIRECTIONS = { IpSecTransform . DIRECTION_OUT , IpSecTransform . DIRECTION_IN } ;
",,,"public Bundle createTransportModeTransform ( IpSecConfig c , IBinder binder ) { int resourceId = mNextTransformId . getAndIncrement ( ) ; for ( int direction : DIRECTIONS ) { IpSecAlgorithm auth = c . getAuthentication ( direction ) ; IpSecAlgorithm crypt = c . getEncryption ( direction ) ; try { int result = getNetdInstance ( ) . ipSecAddSecurityAssociation ( resourceId , c . getMode ( ) , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : """" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : """" , ( c . getNetwork ( ) != null ) ? c . getNetwork ( ) . getNetworkHandle ( ) : 0 , c . getSpi ( direction ) , ( auth != null ) ? auth . getName ( ) : """" , ( auth != null ) ? auth . getKey ( ) : null , ( auth != null ) ? auth . getTruncationLengthBits ( ) : 0 , ( crypt != null ) ? crypt . getName ( ) : """" , ( crypt != null ) ? crypt . getKey ( ) : null , ( crypt != null ) ? crypt . getTruncationLengthBits ( ) : 0 ) ; } catch ( Exception e ) { // Handle exception } } // Rest of the code } private static final int [ ] DIRECTIONS = { IpSecTransform . DIRECTION_OUT , IpSecTransform . DIRECTION_IN } ;
",,,"public Bundle createTransportModeTransform ( IpSecConfig c , IBinder binder ) { int resourceId = mNextTransformId . getAndIncrement ( ) ; < |startfocus| > for ( int direction : new int [ ] { IpSecTransform . DIRECTION_OUT , IpSecTransform . DIRECTION_IN } ) { < |endfocus| > IpSecAlgorithm auth = c . getAuthentication ( direction ) ; IpSecAlgorithm crypt = c . getEncryption ( direction ) ; try { int result = getNetdInstance ( ) . ipSecAddSecurityAssociation ( resourceId , c . getMode ( ) , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : """" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : """" , ( c . getNetwork ( ) != null ) ? c . getNetwork ( ) . getNetworkHandle ( ) : 0 , c . getSpi ( direction ) , ( auth != null ) ? auth . getName ( ) : """" , ( auth != null ) ? auth . getKey ( ) : null , ( auth != null ) ? auth . getTruncationLengthBits ( ) : 0 , ( crypt != null ) ? crypt . getName ( ) : """" , ( crypt != null ) ? crypt . getKey ( ) : null , ( crypt != null ) ? crypt . getTruncationLengthBits ( ) : 0 ,
",,
304,"*/ public static final int ERROR_AUTHENTICATING = 1 ; // Supplicant Authentication Failure reason codes : /* * * Default reason code for error during authentication . * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a timeout authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; /* * * The reason code if there was a wrong password while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was EAP failure while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ; /* * * Broadcast intent action indicating whether Wi - Fi scanning is allowed currently * @hide */
","< |del| >/ / Supplicant Authentication Failure reason codes :
","<|del|>
",,,"<|del|>
",,,"public static final int ERROR_AUTHENTICATING = 1 ; public static final int ERROR_AUTH_FAILURE_NONE = 0 ; public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ;
",,,"public static final int ERROR_AUTHENTICATING = 1 ; public static final int ERROR_AUTH_FAILURE_NONE = 0 ; public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ;
",,,"*/ public static final int ERROR_AUTHENTICATING = 1 ; // Supplicant Authentication Failure reason codes : /* * * Default reason code for error during authentication . * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a timeout authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a wrong password while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was EAP failure while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ; /* * * Broadcast intent action indicating whether Wi - Fi scanning is allowed currently * @hide */
",,
305,"// Supplicant Authentication Failure reason codes : /* * * The reason code if there was a timeout authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a wrong password while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; /* * * The reason code if there was EAP failure while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ; /* * * Broadcast intent action indicating whether Wi - Fi scanning is allowed currently * @hide */ public static final String WIFI_SCAN_AVAILABLE = ""wifi_scan_available"" ; /* * * Extra int indicating scan availability , WIFI_STATE_ENABLED and WIFI_STATE_DISABLED * @hide */ public static final String EXTRA_SCAN_AVAILABLE = ""scan_enabled"" ; /* *
","< |del| >/ / Supplicant Authentication Failure reason codes :
","<|del|>
",,,"<|del|>
",,,"public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ; public static final String WIFI_SCAN_AVAILABLE = ""wifi_scan_available"" ; public static final String EXTRA_SCAN_AVAILABLE = ""scan_enabled"" ;
",,,"public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ; public static final String WIFI_SCAN_AVAILABLE = ""wifi_scan_available"" ; public static final String EXTRA_SCAN_AVAILABLE = ""scan_enabled"" ;
",,,"// Supplicant Authentication Failure reason codes : /* * * The reason code if there was a timeout authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a wrong password while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was EAP failure while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ; /* * * Broadcast intent action indicating whether Wi - Fi scanning is allowed currently * @hide */ public static final String WIFI_SCAN_AVAILABLE = ""wifi_scan_available"" ; /* * * Extra int indicating scan availability , WIFI_STATE_ENABLED and WIFI_STATE_DISABLED * @hide */ public static final String EXTRA_SCAN_AVAILABLE = ""scan_enabled"" ; /* *
",,
320,"if ( phone instanceof ImsPhone ) { ImsPhone imsPhone = ( ImsPhone ) phone ; imsPhone . sendRttModifyRequest ( textStream ) ; } else { Log . w ( this , ""onStartRtt - not in IMS , so RTT cannot be enabled . "" ) ; } } @Override public void onStopRtt ( ) { // This is not supported by carriers / vendor yet . No - op for now . } @Override public void handleRttUpgradeResponse ( RttTextStream textStream ) { if ( ! isImsConnection ( ) ) { Log . w ( this , ""handleRttUpgradeResponse - not in IMS , so RTT cannot be enabled . "" ) ; return ; } ImsPhone imsPhone = ( ImsPhone ) phone ; imsPhone . sendRttModifyResponse ( textStream ) ; } public void performHold ( ) { Log . v ( this , ""performHold"" ) ; // TODO : Can dialing calls be put on hold as well since they take up the // foreground call slot ? if ( Call . State . ACTIVE == mConnectionState ) { Log . v ( this , ""Holding active call"" ) ; try {
","if ( ! isImsConnection ( ) ) {
","if (!(phone instanceof ImsPhone)) {
",,,"Phone phone = getPhone(); if (!(phone instanceof ImsPhone)) {
",,,"if ( isImsConnection ( ) ) { ImsPhone imsPhone = ( ImsPhone ) getPhone ( ) ; imsPhone . sendRttModifyRequest ( textStream ) ; } else { Log . w ( this , ""onStartRtt - not in IMS , so RTT cannot be enabled . "" ) ; } @Override public void onStopRtt ( ) { // This is not supported by carriers / vendor yet . No - op for now . } @Override public void handleRttUpgradeResponse ( RttTextStream textStream ) { if ( ! isImsConnection ( ) ) { Log . w ( this , ""handleRttUpgradeResponse - not in IMS , so RTT cannot be enabled . "" ) ; return ; } ImsPhone imsPhone = ( ImsPhone ) getPhone ( ) ; imsPhone . sendRttModifyResponse ( textStream ) ; } public void performHold ( ) { Log . v ( this , ""performHold"" ) ; // TODO : Can dialing calls be put on hold as well since they take up the // foreground call slot ? if ( Call . State . ACTIVE == mConnectionState ) { Log . v ( this , ""Holding active call"" ) ; try {
",,,"if ( phone instanceof ImsPhone ) { ImsPhone imsPhone = ( ImsPhone ) phone ; imsPhone . sendRttModifyRequest ( textStream ) ; } else { Log . w ( this , ""onStartRtt - not in IMS , so RTT cannot be enabled . "" ) ; } @Override public void onStopRtt ( ) { // This is not supported by carriers / vendor yet . No - op for now . } @Override public void handleRttUpgradeResponse ( RttTextStream textStream ) { Phone phone = getPhone ( ) ; if ( ! ( phone instanceof ImsPhone ) ) { Log . w ( this , ""handleRttUpgradeResponse - not in IMS , so RTT cannot be enabled . "" ) ; return ; } ImsPhone imsPhone = ( ImsPhone ) phone ; imsPhone . sendRttModifyResponse ( textStream ) ; } public void performHold ( ) { Log . v ( this , ""performHold"" ) ; // TODO : Can dialing calls be put on hold as well since they take up the // foreground call slot ? if ( Call . State . ACTIVE == mConnectionState ) { Log . v ( this , ""Holding active call"" ) ; try { // Perform hold operation } catch ( Exception e ) { Log . e ( this , ""Error performing hold operation"" , e ) ; } } }
",,,"if ( phone instanceof ImsPhone ) { ImsPhone imsPhone = ( ImsPhone ) phone ; imsPhone . sendRttModifyRequest ( textStream ) ; } else { Log . w ( this , ""onStartRtt - not in IMS , so RTT cannot be enabled . "" ) ; } } @Override public void onStopRtt ( ) { // This is not supported by carriers / vendor yet . No - op for now . } @Override public void handleRttUpgradeResponse ( RttTextStream textStream ) { < |startfocus| > if ( ! isImsConnection ( ) ) { < |endfocus| > Log . w ( this , ""handleRttUpgradeResponse - not in IMS , so RTT cannot be enabled . "" ) ; return ; } ImsPhone imsPhone = ( ImsPhone ) getPhone ( ) ; imsPhone . sendRttModifyResponse ( textStream ) ; } public void performHold ( ) { Log . v ( this , ""performHold"" ) ; // TODO : Can dialing calls be put on hold as well since they take up the // foreground call slot ? if ( Call . State . ACTIVE == mConnectionState ) { Log . v ( this , ""Holding active call"" ) ; try {
",,
332,"if ( record == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not available to be deleted"" ) ; } if ( record . pid != getCallingPid ( ) || record . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may delete it ! "" ) ; } // TODO : if releaseResources ( ) throws RemoteException , we can try again to clean up on // binder death . Need to make sure that path is actually functional . record . releaseResources ( ) ; mTransformRecords . remove ( resourceId ) ; record . nullifyRecord ( ) ; } } /* * * Apply an active transport mode transform to a socket , which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override public void applyTransportModeTransform ( ParcelFileDescriptor socket , int resourceId ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ;
","// TODO : if releaseResources ( ) throws RemoteException , we can try again to clean up on // binder death . Need to make sure that path is actually functional .
","// TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional
",,,"// TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional
",,,"if ( record == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not available to be deleted"" ) ; } if ( record . pid != getCallingPid ( ) || record . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may delete it ! "" ) ; } // TODO : if releaseResources ( ) throws RemoteException , we can try again to clean up on binder death . // Need to make sure that path is actually functional record . releaseResources ( ) ; mTransformRecords . remove ( resourceId ) ; record . nullifyRecord ( ) ; } @Override public void applyTransportModeTransform ( ParcelFileDescriptor socket , int resourceId ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; } }
",,,"if ( record == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not available to be deleted"" ) ; } if ( record . pid != getCallingPid ( ) || record . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may delete it ! "" ) ; } record . releaseResources ( ) ; mTransformRecords . remove ( resourceId ) ; record . nullifyRecord ( ) ; } /* * * Apply an active transport mode transform to a socket , which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override public void applyTransportModeTransform ( ParcelFileDescriptor socket , int resourceId ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; info = mTransformRecords . get ( resourceId ) ; // TODO : if releaseResources ( ) throws RemoteException , we can try again to clean up on binder death . // Need to make sure that path is actually functional info . releaseResources ( ) ; } }
",,,"if ( record == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not available to be deleted"" ) ; } if ( record . pid != getCallingPid ( ) || record . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may delete it ! "" ) ; } < |startfocus| > // TODO : if releaseResources ( ) throws RemoteException , we can try again to clean up on binder death . // Need to make sure that path is actually functional < |endfocus| > record . releaseResources ( ) ; mTransformRecords . remove ( resourceId ) ; record . nullifyRecord ( ) ; } } /* * * Apply an active transport mode transform to a socket , which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override public void applyTransportModeTransform ( ParcelFileDescriptor socket , int resourceId ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not available to be applied"" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may apply it ! "" ) ; } if ( info . mode != IpSecTransform . MODE_TRANSPORT ) { throw new IllegalArgumentException ( ""Only a transport mode transform may be applied to a socket"" ) ; } if ( info . socket != null ) { throw new IllegalStateException ( ""Transform "" + resourceId + "" is already applied to a socket"" ) ; } info . socket = socket ; } } /* * * Remove an active transport mode transform from a socket , which will remove the IPsec security * association as a correspondent policy from the provided socket */ @Override public void removeTransportModeTransform ( ParcelFileDescriptor socket ) throws RemoteException { synchronized ( mTransformRecords ) { for ( TransformRecord info : mTransformRecords . values ( ) ) { if ( info . socket == socket ) { info . socket = null ; return ; } } throw new IllegalArgumentException ( ""No transform is applied to the provided socket"" ) ; } } /* * * Apply an active tunnel mode transform to a socket , which will apply the IPsec security * association as a policy to the provided socket */ @Override public void applyTunnelModeTransform ( ParcelFileDescriptor socket , int resourceId , int direction ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not available to be applied"" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may apply it ! "" ) ; } if ( info . mode != IpSecTransform . MODE_TUNNEL ) { throw new IllegalArgumentException ( ""Only a tunnel mode transform may be applied to a socket"" ) ; } if ( info . socket != null ) { throw new IllegalStateException ( ""Transform "" + resourceId + "" is already applied to a socket"" ) ; } info . socket = socket ; info . direction = direction ; } } /* * * Remove an active tunnel mode transform from a socket , which will remove the IPsec security * association as a policy from the provided socket */ @Override public void removeTunnelModeTransform ( ParcelFileDescriptor socket ) throws RemoteException { synchronized ( mTransformRecords ) { for ( TransformRecord info : mTransformRecords . values ( ) ) { if ( info . socket == socket ) { info . socket = null ; return ; } } throw new IllegalArgumentException ( ""No transform is applied to the provided socket"" ) ; } } /* * * Apply an active tunnel mode transform to a socket , which will apply the IPsec security * association as a policy to the provided socket */ @Override public void applyTunnelModeTransform ( ParcelFileDescriptor socket , int resourceId , int direction ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not available to be applied"" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may apply it ! "" ) ; } if ( info . mode != IpSecTransform . MODE_TUNNEL ) { throw new IllegalArgumentException ( ""Only a tunnel mode transform may be applied to a socket"" ) ; } if ( info . socket != null ) { throw new IllegalStateException ( ""Transform "" + resourceId + "" is already applied to a socket"" ) ; } info . socket = socket ; info . direction = direction ; } } /* * * Remove an active tunnel mode transform from a socket , which will remove the IPsec security * association as a policy from the provided socket */ @Override public void removeTunnelModeTransform ( ParcelFileDescriptor socket ) throws RemoteException { synchronized ( mTransformRecords ) { for ( TransformRecord info : mTransformRecords . values ( ) ) { if ( info . socket == socket ) { info . socket = null ; return ; } } throw new IllegalArgumentException ( ""No transform is applied to the provided socket"" ) ; } } /* * * Apply an active tunnel mode transform to a socket , which will apply the IPsec security * association as a policy to the provided socket */ @Override public void applyTunnelModeTransform ( ParcelFileDescriptor socket , int resourceId , int direction ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not available to be applied"" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may apply it ! "" ) ; } if ( info . mode != IpSecTransform . MODE_TUNNEL ) { throw new IllegalArgumentException ( ""Only a tunnel mode transform may be applied to a socket"" ) ; } if ( info . socket != null ) { throw new IllegalStateException ( ""Transform "" + resourceId + "" is already applied to a socket"" ) ; } info . socket = socket ; info . direction = direction ; } } /* * * Remove an active tunnel mode transform from a socket , which will remove the IPsec security * association as a policy from the provided socket */ @Override public void removeTunnelModeTransform ( ParcelFileDescriptor socket ) throws RemoteException { synchronized ( mTransformRecords ) { for ( TransformRecord info : mTransformRecords . values ( ) ) { if ( info . socket == socket ) { info . socket = null ; return ; } } throw new IllegalArgumentException ( ""No transform is applied to the provided socket"" ) ; } } /* * * Apply an active tunnel mode transform to a socket , which will apply the IPsec security * association as a policy to the provided socket */ @Override public void applyTunnelModeTransform ( ParcelFileDescriptor socket , int resourceId , int direction ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not available to be applied"" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may apply it ! "" ) ; } if ( info . mode != IpSecTransform . MODE_TUNNEL ) { throw new IllegalArgumentException ( ""Only a tunnel mode
",,
344,"mResourceId , direction , ( mConfig . getLocalAddress ( ) != null ) ? mConfig . getLocalAddress ( ) . getHostAddress ( ) : """" , ( mConfig . getRemoteAddress ( ) != null ) ? mConfig . getRemoteAddress ( ) . getHostAddress ( ) : """" , mConfig . getSpi ( direction ) ) ; } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception } catch ( RemoteException e ) { Log . e ( TAG , ""Failed to delete SA with ID : "" + mResourceId ) ; } }
","Log . e ( TAG , ""Failed to delete SA with ID : "" + mResourceId ) ;
","throw e.rethrowFromSystemServer(); } catch (IOException e) {
",,,"throw e.rethrowFromSystemServer(); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception
",,,"try { mResourceId , direction , ( mConfig . getLocalAddress ( ) != null ) ? mConfig . getLocalAddress ( ) . getHostAddress ( ) : """" , ( mConfig . getRemoteAddress ( ) != null ) ? mConfig . getRemoteAddress ( ) . getHostAddress ( ) : """" , mConfig . getSpi ( direction ) ) ; } catch ( ServiceSpecificException e ) { int errorCode = e . errorCode ; throw new IOException ( ""ServiceSpecificException : "" + errorCode , e ) ; } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; }
",,,"mResourceId , direction , ( mConfig . getLocalAddress ( ) != null ) ? mConfig . getLocalAddress ( ) . getHostAddress ( ) : """" , ( mConfig . getRemoteAddress ( ) != null ) ? mConfig . getRemoteAddress ( ) . getHostAddress ( ) : """" , mConfig . getSpi ( direction ) ) ; } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } }
",,,"mResourceId , direction , ( mConfig . getLocalAddress ( ) != null ) ? mConfig . getLocalAddress ( ) . getHostAddress ( ) : """" , ( mConfig . getRemoteAddress ( ) != null ) ? mConfig . getRemoteAddress ( ) . getHostAddress ( ) : """" , mConfig . getSpi ( direction ) ) ; } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception } catch ( RemoteException e ) { < |startfocus| > throw e . rethrowFromSystemServer ( ) ; < |endfocus| > } }
",,
348,"info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not active"" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may apply it ! "" ) ; } IpSecConfig c = info . getConfig ( ) ; try { for ( int direction : DIRECTIONS ) { getNetdInstance ( ) . ipSecApplyTransportModeTransform ( socket . getFileDescriptor ( ) , resourceId , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : """" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : """" , c . getSpi ( direction ) ) ; } } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception
","for ( int direction : DIRECTIONS ) {
","for (int direction : new int[] {IpSecTransform.DIRECTIONS, IpSecTransform.DIRECTIONS}) {
",,,"for (int direction : IpSecTransform.DIRECTIONS) {
",,,"info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not active"" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may apply it ! "" ) ; } IpSecConfig c = info . getConfig ( ) ; try { for ( int direction : IpSecTransform . DIRECTIONS ) { getNetdInstance ( ) . ipSecApplyTransportModeTransform ( socket . getFileDescriptor ( ) , resourceId , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : """" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : """" , c . getSpi ( direction ) ) ; } } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception }
",,,"info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not active"" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may apply it ! "" ) ; } IpSecConfig c = info . getConfig ( ) ; try { for ( int direction : IpSecTransform . DIRECTIONS ) { getNetdInstance ( ) . ipSecApplyTransportModeTransform ( socket . getFileDescriptor ( ) , resourceId , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : """" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : """" , c . getSpi ( direction ) ) ; } } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception }
",,,"info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( ""Transform "" + resourceId + "" is not active"" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( ""Only the owner of an IpSec Transform may apply it ! "" ) ; } IpSecConfig c = info . getConfig ( ) ; try { < |startfocus| > for ( int direction : IpSecTransform . DIRECTIONS ) { < |endfocus| > getNetdInstance ( ) . ipSecApplyTransportModeTransform ( socket . getFileDescriptor ( ) , resourceId , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : """" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : """" , c . getSpi ( direction ) ) ; } } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception
",,
358,"mHandler . sendMessageDelayed ( msg1 , 1000 ) ; } } break ; case MSG_INCOMING_CONNECTION_RETRY : if ( mBatchs . size ( ) == 0 ) { Log . i ( TAG , ""Start Obex Server"" ) ; createServerSession ( mPendingConnection ) ; mIncomingRetries = 0 ; mPendingConnection = null ; } else { if ( mIncomingRetries == 20 ) { Log . w ( TAG , ""Retried 20 seconds , reject connection"" ) ; try { mPendingConnection . close ( ) ; } catch ( IOException e ) { Log . e ( TAG , ""close tranport error"" ) ; } mIncomingRetries = 0 ; mPendingConnection = null ; } else { Log . i ( TAG , ""OPP busy ! Retry after 1 second"" ) ; mIncomingRetries = mIncomingRetries + 1 ; Message msg2 = Message . obtain ( mHandler ) ; msg2 . what = MSG_INCOMING_CONNECTION_RETRY ; mHandler . sendMessageDelayed ( msg2 , 1000 ) ; } } break ; }
","< |del| > if ( mServerSocket != null ) { mServerSocket . prepareForNewConnect ( ) ; }
","<|del|>
",,,"<|del|>
",,,"mHandler . sendMessageDelayed ( msg1 , 1000 ) ; } break ; case MSG_INCOMING_CONNECTION_RETRY : if ( mBatchs . size ( ) == 0 ) { Log . i ( TAG , ""Start Obex Server"" ) ; createServerSession ( mPendingConnection ) ; mIncomingRetries = 0 ; mPendingConnection = null ; } else { if ( mIncomingRetries == 20 ) { Log . w ( TAG , ""Retried 20 seconds , reject connection"" ) ; if ( mServerSocket != null ) { mServerSocket . prepareForNewConnect ( ) ; } try { mPendingConnection . close ( ) ; } catch ( IOException e ) { Log . e ( TAG , ""close tranport error"" ) ; } mIncomingRetries = 0 ; mPendingConnection = null ; } else { Log . i ( TAG , ""OPP busy ! Retry after 1 second"" ) ; mIncomingRetries = mIncomingRetries + 1 ; Message msg2 = Message . obtain ( mHandler ) ; msg2 . what = MSG_INCOMING_CONNECTION_RETRY ; mHandler . sendMessageDelayed ( msg2 , 1000 ) ; } } break ;
",,,"mHandler . sendMessageDelayed ( msg1 , 1000 ) ; } break ; case MSG_INCOMING_CONNECTION_RETRY : if ( mBatchs . size ( ) == 0 ) { Log . i ( TAG , ""Start Obex Server"" ) ; createServerSession ( mPendingConnection ) ; mIncomingRetries = 0 ; mPendingConnection = null ; } else { if ( mIncomingRetries == 20 ) { Log . w ( TAG , ""Retried 20 seconds , reject connection"" ) ; if ( mServerSocket != null ) { mServerSocket . prepareForNewConnect ( ) ; } try { mPendingConnection . close ( ) ; } catch ( IOException e ) { Log . e ( TAG , ""close tranport error"" ) ; } mIncomingRetries = 0 ; mPendingConnection = null ; } else { Log . i ( TAG , ""OPP busy ! Retry after 1 second"" ) ; mIncomingRetries = mIncomingRetries + 1 ; Message msg2 = Message . obtain ( mHandler ) ; msg2 . what = MSG_INCOMING_CONNECTION_RETRY ; mHandler . sendMessageDelayed ( msg2 , 1000 ) ; } } break ;
",,,"mHandler . sendMessageDelayed ( msg1 , 1000 ) ; } } break ; case MSG_INCOMING_CONNECTION_RETRY : if ( mBatchs . size ( ) == 0 ) { Log . i ( TAG , ""Start Obex Server"" ) ; createServerSession ( mPendingConnection ) ; mIncomingRetries = 0 ; mPendingConnection = null ; } else { if ( mIncomingRetries == 20 ) { Log . w ( TAG , ""Retried 20 seconds , reject connection"" ) ; try { mPendingConnection . close ( ) ; } catch ( IOException e ) { Log . e ( TAG , ""close tranport error"" ) ; } < |startfocus| > if ( mServerSocket != null ) { mServerSocket . prepareForNewConnect ( ) ; } < |endfocus| > mIncomingRetries = 0 ; mPendingConnection = null ; } else { Log . i ( TAG , ""OPP busy ! Retry after 1 second"" ) ; mIncomingRetries = mIncomingRetries + 1 ; Message msg2 = Message . obtain ( mHandler ) ; msg2 . what = MSG_INCOMING_CONNECTION_RETRY ; mHandler . sendMessageDelayed ( msg2 , 1000 ) ; } } break ; }
",,
371,"assertEquals ( TimeZoneDistroInstaller . INSTALL_SUCCESS , installer . stageInstallWithErrorCode ( stagedDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder ( NEWER_RULES_VERSION , 1 ) . setTzLookupXml ( null ) . buildUnvalidated ( ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_FAIL_BAD_DISTRO_STRUCTURE , installer . stageInstallWithErrorCode ( incompleteDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; assertNoInstalledDistro ( ) ; } /* * Tests that a distro with a bad tzlookup file will not update the content . */ public void testStageInstallWithErrorCode_badTzLookupFile ( ) throws Exception { TimeZoneDistro stagedDistro = createValidTimeZoneDistro ( NEW_RULES_VERSION , 1 ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_SUCCESS , installer . stageInstallWithErrorCode ( stagedDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder ( NEWER_RULES_VERSION , 1 ) . setTzLookupXml ( "" < foo / > "" ) . buildUnvalidated ( ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_FAIL_VALIDATION_ERROR , installer . stageInstallWithErrorCode ( incompleteDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ;
","/* * Tests that a distro with a bad tzlookup file will not update the content . */
","/** Tests that a distro with a missing tzlookup file will not update the content. */
",,,"/** * Tests that a distro with a missing tzlookup file will not update the content. */
",,,"// Test that a distro with a missing tzlookup file will not update the content . public void testStageInstallWithErrorCode_badTzLookupFile ( ) throws Exception { TimeZoneDistro stagedDistro = createValidTimeZoneDistro ( NEW_RULES_VERSION , 1 ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_SUCCESS , installer . stageInstallWithErrorCode ( stagedDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder ( NEWER_RULES_VERSION , 1 ) . setTzLookupXml ( "" < foo / > "" ) . buildUnvalidated ( ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_FAIL_VALIDATION_ERROR , installer . stageInstallWithErrorCode ( incompleteDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; }
",,,"assertEquals ( TimeZoneDistroInstaller . INSTALL_SUCCESS , installer . stageInstallWithErrorCode ( stagedDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder ( NEWER_RULES_VERSION , 1 ) . setTzLookupXml ( null ) . buildUnvalidated ( ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_FAIL_BAD_DISTRO_STRUCTURE , installer . stageInstallWithErrorCode ( incompleteDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; assertNoInstalledDistro ( ) ; public void testStageInstallWithErrorCode_badTzLookupFile ( ) throws Exception { TimeZoneDistro stagedDistro = createValidTimeZoneDistro ( NEW_RULES_VERSION , 1 ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_SUCCESS , installer . stageInstallWithErrorCode ( stagedDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder ( NEWER_RULES_VERSION , 1 ) . setTzLookupXml ( "" < foo / > "" ) . buildUnvalidated ( ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_FAIL_VALIDATION_ERROR , installer . stageInstallWithErrorCode ( incompleteDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; }
",,,"assertEquals ( TimeZoneDistroInstaller . INSTALL_SUCCESS , installer . stageInstallWithErrorCode ( stagedDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder ( NEWER_RULES_VERSION , 1 ) . setTzLookupXml ( null ) . buildUnvalidated ( ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_FAIL_BAD_DISTRO_STRUCTURE , installer . stageInstallWithErrorCode ( incompleteDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; assertNoInstalledDistro ( ) ; } < |startfocus| > /* * Tests that a distro with a missing tzlookup file will not update the content . */ < |endfocus| > public void testStageInstallWithErrorCode_badTzLookupFile ( ) throws Exception { TimeZoneDistro stagedDistro = createValidTimeZoneDistro ( NEW_RULES_VERSION , 1 ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_SUCCESS , installer . stageInstallWithErrorCode ( stagedDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder ( NEWER_RULES_VERSION , 1 ) . setTzLookupXml ( "" < foo / > "" ) . buildUnvalidated ( ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_FAIL_VALIDATION_ERROR , installer . stageInstallWithErrorCode ( incompleteDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ;
",,
374,"public static char maybeStripMarkers ( String symbol , char fallback ) { final int length = symbol . length ( ) ; if ( length == 1 ) { char c = symbol . charAt ( 0 ) ; if ( c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000' ) { return c ; } } else if ( length > 1 ) { char nonMarker = 0 ; for ( int i = 0 ; i < length ; i ++ ) { char c = symbol . charAt ( i ) ; if ( c == '\u200E' || c == '\u200F' || c == '\u061C' ) { continue ; } if ( nonMarker != 0 || c == '\u0000' ) { // more than one non - marker character or U + 0000 in the input string . return fallback ; } nonMarker = c ; } if ( nonMarker != 0 ) { return nonMarker ; } } return fallback ;
","for ( int i = 0 ; i < length ; i ++ ) { char c = symbol . charAt ( i ) ;
","for (char c : symbol.CharArray()) {
",,,"for (char c : symbol.toCharArray()) {
",,,"public static char maybeStripMarkers ( String symbol , char fallback ) { final int length = symbol . length ( ) ; if ( length == 1 ) { char c = symbol . charAt ( 0 ) ; if ( c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000' ) { return c ; } } else if ( length > 1 ) { char nonMarker = 0 ; char [ ] chars = symbol . toCharArray ( ) ; for ( int i = 0 ; i < length ; i ++ ) { char c = chars [ i ] ; if ( c == '\u200E' || c == '\u200F' || c == '\u061C' ) { continue ; } if ( nonMarker != 0 || c == '\u0000' ) { return fallback ; } nonMarker = c ; } if ( nonMarker != 0 ) { return nonMarker ; } } return fallback ; }
",,,"public static char maybeStripMarkers ( String symbol , char fallback ) { final int length = symbol . length ( ) ; if ( length == 1 ) { char c = symbol . charAt ( 0 ) ; if ( c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000' ) { return c ; } } else if ( length > 1 ) { char nonMarker = 0 ; for ( int i = 0 ; i < length ; i ++ ) { char c = symbol . charAt ( i ) ; if ( c == '\u200E' || c == '\u200F' || c == '\u061C' ) { continue ; } if ( nonMarker != 0 || c == '\u0000' ) { // more than one non - marker character or U + 0000 in the input string . return fallback ; } nonMarker = c ; } if ( nonMarker != 0 ) { return nonMarker ; } } return fallback ; }
",,,"public static char maybeStripMarkers ( String symbol , char fallback ) { final int length = symbol . length ( ) ; if ( length == 1 ) { char c = symbol . charAt ( 0 ) ; if ( c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000' ) { return c ; } } else if ( length > 1 ) { char nonMarker = 0 ; < |startfocus| > for ( int i = 0 ; i < length ; i ++ ) { char c = symbol . charAt ( i ) ; < |endfocus| > if ( c == '\u200E' || c == '\u200F' || c == '\u061C' ) { continue ; } if ( nonMarker != 0 || c == '\u0000' ) { // more than one non - marker character or U + 0000 in the input string . return fallback ; } nonMarker = c ; } if ( nonMarker != 0 ) { return nonMarker ; } } return fallback ;
",,
382,"intent . putExtra ( WifiManager . EXTRA_WIFI_AP_STATE , state ) ; mServiceContext . sendStickyBroadcastAsUser ( intent , UserHandle . ALL ) ; } @Test public void workingWifiHotspot ( ) throws Exception { when ( mConnectivityManager . isTetheringSupported ( ) ) . thenReturn ( true ) ; when ( mWifiManager . setWifiApEnabled ( any ( WifiConfiguration . class ) , anyBoolean ( ) ) ) . thenReturn ( true ) ; // Emulate externally - visible WifiManager effects , causing the // per - interface state machine to start up , and telling us that // hotspot mode is to be started . mTethering . interfaceStatusChanged ( mTestIfname , true ) ; sendWifiApStateChanged ( WifiManager . WIFI_AP_STATE_ENABLED ) ; mLooper . dispatchAll ( ) ; verify ( mNMService , times ( 1 ) ) . listInterfaces ( ) ; verify ( mNMService , times ( 1 ) ) . getInterfaceConfig ( mTestIfname ) ; verify ( mNMService , times ( 1 ) ) . setInterfaceConfig ( eq ( mTestIfname ) , any ( InterfaceConfiguration . class ) ) ; verify ( mNMService , times ( 1 ) ) . tetherInterface ( mTestIfname ) ; verify ( mNMService , times ( 1 ) ) . setIpForwardingEnabled ( true ) ; verify ( mNMService , times ( 1 ) ) . startTethering ( any ( String [ ] . class ) ) ; verifyNoMoreInteractions ( mNMService ) ;
","// per - interface state machine to start up , and telling us that // hotspot mode is to be started .
","// per-interface state machine starts up, and telling us that hotspot mode is to be started.
",,,"// per-interface state machine starts up, and telling us that hotspot mode is to start.
",,,"Intent intent = new Intent ( ) ; intent . putExtra ( WifiManager . EXTRA_WIFI_AP_STATE , state ) ; mServiceContext . sendStickyBroadcastAsUser ( intent , UserHandle . ALL ) ; @Test public void testWorkingWifiHotspot ( ) throws Exception { when ( mConnectivityManager . isTetheringSupported ( ) ) . thenReturn ( true ) ; when ( mWifiManager . setWifiApEnabled ( any ( WifiConfiguration . class ) , anyBoolean ( ) ) ) . thenReturn ( true ) ; // Emulate externally - visible WifiManager effects , causing the per - interface state machine starts up , and telling us that hotspot mode is to be started . mTethering . interfaceStatusChanged ( mTestIfname , true ) ; sendWifiApStateChanged ( WifiManager . WIFI_AP_STATE_ENABLED ) ; mLooper . dispatchAll ( ) ; verify ( mNMService , times ( 1 ) ) . listInterfaces ( ) ; verify ( mNMService , times ( 1 ) ) . getInterfaceConfig ( mTestIfname ) ; verify ( mNMService , times ( 1 ) ) . setInterfaceConfig ( eq ( mTestIfname ) , any ( InterfaceConfiguration . class ) ) ; verify ( mNMService , times ( 1 ) ) . tetherInterface ( mTestIfname ) ; verify ( mNMService , times ( 1 ) ) . setIpForwardingEnabled ( true ) ; verify ( mNMService , times ( 1 ) ) . startTethering ( any ( String [ ] . class ) ) ; verifyNoMoreInteractions ( mNMService ) ; }
",,,"intent . putExtra ( WifiManager . EXTRA_WIFI_AP_STATE , state ) ; mServiceContext . sendStickyBroadcastAsUser ( intent , UserHandle . ALL ) ; } @Test public void workingWifiHotspot ( ) throws Exception { when ( mConnectivityManager . isTetheringSupported ( ) ) . thenReturn ( true ) ; when ( mWifiManager . setWifiApEnabled ( any ( WifiConfiguration . class ) , anyBoolean ( ) ) ) . thenReturn ( true ) ; // Emulate externally - visible WifiManager effects , causing the per - interface state machine starts up , and telling us that hotspot mode is to be started . mTethering . interfaceStatusChanged ( mTestIfname , true ) ; sendWifiApStateChanged ( WifiManager . WIFI_AP_STATE_ENABLED ) ; mLooper . dispatchAll ( ) ; verify ( mNMService , times ( 1 ) ) . listInterfaces ( ) ; verify ( mNMService , times ( 1 ) ) . getInterfaceConfig ( mTestIfname ) ; verify ( mNMService , times ( 1 ) ) . setInterfaceConfig ( eq ( mTestIfname ) , any ( InterfaceConfiguration . class ) ) ; verify ( mNMService , times ( 1 ) ) . tetherInterface ( mTestIfname ) ; verify ( mNMService , times ( 1 ) ) . setIpForwardingEnabled ( true ) ; verify ( mNMService , times ( 1 ) ) . startTethering ( any ( String [ ] . class ) ) ; verifyNoMoreInteractions ( mNMService ) ; }
",,,"intent . putExtra ( WifiManager . EXTRA_WIFI_AP_STATE , state ) ; mServiceContext . sendStickyBroadcastAsUser ( intent , UserHandle . ALL ) ; } @Test public void workingWifiHotspot ( ) throws Exception { when ( mConnectivityManager . isTetheringSupported ( ) ) . thenReturn ( true ) ; when ( mWifiManager . setWifiApEnabled ( any ( WifiConfiguration . class ) , anyBoolean ( ) ) ) . thenReturn ( true ) ; // Emulate externally - visible WifiManager effects , causing the < |startfocus| > // per - interface state machine starts up , and telling us that hotspot // mode is to be started . < |endfocus| > mTethering . interfaceStatusChanged ( mTestIfname , true ) ; sendWifiApStateChanged ( WifiManager . WIFI_AP_STATE_ENABLED ) ; mLooper . dispatchAll ( ) ; verify ( mNMService , times ( 1 ) ) . listInterfaces ( ) ; verify ( mNMService , times ( 1 ) ) . getInterfaceConfig ( mTestIfname ) ; verify ( mNMService , times ( 1 ) ) . setInterfaceConfig ( eq ( mTestIfname ) , any ( InterfaceConfiguration . class ) ) ; verify ( mNMService , times ( 1 ) ) . tetherInterface ( mTestIfname ) ; verify ( mNMService , times ( 1 ) ) . setIpForwardingEnabled ( true ) ; verify ( mNMService , times ( 1 ) ) . startTethering ( any ( String [ ] . class ) ) ; verifyNoMoreInteractions ( mNMService ) ;
",,
384,"private void combineSpecifiers ( NetworkCapabilities nc ) { if ( mNetworkSpecifier != null && ! mNetworkSpecifier . equals ( nc . getNetworkSpecifier ( ) ) ) { throw new IllegalStateException ( ""Can't combine two networkSpecifiers"" ) ; } setNetworkSpecifier ( nc . mNetworkSpecifier ) ;
","setNetworkSpecifier ( nc . mNetworkSpecifier ) ;
","setNetworkSpecifier(nc.mNetworkSpecifier);
",,,"setNetworkSpecifier(nc.mNetworkSpecifier);
",,,"private void combineSpecifiers ( NetworkCapabilities nc ) { if ( mNetworkSpecifier != null && ! mNetworkSpecifier . equals ( nc . mNetworkSpecifier ) ) { throw new IllegalStateException ( ""Can't combine two networkSpecifiers"" ) ; } setNetworkSpecifier ( nc . mNetworkSpecifier ) ; }
",,,"private void combineSpecifiers ( NetworkCapabilities nc ) { if ( mNetworkSpecifier != null && ! mNetworkSpecifier . equals ( nc . getNetworkSpecifier ( ) ) ) { throw new IllegalStateException ( ""Can't combine two networkSpecifiers"" ) ; } setNetworkSpecifier ( nc . getNetworkSpecifier ( ) ) ; }
",,,"private void combineSpecifiers ( NetworkCapabilities nc ) { if ( mNetworkSpecifier != null && ! mNetworkSpecifier . equals ( nc . mNetworkSpecifier ) ) { throw new IllegalStateException ( ""Can't combine two networkSpecifiers"" ) ; } < |startfocus| > setNetworkSpecifier ( nc . mNetworkSpecifier ) ; < |endfocus| >
",,
388,"public void setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { mNetworkCapabilities . setNetworkSpecifier ( networkSpecifier ) ; mNetworkAgent . sendNetworkCapabilities ( mNetworkCapabilities ) ;
","public void setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { mNetworkCapabilities . setNetworkSpecifier ( networkSpecifier ) ;
","public void setNetworkSpecifier(String specifier) { mNetworkCapabilities.setNetworkSpecifier(new NetworkSpecifier(specifier));
",,,"public void setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (TextUtils.isEmpty(networkSpecifier)) { mNetworkCapabilities.setNetworkSpecifier(null); } else { mNetworkCapabilities.setNetworkSpecifier(networkSpecifier); }
",,,"public void setNetworkSpecifier ( NetworkSpecifier specifier ) { if ( specifier == null ) { mNetworkCapabilities . setNetworkSpecifier ( null ) ; } else { mNetworkCapabilities . setNetworkSpecifier ( specifier ) ; } mNetworkAgent . sendNetworkCapabilities ( mNetworkCapabilities ) ; }
",,,"public void setNetworkSpecifier ( NetworkSpecifier specifier ) { if ( specifier == null ) { mNetworkCapabilities . setNetworkSpecifier ( null ) ; } else { mNetworkCapabilities . setNetworkSpecifier ( specifier ) ; } mNetworkAgent . sendNetworkCapabilities ( mNetworkCapabilities ) ; }
",,,"public void setNetworkSpecifier ( String specifier ) { if ( TextUtils . isEmpty ( specifier ) ) { mNetworkCapabilities . setNetworkSpecifier ( null ) ; } else { mNetworkCapabilities . setNetworkSpecifier ( new StringNetworkSpecifier ( specifier ) ) ; } mNetworkAgent . sendNetworkCapabilities ( mNetworkCapabilities ) ;
",,
393,"private int phoneIdForRequest ( NetworkRequest netRequest ) { NetworkSpecifier specifier = netRequest . networkCapabilities . getNetworkSpecifier ( ) ; int subId ; if ( specifier == null ) { subId = mDefaultDataSubscription ; } else if ( specifier instanceof StringNetworkSpecifier ) { try { subId = Integer . parseInt ( ( ( StringNetworkSpecifier ) specifier ) . specifier ) ; } catch ( NumberFormatException e ) { Rlog . e ( LOG_TAG , ""NumberFormatException on "" + ( ( StringNetworkSpecifier ) specifier ) . specifier ) ; subId = INVALID_SUBSCRIPTION_ID ; } } else { subId = INVALID_SUBSCRIPTION_ID ; } int phoneId = INVALID_PHONE_INDEX ; if ( subId == INVALID_SUBSCRIPTION_ID ) return phoneId ; for ( int i = 0 ; i < mNumPhones ; i ++ ) { if ( mPhoneSubscriptions [ i ] == subId ) { phoneId = i ; break ; } } return phoneId ;
","try { subId = Integer . parseInt ( ( ( StringNetworkSpecifier ) specifier ) . specifier ) ; } catch ( NumberFormatException e ) { Rlog . e ( LOG_TAG , ""NumberFormatException on "" + ( ( StringNetworkSpecifier ) specifier ) . specifier ) ; subId = INVALID_SUBSCRIPTION_ID ; }
","subId = Integer.parseInt(((StringNetworkSpecifier) specifier).specifier);
",,,"subId = Integer.parseInt(((StringNetworkSpecifier) specifier).specifier);
",,,"private int phoneIdForRequest ( NetworkRequest netRequest ) { NetworkSpecifier specifier = netRequest . networkCapabilities . getNetworkSpecifier ( ) ; int subId ; if ( specifier == null ) { subId = mDefaultDataSubscription ; } else if ( specifier instanceof StringNetworkSpecifier ) { try { subId = Integer . parseInt ( ( ( StringNetworkSpecifier ) specifier ) . specifier ) ; } catch ( NumberFormatException e ) { subId = INVALID_SUBSCRIPTION_ID ; } } else { subId = INVALID_SUBSCRIPTION_ID ; } int phoneId = INVALID_PHONE_INDEX ; if ( subId == INVALID_SUBSCRIPTION_ID ) { return phoneId ; } for ( int i = 0 ; i < mNumPhones ; i ++ ) { if ( mPhoneSubscriptions [ i ] == subId ) { phoneId = i ; break ; } } return phoneId ; }
",,,"private int phoneIdForRequest ( NetworkRequest netRequest ) { NetworkSpecifier specifier = netRequest . networkCapabilities . getNetworkSpecifier ( ) ; int subId ; if ( specifier == null ) { subId = mDefaultDataSubscription ; } else if ( specifier instanceof StringNetworkSpecifier ) { try { subId = Integer . parseInt ( ( ( StringNetworkSpecifier ) specifier ) . specifier ) ; } catch ( NumberFormatException e ) { subId = INVALID_SUBSCRIPTION_ID ; } } else { subId = INVALID_SUBSCRIPTION_ID ; } int phoneId = INVALID_PHONE_INDEX ; if ( subId == INVALID_SUBSCRIPTION_ID ) { return phoneId ; } for ( int i = 0 ; i < mNumPhones ; i ++ ) { if ( mPhoneSubscriptions [ i ] == subId ) { phoneId = i ; break ; } } return phoneId ; }
",,,"private int phoneIdForRequest ( NetworkRequest netRequest ) { NetworkSpecifier specifier = netRequest . networkCapabilities . getNetworkSpecifier ( ) ; int subId ; if ( specifier == null ) { subId = mDefaultDataSubscription ; } else if ( specifier instanceof StringNetworkSpecifier ) { < |startfocus| > try { subId = Integer . parseInt ( ( ( StringNetworkSpecifier ) specifier ) . specifier ) ; } catch ( NumberFormatException e ) { subId = INVALID_SUBSCRIPTION_ID ; } < |endfocus| > } else { subId = INVALID_SUBSCRIPTION_ID ; } int phoneId = INVALID_PHONE_INDEX ; if ( subId == INVALID_SUBSCRIPTION_ID ) return phoneId ; for ( int i = 0 ; i < mNumPhones ; i ++ ) { if ( mPhoneSubscriptions [ i ] == subId ) { phoneId = i ; break ; } } return phoneId ;
",,
407,"private static byte getRandomNonZeroByte ( ) { final byte random = ( byte ) ( new Random ( ) ) . nextInt ( ) ; // Don't pick the subnet - router anycast address , since that might be // in use on the upstream already . return ( random != 0 ) ? random : 0x1 ;
","// Don't pick the subnet - router anycast address , since that might be // in use on the upstream already .
","// Don't pick the subnet-router anycast address, since that // mind be to the upstream already.
",,,"// Don't pick the subnet-router anycast address, since that might be to the // upstream already.
",,,"private static byte getRandomNonZeroByte ( ) { final byte random = ( byte ) ( new Random ( ) ) . nextInt ( ) ; if ( random == 0 ) { return 0x1 ; } return random ; } The code now checks if the random byte generated is equal to 0 . If it is , it returns 0x1 ( which is a non - zero byte ) . Otherwise , it returns the random byte generated .
",,,"private static byte getRandomNonZeroByte ( ) { final byte random = ( byte ) ( new Random ( ) ) . nextInt ( ) ; return ( random != 0 ) ? random : 0x1 ; }
",,,"private static byte getRandomNonZeroByte ( ) { final byte random = ( byte ) ( new Random ( ) ) . nextInt ( ) ; < |startfocus| > // Don't pick the subnet - router anycast address , since that might be // to the upstream already . < |endfocus| > return ( random != 0 ) ? random : 0x1 ;
",,
417,"// by sending CMD_CLEAR_ERROR if ( error == ConnectivityManager . TETHER_ERROR_MASTER_ERROR ) { mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_CLEAR_ERROR , who ) ; } switch ( state ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : mUpstreamWantingIfaces . remove ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_UNREQUESTED , who ) ; break ; case IControlsTethering . STATE_TETHERED : case IControlsTethering . STATE_LOCAL_HOTSPOT : mUpstreamWantingIfaces . remove ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , who ) ; break ; } sendTetherStateChangedBroadcast ( ) ;
","< |del| > mUpstreamWantingIfaces . add ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , who ) ; break ;
","mUpstreamWantingIfaces.add(iface); mTetherMasterSM.sendMessage(TetherMasterSM.CMD_TETHER_MODE_REQUESTED, who); break;
",,,"<|del|>
",,,"// by sending CMD_CLEAR_ERROR if ( error == ConnectivityManager . TETHER_ERROR_MASTER_ERROR ) { mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_CLEAR_ERROR , who ) ; } switch ( state ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : mUpstreamWantingIfaces . remove ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_UNREQUESTED , who ) ; break ; case IControlsTethering . STATE_TETHERED : mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , who ) ; mUpstreamWantingIfaces . add ( iface ) ; break ; case IControlsTethering . STATE_LOCAL_HOTSPOT : mUpstreamWantingIfaces . remove ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , who ) ; break ; } sendTetherStateChangedBroadcast ( ) ;
",,,"// by sending CMD_CLEAR_ERROR if ( error == ConnectivityManager . TETHER_ERROR_MASTER_ERROR ) { mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_CLEAR_ERROR , who ) ; } switch ( state ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : mUpstreamWantingIfaces . remove ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_UNREQUESTED , who ) ; break ; case IControlsTethering . STATE_TETHERED : mUpstreamWantingIfaces . add ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , who ) ; break ; case IControlsTethering . STATE_LOCAL_HOTSPOT : mUpstreamWantingIfaces . remove ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , who ) ; break ; } sendTetherStateChangedBroadcast ( ) ;
",,,"// by sending CMD_CLEAR_ERROR if ( error == ConnectivityManager . TETHER_ERROR_MASTER_ERROR ) { mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_CLEAR_ERROR , who ) ; } switch ( state ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : mUpstreamWantingIfaces . remove ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_UNREQUESTED , who ) ; break ; case IControlsTethering . STATE_TETHERED : < |startfocus| > mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , who ) ; break ; < |endfocus| > case IControlsTethering . STATE_LOCAL_HOTSPOT : mUpstreamWantingIfaces . remove ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , who ) ; break ; } sendTetherStateChangedBroadcast ( ) ;
",,
418,"case CMD_START_TETHERING_ERROR : case CMD_STOP_TETHERING_ERROR : case CMD_SET_DNS_FORWARDERS_ERROR : mLastError = ConnectivityManager . TETHER_ERROR_MASTER_ERROR ; transitionTo ( mInitialState ) ; break ; default : return false ; } return true ; } } class LocalHotspotState extends State { @Override public void enter ( ) { if ( DBG ) Log . d ( TAG , ""Local hotspot "" + mIfaceName ) ; setInterfaceState ( IControlsTethering . STATE_LOCAL_HOTSPOT ) ; } @Override public boolean processMessage ( Message message ) { maybeLogMessage ( this , message . what ) ; switch ( message . what ) { case CMD_TETHER_REQUESTED : Log . e ( TAG , ""CMD_TETHER_REQUESTED while in local hotspot mode . "" ) ; break ; case CMD_TETHER_CONNECTION_CHANGED : // Ignored in local hotspot state . break ; default : return false ; } return true ; } } class TetheredState extends State { @Override public void enter ( ) { if ( DBG ) Log . d ( TAG , ""Tethered "" + mIfaceName ) ;
","< |del| > public void exit ( ) { } @Override
","<|del|>
",,,"<|del|>
",,,"class TetherMasterSM extends StateMachine { private static final int CMD_START_TETHERING_ERROR = 1 ; private static final int CMD_STOP_TETHERING_ERROR = 2 ; private static final int CMD_SET_DNS_FORWARDERS_ERROR = 3 ; private static final int CMD_TETHER_REQUESTED = 4 ; private static final int CMD_TETHER_CONNECTION_CHANGED = 5 ; private static final String TAG = TetherMasterSM . class . getSimpleName ( ) ; private static final boolean DBG = false ; private final String mIfaceName ; private final TetherInterfaceStateMachine mTetherInterfaceStateMachine ; private int mLastError ; private final State mInitialState = new InitialState ( ) ; private final State mLocalHotspotState = new LocalHotspotState ( ) ; private final State mTetheredState = new TetheredState ( ) ; TetherMasterSM ( String ifaceName , Looper looper , TetherInterfaceStateMachine tetherInterfaceStateMachine ) { super ( TAG , looper ) ; mIfaceName = ifaceName ; mTetherInterfaceStateMachine = tetherInterfaceStateMachine ; addState ( mInitialState ) ; addState ( mLocalHotspotState ) ; addState ( mTetheredState ) ; setInitialState ( mInitialState ) ; } private void setInterfaceState ( int state ) { mTetherInterfaceStateMachine . sendMessage ( TetherInterfaceStateMachine . CMD_INTERFACE_DOWN ) ; mTetherInterfaceStateMachine . sendMessage ( TetherInterfaceStateMachine . CMD_INTERFACE_UP ) ; mTetherInterfaceStateMachine . sendMessage ( TetherInterfaceStateMachine . CMD_IPV6_TETHER_UPDATE , state ) ; } private void maybeLogMessage ( State state , int message ) { if ( DBG ) Log . d ( TAG , state . getName ( ) + "" what = "" + message ) ; } private class InitialState extends State { @Override public void enter ( ) { if ( DBG ) Log . d ( TAG , ""InitialState enter"" ) ; mLastError = ConnectivityManager . TETHER_ERROR_NO_ERROR ; } @Override public boolean processMessage ( Message message ) { maybeLogMessage ( this , message . what ) ; switch ( message . what ) { case CMD_START_TETHERING_ERROR : case CMD_STOP_TETHERING_ERROR : case CMD_SET_DNS_FORWARDERS_ERROR : mLastError = ConnectivityManager . TETHER_ERROR_MASTER_ERROR ; transitionTo ( mInitialState ) ; break ; default : return false ; } return true ; } }
",,,"case CMD_START_TETHERING_ERROR : case CMD_STOP_TETHERING_ERROR : case CMD_SET_DNS_FORWARDERS_ERROR : mLastError = ConnectivityManager . TETHER_ERROR_MASTER_ERROR ; transitionTo ( mInitialState ) ; break ; default : return false ; } return true ; } class LocalHotspotState extends State { @Override public void enter ( ) { if ( DBG ) Log . d ( TAG , ""Local hotspot "" + mIfaceName ) ; setInterfaceState ( IControlsTethering . STATE_LOCAL_HOTSPOT ) ; } @Override public void exit ( ) { } @Override public boolean processMessage ( Message message ) { maybeLogMessage ( this , message . what ) ; switch ( message . what ) { case CMD_TETHER_REQUESTED : Log . e ( TAG , ""CMD_TETHER_REQUESTED while in local hotspot mode . "" ) ; break ; case CMD_TETHER_CONNECTION_CHANGED : // Ignored in local hotspot state . break ; default : return false ; } return true ; } } class TetheredState extends State { @Override public void enter ( ) { if ( DBG ) Log . d ( TAG , ""Tethered "" + mIfaceName ) ; }
",,,"case CMD_START_TETHERING_ERROR : case CMD_STOP_TETHERING_ERROR : case CMD_SET_DNS_FORWARDERS_ERROR : mLastError = ConnectivityManager . TETHER_ERROR_MASTER_ERROR ; transitionTo ( mInitialState ) ; break ; default : return false ; } return true ; } } class LocalHotspotState extends State { @Override public void enter ( ) { if ( DBG ) Log . d ( TAG , ""Local hotspot "" + mIfaceName ) ; setInterfaceState ( IControlsTethering . STATE_LOCAL_HOTSPOT ) ; } @Override public void exit ( ) { } @Override public boolean processMessage ( Message message ) { maybeLogMessage ( this , message . what ) ; switch ( message . what ) { case CMD_TETHER_REQUESTED : Log . e ( TAG , ""CMD_TETHER_REQUESTED while in local hotspot mode . "" ) ; break ; case CMD_TETHER_CONNECTION_CHANGED : // Ignored in local hotspot state . break ; default : return false ; } return true ; } } class TetheredState extends State { @Override public void enter ( ) { if ( DBG ) Log . d ( TAG , ""Tethered "" + mIfaceName ) ;
",,
420,"if ( error == ConnectivityManager . TETHER_ERROR_MASTER_ERROR ) { mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_CLEAR_ERROR , who ) ; } int which ; switch ( state ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : which = TetherMasterSM . EVENT_IFACE_SERVING_STATE_INACTIVE ; break ; case IControlsTethering . STATE_TETHERED : case IControlsTethering . STATE_LOCAL_HOTSPOT : which = TetherMasterSM . EVENT_IFACE_SERVING_STATE_ACTIVE ; break ; default : Log . wtf ( TAG , ""Unknown interface state : "" + state ) ; return ; } mTetherMasterSM . sendMessage ( which , state , 0 , who ) ; sendTetherStateChangedBroadcast ( ) ;
","Log . wtf ( TAG , ""Unknown interface state : "" + state ) ;
","Log.wtf(TAG, ""Unknown interface state: "" + state);
",,,"Log.wtf(TAG, ""Unknown interface state: "" + state);
",,,"if ( error == ConnectivityManager . TETHER_ERROR_MASTER_ERROR ) { mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_CLEAR_ERROR , who ) ; } int which ; switch ( state ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : which = TetherMasterSM . EVENT_IFACE_SERVING_STATE_INACTIVE ; break ; case IControlsTethering . STATE_TETHERED : case IControlsTethering . STATE_LOCAL_HOTSPOT : which = TetherMasterSM . EVENT_IFACE_SERVING_STATE_ACTIVE ; break ; default : Log . wtf ( TAG , ""Unknown interface state : "" + state ) ; return ; } mTetherMasterSM . sendMessage ( which , state , 0 , who ) ; sendTetherStateChangedBroadcast ( ) ;
",,,"if ( error == ConnectivityManager . TETHER_ERROR_MASTER_ERROR ) { mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_CLEAR_ERROR , who ) ; } int which ; switch ( state ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : which = TetherMasterSM . EVENT_IFACE_SERVING_STATE_INACTIVE ; break ; case IControlsTethering . STATE_TETHERED : case IControlsTethering . STATE_LOCAL_HOTSPOT : which = TetherMasterSM . EVENT_IFACE_SERVING_STATE_ACTIVE ; break ; default : Log . wtf ( TAG , ""Unknown interface state : "" + state ) ; return ; } mTetherMasterSM . sendMessage ( which , state , 0 , who ) ; sendTetherStateChangedBroadcast ( ) ;
",,,"if ( error == ConnectivityManager . TETHER_ERROR_MASTER_ERROR ) { mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_CLEAR_ERROR , who ) ; } int which ; switch ( state ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : which = TetherMasterSM . EVENT_IFACE_SERVING_STATE_INACTIVE ; break ; case IControlsTethering . STATE_TETHERED : case IControlsTethering . STATE_LOCAL_HOTSPOT : which = TetherMasterSM . EVENT_IFACE_SERVING_STATE_ACTIVE ; break ; default : < |startfocus| > Log . wtf ( TAG , ""Unknown interface state : "" + state ) ; < |endfocus| > return ; } mTetherMasterSM . sendMessage ( which , state , 0 , who ) ; sendTetherStateChangedBroadcast ( ) ;
",,
427,"import android . util . Log ; import java . util . Arrays ; import java . util . Objects ; /* * * Network specifier object used to request a Wi - Fi Aware network . Apps do not create these objects * directly but obtain them using * { @link WifiAwareSession#createNetworkSpecifierOpen ( int , byte [ ] ) } or * { @link DiscoverySession#createNetworkSpecifierOpen ( PeerHandle ) } or their secure ( Passphrase ) * versions . * * @hide */ public final class WifiAwareNetworkSpecifier extends NetworkSpecifier implements Parcelable { /* * * TYPE : in band , specific peer : role , client_id , session_id , peer_id , pmk / passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB = 0 ; /* * * TYPE : in band , any peer : role , client_id , session_id , pmk / passphrase optional * [ only permitted for RESPONDER ] * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB_ANY_PEER = 1 ; /* * * TYPE : out - of - band : role , client_id , peer_mac , pmk / passphrase optional
","public final class WifiAwareNetworkSpecifier extends NetworkSpecifier implements Parcelable {
","public final class WifiAwareNetworkSpecifier extends NetworkSpecifier {
",,,"public final class WifiAwareNetworkSpecifier extends NetworkSpecifier {
",,,"import android . util . Log ; import java . util . Arrays ; import java . util . Objects ; /* * * Network specifier object used to request a Wi - Fi Aware network . Apps do not create these objects * directly but obtain them using * { @link WifiAwareSession#createNetworkSpecifierOpen ( int , byte [ ] ) } or * { @link DiscoverySession#createNetworkSpecifierOpen ( PeerHandle ) } or their secure ( Passphrase ) * versions . * * @hide */ public final class WifiAwareNetworkSpecifier extends NetworkSpecifier implements Parcelable { private int uid ; /* * * TYPE : in band , specific peer : role , client_id , session_id , peer_id , pmk / passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB = 0 ; /* * * TYPE : in band , any peer : role , client_id , session_id , pmk / passphrase optional * [ only permitted for RESPONDER ] * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB_ANY_PEER = 1 ; /* * * TYPE : out - of - band : role , client_id , peer_mac , pmk / passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_OOB = 2 ; /* * * Create a new WifiAwareNetworkSpecifier instance . * * @param type The type of the network specifier . * @param role The role of the device . * @param clientId The client ID . * @param sessionId The session ID . * @param peerId The peer ID . * @param peerMac The peer MAC address . * @param pmk The pre - shared master key . * @param passphrase The passphrase . * @param uid The UID of the app . */ private WifiAwareNetworkSpecifier ( int type , int role , int clientId , int sessionId , int peerId , byte [ ] peerMac , byte [ ] pmk , String passphrase , int uid ) { this . uid = uid ; } /* * * Get the UID of the app . * * @return The UID of the app . */ public int getUid ( ) { return uid ; } // Parcelable implementation public static final Creator < WifiAwareNetworkSpecifier > CREATOR = new Creator < WifiAwareNetworkSpecifier > ( ) { public WifiAwareNetworkSpecifier createFromParcel ( Parcel in ) {
",,,"import android . util . Log ; import java . util . Arrays ; import java . util . Objects ; /* * * Network specifier object used to request a Wi - Fi Aware network . Apps do not create these objects * directly but obtain them using * { @link WifiAwareSession#createNetworkSpecifierOpen ( int , byte [ ] ) } or * { @link DiscoverySession#createNetworkSpecifierOpen ( PeerHandle ) } or their secure ( Passphrase ) * versions . * * @hide */ public final class WifiAwareNetworkSpecifier extends NetworkSpecifier implements Parcelable , NetworkSpecifier . UidContainer { /* * * TYPE : in band , specific peer : role , client_id , session_id , peer_id , pmk / passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB = 0 ; /* * * TYPE : in band , any peer : role , client_id , session_id , pmk / passphrase optional * [ only permitted for RESPONDER ] * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB_ANY_PEER = 1 ; /* * * TYPE : out - of - band : role , client_id , peer_mac , pmk / passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_OOB = 2 ; /* * * TYPE : out - of - band : role , client_id , pmk / passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_OOB_ANY_PEER = 3 ; /* * * TYPE : out - of - band : role , client_id , pmk / passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_OOB_ANY_PEER_OOB = 4 ; private static final String TAG = ""WifiAwareNetworkSpecifier"" ; private final int mType ; private final int mRole ; private final int mClientId ; private final int mSessionId ; private final byte [ ] mPeerMac ; private final byte [ ] mPmk ; private final String mPassphrase ; private final int mUid ; private WifiAwareNetworkSpecifier ( int type , int role , int clientId , int sessionId , byte [ ] peerMac , byte [ ] pmk , String passphrase , int uid ) { mType = type ; mRole = role ; mClientId = clientId ; mSessionId = sessionId ; mPeerMac = peerMac ;
",,,"import android . util . Log ; import java . util . Arrays ; import java . util . Objects ; /* * * Network specifier object used to request a Wi - Fi Aware network . Apps do not create these objects * directly but obtain them using * { @link WifiAwareSession#createNetworkSpecifierOpen ( int , byte [ ] ) } or * { @link DiscoverySession#createNetworkSpecifierOpen ( PeerHandle ) } or their secure ( Passphrase ) * versions . * * @hide */ < |startfocus| > public final class WifiAwareNetworkSpecifier extends NetworkSpecifier implements Parcelable { < |endfocus| > /* * * TYPE : in band , specific peer : role , client_id , session_id , peer_id , pmk / passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB = 0 ; /* * * TYPE : in band , any peer : role , client_id , session_id , pmk / passphrase optional * [ only permitted for RESPONDER ] * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB_ANY_PEER = 1 ; /* * * TYPE : out - of - band : role , client_id , peer_mac , pmk / passphrase optional
",,
433,"* Inc . , 51 Franklin St , Fifth Floor , Boston , MA 02110 - 1301 USA . * * Please contact Oracle , 500 Oracle Parkway , Redwood Shores , CA 94065 USA * or visit www . oracle . com if you need additional information or have any * questions . */ package java . util ; import java . util . function . Consumer ; import java . util . function . Function ; import java . util . function . Predicate ; import java . util . function . Supplier ; // Android - changed : removed ValueBased paragraph . /* * * A container object which may or may not contain a non - null value . * If a value is present , { @code isPresent ( ) } will return { @code true } and * { @code get ( ) } will return the value . * * < p > Additional methods that depend on the presence or absence of a contained * value are provided , such as { @link #orElse ( java . lang . Object ) orElse ( ) } * ( return a default value if value not present ) and * { @link #ifPresent ( java . util . function . Consumer ) ifPresent ( ) } ( execute a block
","// Android - changed : removed ValueBased paragraph .
","// Android-changed: removed value-based paragraph.
",,,"// Android-changed: removed Value-based paragraph. // Note that the removed paragraph actually used the spellings ""ValueBased"" (in the link target) // and ""Value-based"" (in the link text).
",,,"package java . util ; import java . util . function . Consumer ; import java . util . function . Function ; import java . util . function . Predicate ; import java . util . function . Supplier ; /* * * A container object which may or may not contain a non - null value . * If a value is present , { @code isPresent ( ) } will return { @code true } and * { @code get ( ) } will return the value . * * < p > Additional methods that depend on the presence or absence of a contained * value are provided , such as { @link #orElse ( Object ) orElse ( ) } * ( return a default value if value not present ) and * { @link #ifPresent ( Consumer ) ifPresent ( ) } ( execute a block of code if the value is present ) . */ public final class Optional < T > { private static final Optional < ? > EMPTY = new Optional < > ( ) ; private final T value ; private Optional ( ) { this . value = null ; } private Optional ( T value ) { this . value = Objects . requireNonNull ( value ) ; } /* * * Returns an empty { @code Optional } instance . No value is present for this * Optional . * * @param < T > Type of the non - existent value * @return an empty { @code Optional } */ public static < T > Optional < T > empty ( ) { @SuppressWarnings ( ""unchecked"" ) Optional < T > t = ( Optional < T > ) EMPTY ; return t ; } /* * * Returns an { @code Optional } with the specified present non - null value . * * @param < T > the class of the value * @param value the value to be present , which must be non - null * @return an { @code Optional } with the value present * @throws NullPointerException if value is null */ public static < T > Optional < T > of ( T value ) { return new Optional < > ( value ) ; } /* * * Returns an { @code Optional } describing the specified value , if non - null , * otherwise returns an empty { @code Optional } . * * @param < T > the class of the value * @param value the possibly - null value to describe * @return an { @code Optional } with a present value if the specified value * is non - null , otherwise an empty { @code Optional } */ public static < T > Optional < T > ofNullable ( T value ) {
",,,"import com . google . gerrit . reviewdb . client . Change ; import com . google . gerrit . reviewdb . client . CommentRange ; import com . google . gerrit . reviewdb . client . Patch ; import com . google . gerrit . reviewdb . client . PatchLineComment ; import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . gerrit . reviewdb . client . RevId ; import com . google . gwtorm . client . Column ; import java . sql . Timestamp ; import java . util . ArrayList ; import java . util . List ; import javax . annotation . concurrent . Immutable ; /* * * Holds the raw data of a RevisionNote . * It is intended for ( de ) serialization to JSON only . */ class RevisionNoteData { static class Identity { int id ; Identity ( Account . Id id ) { this . id = id . get ( ) ; } Account . Id export ( ) { return new Account . Id ( id ) ; } } static class CommentKey { String uuid ; PatchKey patchKey ; CommentKey ( PatchLineComment . Key k ) { uuid = k . get ( ) ; patchKey = new PatchKey ( k . getParentKey ( ) ) ; } PatchLineComment . Key export ( ) { return new PatchLineComment . Key ( patchKey . export ( ) , uuid ) ; } } } // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . extensions . api ; import com . google . gerrit . extensions . api . changes . Changes ; import com . google . gerrit . extensions . api . projects . Projects ; import com . google . gerrit . extensions . restapi . NotImplementedException ; public interface GerritApi { public Changes changes ( ) ; public Projects projects ( ) ; /* * * A default implementation which allows source compatibility when adding new methods to the interface . */ public class NotImplementedGerritApi implements GerritApi { @Override public Changes changes ( ) { throw new NotImplementedException ( ) ; } @Override public Projects projects ( ) { throw new NotImplementedException ( ) ; } } } // Android - changed : removed Value - Based paragraph . import java . util . function . Consumer ; import java . util . function . Function ; import java . util . function . Predicate ; import java . util . function . Supplier ; /* * * A container object which may or may not contain a non - null value . * If a value is present , { @code isPresent ( ) } will return { @code true } and * { @code get ( ) } will return the value . * * < p >
",,,"* Inc . , 51 Franklin St , Fifth Floor , Boston , MA 02110 - 1301 USA . * * Please contact Oracle , 500 Oracle Parkway , Redwood Shores , CA 94065 USA * or visit www . oracle . com if you need additional information or have any * questions . */ package java . util ; import java . util . function . Consumer ; import java . util . function . Function ; import java . util . function . Predicate ; import java . util . function . Supplier ; < |startfocus| > // Android - changed : removed paragraph about value - based class semantics . < |endfocus| > /* * * A container object which may or may not contain a non - null value . * If a value is present , { @code isPresent ( ) } will return { @code true } and * { @code get ( ) } will return the value . * * < p > Additional methods that depend on the presence or absence of a contained * value are provided , such as { @link #orElse ( java . lang . Object ) orElse ( ) } * ( return a default value if value not present ) and * { @link #ifPresent ( java . util . function . Consumer ) ifPresent ( ) } ( execute a block
",,
438,"Log . addEvent ( foregroundCall , LogUtils . Events . START_RINGER ) ; // Because we wait until a contact info query to complete before processing a // call ( for the purposes of direct - to - voicemail ) , the information about custom // ringtones should be available by the time this code executes . We can safely // request the custom ringtone from the call and expect it to be current . mRingtonePlayer . play ( mRingtoneFactory , foregroundCall ) ; } else { Log . i ( this , ""startRinging : skipping because ringer would not be audible . "" + ""isVolumeOverZero = % s , shouldRingForContact = % s , isRingtonePresent = % s"" , isVolumeOverZero , shouldRingForContact , isRingtonePresent ) ; } if ( shouldVibrate ( mContext , foregroundCall ) && ! mIsVibrating && shouldRingForContact ) { mVibratingCall = foregroundCall ; mVibrator . vibrate ( VIBRATION_PATTERN , VIBRATION_PATTERN_REPEAT , VIBRATION_ATTRIBUTES ) ; mIsVibrating = true ; } else if ( mIsVibrating ) { Log . addEvent ( foregroundCall , LogUtils . Events . SKIP_VIBRATION , ""already vibrating"" ) ; } return shouldAcquireAudioFocus ;
","Log . i ( this , ""startRinging : skipping because ringer would not be audible . "" + ""isVolumeOverZero = % s , shouldRingForContact = % s , isRingtonePresent = % s"" , isVolumeOverZero , shouldRingForContact , isRingtonePresent ) ;
","Log.i(this, ""startRinging: skipping because ringer would not beAudible."");
",,,"Log.i(this, ""startRinging: skipping because ringer would not be audible."");
",,,"if ( isVolumeOverZero && shouldRingForContact && isRingtonePresent ) { Log . addEvent ( foregroundCall , LogUtils . Events . START_RINGER ) ; mRingtonePlayer . play ( mRingtoneFactory , foregroundCall ) ; } else { Log . i ( this , ""startRinging : skipping because ringer would not be audible . "" ) ; } if ( shouldVibrate ( mContext , foregroundCall ) && ! mIsVibrating && shouldRingForContact ) { mVibratingCall = foregroundCall ; mVibrator . vibrate ( VIBRATION_PATTERN , VIBRATION_PATTERN_REPEAT , VIBRATION_ATTRIBUTES ) ; mIsVibrating = true ; } else if ( mIsVibrating ) { Log . addEvent ( foregroundCall , LogUtils . Events . SKIP_VIBRATION , ""already vibrating"" ) ; } return shouldAcquireAudioFocus ;
",,,"Log . addEvent ( foregroundCall , LogUtils . Events . START_RINGER ) ; if ( isVolumeOverZero && shouldRingForContact && isRingtonePresent ) { mRingtonePlayer . play ( mRingtoneFactory , foregroundCall ) ; } else { Log . i ( this , ""startRinging : skipping because ringer would not be audible . "" ) ; } if ( shouldVibrate ( mContext , foregroundCall ) && ! mIsVibrating && shouldRingForContact ) { mVibratingCall = foregroundCall ; mVibrator . vibrate ( VIBRATION_PATTERN , VIBRATION_PATTERN_REPEAT , VIBRATION_ATTRIBUTES ) ; mIsVibrating = true ; } else if ( mIsVibrating ) { Log . addEvent ( foregroundCall , LogUtils . Events . SKIP_VIBRATION , ""already vibrating"" ) ; } return shouldAcquireAudioFocus ;
",,,"Log . addEvent ( foregroundCall , LogUtils . Events . START_RINGER ) ; // Because we wait until a contact info query to complete before processing a // call ( for the purposes of direct - to - voicemail ) , the information about custom // ringtones should be available by the time this code executes . We can safely // request the custom ringtone from the call and expect it to be current . mRingtonePlayer . play ( mRingtoneFactory , foregroundCall ) ; } else { < |startfocus| > Log . i ( this , ""startRinging : skipping because ringer would not be audible . isVolumeOverZero : "" + isVolumeOverZero + "" shouldRingForContact : "" + shouldRingForContact + "" isRingtonePresent : "" + isRingtonePresent ) ; < |endfocus| > } if ( shouldVibrate ( mContext , foregroundCall ) && ! mIsVibrating && shouldRingForContact ) { mVibratingCall = foregroundCall ; mVibrator . vibrate ( VIBRATION_PATTERN , VIBRATION_PATTERN_REPEAT , VIBRATION_ATTRIBUTES ) ; mIsVibrating = true ; } else if ( mIsVibrating ) { Log . addEvent ( foregroundCall , LogUtils . Events . SKIP_VIBRATION , ""already vibrating"" ) ; } return shouldAcquireAudioFocus ;
",,
442,"for ( int i = 0 ; i <= 255 ; ++ i ) { s . setTrafficClass ( i ) ; // b / 30909505 // Linux does not set ECN bits for IP_TOS , but sets for IPV6_TCLASS . We should // accept either output . int actual = s . getTrafficClass ( ) ; assertTrue ( i == actual || // IPV6_TCLASS ( actual == ( i & ~INET_ECN_MASK ) ) ; // IP_TOS : ECN bits should be 0 } } } public void testReadAfterClose ( ) throws Exception { MockServer server = new MockServer ( ) ; server . enqueue ( new byte [ ] { 5 , 3 } , 0 ) ; Socket socket = new Socket ( ""localhost"" , server . port ) ; InputStream in = socket . getInputStream ( ) ; assertEquals ( 5 , in . read ( ) ) ; assertEquals ( 3 , in . read ( ) ) ; assertEquals ( - 1 , in . read ( ) ) ; assertEquals ( - 1 , in . read ( ) ) ; socket . close ( ) ; in . close ( ) ; /* * Rather astonishingly , read ( ) doesn't throw even though the stream is
","( actual == ( i & ~INET_ECN_MASK ) ) ; // IP_TOS : ECN bits should be 0
","(((i & ~INET_ECN_MASK) == (actual & ~INET_ECN_MASK)) && ((actual & INET_ECN_MASK) == 0))); // IP_TOS
",,,"(((i & ~INET_ECN_MASK) == (actual & ~INET_ECN_MASK)) || // IP_TOS
",,,"for ( int i = 0 ; i <= 255 ; ++ i ) { s . setTrafficClass ( i ) ; int actual = s . getTrafficClass ( ) ; assertTrue ( actual == i || ( actual == ( i & ~INET_ECN_MASK ) ) ) ; } public void testReadAfterClose ( ) throws Exception { MockServer server = new MockServer ( ) ; server . enqueue ( new byte [ ] { 5 , 3 } , 0 ) ; Socket socket = new Socket ( ""localhost"" , server . port ) ; InputStream in = socket . getInputStream ( ) ; assertEquals ( 5 , in . read ( ) ) ; assertEquals ( 3 , in . read ( ) ) ; assertEquals ( - 1 , in . read ( ) ) ; assertEquals ( - 1 , in . read ( ) ) ; socket . close ( ) ; in . close ( ) ; }
",,,"public void test_SystemProperties ( ) { Properties originalProperties = System . getProperties ( ) ; try { Properties testProperties = new Properties ( ) ; testProperties . put ( ""testIncInt"" , ""notInt"" ) ; System . setProperties ( testProperties ) ; assertNull ( ""returned incorrect default Integer"" , Integer . getInteger ( ""testIncInt"" ) ) ; assertEquals ( new Integer ( 4 ) , Integer . getInteger ( ""testIncInt"" , 4 ) ) ; assertEquals ( new Integer ( 4 ) , Integer . getInteger ( ""testIncInt"" , new Integer ( 4 ) ) ) ; } finally { System . setProperties ( originalProperties ) ; } } for ( int i = 0 ; i <= 255 ; ++ i ) { s . setTrafficClass ( i ) ; int actual = s . getTrafficClass ( ) ; assertTrue ( actual == i || ( ( ( i & ~INET_ECN_MASK ) == ( actual & ~INET_ECN_MASK ) ) && ( ( actual & INET_ECN_MASK ) == 0 ) ) ) ; } public void testReadAfterClose ( ) throws Exception { MockServer server = new MockServer ( ) ; server . enqueue ( new byte [ ] { 5 , 3 } , 0 ) ; Socket socket = new Socket ( ""localhost"" , server . port ) ; InputStream in = socket . getInputStream ( ) ; assertEquals ( 5 , in . read ( ) ) ; assertEquals ( 3 , in . read ( ) ) ; assertEquals ( - 1 , in . read ( ) ) ; assertEquals ( - 1 , in . read ( ) ) ; socket . close ( ) ; in . close ( ) ; }
",,,"for ( int i = 0 ; i <= 255 ; ++ i ) { s . setTrafficClass ( i ) ; // b / 30909505 // Linux does not set ECN bits for IP_TOS , but sets for IPV6_TCLASS . We should // accept either output . int actual = s . getTrafficClass ( ) ; assertTrue ( i == actual || // IPV6_TCLASS < |startfocus| > ( ( ( i & ~INET_ECN_MASK ) == ( actual & ~INET_ECN_MASK ) ) && ( ( actual & INET_ECN_MASK ) == 0 ) ) ) ; // IP_TOS < |endfocus| > } } } public void testReadAfterClose ( ) throws Exception { MockServer server = new MockServer ( ) ; server . enqueue ( new byte [ ] { 5 , 3 } , 0 ) ; Socket socket = new Socket ( ""localhost"" , server . port ) ; InputStream in = socket . getInputStream ( ) ; assertEquals ( 5 , in . read ( ) ) ; assertEquals ( 3 , in . read ( ) ) ; assertEquals ( - 1 , in . read ( ) ) ; assertEquals ( - 1 , in . read ( ) ) ; socket . close ( ) ; in . close ( ) ; /* * Rather astonishingly , read ( ) doesn't throw even though the stream is
",,
445,"} else { doConnect ( address , port , timeout ) ; } } public void setOption ( int opt , Object val ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( ""Socket Closed"" ) ; } // Android - removed : alternative implementation /* boolean on = true ; switch ( opt ) { // check type safety b4 going native . These should never * fail , since only java . Socket * has access to * PlainSocketImpl . setOption ( ) . * case SO_LINGER : if ( val == null || ( ! ( val instanceof Integer ) && ! ( val instanceof Boolean ) ) ) throw new SocketException ( ""Bad parameter for option"" ) ; if ( val instanceof Boolean ) { // true only if disabling - enabling should be Integer on = false ; } break ; case SO_TIMEOUT : if ( val == null || ( ! ( val instanceof Integer ) ) ) throw new SocketException ( ""Bad parameter for SO_TIMEOUT"" ) ; int tmp = ( ( Integer ) val ) . intValue ( ) ; if ( tmp < 0 ) throw new IllegalArgumentException ( ""timeout < 0"" ) ;
","*
","/** * check type safety b4 going native. These should never * fail, since only java.Socket has access to PlainSocketImpl.setOption(). */
",,,"//
",,,"} else { doConnect ( address , port , timeout ) ; } public void setOption ( int opt , Object val ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( ""Socket Closed"" ) ; } boolean on = true ; switch ( opt ) { case SO_LINGER : if ( val == null || ( ! ( val instanceof Integer ) && ! ( val instanceof Boolean ) ) ) { throw new SocketException ( ""Bad parameter for option"" ) ; } if ( val instanceof Boolean ) { on = false ; } break ; case SO_TIMEOUT : if ( val == null || ( ! ( val instanceof Integer ) ) ) { throw new SocketException ( ""Bad parameter for SO_TIMEOUT"" ) ; } int tmp = ( ( Integer ) val ) . intValue ( ) ; if ( tmp < 0 ) { throw new IllegalArgumentException ( ""timeout < 0"" ) ; } break ; default : throw new SocketException ( ""Invalid option"" ) ; } }
",,,"} else { doConnect ( address , port , timeout ) ; } public void setOption ( int opt , Object val ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( ""Socket Closed"" ) ; } // Android - removed : alternative implementation /* boolean on = true ; switch ( opt ) { // check type safety b4 going native . These should never * fail , since only java . Socket * has access to * PlainSocketImpl . setOption ( ) . // < |startfocus| > // < |endfocus| > case SO_LINGER : if ( val == null || ( ! ( val instanceof Integer ) && ! ( val instanceof Boolean ) ) ) { throw new SocketException ( ""Bad parameter for option"" ) ; } if ( val instanceof Boolean ) { // true only if disabling - enabling should be Integer on = false ; } break ; case SO_TIMEOUT : if ( val == null || ( ! ( val instanceof Integer ) ) ) { throw new SocketException ( ""Bad parameter for SO_TIMEOUT"" ) ; } int tmp = ( ( Integer ) val ) . intValue ( ) ; if ( tmp < 0 ) { throw new IllegalArgumentException ( ""timeout < 0"" ) ; } // < |startfocus| > // < |endfocus| > break ; default : throw new SocketException ( ""Option not supported"" ) ; } // < |startfocus| > // < |endfocus| > }
",,,"} else { doConnect ( address , port , timeout ) ; } } public void setOption ( int opt , Object val ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( ""Socket Closed"" ) ; } // Android - removed : alternative implementation /* boolean on = true ; switch ( opt ) { // check type safety b4 going native . These should never * fail , since only java . Socket * has access to * PlainSocketImpl . setOption ( ) . < |startfocus| > // < |endfocus| > case SO_LINGER : if ( val == null || ( ! ( val instanceof Integer ) && ! ( val instanceof Boolean ) ) ) throw new SocketException ( ""Bad parameter for option"" ) ; if ( val instanceof Boolean ) { // true only if disabling - enabling should be * Integer on = false ; } break ; case SO_TIMEOUT : if ( val == null || ( ! ( val instanceof Integer ) ) ) throw new SocketException ( ""Bad parameter for SO_TIMEOUT"" ) ; int tmp = ( ( Integer ) val ) . intValue ( ) ; if ( tmp < 0 ) throw new IllegalArgumentException ( ""timeout < 0"" ) ;
",,
456,"// / CHECK - DAG : VecAdd loop : < < Loop > > outer_loop : none // // / CHECK - START - ARM64 : void Main . SimdMulAdd ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMultiplyAccumulate kind : Add loop : < < Loop > > outer_loop : none public static void SimdMulAdd ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { array2 [ j ] += 12345 * array1 [ j ] ; } } // / CHECK - START - ARM64 : void Main . SimdMulSub ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( before ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMul loop : < < Loop > > outer_loop : none // / CHECK - DAG : VecSub loop : < < Loop > > outer_loop : none // // / CHECK - START - ARM64 : void Main . SimdMulSub ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after )
","array2 [ j ] += 12345 * array1 [ j ] ;
","array2[j] += 12345 * array1[j];
",,,"array2[j] += 12345 * array1[j];
",,,"public static void SimdMulAdd ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { array2 [ j ] += 12345 * array1 [ j ] ; } } public static void SimdMulSub ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { array2 [ j ] -= 12345 * array1 [ j ] ; } }
",,,"public static void SimdMulAdd ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { array2 [ j ] += 12345 * array1 [ j ] ; } } public static void SimdMulSub ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { array2 [ j ] -= 12345 * array1 [ j ] ; } }
",,,"// / CHECK - DAG : VecAdd loop : < < Loop > > outer_loop : none // // / CHECK - START - ARM64 : void Main . SimdMulAdd ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMultiplyAccumulate kind : Add loop : < < Loop > > outer_loop : none public static void SimdMulAdd ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { < |startfocus| > array2 [ j ] += 12345 * array1 [ j ] ; < |endfocus| > } } // / CHECK - START - ARM64 : void Main . SimdMulSub ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( before ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMul loop : < < Loop > > outer_loop : none // / CHECK - DAG : VecSub loop : < < Loop > > outer_loop : none // // / CHECK - START - ARM64 : void Main . SimdMulSub ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMultiplyAccumulate kind : Sub loop : < < Loop > > outer_loop : none public static void SimdMulSub ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { < |startfocus| > array2 [ j ] -= 12345 * array1 [ j ] ; < |endfocus| > } }
",,
459,"if ( DBG ) { log ( ""reportNetworkConnectivity ( "" + nai . network . netId + "" , "" + hasConnectivity + "" ) by "" + uid ) ; } synchronized ( nai ) { // Validating a network that has not yet connected could result in a call to // rematchNetworkAndRequests ( ) which is not meant to work on such networks . if ( ! nai . everConnected ) return ; if ( isNetworkWithLinkPropertiesBlocked ( nai . linkProperties , uid , false ) ) return ; nai . networkMonitor . sendMessage ( NetworkMonitor . CMD_FORCE_REEVALUATION , uid ) ; } LinkProperties lp = getLinkProperties ( nai ) ; if ( isNetworkWithLinkPropertiesBlocked ( lp , uid , false ) ) { return ; } nai . networkMonitor . sendMessage ( NetworkMonitor . CMD_FORCE_REEVALUATION , uid ) ;
","} LinkProperties lp = getLinkProperties ( nai ) ; if ( isNetworkWithLinkPropertiesBlocked ( lp , uid , false ) ) { return ; } nai . networkMonitor . sendMessage ( NetworkMonitor . CMD_FORCE_REEVALUATION , uid ) ;
","} nai.networkMonitor.sendMessage(NetworkMonitor.CMD_FORCE_REEVALUATION, uid);
",,,"} if (!isNetworkWithLinkPropertiesBlocked(nai.linkProperties, uid, false)) return; nai.networkMonitor.sendMessage(NetworkMonitor.CMD_FORCE_REEVALUATION, uid);
",,,"if ( DBG ) { log ( ""reportNetworkConnectivity ( networkId = "" + nai . network . netId + "" , hasConnectivity = "" + hasConnectivity + "" ) by "" + uid ) ; } synchronized ( nai ) { if ( ! nai . everConnected ) { return ; } if ( isNetworkWithLinkPropertiesBlocked ( nai . linkProperties , uid , false ) ) { return ; } nai . networkMonitor . sendMessage ( NetworkMonitor . CMD_FORCE_REEVALUATION , uid ) ; }
",,,"if ( DBG ) { log ( ""reportNetworkConnectivity ( "" + nai . network . netId + "" , "" + hasConnectivity + "" ) by "" + uid ) ; } synchronized ( nai ) { // Validating a network that has not yet connected could result in a call to // rematchNetworkAndRequests ( ) which is not meant to work on such networks . if ( ! nai . everConnected ) { return ; } if ( isNetworkWithLinkPropertiesBlocked ( nai . linkProperties , uid , false ) ) { return ; } nai . networkMonitor . sendMessage ( NetworkMonitor . CMD_FORCE_REEVALUATION , uid ) ; }
",,,"if ( DBG ) { log ( ""reportNetworkConnectivity ( "" + nai . network . netId + "" , "" + hasConnectivity + "" ) by "" + uid ) ; } synchronized ( nai ) { // Validating a network that has not yet connected could result in a call to // rematchNetworkAndRequests ( ) which is not meant to work on such networks . if ( ! nai . everConnected ) return ; if ( isNetworkWithLinkPropertiesBlocked ( nai . linkProperties , uid , false ) ) return ; nai . networkMonitor . sendMessage ( NetworkMonitor . CMD_FORCE_REEVALUATION , uid ) ; < |startfocus| > } < |endfocus| >
",,
466,"import com . android . dx . rop . cst . CstMethodRef ; import com . android . dx . rop . cst . CstNat ; import com . android . dx . rop . cst . CstType ; import com . android . dx . rop . type . StdTypeList ; import com . android . dx . rop . type . Type ; import com . android . dx . rop . type . TypeList ; import com . android . dx . util . Warning ; import java . util . ArrayList ; /* * * Utility methods that translate various classfile attributes * into forms suitable for use in creating { @code dex } files . */ /* package */ class AttributeTranslator { /* * * This class is uninstantiable . */ private AttributeTranslator ( ) { // This space intentionally left blank . } /* * * Gets the list of thrown exceptions for a given method . * * @param method { @code non - null ; } the method in question * @return { @code non - null ; } the list of thrown exceptions */ public static TypeList getExceptions ( Method method ) { AttributeList attribs = method . getAttributes ( ) ; AttExceptions exceptions = ( AttExceptions ) attribs . findFirst ( AttExceptions . ATTRIBUTE_NAME ) ; if ( exceptions == null ) {
","< |del| >
","<|del|>
",,,"<|del|>
",,,"import com . android . dx . rop . cst . CstMethodRef ; import com . android . dx . rop . cst . CstNat ; import com . android . dx . rop . cst . CstType ; import com . android . dx . rop . type . StdTypeList ; import com . android . dx . rop . type . Type ; import com . android . dx . rop . type . TypeList ; import com . android . dx . util . Warning ; import java . util . ArrayList ; /* package */ class AttributeTranslator { /* * * This class is uninstantiable . */ private AttributeTranslator ( ) { // This space intentionally left blank . } /* * * Gets the list of thrown exceptions for a given method . * * @param method { @code non - null ; } the method in question * @return { @code non - null ; } the list of thrown exceptions */ public static TypeList getExceptions ( Method method ) { AttributeList attribs = method . getAttributes ( ) ; AttExceptions exceptions = ( AttExceptions ) attribs . findFirst ( AttExceptions . ATTRIBUTE_NAME ) ; if ( exceptions == null ) { return StdTypeList . EMPTY ; } return exceptions . getExceptions ( ) ; } }
",,,"import com . android . dx . rop . cst . CstMethodRef ; import com . android . dx . rop . cst . CstNat ; import com . android . dx . rop . cst . CstType ; import com . android . dx . rop . type . StdTypeList ; import com . android . dx . rop . type . Type ; import com . android . dx . rop . type . TypeList ; import com . android . dx . util . Warning ; import java . util . ArrayList ; /* package */ class AttributeTranslator { private AttributeTranslator ( ) { // This space intentionally left blank . } public static TypeList getExceptions ( Method method ) { AttributeList attribs = method . getAttributes ( ) ; AttExceptions exceptions = ( AttExceptions ) attribs . findFirst ( AttExceptions . ATTRIBUTE_NAME ) ; if ( exceptions == null ) { return StdTypeList . EMPTY ; } else { return exceptions . getExceptions ( ) ; } } }
",,,"import com . android . dx . rop . cst . CstMethodRef ; import com . android . dx . rop . cst . CstNat ; import com . android . dx . rop . cst . CstType ; import com . android . dx . rop . type . StdTypeList ; import com . android . dx . rop . type . Type ; import com . android . dx . rop . type . TypeList ; import com . android . dx . util . Warning ; import java . util . ArrayList ; /* * * Utility methods that translate various classfile attributes * into forms suitable for use in creating { @code dex } files . */ /* package */ class AttributeTranslator { < |startfocus| > < |endfocus| > /* * * This class is uninstantiable . */ private AttributeTranslator ( ) { // This space intentionally left blank . } /* * * Gets the list of thrown exceptions for a given method . * * @param method { @code non - null ; } the method in question * @return { @code non - null ; } the list of thrown exceptions */ public static TypeList getExceptions ( Method method ) { AttributeList attribs = method . getAttributes ( ) ; AttExceptions exceptions = ( AttExceptions ) attribs . findFirst ( AttExceptions . ATTRIBUTE_NAME ) ; if ( exceptions == null ) {
",,
468,"private static void throttle ( byte [ ] bArray , short bOff , short failureCount ) { short highWord = 0 ; short lowWord = 0 ; final short thirtySecondsInMilliseconds = 0x7530 ; // = 1000 * 30 if ( failureCount == 0 ) { // 0s } else if ( failureCount > 0 && failureCount <= 10 ) { if ( failureCount % 5 == 0 ) { // 30s lowWord = thritySecondsInMilliseconds ; } else { // 0s } } else if ( failureCount < 30 ) { // 30s lowWord = thritySecondsInMilliseconds ; } else if ( failureCount < 140 ) { // 30 * ( 2 ^ ( ( x - 30 ) / 10 ) ) final short shift = ( short ) ( ( short ) ( failureCount - 30 ) / 10 ) ; highWord = ( short ) ( thritySecondsInMilliseconds > > ( 16 - shift ) ) ; lowWord = ( short ) ( thritySecondsInMilliseconds < < shift ) ; } else { // 1 day in ms = 1000 * 60 * 60 * 24 = 0x526 5C00 highWord = 0x0526 ;
","final short thirtySecondsInMilliseconds = 0x7530 ; // = 1000 * 30
","final short thritySecondsInMilliseconds = 0x7530; // = 1000 * 30
",,,"final short dirtySecondsInMilliseconds = 0x7530; // = 1000 * 30
",,,"private static void throttle ( byte [ ] bArray , short bOff , short failureCount ) { short highWord = 0 ; short lowWord = 0 ; final short thirtySecondsInMilliseconds = 0x7530 ; // = 1000 * 30 if ( failureCount == 0 ) { // 0s } else if ( failureCount > 0 && failureCount <= 10 ) { if ( failureCount % 5 == 0 ) { // 30s lowWord = thirtySecondsInMilliseconds ; } else { // 0s } } else if ( failureCount < 30 ) { // 30s lowWord = thirtySecondsInMilliseconds ; } else if ( failureCount < 140 ) { // 30 * ( 2 ^ ( ( x - 30 ) / 10 ) ) final short shift = ( short ) ( ( short ) ( failureCount - 30 ) / 10 ) ; highWord = ( short ) ( thirtySecondsInMilliseconds > > ( 16 - shift ) ) ; lowWord = ( short ) ( thirtySecondsInMilliseconds < < shift ) ; } else { // 1 day in ms = 1000 * 60 * 60 * 24 = 0x5265C00 highWord = 0x0526 ; } }
",,,"private static void throttle ( byte [ ] bArray , short bOff , short failureCount ) { short highWord = 0 ; short lowWord = 0 ; final short thirtySecondsInMilliseconds = 0x7530 ; // = 1000 * 30 if ( failureCount == 0 ) { // 0s } else if ( failureCount > 0 && failureCount <= 10 ) { if ( failureCount % 5 == 0 ) { // 30s lowWord = thirtySecondsInMilliseconds ; } else { // 0s } } else if ( failureCount < 30 ) { // 30s lowWord = thirtySecondsInMilliseconds ; } else if ( failureCount < 140 ) { // 30 * ( 2 ^ ( ( x - 30 ) / 10 ) ) final short shift = ( short ) ( ( short ) ( failureCount - 30 ) / 10 ) ; highWord = ( short ) ( thirtySecondsInMilliseconds > > ( 16 - shift ) ) ; lowWord = ( short ) ( thirtySecondsInMilliseconds < < shift ) ; } else { // 1 day in ms = 1000 * 60 * 60 * 24 = 0x5265C00 highWord = 0x0526 ; } }
",,,"private static void throttle ( byte [ ] bArray , short bOff , short failureCount ) { short highWord = 0 ; short lowWord = 0 ; < |startfocus| > final short thirtySecondsInMilliseconds = 0x7530 ; // = 1000 * 30 < |endfocus| > if ( failureCount == 0 ) { // 0s } else if ( failureCount > 0 && failureCount <= 10 ) { if ( failureCount % 5 == 0 ) { // 30s lowWord = thirtySecondsInMilliseconds ; } else { // 0s } } else if ( failureCount < 30 ) { // 30s lowWord = thirtySecondsInMilliseconds ; } else if ( failureCount < 140 ) { // 30 * ( 2 ^ ( ( x - 30 ) / 10 ) ) final short shift = ( short ) ( ( short ) ( failureCount - 30 ) / 10 ) ; highWord = ( short ) ( thirtySecondsInMilliseconds > > ( 16 - shift ) ) ; lowWord = ( short ) ( thirtySecondsInMilliseconds < < shift ) ; } else { // 1 day in ms = 1000 * 60 * 60 * 24 = 0x526 5C00 highWord = 0x0526 ;
",,
473,"/* * * Broadcast Action : The Bluetooth adapter state has changed in LE only mode . * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = ""android . bluetooth . adapter . action . BLE_STATE_CHANGED"" ; /* * * Broadcast Action : The notifys Bluetooth BD ( mac ) address * updated event . * * @hide */ public static final String ACTION_BD_ADDR_CHANGED = ""android . bluetooth . adapter . action . BD_ADDR_CHANGED"" ; /* * * Extra used by { @link #ACTION_BT_BD_ADDR_CHANGED } * * This extra represents the BD Address . * * @hide */ public static final String EXTRA_BT_BD_ADDR = ""android . bluetooth . adapter . extra . BT_BD_ADDR"" ; /* * * Broadcast Action : The notifys Bluetooth ACL connected event . This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT connection
","public static final String ACTION_BD_ADDR_CHANGED = ""android . bluetooth . adapter . action . BD_ADDR_CHANGED"" ;
","<|del|>
",,,"public static final String ACTION_BT_BD_ADDR_CHANGED = ""android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"";
",,,"public static final String ACTION_BLE_STATE_CHANGED = ""android . bluetooth . adapter . action . BLE_STATE_CHANGED"" ; public static final String ACTION_BT_BD_ADDR_CHANGED_INTERNAL = ""android . bluetooth . adapter . action . BT_BD_ADDR_CHANGED_INTERNAL"" ; public static final String EXTRA_BT_BD_ADDR = ""android . bluetooth . adapter . extra . BT_BD_ADDR"" ; public static final String ACTION_BT_ACL_CONNECTED = ""android . bluetooth . adapter . action . BT_ACL_CONNECTED"" ;
",,,"/* * * Broadcast Action : The Bluetooth adapter state has changed in LE only mode . * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = ""android . bluetooth . adapter . action . BLE_STATE_CHANGED"" ; /* * * Broadcast Action : The notifies Bluetooth BD ( mac ) address updated event . * @hide */ public static final String ACTION_BT_BD_ADDR_CHANGED = ""android . bluetooth . adapter . action . BT_BD_ADDR_CHANGED"" ; /* * * Extra used by { @link #ACTION_BT_BD_ADDR_CHANGED } * This extra represents the BD Address . * @hide */ public static final String EXTRA_BT_BD_ADDR = ""android . bluetooth . adapter . extra . BT_BD_ADDR"" ; /* * * Broadcast Action : The notifies Bluetooth ACL connected event . * This will be used by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state is in STATE_BLE_ON . * This denotes GATT connection . * @hide */ public static final String ACTION_BT_ACL_CONNECTED = ""android . bluetooth . adapter . action . BT_ACL_CONNECTED"" ;
",,,"/* * * Broadcast Action : The Bluetooth adapter state has changed in LE only mode . * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = ""android . bluetooth . adapter . action . BLE_STATE_CHANGED"" ; /* * * Broadcast Action : The notifys Bluetooth BD ( mac ) address * updated event . * * @hide */ < |startfocus| > public static final String ACTION_BT_BD_ADDR_CHANGED = ""android . bluetooth . adapter . action . BT_BD_ADDR_CHANGED"" ; < |endfocus| > /* * * Extra used by { @link #ACTION_BT_BD_ADDR_CHANGED } * * This extra represents the BD Address . * * @hide */ public static final String EXTRA_BT_BD_ADDR = ""android . bluetooth . adapter . extra . BT_BD_ADDR"" ; /* * * Broadcast Action : The notifys Bluetooth ACL connected event . This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT connection
",,
493,"public static List < String > getTimeZoneIdsWithUniqueOffsets ( String country ) { synchronized ( sLastUniqueLockObj ) { if ( ( country != null ) && country . equals ( sLastUniqueCountry ) ) { if ( DBG ) { Log . d ( TAG , ""getTimeZonesWithUniqueOffsets ( "" + country + "" ) : return cached version"" ) ; } return sLastUniqueZoneOffsets ; } } Collection < TimeZone > zones = getTimeZones ( country ) ; ArrayList < TimeZone > uniqueTimeZones = new ArrayList < > ( ) ; for ( TimeZone zone : zones ) { // See if we already have this offset , // Using slow but space efficient and these are small . boolean found = false ; for ( int i = 0 ; i < uniqueTimeZones . size ( ) ; i ++ ) { if ( uniqueTimeZones . get ( i ) . getRawOffset ( ) == zone . getRawOffset ( ) ) { found = true ; break ; } } if ( ! found ) { if ( DBG ) { Log . d ( TAG , ""getTimeZonesWithUniqueOffsets : add unique offset = "" +
","public static List < String > getTimeZoneIdsWithUniqueOffsets ( String country ) {
","public static List<TimeZone> getTimeZoneWithUniqueOffsets(String country) {
",,,"public static List<TimeZone> getTimeZonesWithUniqueOffsets(String country) {
",,,"public static List < TimeZone > getTimeZonesWithUniqueOffsets ( String country ) { synchronized ( sLastUniqueLockObj ) { if ( ( country != null ) && country . equals ( sLastUniqueCountry ) ) { return sLastUniqueZoneOffsets ; } } Collection < TimeZone > zones = getTimeZones ( country ) ; ArrayList < TimeZone > uniqueTimeZones = new ArrayList < > ( ) ; for ( TimeZone zone : zones ) { boolean found = false ; for ( int i = 0 ; i < uniqueTimeZones . size ( ) ; i ++ ) { if ( uniqueTimeZones . get ( i ) . getRawOffset ( ) == zone . getRawOffset ( ) ) { found = true ; break ; } } if ( ! found ) { uniqueTimeZones . add ( zone ) ; } } synchronized ( sLastUniqueLockObj ) { sLastUniqueCountry = country ; sLastUniqueZoneOffsets = uniqueTimeZones ; } return uniqueTimeZones ; }
",,,"public static List < TimeZone > getUniqueOffsetTimeZones ( String country ) { synchronized ( sLastUniqueLockObj ) { if ( country != null && country . equals ( sLastUniqueCountry ) ) { if ( DBG ) { Log . d ( TAG , ""getUniqueOffsetTimeZones ( "" + country + "" ) : return cached version"" ) ; } return sLastUniqueZoneOffsets ; } } Collection < TimeZone > zones = getTimeZones ( country ) ; ArrayList < TimeZone > uniqueTimeZones = new ArrayList < > ( ) ; for ( TimeZone zone : zones ) { boolean found = false ; for ( int i = 0 ; i < uniqueTimeZones . size ( ) ; i ++ ) { if ( uniqueTimeZones . get ( i ) . getRawOffset ( ) == zone . getRawOffset ( ) ) { found = true ; break ; } } if ( ! found ) { if ( DBG ) { Log . d ( TAG , ""getUniqueOffsetTimeZones : add unique offset = "" + zone . getRawOffset ( ) ) ; } uniqueTimeZones . add ( zone ) ; } } synchronized ( sLastUniqueLockObj ) { sLastUniqueCountry = country ; sLastUniqueZoneOffsets = uniqueTimeZones ; } return uniqueTimeZones ; }
",,,"< |startfocus| > public static List < TimeZone > getTimeZonesWithUniqueOffsets ( String country ) { < |endfocus| > synchronized ( sLastUniqueLockObj ) { if ( ( country != null ) && country . equals ( sLastUniqueCountry ) ) { if ( DBG ) { Log . d ( TAG , ""getTimeZonesWithUniqueOffsets ( "" + country + "" ) : return cached version"" ) ; } return sLastUniqueZoneOffsets ; } } Collection < TimeZone > zones = getTimeZones ( country ) ; ArrayList < TimeZone > uniqueTimeZones = new ArrayList < > ( ) ; for ( TimeZone zone : zones ) { // See if we already have this offset , // Using slow but space efficient and these are small . boolean found = false ; for ( int i = 0 ; i < uniqueTimeZones . size ( ) ; i ++ ) { if ( uniqueTimeZones . get ( i ) . getRawOffset ( ) == zone . getRawOffset ( ) ) { found = true ; break ; } } if ( ! found ) { if ( DBG ) { Log . d ( TAG , ""getTimeZonesWithUniqueOffsets : add unique offset = "" + zone . getRawOffset ( ) ) ; } uniqueTimeZones . add ( zone ) ; } } if ( DBG ) { Log . d ( TAG , ""getTimeZonesWithUniqueOffsets ( "" + country + "" ) : cache unique version"" ) ; } synchronized ( sLastUniqueLockObj ) { sLastUniqueCountry = country ; sLastUniqueZoneOffsets = uniqueTimeZones ; } return uniqueTimeZones ; }
",,
500,"mConnected . countDown ( ) ; return ; case AsyncChannel . CMD_CHANNEL_DISCONNECTED : Log . e ( TAG , ""Channel lost"" ) ; return ; default : break ; } final NsdServiceInfo ns = getNsdService ( key ) ; final Object listener = getListener ( key ) ; if ( listener == null ) { // Another message associated with that key notified the listener first . // This is expected for replies and timeouts to resolveService ( ) . return ; } if ( DBG ) { Log . d ( TAG , ""received "" + nameOf ( what ) + "" for key "" + key + "" , service "" + ns ) ; } switch ( what ) { case DISCOVER_SERVICES_STARTED : String s = getNsdServiceInfoType ( ( NsdServiceInfo ) message . obj ) ; ( ( DiscoveryListener ) listener ) . onDiscoveryStarted ( s ) ; break ; case DISCOVER_SERVICES_FAILED : removeListener ( key ) ; ( ( DiscoveryListener ) listener ) . onStartDiscoveryFailed ( getNsdServiceInfoType ( ns ) , message . arg1 ) ; break ; case SERVICE_FOUND :
","// Another message associated with that key notified the listener first . // This is expected for replies and timeouts to resolveService ( ) .
","if (what != RESOLVE_SERVICE_SUCCEEDED || what != RESOLVE_SERVICE_FAILED || what != RESOLVE_SERVICE_TIMEOUT) { Log.d(TAG, ""Stale key "" + key); }
",,,"// Expected for replies/timouts to resolveService() if (what != RESOLVE_SERVICE_SUCCEEDED || what != RESOLVE_SERVICE_FAILED || what != RESOLVE_SERVICE_TIMEOUT) { Log.d(TAG, ""Stale key "" + key); }
",,,"mConnected . countDown ( ) ; switch ( what ) { case AsyncChannel . CMD_CHANNEL_DISCONNECTED : Log . e ( TAG , ""Channel lost"" ) ; return ; default : break ; } final NsdServiceInfo ns = getNsdService ( key ) ; final Object listener = getListener ( key ) ; if ( listener == null && ( what == RESOLVE_SERVICE_SUCCEEDED || what == RESOLVE_SERVICE_FAILED || what == RESOLVE_SERVICE_TIMEOUT ) ) { return ; } if ( DBG ) { Log . d ( TAG , ""received "" + nameOf ( what ) + "" for key "" + key + "" , service "" + ns ) ; } switch ( what ) { case DISCOVER_SERVICES_STARTED : String s = getNsdServiceInfoType ( ( NsdServiceInfo ) message . obj ) ; ( ( DiscoveryListener ) listener ) . onDiscoveryStarted ( s ) ; break ; case DISCOVER_SERVICES_FAILED : removeListener ( key ) ; ( ( DiscoveryListener ) listener ) . onStartDiscoveryFailed ( getNsdServiceInfoType ( ns ) , message . arg1 ) ; break ; case SERVICE_FOUND : // code for SERVICE_FOUND case break ; default : break ; }
",,,"mConnected . countDown ( ) ; return ; case AsyncChannel . CMD_CHANNEL_DISCONNECTED : Log . e ( TAG , ""Channel lost"" ) ; return ; default : break ; } final NsdServiceInfo ns = getNsdService ( key ) ; final Object listener = getListener ( key ) ; if ( listener == null ) { if ( what != RESOLVE_SERVICE_SUCCEEDED || what != RESOLVE_SERVICE_FAILED || what != RESOLVE_SERVICE_TIMEOUT ) { Log . d ( TAG , ""Stale key "" + key ) ; } return ; } if ( DBG ) { Log . d ( TAG , ""received "" + nameOf ( what ) + "" for key "" + key + "" , service "" + ns ) ; } switch ( what ) { case DISCOVER_SERVICES_STARTED : String s = getNsdServiceInfoType ( ( NsdServiceInfo ) message . obj ) ; ( ( DiscoveryListener ) listener ) . onDiscoveryStarted ( s ) ; break ; case DISCOVER_SERVICES_FAILED : removeListener ( key ) ; ( ( DiscoveryListener ) listener ) . onStartDiscoveryFailed ( getNsdServiceInfoType ( ns ) , message . arg1 ) ; break ; case SERVICE_FOUND :
",,,"mConnected . countDown ( ) ; return ; case AsyncChannel . CMD_CHANNEL_DISCONNECTED : Log . e ( TAG , ""Channel lost"" ) ; return ; default : break ; } final NsdServiceInfo ns = getNsdService ( key ) ; final Object listener = getListener ( key ) ; if ( listener == null ) { < |startfocus| > // Expected for replies / timouts to resolveService ( ) if ( what != RESOLVE_SERVICE_SUCCEEDED && what != RESOLVE_SERVICE_FAILED && what != RESOLVE_SERVICE_TIMEOUT ) { Log . d ( TAG , ""Stale key "" + key ) ; } < |endfocus| > return ; } if ( DBG ) { Log . d ( TAG , ""received "" + nameOf ( what ) + "" for key "" + key + "" , service "" + ns ) ; } switch ( what ) { case DISCOVER_SERVICES_STARTED : String s = getNsdServiceInfoType ( ( NsdServiceInfo ) message . obj ) ; ( ( DiscoveryListener ) listener ) . onDiscoveryStarted ( s ) ; break ; case DISCOVER_SERVICES_FAILED : removeListener ( key ) ; ( ( DiscoveryListener ) listener ) . onStartDiscoveryFailed ( getNsdServiceInfoType ( ns ) , message . arg1 ) ; break ; case SERVICE_FOUND :
",,
502,"""android . bluetooth . adapter . extra . PREVIOUS_CONNECTION_STATE"" ; /* * * Broadcast Action : The Bluetooth adapter state has changed in LE only mode . * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = ""android . bluetooth . adapter . action . BLE_STATE_CHANGED"" ; /* * * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter . * < p > Always contains the extra field { @link * #EXTRA_BLUETOOTH_ADDRESS } containing the Bluetooth address . * * Note : only system level processes are allowed to send this * defined broadcast . * * @hide */ public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = ""android . bluetooth . adapter . action . BLUETOOTH_ADDRESS_CHANGED"" ; /* * * Used as a String extra field in { @link * #ACTION_BLUETOOTH_ADDRESS_CHANGED } intent to store the local * Bluetooth MAC address . * * @hide */ public static final String EXTRA_BLUETOOTH_ADDRESS = ""android . bluetooth . adapter . extra . BLUETOOTH_ADDRESS"" ;
","* #EXTRA_BLUETOOTH_ADDRESS } containing the Bluetooth address .
","* #EXTRA_BLUETOOTH_ADDRESS} containing the Bluetooth MAC address.
",,,"* #EXTRA_BLUETOOTH_ADDRESS} containing the MAC address.
",,,"public class BluetoothAdapter { public static final String ACTION_BLE_STATE_CHANGED = ""android . bluetooth . adapter . action . BLE_STATE_CHANGED"" ; public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = ""android . bluetooth . adapter . action . BLUETOOTH_ADDRESS_CHANGED"" ; public static final String EXTRA_BLUETOOTH_ADDRESS = ""android . bluetooth . adapter . extra . BLUETOOTH_ADDRESS"" ; }
",,,"""android . bluetooth . adapter . extra . PREVIOUS_CONNECTION_STATE"" ; /* * * Broadcast Action : The Bluetooth adapter state has changed in LE only mode . * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = ""android . bluetooth . adapter . action . BLE_STATE_CHANGED"" ; /* * * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter . * < p > Always contains the extra field { @link #EXTRA_BLUETOOTH_ADDRESS } containing the MAC address . * *
",,,"""android . bluetooth . adapter . extra . PREVIOUS_CONNECTION_STATE"" ; /* * * Broadcast Action : The Bluetooth adapter state has changed in LE only mode . * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = ""android . bluetooth . adapter . action . BLE_STATE_CHANGED"" ; /* * * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter . * < p > Always contains the extra field { @link < |startfocus| > * #EXTRA_BLUETOOTH_ADDRESS } containing the MAC address . < |endfocus| > * *
",,
505,"if ( newName != null ) { storeNameAndAddress ( newName , null ) ; } } else if ( BluetoothAdapter . ACTION_BLUETOOTH_ADDRESS_CHANGED . equals ( action ) ) { String newAddress = intent . getStringExtra ( BluetoothAdapter . EXTRA_BLUETOOTH_ADDRESS ) ; if ( newAddress != null ) { if ( DBG ) Slog . d ( TAG , ""Bluetooth Adapter MAC Address changed to "" + newAddress ) ; storeNameAndAddress ( null , newAddress ) ; } else { if ( DBG ) Slog . e ( TAG , ""No Bluetooth Adapter address parameter found"" ) ; } }
","if ( DBG ) Slog . e ( TAG , ""No Bluetooth Adapter address parameter found"" ) ;
","if (DBG) Slog.e(TAG, ""No Bluetooth Adapter MAC Address parameter found"");
",,,"if (DBG) Slog.e(TAG, ""No Bluetooth Adapter MAC Address parameter found"");
",,,"if ( newName != null ) { storeNameAndAddress ( newName , null ) ; } else if ( BluetoothAdapter . ACTION_BLUETOOTH_ADDRESS_CHANGED . equals ( action ) ) { String newAddress = intent . getStringExtra ( BluetoothAdapter . EXTRA_BLUETOOTH_ADDRESS ) ; if ( newAddress != null ) { if ( DBG ) { Slog . d ( TAG , ""Bluetooth Adapter MAC Address changed to "" + newAddress ) ; } storeNameAndAddress ( null , newAddress ) ; } else { if ( DBG ) { Slog . e ( TAG , ""No Bluetooth Adapter MAC Address parameter found"" ) ; } } }
",,,"if ( newName != null ) { storeNameAndAddress ( newName , null ) ; } else if ( BluetoothAdapter . ACTION_BLUETOOTH_ADDRESS_CHANGED . equals ( action ) ) { String newAddress = intent . getStringExtra ( BluetoothAdapter . EXTRA_BLUETOOTH_ADDRESS ) ; if ( newAddress != null ) { if ( DBG ) Slog . d ( TAG , ""Bluetooth Adapter MAC Address changed to "" + newAddress ) ; storeNameAndAddress ( null , newAddress ) ; } else { if ( DBG ) Slog . e ( TAG , ""No Bluetooth Adapter MAC Address parameter found"" ) ; } }
",,,"if ( newName != null ) { storeNameAndAddress ( newName , null ) ; } } else if ( BluetoothAdapter . ACTION_BLUETOOTH_ADDRESS_CHANGED . equals ( action ) ) { String newAddress = intent . getStringExtra ( BluetoothAdapter . EXTRA_BLUETOOTH_ADDRESS ) ; if ( newAddress != null ) { if ( DBG ) Slog . d ( TAG , ""Bluetooth Adapter MAC Address changed to "" + newAddress ) ; storeNameAndAddress ( null , newAddress ) ; } else { < |startfocus| > if ( DBG ) Slog . e ( TAG , ""No Bluetooth Adapter MAC Address parameter found"" ) ; < |endfocus| > } } < |startfocus| >
",,
511,"* < tr > < td > Android 7 . 0 ( Nougat ) </ td > * < td > < a href = ""http :/ / site . icu - project . org / download / 56"" > ICU 56 . 1 </ a > </ td > * < td > < a href = ""http :/ / cldr . unicode . org / index / downloads / cldr - 28"" > CLDR 28 </ a > </ td > * < td > < a href = ""http :/ / www . unicode . org / versions / Unicode8 . 0 . 0 / "" > Unicode 8 . 0 </ a > </ td > </ tr > * < tr > < td > Android O </ td > * < td > < a href = ""http :/ / site . icu - project . org / download / 58"" > ICU 58 . 2 </ a > </ td > * < td > < a href = ""http :/ / cldr . unicode . org / index / downloads / cldr - 30"" > CLDR 30 . 0 . 3 </ a > </ td > * < td > < a href = ""http :/ / www . unicode . org / versions / Unicode9 . 0 . 0 / "" > Unicode 9 . 0 </ a > </ td > </ tr > * </ table > * * < a name = ""default_locale"" > </ a > < h4 > Be wary of the default locale </ h3 > * < p > Note that there are many convenience methods that automatically use the default locale , but
","* < tr > < td > Android O </ td >
","* <tr><td>Android O</td>
",,,"* <tr><td>Android O</td>
",,,"< tr > < td > Android O </ td > < td > < a href = ""http :/ / site . icu - project . org / download / 58"" > ICU 58 . 2 </ a > </ td > < td > < a href = ""http :/ / cldr . unicode . org / index / downloads / cldr - 30"" > CLDR 30 . 0 . 3 </ a > </ td > < td > < a href = ""http :/ / www . unicode . org / versions / Unicode9 . 0 . 0 / "" > Unicode 9 . 0 </ a > </ td > </ tr > </ table > < a name = ""default_locale"" > </ a > < h4 > Be wary of the default locale </ h3 > < p > Note that there are many convenience methods that automatically use the default locale , but
",,,"< tr > < td > Android ( TBD ) </ td > < td > < a href = ""http :/ / site . icu - project . org / download / 58"" > ICU 58 . 2 </ a > </ td > < td > < a href = ""http :/ / cldr . unicode . org / index / downloads / cldr - 30"" > CLDR 30 . 0 . 3 </ a > </ td > < td > < a href = ""http :/ / www . unicode . org / versions / Unicode9 . 0 . 0 / "" > Unicode 9 . 0 </ a > </ td > </ tr >
",,,"* < tr > < td > Android 7 . 0 ( Nougat ) </ td > * < td > < a href = ""http :/ / site . icu - project . org / download / 56"" > ICU 56 . 1 </ a > </ td > * < td > < a href = ""http :/ / cldr . unicode . org / index / downloads / cldr - 28"" > CLDR 28 </ a > </ td > * < td > < a href = ""http :/ / www . unicode . org / versions / Unicode8 . 0 . 0 / "" > Unicode 8 . 0 </ a > </ td > </ tr > < |startfocus| > * < tr > < td > Android O </ td > < |endfocus| > * < td > < a href = ""http :/ / site . icu - project . org / download / 58"" > ICU 58 . 2 </ a > </ td > * < td > < a href = ""http :/ / cldr . unicode . org / index / downloads / cldr - 30"" > CLDR 30 . 0 . 3 </ a > </ td > * < td > < a href = ""http :/ / www . unicode . org / versions / Unicode9 . 0 . 0 / "" > Unicode 9 . 0 </ a > </ td > </ tr > * </ table > * * < a name = ""default_locale"" > </ a > < h4 > Be wary of the default locale </ h3 > * < p > Note that there are many convenience methods that automatically use the default locale , but
",,
518,"public boolean imsIsEnhanced4gLteModeSettingEnabledByPlatform ( ) { return mImsManager . isVolteEnabledByPlatformForSlot ( ) ;
","return mImsManager . isVolteEnabledByPlatformForSlot ( ) ;
","return mImsManager.isVolteEnabledByPlatformForSlot();
",,,"return mImsManager.isVolteEnabledByPlatformForSlot();
",,,"public boolean imsIsEnhanced4gLteModeSettingEnabledByPlatform ( ) { return mImsManager . isVolteEnabledByPlatformForSlot ( ) ; }
",,,"public boolean imsIsEnhanced4gLteModeSettingEnabledByPlatform ( ) { return mImsManager . isVolteEnabledByPlatformForSlot ( ) ; }
",,,"public boolean imsIsEnhanced4gLteModeSettingEnabledByPlatform ( ) { < |startfocus| > return mImsManager . isVolteEnabledByPlatformForSlot ( ) ; < |endfocus| >
",,
522,"} return findPreviousZoneTransitionTime ( tz , upperOffset , mid , lower ) ; } /* * * Compute the milliseconds in the day from the fields . This is a * value from 0 to 23 : 59 : 59 . 999 inclusive , unless fields are out of * range , in which case it can be an arbitrary value . This value * reflects local zone wall time . * @deprecated This method suffers from a potential integer overflow and may be removed in a * future release . Overriding this method in subclasses will not have the desired effect . * See ICU ticket #11632 . */ protected int computeMillisInDay ( ) { // Do the time portion of the conversion . int millisInDay = 0 ; // Find the best set of fields specifying the time of day . There // are only two possibilities here ; the HOUR_OF_DAY or the // AM_PM and the HOUR . int hourOfDayStamp = stamp [ HOUR_OF_DAY ] ; int hourStamp = Math . max ( stamp [ HOUR ] , stamp [ AM_PM ] ) ;
","* @deprecated This method suffers from a potential integer overflow and may be removed in a * future release . Overriding this method in subclasses will not have the desired effect . * See ICU ticket #11632 .
","* @deprecated This method suffers from a potential integer overflow and may be removed in a future * release. Overriding this method in subclasses will not have the desired effect. See ICU * ticket #11632.
",,,"* @deprecated This method suffers from a potential integer overflow and may be removed in a future release. * Overriding this method in subclasses will not have the desired effect. See ICU * ticket #11632.
",,,"protected int computeMillisInDay ( ) { int millisInDay = 0 ; int hourOfDayStamp = stamp [ HOUR_OF_DAY ] ; int hourStamp = Math . max ( stamp [ HOUR ] , stamp [ AM_PM ] ) ; millisInDay += hourOfDayStamp == UNSET ? hourStamp : hourOfDayStamp + hourStamp ; millisInDay *= MILLIS_PER_HOUR ; millisInDay += stamp [ MINUTE ] * MILLIS_PER_MINUTE ; millisInDay += stamp [ SECOND ] * MILLIS_PER_SECOND ; millisInDay += stamp [ MILLISECOND ] ; return millisInDay ; }
",,,"protected int computeMillisInDay ( ) { int millisInDay = 0 ; int hourOfDayStamp = stamp [ HOUR_OF_DAY ] ; int hourStamp = Math . max ( stamp [ HOUR ] , stamp [ AM_PM ] ) ; if ( hourOfDayStamp >= 0 ) { millisInDay += fields [ HOUR_OF_DAY ] ; } else if ( hourStamp >= 0 ) { millisInDay += fields [ HOUR ] + ( fields [ AM_PM ] * 12 ) ; } millisInDay *= 60 ; millisInDay += fields [ MINUTE ] ; millisInDay *= 60 ; millisInDay += fields [ SECOND ] ; millisInDay *= 1000 ; millisInDay += fields [ MILLISECOND ] ; return millisInDay ; }
",,,"} return findPreviousZoneTransitionTime ( tz , upperOffset , mid , lower ) ; } /* * * Compute the milliseconds in the day from the fields . This is a * value from 0 to 23 : 59 : 59 . 999 inclusive , unless fields are out of * range , in which case it can be an arbitrary value . This value * reflects local zone wall time . < |startfocus| > * @deprecated This method suffers from a potential integer overflow and may be removed in a future * release . Overriding this method in subclasses will not have the desired effect . See ICU * ticket #11632 . < |endfocus| > */ protected int computeMillisInDay ( ) { // Do the time portion of the conversion . int millisInDay = 0 ; // Find the best set of fields specifying the time of day . There // are only two possibilities here ; the HOUR_OF_DAY or the // AM_PM and the HOUR . int hourOfDayStamp = stamp [ HOUR_OF_DAY ] ; int hourStamp = Math . max ( stamp [ HOUR ] , stamp [ AM_PM ] ) ;
",,
537,"private boolean initialize ( ) { Log . d ( TAG , ""Start initialize ( ) "" ) ; mPMCStatusLogger = new PMCStatusLogger ( TAG + "" . log"" , TAG ) ; // Check if any Bluetooth devices are connected ArrayList < BluetoothDevice > results = new ArrayList < BluetoothDevice > ( ) ; Set < BluetoothDevice > bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; if ( bondedDevices == null ) { Log . e ( TAG , ""Bonded devices list is null"" ) ; return false ; } for ( BluetoothDevice bd : bondedDevices ) { if ( bd . isConnected ( ) ) { results . add ( bd ) ; } } if ( results . isEmpty ( ) ) { Log . e ( TAG , ""No device is connected"" ) ; return false ; } Log . d ( TAG , ""Finish initialize ( ) "" ) ; return true ;
","if ( bondedDevices == null ) { Log . e ( TAG , ""Bonded devices list is null"" ) ; return false ; }
","if (bondedDevices == null) return false;
",,,"<|del|>
",,,"private boolean initialize ( ) { Log . d ( TAG , ""Start initialize ( ) "" ) ; mPMCStatusLogger = new PMCStatusLogger ( TAG + "" . log"" , TAG ) ; Set < BluetoothDevice > bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; if ( bondedDevices == null || bondedDevices . isEmpty ( ) ) { Log . e ( TAG , ""No bonded devices found"" ) ; return false ; } ArrayList < BluetoothDevice > results = new ArrayList < > ( ) ; for ( BluetoothDevice bd : bondedDevices ) { if ( bd . isConnected ( ) ) { results . add ( bd ) ; } } if ( results . isEmpty ( ) ) { Log . e ( TAG , ""No connected devices found"" ) ; return false ; } Log . d ( TAG , ""Finish initialize ( ) "" ) ; return true ; }
",,,"private boolean initialize ( ) { Log . d ( TAG , ""Start initialize ( ) "" ) ; mPMCStatusLogger = new PMCStatusLogger ( TAG + "" . log"" , TAG ) ; // Check if any Bluetooth devices are connected ArrayList < BluetoothDevice > results = new ArrayList < BluetoothDevice > ( ) ; Set < BluetoothDevice > bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; if ( bondedDevices == null ) { Log . e ( TAG , ""No device is connected"" ) ; return false ; } for ( BluetoothDevice bd : bondedDevices ) { if ( bd . isConnected ( ) ) { results . add ( bd ) ; } } if ( results . isEmpty ( ) ) { Log . e ( TAG , ""No device is connected"" ) ; return false ; } Log . d ( TAG , ""Finish initialize ( ) "" ) ; return true ; }
",,,"private boolean initialize ( ) { Log . d ( TAG , ""Start initialize ( ) "" ) ; mPMCStatusLogger = new PMCStatusLogger ( TAG + "" . log"" , TAG ) ; // Check if any Bluetooth devices are connected ArrayList < BluetoothDevice > results = new ArrayList < BluetoothDevice > ( ) ; Set < BluetoothDevice > bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; < |startfocus| > if ( bondedDevices == null ) return false ; < |endfocus| > for ( BluetoothDevice bd : bondedDevices ) { if ( bd . isConnected ( ) ) { results . add ( bd ) ; } } if ( results . isEmpty ( ) ) { Log . e ( TAG , ""No device is connected"" ) ; return false ; } Log . d ( TAG , ""Finish initialize ( ) "" ) ; return true ;
",,
538,"private boolean initialize ( ) { Log . d ( TAG , ""Start initialize ( ) "" ) ; mPMCStatusLogger = new PMCStatusLogger ( TAG + "" . log"" , TAG ) ; // Check if any BT devices are connected ArrayList < BluetoothDevice > results = new ArrayList < BluetoothDevice > ( ) ; Set < BluetoothDevice > bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; if ( bondedDevices == null ) return false ; for ( BluetoothDevice bd : bondedDevices ) { if ( bd . isConnected ( ) ) { results . add ( bd ) ; } } if ( results . isEmpty ( ) ) { Log . e ( TAG , ""No device is connected"" ) ; return false ; } Log . d ( TAG , ""Finish initialize ( ) "" ) ; return true ;
","Set < BluetoothDevice > bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; if ( bondedDevices == null ) return false ; for ( BluetoothDevice bd : bondedDevices ) {
","for (BluetoothDevice bd : getBondedDevices()) {
",,,"for (BluetoothDevice bd : mBluetoothAdapter.getBondedDevices()) {
",,,"private boolean initialize ( ) { Log . d ( TAG , ""Start initialize ( ) "" ) ; mPMCStatusLogger = new PMCStatusLogger ( TAG + "" . log"" , TAG ) ; // Check if any BT devices are connected ArrayList < BluetoothDevice > results = new ArrayList < BluetoothDevice > ( ) ; Set < BluetoothDevice > bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; if ( bondedDevices == null ) { Log . e ( TAG , ""No bonded devices found"" ) ; return false ; } for ( BluetoothDevice bd : bondedDevices ) { if ( bd . isConnected ( ) ) { results . add ( bd ) ; } } if ( results . isEmpty ( ) ) { Log . e ( TAG , ""No device is connected"" ) ; return false ; } Log . d ( TAG , ""Finish initialize ( ) "" ) ; return true ; }
",,,"private boolean initialize ( ) { Log . d ( TAG , ""Start initialize ( ) "" ) ; mPMCStatusLogger = new PMCStatusLogger ( TAG + "" . log"" , TAG ) ; // Check if any BT devices are connected ArrayList < BluetoothDevice > results = new ArrayList < BluetoothDevice > ( ) ; BluetoothDevice [ ] bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; if ( bondedDevices != null ) { for ( BluetoothDevice bd : bondedDevices ) { if ( bd . isConnected ( ) ) { results . add ( bd ) ; } } } if ( results . isEmpty ( ) ) { Log . e ( TAG , ""No device is connected"" ) ; return false ; } Log . d ( TAG , ""Finish initialize ( ) "" ) ; return true ; }
",,,"private boolean initialize ( ) { Log . d ( TAG , ""Start initialize ( ) "" ) ; mPMCStatusLogger = new PMCStatusLogger ( TAG + "" . log"" , TAG ) ; // Check if any BT devices are connected ArrayList < BluetoothDevice > results = new ArrayList < BluetoothDevice > ( ) ; < |startfocus| > Set < BluetoothDevice > bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; if ( bondedDevices == null ) { Log . e ( TAG , ""No device is connected"" ) ; return false ; } for ( BluetoothDevice bd : bondedDevices ) { < |endfocus| > if ( bd . isConnected ( ) ) { results . add ( bd ) ; } } if ( results . isEmpty ( ) ) { Log . e ( TAG , ""No device is connected"" ) ; return false ; } Log . d ( TAG , ""Finish initialize ( ) "" ) ; return true ;
",,
539,"boolean bt_off_mute = false ; Bundle extras = intent . getExtras ( ) ; if ( extras == null ) { Log . e ( TAG , ""No parameters specified"" ) ; return ; } // Always initialize ( ) if ( ! initialize ( ) ) { mPMCStatusLogger . logStatus ( ""initialize ( ) Failed"" ) ; return ; } // Check if it is baseline BT is on but not stream if ( extras . containsKey ( ""BT_ON_NotPlay"" ) ) { Log . v ( TAG , ""NotPlay is specified for baseline case that only Bluetooth is on"" ) ; // Do nothing further mPMCStatusLogger . logStatus ( ""READY"" ) ; mPMCStatusLogger . logStatus ( ""SUCCEED"" ) ; return ; } if ( ! extras . containsKey ( ""PlayTime"" ) ) { Log . e ( TAG , ""No Play Time specified"" ) ; return ; } tmpStr = extras . getString ( ""PlayTime"" ) ; Log . d ( TAG , ""Play Time = "" + tmpStr ) ; playTime = Integer . valueOf ( tmpStr ) ; if ( ! extras . containsKey ( ""MusicURL"" ) ) { Log . e ( TAG , ""No Music URL specified"" ) ; return ; }
","Log . v ( TAG , ""NotPlay is specified for baseline case that only Bluetooth is on"" ) ;
","Log.v(TAG, ""Notplay is specified for baseline case of only Bluetooth on"");
",,,"Log.v(TAG, ""NotPlay is specified for only Bluetooth on"");
",,,"boolean bluetoothOffMute = false ; Bundle extras = intent . getExtras ( ) ; if ( extras == null ) { Log . e ( TAG , ""No parameters specified"" ) ; return ; } // Always initialize ( ) if ( ! initialize ( ) ) { mPMCStatusLogger . logStatus ( ""initialize ( ) Failed"" ) ; return ; } // Check if Bluetooth is on but not streaming if ( extras . containsKey ( ""BLUETOOTH_ON_NOT_PLAY"" ) ) { Log . v ( TAG , ""NotPlay is specified for baseline case of only Bluetooth on"" ) ; // Do nothing further mPMCStatusLogger . logStatus ( ""READY"" ) ; mPMCStatusLogger . logStatus ( ""SUCCEED"" ) ; return ; } if ( ! extras . containsKey ( ""PlayTime"" ) ) { Log . e ( TAG , ""No Play Time specified"" ) ; return ; } String playTimeStr = extras . getString ( ""PlayTime"" ) ; Log . d ( TAG , ""Play Time = "" + playTimeStr ) ; int playTime = Integer . valueOf ( playTimeStr ) ; if ( ! extras . containsKey ( ""MusicURL"" ) ) { Log . e ( TAG , ""No Music URL specified"" ) ; return ; }
",,,"boolean bluetoothOffMute = false ; Bundle extras = intent . getExtras ( ) ; if ( extras == null ) { Log . e ( TAG , ""No parameters specified"" ) ; return ; } // Always initialize ( ) if ( ! initialize ( ) ) { mPMCStatusLogger . logStatus ( ""initialize ( ) Failed"" ) ; return ; } // Check if it is baseline Bluetooth is on but not streaming if ( extras . containsKey ( ""BT_ON_NotPlay"" ) ) { Log . v ( TAG , ""NotPlay is specified for baseline case of only Bluetooth on"" ) ; // Do nothing further mPMCStatusLogger . logStatus ( ""READY"" ) ; mPMCStatusLogger . logStatus ( ""SUCCEED"" ) ; return ; } if ( ! extras . containsKey ( ""PlayTime"" ) ) { Log . e ( TAG , ""No Play Time specified"" ) ; return ; } String playTimeStr = extras . getString ( ""PlayTime"" ) ; Log . d ( TAG , ""Play Time = "" + playTimeStr ) ; int playTime = Integer . valueOf ( playTimeStr ) ; if ( ! extras . containsKey ( ""MusicURL"" ) ) { Log . e ( TAG , ""No Music URL specified"" ) ; return ; }
",,,"boolean bt_off_mute = false ; Bundle extras = intent . getExtras ( ) ; if ( extras == null ) { Log . e ( TAG , ""No parameters specified"" ) ; return ; } // Always initialize ( ) if ( ! initialize ( ) ) { mPMCStatusLogger . logStatus ( ""initialize ( ) Failed"" ) ; return ; } // Check if it is baseline Bluetooth is on but not stream if ( extras . containsKey ( ""Bluetooth_ON_NotPlay"" ) ) { < |startfocus| > Log . v ( TAG , ""NotPlay is specified for baseline case of only Bluetooth on"" ) ; < |endfocus| > // Do nothing further mPMCStatusLogger . logStatus ( ""READY"" ) ; mPMCStatusLogger . logStatus ( ""SUCCEED"" ) ; return ; } if ( ! extras . containsKey ( ""PlayTime"" ) ) { Log . e ( TAG , ""No Play Time specified"" ) ; return ; } tmpStr = extras . getString ( ""PlayTime"" ) ; Log . d ( TAG , ""Play Time = "" + tmpStr ) ; playTime = Integer . valueOf ( tmpStr ) ; if ( ! extras . containsKey ( ""MusicURL"" ) ) { Log . e ( TAG , ""No Music URL specified"" ) ; return ; }
",,
546,"pw . increaseIndent ( ) ; if ( apfFilter != null ) { apfFilter . dump ( pw ) ; } else { if ( provisioningConfig != null ) { pw . println ( ""No active ApfFilter ; provisioned capabilities : "" + provisioningConfig . mApfCapabilities ) ; } else { pw . println ( ""N / A -- no ProvisioningConfiguration available"" ) ; } } pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" current ProvisioningConfiguration : "" ) ; pw . increaseIndent ( ) ; pw . println ( Objects . toString ( provisioningConfig , ""N / A"" ) ) ; pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" StateMachine dump : "" ) ; pw . increaseIndent ( ) ; mLocalLog . readOnlyLocalLog ( ) . dump ( fd , pw , args ) ; pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" connectivity packet log : "" ) ; pw . println ( ) ; pw . println ( ""Debug with python and scapy via : "" ) ; pw . println ( ""shell$ python"" ) ; pw . println ( "" > > > from scapy import all as scapy"" ) ;
","pw . println ( Objects . toString ( provisioningConfig , ""N / A"" ) ) ;
","pw.println(Objects.toString(provisioningConfig));
",,,"pw.println(Objects.toString(provisioningConfig));
",,,"pw . increaseIndent ( ) ; if ( apfFilter != null ) { apfFilter . dump ( pw ) ; } else { if ( provisioningConfig != null ) { pw . println ( ""No active ApfFilter ; provisioned capabilities : "" + provisioningConfig . mApfCapabilities ) ; } else { pw . println ( ""N / A -- no ProvisioningConfiguration available"" ) ; } } pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" current ProvisioningConfiguration : "" ) ; pw . increaseIndent ( ) ; pw . println ( Objects . toString ( provisioningConfig , ""N / A"" ) ) ; pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" StateMachine dump : "" ) ; pw . increaseIndent ( ) ; mLocalLog . readOnlyLocalLog ( ) . dump ( fd , pw , args ) ; pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" connectivity packet log : "" ) ; pw . println ( ) ; pw . println ( ""Debug with python and scapy via : "" ) ; pw . println ( ""shell$ python"" ) ; pw . println ( "" > > > from scapy import all as scapy"" ) ;
",,,"pw . increaseIndent ( ) ; if ( apfFilter != null ) { apfFilter . dump ( pw ) ; } else { if ( provisioningConfig != null ) { pw . println ( ""No active ApfFilter ; provisioned capabilities : "" + provisioningConfig . mApfCapabilities ) ; } else { pw . println ( ""N / A -- no ProvisioningConfiguration available"" ) ; } } pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" current ProvisioningConfiguration : "" ) ; pw . increaseIndent ( ) ; pw . println ( Objects . toString ( provisioningConfig , ""N / A"" ) ) ; pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" StateMachine dump : "" ) ; pw . increaseIndent ( ) ; mLocalLog . readOnlyLocalLog ( ) . dump ( fd , pw , args ) ; pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" connectivity packet log : "" ) ; pw . println ( ) ; pw . println ( ""Debug with python and scapy via : "" ) ; pw . println ( ""shell$ python"" ) ; pw . println ( "" > > > from scapy import all as scapy"" ) ;
",,,"pw . increaseIndent ( ) ; if ( apfFilter != null ) { apfFilter . dump ( pw ) ; } else { if ( provisioningConfig != null ) { pw . println ( ""No active ApfFilter ; provisioned capabilities : "" + provisioningConfig . mApfCapabilities ) ; } else { pw . println ( ""N / A -- no ProvisioningConfiguration available"" ) ; } } pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" current ProvisioningConfiguration : "" ) ; pw . increaseIndent ( ) ; < |startfocus| > pw . println ( Objects . toString ( provisioningConfig , ""N / A"" ) ) ; < |endfocus| > pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" StateMachine dump : "" ) ; pw . increaseIndent ( ) ; mLocalLog . readOnlyLocalLog ( ) . dump ( fd , pw , args ) ; pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + "" connectivity packet log : "" ) ; pw . println ( ) ; pw . println ( ""Debug with python and scapy via : "" ) ; pw . println ( ""shell$ python"" ) ; pw . println ( "" > > > from scapy import all as scapy"" ) ;
",,
547,"private int putListener ( Object listener , NsdServiceInfo s ) { checkListener ( listener ) ; final int key ; synchronized ( mMapLock ) { int valueIndex = mListenerMap . indexOfValue ( listener ) ; checkArgument ( valueIndex == - 1 , ""listener already in use"" ) ; key = nextListenerKey ( ) ; mListenerMap . put ( key , listener ) ; mServiceMap . put ( key , s ) ; } return key ;
","key = nextListenerKey ( ) ;
","key = Math.abs(mListenerKey++);
",,,"key = Math.abs(mListenerKey++); if (key == 0) { key = 1; }
",,,"private int putListener ( Object listener , NsdServiceInfo s ) { checkListener ( listener ) ; final int key ; synchronized ( mMapLock ) { int valueIndex = mListenerMap . indexOfValue ( listener ) ; checkArgument ( valueIndex == - 1 , ""listener already in use"" ) ; do { key = Math . abs ( mListenerKey ++ ) ; } while ( key == 0 || mListenerMap . indexOfKey ( key ) >= 0 ) ; mListenerMap . put ( key , listener ) ; mServiceMap . put ( key , s ) ; } return key ; }
",,,"private int putListener ( Object listener , NsdServiceInfo s ) { checkListener ( listener ) ; final int key ; synchronized ( mMapLock ) { int valueIndex = mListenerMap . indexOfValue ( listener ) ; checkArgument ( valueIndex == - 1 , ""listener already in use"" ) ; key = Math . abs ( mListenerKey ++ ) ; mListenerMap . put ( key , listener ) ; mServiceMap . put ( key , s ) ; } return key ; }
",,,"private int putListener ( Object listener , NsdServiceInfo s ) { checkListener ( listener ) ; final int key ; synchronized ( mMapLock ) { int valueIndex = mListenerMap . indexOfValue ( listener ) ; checkArgument ( valueIndex == - 1 , ""listener already in use"" ) ; < |startfocus| > key = mListenerKey ++ ; < |endfocus| > mListenerMap . put ( key , listener ) ; mServiceMap . put ( key , s ) ; } return key ;
",,
556,"classLoader = getClassLoaderInitializedWithDexFile ( ) ; } else { classLoader = getClassLoaderInitializedWithClassFile ( ) ; } Class < ? > klass = null ; try { klass = classLoader . loadClass ( classWithSourceDebugExtension ) ; } catch ( ClassNotFoundException e ) { logWriter . println ( "" -- > Debuggee : Could not find class "" + classWithSourceDebugExtension ) ; } // Create an instance of classWithSourceDebugExtension so the // SourceDebugExtension metadata can be reported back to the debugger . Object o = null ; if ( klass != null ) { try { o = klass . getConstructor ( ) . newInstance ( ) ; } catch ( Exception e ) { logWriter . println ( "" -- > Debuggee : Failed to instantiate "" + classWithSourceDebugExtension + "" : "" + e ) ; } } synchronizer . sendMessage ( JPDADebuggeeSynchronizer . SGNL_READY ) ; logWriter . println ( "" -- > Debuggee : SourceDebugExtensionDebuggee . . . "" ) ; synchronizer . receiveMessage ( JPDADebuggeeSynchronizer . SGNL_CONTINUE ) ;
","// SourceDebugExtension metadata can be reported back to the debugger .
","// SourceDebugExtension metadata can be reported back to the debugger.
",,,"// SourceDebugExtension metadata can be reported back to the debugger.
",,,"classLoader = getClassLoaderInitializedWithDexFile ( ) ; } else { classLoader = getClassLoaderInitializedWithClassFile ( ) ; } Class < ? > klass = null ; try { klass = classLoader . loadClass ( classWithSourceDebugExtension ) ; } catch ( ClassNotFoundException e ) { logWriter . println ( "" -- > Debuggee : Could not find class "" + classWithSourceDebugExtension ) ; } Object o = null ; if ( klass != null ) { try { o = klass . getConstructor ( ) . newInstance ( ) ; } catch ( Exception e ) { logWriter . println ( "" -- > Debuggee : Failed to instantiate "" + classWithSourceDebugExtension + "" : "" + e ) ; } } synchronizer . sendMessage ( JPDADebuggeeSynchronizer . SGNL_READY ) ; logWriter . println ( "" -- > Debuggee : SourceDebugExtensionDebuggee . . . "" ) ; synchronizer . receiveMessage ( JPDADebuggeeSynchronizer . SGNL_CONTINUE ) ;
",,,"classLoader = getClassLoaderInitializedWithDexFile ( ) ; } else { classLoader = getClassLoaderInitializedWithClassFile ( ) ; } Class < ? > klass = null ; try { klass = classLoader . loadClass ( classWithSourceDebugExtension ) ; } catch ( ClassNotFoundException e ) { logWriter . println ( "" -- > Debuggee : Could not find class "" + classWithSourceDebugExtension ) ; } Object o = null ; if ( klass != null ) { try { o = klass . getConstructor ( ) . newInstance ( ) ; } catch ( Exception e ) { logWriter . println ( "" -- > Debuggee : Failed to instantiate "" + classWithSourceDebugExtension + "" : "" + e ) ; } } synchronizer . sendMessage ( JPDADebuggeeSynchronizer . SGNL_READY ) ; logWriter . println ( "" -- > Debuggee : SourceDebugExtensionDebuggee . . . "" ) ; synchronizer . receiveMessage ( JPDADebuggeeSynchronizer . SGNL_CONTINUE ) ;
",,,"classLoader = getClassLoaderInitializedWithDexFile ( ) ; } else { classLoader = getClassLoaderInitializedWithClassFile ( ) ; } Class < ? > klass = null ; try { klass = classLoader . loadClass ( classWithSourceDebugExtension ) ; } catch ( ClassNotFoundException e ) { logWriter . println ( "" -- > Debuggee : Could not find class "" + classWithSourceDebugExtension ) ; } // Create an instance of classWithSourceDebugExtension so the < |startfocus| > // SourceDebugExntension metadata can be reported back to the debugger . < |endfocus| > Object o = null ; if ( klass != null ) { try { o = klass . getConstructor ( ) . newInstance ( ) ; } catch ( Exception e ) { logWriter . println ( "" -- > Debuggee : Failed to instantiate "" + classWithSourceDebugExtension + "" : "" + e ) ; } } synchronizer . sendMessage ( JPDADebuggeeSynchronizer . SGNL_READY ) ; logWriter . println ( "" -- > Debuggee : SourceDebugExtensionDebuggee . . . "" ) ; synchronizer . receiveMessage ( JPDADebuggeeSynchronizer . SGNL_CONTINUE ) ;
",,
557,"/* * * The MBMS middleware should send this when a download of single file has completed or * failed . Mandatory extras are * { @link #EXTRA_RESULT } * { @link #EXTRA_INFO } * { @link #EXTRA_REQUEST } * { @link #EXTRA_TEMP_LIST } * { @link #EXTRA_FINAL_URI } * * TODO : future systemapi */ public static final String ACTION_DOWNLOAD_RESULT_INTERNAL = ""android . telephony . mbms . action . DOWNLOAD_RESULT_INTERNAL"" ; /* * * The MBMS middleware should send this when it wishes to request { @code content :/ / } URIs to * serve as temp files for downloads or when it wishes to resume paused downloads . Mandatory * extras are * { @link #EXTRA_REQUEST } * * Optional extras are * { @link #EXTRA_FD_COUNT } ( 0 if not present ) * { @link #EXTRA_PAUSED_LIST } ( empty if not present ) * * TODO : future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST =
","""android . telephony . mbms . action . DOWNLOAD_RESULT_INTERNAL"" ;
","""android.telephony.mbms.action.DOWNLOAD_RESULT_INTERNAL"";
",,,"""android.telephony.mbms.action.DOWNLOAD_RESULT_INTERNAL"";
",,,"/* * * The MBMS middleware should send this when a download of single file has completed or failed . * Mandatory extras are : * { @link #EXTRA_RESULT } * { @link #EXTRA_INFO } * { @link #EXTRA_REQUEST } * { @link #EXTRA_TEMP_LIST } * { @link #EXTRA_FINAL_URI } * * TODO : future systemapi */ public static final String ACTION_DOWNLOAD_COMPLETE = ""android . telephony . mbms . action . DOWNLOAD_RESULT_INTERNAL"" ; /* * * The MBMS middleware should send this when it wishes to request { @code content :/ / } URIs to * serve as temp files for downloads or when it wishes to resume paused downloads . * Mandatory extras are : * { @link #EXTRA_REQUEST } * * Optional extras are : * { @link #EXTRA_FD_COUNT } ( 0 if not present ) * { @link #EXTRA_PAUSED_LIST } ( empty if not present ) * * TODO : future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST = . . .
",,,"public static final String ACTION_DOWNLOAD_RESULT_INTERNAL = ""android . telephony . mbms . action . DOWNLOAD_RESULT_INTERNAL"" ; public static final String ACTION_FILE_DESCRIPTOR_REQUEST = ""android . telephony . mbms . action . FILE_DESCRIPTOR_REQUEST"" ;
",,,"/* * * The MBMS middleware should send this when a download of single file has completed or * failed . Mandatory extras are * { @link #EXTRA_RESULT } * { @link #EXTRA_INFO } * { @link #EXTRA_REQUEST } * { @link #EXTRA_TEMP_LIST } * { @link #EXTRA_FINAL_URI } * * TODO : future systemapi */ public static final String ACTION_DOWNLOAD_COMPLETE = < |startfocus| > ""android . telephony . mbms . action . DOWNLOAD_COMPLETE"" ; < |endfocus| > /* * * The MBMS middleware should send this when it wishes to request { @code content :/ / } URIs to * serve as temp files for downloads or when it wishes to resume paused downloads . Mandatory * extras are * { @link #EXTRA_REQUEST } * * Optional extras are * { @link #EXTRA_FD_COUNT } ( 0 if not present ) * { @link #EXTRA_PAUSED_LIST } ( empty if not present ) * * TODO : future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST =
",,
564,"private MbmsDownloadManager ( Context context , IMbmsDownloadManagerCallback callback , String downloadAppName , int subId ) { mContext = context ; mCallback = callback ; mDownloadAppName = downloadAppName ; mSubId = subId ;
","private MbmsDownloadManager ( Context context , IMbmsDownloadManagerCallback callback ,
","private MbmsDownloadManager(Context context, IMbmsDownloadManagerListener callback,
",,,"private MbmsDownloadManager(Context context, IMbmsDownloadManagerListener callback,
",,,"private MbmsDownloadManager ( Context context , IMbmsDownloadManagerListener callback , String downloadAppName , int subId ) { mContext = context ; mCallback = callback ; mDownloadAppName = downloadAppName ; mSubId = subId ; }
",,,"private void validateFragmentContributions ( IBuildEntry binIncludes ) { try { Document doc = DocumentBuilderFactory . newInstance ( ) . newDocumentBuilder ( ) . parse ( PDEProject . getPluginXml ( fProject ) . getContents ( ) ) ; XPath xpath = XPathFactory . newInstance ( ) . newXPath ( ) ; NodeList list = ( NodeList ) xpath . evaluate ( "" / plugin / extension [ @point = 'org . eclipse . e4 . workbench . model' ] / fragment / @uri"" , doc , XPathConstants . NODESET ) ; for ( int i = 0 ; i < list . getLength ( ) ; i ++ ) { Node node = list . item ( i ) ; validateBinIncludes ( binIncludes , node . getNodeValue ( ) ) ; } } catch ( Exception e ) { e . printStackTrace ( ) ; } } private void validateApplicationContributions ( IBuildEntry binIncludes ) { try { Document doc = DocumentBuilderFactory . newInstance ( ) . newDocumentBuilder ( ) . parse ( PDEProject . getPluginXml ( fProject ) . getContents ( ) ) ; XPath xpath = XPathFactory . newInstance ( ) . newXPath ( ) ; Node nodeProduct = ( Node ) xpath . evaluate ( "" / plugin / extension [ @point = 'org . eclipse . core . runtime . products' ] / product"" , doc , XPathConstants . NODE ) ; if ( nodeProduct != null ) { Node attValue = ( Node ) xpath . evaluate ( ""property [ @name = 'applicationXMI' ] / @value"" , nodeProduct , XPathConstants . NODE ) ; if ( attValue != null ) { if ( attValue . getNodeValue ( ) . isEmpty ( ) ) { // Error : no URL defined but should already be reported . } else { validateBinIncludes ( binIncludes , attValue . getNodeValue ( ) ) ; } } else { validateBinIncludes ( binIncludes , ""Application . e4xmi"" ) ; } } } catch ( Exception e ) { e . printStackTrace ( ) ; } } private IAtsTeamDefinition getTeamDefinition ( ) { if ( teamDef == null ) { TeamDefinitionDialog ld = new TeamDefinitionDialog ( ""Select Team"" , ""Select Team"" ) ; ld . setInput ( TeamDefinitions . getTeamReleaseableDefinitions ( Active . Active ) ) ; int result = ld . open ( ) ; if ( result == 0 ) { return ( IAtsTeamDefinition ) ld . getResult ( ) [ 0 ] ; } return null ; } else { return teamDef ; } } private MbmsDownloadManager ( Context context , IMbmsDownloadManagerListener callback , String downloadAppName , int subId ) { mContext = context ; mCallback = callback ; mDownloadAppName = downloadAppName ; mSubId =
",,,"< |startfocus| > private MbmsDownloadManager ( Context context , IMbmsDownloadManagerListener callback , < |endfocus| > String downloadAppName , int subId ) { mContext = context ; mCallback = callback ; mDownloadAppName = downloadAppName ; mSubId = subId ;
",,
576,"private static final String CLATD_INTEFACE_PREFIX = ""v4 - "" ; /* * Path to { @code / proc / net / xt_qtaguid / iface_stat_all } . */ private final File mStatsXtIfaceAll ; /* * Path to { @code / proc / net / xt_qtaguid / iface_stat_fmt } . */ private final File mStatsXtIfaceFmt ; /* * Path to { @code / proc / net / xt_qtaguid / stats } . */ private final File mStatsXtUid ; // TODO : to improve testability and avoid global state , do no use a static variable . @GuardedBy ( ""sStackedIfaces"" ) private static final ArrayMap < String , String > sStackedIfaces = new ArrayMap < > ( ) ; public static void noteStackedIface ( String stackedIface , String baseIface ) { synchronized ( sStackedIfaces ) { if ( baseIface != null ) { sStackedIfaces . put ( stackedIface , baseIface ) ; } else { sStackedIfaces . remove ( stackedIface ) ; } } } public NetworkStatsFactory ( ) { this ( new File ( "" / proc / "" ) ) ; } @VisibleForTesting public NetworkStatsFactory ( File procRoot ) {
","// TODO : to improve testability and avoid global state , do no use a static variable .
","// TODO: for testability, do not use a static variable.
",,,"// TODO: for testability, do not use a static variable.
",,,"private static final String CLATD_INTERFACE_PREFIX = ""v4 - "" ; private final File mStatsXtIfaceAll ; private final File mStatsXtIfaceFmt ; private final File mStatsXtUid ; private final ArrayMap < String , String > stackedIfaces = new ArrayMap < > ( ) ; public static void noteStackedIface ( String stackedIface , String baseIface ) { synchronized ( stackedIfaces ) { if ( baseIface != null ) { stackedIfaces . put ( stackedIface , baseIface ) ; } else { stackedIfaces . remove ( stackedIface ) ; } } } public NetworkStatsFactory ( ) { this ( new File ( "" / proc / "" ) ) ; } public NetworkStatsFactory ( File procRoot ) { stackedIfaces = new ArrayMap < > ( ) ; }
",,,"private static final String CLATD_INTEFACE_PREFIX = ""v4 - "" ; private final File mStatsXtIfaceAll ; private final File mStatsXtIfaceFmt ; private final File mStatsXtUid ; // TODO : for testability , do not use a static variable . @GuardedBy ( ""sStackedIfaces"" ) private static final ArrayMap < String , String > sStackedIfaces = new ArrayMap < > ( ) ; public static void noteStackedIface ( String stackedIface , String baseIface ) { synchronized ( sStackedIfaces ) { if ( baseIface != null ) { sStackedIfaces . put ( stackedIface , baseIface ) ; } else { sStackedIfaces . remove ( stackedIface ) ; } } } public NetworkStatsFactory ( ) { this ( new File ( "" / proc / "" ) ) ; } @VisibleForTesting public NetworkStatsFactory ( File procRoot ) {
",,,"private static final String CLATD_INTEFACE_PREFIX = ""v4 - "" ; /* * Path to { @code / proc / net / xt_qtaguid / iface_stat_all } . */ private final File mStatsXtIfaceAll ; /* * Path to { @code / proc / net / xt_qtaguid / iface_stat_fmt } . */ private final File mStatsXtIfaceFmt ; /* * Path to { @code / proc / net / xt_qtaguid / stats } . */ private final File mStatsXtUid ; < |startfocus| > // TODO : for testability , do not use a static variable . < |endfocus| > @GuardedBy ( ""sStackedIfaces"" ) private static final ArrayMap < String , String > sStackedIfaces = new ArrayMap < > ( ) ; public static void noteStackedIface ( String stackedIface , String baseIface ) { synchronized ( sStackedIfaces ) { if ( baseIface != null ) { sStackedIfaces . put ( stackedIface , baseIface ) ; } else { sStackedIfaces . remove ( stackedIface ) ; } } } public NetworkStatsFactory ( ) { this ( new File ( "" / proc / "" ) ) ; } @VisibleForTesting public NetworkStatsFactory ( File procRoot ) {
",,
582,"while ( true ) { c = in . read ( ) ; if ( isTerminator ( c , format ) ) { break ; } // Android - changed : Skip trailing whitespace . if ( c == ' ' || c == '\n' ) { do { if ( c != ' ' && c != '\n' ) { throw new IOException ( ""AVA parse , invalid hex "" + ""digit : "" + ( char ) c ) ; } c = in . read ( ) ; } while ( ! isTerminator ( c , format ) ) ; break ; } // END Android - added : AVA : Support DerValue hex strings that contain ' ' or '\n' int cVal = hexDigits . indexOf ( Character . toUpperCase ( ( char ) c ) ) ; if ( cVal == - 1 ) { throw new IOException ( ""AVA parse , invalid hex "" + ""digit : "" + ( char ) c ) ; } if ( ( cNdx % 2 ) == 1 ) { b = ( byte ) ( ( b * 16 ) + ( byte ) ( cVal ) ) ; baos . write ( b ) ; } else { b = ( byte ) ( cVal ) ; } cNdx ++ ; } // throw exception if no hex digits
","// END Android - added : AVA : Support DerValue hex strings that contain ' ' or '\n'
","// END Android-added: AVA: Support DerValue hex strings that contain ' or '\n' in line 285.
",,,"// END Android-added: AVA: Support DerValue hex strings that contain ' ' or '\n' in line 285.
",,,"while ( true ) { c = in . read ( ) ; if ( isTerminator ( c , format ) ) { break ; } if ( c == ' ' || c == '\n' ) { do { if ( c != ' ' && c != '\n' ) { throw new IOException ( ""AVA parse , invalid hex digit : "" + ( char ) c ) ; } c = in . read ( ) ; } while ( ! isTerminator ( c , format ) ) ; break ; } int cVal = hexDigits . indexOf ( Character . toUpperCase ( ( char ) c ) ) ; if ( cVal == - 1 ) { throw new IOException ( ""AVA parse , invalid hex digit : "" + ( char ) c ) ; } if ( ( cNdx % 2 ) == 1 ) { b = ( byte ) ( ( b * 16 ) + ( byte ) ( cVal ) ) ; baos . write ( b ) ; } else { b = ( byte ) ( cVal ) ; } cNdx ++ ; } if ( cNdx % 2 == 1 ) { throw new IOException ( ""AVA parse , odd number of hex digits"" ) ; }
",,,"while ( true ) { c = in . read ( ) ; if ( isTerminator ( c , format ) ) { break ; } if ( c == ' ' || c == '\n' ) { do { if ( c != ' ' && c != '\n' ) { throw new IOException ( ""AVA parse , invalid hex digit : "" + ( char ) c ) ; } c = in . read ( ) ; } while ( ! isTerminator ( c , format ) ) ; break ; } int cVal = hexDigits . indexOf ( Character . toUpperCase ( ( char ) c ) ) ; if ( cVal == - 1 ) { throw new IOException ( ""AVA parse , invalid hex digit : "" + ( char ) c ) ; } if ( ( cNdx % 2 ) == 1 ) { b = ( byte ) ( ( b * 16 ) + ( byte ) ( cVal ) ) ; baos . write ( b ) ; } else { b = ( byte ) ( cVal ) ; } cNdx ++ ; } // throw exception if no hex digits
",,,"while ( true ) { c = in . read ( ) ; if ( isTerminator ( c , format ) ) { break ; } // Android - changed : Skip trailing whitespace . if ( c == ' ' || c == '\n' ) { do { if ( c != ' ' && c != '\n' ) { throw new IOException ( ""AVA parse , invalid hex "" + ""digit : "" + ( char ) c ) ; } c = in . read ( ) ; } while ( ! isTerminator ( c , format ) ) ; break ; } < |startfocus| > < |endfocus| > int cVal = hexDigits . indexOf ( Character . toUpperCase ( ( char ) c ) ) ; if ( cVal == - 1 ) { throw new IOException ( ""AVA parse , invalid hex "" + ""digit : "" + ( char ) c ) ; } if ( ( cNdx % 2 ) == 1 ) { b = ( byte ) ( ( b * 16 ) + ( byte ) ( cVal ) ) ; baos . write ( b ) ; } else { b = ( byte ) ( cVal ) ; } cNdx ++ ; } // throw exception if no hex digits // END Android - added : AVA : Support DerValue hex strings that contain ' ' or '\n' in line 285 .
",,
587,"SubjectInfoAccessExtension . class ) ; addInternal ( AUTH_INFO_ACCESS , PKIXExtensions . AuthInfoAccess_Id , AuthorityInfoAccessExtension . class ) ; addInternal ( ISSUING_DIST_POINT , PKIXExtensions . IssuingDistributionPoint_Id , IssuingDistributionPointExtension . class ) ; addInternal ( DELTA_CRL_INDICATOR , PKIXExtensions . DeltaCRLIndicator_Id , DeltaCRLIndicatorExtension . class ) ; addInternal ( FRESHEST_CRL , PKIXExtensions . FreshestCRL_Id , FreshestCRLExtension . class ) ; addInternal ( OCSPNOCHECK , PKIXExtensions . OCSPNoCheck_Id , OCSPNoCheckExtension . class ) ; } /* * * Add attributes to the table . For internal use in the static * initializer . */ private static void addInternal ( String name , ObjectIdentifier oid , Class clazz ) { OIDInfo info = new OIDInfo ( name , oid , clazz ) ; oidMap . put ( oid , info ) ; nameMap . put ( name , info ) ; } /* * * Inner class encapsulating the mapping info and Class loading . */ private static class OIDInfo { final ObjectIdentifier oid ; final String name ; private volatile Class < ? > clazz ; OIDInfo ( String name , ObjectIdentifier oid , Class < ? > clazz ) {
","< |del| >/ / END Android - changed : Hardcode class names in OIDMap to fix proguard issues
","// END Android-changed: hardcode class names in OIDMap to fix proguard issues
",,,"// END Android-changed: Hardcode class names in OIDMap to fix proguard issues
",,,"// Hardcode class names in OIDMap to fix proguard issues oidMap . put ( PKIXExtensions . BasicConstraints_Id , new OIDInfo ( BASIC_CONSTRAINTS , PKIXExtensions . BasicConstraints_Id , BasicConstraintsExtension . class ) ) ; oidMap . put ( PKIXExtensions . KeyUsage_Id , new OIDInfo ( KEY_USAGE , PKIXExtensions . KeyUsage_Id , KeyUsageExtension . class ) ) ; oidMap . put ( PKIXExtensions . ExtendedKeyUsage_Id , new OIDInfo ( EXTENDED_KEY_USAGE , PKIXExtensions . ExtendedKeyUsage_Id , ExtendedKeyUsageExtension . class ) ) ; oidMap . put ( PKIXExtensions . SubjectAlternativeName_Id , new OIDInfo ( SUBJECT_ALT_NAME , PKIXExtensions . SubjectAlternativeName_Id , SubjectAlternativeNameExtension . class ) ) ; oidMap . put ( PKIXExtensions . IssuerAlternativeName_Id , new OIDInfo ( ISSUER_ALT_NAME , PKIXExtensions . IssuerAlternativeName_Id , IssuerAlternativeNameExtension . class ) ) ; oidMap . put ( PKIXExtensions . SubjectInfoAccess_Id , new OIDInfo ( SUBJECT_INFO_ACCESS , PKIXExtensions . SubjectInfoAccess_Id , SubjectInfoAccessExtension . class ) ) ; oidMap . put ( PKIXExtensions . AuthInfoAccess_Id , new OIDInfo ( AUTH_INFO_ACCESS , PKIXExtensions . AuthInfoAccess_Id , AuthorityInfoAccessExtension . class ) ) ; oidMap . put ( PKIXExtensions . IssuingDistributionPoint_Id , new OIDInfo ( ISSUING_DIST_POINT , PKIXExtensions . IssuingDistributionPoint_Id , IssuingDistributionPointExtension . class ) ) ; oidMap . put ( PKIXExtensions . DeltaCRLIndicator_Id , new OIDInfo ( DELTA_CRL_INDICATOR , PKIXExtensions . DeltaCRLIndicator_Id , DeltaCRLIndicatorExtension . class ) ) ; oidMap . put ( PKIXExtensions . FreshestCRL_Id , new OIDInfo ( FRESHEST_CRL , PKIXExtensions . FreshestCRL_Id , FreshestCRLExtension . class ) ) ; oidMap . put ( PKIXExtensions . OCSPNoCheck_Id , new OIDInfo ( OCSPNOCHECK , PKIXExtensions . OCSPNoCheck_Id , OCSPNoCheckExtension . class ) ) ; /* * * Add attributes to the table . For internal use in the static initializer . */ private static void addInternal ( String name , ObjectIdentifier oid , Class < ? > clazz ) { OIDInfo info = new OIDInfo ( name , oid , clazz ) ; oidMap . put ( oid , info ) ; nameMap . put ( name , info ) ; } /* * * Inner class encapsulating the mapping info and Class loading
",,,"// limitations under the License . package net . codemirror . lib ; import com . google . gwt . core . client . JavaScriptObject ; /* * * { line , ch } objects used within CodeMirror . */ public class LineCharacter extends JavaScriptObject { public static LineCharacter create ( int line , int ch ) { LineCharacter lineCh = createObject ( ) . cast ( ) ; return lineCh . setLine ( line ) . setCh ( ch ) ; } private final native LineCharacter setLine ( int line ) /* - { this . line = line ; return this ; } -* / ; public final native LineCharacter setCh ( int ch ) /* - { this [ 'ch' ] = ch ; return this ; } -* / ; public final native int getLine ( ) /* - { return this . line ; } -* / ; public final native int getCh ( ) /* - { return this . ch ; } -* / ; protected LineCharacter ( ) { } } private static boolean isWrapped ( final SWTBot bot ) { return bot . label ( 1 ) . getText ( ) . equals ( ""Wrapped search"" ) ; } // limitations under the License . package net . codemirror . lib ; import com . google . gwt . core . client . JavaScriptObject ; /* * * { line , ch } objects used within CodeMirror . */ public class LineCharacter extends JavaScriptObject { public static LineCharacter create ( int line , int ch ) { LineCharacter lineCh = createObject ( ) . cast ( ) ; return lineCh . setLine ( line ) . setCh ( ch ) ; } private final native LineCharacter setLine ( int line ) /* - { this . line = line ; return this ; } -* / ; public final native LineCharacter setCh ( int ch ) /* - { this [ 'ch' ] = ch ; return this ; } -* / ; public final native int getLine ( ) /* - { return this . line ; } -* / ; public final native int getCh ( ) /* - { return this . ch ; } -* / ; protected LineCharacter ( ) { } } private static boolean isWrapped ( final SWTBot bot ) { return bot . label ( 1 ) . getText ( ) . equals ( ""Wrapped search"" ) ; } // limitations under the License . package org . eclipse . tracecompass . internal . analysis . os . linux . core . latency ; import org . eclipse . jdt . annotation . NonNull ; import org . eclipse . tracecompass . datastore . core . interval . IHTIntervalReader ; import org . eclipse . tracecompass . datastore . core . serialization . ISafeByteBufferWriter ; import org . eclipse . trace
",,,"SubjectInfoAccessExtension . class ) ; addInternal ( AUTH_INFO_ACCESS , PKIXExtensions . AuthInfoAccess_Id , AuthorityInfoAccessExtension . class ) ; addInternal ( ISSUING_DIST_POINT , PKIXExtensions . IssuingDistributionPoint_Id , IssuingDistributionPointExtension . class ) ; addInternal ( DELTA_CRL_INDICATOR , PKIXExtensions . DeltaCRLIndicator_Id , DeltaCRLIndicatorExtension . class ) ; addInternal ( FRESHEST_CRL , PKIXExtensions . FreshestCRL_Id , FreshestCRLExtension . class ) ; addInternal ( OCSPNOCHECK , PKIXExtensions . OCSPNoCheck_Id , OCSPNoCheckExtension . class ) ; } < |startfocus| > // END Android - changed : Hardcode class names in OIDMap to fix proguard issues < |endfocus| > /* * * Add attributes to the table . For internal use in the static * initializer . */ private static void addInternal ( String name , ObjectIdentifier oid , Class clazz ) { OIDInfo info = new OIDInfo ( name , oid , clazz ) ; oidMap . put ( oid , info ) ; nameMap . put ( name , info ) ; } /* * * Inner class encapsulating the mapping info and Class loading . */ private static class OIDInfo { final ObjectIdentifier oid ; final String name ; private volatile Class < ? > clazz ; OIDInfo ( String name , ObjectIdentifier oid , Class < ? > clazz ) { this . oid = oid ; this . name = name ; this . clazz = clazz ; } Class < ? > getClazz ( ) { if ( clazz == null ) { synchronized ( this ) { if ( clazz == null ) { try { clazz = Class . forName ( clazz . getName ( ) ) ; } catch ( ClassNotFoundException e ) { // ignore } } } } return clazz ; } } }
",,
593,"*/ public static native String getOsVersion ( ) ; /* * * @return hardware id extracted from uname ( ) native call */ public static native String getHardwareId ( ) ; /* * * @return kernel version extracted from uname ( ) native call */ public static native String getKernelVersion ( ) ; /* * * @return sysprop ro . boot . avb_version */ public static native String getBootAvbVersion ( ) ; /* * * @return libavb version in bootloader . Format is { @code x . y } . */ public static native String getBootVbmetaAvbVersion ( ) ; }
","* @return libavb version in bootloader . Format is { @code x . y } .
","* @return sysprop ro.boot. vbmeta.avb_version * @return sysprop ro.boot. vbmeta.avb_version
",,,"* @return sysprop ro.boot.vbmeta.avb_version
",,,"public class NativeUtils { public static native String getOsVersion ( ) ; public static native String getHardwareId ( ) ; public static native String getKernelVersion ( ) ; public static native String getBootAvbVersion ( ) ; /* * * @return boot vbmeta avb version in the format X . Y or X . Y . Z */ public static native String getBootVbmetaAvbVersion ( ) ; }
",,,"*/ public static native String getOsVersion ( ) ; /* * * @return hardware id extracted from uname ( ) native call */ public static native String getHardwareId ( ) ; /* * * @return kernel version extracted from uname ( ) native call */ public static native String getKernelVersion ( ) ; /* * * @return sysprop ro . boot . avb_version */ public static native String getBootAvbVersion ( ) ; /* * * @return sysprop ro . boot . vbmeta . avb_version */ public static native String getBootVbmetaAvbVersion ( ) ;
",,,"*/ public static native String getOsVersion ( ) ; /* * * @return hardware id extracted from uname ( ) native call */ public static native String getHardwareId ( ) ; /* * * @return kernel version extracted from uname ( ) native call */ public static native String getKernelVersion ( ) ; /* * * @return sysprop ro . boot . avb_version */ public static native String getBootAvbVersion ( ) ; /* * < |startfocus| > * @return sysprop ro . boot . vbmeta . avb_version < |endfocus| > */ public static native String getBootVbmetaAvbVersion ( ) ; }
",,
607,"return RSUtils . getProperSubclasses ( UnitTest . class ) ; } @Parameter ( 0 ) public Class < ? extends UnitTest > mTestClass ; @Test @MediumTest public void testRSUnitTest ( ) throws Exception { Context ctx = InstrumentationRegistry . getTargetContext ( ) ; UnitTest test = mTestClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; test . runTest ( ) ; switch ( test . getResult ( ) ) { case UT_NOT_STARTED : case UT_RUNNING : Log . w ( TAG , ""unexpected unit test result : "" + test . getResult ( ) . toString ( ) ) ; break ; } Assert . assertTrue ( mTest . getSuccess ( ) ) ; } }
","Assert . assertTrue ( mTest . getSuccess ( ) ) ;
","Assert.assertTrue(test.getSuccess());
",,,"Assert.assertTrue(test.getSuccess()); Assert.assertTrue(test.getFailed());
",,,"return RSUtils . getProperSubclasses ( UnitTest . class ) ; } @Parameter ( 0 ) public Class < ? extends UnitTest > mTestClass ; @Test @MediumTest public void testRSUnitTest ( ) throws Exception { Context ctx = InstrumentationRegistry . getTargetContext ( ) ; UnitTest test = mTestClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; test . runTest ( ) ; switch ( test . getResult ( ) ) { case UT_NOT_STARTED : case UT_RUNNING : Log . w ( TAG , ""unexpected unit test result : "" + test . getResult ( ) . toString ( ) ) ; break ; } Assert . assertTrue ( test . getSuccess ( ) ) ; }
",,,"return RSUtils . getProperSubclasses ( UnitTest . class ) ; @Parameter ( 0 ) public Class < ? extends UnitTest > mTestClass ; @Test @MediumTest public void testRSUnitTest ( ) throws Exception { Context ctx = InstrumentationRegistry . getTargetContext ( ) ; UnitTest test = mTestClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; test . runTest ( ) ; switch ( test . getResult ( ) ) { case UT_NOT_STARTED : case UT_RUNNING : Log . w ( TAG , ""unexpected unit test result : "" + test . getResult ( ) . toString ( ) ) ; break ; } Assert . assertTrue ( test . getSuccess ( ) ) ; }
",,,"return RSUtils . getProperSubclasses ( UnitTest . class ) ; } @Parameter ( 0 ) public Class < ? extends UnitTest > mTestClass ; @Test @MediumTest public void testRSUnitTest ( ) throws Exception { Context ctx = InstrumentationRegistry . getTargetContext ( ) ; UnitTest test = mTestClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; test . runTest ( ) ; switch ( test . getResult ( ) ) { case UT_NOT_STARTED : case UT_RUNNING : Log . w ( TAG , ""unexpected unit test result : "" + test . getResult ( ) . toString ( ) ) ; break ; } < |startfocus| > Assert . assertTrue ( test . getSuccess ( ) ) ; < |endfocus| > } }
",,
629,"private static final int MESSAGE_BLUETOOTH_STATE_CHANGE = 60 ; private static final int MESSAGE_TIMEOUT_BIND = 100 ; private static final int MESSAGE_TIMEOUT_UNBIND = 101 ; private static final int MESSAGE_GET_NAME_AND_ADDRESS = 200 ; private static final int MESSAGE_USER_SWITCHED = 300 ; private static final int MESSAGE_USER_UNLOCKED = 301 ; private static final int MESSAGE_ADD_PROXY_DELAYED = 400 ; private static final int MESSAGE_BIND_PROFILE_SERVICE = 401 ; private static final int MESSAGE_RESTORE_USER_SETTING = 500 ; private static final int RESTORE_SETTING_TO_ON = 1 ; private static final int RESTORE_SETTING_TO_OFF = 0 ; private static final int MAX_SAVE_RETRIES = 3 ; private static final int MAX_ERROR_RESTART_RETRIES = 6 ; // Bluetooth persisted setting is off private static final int BLUETOOTH_OFF = 0 ; // Bluetooth persisted setting is on // and Airplane mode won't affect Bluetooth state at start up private static final int BLUETOOTH_ON_BLUETOOTH = 1 ; // Bluetooth persisted setting is on
","private static final int MESSAGE_RESTORE_USER_SETTING = 500 ;
","private static final int MESSAGE_RESTORE_USER_SETTING = 500;
",,,"private static final int MESSAGE_RESTORE_USER_SETTING = 500;
",,,"private static final int MESSAGE_BLUETOOTH_STATE_CHANGE = 60 ; private static final int MESSAGE_TIMEOUT_BIND = 100 ; private static final int MESSAGE_TIMEOUT_UNBIND = 101 ; private static final int MESSAGE_GET_NAME_AND_ADDRESS = 200 ; private static final int MESSAGE_USER_SWITCHED = 300 ; private static final int MESSAGE_USER_UNLOCKED = 301 ; private static final int MESSAGE_ADD_PROXY_DELAYED = 400 ; private static final int MESSAGE_BIND_PROFILE_SERVICE = 401 ; private static final int MESSAGE_RESTORE_USER_SETTING = 500 ; private static final int RESTORE_SETTING_TO_ON = 1 ; private static final int RESTORE_SETTING_TO_OFF = 0 ; private static final int MAX_SAVE_RETRIES = 3 ; private static final int MAX_ERROR_RESTART_RETRIES = 6 ; private static final int BLUETOOTH_OFF = 0 ; private static final int BLUETOOTH_ON_BLUETOOTH = 1 ;
",,,"private static final int MESSAGE_BLUETOOTH_STATE_CHANGE = 60 ; private static final int MESSAGE_TIMEOUT_BIND = 100 ; private static final int MESSAGE_TIMEOUT_UNBIND = 101 ; private static final int MESSAGE_GET_NAME_AND_ADDRESS = 200 ; private static final int MESSAGE_USER_SWITCHED = 300 ; private static final int MESSAGE_USER_UNLOCKED = 301 ; private static final int MESSAGE_ADD_PROXY_DELAYED = 400 ; private static final int MESSAGE_BIND_PROFILE_SERVICE = 401 ; private static final int MESSAGE_RESTORE_ON_SETTING = 500 ; private static final int RESTORE_SETTING_TO_ON = 1 ; private static final int RESTORE_SETTING_TO_OFF = 0 ; private static final int MAX_SAVE_RETRIES = 3 ; private static final int MAX_ERROR_RESTART_RETRIES = 6 ; private static final int BLUETOOTH_OFF = 0 ; private static final int BLUETOOTH_ON_BLUETOOTH = 1 ; // Bluetooth persisted setting is off private static final int RESTORE_USER_SETTING = 500 ; // Bluetooth persisted setting is on // and Airplane mode won't affect Bluetooth state at start up private static final int BLUETOOTH_ON_AIRPLANE_MODE = 1 ;
",,,"private static final int MESSAGE_BLUETOOTH_STATE_CHANGE = 60 ; private static final int MESSAGE_TIMEOUT_BIND = 100 ; private static final int MESSAGE_TIMEOUT_UNBIND = 101 ; private static final int MESSAGE_GET_NAME_AND_ADDRESS = 200 ; private static final int MESSAGE_USER_SWITCHED = 300 ; private static final int MESSAGE_USER_UNLOCKED = 301 ; private static final int MESSAGE_ADD_PROXY_DELAYED = 400 ; private static final int MESSAGE_BIND_PROFILE_SERVICE = 401 ; < |startfocus| > private static final int MESSAGE_RESTORE_USER_SETTING = 500 ; < |endfocus| > private static final int RESTORE_SETTING_TO_ON = 1 ; private static final int RESTORE_SETTING_TO_OFF = 0 ; private static final int MAX_SAVE_RETRIES = 3 ; private static final int MAX_ERROR_RESTART_RETRIES = 6 ; // Bluetooth persisted setting is off private static final int BLUETOOTH_OFF = 0 ; // Bluetooth persisted setting is on // and Airplane mode won't affect Bluetooth state at start up private static final int BLUETOOTH_ON_BLUETOOTH = 1 ; // Bluetooth persisted setting is on
",,
634,"/* * * Initialize streaming service for this app and subId , registering the listener . * * @param listener The callback to use to communicate with the app . * @param appName The package name of the calling app . * @param subscriptionId The subscription ID to use . * @return { @link MbmsException#ERROR_ALREADY_INITIALIZED } or { @link MbmsException#SUCCESS } . */ @Override public int initialize ( IMbmsStreamingManagerCallback listener , String appName , int subscriptionId ) throws RemoteException { return 0 ; } /* * * Registers serviceClasses of interest with the appName / subId key . * Starts async fetching data on streaming services of matching classes to be reported * later via { @link IMbmsStreamingManagerCallback#streamingServicesUpdated ( List ) } * * Note that subsequent calls with the same appName and subId will replace * the service class list . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS
","int subscriptionId ) throws RemoteException {
","int subscriptions) throws RemoteException {
",,,"int subscriptionId) throws RemoteException {
",,,"I'm sorry , but I cannot provide a solution without comments or a clear indication of what needs to be changed . Please provide more specific instructions or comments for me to work with .
",,,"@Override public int initialize ( IMbmsStreamingManagerCallback listener , String appName , int subscriptionId ) throws RemoteException { return 0 ; } @Override public void registerStreamingServices ( String appName , int subscriptionId , List < ServiceClass > serviceClasses ) throws RemoteException { // Register serviceClasses of interest with the appName / subId key // Starts async fetching data on streaming services of matching classes to be reported // later via IMbmsStreamingManagerCallback . streamingServicesUpdated ( List ) // Note that subsequent calls with the same appName and subId will replace // the service class list . }
",,,"/* * * Initialize streaming service for this app and subId , registering the listener . * * @param listener The callback to use to communicate with the app . * @param appName The package name of the calling app . * @param subscriptionId The subscription ID to use . * @return { @link MbmsException#ERROR_ALREADY_INITIALIZED } or { @link MbmsException#SUCCESS } . */ @Override public int initialize ( IMbmsStreamingManagerCallback listener , String appName , < |startfocus| > int subscriptionId ) throws RemoteException { < |endfocus| > return 0 ; } /* * * Registers serviceClasses of interest with the appName / subId key . * Starts async fetching data on streaming services of matching classes to be reported * later via { @link IMbmsStreamingManagerCallback#streamingServicesUpdated ( List ) } * * Note that subsequent calls with the same appName and subId will replace * the service class list . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param serviceClasses The service classes of interest . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_ALREADY_INITIALIZED } * if the app is already initialized , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int initialize ( IMbmsStreamingManagerCallback listener , String appName , int subscriptionId , List < String > serviceClasses ) throws RemoteException { return 0 ; } /* * * Asynchronously fetches the list of streaming services available to the app . * The results will be returned via { @link IMbmsStreamingManagerCallback#streamingServicesUpdated ( List ) } * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int getStreamingServices ( String appName , int subscriptionId ) throws RemoteException { return 0 ; } /* * * Asynchronously fetches the list of streaming services available to the app . * The results will be returned via { @link IMbmsStreamingManagerCallback#streamingServicesUpdated ( List ) } * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param serviceClasses The service classes of interest . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int getStreamingServices ( String appName , int subscriptionId , List < String > serviceClasses ) throws RemoteException { return 0 ; } /* * * Starts streaming the service identified by the serviceId . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param serviceId The service id of the service to start streaming . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#ERROR_UNABLE_TO_START_SERVICE } * if the service could not be started , { @link MbmsException#SUCCESS } otherwise . */ @Override public int startStreaming ( String appName , int subscriptionId , String serviceId ) throws RemoteException { return 0 ; } /* * * Stops streaming the service identified by the serviceId . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param serviceId The service id of the service to stop streaming . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#ERROR_UNABLE_TO_STOP_SERVICE } * if the service could not be stopped , { @link MbmsException#SUCCESS } otherwise . */ @Override public int stopStreaming ( String appName , int subscriptionId , String serviceId ) throws RemoteException { return 0 ; } /* * * Resets the streaming manager . * * This will cause the middleware to forget about all state associated with the appName / subId * pair . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int dispose ( String appName , int subscriptionId ) throws RemoteException { return 0 ; } /* * * Sets the temp file root directory for the appName / subId pair . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param fileRoot The root directory to use . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int setTempFileRootDirectory ( String appName , int subscriptionId , File fileRoot ) throws RemoteException { return 0 ; } /* * * Sets the temp file root directory for the appName / subId pair . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param fileRoot The root directory to use . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int setTempFileRootDirectory ( String appName , int subscriptionId , String fileRoot ) throws RemoteException { return 0 ; } /* * * Sets the temp file root directory for the appName / subId pair . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param fileRoot The root directory to use . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int setTempFileRootDirectory (
",,
638,"// // / CHECK - START : int Main . getSum21 ( ) instruction_simplifier$after_bce ( after ) // / CHECK - DAG : < < Int : i\d + > > IntConstant 21 loop : none // / CHECK - DAG : Return [ < < Int > > ] loop : none private static int getSum21 ( ) { int k = 0 ; int sum = 0 ; for ( int i = 0 ; i < 6 ; i ++ ) { k ++ ; sum += k ; } return sum ; } // Ensure double induction does not ""overshoot"" the subscript range . private static int getIncr2 ( int [ ] arr ) { for ( int i = 0 ; i < 12 ; ) { arr [ i ++ ] = 30 ; arr [ i ++ ] = 29 ; } int sum = 0 ; for ( int i = 0 ; i < 12 ; i ++ ) { sum += arr [ i ] ; } return sum ; } // TODO : handle as closed / empty eventually ? static int mainIndexReturnedN ( int n ) { int i ; for ( i = 0 ; i < n ; i ++ ) ; return i ; }
","// Ensure double induction does not ""overshoot"" the subscript range .
","// Ensure double induction does not ""overshoot"". // CHECK-START: int Main.get sum21() instruction_simplifier$after_bce (after) /// CHECK-DAG: <<Int:i\d+>> IntConstant 21 loop:none /// CHECK-DAG: Return [<<Int>>] loop:none
",,,"// Ensure double induction does not ""overshoot"". This is done in a separate pass through the code path.
",,,"private static int getSum21 ( ) { int k = 0 ; int sum = 0 ; for ( int i = 0 ; i < 6 ; i ++ ) { k ++ ; sum += k ; } return sum ; } private static int getIncr2 ( int [ ] arr ) { for ( int i = 0 ; i < 12 ; ) { arr [ i ++ ] = 30 ; arr [ i ++ ] = 29 ; } int sum = 0 ; for ( int i = 0 ; i < 12 ; i ++ ) { sum += arr [ i ] ; } return sum ; } static int mainIndexReturnedN ( int n ) { int i ; for ( i = 0 ; i < n ; i ++ ) ; return i ; }
",,,"// Buggy Code private static int getSum21 ( ) { int k = 0 ; int sum = 0 ; for ( int i = 0 ; i < 6 ; i ++ ) { k ++ ; sum += k ; } return sum ; } // Review : Ensure double induction does not ""overshoot"" . private static int getIncr2 ( int [ ] arr ) { for ( int i = 0 ; i < 12 ; ) { arr [ i ++ ] = 30 ; arr [ i ++ ] = 29 ; } int sum = 0 ; for ( int i = 0 ; i < 12 ; i ++ ) { sum += arr [ i ] ; } return sum ; } // TODO : handle as closed / empty eventually ? static int mainIndexReturnedN ( int n ) { int i ; for ( i = 0 ; i < n ; i ++ ) ; return i ; }
",,,"// // / CHECK - START : int Main . getSum21 ( ) instruction_simplifier$after_bce ( after ) // / CHECK - DAG : < < Int : i\d + > > IntConstant 21 loop : none // / CHECK - DAG : Return [ < < Int > > ] loop : none private static int getSum21 ( ) { int k = 0 ; int sum = 0 ; for ( int i = 0 ; i < 6 ; i ++ ) { k ++ ; sum += k ; } return sum ; } < |startfocus| > // Ensure double induction does not ""overshoot"" . < |endfocus| > private static int getIncr2 ( int [ ] arr ) { for ( int i = 0 ; i < 12 ; ) { arr [ i ++ ] = 30 ; arr [ i ++ ] = 29 ; } int sum = 0 ; for ( int i = 0 ; i < 12 ; i ++ ) { sum += arr [ i ] ; } return sum ; } // TODO : handle as closed / empty eventually ? static int mainIndexReturnedN ( int n ) { int i ; for ( i = 0 ; i < n ; i ++ ) ; return i ; }
",,
668,"* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . telephony ; import android . content . ComponentName ; import android . content . Context ; import android . content . Intent ; import android . content . ServiceConnection ; import android . content . pm . PackageManager ; import android . content . pm . ResolveInfo ; import android . os . DeadObjectException ; import android . os . IBinder ; import android . os . RemoteException ; import android . telephony . mbms . MbmsException ; import android . telephony . mbms . StreamingService ; import android . telephony . mbms . StreamingServiceInfo ; import android . telephony . mbms . vendor . IMbmsStreamingService ; import android . util . Log ; import java . util . LinkedList ; import java . util . List ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . TimeUnit ; import static android . telephony . SubscriptionManager . INVALID_SUBSCRIPTION_ID ; /* * @hide */ public class MbmsStreamingManager { private interface ServiceListener { void onServiceConnected ( ) ; void onServiceDisconnected ( ) ; } private static final String LOG_TAG = ""MbmsStreamingManager"" ;
","< |del| > import android . telephony . mbms . IMbmsStreamingManagerCallback ; import android . telephony . mbms . IStreamingServiceCallback ;
","<|del|>
",,,"<|del|>
",,,"package android . telephony ; import android . content . ComponentName ; import android . content . Context ; import android . content . Intent ; import android . content . ServiceConnection ; import android . content . pm . PackageManager ; import android . content . pm . ResolveInfo ; import android . os . DeadObjectException ; import android . os . IBinder ; import android . os . RemoteException ; import android . telephony . mbms . IMbmsStreamingManagerCallback ; import android . telephony . mbms . IStreamingServiceCallback ; import android . telephony . mbms . MbmsException ; import android . telephony . mbms . StreamingService ; import android . telephony . mbms . StreamingServiceInfo ; import android . telephony . mbms . vendor . IMbmsStreamingService ; import android . util . Log ; import java . util . LinkedList ; import java . util . List ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . TimeUnit ; import static android . telephony . SubscriptionManager . INVALID_SUBSCRIPTION_ID ; public class MbmsStreamingManager { private interface ServiceListener { void onServiceConnected ( ) ; void onServiceDisconnected ( ) ; } private static final String LOG_TAG = ""MbmsStreamingManager"" ; }
",,,"package android . telephony ; import android . content . ComponentName ; import android . content . Context ; import android . content . Intent ; import android . content . ServiceConnection ; import android . content . pm . PackageManager ; import android . content . pm . ResolveInfo ; import android . os . DeadObjectException ; import android . os . IBinder ; import android . os . RemoteException ; import android . telephony . mbms . IMbmsStreamingManagerCallback ; import android . telephony . mbms . IStreamingServiceCallback ; import android . telephony . mbms . MbmsException ; import android . telephony . mbms . StreamingService ; import android . telephony . mbms . StreamingServiceInfo ; import android . telephony . mbms . vendor . IMbmsStreamingService ; import android . util . Log ; import java . util . LinkedList ; import java . util . List ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . TimeUnit ; import static android . telephony . SubscriptionManager . INVALID_SUBSCRIPTION_ID ; /* * @hide */ public class MbmsStreamingManager { private interface ServiceListener { void onServiceConnected ( ) ; void onServiceDisconnected ( ) ; } private static final String LOG_TAG = ""MbmsStreamingManager"" ; }
",,,"* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . telephony ; import android . content . ComponentName ; import android . content . Context ; import android . content . Intent ; import android . content . ServiceConnection ; import android . content . pm . PackageManager ; import android . content . pm . ResolveInfo ; import android . os . DeadObjectException ; import android . os . IBinder ; import android . os . RemoteException ; import android . telephony . mbms . IMbmsStreamingManagerCallback ; import android . telephony . mbms . IStreamingServiceCallback ; import android . telephony . mbms . MbmsException ; import android . telephony . mbms . StreamingService ; import android . telephony . mbms . StreamingServiceInfo ; import android . telephony . mbms . vendor . IMbmsStreamingService ; import android . util . Log ; import java . util . LinkedList ; import java . util . List ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . TimeUnit ; import static android . telephony . SubscriptionManager . INVALID_SUBSCRIPTION_ID ; /* * @hide */ public class MbmsStreamingManager { private interface ServiceListener { void onServiceConnected ( ) ; void onServiceDisconnected ( ) ; } private static final String LOG_TAG = ""MbmsStreamingManager"" ;
",,
673,"private void recordAndEmit ( Category category , String msg ) { final String entry = logLine ( category , msg ) ; mLocalLog . log ( entry ) ; if ( ERROR . equals ( category ) ) { Log . e ( mTag , entry ) ; } else { Log . d ( mTag , entry ) ; }
","private void recordAndEmit ( Category category , String msg ) {
","private void recordAndEmit(String category, String msg) {
",,,"private void recordAndEmit(Category category, String msg) {
",,,"private enum Category { ERROR , DEBUG } private void recordAndEmit ( Category category , String msg ) { final String entry = logLine ( category . toString ( ) , msg ) ; mLocalLog . log ( entry ) ; if ( Category . ERROR . equals ( category ) ) { Log . e ( mTag , entry ) ; } else { Log . d ( mTag , entry ) ; } }
",,,"private void recordAndEmit ( Category category , String msg ) { final String entry = logLine ( category . toString ( ) , msg ) ; mLocalLog . log ( entry ) ; if ( Category . ERROR . equals ( category ) ) { Log . e ( mTag , entry ) ; } else { Log . d ( mTag , entry ) ; } }
",,,"< |startfocus| > private void recordAndEmit ( Category category , String msg ) { < |endfocus| > final String entry = logLine ( category , msg ) ; mLocalLog . log ( entry ) ; if ( ERROR . equals ( category ) ) { Log . e ( mTag , entry ) ; } else { Log . d ( mTag , entry ) ; }
",,
677,"* releases and / or devices . * * @hide */ public static native String getDexFileStatus ( String fileName , String instructionSet ) throws FileNotFoundException ; /* * * Returns the full file path of the optimized dex file { @code fileName } . The returned string * is the full file name including path of optimized dex file , if it exists . * @hide */ public static native String [ ] getDexFileOutputPaths ( String fileName , String instructionSet ) throws FileNotFoundException ; /* * * Returns whether the given filter is a valid filter . * * @hide */ public native static boolean isValidCompilerFilter ( String filter ) ; /* * * Returns whether the given filter is based on profiles . * * @hide */ public native static boolean isProfileGuidedCompilerFilter ( String filter ) ; /* * * Returns the version of the compiler filter that is not based on profiles . * If the input is not a valid filter , or the filter is already not based on
","public static native String [ ] getDexFileOutputPaths ( String fileName , String instructionSet )
","public static native String[] getDexFileOutputPaths(String fileName, String instructionSet)
",,,"public static native String[] getDexFileOutputPaths(String fileName, String instructionSet)
",,,"public static native String getDexFileStatus ( String fileName , String instructionSet ) throws FileNotFoundException ; /* * * Returns the full file path of the optimized dex file { @code fileName } . The returned string * is the full file name including path of optimized dex file , if it exists . * @hide */ public static native String [ ] getDexFileOutputPaths ( String fileName , String instructionSet ) throws FileNotFoundException ; /* * * Returns whether the given filter is a valid filter . * @hide */ public native static boolean isValidCompilerFilter ( String filter ) ; /* * * Returns whether the given filter is based on profiles . * @hide */ public native static boolean isProfileGuidedCompilerFilter ( String filter ) ; /* * * Returns the version of the compiler filter that is not based on profiles . * If the input is not a valid filter , or the filter is already not based on profiles , returns null . * @hide */ public native static String getNonProfileGuidedCompilerFilter ( String filter ) ;
",,,"/* * * Returns the full file path of the optimized dex file { @code fileName } . * The returned string is the full file name including path of optimized dex file , if it exists . * * @param fileName The name of the dex file . * @param instructionSet The instruction set of the device . * @return The full file path of the optimized dex file . * @throws FileNotFoundException If the optimized dex file is not found . */ public static native String [ ] getDexFileOutputPaths ( String fileName , String instructionSet ) throws FileNotFoundException ; /* * * Returns whether the given filter is a valid filter . * * @param filter The filter to check . * @return True if the filter is valid , false otherwise . */ public native static boolean isValidCompilerFilter ( String filter ) ; /* * * Returns whether the given filter is based on profiles . * * @param filter The filter to check . * @return True if the filter is based on profiles , false otherwise . */ public native static boolean isProfileGuidedCompilerFilter ( String filter ) ; /* * * Returns the version of the compiler filter that is not based on profiles . * If the input is not a valid filter , or the filter is already not based on profiles , * the input filter is returned . * * @param filter The filter to convert . * @return The version of the compiler filter that is not based on profiles . */ public native static String getNonProfileGuidedCompilerFilter ( String filter ) ;
",,,"* releases and / or devices . * * @hide */ public static native String getDexFileStatus ( String fileName , String instructionSet ) throws FileNotFoundException ; /* * * Returns the full file path of the optimized dex file { @code fileName } . The returned string * is the full file name including path of optimized dex file , if it exists . * @hide */ < |startfocus| > public static native String [ ] getDexFileOutputPaths ( String fileName , String instructionSet ) < |endfocus| > throws FileNotFoundException ; /* * * Returns whether the given filter is a valid filter . * * @hide */ public native static boolean isValidCompilerFilter ( String filter ) ; /* * * Returns whether the given filter is based on profiles . * * @hide */ public native static boolean isProfileGuidedCompilerFilter ( String filter ) ; /* * * Returns the version of the compiler filter that is not based on profiles . * If the input is not a valid filter , or the filter is already not based on
",,
682,"public IPv6TetheringCoordinator ( ArrayList < TetherInterfaceStateMachine > notifyList ) { mNotifyList = notifyList ; mActiveDownstreams = new LinkedList < > ( ) ; mUniqueLocalPrefix = generateUniqueLocalPrefix ( ) ; mNextSubnetId = 0 ;
","public IPv6TetheringCoordinator ( ArrayList < TetherInterfaceStateMachine > notifyList ) {
","public IPv6TetheringCoordinator( SharedLog log, ArrayList<TetherInterfaceStateMachine> notifyList) { mLog = log.forSubComponent(TAG);
",,,"public IPv6TetheringCoordinator(ArrayList<TetherInterfaceStateMachine> notifyList) { mLog = log.forSubComponent(TAG);
",,,"public IPv6TetheringCoordinator ( ArrayList < TetherInterfaceStateMachine > notifyList , SharedLog log ) { mNotifyList = notifyList ; mActiveDownstreams = new LinkedList < > ( ) ; mUniqueLocalPrefix = generateUniqueLocalPrefix ( ) ; mNextSubnetId = 0 ; mLog = log . forSubComponent ( TAG ) ; }
",,,"public IPv6TetheringCoordinator ( ArrayList < TetherInterfaceStateMachine > notifyList , SharedLog log ) { mLog = log . forSubComponent ( TAG ) ; mNotifyList = notifyList ; mActiveDownstreams = new LinkedList < > ( ) ; mUniqueLocalPrefix = generateUniqueLocalPrefix ( ) ; mNextSubnetId = 0 ; }
",,,"< |startfocus| > public IPv6TetheringCoordinator ( ArrayList < TetherInterfaceStateMachine > notifyList , SharedLog log ) { mLog = log . forSubComponent ( TAG ) ; < |endfocus| > mNotifyList = notifyList ; mActiveDownstreams = new LinkedList < > ( ) ; mUniqueLocalPrefix = generateUniqueLocalPrefix ( ) ; mNextSubnetId = 0 ;
",,
687,"* is used for accessing the key store and trust store for TLS * certificates . * * @param target The base URL for the server to be accessed . * @param conf The configuration for certificates and credentials . * @param mapper The object mapper . * @param loader The resource loader . */ public GatewayClient ( String target , ClientConfig conf , ObjectMapper mapper , ResourceLoader loader ) { super ( target , conf , mapper , loader ) ; } /* * * Verify connectivity between the local gateway server and the remote * federation server . * * @param peerId The ID of the peer Acumos . * @return Information about the peer . */ public MLPPeer ping ( String peerId ) { return handleResponse ( PEER_PFX + FederationClient . PING_URI , new ParameterizedTypeReference < JsonResponse < MLPPeer > > ( ) { } , peerId ) ; } /* * * Ask the peer about its peers . * * @param peerId The ID of the peer Acumos . * @return The list of the peer's peers . */ public List < MLPPeer > getPeers ( String peerId ) {
","* Verify connectivity between the local gateway server and the remote * federation server .
","* Get the peer Acumos.
",,,"* Ping the peer Acumos.
",,,"/* * * Gateway client for accessing a server with TLS certificates and credentials . * The * is used for accessing the key store and trust store for TLS certificates . * * @param target The base URL for the server to be accessed . * @param conf The configuration for certificates and credentials . * @param mapper The object mapper . * @param loader The resource loader . */ public GatewayClient ( String target , ClientConfig conf , ObjectMapper mapper , ResourceLoader loader ) { super ( target , conf , mapper , loader ) ; } /* * * Ping the peer Acumos . * * @param peerId The ID of the peer Acumos . * @return Information about the peer . */ public MLPPeer ping ( String peerId ) { return handleResponse ( PEER_PFX + FederationClient . PING_URI , new ParameterizedTypeReference < JsonResponse < MLPPeer > > ( ) { } , peerId ) ; } /* * * Ask the peer about its peers . * * @param peerId The ID of the peer Acumos . * @return The list of the peer's peers . */ public List < MLPPeer > getPeers ( String peerId ) { // implementation }
",,,"public GatewayClient ( String target , ClientConfig conf , ObjectMapper mapper , ResourceLoader loader ) { super ( target , conf , mapper , loader ) ; } public MLPPeer ping ( String peerId ) { return handleResponse ( PEER_PFX + FederationClient . PING_URI , new ParameterizedTypeReference < JsonResponse < MLPPeer > > ( ) { } , peerId ) ; } public List < MLPPeer > getPeers ( String peerId ) { // implementation }
",,,"* is used for accessing the key store and trust store for TLS * certificates . * * @param target The base URL for the server to be accessed . * @param conf The configuration for certificates and credentials . * @param mapper The object mapper . * @param loader The resource loader . */ public GatewayClient ( String target , ClientConfig conf , ObjectMapper mapper , ResourceLoader loader ) { super ( target , conf , mapper , loader ) ; } /* * * Ping the peer Acumos . * * @param peerId The ID of the peer Acumos . * @return Information about the peer . */ public MLPPeer ping ( String peerId ) { return handleResponse ( PEER_PFX + FederationClient . PING_URI , new ParameterizedTypeReference < JsonResponse < MLPPeer > > ( ) { } , peerId ) ; } /* * * Ask the peer about its peers . * * @param peerId The ID of the peer Acumos . * @return The list of the peer's peers . */ public List < MLPPeer > getPeers ( String peerId ) {
",,
696,"public JsonResponse < Void > badRequestError ( HttpServletRequest request , HttpServletResponse response , BadRequestException badRequest ) { log . warn ( ""Rejecting invalid request { } : { } { } { } "" , request . getRequestURI ( ) , badRequest . getMessage ( ) , badRequest . getCode ( ) , badRequest ) ; JsonResponse < Void > ret = new JsonResponse < > ( ) ; ret . setError ( badRequest . getMessage ( ) ) ; response . setStatus ( badRequest . getCode ( ) ) ; return ret ;
","log . warn ( ""Rejecting invalid request { } : { } { } { } "" , request . getRequestURI ( ) , badRequest . getMessage ( ) , badRequest . getCode ( ) , badRequest ) ;
","log.error(""Request {} failed {} {}"", request.getRequestURI(), badRequest.getMessage(), badRequest.getCode(), badRequest);
",,,"log.error(""Request {} failed {} {}"", request.getRequestURI(), badRequest.getMessage(), badRequest.getCode(), badRequest);
",,,"public JsonResponse < Void > badRequestError ( HttpServletRequest request , HttpServletResponse response , BadRequestException badRequest ) { log . error ( ""Request { } failed { } { } { } "" , request . getRequestURI ( ) , badRequest . getMessage ( ) , badRequest . getCode ( ) , badRequest ) ; JsonResponse < Void > ret = new JsonResponse < > ( ) ; ret . setError ( badRequest . getMessage ( ) ) ; response . setStatus ( badRequest . getCode ( ) ) ; return ret ; }
",,,"public JsonResponse < Void > badRequestError ( HttpServletRequest request , HttpServletResponse response , BadRequestException badRequest ) { log . error ( ""Request { } failed { } { } { } "" , request . getRequestURI ( ) , badRequest . getMessage ( ) , badRequest . getCode ( ) , badRequest ) ; JsonResponse < Void > ret = new JsonResponse < > ( ) ; ret . setError ( badRequest . getMessage ( ) ) ; response . setStatus ( badRequest . getCode ( ) ) ; return ret ; }
",,,"public JsonResponse < Void > badRequestError ( HttpServletRequest request , HttpServletResponse response , BadRequestException badRequest ) { < |startfocus| > log . error ( ""Request { } failed { } { } { } "" , request . getRequestURI ( ) , badRequest . getMessage ( ) , badRequest . getCode ( ) , badRequest ) ; < |endfocus| > JsonResponse < Void > ret = new JsonResponse < > ( ) ; ret . setError ( badRequest . getMessage ( ) ) ; response . setStatus ( badRequest . getCode ( ) ) ; return ret ;
",,
723,"* == == == == == == == = LICENSE_START == == == == == == == == == == == == == == == == == == == == == == == == == == == = * Acumos * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = * Copyright ( C ) 2019 AT & T Intellectual Property & Tech Mahindra . All rights reserved . * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = * This Acumos software file is distributed by AT & T and Tech Mahindra * under the Apache License , Version 2 . 0 ( the ""License"" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an ""AS IS"" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . csvdatabroker . vo ; import static org . junit . Assert . assertTrue ; import org . junit . Test ; public class CSVdatabrokerVOTest { @Test public void csvdatabrokerVOTest ( ) { DataBrokerMap dataBrokerMap = new DataBrokerMap ( ) ; dataBrokerMap . setScript ( ""test"" ) ;
","* Copyright ( C ) 2019 AT & T Intellectual Property & Tech Mahindra . All rights reserved .
","* Copyright (C) 2018 AT&T Intellectual Property & Tech Mahindra. All rights reserved.
",,,"* Copyright (C) 2016 AT&T Intellectual Property & Tech Mahindra. All rights reserved.
",,,"/* == == == == == == == = LICENSE_START == == == == == == == == == == == == == == == == == == == == == == == == == == == = Acumos == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ /* Copyright ( C ) 2018 - 2019 AT & T Intellectual Property & Tech Mahindra . All rights reserved . */ /* == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ /* This Acumos software file is distributed by AT & T and Tech Mahindra */ /* under the Apache License , Version 2 . 0 ( the ""License"" ) ; */ /* you may not use this file except in compliance with the License . */ /* You may obtain a copy of the License at */ /* */ /* http :/ / www . apache . org / licenses / LICENSE - 2 . 0 */ /* */ /* This file is distributed on an ""AS IS"" BASIS , */ /* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . */ /* See the License for the specific language governing permissions and */ /* limitations under the License . */ /* == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . csvdatabroker . vo ; import static org . junit . Assert . assertTrue ; import org . junit . Test ; public class CSVdatabrokerVOTest { @Test public void testCSVdatabrokerVO ( ) { DataBrokerMap dataBrokerMap = new DataBrokerMap ( ) ; dataBrokerMap . setScript ( ""test"" ) ; assertTrue ( dataBrokerMap . getScript ( ) . equals ( ""test"" ) ) ; } }
",,,"/* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * Copyright ( C ) 2018 - 2019 AT & T Intellectual Property & Tech Mahindra . All rights reserved . * * This Acumos software file is distributed by AT & T and Tech Mahindra * under the Apache License , Version 2 . 0 ( the ""License"" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an ""AS IS"" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . acumos . csvdatabroker . vo ; import static org . junit . Assert . assertTrue ; import org . junit . Test ; public class CSVdatabrokerVOTest { 	@Test 	public void csvdatabrokerVOTest ( ) { 		DataBrokerMap dataBrokerMap = new DataBrokerMap ( ) ; 		dataBrokerMap . setScript ( ""test"" ) ; 	 } }
",,,"* == == == == == == == = LICENSE_START == == == == == == == == == == == == == == == == == == == == == == == == == == == = * Acumos * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = < |startfocus| > * Copyright ( C ) 2019 AT & T Intellectual Property & Tech Mahindra . All rights reserved . < |endfocus| > * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = * This Acumos software file is distributed by AT & T and Tech Mahindra * under the Apache License , Version 2 . 0 ( the ""License"" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an ""AS IS"" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . csvdatabroker . vo ; import static org . junit . Assert . assertTrue ; import org . junit . Test ; public class CSVdatabrokerVOTest { @Test public void csvdatabrokerVOTest ( ) { DataBrokerMap dataBrokerMap = new DataBrokerMap ( ) ; dataBrokerMap . setScript ( ""test"" ) ;
",,
745,"ITupleReference highSearchKey = null ; partSearcher . setNumTokensBoundsInSearchKeys ( numTokensLowerBound , numTokensUpperBound ) ; if ( numTokensLowerBound < 0 ) { ctx . getBtreePred ( ) . setLowKeyComparator ( ctx . getPrefixSearchCmp ( ) ) ; lowSearchKey = partSearcher . getPrefixSearchKey ( ) ; } else { ctx . getBtreePred ( ) . setLowKeyComparator ( ctx . getSearchCmp ( ) ) ; lowSearchKey = partSearcher . getFullLowSearchKey ( ) ; } if ( numTokensUpperBound < 0 ) { ctx . btreePred . setHighKeyComparator ( ctx . prefixSearchCmp ) ; highSearchKey = partSearcher . getPrefixSearchKey ( ) ; } else { ctx . getBtreePred ( ) . setHighKeyComparator ( ctx . getSearchCmp ( ) ) ; highSearchKey = partSearcher . getFullHighSearchKey ( ) ; } ctx . getBtreePred ( ) . setLowKey ( lowSearchKey , true ) ; ctx . getBtreePred ( ) . setHighKey ( highSearchKey , true ) ; ctx . getBtreeAccessor ( ) . search ( ctx . getBtreeCursor ( ) , ctx . getBtreePred ( ) ) ; boolean tokenExists = false ; try { while ( ctx . getBtreeCursor ( ) . hasNext ( ) ) { ctx . getBtreeCursor ( ) . next ( ) ; ITupleReference btreeTuple = ctx . getBtreeCursor ( ) . getTuple ( ) ;
","ctx . btreePred . setHighKeyComparator ( ctx . prefixSearchCmp ) ;
","ctx.getBtreePred().setHighKeyComparator(ctx.getPrefixSearchCmp()); ctx.getBtreePred().setLowKeyComparator(ctx.getPrefixSearchCmp());
",,,"ctx.getBtreePred().setHighKeyComparator(ctx.getSearchCmp());
",,,"ITupleReference highSearchKey = null ; partSearcher . setNumTokensBoundsInSearchKeys ( numTokensLowerBound , numTokensUpperBound ) ; if ( numTokensLowerBound < 0 ) { ctx . getBtreePred ( ) . setLowKeyComparator ( ctx . getPrefixSearchCmp ( ) ) ; lowSearchKey = partSearcher . getPrefixSearchKey ( ) ; } else { ctx . getBtreePred ( ) . setLowKeyComparator ( ctx . getSearchCmp ( ) ) ; lowSearchKey = partSearcher . getFullLowSearchKey ( ) ; } if ( numTokensUpperBound < 0 ) { ctx . getBtreePred ( ) . setHighKeyComparator ( ctx . getPrefixSearchCmp ( ) ) ; highSearchKey = partSearcher . getPrefixSearchKey ( ) ; } else { ctx . getBtreePred ( ) . setHighKeyComparator ( ctx . getSearchCmp ( ) ) ; highSearchKey = partSearcher . getFullHighSearchKey ( ) ; } ctx . getBtreePred ( ) . setLowKey ( lowSearchKey , true ) ; ctx . getBtreePred ( ) . setHighKey ( highSearchKey , true ) ; ctx . getBtreeAccessor ( ) . search ( ctx . getBtreeCursor ( ) , ctx . getBtreePred ( ) ) ; boolean tokenExists = false ; try { while ( ctx . getBtreeCursor ( ) . hasNext ( ) ) { ctx . getBtreeCursor ( ) . next ( ) ; ITupleReference btreeTuple = ctx . getBtreeCursor ( ) . getTuple ( ) ; } }
",,,"ITupleReference highSearchKey = null ; partSearcher . setNumTokensBoundsInSearchKeys ( numTokensLowerBound , numTokensUpperBound ) ; if ( numTokensLowerBound < 0 ) { ctx . getBtreePred ( ) . setLowKeyComparator ( ctx . getPrefixSearchCmp ( ) ) ; lowSearchKey = partSearcher . getPrefixSearchKey ( ) ; } else { ctx . getBtreePred ( ) . setLowKeyComparator ( ctx . getSearchCmp ( ) ) ; lowSearchKey = partSearcher . getFullLowSearchKey ( ) ; } if ( numTokensUpperBound < 0 ) { ctx . getBtreePred ( ) . setHighKeyComparator ( ctx . getPrefixSearchCmp ( ) ) ; highSearchKey = partSearcher . getPrefixSearchKey ( ) ; } else { ctx . getBtreePred ( ) . setHighKeyComparator ( ctx . getSearchCmp ( ) ) ; highSearchKey = partSearcher . getFullHighSearchKey ( ) ; } ctx . getBtreePred ( ) . setLowKey ( lowSearchKey , true ) ; ctx . getBtreePred ( ) . setHighKey ( highSearchKey , true ) ; ctx . getBtreeAccessor ( ) . search ( ctx . getBtreeCursor ( ) , ctx . getBtreePred ( ) ) ; boolean tokenExists = false ; try { while ( ctx . getBtreeCursor ( ) . hasNext ( ) ) { ctx . getBtreeCursor ( ) . next ( ) ; ITupleReference btreeTuple = ctx . getBtreeCursor ( ) . getTuple ( ) ; } } catch ( Exception e ) { // Handle exception } finally { ctx . getBtreeCursor ( ) . close ( ) ; }
",,,"ITupleReference highSearchKey = null ; partSearcher . setNumTokensBoundsInSearchKeys ( numTokensLowerBound , numTokensUpperBound ) ; if ( numTokensLowerBound < 0 ) { ctx . getBtreePred ( ) . setLowKeyComparator ( ctx . getPrefixSearchCmp ( ) ) ; lowSearchKey = partSearcher . getPrefixSearchKey ( ) ; } else { ctx . getBtreePred ( ) . setLowKeyComparator ( ctx . getSearchCmp ( ) ) ; lowSearchKey = partSearcher . getFullLowSearchKey ( ) ; } if ( numTokensUpperBound < 0 ) { < |startfocus| > ctx . getBtreePred ( ) . setHighKeyComparator ( ctx . getPrefixSearchCmp ( ) ) ; < |endfocus| > highSearchKey = partSearcher . getPrefixSearchKey ( ) ; } else { ctx . getBtreePred ( ) . setHighKeyComparator ( ctx . getSearchCmp ( ) ) ; highSearchKey = partSearcher . getFullHighSearchKey ( ) ; } ctx . getBtreePred ( ) . setLowKey ( lowSearchKey , true ) ; ctx . getBtreePred ( ) . setHighKey ( highSearchKey , true ) ; ctx . getBtreeAccessor ( ) . search ( ctx . getBtreeCursor ( ) , ctx . getBtreePred ( ) ) ; boolean tokenExists = false ; try { while ( ctx . getBtreeCursor ( ) . hasNext ( ) ) { ctx . getBtreeCursor ( ) . next ( ) ; ITupleReference btreeTuple = ctx . getBtreeCursor ( ) . getTuple ( ) ;
",,
747,"foundIn = i ; return true ; } } if ( i == 0 && includeMutableComponent ) { // unlatch / unpin btreeCursors [ i ] . reset ( ) ; searchCallback . reconcile ( predicate . getLowKey ( ) ) ; reconciled = true ; // retraverse btreeAccessors [ 0 ] . search ( btreeCursors [ i ] , predicate ) ; if ( btreeCursors [ i ] . hasNext ( ) ) { btreeCursors [ i ] . next ( ) ; if ( ( ( ILSMTreeTupleReference ) btreeCursors [ i ] . getTuple ( ) ) . isAntimatter ( ) ) { searchCallback . cancel ( predicate . getLowKey ( ) ) ; rangeCursors [ i ] . close ( ) ; return false ; } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; foundTuple = true ; searchCallback . complete ( predicate . getLowKey ( ) ) ; foundIn = i ; return true ; } } else { searchCallback . cancel ( predicate . getLowKey ( ) ) ; btreeCursors [ i ] . close ( ) ; } } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; searchCallback . reconcile ( frameTuple ) ; searchCallback . complete ( frameTuple ) ; foundTuple = true ; foundIn = i ;
","rangeCursors [ i ] . close ( ) ;
","btreeCursors[i].close(); indexTuple = btreeCursors[i].getIndex();
",,,"btreeCursors[i].close(); } if (btreeCursors[i].getTuple() == null) { searchCallback.cancel(predicate.getLowKey());
",,,"int foundIn = - 1 ; boolean foundTuple = false ; for ( int i = 0 ; i < btreeAccessors . length ; i ++ ) { if ( btreeAccessors [ i ] == null ) { continue ; } btreeAccessors [ i ] . search ( btreeCursors [ i ] , predicate ) ; if ( btreeCursors [ i ] . hasNext ( ) ) { btreeCursors [ i ] . next ( ) ; if ( ( ( ILSMTreeTupleReference ) btreeCursors [ i ] . getTuple ( ) ) . isAntimatter ( ) ) { searchCallback . cancel ( predicate . getLowKey ( ) ) ; btreeCursors [ i ] . close ( ) ; return false ; } else { foundTuple = true ; foundIn = i ; } } else { btreeCursors [ i ] . close ( ) ; } } if ( foundTuple ) { frameTuple = btreeCursors [ foundIn ] . getTuple ( ) ; searchCallback . reconcile ( frameTuple ) ; searchCallback . complete ( frameTuple ) ; return true ; } else if ( includeMutableComponent ) { for ( int i = 0 ; i < btreeAccessors . length ; i ++ ) { if ( btreeAccessors [ i ] == null ) { continue ; } btreeCursors [ i ] . reset ( ) ; searchCallback . reconcile ( predicate . getLowKey ( ) ) ; btreeAccessors [ 0 ] . search ( btreeCursors [ i ] , predicate ) ; if ( btreeCursors [ i ] . hasNext ( ) ) { btreeCursors [ i ] . next ( ) ; if ( ( ( ILSMTreeTupleReference ) btreeCursors [ i ] . getTuple ( ) ) . isAntimatter ( ) ) { searchCallback . cancel ( predicate . getLowKey ( ) ) ; btreeCursors [ i ] . close ( ) ; return false ; } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; foundTuple = true ; foundIn = i ; searchCallback . complete ( predicate . getLowKey ( ) ) ; break ; } } else { searchCallback . cancel ( predicate . getLowKey ( ) ) ; btreeCursors [ i ] . close ( ) ; } } if ( foundTuple ) { frameTuple = btreeCursors [ foundIn ] . getTuple ( ) ; searchCallback . reconcile ( frameTuple ) ; searchCallback . complete ( frameTuple ) ; return true ; } } return false ;
",,,"private boolean searchInBTreeCursors ( int i , boolean includeMutableComponent ) { if ( i == 0 && includeMutableComponent ) { btreeCursors [ i ] . reset ( ) ; searchCallback . reconcile ( predicate . getLowKey ( ) ) ; reconciled = true ; btreeAccessors [ 0 ] . search ( btreeCursors [ i ] , predicate ) ; if ( btreeCursors [ i ] . hasNext ( ) ) { btreeCursors [ i ] . next ( ) ; if ( ( ( ILSMTreeTupleReference ) btreeCursors [ i ] . getTuple ( ) ) . isAntimatter ( ) ) { searchCallback . cancel ( predicate . getLowKey ( ) ) ; btreeCursors [ i ] . close ( ) ; return false ; } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; foundTuple = true ; searchCallback . complete ( predicate . getLowKey ( ) ) ; foundIn = i ; return true ; } } else { searchCallback . cancel ( predicate . getLowKey ( ) ) ; btreeCursors [ i ] . close ( ) ; } } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; searchCallback . reconcile ( frameTuple ) ; searchCallback . complete ( frameTuple ) ; foundTuple = true ; foundIn = i ; return true ; } return false ; }
",,,"foundIn = i ; return true ; } } if ( i == 0 && includeMutableComponent ) { // unlatch / unpin btreeCursors [ i ] . reset ( ) ; searchCallback . reconcile ( predicate . getLowKey ( ) ) ; reconciled = true ; // retraverse btreeAccessors [ 0 ] . search ( btreeCursors [ i ] , predicate ) ; if ( btreeCursors [ i ] . hasNext ( ) ) { btreeCursors [ i ] . next ( ) ; if ( ( ( ILSMTreeTupleReference ) btreeCursors [ i ] . getTuple ( ) ) . isAntimatter ( ) ) { searchCallback . cancel ( predicate . getLowKey ( ) ) ; < |startfocus| > btreeCursors [ i ] . close ( ) ; < |endfocus| > return false ; } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; foundTuple = true ; searchCallback . complete ( predicate . getLowKey ( ) ) ; foundIn = i ; return true ; } } else { searchCallback . cancel ( predicate . getLowKey ( ) ) ; btreeCursors [ i ] . close ( ) ; } } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; searchCallback . reconcile ( frameTuple ) ; searchCallback . complete ( frameTuple ) ; foundTuple = true ; foundIn = i ; return true ; } } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; searchCallback . reconcile ( frameTuple ) ; searchCallback . complete ( frameTuple ) ; foundTuple = true ; foundIn = i ;
",,
756,"protected void cleanupForAbort ( ) { for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) { AtomicInteger pendingOps = partitionPendingOps . get ( e . getKey ( ) ) ; e . getValue ( ) . first . cleanupNumActiveOperationsForAbortedJob ( pendingOps . get ( ) ) ; }
","for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) {
","for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e:primaryIndexTrackers.entrySet()) {
",,,"for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e: primaryIndexTrackers.entrySet()) {
",,,"protected void cleanupForAbort ( ) { for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) { AtomicInteger pendingOps = partitionPendingOps . get ( e . getKey ( ) ) ; e . getValue ( ) . first . cleanupNumActiveOperationsForAbortedJob ( pendingOps . get ( ) ) ; } }
",,,"protected void cleanupForAbort ( ) { for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) { AtomicInteger pendingOps = partitionPendingOps . get ( e . getKey ( ) ) ; e . getValue ( ) . first . cleanupNumActiveOperationsForAbortedJob ( pendingOps . get ( ) ) ; } }
",,,"protected void cleanupForAbort ( ) { < |startfocus| > for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) { < |endfocus| > AtomicInteger pendingOps = partitionPendingOps . get ( e . getKey ( ) ) ; e . getValue ( ) . first . cleanupNumActiveOperationsForAbortedJob ( pendingOps . get ( ) ) ; }
",,
762,"try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { flushDatasetOpenIndexes ( dsInfo , false ) ; } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { closeIndex ( iInfo ) ; } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { closeDataset ( dsr . getDatasetInfo ( ) ) ; } } @Override public synchronized void closeUserDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) {
","closeIndex ( iInfo ) ;
","Thread.currentThread().interrupt();
",,,"iInfo.getIndex().deactivate(false);
",,,"try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; throw new HyracksDataException ( e ) ; } try { flushDatasetOpenIndexes ( dsInfo , false ) ; } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { closeDataset ( dsr . getDatasetInfo ( ) ) ; } } @Override public synchronized void closeUserDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { closeDataset ( dsr . getDatasetInfo ( ) ) ; } }
",,,"try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { flushDatasetOpenIndexes ( dsInfo , false ) ; } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { closeDataset ( dsr . getDatasetInfo ( ) ) ; } } @Override public synchronized void closeUserDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { try { closeDataset ( dsr . getDatasetInfo ( ) ) ; } catch ( HyracksDataException e ) { // handle exception } } }
",,,"try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { flushDatasetOpenIndexes ( dsInfo , false ) ; } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { < |startfocus| > if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } < |endfocus| > } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { closeDataset ( dsr . getDatasetInfo ( ) ) ; } } @Override public synchronized void closeUserDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { Thread . currentThread ( ) . interrupt ( ) ;
",,
763,"// we will force all jobs to spill their cached entities to disk . // This could happen only when we have many jobs with small // number of records and none of them have job commit . freeJobsCachedEntities ( txnId ) ; } jobId2WinnerEntitiesMap . put ( txnId , jobEntityWinners ) ; } else { jobEntityWinners = jobId2WinnerEntitiesMap . get ( txnId ) ; } jobEntityWinners . add ( logRecord ) ; } private synchronized void startRecoveryRedoPhase ( Set < Integer > partitions , ILogReader logReader , long lowWaterMarkLSN , Set < Long > winnerTxnSet ) throws IOException , ACIDException { int redoCount = 0 ; long txnId = 0 ; long resourceId ; long maxDiskLastLsn ; long lsn = - 1 ; ILSMIndex index = null ; LocalResource localResource = null ; DatasetLocalResource localResourceMetadata = null ; boolean foundWinner = false ; JobEntityCommits jobEntityWinners = null ; IAppRuntimeContextProvider appRuntimeContext = txnSubsystem . getAsterixAppRuntimeContextProvider ( ) ; IDatasetLifecycleManager datasetLifecycleManager = appRuntimeContext . getDatasetLifecycleManager ( ) ;
","< |del| > @SuppressWarnings ( { ""squid : MethodCyclomaticComplexity"" , ""squid : S134"" } )
","<|del|>
",,,"<|del|>
",,,"private synchronized void startRecoveryRedoPhase ( Set < Integer > partitions , ILogReader logReader , long lowWaterMarkLSN , Set < Long > winnerTxnSet ) throws IOException , ACIDException { int redoCount = 0 ; long txnId = 0 ; long resourceId ; long maxDiskLastLsn ; long lsn = - 1 ; ILSMIndex index = null ; LocalResource localResource = null ; DatasetLocalResource localResourceMetadata = null ; boolean foundWinner = false ; JobEntityCommits jobEntityWinners = null ; IAppRuntimeContextProvider appRuntimeContext = txnSubsystem . getAsterixAppRuntimeContextProvider ( ) ; IDatasetLifecycleManager datasetLifecycleManager = appRuntimeContext . getDatasetLifecycleManager ( ) ; } @SuppressWarnings ( { ""squid : MethodCyclomaticComplexity"" , ""squid : S134"" } ) private synchronized void startRecoveryRedoPhase ( Set < Integer > partitions , ILogReader logReader , long lowWaterMarkLSN , Set < Long > winnerTxnSet ) throws IOException , ACIDException { int redoCount = 0 ; long txnId = 0 ; long resourceId ; long maxDiskLastLsn ; long lsn = - 1 ; ILSMIndex index = null ; LocalResource localResource = null ; DatasetLocalResource localResourceMetadata = null ; boolean foundWinner = false ; JobEntityCommits jobEntityWinners = null ; IAppRuntimeContextProvider appRuntimeContext = txnSubsystem . getAsterixAppRuntimeContextProvider ( ) ; IDatasetLifecycleManager datasetLifecycleManager = appRuntimeContext . getDatasetLifecycleManager ( ) ; }
",,,"// we will force all jobs to spill their cached entities to disk . // This could happen only when we have many jobs with small // number of records and none of them have job commit . freeJobsCachedEntities ( txnId ) ; jobId2WinnerEntitiesMap . put ( txnId , jobEntityWinners ) ; } else { jobEntityWinners = jobId2WinnerEntitiesMap . get ( txnId ) ; } jobEntityWinners . add ( logRecord ) ; @SuppressWarnings ( { ""squid : MethodCyclomaticComplexity"" , ""squid : S134"" } ) private synchronized void startRecoveryRedoPhase ( Set < Integer > partitions , ILogReader logReader , long lowWaterMarkLSN , Set < Long > winnerTxnSet ) throws IOException , ACIDException { int redoCount = 0 ; long txnId = 0 ; long resourceId ; long maxDiskLastLsn ; long lsn = - 1 ; ILSMIndex index = null ; LocalResource localResource = null ; DatasetLocalResource localResourceMetadata = null ; boolean foundWinner = false ; JobEntityCommits jobEntityWinners = null ; IAppRuntimeContextProvider appRuntimeContext = txnSubsystem . getAsterixAppRuntimeContextProvider ( ) ; IDatasetLifecycleManager datasetLifecycleManager = appRuntimeContext . getDatasetLifecycleManager ( ) ;
",,,"// we will force all jobs to spill their cached entities to disk . // This could happen only when we have many jobs with small // number of records and none of them have job commit . freeJobsCachedEntities ( txnId ) ; } jobId2WinnerEntitiesMap . put ( txnId , jobEntityWinners ) ; } else { jobEntityWinners = jobId2WinnerEntitiesMap . get ( txnId ) ; } jobEntityWinners . add ( logRecord ) ; } < |startfocus| > @SuppressWarnings ( { ""squid : MethodCyclomaticComplexity"" , ""squid : S134"" } ) < |endfocus| > private synchronized void startRecoveryRedoPhase ( Set < Integer > partitions , ILogReader logReader , long lowWaterMarkLSN , Set < Long > winnerTxnSet ) throws IOException , ACIDException { int redoCount = 0 ; long txnId = 0 ; long resourceId ; long maxDiskLastLsn ; long lsn = - 1 ; ILSMIndex index = null ; LocalResource localResource = null ; DatasetLocalResource localResourceMetadata = null ; boolean foundWinner = false ; JobEntityCommits jobEntityWinners = null ; IAppRuntimeContextProvider appRuntimeContext = txnSubsystem . getAsterixAppRuntimeContextProvider ( ) ; IDatasetLifecycleManager datasetLifecycleManager = appRuntimeContext . getDatasetLifecycleManager ( ) ;
",,
771,"private boolean readEntityInfo ( ByteBuffer buffer ) { // attempt to read in the resourcePartition , dsid , PK hash and PK length if ( buffer . remaining ( ) < ENTITY_VALUE_HEADER_LEN ) { return false ; } resourcePartition = buffer . getInt ( ) ; datasetId = buffer . getInt ( ) ; PKHashValue = buffer . getInt ( ) ; PKValueSize = buffer . getInt ( ) ; // attempt to read in the PK if ( buffer . remaining ( ) < PKValueSize ) { return false ; } if ( PKValueSize <= 0 ) { throw new IllegalStateException ( ""Primary Key Size is less than or equal to 0"" ) ; } PKValue = readPKValue ( buffer ) ; return true ;
","if ( buffer . remaining ( ) < ENTITY_VALUE_HEADER_LEN ) {
","if (buffer.remaining() < entityCOMMIT_UPDATE_HEADER_LEN) {
",,,"if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) {
",,,"private boolean readEntityInfo ( ByteBuffer buffer ) { if ( buffer . remaining ( ) < ENTITYCOMMIT_UPDATE_HEADER_LEN ) { return false ; } resourcePartition = buffer . getInt ( ) ; datasetId = buffer . getInt ( ) ; PKHashValue = buffer . getInt ( ) ; PKValueSize = buffer . getInt ( ) ; if ( buffer . remaining ( ) < PKValueSize ) { return false ; } if ( PKValueSize <= 0 ) { throw new IllegalStateException ( ""Primary Key Size is less than or equal to 0"" ) ; } PKValue = readPKValue ( buffer ) ; return true ; }
",,,"private boolean readEntityInfo ( ByteBuffer buffer ) { if ( buffer . remaining ( ) < ENTITYCOMMIT_UPDATE_HEADER_LEN ) { return false ; } resourcePartition = buffer . getInt ( ) ; datasetId = buffer . getInt ( ) ; PKHashValue = buffer . getInt ( ) ; PKValueSize = buffer . getInt ( ) ; if ( buffer . remaining ( ) < PKValueSize ) { return false ; } if ( PKValueSize <= 0 ) { throw new IllegalStateException ( ""Primary Key Size is less than or equal to 0"" ) ; } PKValue = readPKValue ( buffer ) ; return true ; }
",,,"private boolean readEntityInfo ( ByteBuffer buffer ) { // attempt to read in the resourcePartition , dsid , PK hash and PK length < |startfocus| > if ( buffer . remaining ( ) < ENTITYCOMMIT_UPDATE_HEADER_LEN ) { < |endfocus| > return false ; } resourcePartition = buffer . getInt ( ) ; datasetId = buffer . getInt ( ) ; PKHashValue = buffer . getInt ( ) ; PKValueSize = buffer . getInt ( ) ; // attempt to read in the PK < |startfocus| > if ( buffer . remaining ( ) < PKValueSize ) { return false ; } if ( PKValueSize <= 0 ) { throw new IllegalStateException ( ""Primary Key Size is less than or equal to 0"" ) ; } < |endfocus| > PKValue = readPKValue ( buffer ) ; return true ;
",,
783,"// ( e . g . , the shape of the given query is not a point or rectangle . // Then , we may need to apply the select again using the real polygon , not MBR of it to get the true // result , not a super - set of it . ) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo . getThird ( ) ; // Does the given index can cover all search predicates ? boolean doesSIdxSearchCoverAllPredicates ; // matched function expressions List < IOptimizableFuncExpr > matchedFuncExprs = analysisCtx . getMatchedFuncExprs ( ) ; // If no - index - only option is given , we stop here to honor that request . boolean noIndexOnlyPlanOption = getNoIndexOnlyOption ( context ) ; if ( noIndexOnlyPlanOption ) { indexOnlyPlanInfo . setFirst ( isIndexOnlyPlan ) ; return ; } // logical variables that select ( join ) operator is using List < LogicalVariable > usedVarsInSelJoinOp = new ArrayList < > ( ) ; List < LogicalVariable > usedVarsInSelJoinOpTemp = new ArrayList < > ( ) ; // live variables that select ( join ) operator can access
","boolean doesSIdxSearchCoverAllPredicates ;
","boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getThree();
",,,"boolean doesSIdxSearchCoverAllPredicates;
",,,"boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo . getThird ( ) ; List < IOptimizableFuncExpr > matchedFuncExprs = analysisCtx . getMatchedFuncExprs ( ) ; boolean noIndexOnlyPlanOption = getNoIndexOnlyOption ( context ) ; if ( noIndexOnlyPlanOption ) { indexOnlyPlanInfo . setFirst ( isIndexOnlyPlan ) ; return ; } List < LogicalVariable > usedVarsInSelJoinOp = new ArrayList < > ( ) ; List < LogicalVariable > usedVarsInSelJoinOpTemp = new ArrayList < > ( ) ;
",,,"boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo . getThird ( ) ; boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo . getFourth ( ) ; List < IOptimizableFuncExpr > matchedFuncExprs = analysisCtx . getMatchedFuncExprs ( ) ; boolean noIndexOnlyPlanOption = getNoIndexOnlyOption ( context ) ; if ( noIndexOnlyPlanOption ) { indexOnlyPlanInfo . setFirst ( isIndexOnlyPlan ) ; return ; } List < LogicalVariable > usedVarsInSelJoinOp = new ArrayList < > ( ) ; List < LogicalVariable > usedVarsInSelJoinOpTemp = new ArrayList < > ( ) ; // remaining code . . .
",,,"// ( e . g . , the shape of the given query is not a point or rectangle . // Then , we may need to apply the select again using the real polygon , not MBR of it to get the true // result , not a super - set of it . ) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo . getThird ( ) ; // Does the given index can cover all search predicates ? < |startfocus| > indexOnlyPlanInfo . getFourth ( ) ; < |endfocus| > // matched function expressions List < IOptimizableFuncExpr > matchedFuncExprs = analysisCtx . getMatchedFuncExprs ( ) ; // If no - index - only option is given , we stop here to honor that request . boolean noIndexOnlyPlanOption = getNoIndexOnlyOption ( context ) ; if ( noIndexOnlyPlanOption ) { indexOnlyPlanInfo . setFirst ( isIndexOnlyPlan ) ; return ; } // logical variables that select ( join ) operator is using List < LogicalVariable > usedVarsInSelJoinOp = new ArrayList < > ( ) ; List < LogicalVariable > usedVarsInSelJoinOpTemp = new ArrayList < > ( ) ; // live variables that select ( join ) operator can access
",,
795,"if ( minTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; minTupleBytes = new byte [ numBytes ] ; opCallback . after ( tuple ) ; logged = true ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; minTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , minTuple ) ; if ( c < 0 ) { if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( minTupleBytes . length < numBytes ) { minTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } } if ( maxTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ;
","if ( ! logged ) {
","if (logged) {
",,,"if (!logged) {
",,,"if ( minTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; minTupleBytes = new byte [ numBytes ] ; opCallback . after ( tuple ) ; logged = true ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; minTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , minTuple ) ; if ( c < 0 ) { if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( minTupleBytes . length < numBytes ) { minTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } } if ( maxTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; // code for maxTuple } else { // code for maxTuple }
",,,"if ( minTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; minTupleBytes = new byte [ numBytes ] ; opCallback . after ( tuple ) ; logged = true ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; minTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , minTuple ) ; if ( c < 0 ) { if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( minTupleBytes . length < numBytes ) { minTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } } if ( maxTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; // . . . rest of the code }
",,,"if ( minTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; minTupleBytes = new byte [ numBytes ] ; opCallback . after ( tuple ) ; logged = true ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; minTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , minTuple ) ; if ( c < 0 ) { < |startfocus| > if ( logged ) { < |endfocus| > opCallback . after ( tuple ) ; logged = true ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( minTupleBytes . length < numBytes ) { minTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } } if ( maxTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ;
",,
799,"int numBytes = tupleWriter . bytesRequired ( tuple ) ; maxTupleBytes = new byte [ numBytes ] ; if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; maxTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , maxTuple ) ; if ( c > 0 ) { if ( ! logged ) { opCallback . after ( tuple ) ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( maxTupleBytes . length < numBytes ) { maxTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } } } @Override public ITupleReference getMinTuple ( ) { return minTuple ; } @Override
","if ( ! logged ) {
","if (!logged) {
",,,"if (!logged) {
",,,"int numBytes = tupleWriter . bytesRequired ( tuple ) ; maxTupleBytes = new byte [ numBytes ] ; if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; maxTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , maxTuple ) ; if ( c > 0 ) { if ( ! logged ) { opCallback . after ( tuple ) ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( maxTupleBytes . length < numBytes ) { maxTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } } @Override public ITupleReference getMinTuple ( ) { return minTuple ; } @Override
",,,"int numBytes = tupleWriter . bytesRequired ( tuple ) ; maxTupleBytes = new byte [ numBytes ] ; if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; maxTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , maxTuple ) ; if ( c > 0 ) { if ( ! logged ) { opCallback . after ( tuple ) ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( maxTupleBytes . length < numBytes ) { maxTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } } } @Override public ITupleReference getMinTuple ( ) { return minTuple ; } @Override
",,,"int numBytes = tupleWriter . bytesRequired ( tuple ) ; maxTupleBytes = new byte [ numBytes ] ; if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; maxTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , maxTuple ) ; if ( c > 0 ) { < |startfocus| > if ( ! logged ) { < |endfocus| > opCallback . after ( tuple ) ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( maxTupleBytes . length < numBytes ) { maxTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } } } @Override public ITupleReference getMinTuple ( ) { return minTuple ; } @Override
",,
804,"// may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker . flushAndWaitForIO ( dsInfo , iInfo ) ; } } } private void closeDataset ( DatasetInfo dsInfo ) throws HyracksDataException { // First wait for any ongoing IO operations synchronized ( dsInfo ) { while ( dsInfo . getNumActiveIOOps ( ) > 0 ) { try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { flushDatasetOpenIndexes ( dsr , false ) ; } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException {
","flushDatasetOpenIndexes ( dsr , false ) ;
","flushDatasetOpenIndexes(dsInfo, false); Thread.currentThread().interrupt();
",,,"flushDatasetOpenIndexes(dsInfo, false); Thread.currentThread().interrupt();
",,,"private void closeDataset ( DatasetInfo dsInfo ) throws HyracksDataException { // First wait for any ongoing IO operations synchronized ( dsInfo ) { while ( dsInfo . getNumActiveIOOps ( ) > 0 ) { try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { flushDatasetOpenIndexes ( dsInfo , false ) ; } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { for ( DatasetInfo dsInfo : datasetInfos . values ( ) ) { closeDataset ( dsInfo ) ; } }
",,,"// may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker . flushAndWaitForIO ( dsInfo , iInfo ) ; } } private void closeDataset ( DatasetInfo dsInfo ) throws HyracksDataException { // First wait for any ongoing IO operations synchronized ( dsInfo ) { while ( dsInfo . getNumActiveIOOps ( ) > 0 ) { try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { flushDatasetOpenIndexes ( dsInfo , false ) ; } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { // First wait for any ongoing IO operations for ( DatasetInfo dsInfo : datasetInfos . values ( ) ) { synchronized ( dsInfo ) { while ( dsInfo . getNumActiveIOOps ( ) > 0 ) { try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } } // Close all datasets for ( DatasetInfo dsInfo : datasetInfos . values ( ) ) { closeDataset ( dsInfo ) ; } }
",,,"// may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker . flushAndWaitForIO ( dsInfo , iInfo ) ; } } } private void closeDataset ( DatasetInfo dsInfo ) throws HyracksDataException { // First wait for any ongoing IO operations synchronized ( dsInfo ) { while ( dsInfo . getNumActiveIOOps ( ) > 0 ) { try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { < |startfocus| > flushDatasetOpenIndexes ( dsInfo , false ) ; < |endfocus| > } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { while ( true ) {
",,
806,"} catch ( HyracksDataException e ) { datasetLifecycleManager . close ( localResource . getPath ( ) ) ; throw e ; } // # . set resourceId and maxDiskLastLSN to the map resourceId2MaxLSNMap . put ( resourceId , maxDiskLastLsn ) ; } else { maxDiskLastLsn = resourceId2MaxLSNMap . get ( resourceId ) ; } } } break ; case LogType . JOB_COMMIT : case LogType . ENTITY_COMMIT : case LogType . ABORT : case LogType . FLUSH : case LogType . WAIT : case LogType . MARKER : // do nothing break ; default : throw new ACIDException ( ""Unsupported LogType : "" + logRecord . getLogType ( ) ) ; } logRecord = logReader . next ( ) ; } LOGGER . info ( ""Logs REDO phase completed . Redo logs count : "" + redoCount ) ; } finally {
","}
","// lsn @ maxDiskLastLsn is either a flush log or a master replica log if (lsn >= maxDiskLastLsn) { redo(logRecord, datasetLifecycleManager); redoCount++;
",,,"// lsn @ maxDiskLastLsn is either a flush log or a master replica log if (lsn >= maxDiskLastLsn) { redo(logRecord, datasetLifecycleManager); redoCount++; }
",,,"} catch ( HyracksDataException e ) { datasetLifecycleManager . close ( localResource . getPath ( ) ) ; throw e ; } resourceId2MaxLSNMap . put ( resourceId , maxDiskLastLsn ) ; } else { maxDiskLastLsn = resourceId2MaxLSNMap . get ( resourceId ) ; } if ( lsn >= maxDiskLastLsn ) { redo ( logRecord , datasetLifecycleManager ) ; redoCount ++ ; } break ; case LogType . JOB_COMMIT : case LogType . ENTITY_COMMIT : case LogType . ABORT : case LogType . FLUSH : case LogType . WAIT : case LogType . MARKER : // do nothing break ; default : throw new ACIDException ( ""Unsupported LogType : "" + logRecord . getLogType ( ) ) ; } logRecord = logReader . next ( ) ; } LOGGER . info ( ""Logs REDO phase completed . Redo logs count : "" + redoCount ) ; } finally {
",,,"} catch ( HyracksDataException e ) { datasetLifecycleManager . close ( localResource . getPath ( ) ) ; throw e ; } resourceId2MaxLSNMap . put ( resourceId , maxDiskLastLsn ) ; } else { maxDiskLastLsn = resourceId2MaxLSNMap . get ( resourceId ) ; } if ( lsn >= maxDiskLastLsn ) { redo ( logRecord , datasetLifecycleManager ) ; redoCount ++ ; } break ; case LogType . JOB_COMMIT : case LogType . ENTITY_COMMIT : case LogType . ABORT : case LogType . FLUSH : case LogType . WAIT : case LogType . MARKER : // do nothing break ; default : throw new ACIDException ( ""Unsupported LogType : "" + logRecord . getLogType ( ) ) ; } logRecord = logReader . next ( ) ; } LOGGER . info ( ""Logs REDO phase completed . Redo logs count : "" + redoCount ) ; } finally {
",,,"} catch ( HyracksDataException e ) { datasetLifecycleManager . close ( localResource . getPath ( ) ) ; throw e ; } // # . set resourceId and maxDiskLastLSN to the map resourceId2MaxLSNMap . put ( resourceId , maxDiskLastLsn ) ; } else { maxDiskLastLsn = resourceId2MaxLSNMap . get ( resourceId ) ; } < |startfocus| > // lsn @ maxDiskLastLsn is either a flush log or a master replica log if ( lsn >= maxDiskLastLsn ) { redo ( logRecord , datasetLifecycleManager ) ; redoCount ++ ; } < |endfocus| > } break ; case LogType . JOB_COMMIT : case LogType . ENTITY_COMMIT : case LogType . ABORT : case LogType . FLUSH : case LogType . WAIT : case LogType . MARKER : // do nothing break ; default : throw new ACIDException ( ""Unsupported LogType : "" + logRecord . getLogType ( ) ) ; } logRecord = logReader . next ( ) ; } LOGGER . info ( ""Logs REDO phase completed . Redo logs count : "" + redoCount ) ; } finally {
",,
809,"return pin ( dpid , newPage , null ) ; } @Override public ICachedPage pin ( long dpid , boolean newPage , ILargePageHelper helper ) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging , since // the synchronized block over the fileInfoMap is a hot spot . if ( DEBUG ) { pinSanityCheck ( dpid ) ; } CachedPage cPage = findPage ( dpid , false ) ; if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { throw new IllegalStateException ( ) ; } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage , helper ) ; cPage . valid = true ; } } } else { cPage . valid = true ; }
","throw new IllegalStateException ( ) ;
","while (confiscatedPages.contains(c)) { throw new IllegalStateException();
",,,"assert !confiscatedPages.contains(c);
",,,"public ICachedPage pin ( long dpid , boolean newPage , ILargePageHelper helper ) throws HyracksDataException { if ( DEBUG ) { pinSanityCheck ( dpid ) ; } CachedPage cPage = findPage ( dpid , false ) ; if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { while ( confiscatedPages . contains ( c ) ) { throw new IllegalStateException ( ) ; } } } } finally { confiscateLock . unlock ( ) ; } } synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage , helper ) ; cPage . valid = true ; } } } else { cPage . valid = true ; } return pin ( dpid , newPage , null ) ; }
",,,"return pin ( dpid , newPage , null ) ; } @Override public ICachedPage pin ( long dpid , boolean newPage , ILargePageHelper helper ) throws HyracksDataException { if ( DEBUG ) { pinSanityCheck ( dpid ) ; } CachedPage cPage = findPage ( dpid , false ) ; if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { while ( confiscatedPages . contains ( c ) ) { throw new IllegalStateException ( ) ; } } } } finally { confiscateLock . unlock ( ) ; } } synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage , helper ) ; cPage . valid = true ; } } } else { cPage . valid = true ; } }
",,,"return pin ( dpid , newPage , null ) ; } @Override public ICachedPage pin ( long dpid , boolean newPage , ILargePageHelper helper ) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging , since // the synchronized block over the fileInfoMap is a hot spot . if ( DEBUG ) { pinSanityCheck ( dpid ) ; } CachedPage cPage = findPage ( dpid , false ) ; if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { < |startfocus| > while ( confiscatedPages . contains ( c ) ) { throw new IllegalStateException ( ) ; } < |endfocus| > } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage , helper ) ; cPage . valid = true ; } } } else { cPage . valid = true ; }
",,
821,"int n = subplans . size ( ) ; AlgebricksPipeline [ ] result = new AlgebricksPipeline [ n ] ; for ( int i = 0 ; i < n ; i ++ ) { List < AlgebricksPipeline > subplanOps = subplans . get ( i ) ; if ( subplanOps . size ( ) != 1 ) { throw new AlgebricksException ( ""Attempting to construct a nested plan with "" + subplanOps . size ( ) + "" operator descriptors . Currently , nested plans can only consist in linear pipelines of "" + ""Asterix micro operators . "" ) ; } result [ i ] = subplanOps . get ( 0 ) ; } return result ; } protected List < List < AlgebricksPipeline > > compileSubplansImpl ( IOperatorSchema outerPlanSchema , AbstractOperatorWithNestedPlans npOp , IOperatorSchema opSchema , JobGenContext context ) throws AlgebricksException { List < List < AlgebricksPipeline > > subplans = new ArrayList < > ( npOp . getNestedPlans ( ) . size ( ) ) ; PlanCompiler pc = new PlanCompiler ( context ) ; for ( ILogicalPlan p : npOp . getNestedPlans ( ) ) { subplans . add ( buildPipelineWithProjection ( p , outerPlanSchema , npOp , opSchema , pc ) ) ; } return subplans ; }
","+ "" operator descriptors . Currently , nested plans can only consist in linear pipelines of "" + ""Asterix micro operators . "" ) ;
","+ "" operator descriptors. Currently, nested plans can only consist in linear pipeline of Asterix micro operators."");
",,,"+ "" operator descriptors. Currently, nested plans can only consist in linear pipelines of Asterix micro operators."");
",,,"int n = subplans . size ( ) ; AlgebricksPipeline [ ] result = new AlgebricksPipeline [ n ] ; for ( int i = 0 ; i < n ; i ++ ) { List < AlgebricksPipeline > subplanOps = subplans . get ( i ) ; if ( subplanOps . size ( ) != 1 ) { throw new AlgebricksException ( ""Attempting to construct a nested plan with "" + subplanOps . size ( ) + "" operator descriptors . Currently , nested plans can only consist in linear pipelines of Asterix micro operators . "" ) ; } result [ i ] = subplanOps . get ( 0 ) ; } return result ; protected List < List < AlgebricksPipeline > > compileSubplansImpl ( IOperatorSchema outerPlanSchema , AbstractOperatorWithNestedPlans npOp , IOperatorSchema opSchema , JobGenContext context ) throws AlgebricksException { List < List < AlgebricksPipeline > > subplans = new ArrayList < > ( npOp . getNestedPlans ( ) . size ( ) ) ; PlanCompiler pc = new PlanCompiler ( context ) ; for ( ILogicalPlan p : npOp . getNestedPlans ( ) ) { subplans . add ( buildPipelineWithProjection ( p , outerPlanSchema , npOp , opSchema , pc ) ) ; } return subplans ; }
",,,"int n = subplans . size ( ) ; AlgebricksPipeline [ ] result = new AlgebricksPipeline [ n ] ; for ( int i = 0 ; i < n ; i ++ ) { List < AlgebricksPipeline > subplanOps = subplans . get ( i ) ; if ( subplanOps . size ( ) != 1 ) { throw new AlgebricksException ( ""Attempting to construct a nested plan with "" + subplanOps . size ( ) + "" operator descriptors . Currently , nested plans can only consist in linear pipelines of Asterix micro operators . "" ) ; } result [ i ] = subplanOps . get ( 0 ) ; } return result ; } protected List < List < AlgebricksPipeline > > compileSubplansImpl ( IOperatorSchema outerPlanSchema , AbstractOperatorWithNestedPlans npOp , IOperatorSchema opSchema , JobGenContext context ) throws AlgebricksException { List < List < AlgebricksPipeline > > subplans = new ArrayList < > ( npOp . getNestedPlans ( ) . size ( ) ) ; PlanCompiler pc = new PlanCompiler ( context ) ; for ( ILogicalPlan p : npOp . getNestedPlans ( ) ) { subplans . add ( buildPipelineWithProjection ( p , outerPlanSchema , npOp , opSchema , pc ) ) ; } return subplans ; }
",,,"int n = subplans . size ( ) ; AlgebricksPipeline [ ] result = new AlgebricksPipeline [ n ] ; for ( int i = 0 ; i < n ; i ++ ) { List < AlgebricksPipeline > subplanOps = subplans . get ( i ) ; if ( subplanOps . size ( ) != 1 ) { throw new AlgebricksException ( ""Attempting to construct a nested plan with "" + subplanOps . size ( ) < |startfocus| > + "" operator descriptors . Currently , nested plans can only consist in linear pipelines of Asterix micro operators . "" ) ; < |endfocus| > } result [ i ] = subplanOps . get ( 0 ) ; } return result ; } protected List < List < AlgebricksPipeline > > compileSubplansImpl ( IOperatorSchema outerPlanSchema , AbstractOperatorWithNestedPlans npOp , IOperatorSchema opSchema , JobGenContext context ) throws AlgebricksException { List < List < AlgebricksPipeline > > subplans = new ArrayList < > ( npOp . getNestedPlans ( ) . size ( ) ) ; PlanCompiler pc = new PlanCompiler ( context ) ; for ( ILogicalPlan p : npOp . getNestedPlans ( ) ) { subplans . add ( buildPipelineWithProjection ( p , outerPlanSchema , npOp , opSchema , pc ) ) ; } return subplans ; }
",,
823,"public void setInputRecordDescriptor ( int index , RecordDescriptor recordDescriptor ) { // input is not accessed
","public void setInputRecordDescriptor ( int index , RecordDescriptor recordDescriptor ) { // input is not accessed
","public void setInputRecordDescriptor(int index, RecordDescriptor recordDescriptor) { // empty constructor
",,,"public void setInputRecordDescriptor(int index, RecordDescriptor recordDescriptor) { // do nothing
",,,"public void setInputRecordDescriptor ( int index , RecordDescriptor recordDescriptor ) { // TODO : Implement this method throw new UnsupportedOperationException ( ""Not implemented yet . "" ) ; }
",,,"public void setInputRecordDescriptor ( int index , RecordDescriptor recordDescriptor ) { // TODO : Implement this method throw new UnsupportedOperationException ( ""Not implemented yet"" ) ; }
",,,"< |startfocus| > public void setInputRecordDescriptor ( int index , RecordDescriptor recordDescriptor ) { // TODO : Implement this method } < |endfocus| >
",,
832,"* * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * ""AS IS"" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . common . api ; import org . apache . hyracks . dataflow . common . data . accessors . ITupleReference ; import org . apache . hyracks . storage . common . IIndexCursor ; public interface ILSMIndexCursor extends IIndexCursor { /* * * @return the min tuple of the current index's filter */ ITupleReference getFilterMinTuple ( ) ; /* * * * @return the max tuple of the current index's filter */ ITupleReference getFilterMaxTuple ( ) ; }
","public interface ILSMIndexCursor extends IIndexCursor {
","public interface ILSMIndexCursor extends IIndexCursor {
",,,"public interface ILSMIndexCursor extends IIndexCursor {
",,,"/* Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * ""AS IS"" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . common . api ; import org . apache . hyracks . dataflow . common . data . accessors . ITupleReference ; import org . apache . hyracks . storage . common . IIndexCursor ; public interface ILSMIndexCursor extends IIndexCursor { ITupleReference getFilterMinTuple ( ) ; ITupleReference getFilterMaxTuple ( ) ; }
",,,"/* * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * ""AS IS"" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . common . api ; import org . apache . hyracks . dataflow . common . data . accessors . ITupleReference ; import org . apache . hyracks . storage . common . IIndexCursor ; public interface ILSMIndexCursor extends IIndexCursor { ITupleReference getFilterMinTuple ( ) ; ITupleReference getFilterMaxTuple ( ) ; }
",,,"* * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * ""AS IS"" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . common . api ; import org . apache . hyracks . dataflow . common . data . accessors . ITupleReference ; import org . apache . hyracks . storage . common . IIndexCursor ; < |startfocus| > public interface ILSMIndexCursor extends IIndexCursor { < |endfocus| > /* * * @return the min tuple of the current index's filter */ ITupleReference getFilterMinTuple ( ) ; /* * * * @return the max tuple of the current index's filter */ ITupleReference getFilterMaxTuple ( ) ; }
",,
851,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
","if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; }
","if(n>0xff){n>>>=8;log=8;}
",,,"if (n > 0xff) { n>>>=8; log=8; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
",,
853,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
","if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; }
","if(n>0xff){n>>>=8;log=8;}
",,,"if (n > 0xff) { n>>>=8; log=8; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
",,
855,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
","if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; }
","if(n>0xff){n>>>=8;log| 8;}
",,,"if (n > 0xff) { n>>>=8; log|=8; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
",,
862,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
","if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; }
","if(n>0xf){n>>> 4;log|=4;}
",,,"if (n > 0xf){ n>>>=4; log|=4; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
",,
868,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
","if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; }
","if(n>0xf){n>>> 4;log|=4;}
",,,"if (n > 0xf){ n>>>=4; log|=4; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ;
",,
876,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 3 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ;
","if ( n > 3 ) { n > > >= 2 ; log | = 2 ; }
","if(n>0b11){n>>>=2;log|=2;}
",,,"<|del|>
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
",,
878,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 3 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ;
","if ( n > 3 ) { n > > >= 2 ; log | = 2 ; }
","if(n>0b11){n>>>=2;log|=2;}
",,,"<|del|>
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
",,
883,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
","return log + ( n > > > 1 ) ;
","return log+(n>>>1);
",,,"return log + (n>>>1);
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ; }
",,,"public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
",,
907,"* software distributed under the License is distributed on an * ""AS IS"" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . lsm . common . util ; import org . apache . hyracks . storage . am . common . api . IIndexOperationContext ; import org . apache . hyracks . storage . common . IIndexAccessor ; import org . apache . hyracks . storage . common . IIndexCursor ; public class DestroyUtils { private DestroyUtils ( ) { } public static < T extends IIndexOperationContext > Throwable destroy ( T [ ] contexts ) { Throwable failure = null ; for ( int i = 0 ; i < contexts . length ; i ++ ) { if ( contexts [ i ] != null ) { try { contexts [ i ] . destroy ( ) ; } catch ( Throwable th ) { if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } public static < T extends IIndexAccessor > Throwable destroy ( T [ ] accessors ) { Throwable failure = null ;
","private DestroyUtils ( ) { }
","private DestroyUtils() { }
",,,"private DestroyUtils() { }
",,,"/* * Licensed to the Apache Software Foundation ( ASF ) under one * or more contributor license agreements . See the NOTICE file * distributed with this work for additional information * regarding copyright ownership . The ASF licenses this file * to you under the Apache License , Version 2 . 0 ( the * ""License"" ) ; you may not use this file except in compliance * with the License . You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * ""AS IS"" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . lsm . common . util ; import org . apache . hyracks . storage . am . common . api . IIndexOperationContext ; import org . apache . hyracks . storage . common . IIndexAccessor ; import org . apache . hyracks . storage . common . IIndexCursor ; public class DestroyUtils { private DestroyUtils ( ) { // private constructor to hide the implicit public one } public static < T extends IIndexOperationContext > Throwable destroy ( T [ ] contexts ) { Throwable failure = null ; for ( int i = 0 ; i < contexts . length ; i ++ ) { if ( contexts [ i ] != null ) { try { contexts [ i ] . destroy ( ) ; } catch ( Throwable th ) { if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } public static < T extends IIndexAccessor > Throwable destroy ( T [ ] accessors ) { Throwable failure = null ; for ( int i = 0 ; i < accessors . length ; i ++ ) { if ( accessors [ i ] != null ) { try { accessors [ i ] . destroy ( ) ; } catch ( Throwable th ) { if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } }
",,,"package org . apache . hyracks . storage . am . lsm . common . util ; import org . apache . hyracks . storage . am . common . api . IIndexOperationContext ; import org . apache . hyracks . storage . common . IIndexAccessor ; import org . apache . hyracks . storage . common . IIndexCursor ; public class DestroyUtils { private DestroyUtils ( ) { throw new AssertionError ( ""This util class should not be initialized . "" ) ; } public static < T extends IIndexOperationContext > Throwable destroy ( T [ ] contexts ) { Throwable failure = null ; for ( int i = 0 ; i < contexts . length ; i ++ ) { if ( contexts [ i ] != null ) { try { contexts [ i ] . destroy ( ) ; } catch ( Throwable th ) { if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } public static < T extends IIndexAccessor > Throwable destroy ( T [ ] accessors ) { Throwable failure = null ; for ( int i = 0 ; i < accessors . length ; i ++ ) { if ( accessors [ i ] != null ) { try { accessors [ i ] . destroy ( ) ; } catch ( Throwable th ) { if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } }
",,,"* software distributed under the License is distributed on an * ""AS IS"" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . lsm . common . util ; import org . apache . hyracks . storage . am . common . api . IIndexOperationContext ; import org . apache . hyracks . storage . common . IIndexAccessor ; import org . apache . hyracks . storage . common . IIndexCursor ; public class DestroyUtils { < |startfocus| > < |endfocus| > public static < T extends IIndexOperationContext > Throwable destroy ( T [ ] contexts ) { Throwable failure = null ; for ( int i = 0 ; i < contexts . length ; i ++ ) { if ( contexts [ i ] != null ) { try { contexts [ i ] . destroy ( ) ; } catch ( Throwable th ) { if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } public static < T extends IIndexAccessor > Throwable destroy ( T [ ] accessors ) { Throwable failure = null ;
",,
914,"if ( state != State . OPENED ) { throw new IllegalStateException ( ""Cannot call hasNext ( ) on a cursor in the state "" + state ) ; } } return doHasNext ( ) ; } protected boolean doHasNext ( ) throws HyracksDataException { return false ; } @Override public final void next ( ) throws HyracksDataException { if ( ENFORCE_NEXT_HAS_NEXT && state != State . OPENED ) { throw new IllegalStateException ( ""Cannot call next ( ) on a cursor in the state "" + state ) ; } doNext ( ) ; } protected void doNext ( ) throws HyracksDataException { // Do nothing } @Override public final void destroy ( ) throws HyracksDataException { if ( ENFORCE_OPEN_CLOSE_DESTROY ) { if ( state == State . DESTROYED ) { LOGGER . log ( Level . WARN , ""multiple cursor . destroy ( ) call in "" + Arrays . toString ( new Throwable ( ) . getStackTrace ( ) ) ) ; return ; } else if ( state != State . CLOSED ) { if ( STORE_TRACES && openCallStack != null ) {
","if ( ENFORCE_NEXT_HAS_NEXT && state != State . OPENED ) { throw new IllegalStateException ( ""Cannot call next ( ) on a cursor in the state "" + state ) ;
","if (ENFORCE_NEXT_HAS_NEXT && state != State.OPENED) { throw new IllegalStateException(""Cannot call next() on a cursor in the state "" + state);
",,,"if (state != State.OPENED) { throw new IllegalStateException(""Cannot call next() on a cursor in the state "" + state);
",,,"if ( state != State . OPENED ) { throw new IllegalStateException ( ""Cannot call hasNext ( ) on a cursor in the state "" + state ) ; } return doHasNext ( ) ; protected boolean doHasNext ( ) throws HyracksDataException { return false ; } @Override public final void next ( ) throws HyracksDataException { if ( ENFORCE_NEXT_HAS_NEXT && state != State . OPENED ) { throw new IllegalStateException ( ""Cannot call next ( ) on a cursor in the state "" + state ) ; } doNext ( ) ; } protected void doNext ( ) throws HyracksDataException { // Do nothing } @Override public final void destroy ( ) throws HyracksDataException { if ( ENFORCE_OPEN_CLOSE_DESTROY ) { if ( state == State . DESTROYED ) { LOGGER . log ( Level . WARN , ""multiple cursor . destroy ( ) call in "" + Arrays . toString ( new Throwable ( ) . getStackTrace ( ) ) ) ; return ; } else if ( state != State . CLOSED ) { if ( STORE_TRACES && openCallStack != null ) { LOGGER . log ( Level . WARN , ""cursor . destroy ( ) call in "" + Arrays . toString ( new Throwable ( ) . getStackTrace ( ) ) , openCallStack ) ; } else { LOGGER . log ( Level . WARN , ""cursor . destroy ( ) call in "" + Arrays . toString ( new Throwable ( ) . getStackTrace ( ) ) ) ; } } } state = State . DESTROYED ; }
",,,"if ( state != State . OPENED ) { throw new IllegalStateException ( ""Cannot call hasNext ( ) on a cursor in the state "" + state ) ; } return doHasNext ( ) ; } protected boolean doHasNext ( ) throws HyracksDataException { return false ; } @Override public final void next ( ) throws HyracksDataException { if ( ENFORCE_NEXT_HAS_NEXT && state != State . OPENED ) { throw new IllegalStateException ( ""Cannot call next ( ) on a cursor in the state "" + state ) ; } doNext ( ) ; } protected void doNext ( ) throws HyracksDataException { // Do nothing } @Override public final void destroy ( ) throws HyracksDataException { if ( ENFORCE_OPEN_CLOSE_DESTROY ) { if ( state == State . DESTROYED ) { LOGGER . log ( Level . WARN , ""multiple cursor . destroy ( ) call in "" + Arrays . toString ( new Throwable ( ) . getStackTrace ( ) ) ) ; return ; } else if ( state != State . CLOSED ) { if ( STORE_TRACES && openCallStack != null ) { LOGGER . log ( Level . WARN , ""cursor . destroy ( ) called without cursor . close ( ) in "" + Arrays . toString ( openCallStack ) ) ; } close ( ) ; } state = State . DESTROYED ; } }
",,,"if ( state != State . OPENED ) { throw new IllegalStateException ( ""Cannot call hasNext ( ) on a cursor in the state "" + state ) ; } } return doHasNext ( ) ; } protected boolean doHasNext ( ) throws HyracksDataException { return false ; } @Override public final void next ( ) throws HyracksDataException { < |startfocus| > if ( ENFORCE_NEXT_HAS_NEXT && state != State . OPENED ) { throw new IllegalStateException ( ""Cannot call next ( ) on a cursor in the state "" + state ) ; } < |endfocus| > doNext ( ) ; } protected void doNext ( ) throws HyracksDataException { // Do nothing } @Override public final void destroy ( ) throws HyracksDataException { if ( ENFORCE_OPEN_CLOSE_DESTROY ) { if ( state == State . DESTROYED ) { LOGGER . log ( Level . WARN , ""multiple cursor . destroy ( ) call in "" + Arrays . toString ( new Throwable ( ) . getStackTrace ( ) ) ) ; return ; } else if ( state != State . CLOSED ) { if ( STORE_TRACES && openCallStack != null ) {
",,
919,"CCNCFunctions . NodeRegistrationResult nrrf = ( CCNCFunctions . NodeRegistrationResult ) fn ; setNodeRegistrationResult ( nrrf . getNodeParameters ( ) , nrrf . getException ( ) ) ; return ; case GET_NODE_CONTROLLERS_INFO_RESPONSE : CCNCFunctions . GetNodeControllersInfoResponseFunction gncirf = ( CCNCFunctions . GetNodeControllersInfoResponseFunction ) fn ; setNodeControllersInfo ( gncirf . getNodeControllerInfos ( ) ) ; return ; case DEPLOY_BINARY : CCNCFunctions . DeployBinaryFunction dbf = ( CCNCFunctions . DeployBinaryFunction ) fn ; queue . schedule ( new DeployBinaryWork ( NodeControllerService . this , dbf . getDeploymentId ( ) , dbf . getBinaryURLs ( ) ) ) ; return ; } case UNDEPLOY_BINARY : CCNCFunctions . UnDeployBinaryFunction ndbf = ( CCNCFunctions . UnDeployBinaryFunction ) fn ; queue . schedule ( new UnDeployBinaryWork ( NodeControllerService . this , ndbf . getDeploymentId ( ) ) ) ; return ; case STATE_DUMP_REQUEST : final CCNCFunctions . StateDumpRequestFunction dsrf = ( StateDumpRequestFunction ) fn ; queue . schedule ( new StateDumpWork ( NodeControllerService . this , dsrf . getStateDumpId ( ) ) ) ; return ; case SHUTDOWN_REQUEST : final CCNCFunctions . ShutdownRequestFunction sdrf = ( CCNCFunctions . ShutdownRequestFunction ) fn ;
","return ; }
","<|del|>
",,,"return; }
",,,"@Deprecated void processFunction ( CCNCFunctions fn ) { switch ( fn . getFunctionType ( ) ) { case NODE_REGISTRATION_RESULT : CCNCFunctions . NodeRegistrationResult nrrf = ( CCNCFunctions . NodeRegistrationResult ) fn ; setNodeRegistrationResult ( nrrf . getNodeParameters ( ) , nrrf . getException ( ) ) ; return ; case GET_NODE_CONTROLLERS_INFO_RESPONSE : CCNCFunctions . GetNodeControllersInfoResponseFunction gncirf = ( CCNCFunctions . GetNodeControllersInfoResponseFunction ) fn ; setNodeControllersInfo ( gncirf . getNodeControllerInfos ( ) ) ; return ; case DEPLOY_BINARY : CCNCFunctions . DeployBinaryFunction dbf = ( CCNCFunctions . DeployBinaryFunction ) fn ; queue . schedule ( new DeployBinaryWork ( NodeControllerService . this , dbf . getDeploymentId ( ) , dbf . getBinaryURLs ( ) ) ) ; return ; case UNDEPLOY_BINARY : CCNCFunctions . UnDeployBinaryFunction ndbf = ( CCNCFunctions . UnDeployBinaryFunction ) fn ; queue . schedule ( new UnDeployBinaryWork ( NodeControllerService . this , ndbf . getDeploymentId ( ) ) ) ; return ; case STATE_DUMP_REQUEST : final CCNCFunctions . StateDumpRequestFunction dsrf = ( StateDumpRequestFunction ) fn ; queue . schedule ( new StateDumpWork ( NodeControllerService . this , dsrf . getStateDumpId ( ) ) ) ; return ; case SHUTDOWN_REQUEST : final CCNCFunctions . ShutdownRequestFunction sdrf = ( CCNCFunctions . ShutdownRequestFunction ) fn ; // Deprecated method deprecatedMethod ( sdrf ) ; return ; default : throw new IllegalArgumentException ( ""Invalid function type : "" + fn . getFunctionType ( ) ) ; } } @Deprecated void deprecatedMethod ( CCNCFunctions . ShutdownRequestFunction sdrf ) { // Deprecated method implementation }
",,,"CCNCFunctions . NodeRegistrationResult nrrf = ( CCNCFunctions . NodeRegistrationResult ) fn ; setNodeRegistrationResult ( nrrf . getNodeParameters ( ) , nrrf . getException ( ) ) ; return ; case GET_NODE_CONTROLLERS_INFO_RESPONSE : CCNCFunctions . GetNodeControllersInfoResponseFunction gncirf = ( CCNCFunctions . GetNodeControllersInfoResponseFunction ) fn ; setNodeControllersInfo ( gncirf . getNodeControllerInfos ( ) ) ; return ; case DEPLOY_BINARY : CCNCFunctions . DeployBinaryFunction dbf = ( CCNCFunctions . DeployBinaryFunction ) fn ; queue . schedule ( new DeployBinaryWork ( NodeControllerService . this , dbf . getDeploymentId ( ) , dbf . getBinaryURLs ( ) ) ) ; return ; @Deprecated case UNDEPLOY_BINARY : CCNCFunctions . UnDeployBinaryFunction ndbf = ( CCNCFunctions . UnDeployBinaryFunction ) fn ; queue . schedule ( new UnDeployBinaryWork ( NodeControllerService . this , ndbf . getDeploymentId ( ) ) ) ; return ; case STATE_DUMP_REQUEST : final CCNCFunctions . StateDumpRequestFunction dsrf = ( StateDumpRequestFunction ) fn ; queue . schedule ( new StateDumpWork ( NodeControllerService . this , dsrf . getStateDumpId ( ) ) ) ; return ; case SHUTDOWN_REQUEST : final CCNCFunctions . ShutdownRequestFunction sdrf = ( CCNCFunctions . ShutdownRequestFunction ) fn ;
",,,"CCNCFunctions . NodeRegistrationResult nrrf = ( CCNCFunctions . NodeRegistrationResult ) fn ; setNodeRegistrationResult ( nrrf . getNodeParameters ( ) , nrrf . getException ( ) ) ; return ; case GET_NODE_CONTROLLERS_INFO_RESPONSE : CCNCFunctions . GetNodeControllersInfoResponseFunction gncirf = ( CCNCFunctions . GetNodeControllersInfoResponseFunction ) fn ; setNodeControllersInfo ( gncirf . getNodeControllerInfos ( ) ) ; return ; case DEPLOY_BINARY : CCNCFunctions . DeployBinaryFunction dbf = ( CCNCFunctions . DeployBinaryFunction ) fn ; queue . schedule ( new DeployBinaryWork ( NodeControllerService . this , dbf . getDeploymentId ( ) , dbf . getBinaryURLs ( ) ) ) ; < |startfocus| > return ; < |endfocus| > case UNDEPLOY_BINARY : CCNCFunctions . UnDeployBinaryFunction ndbf = ( CCNCFunctions . UnDeployBinaryFunction ) fn ; queue . schedule ( new UnDeployBinaryWork ( NodeControllerService . this , ndbf . getDeploymentId ( ) ) ) ; return ; case STATE_DUMP_REQUEST : final CCNCFunctions . StateDumpRequestFunction dsrf = ( StateDumpRequestFunction ) fn ; queue . schedule ( new StateDumpWork ( NodeControllerService . this , dsrf . getStateDumpId ( ) ) ) ; return ; case SHUTDOWN_REQUEST : final CCNCFunctions . ShutdownRequestFunction sdrf = ( CCNCFunctions . ShutdownRequestFunction ) fn ; < |startfocus| > return ; < |endfocus| >
",,
928,"private final LSMBTreeRangeSearchCursor rangeCursor ; private ITreeIndexCursor currentCursor ; public LSMBTreeSearchCursor ( ILSMIndexOperationContext opCtx ) { pointCursor = new LSMBTreePointSearchCursor ( opCtx ) ; rangeCursor = new LSMBTreeRangeSearchCursor ( opCtx ) ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMBTreeCursorInitialState lsmInitialState = ( LSMBTreeCursorInitialState ) initialState ; RangePredicate btreePred = ( RangePredicate ) searchPred ; currentCursor = lsmInitialState . isDiskComponentScan ( ) ? scanCursor : btreePred . isPointPredicate ( lsmInitialState . getOriginalKeyComparator ( ) ) ? pointCursor : rangeCursor ; currentCursor . open ( lsmInitialState , searchPred ) ; } @Override public boolean hasNext ( ) throws HyracksDataException { return currentCursor . hasNext ( ) ; } @Override public void next ( ) throws HyracksDataException { currentCursor . next ( ) ; } @Override public void close ( ) throws HyracksDataException { if ( currentCursor != null ) { currentCursor . close ( ) ; } currentCursor = null ; } @Override public void reset ( ) throws HyracksDataException { if ( currentCursor != null ) { currentCursor . reset ( ) ; } currentCursor = null ;
","currentCursor = lsmInitialState . isDiskComponentScan ( ) ? scanCursor : btreePred . isPointPredicate ( lsmInitialState . getOriginalKeyComparator ( ) ) ? pointCursor : rangeCursor ;
","currentCursor = btreePred.isPointPredicate(lsmInitialState.getOriginalKeyComparator()) ? pointCursor : rangeCursor;
",,,"currentCursor = btreePred.isScan(lsmInitialState.getOriginalKeyComparator()) ? pointCursor : rangeCursor;
",,,"private final LSMBTreeRangeSearchCursor rangeCursor ; private final LSMBTreePointSearchCursor pointCursor ; private ITreeIndexCursor currentCursor ; public LSMBTreeSearchCursor ( ILSMIndexOperationContext opCtx ) { pointCursor = new LSMBTreePointSearchCursor ( opCtx ) ; rangeCursor = new LSMBTreeRangeSearchCursor ( opCtx ) ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMBTreeCursorInitialState lsmInitialState = ( LSMBTreeCursorInitialState ) initialState ; RangePredicate btreePred = ( RangePredicate ) searchPred ; currentCursor = btreePred . isDiskComponentScan ( lsmInitialState . getOriginalKeyComparator ( ) ) ? pointCursor : rangeCursor ; currentCursor . open ( lsmInitialState , searchPred ) ; } @Override public boolean hasNext ( ) throws HyracksDataException { return currentCursor . hasNext ( ) ; } @Override public void next ( ) throws HyracksDataException { currentCursor . next ( ) ; } @Override public void close ( ) throws HyracksDataException { if ( currentCursor != null ) { currentCursor . close ( ) ; } currentCursor = null ; } @Override public void reset ( ) throws HyracksDataException { if ( currentCursor != null ) { currentCursor . reset ( ) ; } currentCursor = null ; }
",,,"private final LSMBTreeRangeSearchCursor rangeCursor ; private ITreeIndexCursor currentCursor ; public LSMBTreeSearchCursor ( ILSMIndexOperationContext opCtx ) { pointCursor = new LSMBTreePointSearchCursor ( opCtx ) ; rangeCursor = new LSMBTreeRangeSearchCursor ( opCtx ) ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMBTreeCursorInitialState lsmInitialState = ( LSMBTreeCursorInitialState ) initialState ; RangePredicate btreePred = ( RangePredicate ) searchPred ; currentCursor = btreePred . isPointPredicate ( lsmInitialState . getOriginalKeyComparator ( ) ) ? pointCursor : rangeCursor ; currentCursor . open ( lsmInitialState , searchPred ) ; } @Override public boolean hasNext ( ) throws HyracksDataException { return currentCursor . hasNext ( ) ; } @Override public void next ( ) throws HyracksDataException { currentCursor . next ( ) ; } @Override public void close ( ) throws HyracksDataException { if ( currentCursor != null ) { currentCursor . close ( ) ; } currentCursor = null ; } @Override public void reset ( ) throws HyracksDataException { if ( currentCursor != null ) { currentCursor . reset ( ) ; } currentCursor = null ; }
",,,"private final LSMBTreeRangeSearchCursor rangeCursor ; private ITreeIndexCursor currentCursor ; public LSMBTreeSearchCursor ( ILSMIndexOperationContext opCtx ) { pointCursor = new LSMBTreePointSearchCursor ( opCtx ) ; rangeCursor = new LSMBTreeRangeSearchCursor ( opCtx ) ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMBTreeCursorInitialState lsmInitialState = ( LSMBTreeCursorInitialState ) initialState ; RangePredicate btreePred = ( RangePredicate ) searchPred ; < |startfocus| > currentCursor = btreePred . isPointPredicate ( lsmInitialState . getOriginalKeyComparator ( ) ) ? pointCursor : rangeCursor ; < |endfocus| > currentCursor . open ( lsmInitialState , searchPred ) ; } @Override public boolean hasNext ( ) throws HyracksDataException { return currentCursor . hasNext ( ) ; } @Override public void next ( ) throws HyracksDataException { currentCursor . next ( ) ; } @Override public void close ( ) throws HyracksDataException { if ( currentCursor != null ) { currentCursor . close ( ) ; } currentCursor = null ; } @Override public void reset ( ) throws HyracksDataException { if ( currentCursor != null ) { currentCursor . reset ( ) ; } currentCursor = null ;
",,
931,"private ITreeIndexAccessor [ ] btreeAccessors ; private RTreeSearchCursor [ ] mutableRTreeCursors ; private ITreeIndexCursor [ ] btreeCursors ; private RangePredicate btreeRangePredicate ; private boolean foundNext ; private ITupleReference frameTuple ; private int [ ] comparatorFields ; private MultiComparator btreeCmp ; private int currentCursor ; private SearchPredicate rtreeSearchPredicate ; private int numMutableComponents ; private boolean open ; protected ISearchOperationCallback searchCallback ; private boolean resultOfsearchCallBackProceed = false ; public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx ) { this ( opCtx , false ) ; } public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx , boolean returnDeletedTuples ) { super ( opCtx , returnDeletedTuples ) ; currentCursor = 0 ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = ( LSMRTreeCursorInitialState ) initialState ; cmp = lsmInitialState . getHilbertCmp ( ) ; btreeCmp = lsmInitialState . getBTreeCmp ( ) ; lsmHarness = lsmInitialState . getLSMHarness ( ) ;
","< |del| > private int numberOfFieldFromIndex = 0 ; private ArrayTupleBuilder tupleBuilderForProceedResult ; private ArrayTupleReference copyTuple = null ;
","<|del|>
",,,"<|del|>
",,,"private ITreeIndexAccessor [ ] btreeAccessors ; private RTreeSearchCursor [ ] mutableRTreeCursors ; private ITreeIndexCursor [ ] btreeCursors ; private RangePredicate btreeRangePredicate ; private boolean foundNext ; private ITupleReference frameTuple ; private int [ ] comparatorFields ; private MultiComparator btreeCmp ; private int currentCursor ; private SearchPredicate rtreeSearchPredicate ; private int numMutableComponents ; private boolean open ; protected ISearchOperationCallback searchCallback ; private boolean resultOfsearchCallBackProceed = false ; private ArrayTupleBuilder tupleBuilderForProceedResult ; private ArrayTupleReference copyTuple = null ; public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx ) { this ( opCtx , false ) ; } public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx , boolean returnDeletedTuples ) { super ( opCtx , returnDeletedTuples ) ; currentCursor = 0 ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = ( LSMRTreeCursorInitialState ) initialState ; cmp = lsmInitialState . getHilbertCmp ( ) ; btreeCmp = lsmInitialState . getBTreeCmp ( ) ; lsmHarness = lsmInitialState . getLSMHarness ( ) ; tupleBuilderForProceedResult = new ArrayTupleBuilder ( cmp . getKeyFieldCount ( ) + 1 ) ; }
",,,"private ITreeIndexAccessor [ ] btreeAccessors ; private RTreeSearchCursor [ ] mutableRTreeCursors ; private ITreeIndexCursor [ ] btreeCursors ; private RangePredicate btreeRangePredicate ; private boolean foundNext ; private ITupleReference frameTuple ; private int [ ] comparatorFields ; private MultiComparator btreeCmp ; private int currentCursor ; private SearchPredicate rtreeSearchPredicate ; private int numMutableComponents ; private boolean open ; protected ISearchOperationCallback searchCallback ; private boolean resultOfsearchCallBackProceed = false ; private ArrayTupleBuilder tupleBuilderForProceedResult ; private ArrayTupleReference copyTuple = null ; public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx ) { this ( opCtx , false ) ; } public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx , boolean returnDeletedTuples ) { super ( opCtx , returnDeletedTuples ) ; currentCursor = 0 ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = ( LSMRTreeCursorInitialState ) initialState ; cmp = lsmInitialState . getHilbertCmp ( ) ; btreeCmp = lsmInitialState . getBTreeCmp ( ) ; lsmHarness = lsmInitialState . getLSMHarness ( ) ; }
",,,"private ITreeIndexAccessor [ ] btreeAccessors ; private RTreeSearchCursor [ ] mutableRTreeCursors ; private ITreeIndexCursor [ ] btreeCursors ; private RangePredicate btreeRangePredicate ; private boolean foundNext ; private ITupleReference frameTuple ; private int [ ] comparatorFields ; private MultiComparator btreeCmp ; private int currentCursor ; private SearchPredicate rtreeSearchPredicate ; private int numMutableComponents ; private boolean open ; protected ISearchOperationCallback searchCallback ; private boolean resultOfsearchCallBackProceed = false ; < |startfocus| > private ArrayTupleBuilder tupleBuilderForProceedResult ; private ArrayTupleReference copyTuple = null ; < |endfocus| > public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx ) { this ( opCtx , false ) ; } public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx , boolean returnDeletedTuples ) { super ( opCtx , returnDeletedTuples ) ; currentCursor = 0 ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = ( LSMRTreeCursorInitialState ) initialState ; cmp = lsmInitialState . getHilbertCmp ( ) ; btreeCmp = lsmInitialState . getBTreeCmp ( ) ; lsmHarness = lsmInitialState . getLSMHarness ( ) ;
",,
942,"public IScalarEvaluatorFactory createEvaluatorFactory ( final IScalarEvaluatorFactory [ ] args ) { return new IScalarEvaluatorFactory ( ) { private static final long serialVersionUID = 1L ; @Override @SuppressWarnings ( ""unchecked"" ) public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { return new IScalarEvaluator ( ) { private class AbstractSTSingleGeometryEvaluator implements IScalarEvaluator { private final AMutableInt32 intRes = new AMutableInt32 ( 0 ) ; @Override public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { resultStorage . reset ( ) ; eval0 . evaluate ( tuple , argPtr0 ) ; try { byte [ ] bytes0 = argPtr0 . getByteArray ( ) ; int offset0 = argPtr0 . getStartOffset ( ) ; int len0 = argPtr0 . getLength ( ) ; ATypeTag tag = EnumDeserializer . ATYPETAGDESERIALIZER . deserialize ( bytes0 [ offset0 ] ) ; if ( tag != ATypeTag . GEOMETRY ) {
","private class AbstractSTSingleGeometryEvaluator implements IScalarEvaluator {
","private final IStorage resultStorage = new ArrayBackedValueStorage(); private final DataOutput out = resultStorage.getDataOutput(); private final IPointable argPtr0 = new VoidPointable(); private final IScalarEvaluator eval0 = args[0].createScalarEvaluator(ctx);
",,,"private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private final IPointable argPtr0 = new VoidPointable(); private final IScalarEvaluator eval0 = args[0].createScalarEvaluator(ctx);
",,,"public IScalarEvaluatorFactory createEvaluatorFactory ( final IScalarEvaluatorFactory [ ] args ) { return new IScalarEvaluatorFactory ( ) { private static final long serialVersionUID = 1L ; @Override @SuppressWarnings ( ""unchecked"" ) public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { return new IScalarEvaluator ( ) { private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; private final DataOutput out = resultStorage . getDataOutput ( ) ; private final IPointable argPtr0 = new VoidPointable ( ) ; private final IScalarEvaluator eval0 = args [ 0 ] . createScalarEvaluator ( ctx ) ; private final AMutableInt32 intRes = new AMutableInt32 ( 0 ) ; @Override public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { resultStorage . reset ( ) ; eval0 . evaluate ( tuple , argPtr0 ) ; try { byte [ ] bytes0 = argPtr0 . getByteArray ( ) ; int offset0 = argPtr0 . getStartOffset ( ) ; int len0 = argPtr0 . getLength ( ) ; ATypeTag tag = EnumDeserializer . ATYPETAGDESERIALIZER . deserialize ( bytes0 [ offset0 ] ) ; if ( tag != ATypeTag . GEOMETRY ) { throw new TypeMismatchException ( sourceLoc , getIdentifier ( ) , 0 , bytes0 [ offset0 ] , ATypeTag . SERIALIZED_GEOMETRY_TYPE_TAG ) ; } intRes . setValue ( 0 ) ; out . write ( bytes0 , offset0 , len0 ) ; result . set ( resultStorage ) ; } catch ( IOException e ) { throw HyracksDataException . create ( e ) ; } } } ; } } ; }
",,,"public IScalarEvaluatorFactory createEvaluatorFactory ( final IScalarEvaluatorFactory [ ] args ) { return new IScalarEvaluatorFactory ( ) { private static final long serialVersionUID = 1L ; @Override @SuppressWarnings ( ""unchecked"" ) public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { return new IScalarEvaluator ( ) { private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; private final DataOutput out = resultStorage . getDataOutput ( ) ; private final IPointable argPtr0 = new VoidPointable ( ) ; private final IScalarEvaluator eval0 = args [ 0 ] . createScalarEvaluator ( ctx ) ; private final AMutableInt32 intRes = new AMutableInt32 ( 0 ) ; @Override public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { resultStorage . reset ( ) ; eval0 . evaluate ( tuple , argPtr0 ) ; try { byte [ ] bytes0 = argPtr0 . getByteArray ( ) ; int offset0 = argPtr0 . getStartOffset ( ) ; int len0 = argPtr0 . getLength ( ) ; ATypeTag tag = EnumDeserializer . ATYPETAGDESERIALIZER . deserialize ( bytes0 [ offset0 ] ) ; if ( tag != ATypeTag . GEOMETRY ) { // Rest of the code } } catch ( IOException e ) { throw HyracksDataException . create ( e ) ; } } } ; } } ; }
",,,"public IScalarEvaluatorFactory createEvaluatorFactory ( final IScalarEvaluatorFactory [ ] args ) { return new IScalarEvaluatorFactory ( ) { private static final long serialVersionUID = 1L ; @Override @SuppressWarnings ( ""unchecked"" ) public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { return new IScalarEvaluator ( ) { < |startfocus| > private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; private final DataOutput out = resultStorage . getDataOutput ( ) ; private final IPointable argPtr0 = new VoidPointable ( ) ; private final IScalarEvaluator eval0 = args [ 0 ] . createScalarEvaluator ( ctx ) ; private final AMutableInt32 intRes = new AMutableInt32 ( 0 ) ; < |endfocus| > @Override public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { resultStorage . reset ( ) ; eval0 . evaluate ( tuple , argPtr0 ) ; try { byte [ ] bytes0 = argPtr0 . getByteArray ( ) ; int offset0 = argPtr0 . getStartOffset ( ) ; int len0 = argPtr0 . getLength ( ) ; ATypeTag tag = EnumDeserializer . ATYPETAGDESERIALIZER . deserialize ( bytes0 [ offset0 ] ) ; if ( tag != ATypeTag . GEOMETRY ) {
",,
947,"public boolean hasNext ( ) { return currentElementIx < numElements ;
","return currentElementIx < numElements ;
","return currentElementIx < numElements;
",,,"return currentElementIx < numElements;
",,,"public boolean hasNext ( ) { return currentElementIx < numElements ; }
",,,"public boolean hasNext ( ) { return currentElementIx < numElements ; }
",,,"public boolean hasNext ( ) { < |startfocus| > return currentElementIx < numElements ; < |endfocus| >
",,
970,"class CachingTxnIdFactory implements ITxnIdFactory { private static final Logger LOGGER = LogManager . getLogger ( ) ; private final INcApplicationContext appCtx ; private volatile Block block = new Block ( 0 , 0 ) ; public CachingTxnIdFactory ( INcApplicationContext appCtx ) { this . appCtx = appCtx ; } @Override public TxnId create ( ) throws AlgebricksException { while ( true ) { try { return new TxnId ( block . nextId ( ) ) ; } catch ( BlockExhaustedException ex ) { // retry LOGGER . info ( ""block exhausted ; obtaining new block from supplier"" ) ; TxnIdBlockRequest . Block newBlock ; try { newBlock = TxnIdBlockRequestMessage . send ( appCtx ) ; } catch ( HyracksDataException e ) { throw new AlgebricksException ( e ) ; } block = new Block ( newBlock . getStartingId ( ) , newBlock . getBlockSize ( ) ) ; } } } @Override public void ensureMinimumId ( long id ) throws AlgebricksException { throw new UnsupportedOperationException ( ) ; } @Override public long getIdBlock ( int blockSize ) { throw new UnsupportedOperationException ( ) ; } @Override
","TxnIdBlockRequest . Block newBlock ;
","TTxnIdBlockRequestMessage.Block newBlock;
",,,"TxnIdBlockRequestMessage.Block newBlock; if (LOGGER.isLoggable(Level.WARNING)) { LOGGER.log(Level.WARNING, ""block exhausted; obtaining new block from supplier""); }
",,,"class CachingTxnIdFactory implements ITxnIdFactory { private static final Logger LOGGER = LogManager . getLogger ( ) ; private final INcApplicationContext appCtx ; private volatile Block block = new Block ( 0 , 0 ) ; public CachingTxnIdFactory ( INcApplicationContext appCtx ) { this . appCtx = appCtx ; } @Override public TxnId create ( ) throws AlgebricksException { while ( true ) { try { return new TxnId ( block . nextId ( ) ) ; } catch ( BlockExhaustedException ex ) { LOGGER . info ( ""block exhausted ; obtaining new block from supplier"" ) ; try { TxnIdBlockRequestMessage . Block newBlock = TxnIdBlockRequestMessage . send ( appCtx ) ; block = new Block ( newBlock . getStartingId ( ) , newBlock . getBlockSize ( ) ) ; } catch ( HyracksDataException e ) { LOGGER . error ( ""Failed to obtain new block"" , e ) ; throw new AlgebricksException ( e ) ; } } } } @Override public void ensureMinimumId ( long id ) throws AlgebricksException { throw new UnsupportedOperationException ( ) ; } @Override public long getIdBlock ( int blockSize ) { throw new UnsupportedOperationException ( ) ; } }
",,,"class CachingTxnIdFactory implements ITxnIdFactory { private static final Logger LOGGER = LogManager . getLogger ( ) ; private final INcApplicationContext appCtx ; private volatile Block block = new Block ( 0 , 0 ) ; public CachingTxnIdFactory ( INcApplicationContext appCtx ) { this . appCtx = appCtx ; } @Override public TxnId create ( ) throws AlgebricksException { while ( true ) { try { return new TxnId ( block . nextId ( ) ) ; } catch ( BlockExhaustedException ex ) { LOGGER . info ( ""block exhausted ; obtaining new block from supplier"" ) ; TxnIdBlockRequestMessage . Block newBlock ; try { newBlock = TxnIdBlockRequestMessage . send ( appCtx ) ; } catch ( HyracksDataException e ) { throw new AlgebricksException ( e ) ; } block = new Block ( newBlock . getStartingId ( ) , newBlock . getBlockSize ( ) ) ; } } } @Override public void ensureMinimumId ( long id ) throws AlgebricksException { throw new UnsupportedOperationException ( ) ; } @Override public long getIdBlock ( int blockSize ) { throw new UnsupportedOperationException ( ) ; } }
",,,"class CachingTxnIdFactory implements ITxnIdFactory { private static final Logger LOGGER = LogManager . getLogger ( ) ; private final INcApplicationContext appCtx ; private volatile Block block = new Block ( 0 , 0 ) ; public CachingTxnIdFactory ( INcApplicationContext appCtx ) { this . appCtx = appCtx ; } @Override public TxnId create ( ) throws AlgebricksException { while ( true ) { try { return new TxnId ( block . nextId ( ) ) ; } catch ( BlockExhaustedException ex ) { // retry LOGGER . info ( ""block exhausted ; obtaining new block from supplier"" ) ; < |startfocus| > TxnIdBlockRequestMessage . Block newBlock ; < |endfocus| > try { newBlock = TxnIdBlockRequestMessage . send ( appCtx ) ; } catch ( HyracksDataException e ) { LOGGER . error ( ""Error while obtaining new block from supplier"" , e ) ; throw new AlgebricksException ( e ) ; } block = new Block ( newBlock . getStartingId ( ) , newBlock . getBlockSize ( ) ) ; } } } @Override public void ensureMinimumId ( long id ) throws AlgebricksException { throw new UnsupportedOperationException ( ) ; } @Override public long getIdBlock ( int blockSize ) { throw new UnsupportedOperationException ( ) ; } @Override
",,
972,"public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , ""Failure closing a closeable resource"" , th ) ; } catch ( Throwable ignore ) { // NOSONAR Logging exception will be ignored // NOSONAR ignore } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
","} catch ( Throwable ignore ) { // NOSONAR Logging exception will be ignored // NOSONAR ignore
","} catch (Exception e) { // Do nothing
",,,"<|del|>
",,,"public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Exception ex ) { LOGGER . log ( Level . WARN , ""Failure closing a closeable resource"" , ex ) ; root = ExceptionUtils . suppress ( root , ex ) ; } } return root ; }
",,,"public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Exception e ) { try { LOGGER . log ( Level . WARN , ""Failure closing a closeable resource"" , e ) ; } catch ( Throwable loggingFailure ) { // Do nothing } root = ExceptionUtils . suppress ( root , e ) ; } } return root ; }
",,,"public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , ""Failure closing a closeable resource"" , th ) ; < |startfocus| > } catch ( Exception loggingFailure ) { // Do nothing < |endfocus| > } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
",,
973,"public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , ""Failure closing a closeable resource"" , th ) ; } catch ( Throwable ignore ) { // NOSONAR Logging exception will be ignored // NOSONAR ignore } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
","} catch ( Throwable ignore ) { // NOSONAR Logging exception will be ignored // NOSONAR ignore
","} catch (Throwable e) { LOGGER.log(Level.WARNING, ""Failure closing a closeable resource"", e);
",,,"<|del|>
",,,"public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Throwable th ) { LOGGER . log ( Level . WARN , ""Failure closing a closeable resource"" , th ) ; root = ExceptionUtils . suppress ( root , th ) ; throw th ; } } return root ; }
",,,"public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Throwable th ) { root = ExceptionUtils . suppress ( root , th ) ; } } return root ; }
",,,"public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , ""Failure closing a closeable resource"" , th ) ; < |startfocus| > } catch ( Throwable loggingFailure ) { // Do nothing } < |endfocus| > root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
",,
989,"public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Had to be done to satisfy contracts try { LOGGER . log ( Level . WARN , ""Failure destroying a destroyable resource"" , th ) ; } catch ( Throwable ignore ) { // Do nothing } } } return root ;
","< |del| > root = ExceptionUtils . suppress ( root , th ) ;
","root = ExceptionUtils.suppress(root, th);
",,,"root = ExceptionUtils.suppress(root, th); } catch (Throwable ignore) { LOGGER.log(Level.WARN, ""Failure destroying a destroyable resource"", ignore);
",,,"public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Exception e ) { root = ExceptionUtils . suppress ( root , e ) ; } } return root ; }
",,,"public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Exception e ) { try { LOGGER . log ( Level . WARN , ""Failure destroying a destroyable resource"" , e ) ; } catch ( Throwable ignore ) { // Do nothing } root = ExceptionUtils . suppress ( root , e ) ; } } return root ; }
",,,"public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Had to be done to satisfy contracts try { LOGGER . log ( Level . WARN , ""Failure destroying a destroyable resource"" , th ) ; } catch ( Exception ignore ) { // Do nothing } < |startfocus| > root = ExceptionUtils . suppress ( root , th ) ; < |endfocus| > } } return root ;
",,
992,"} public LSMBTreePointSearchCursor getInsertSearchCursor ( ) { return insertSearchCursor ; } public BTreeRangeSearchCursor getMemCursor ( ) { return memCursor ; } public LSMBTreeCursorInitialState getSearchInitialState ( ) { return searchInitialState ; } public MultiComparator getCmp ( ) { return cmp ; } @Override public void destroy ( ) throws HyracksDataException { if ( destroyed ) { return ; } destroyed = true ; Throwable failure = DestroyUtils . destroy ( null , mutableBTreeAccessors ) ; failure = DestroyUtils . destroy ( failure , mutableBTreeOpCtxs ) ; failure = DestroyUtils . destroy ( failure , insertSearchCursor , memCursor ) ; if ( failure != null ) { throw HyracksDataException . create ( failure ) ; } } }
","failure = DestroyUtils . destroy ( failure , insertSearchCursor , memCursor ) ;
","failure = DestroyUtils.destroy(insertSearchCursor, failure); failure = DestroyUtils.destroy(memCursor, failure);
",,,"failure = DestroyUtils.destroy(insertSearchCursor, failure); failure = DestroyUtils.destroy(memCursor, failure);
",,,"public LSMBTreePointSearchCursor getInsertSearchCursor ( ) { return insertSearchCursor ; } public BTreeRangeSearchCursor getMemCursor ( ) { return memCursor ; } public LSMBTreeCursorInitialState getSearchInitialState ( ) { return searchInitialState ; } public MultiComparator getCmp ( ) { return cmp ; } @Override public void destroy ( ) throws HyracksDataException { if ( destroyed ) { return ; } destroyed = true ; Throwable failure = DestroyUtils . destroy ( null , mutableBTreeAccessors ) ; failure = DestroyUtils . destroy ( failure , mutableBTreeOpCtxs ) ; failure = DestroyUtils . destroy ( insertSearchCursor , failure ) ; failure = DestroyUtils . destroy ( memCursor , failure ) ; if ( failure != null ) { throw HyracksDataException . create ( failure ) ; } }
",,,"public LSMBTreePointSearchCursor getInsertSearchCursor ( ) { return insertSearchCursor ; } public BTreeRangeSearchCursor getMemCursor ( ) { return memCursor ; } public LSMBTreeCursorInitialState getSearchInitialState ( ) { return searchInitialState ; } public MultiComparator getCmp ( ) { return cmp ; } @Override public void destroy ( ) throws HyracksDataException { if ( destroyed ) { return ; } destroyed = true ; Throwable failure = DestroyUtils . destroy ( null , mutableBTreeAccessors ) ; failure = DestroyUtils . destroy ( failure , mutableBTreeOpCtxs ) ; failure = DestroyUtils . destroy ( insertSearchCursor , failure ) ; failure = DestroyUtils . destroy ( memCursor , failure ) ; if ( failure != null ) { throw HyracksDataException . create ( failure ) ; } } }
",,,"} public LSMBTreePointSearchCursor getInsertSearchCursor ( ) { return insertSearchCursor ; } public BTreeRangeSearchCursor getMemCursor ( ) { return memCursor ; } public LSMBTreeCursorInitialState getSearchInitialState ( ) { return searchInitialState ; } public MultiComparator getCmp ( ) { return cmp ; } @Override public void destroy ( ) throws HyracksDataException { if ( destroyed ) { return ; } destroyed = true ; Throwable failure = DestroyUtils . destroy ( null , mutableBTreeAccessors ) ; failure = DestroyUtils . destroy ( failure , mutableBTreeOpCtxs ) ; < |startfocus| > failure = DestroyUtils . destroy ( insertSearchCursor , failure ) ; failure = DestroyUtils . destroy ( memCursor , failure ) ; < |endfocus| > if ( failure != null ) { throw HyracksDataException . create ( failure ) ; } } }
",,
998,"try { while ( true ) { pageCleanerPolicy . notifyCleanCycleStart ( this ) ; int curPage = 0 ; while ( true ) { synchronized ( cachedPages ) { if ( curPage >= cachedPages . size ( ) ) { break ; } CachedPage cPage = ( CachedPage ) cachedPages . get ( curPage ) ; if ( cPage != null ) { cleanPage ( cPage , false ) ; } } curPage ++ ; } if ( shutdownStart ) { break ; } pageCleanerPolicy . notifyCleanCycleFinish ( this ) ; } curPage ++ ; } } } @Override public void close ( ) { closed = true ; fifoWriter . destroyQueue ( ) ; synchronized ( cleanerThread ) { cleanerThread . shutdownStart = true ; cleanerThread . notifyAll ( ) ; while ( ! cleanerThread . shutdownComplete ) { try { cleanerThread . wait ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } } } synchronized ( fileInfoMap ) { try {
","curPage ++ ;
","<|del|>
",,,"if (shutdownStart) { break; } pageCleanerPolicy.notifyCleanCycleFinish(this);
",,,"try { while ( true ) { pageCleanerPolicy . notifyCleanCycleStart ( this ) ; int curPage = 0 ; while ( true ) { synchronized ( cachedPages ) { if ( curPage >= cachedPages . size ( ) ) { break ; } CachedPage cPage = ( CachedPage ) cachedPages . get ( curPage ) ; if ( cPage != null ) { cleanPage ( cPage , false ) ; } } curPage ++ ; } if ( shutdownStart ) { break ; } pageCleanerPolicy . notifyCleanCycleFinish ( this ) ; } } catch ( Exception e ) { e . printStackTrace ( ) ; } finally { shutdownComplete = true ; notifyAll ( ) ; } @Override public void close ( ) { closed = true ; fifoWriter . destroyQueue ( ) ; synchronized ( cleanerThread ) { cleanerThread . shutdownStart = true ; cleanerThread . notifyAll ( ) ; while ( ! cleanerThread . shutdownComplete ) { try { cleanerThread . wait ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } } } synchronized ( fileInfoMap ) { try { // code here } catch ( IOException e ) { e . printStackTrace ( ) ; } } }
",,,"try { while ( true ) { pageCleanerPolicy . notifyCleanCycleStart ( this ) ; int curPage = 0 ; while ( true ) { synchronized ( cachedPages ) { if ( curPage >= cachedPages . size ( ) ) { break ; } CachedPage cPage = ( CachedPage ) cachedPages . get ( curPage ) ; if ( cPage != null ) { cleanPage ( cPage , false ) ; } } curPage ++ ; } if ( shutdownStart ) { break ; } pageCleanerPolicy . notifyCleanCycleFinish ( this ) ; } } catch ( Exception e ) { e . printStackTrace ( ) ; } finally { shutdownComplete = true ; notifyAll ( ) ; } @Override public void close ( ) { closed = true ; fifoWriter . destroyQueue ( ) ; synchronized ( cleanerThread ) { cleanerThread . shutdownStart = true ; cleanerThread . notifyAll ( ) ; while ( ! cleanerThread . shutdownComplete ) { try { cleanerThread . wait ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } } } synchronized ( fileInfoMap ) { try { // code here } catch ( IOException e ) { e . printStackTrace ( ) ; } } }
",,,"try { while ( true ) { pageCleanerPolicy . notifyCleanCycleStart ( this ) ; int curPage = 0 ; while ( true ) { synchronized ( cachedPages ) { if ( curPage >= cachedPages . size ( ) ) { break ; } CachedPage cPage = ( CachedPage ) cachedPages . get ( curPage ) ; if ( cPage != null ) { cleanPage ( cPage , false ) ; } } curPage ++ ; } if ( shutdownStart ) { break ; } pageCleanerPolicy . notifyCleanCycleFinish ( this ) ; } < |startfocus| > } catch ( Exception e ) { e . printStackTrace ( ) ; } finally { shutdownComplete = true ; notifyAll ( ) ; < |endfocus| > } } } @Override public void close ( ) { closed = true ; fifoWriter . destroyQueue ( ) ; synchronized ( cleanerThread ) { cleanerThread . shutdownStart = true ; cleanerThread . notifyAll ( ) ; while ( ! cleanerThread . shutdownComplete ) { try { cleanerThread . wait ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } } } synchronized ( fileInfoMap ) { try {
",,
1003,"this . argTypes = argTypes ; this . failOnArgTypeMismatch = failOnArgTypeMismatch ; } @Override public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { final IScalarEvaluator [ ] argEvals = new IScalarEvaluator [ args . length ] ; final IPointable [ ] argPtrs = new IPointable [ args . length ] ; for ( int i = 0 ; i < args . length ; i ++ ) { argEvals [ i ] = args [ i ] . createScalarEvaluator ( ctx ) ; argPtrs [ i ] = new VoidPointable ( ) ; } return new IScalarEvaluator ( ) { private static final int TABLE_FRAME_SIZE = 32768 ; private static final int TABLE_SIZE = 100 ; final ARecordVisitablePointable openRecordPointable = new ARecordVisitablePointable ( DefaultOpenFieldType . NESTED_OPEN_RECORD_TYPE ) ; final ARecordVisitablePointable [ ] argVisitablePointables ; final BitSet castRequired ; final ACastVisitor castVisitor ; final Triple < IVisitablePointable , IAType , Boolean > castVisitorArg ; final RecordBuilder outRecordBuilder = new RecordBuilder ( ) ; final BinaryEntry keyEntry = new BinaryEntry ( ) ; final BinaryEntry valEntry = new BinaryEntry ( ) ; final BinaryHashMap fieldMap =
","private static final int TABLE_FRAME_SIZE = 32768 ; private static final int TABLE_SIZE = 100 ;
","DataOutput resultOutput = new DataOutput();
",,,"final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); final DataOutput resultOutput = resultStorage.getDataOutput();
",,,"this . argTypes = argTypes ; this . failOnArgTypeMismatch = failOnArgTypeMismatch ; @Override public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { final IScalarEvaluator [ ] argEvals = new IScalarEvaluator [ args . length ] ; final IPointable [ ] argPtrs = new IPointable [ args . length ] ; for ( int i = 0 ; i < args . length ; i ++ ) { argEvals [ i ] = args [ i ] . createScalarEvaluator ( ctx ) ; argPtrs [ i ] = new VoidPointable ( ) ; } return new ScalarEvaluator ( ctx , argEvals , argPtrs ) ; } private class ScalarEvaluator implements IScalarEvaluator { private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; private final DataOutput resultOutput = resultStorage . getDataOutput ( ) ; private final ARecordVisitablePointable openRecordPointable = new ARecordVisitablePointable ( DefaultOpenFieldType . NESTED_OPEN_RECORD_TYPE ) ; private final ARecordVisitablePointable [ ] argVisitablePointables ; private final BitSet castRequired ; private final ACastVisitor castVisitor ; private final Triple < IVisitablePointable , IAType , Boolean > castVisitorArg ; private final RecordBuilder outRecordBuilder = new RecordBuilder ( ) ; private final BinaryEntry keyEntry = new BinaryEntry ( ) ; private final BinaryEntry valEntry = new BinaryEntry ( ) ; private final BinaryHashMap fieldMap ; public ScalarEvaluator ( final IHyracksTaskContext ctx , final IScalarEvaluator [ ] argEvals , final IPointable [ ] argPtrs ) throws HyracksDataException { argVisitablePointables = new ARecordVisitablePointable [ argEvals . length ] ; castRequired = new BitSet ( argEvals . length ) ; castVisitor = new ACastVisitor ( ) ; castVisitorArg = new Triple < > ( null , null , false ) ; for ( int i = 0 ; i < argEvals . length ; i ++ ) { argVisitablePointables [ i ] = new ARecordVisitablePointable ( DefaultOpenFieldType . NESTED_OPEN_RECORD_TYPE ) ; } fieldMap = new BinaryHashMap ( ctx ) ; } @Override public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { resultStorage . reset ( ) ; outRecordBuilder . reset ( ) ;
",,,"this . argTypes = argTypes ; this . failOnArgTypeMismatch = failOnArgTypeMismatch ; } @Override public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { final IScalarEvaluator [ ] argEvals = new IScalarEvaluator [ args . length ] ; final IPointable [ ] argPtrs = new IPointable [ args . length ] ; for ( int i = 0 ; i < args . length ; i ++ ) { argEvals [ i ] = args [ i ] . createScalarEvaluator ( ctx ) ; argPtrs [ i ] = new VoidPointable ( ) ; } return new IScalarEvaluator ( ) { final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; final DataOutput resultOutput = resultStorage . getDataOutput ( ) ; final ARecordVisitablePointable openRecordPointable = new ARecordVisitablePointable ( DefaultOpenFieldType . NESTED_OPEN_RECORD_TYPE ) ; final ARecordVisitablePointable [ ] argVisitablePointables ; final BitSet castRequired ; final ACastVisitor castVisitor ; final Triple < IVisitablePointable , IAType , Boolean > castVisitorArg ; final RecordBuilder outRecordBuilder = new RecordBuilder ( ) ; final BinaryEntry keyEntry = new BinaryEntry ( ) ; final BinaryEntry valEntry = new BinaryEntry ( ) ; final BinaryHashMap fieldMap = new BinaryHashMap ( ) ; { argVisitablePointables = new ARecordVisitablePointable [ args . length ] ; castRequired = new BitSet ( args . length ) ; castVisitor = new ACastVisitor ( ) ; castVisitorArg = new Triple < > ( null , null , false ) ; for ( int i = 0 ; i < args . length ; i ++ ) { argVisitablePointables [ i ] = new ARecordVisitablePointable ( DefaultOpenFieldType . NESTED_OPEN_RECORD_TYPE ) ; castRequired . set ( i , false ) ; } } @Override public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { resultStorage . reset ( ) ; resultOutput . write ( result . getByteArray ( ) , result . getStartOffset ( ) , result . getLength ( ) ) ; outRecordBuilder . reset ( ) ; fieldMap . clear ( ) ; keyEntry . reset ( ) ; valEntry . reset ( ) ; openRecordPointable . set ( result . getByteArray ( ) , result . getStartOffset ( ) , result . getLength ( ) ) ; try { for ( int i = 0 ; i < args . length ; i ++ ) { argPtrs
",,,"this . argTypes = argTypes ; this . failOnArgTypeMismatch = failOnArgTypeMismatch ; } @Override public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { final IScalarEvaluator [ ] argEvals = new IScalarEvaluator [ args . length ] ; final IPointable [ ] argPtrs = new IPointable [ args . length ] ; for ( int i = 0 ; i < args . length ; i ++ ) { argEvals [ i ] = args [ i ] . createScalarEvaluator ( ctx ) ; argPtrs [ i ] = new VoidPointable ( ) ; } return new IScalarEvaluator ( ) { < |startfocus| > final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; final DataOutput resultOutput = resultStorage . getDataOutput ( ) ; < |endfocus| > final ARecordVisitablePointable openRecordPointable = new ARecordVisitablePointable ( DefaultOpenFieldType . NESTED_OPEN_RECORD_TYPE ) ; final ARecordVisitablePointable [ ] argVisitablePointables ; final BitSet castRequired ; final ACastVisitor castVisitor ; final Triple < IVisitablePointable , IAType , Boolean > castVisitorArg ; final RecordBuilder outRecordBuilder = new RecordBuilder ( ) ; final BinaryEntry keyEntry = new BinaryEntry ( ) ; final BinaryEntry valEntry = new BinaryEntry ( ) ; final BinaryHashMap fieldMap = new BinaryHashMap ( ctx . getJobletContext ( ) . getServiceContext ( ) . getIoManager ( ) ) ;
",,
1011,"Collection < Task > tasks = joblet . getTaskMap ( ) . values ( ) ; for ( Task task : tasks ) { task . abort ( ) ; allTasks . add ( task ) ; } final JobId jobId = joblet . getJobId ( ) ; if ( dpm != null ) { dpm . abortReader ( jobId ) ; dpm . sweep ( jobId ) ; } ncs . getWorkQueue ( ) . schedule ( new CleanupJobletWork ( ncs , jobId , JobStatus . FAILURE ) ) ; } ) ; ncs . getWorkQueue ( ) . schedule ( new EnsureAllCcTasksCompleted ( ncs , ccId , abortedTasks ) ) ; } }
","ncs . getWorkQueue ( ) . schedule ( new EnsureAllCcTasksCompleted ( ncs , ccId , abortedTasks ) ) ;
","allTasks.get(allTasks.size()).awaitCompletion();
",,,"allTasks.clear();
",,,"Collection < Task > tasks = joblet . getTaskMap ( ) . values ( ) ; List < Task > allTasks = new ArrayList < > ( ) ; for ( Task task : tasks ) { task . abort ( ) ; allTasks . add ( task ) ; } final JobId jobId = joblet . getJobId ( ) ; if ( dpm != null ) { dpm . abortReader ( jobId ) ; dpm . sweep ( jobId ) ; } ncs . getWorkQueue ( ) . schedule ( new CleanupJobletWork ( ncs , jobId , JobStatus . FAILURE ) ) ; for ( int i = 0 ; i < allTasks . size ( ) ; i ++ ) { allTasks . get ( i ) . awaitCompletion ( ) ; }
",,,"Collection < Task > tasks = joblet . getTaskMap ( ) . values ( ) ; for ( Task task : tasks ) { task . abort ( ) ; allTasks . add ( task ) ; } final JobId jobId = joblet . getJobId ( ) ; if ( dpm != null ) { dpm . abortReader ( jobId ) ; dpm . sweep ( jobId ) ; } ncs . getWorkQueue ( ) . schedule ( new CleanupJobletWork ( ncs , jobId , JobStatus . FAILURE ) ) ; for ( int i = 0 ; i < allTasks . size ( ) ; i ++ ) { allTasks . get ( i ) . awaitCompletion ( ) ; }
",,,"Collection < Task > tasks = joblet . getTaskMap ( ) . values ( ) ; for ( Task task : tasks ) { task . abort ( ) ; allTasks . add ( task ) ; } final JobId jobId = joblet . getJobId ( ) ; if ( dpm != null ) { dpm . abortReader ( jobId ) ; dpm . sweep ( jobId ) ; } ncs . getWorkQueue ( ) . schedule ( new CleanupJobletWork ( ncs , jobId , JobStatus . FAILURE ) ) ; } ) ; < |startfocus| > for ( int i = 0 ; i < allTasks . size ( ) ; i ++ ) { allTasks . get ( i ) . awaitCompletion ( ) ; } < |endfocus| > } }
",,
1022,"import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static final JBuiltinType JCIRCLE = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) {
","public static final JBuiltinType JCIRCLE = new JBuiltinType ( ) {
","public static JBBuiltinType JCircleType = new JBBuiltinType() {
",,,"public static final JBuiltinType JCircleType = new JBuiltinType() {
",,,"import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { public static final JBuiltinType JBooleanType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static final JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static final JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static final JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static final JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static final JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static final JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; @Override public abstract IAType getIAType ( ) ; }
",,,"import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { public static final JBuiltinType JBooleanType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static final JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static final JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static final JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static final JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static final JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static final JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; }
",,,"import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; < |startfocus| > public static final JBuiltinType JCircleType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) {
",,
1030,"} } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static final JBuiltinType JDATETIME = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ;
","public static final JBuiltinType JDATETIME = new JBuiltinType ( ) {
","public static JBuiltinType JDateTimeType = new JBBuiltinType() {
",,,"public static JBuiltinType JDateTimeType = new JBuiltinType() {
",,,"public static JBuiltinType jDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType jByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType jCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType jDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType jDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType jDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType jFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ;
",,,"import org . apache . asterix . om . types . IAType ; import org . apache . commons . lang3 . mutable . Mutable ; import org . apache . hyracks . algebricks . common . exceptions . AlgebricksException ; import org . apache . hyracks . algebricks . core . algebra . base . ILogicalExpression ; import org . apache . hyracks . algebricks . core . algebra . expressions . AbstractFunctionCallExpression ; import org . apache . hyracks . algebricks . core . algebra . expressions . IVariableTypeEnvironment ; public class TypeComputeUtils { private static final byte CERTAIN = 1 ; private static final byte NULLABLE = 2 ; private static final byte MISSABLE = 4 ; private static final byte MISSING = 8 ; private static final byte NULL = 16 ; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes ( int argIndex , IAType argType ) throws AlgebricksException ; } public static interface ResultTypeGenerator { public IAType getResultType ( IAType . . . knownInputTypes ) ; } private TypeComputeUtils ( ) { } /* * * Resolve the result type of an expression . * * @param expr , the expression to consider . * @param env , the type environment . * @param checker , the argument type checker . * @param resultTypeGenerator , the result type generator . */ public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) {
",,,"} } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; < |startfocus| > public static JBuiltinType jDateTimeType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ;
",,
1035,"} } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static final JBuiltinType JDURATION = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ;
","public static final JBuiltinType JDURATION = new JBuiltinType ( ) {
","public static JBuiltinType JDurationType = new JBBuiltinType() {
",,,"public static final JBuiltinType JDurationType = new JBuiltinType() {
",,,"public class JBuiltinType { public static final JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static final JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static final JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static final JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static final JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static final JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static final JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public IAType getIAType ( ) { return null ; } }
",,,"public static final JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ;
",,,"} } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; < |startfocus| > public static final JBuiltinType JDurationType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ;
",,
1045,"} } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static final JBuiltinType JINTERVAL = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ;
","public static final JBuiltinType JINTERVAL = new JBuiltinType ( ) {
","public static JBBuiltininType JIntervalType = new JBBuiltininType() {
",,,"public static JBuiltinType JIntervalType = new JBuiltinType() {
",,,"public static JBuiltinType jIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType jDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType jFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType jIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType jLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType jLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType jMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ;
",,,"import org . apache . asterix . om . types . IAType ; import org . apache . commons . lang3 . mutable . Mutable ; import org . apache . hyracks . algebricks . common . exceptions . AlgebricksException ; import org . apache . hyracks . algebricks . core . algebra . base . ILogicalExpression ; import org . apache . hyracks . algebricks . core . algebra . expressions . AbstractFunctionCallExpression ; import org . apache . hyracks . algebricks . core . algebra . expressions . IVariableTypeEnvironment ; public class TypeComputeUtils { private static final byte CERTAIN = 1 ; private static final byte NULLABLE = 2 ; private static final byte MISSABLE = 4 ; private static final byte MISSING = 8 ; private static final byte NULL = 16 ; @FunctionalInterface public static interface ArgTypeChecker { public void checkArgTypes ( int argIndex , IAType argType ) throws AlgebricksException ; } public static interface ResultTypeGenerator { public IAType getResultType ( IAType . . . knownInputTypes ) ; } private TypeComputeUtils ( ) { } /* * * Resolve the result type of an expression . * * @param expr , the expression to consider . * @param env , the type environment . * @param checker , the argument type checker . * @param resultTypeGenerator , the result type generator . */ public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; }
",,,"} } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; < |startfocus| > public static JBuiltinType jIntervalType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ;
",,
1050,"} } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static final JBuiltinType JLONG = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ;
","public static final JBuiltinType JLONG = new JBuiltinType ( ) {
","public static JBuiltinType JLongType = new JBBuiltinType() {
",,,"public static final JBuiltinType JLongType = new JBuiltinType() {
",,,"public class JBuiltinType { public static final JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static final JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static final JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static final JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static final JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static final JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static final JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public IAType getIAType ( ) { return null ; } }
",,,"public static final JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static final JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static final JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static final JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ;
",,,"} } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; < |startfocus| > public static final JBuiltinType JLongType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ;
",,
1056,"} } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static final JBuiltinType JNULL = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ;
","public static final JBuiltinType JNULL = new JBuiltinType ( ) {
","public static JBBuiltininType JNullType = new JBBuiltinType() {
",,,"public static final JBuiltinType JNullType = new JBuiltinType() {
",,,"public static final JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static final JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static final JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static final JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static final JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static final JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static final JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ;
",,,"} } ; public static final JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static final JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static final JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static final JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static final JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static final JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static final JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ;
",,,"} } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; < |startfocus| > public static final JBuiltinType JNullType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ;
",,
1077,"} } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static final JBuiltinType JTIME = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
","public static final JBuiltinType JTIME = new JBuiltinType ( ) {
","public static JBuiltinType JTimeType = new JBBuiltinType() {
",,,"public static JBuiltinType JTimeType = new JBuiltinType() {
",,,"public class MyClass { public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; private static final JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; // Accessor method for JTimeType public static JBuiltinType getJTimeType ( ) { return JTimeType ; } }
",,,"public class MyClass { public static final JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static final JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static final JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static final JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
",,,"} } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; < |startfocus| > private static final JBuiltinType JTimeType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
",,
1079,"( ( AMutableCircle ) ( value ) ) . setValue ( ( APoint ) center . getIAObject ( ) , radius ) ; } @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { if ( writeTypeTag ) { try { dataOutput . writeByte ( ATypeTag . CIRCLE . serialize ( ) ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } ACircleSerializerDeserializer . INSTANCE . serialize ( ( AMutableCircle ) value , dataOutput ) ; } @Override public void reset ( ) { ( ( AMutableCircle ) value ) . setValue ( null , 0 ) ; } }
","ACircleSerializerDeserializer . INSTANCE . serialize ( ( AMutableCircle ) value , dataOutput ) ;
","ACircleSerializerDeserializer.INSTANCE.serialize(((AMutableCircle) (value)), dataOutput);
",,,"ACircleSerializerDeserializer.INSTANCE.serialize(((AMutableCircle) (value)), dataOutput);
",,,"AMutableCircle value = ( AMutableCircle ) value ; value . setValue ( ( APoint ) center . getIAObject ( ) , radius ) ; @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { if ( writeTypeTag ) { try { dataOutput . writeByte ( ATypeTag . CIRCLE . serialize ( ) ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } ACircleSerializerDeserializer . INSTANCE . serialize ( value , dataOutput ) ; } @Override public void reset ( ) { value . setValue ( null , 0 ) ; }
",,,"public static IValueParserFactory [ ] getValueParserFactories ( ARecordType recordType ) { int n = recordType . getFieldTypes ( ) . length ; IValueParserFactory [ ] fieldParserFactories = new IValueParserFactory [ n ] ; for ( int i = 0 ; i < n ; i ++ ) { ATypeTag tag = null ; if ( recordType . getFieldTypes ( ) [ i ] . getTypeTag ( ) == ATypeTag . UNION ) { AUnionType unionType = ( AUnionType ) recordType . getFieldTypes ( ) [ i ] ; if ( ! unionType . isNullableType ( ) ) { throw new NotImplementedException ( ""Non - optional UNION type is not supported . "" ) ; } tag = unionType . getActualType ( ) . getTypeTag ( ) ; } else { tag = recordType . getFieldTypes ( ) [ i ] . getTypeTag ( ) ; } if ( tag == null ) { throw new NotImplementedException ( ""Failed to get the type information for field "" + i + "" . "" ) ; } fieldParserFactories [ i ] = getParserFactory ( tag ) ; } return fieldParserFactories ; } if ( ! typeTag . equals ( ATypeTag . BOOLEAN ) ) { throw new AlgebricksException ( AsterixBuiltinFunctions . EDIT_DISTANCE_STRING_IS_FILTERABLE . getName ( ) + "" : expects input type BOOLEAN as fourth argument , but got "" + typeTag + "" . "" ) ; } boolean usePrePost = BooleanPointable . getBoolean ( usePrePostPtr . getByteArray ( ) , usePrePostPtr . getStartOffset ( ) + 1 ) ; long numGrams = usePrePost ? strLen + gramLen - 1 : strLen - gramLen + 1 ; long lowerBound = numGrams - edThresh * gramLen ; try { if ( lowerBound <= 0 || strLen == 0 ) { booleanSerde . serialize ( ABoolean . FALSE , output ) ; } else { booleanSerde . serialize ( ABoolean . TRUE , output ) ; } } catch ( IOException e ) { throw new AlgebricksException ( e ) ; } result . set ( resultStorage ) ; private int indexOf ( byte [ ] source , int sourceOffset , int sourceCount , byte [ ] target , int targetOffset , int targetCount , int fromIndex ) { if ( fromIndex >= sourceCount ) { return targetCount == 0 ? sourceCount : - 1 ; } int from = fromIndex ; if ( from < 0 ) { from = 0 ; } if ( targetCount ==
",,,"( ( AMutableCircle ) value ) . setValue ( ( APoint ) center . getIAObject ( ) , radius ) ; } @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { if ( writeTypeTag ) { try { dataOutput . writeByte ( ATypeTag . CIRCLE . serialize ( ) ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } < |startfocus| > ACircleSerializerDeserializer . INSTANCE . serialize ( ( ( AMutableCircle ) value ) , dataOutput ) ; < |endfocus| > } @Override public void reset ( ) { ( ( AMutableCircle ) value ) . setValue ( null , 0 ) ; } }
",,
1091,"builder . appendString ( String . valueOf ( i ) ) ; break ; } case BIGINT : { long l = AInt64SerializerDeserializer . getLong ( serString , startOffset ) ; builder . appendString ( String . valueOf ( l ) ) ; break ; } case DOUBLE : { double d = ADoubleSerializerDeserializer . getDouble ( serString , startOffset ) ; if ( Double . isNaN ( d ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( d == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; } else if ( d == Double . NEGATIVE_INFINITY ) { // NOSONAR builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( d ) ) ; } break ; } case FLOAT : { float f = AFloatSerializerDeserializer . getFloat ( serString , startOffset ) ; if ( Float . isNaN ( f ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( f == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; } else if ( f == Double . NEGATIVE_INFINITY ) {
","} else if ( d == Double . NEGATIVE_INFINITY ) { // NOSONAR
","} else if (d == Double.NEGATIVE_INFINITY) { // NOSONAR
",,,"} else if (d == Double.NEGATIVE_INFINITY) { // NOSONAR
",,,"builder . appendString ( String . valueOf ( i ) ) ; break ; } case BIGINT : { long l = AInt64SerializerDeserializer . getLong ( serString , startOffset ) ; builder . appendString ( String . valueOf ( l ) ) ; break ; } case DOUBLE : { double d = ADoubleSerializerDeserializer . getDouble ( serString , startOffset ) ; if ( Double . isNaN ( d ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( d == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; // NOSONAR } else if ( d == Double . NEGATIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( d ) ) ; } break ; } case FLOAT : { float f = AFloatSerializerDeserializer . getFloat ( serString , startOffset ) ; if ( Float . isNaN ( f ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( f == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; } else if ( f == Double . NEGATIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } // NOSONAR break ; }
",,,"builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; // NOSONAR } else { builder . appendString ( String . valueOf ( d ) ) ; } break ; } case FLOAT : { float f = AFloatSerializerDeserializer . getFloat ( serString , startOffset ) ; if ( Float . isNaN ( f ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( f == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; } else if ( f == Double . NEGATIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; // NOSONAR } else { builder . appendString ( String . valueOf ( f ) ) ; } break ; }
",,,"builder . appendString ( String . valueOf ( i ) ) ; break ; } case BIGINT : { long l = AInt64SerializerDeserializer . getLong ( serString , startOffset ) ; builder . appendString ( String . valueOf ( l ) ) ; break ; } case DOUBLE : { double d = ADoubleSerializerDeserializer . getDouble ( serString , startOffset ) ; if ( Double . isNaN ( d ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( d == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; < |startfocus| > } else if ( d == Double . NEGATIVE_INFINITY ) { < |endfocus| > builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( d ) ) ; } break ; } case FLOAT : { float f = AFloatSerializerDeserializer . getFloat ( serString , startOffset ) ; if ( Float . isNaN ( f ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( f == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; } else if ( f == Double . NEGATIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( f ) ) ; } break ; } case BOOLEAN : { boolean b = ABooleanSerializerDeserializer . getBoolean ( serString , startOffset ) ; builder . appendString ( String . valueOf ( b ) ) ; break ; } case DATETIME : { long chrononTimeInMs = ADateTimeSerializerDeserializer . getChronon ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertDatetimeToString ( chrononTimeInMs ) ) ; break ; } case DATE : { int chrononTimeInDay = ADateSerializerDeserializer . getChronon ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertDateToString ( chrononTimeInDay ) ) ; break ; } case TIME : { int chrononTimeInMs = ATimeSerializerDeserializer . getChronon ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertTimeToString ( chrononTimeInMs ) ) ; break ; } case DURATION : { long chrononDuration = ADurationSerializerDeserializer . getChrononDuration ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertDurationToString ( chrononDuration ) ) ; break ; } case YEARMONTHDURATION : { int months = AYearMonthDurationSerializerDeserializer . getYearMonth ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertYearMonthDurationToString ( months ) ) ; break ; } case DAYTIMEDURATION : { long millis = ADayTimeDurationSerializerDeserializer . getDayTime ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertDayTimeDurationToString ( millis ) ) ; break ; } case POINT : { builder . appendString ( APointSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case POINT3D : { builder . appendString ( APoint3DSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case CIRCLE : { builder . appendString ( ACircleSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case RECTANGLE : { builder . appendString ( ARectangleSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case LINE : { builder . appendString ( ALineSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case POLYGON : { builder . appendString ( APolygonSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case SYSTEM_NULL : { builder . appendString ( ANullSerializerDeserializer . NULL_STRING ) ; break ; } default : { throw new NotImplementedException ( ""Cannot convert "" + serString . getItemType ( ) + "" to string . "" ) ; } } }
",,
1102,"public static Throwable close ( AutoCloseable closable , Throwable root ) { if ( closable != null ) { try { closable . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , ""Failure closing a closeable resource"" , th ) ; } catch ( Throwable loggingFailure ) { // NOSONAR : Ignore catching Throwable // NOSONAR ignore logging failure } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
","} catch ( Throwable loggingFailure ) { // NOSONAR : Ignore catching Throwable // NOSONAR ignore logging failure
","} catch (Throwable loggingFailure) { LOGGER.warn(""Failure closing a closeable resource"", loggingFailure);
",,,"} catch (Throwable loggingFailure) { LOGGER.log(Level.WARNING, ""Failure closing a closeable resource"", loggingFailure);
",,,"public static Throwable close ( AutoCloseable closable , Throwable root ) { if ( closable != null ) { try { closable . close ( ) ; } catch ( Throwable th ) { LOGGER . log ( Level . WARN , ""Failure closing a closeable resource"" , th ) ; root = ExceptionUtils . suppress ( root , th ) ; } } return root ; }
",,,"public static Throwable close ( AutoCloseable closable , Throwable root ) { if ( closable != null ) { try { closable . close ( ) ; } catch ( Throwable th ) { root = ExceptionUtils . suppress ( root , th ) ; } } return root ; }
",,,"public static Throwable close ( AutoCloseable closable , Throwable root ) { if ( closable != null ) { try { closable . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , ""Failure closing a closeable resource"" , th ) ; < |startfocus| > } catch ( Throwable loggingFailure ) { // Do nothing < |endfocus| > } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
",,
1105,"boolean finishConnect = false ; try { finishConnect = channel . finishConnect ( ) ; } catch ( IOException e ) { key . cancel ( ) ; synchronized ( connectionListener ) { connectionListener . connectionFailure ( ( InetSocketAddress ) key . attachment ( ) , e ) ; } } if ( finishConnect ) { createConnection ( key , channel ) ; } } } } } catch ( Exception e ) { LOGGER . error ( ""Error in TCPEndpoint { } "" , localAddress , e ) ; } }
","LOGGER . error ( ""Error in TCPEndpoint { } "" , localAddress , e ) ;
","LOGGER.error(() -> new ParameterizedMessage(""Error in TCPEndpoint {}"", localAddress, e);
",,,"LOGGER.error(() -> new ParameterizedMessage(""Error in TCPEndpoint {}"", localAddress), e);
",,,"boolean finishConnect = false ; try { finishConnect = channel . finishConnect ( ) ; if ( finishConnect ) { createConnection ( key , channel ) ; } } catch ( IOException e ) { key . cancel ( ) ; synchronized ( connectionListener ) { connectionListener . connectionFailure ( ( InetSocketAddress ) key . attachment ( ) , e ) ; } } catch ( Exception e ) { LOGGER . error ( ( ) - > new ParameterizedMessage ( ""Error in TCPEndpoint { } "" , localAddress ) , e ) ; }
",,,"boolean finishConnect = false ; try { finishConnect = channel . finishConnect ( ) ; } catch ( IOException e ) { key . cancel ( ) ; synchronized ( connectionListener ) { connectionListener . connectionFailure ( ( InetSocketAddress ) key . attachment ( ) , e ) ; } } if ( finishConnect ) { createConnection ( key , channel ) ; } } catch ( Exception e ) { LOGGER . error ( ( ) - > new ParameterizedMessage ( ""Error in TCPEndpoint { } "" , localAddress ) , e ) ; }
",,,"boolean finishConnect = false ; try { finishConnect = channel . finishConnect ( ) ; } catch ( IOException e ) { key . cancel ( ) ; synchronized ( connectionListener ) { connectionListener . connectionFailure ( ( InetSocketAddress ) key . attachment ( ) , e ) ; } } if ( finishConnect ) { createConnection ( key , channel ) ; } } } } } catch ( Exception e ) { LOGGER . error ( ( ) - > new ParameterizedMessage ( ""Error in TCPEndpoint { } "" , localAddress ) , e ) ; } }
",,
1116,"throws Exception { flushPartition ( dslLifecycleMgr , lsmBtree , DATASET , async ) ; } public static void flushPartition ( IDatasetLifecycleManager dslLifecycleMgr , TestLsmBtree lsmBtree , Dataset dataset , boolean async ) throws Exception { waitForOperations ( lsmBtree ) ; PrimaryIndexOperationTracker opTracker = ( PrimaryIndexOperationTracker ) lsmBtree . getOperationTracker ( ) ; opTracker . setFlushOnExit ( true ) ; opTracker . flushIfNeeded ( ) ; long maxWaitTime = 60000L ; // 1min // wait for log record is flushed , i . e . , the flush is scheduled long before = System . nanoTime ( ) ; while ( opTracker . isFlushLogCreated ( ) ) { Thread . sleep ( 5 ) ; // NOSONAR : Test code with a timeout if ( System . currentTimeMillis ( ) - before > maxWaitTime ) { throw new IllegalStateException ( ( System . currentTimeMillis ( ) - before ) + ""ms passed without scheduling the flush operation"" ) ; } } if ( ! async ) { DatasetInfo dsInfo = dslLifecycleMgr . getDatasetInfo ( dataset . getDatasetId ( ) ) ; dsInfo . waitForIO ( ) ; } }
","long before = System . nanoTime ( ) ;
","long before = System.nanoTime();
",,,"long before = System.nanoTime();
",,,"throws Exception { flushPartition ( dslLifecycleMgr , lsmBtree , DATASET , async ) ; } public static void flushPartition ( IDatasetLifecycleManager dslLifecycleMgr , TestLsmBtree lsmBtree , Dataset dataset , boolean async ) throws Exception { waitForOperations ( lsmBtree ) ; PrimaryIndexOperationTracker opTracker = ( PrimaryIndexOperationTracker ) lsmBtree . getOperationTracker ( ) ; opTracker . setFlushOnExit ( true ) ; opTracker . flushIfNeeded ( ) ; long maxWaitTime = TimeUnit . SECONDS . toNanos ( 60 ) ; // 1min long before = System . nanoTime ( ) ; while ( opTracker . isFlushLogCreated ( ) ) { Thread . sleep ( 5 ) ; // NOSONAR : Test code with a timeout if ( System . nanoTime ( ) - before > maxWaitTime ) { throw new IllegalStateException ( TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - before ) + ""ms passed without scheduling the flush operation"" ) ; } } if ( ! async ) { DatasetInfo dsInfo = dslLifecycleMgr . getDatasetInfo ( dataset . getDatasetId ( ) ) ; dsInfo . waitForIO ( ) ; } }
",,,"public void flushPartition ( IDatasetLifecycleManager dslLifecycleMgr , TestLsmBtree lsmBtree , Dataset dataset , boolean async ) throws Exception { waitForOperations ( lsmBtree ) ; PrimaryIndexOperationTracker opTracker = ( PrimaryIndexOperationTracker ) lsmBtree . getOperationTracker ( ) ; opTracker . setFlushOnExit ( true ) ; opTracker . flushIfNeeded ( ) ; long maxWaitTime = 60000L ; // 1min long before = System . nanoTime ( ) ; while ( opTracker . isFlushLogCreated ( ) ) { Thread . sleep ( 5 ) ; if ( System . nanoTime ( ) - before > maxWaitTime * 1000000 ) { throw new IllegalStateException ( ( System . nanoTime ( ) - before ) + ""ns passed without scheduling the flush operation"" ) ; } } if ( ! async ) { DatasetInfo dsInfo = dslLifecycleMgr . getDatasetInfo ( dataset . getDatasetId ( ) ) ; dsInfo . waitForIO ( ) ; } }
",,,"throws Exception { flushPartition ( dslLifecycleMgr , lsmBtree , DATASET , async ) ; } public static void flushPartition ( IDatasetLifecycleManager dslLifecycleMgr , TestLsmBtree lsmBtree , Dataset dataset , boolean async ) throws Exception { waitForOperations ( lsmBtree ) ; PrimaryIndexOperationTracker opTracker = ( PrimaryIndexOperationTracker ) lsmBtree . getOperationTracker ( ) ; opTracker . setFlushOnExit ( true ) ; opTracker . flushIfNeeded ( ) ; long maxWaitTime = 60000L ; // 1min // wait for log record is flushed , i . e . , the flush is scheduled < |startfocus| > long before = System . nanoTime ( ) ; < |endfocus| > while ( opTracker . isFlushLogCreated ( ) ) { Thread . sleep ( 5 ) ; // NOSONAR : Test code with a timeout if ( System . nanoTime ( ) - before > maxWaitTime ) { throw new IllegalStateException ( ( System . nanoTime ( ) - before ) + ""ms passed without scheduling the flush operation"" ) ; } } if ( ! async ) { DatasetInfo dsInfo = dslLifecycleMgr . getDatasetInfo ( dataset . getDatasetId ( ) ) ; dsInfo . waitForIO ( ) ; } }
",,
1120,"* * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * ""AS IS"" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . asterix . external . api ; import java . io . DataOutput ; import org . apache . asterix . om . base . IAObject ; import org . apache . asterix . om . types . IAType ; import org . apache . hyracks . api . exceptions . HyracksDataException ; public interface IJObject { IAType getIAType ( ) ; IAObject getIAObject ( ) ; void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException ; void reset ( ) throws HyracksDataException ; }
","< |del| > import org . apache . asterix . om . types . ATypeTag ;
","<|del|>
",,,"<|del|>
",,,"package org . apache . asterix . external . api ; import java . io . DataOutput ; import org . apache . asterix . om . base . IAObject ; import org . apache . asterix . om . types . IAType ; import org . apache . hyracks . api . exceptions . HyracksDataException ; public interface IJObject { IAType getIAType ( ) ; IAObject getIAObject ( ) ; void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException ; void reset ( ) throws HyracksDataException ; }
",,,"package org . apache . asterix . external . api ; import java . io . DataOutput ; import org . apache . asterix . om . base . IAObject ; import org . apache . asterix . om . types . IAType ; import org . apache . hyracks . api . exceptions . HyracksDataException ; public interface IJObject { IAType getIAType ( ) ; IAObject getIAObject ( ) ; void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException ; void reset ( ) throws HyracksDataException ; }
",,,"* * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * ""AS IS"" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . asterix . external . api ; import java . io . DataOutput ; import org . apache . asterix . om . base . IAObject ; import org . apache . asterix . om . types . ATypeTag ; import org . apache . asterix . om . types . IAType ; import org . apache . hyracks . api . exceptions . HyracksDataException ; public interface IJObject { IAType getIAType ( ) ; IAObject getIAObject ( ) ; void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException ; void reset ( ) throws HyracksDataException ; }
",,
1139,"IOperatorNodePushable operatorNodePushable = operatorNodePushables . get ( activityIdInputIndex . getLeft ( ) ) ; return operatorNodePushable . getInputFrameWriter ( activityIdInputIndex . getRight ( ) ) ; } @Override public String getDisplayName ( ) { return ""Super Activity "" + parent . getActivityMap ( ) . values ( ) . toString ( ) ; } @FunctionalInterface interface OperatorNodePushableAction { void run ( IOperatorNodePushable op ) throws HyracksDataException ; } @SuppressWarnings ( ""unchecked"" ) private void runInParallel ( OperatorNodePushableAction action ) throws HyracksDataException { List < Future < Void > > tasks = new ArrayList < > ( operatorNodePushablesBFSOrder . size ( ) ) ; Queue < Throwable > failures = new ArrayBlockingQueue < > ( operatorNodePushablesBFSOrder . size ( ) ) ; final Semaphore startSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; final Semaphore completeSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; int completed = 0 ; Throwable root = null ; try { for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { final int current = i ; tasks [ i ] = ctx . getExecutorService ( ) . submit ( ( ) - > { startSemaphore . release ( ) ; try {
","List < Future < Void > > tasks = new ArrayList < > ( operatorNodePushablesBFSOrder . size ( ) ) ; Queue < Throwable > failures = new ArrayBlockingQueue < > ( operatorNodePushablesBFSOrder . size ( ) ) ;
","Future<Void> tasks = new Future[operatorNodePushablesBFSOrder.size()]; Throwable[] failures = new Throwable[operatorNodePushablesBFSOrder.size()];
",,,"Future<Void>[] tasks = new Future[operatorNodePushablesBFSOrder.size()]; Throwable[] failures = new Throwable[operatorNodePushablesBFSOrder.size()];
",,,"IOperatorNodePushable operatorNodePushable = operatorNodePushables . get ( activityIdInputIndex . getLeft ( ) ) ; return operatorNodePushable . getInputFrameWriter ( activityIdInputIndex . getRight ( ) ) ; @Override public String getDisplayName ( ) { return ""Super Activity "" + parent . getActivityMap ( ) . values ( ) . toString ( ) ; } @FunctionalInterface interface OperatorNodePushableAction { void run ( IOperatorNodePushable op ) throws HyracksDataException ; } @SuppressWarnings ( ""unchecked"" ) private void runInParallel ( OperatorNodePushableAction action ) throws HyracksDataException { Future < Void > [ ] tasks = new Future [ operatorNodePushablesBFSOrder . size ( ) ] ; Throwable [ ] failures = new Throwable [ operatorNodePushablesBFSOrder . size ( ) ] ; final Semaphore startSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; final Semaphore completeSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; int completed = 0 ; Throwable root = null ; try { for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { final int current = i ; tasks [ i ] = ctx . getExecutorService ( ) . submit ( ( ) - > { startSemaphore . release ( ) ; try { action . run ( operatorNodePushablesBFSOrder . get ( current ) ) ; } catch ( Throwable th ) { failures [ current ] = th ; root = ExceptionUtils . getRootCause ( th ) ; } finally { completeSemaphore . release ( ) ; } return null ; } ) ; } startSemaphore . acquire ( ) ; for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { completeSemaphore . acquire ( ) ; if ( root != null ) { for ( Future < Void > task : tasks ) { task . cancel ( true ) ; } throw new HyracksDataException ( root ) ; } } } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; throw new HyracksDataException ( e ) ; } finally { for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { if ( ! tasks [ i ] . isDone ( ) ) { tasks [ i ] . cancel ( true ) ; } } } }
",,,"IOperatorNodePushable operatorNodePushable = operatorNodePushables . get ( activityIdInputIndex . getLeft ( ) ) ; return operatorNodePushable . getInputFrameWriter ( activityIdInputIndex . getRight ( ) ) ; } @Override public String getDisplayName ( ) { return ""Super Activity "" + parent . getActivityMap ( ) . values ( ) . toString ( ) ; } @FunctionalInterface interface OperatorNodePushableAction { void run ( IOperatorNodePushable op ) throws HyracksDataException ; } @SuppressWarnings ( ""unchecked"" ) private void runInParallel ( OperatorNodePushableAction action ) throws HyracksDataException { Future < Void > [ ] tasks = new Future [ operatorNodePushablesBFSOrder . size ( ) ] ; Throwable [ ] failures = new Throwable [ operatorNodePushablesBFSOrder . size ( ) ] ; final Semaphore startSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; final Semaphore completeSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; int completed = 0 ; Throwable root = null ; try { for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { final int current = i ; tasks [ i ] = ctx . getExecutorService ( ) . submit ( ( ) - > { startSemaphore . release ( ) ; try { action . run ( operatorNodePushablesBFSOrder . get ( current ) ) ; } catch ( Throwable th ) { failures [ current ] = th ; } finally { completeSemaphore . release ( ) ; } return null ; } ) ; } startSemaphore . acquire ( ) ; for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { completeSemaphore . acquire ( ) ; } for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { if ( failures [ i ] != null ) { if ( root == null ) { root = failures [ i ] ; } else { root . addSuppressed ( failures [ i ] ) ; } } } if ( root != null ) { throw HyracksDataException . create ( root ) ; } } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; throw HyracksDataException . create ( e ) ; } }
",,,"IOperatorNodePushable operatorNodePushable = operatorNodePushables . get ( activityIdInputIndex . getLeft ( ) ) ; return operatorNodePushable . getInputFrameWriter ( activityIdInputIndex . getRight ( ) ) ; } @Override public String getDisplayName ( ) { return ""Super Activity "" + parent . getActivityMap ( ) . values ( ) . toString ( ) ; } @FunctionalInterface interface OperatorNodePushableAction { void run ( IOperatorNodePushable op ) throws HyracksDataException ; } @SuppressWarnings ( ""unchecked"" ) private void runInParallel ( OperatorNodePushableAction action ) throws HyracksDataException { < |startfocus| > Future < Void > [ ] tasks = new Future [ operatorNodePushablesBFSOrder . size ( ) ] ; Throwable [ ] failures = new Throwable [ operatorNodePushablesBFSOrder . size ( ) ] ; < |endfocus| > final Semaphore startSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; final Semaphore completeSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; int completed = 0 ; Throwable root = null ; try { for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { final int current = i ; tasks [ i ] = ctx . getExecutorService ( ) . submit ( ( ) - > { startSemaphore . release ( ) ; try { < |startfocus| >
",,
1157,"initializationTasks . add ( ctx . getExecutorService ( ) . submit ( new Callable < Void > ( ) { @Override public Void call ( ) throws Exception { opAction . runAction ( op , opIndex ) ; return null ; } } ) ) ; } // Waits until all parallel actions to finish . for ( Future < Void > initializationTask : initializationTasks ) { initializationTask . get ( ) ; } } catch ( Throwable th ) { for ( Future < Void > initializationTask : initializationTasks ) { initializationTask . cancel ( true ) ; } } finally { completeSemaphore . acquireUninterruptibly ( ) ; } } }
","} finally { completeSemaphore . acquireUninterruptibly ( ) ;
","throw HyracksDataException.create(th);
",,,"<|del|>
",,,"initializationTasks . forEach ( task - > ctx . getExecutorService ( ) . submit ( ( ) - > { opAction . runAction ( op , opIndex ) ; } ) ) ; ExceptionUtils . suppress ( root , failures ) ;
",,,"initializationTasks . add ( ctx . getExecutorService ( ) . submit ( ( ) - > { opAction . runAction ( op , opIndex ) ; return null ; } ) ) ; // Waits until all parallel actions to finish . for ( Future < Void > initializationTask : initializationTasks ) { initializationTask . get ( ) ; } } catch ( Throwable th ) { for ( Future < Void > initializationTask : initializationTasks ) { initializationTask . cancel ( true ) ; } throw new HyracksDataException ( th ) ; } }
",,,"initializationTasks . add ( ctx . getExecutorService ( ) . submit ( new Callable < Void > ( ) { @Override public Void call ( ) throws Exception { opAction . runAction ( op , opIndex ) ; return null ; } } ) ) ; } // Waits until all parallel actions to finish . for ( Future < Void > initializationTask : initializationTasks ) { initializationTask . get ( ) ; } } catch ( Throwable th ) { for ( Future < Void > initializationTask : initializationTasks ) { initializationTask . cancel ( true ) ; } < |startfocus| > throw new HyracksDataException ( th ) ; < |endfocus| > } } }
",,
1169,"* log files that end with LSN < { @code checkpointTargetLSN } are deleted . */ @Override public synchronized long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException { LOGGER . info ( ""Attemping soft checkpoint . . . "" ) ; final long minFirstLSN = txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ; final long minSecuredLSN = getMinSecuredLSN ( ) ; if ( minSecuredLSN != NO_SECURED_LSN && minFirstLSN >= getMinSecuredLSN ( ) ) { return minSecuredLSN ; } boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN ; if ( ! checkpointSucceeded ) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; } capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( ""soft checkpoint succeeded at LSN ( % s ) "" , minFirstLSN ) ) ; } return minFirstLSN ; } private synchronized long getMinSecuredLSN ( ) {
","if ( minSecuredLSN != NO_SECURED_LSN && minFirstLSN >= getMinSecuredLSN ( ) ) { return minSecuredLSN ;
","if (minSecuredLSN != -1 && minFirstLSN >= getMinSecuredLSN()) { return minFirstLSN;
",,,"if (minSecuredLSN != -1 && minFirstLSN >= getMinSecuredLSN(checkpointTargetLSN)) { return minSecuredLSN;
",,,"@Override public synchronized long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException { LOGGER . info ( ""Attempting soft checkpoint . . . "" ) ; final long minFirstLSN = txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ; final long minSecuredLSN = getMinSecuredLSN ( ) ; if ( checkpointTargetLSN >= minSecuredLSN ) { return minSecuredLSN ; } if ( minSecuredLSN != - 1 && minFirstLSN >= minSecuredLSN ) { return minFirstLSN ; } boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN ; if ( ! checkpointSucceeded ) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; } capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( ""Soft checkpoint succeeded at LSN ( % s ) "" , minFirstLSN ) ) ; } return minFirstLSN ; } private synchronized long getMinSecuredLSN ( ) { // implementation }
",,,"@Override public synchronized long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException { LOGGER . info ( ""Attempting soft checkpoint . . . "" ) ; final long minFirstLSN = txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ; final long minSecuredLSN = getMinSecuredLSN ( ) ; if ( checkpointTargetLSN >= minSecuredLSN ) { return minSecuredLSN ; } boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN ; if ( ! checkpointSucceeded ) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; } capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( ""Soft checkpoint succeeded at LSN ( % s ) "" , minFirstLSN ) ) ; } return minFirstLSN ; } private synchronized long getMinSecuredLSN ( ) { // implementation omitted }
",,,"* log files that end with LSN < { @code checkpointTargetLSN } are deleted . */ @Override public synchronized long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException { LOGGER . info ( ""Attemping soft checkpoint . . . "" ) ; final long minFirstLSN = txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ; final long minSecuredLSN = getMinSecuredLSN ( ) ; < |startfocus| > if ( minSecuredLSN != - 1 && minFirstLSN >= getMinSecuredLSN ( ) ) { return minFirstLSN ; < |endfocus| > } boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN ; if ( ! checkpointSucceeded ) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; } capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( ""soft checkpoint succeeded at LSN ( % s ) "" , minFirstLSN ) ) ; } return minFirstLSN ; } private synchronized long getMinSecuredLSN ( ) {
",,
1170,"IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; } capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( ""soft checkpoint succeeded at LSN ( % s ) "" , minFirstLSN ) ) ; } return minFirstLSN ; } private synchronized long getMinSecuredLSN ( ) { return securedLSNs . isEmpty ( ) ? NO_SECURED_LSN : Collections . min ( securedLSNs . values ( ) ) ; } @Override public synchronized void secure ( TxnId id ) throws HyracksDataException { securedLSNs . put ( id , txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ) ; } @Override public synchronized void completed ( TxnId id ) { securedLSNs . remove ( id ) ; } }
","return securedLSNs . isEmpty ( ) ? NO_SECURED_LSN : Collections . min ( securedLSNs . values ( ) ) ;
","return securedTxn.values().stream().min(Long::compareTo).orElse(Long.MAX_VALUE);
",,,"return securedLSNs.isEmpty() ? Long.MAX_VALUE : securedLSNs.values().stream().min(Long::compareTo).orElse(Long.MAX_VALUE);
",,,"IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( ""soft checkpoint succeeded at LSN ( % s ) "" , minFirstLSN ) ) ; } return minFirstLSN ; private synchronized long getMinSecuredLSN ( ) { return securedLSNs . isEmpty ( ) ? - 1 : Collections . min ( securedLSNs . values ( ) ) ; } @Override public synchronized void secure ( TxnId id ) throws HyracksDataException { securedLSNs . put ( id , txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ) ; } @Override public synchronized void completed ( TxnId id ) { securedLSNs . remove ( id ) ; } private static final long DEFAULT_MIN_LSN = - 1 ; private synchronized long getMinSecuredLSN ( ) { return securedLSNs . isEmpty ( ) ? DEFAULT_MIN_LSN : Collections . min ( securedLSNs . values ( ) ) ; } @Override public synchronized void secure ( TxnId id ) throws HyracksDataException { securedLSNs . put ( id , txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ) ; } @Override public synchronized void completed ( TxnId id ) { securedLSNs . remove ( id ) ; }
",,,"IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( ""soft checkpoint succeeded at LSN ( % s ) "" , minFirstLSN ) ) ; } return minFirstLSN ; private synchronized long getMinSecuredLSN ( ) { return securedLSNs . isEmpty ( ) ? - 1 : Collections . min ( securedLSNs . values ( ) ) ; } @Override public synchronized void secure ( TxnId id ) throws HyracksDataException { securedLSNs . put ( id , txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ) ; } @Override public synchronized void completed ( TxnId id ) { securedLSNs . remove ( id ) ; }
",,,"IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; } capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( ""soft checkpoint succeeded at LSN ( % s ) "" , minFirstLSN ) ) ; } return minFirstLSN ; } private synchronized long getMinSecuredLSN ( ) { < |startfocus| > return securedLSNs . isEmpty ( ) ? Long . MAX_VALUE : Collections . min ( securedLSNs . values ( ) ) ; < |endfocus| > } @Override public synchronized void secure ( TxnId id ) throws HyracksDataException { securedLSNs . put ( id , txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ) ; } @Override public synchronized void completed ( TxnId id ) { securedLSNs . remove ( id ) ; } }
",,
1173,"&& data [ dataStart + timezoneEndField ] <= 'Z' ) || data [ dataStart + timezoneEndField ] == ' / ' || data [ dataStart + timezoneEndField ] == '_' ) ) { timezoneEndField ++ ; } int searchIdx = binaryTimezoneIDSearch ( data , dataStart + dataStringPointer , timezoneEndField - dataStringPointer ) ; if ( searchIdx >= 0 ) { timezone = TIMEZONE_OFFSETS [ searchIdx ] ; } else { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Unexpected timezone string : "" + new String ( data , dataStart + dataStringPointer , dataStart + timezoneEndField , ENCODING ) ) ; } else { return false ; } } dataStringPointer = timezoneEndField ; } timezoneExists = true ; break ; case AMPM : if ( dataStringPointer + 1 < dataLength ) { if ( hour > 12 || hour <= 0 ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Hour "" + hour + "" cannot be a time for AM / PM . "" ) ;
","throw new AsterixTemporalTypeParseException ( ""Unexpected timezone string : "" + new String ( data , dataStart + dataStringPointer , dataStart + timezoneEndField , ENCODING ) ) ;
","throw new AsterixTemporalTypeParseException(""Unexpected timezone string: "" + decode(data, dataStart + dataStringPointer, dataStart + timezoneEndField));
",,,"throw new AsterixTemporalTypeParseException(""Unexpected timezone string: "" + decode(data, dataStart + dataStringPointer, dataStart + timezoneEndField));
",,,"if ( data [ dataStart + timezoneEndField ] == ' + ' || data [ dataStart + timezoneEndField ] == ' - ' || ( data [ dataStart + timezoneEndField ] >= 'A' && data [ dataStart + timezoneEndField ] <= 'Z' ) || data [ dataStart + timezoneEndField ] == ' / ' || data [ dataStart + timezoneEndField ] == '_' ) { timezoneEndField ++ ; } int searchIdx = binaryTimezoneIDSearch ( data , dataStart + dataStringPointer , timezoneEndField - dataStringPointer ) ; if ( searchIdx >= 0 ) { timezone = TIMEZONE_OFFSETS [ searchIdx ] ; } else { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Unexpected timezone string : "" + decode ( data , dataStart + dataStringPointer , dataStart + timezoneEndField ) ) ; } else { return false ; } } dataStringPointer = timezoneEndField ; timezoneExists = true ; if ( dataStringPointer + 1 < dataLength && ( hour > 12 || hour <= 0 ) ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Hour "" + hour + "" cannot be a time for AM / PM . "" ) ; } else { return false ; } } break ;
",,,"&& data [ dataStart + timezoneEndField ] <= 'Z' ) || data [ dataStart + timezoneEndField ] == ' / ' || data [ dataStart + timezoneEndField ] == '_' ) { timezoneEndField ++ ; } int searchIdx = binaryTimezoneIDSearch ( data , dataStart + dataStringPointer , timezoneEndField - dataStringPointer ) ; if ( searchIdx >= 0 ) { timezone = TIMEZONE_OFFSETS [ searchIdx ] ; } else { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Unexpected timezone string : "" + decode ( data , dataStart + dataStringPointer , dataStart + timezoneEndField ) ) ; } else { return false ; } } dataStringPointer = timezoneEndField ; timezoneExists = true ; break ; case AMPM : if ( dataStringPointer + 1 < dataLength ) { if ( hour > 12 || hour <= 0 ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Hour "" + hour + "" cannot be a time for AM / PM . "" ) ; } else { return false ; } } char ampm = data [ dataStart + dataStringPointer ] ; if ( ampm == 'A' || ampm == 'a' ) { if ( hour == 12 ) { hour = 0 ; } } else if ( ampm == 'P' || ampm == 'p' ) { if ( hour < 12 ) { hour += 12 ; } } else { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Invalid AM / PM indicator : "" + ampm ) ; } else { return false ; } } dataStringPointer ++ ; break ; }
",,,"&& data [ dataStart + timezoneEndField ] <= 'Z' ) || data [ dataStart + timezoneEndField ] == ' / ' || data [ dataStart + timezoneEndField ] == '_' ) ) { timezoneEndField ++ ; } int searchIdx = binaryTimezoneIDSearch ( data , dataStart + dataStringPointer , timezoneEndField - dataStringPointer ) ; if ( searchIdx >= 0 ) { timezone = TIMEZONE_OFFSETS [ searchIdx ] ; } else { if ( raiseParseDataError ) { < |startfocus| > throw new AsterixTemporalTypeParseException ( ""Unexpected timezone string : "" + decode ( data , dataStart + dataStringPointer , dataStart + timezoneEndField ) ) ; < |endfocus| > } else { return false ; } } dataStringPointer = timezoneEndField ; } timezoneExists = true ; break ; case AMPM : if ( dataStringPointer + 1 < dataLength ) { if ( hour > 12 || hour <= 0 ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Hour "" + hour + "" cannot be a time for AM / PM . "" ) ; } else { return false ; } } if ( data [ dataStart + dataStringPointer ] == 'A' ) { if ( hour == 12 ) { hour = 0 ; } } else if ( data [ dataStart + dataStringPointer ] == 'P' ) { if ( hour != 12 ) { hour += 12 ; } } else { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Unexpected AM / PM string : "" + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 1 ) ) ; } else { return false ; } } dataStringPointer ++ ; } break ; case HOUR_OF_DAY : if ( dataStringPointer + 1 < dataLength ) { if ( data [ dataStart + dataStringPointer ] == '2' && data [ dataStart + dataStringPointer + 1 ] == '4' ) { hour = 0 ; dataStringPointer += 2 ; } else { if ( data [ dataStart + dataStringPointer ] < '0' || data [ dataStart + dataStringPointer ] > '9' || data [ dataStart + dataStringPointer + 1 ] < '0' || data [ dataStart + dataStringPointer + 1 ] > '9' ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Unexpected hour string : "" + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 2 ) ) ; } else { return false ; } } hour = ( data [ dataStart + dataStringPointer ] - '0' ) * 10 + ( data [ dataStart + dataStringPointer + 1 ] - '0' ) ; dataStringPointer += 2 ; } } break ; case MINUTE : if ( dataStringPointer + 1 < dataLength ) { if ( data [ dataStart + dataStringPointer ] < '0' || data [ dataStart + dataStringPointer ] > '9' || data [ dataStart + dataStringPointer + 1 ] < '0' || data [ dataStart + dataStringPointer + 1 ] > '9' ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Unexpected minute string : "" + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 2 ) ) ; } else { return false ; } } minute = ( data [ dataStart + dataStringPointer ] - '0' ) * 10 + ( data [ dataStart + dataStringPointer + 1 ] - '0' ) ; dataStringPointer += 2 ; } break ; case SECOND : if ( dataStringPointer + 1 < dataLength ) { if ( data [ dataStart + dataStringPointer ] < '0' || data [ dataStart + dataStringPointer ] > '9' || data [ dataStart + dataStringPointer + 1 ] < '0' || data [ dataStart + dataStringPointer + 1 ] > '9' ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Unexpected second string : "" + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 2 ) ) ; } else { return false ; } } second = ( data [ dataStart + dataStringPointer ] - '0' ) * 10 + ( data [ dataStart + dataStringPointer + 1 ] - '0' ) ; dataStringPointer += 2 ; } break ; case MILLISECOND : if ( dataStringPointer + 2 < dataLength ) { if ( data [ dataStart + dataStringPointer ] < '0' || data [ dataStart + dataStringPointer ] > '9' || data [ dataStart + dataStringPointer + 1 ] < '0' || data [ dataStart + dataStringPointer + 1 ] > '9' || data [ dataStart + dataStringPointer + 2 ] < '0' || data [ dataStart + dataStringPointer + 2 ] > '9' ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( ""Unexpected millisecond string : "" + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 3 ) ) ; } else { return false ; } } millisecond = ( data [ dataStart + dataStringPointer ] - '0' ) * 100 + ( data [ dataStart + dataStringPointer + 1 ] - '0' ) * 10 + ( data [ dataStart + dataStringPointer + 2 ] - '0' ) ; dataStringPointer += 3 ; } break ; } } }
",,
1180,"for ( int i = 0 ; i < end ; i ++ ) { if ( bloomFilters [ i ] != null && ! bloomFilters [ i ] . contains ( keysOnlyTuple , hashes ) ) { continue ; } deletedKeysBTreeAccessors . get ( i ) . search ( deletedKeysBTreeCursors [ i ] , keySearchPred ) ; try { if ( deletedKeysBTreeCursors [ i ] . hasNext ( ) ) { return true ; } } finally { deletedKeysBTreeCursors [ i ] . close ( ) ; } } return false ; } @Override public void doClose ( ) throws HyracksDataException { try { super . doClose ( ) ; } finally { if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } } == == == = if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } super . doClose ( ) ; > > > > > > > initial commit } @Override public void doDestroy ( ) throws HyracksDataException {
","< |del| > < < < < < < < HEAD
","<|del|>
",,,"<|del|>
",,,"for ( int i = 0 ; i < end ; i ++ ) { if ( bloomFilters [ i ] != null && ! bloomFilters [ i ] . contains ( keysOnlyTuple , hashes ) ) { continue ; } deletedKeysBTreeAccessors . get ( i ) . search ( deletedKeysBTreeCursors [ i ] , keySearchPred ) ; try { if ( deletedKeysBTreeCursors [ i ] . hasNext ( ) ) { return true ; } } finally { deletedKeysBTreeCursors [ i ] . close ( ) ; } } return false ; @Override public void doClose ( ) throws HyracksDataException { if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } super . doClose ( ) ; } @Override public void doDestroy ( ) throws HyracksDataException { if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } super . doDestroy ( ) ; }
",,,"for ( int i = 0 ; i < end ; i ++ ) { if ( bloomFilters [ i ] != null && ! bloomFilters [ i ] . contains ( keysOnlyTuple , hashes ) ) { continue ; } deletedKeysBTreeAccessors . get ( i ) . search ( deletedKeysBTreeCursors [ i ] , keySearchPred ) ; try { if ( deletedKeysBTreeCursors [ i ] . hasNext ( ) ) { return true ; } } finally { deletedKeysBTreeCursors [ i ] . close ( ) ; } } return false ; } @Override public void doClose ( ) throws HyracksDataException { try { super . doClose ( ) ; } finally { if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } } } @Override public void doDestroy ( ) throws HyracksDataException { if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } super . doClose ( ) ; }
",,,"for ( int i = 0 ; i < end ; i ++ ) { if ( bloomFilters [ i ] != null && ! bloomFilters [ i ] . contains ( keysOnlyTuple , hashes ) ) { continue ; } deletedKeysBTreeAccessors . get ( i ) . search ( deletedKeysBTreeCursors [ i ] , keySearchPred ) ; try { if ( deletedKeysBTreeCursors [ i ] . hasNext ( ) ) { return true ; } } finally { deletedKeysBTreeCursors [ i ] . close ( ) ; } } return false ; } @Override public void doClose ( ) throws HyracksDataException { < |startfocus| > < < < < < < < HEAD < |endfocus| > try { super . doClose ( ) ; } finally { if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } } == == == = if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } super . doClose ( ) ; > > > > > > > initial commit } @Override public void doDestroy ( ) throws HyracksDataException { < |startfocus| > < < < < < < < HEAD < |endfocus| > try { super . doDestroy ( ) ; } finally { if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } } == == == = if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } super . doDestroy ( ) ; > > > > > > > initial commit }
",,
1187,"} while ( triggerCount == previousTriggerCount ) ; return triggerCount ; } /* * * Test time - based invalidation in CatalogdTableInvalidator . */ @Test public void testCatalogdTableInvalidator ( ) throws CatalogException , InterruptedException { Reference < Boolean > tblWasRemoved = new Reference < > ( ) ; Reference < Boolean > dbWasAdded = new Reference < > ( ) ; String dbName = ""functional"" ; String tblName = ""alltypes"" ; catalog_ . invalidateTable ( new TTableName ( dbName , tblName ) , tblWasRemoved , dbWasAdded ) ; MockTicker ticker = new MockTicker ( ) ; CatalogdTableInvalidator . TIME_SOURCE = ticker ; catalog_ . setCatalogdTableInvalidator ( new CatalogdTableInvalidator ( catalog_ , /* unusedTableTtlSec =* / 2 , /* invalidateTablesOnMemoryPressure =* / false , /* oldGenFullThreshold =* / 0 . 6 , /* gcInvalidationFraction =* / 0 . 1 ) ) ; Assert . assertFalse ( catalog_ . getDb ( dbName ) . getTable ( tblName ) . isLoaded ( ) ) ; Table table = catalog_ . getOrLoadTable ( dbName , tblName ) ; Assert . assertTrue ( table . isLoaded ( ) ) ; Assert . assertEquals ( ticker . now_ , table . getLastUsedTime ( ) ) ; long previousTriggerCount = catalog_ . getCatalogdTableInvalidator ( ) . triggerCount_ . get ( ) ;
","catalog_ . invalidateTable ( new TTableName ( dbName , tblName ) , tblWasRemoved , dbWasAdded ) ;
","catalog_.invalidateTable(new TTableName(dbName, tblName), tblWasRemoved, dbWasAdded);
",,,"catalog_ .invalidateTable(new TTableName(dbName, tblName), tblWasRemoved, dbWasAdded);
",,,"catalog_ . invalidateTable ( new TTableName ( dbName , tblName ) , tblWasRemoved , dbWasAdded ) ; MockTicker ticker = new MockTicker ( ) ; CatalogdTableInvalidator . TIME_SOURCE = ticker ; catalog_ . setCatalogdTableInvalidator ( new CatalogdTableInvalidator ( catalog_ , /* unusedTableTtlSec =* / 2 , /* invalidateTablesOnMemoryPressure =* / false , /* oldGenFullThreshold =* / 0 . 6 , /* gcInvalidationFraction =* / 0 . 1 ) ) ; Assert . assertFalse ( catalog_ . getDb ( dbName ) . getTable ( tblName ) . isLoaded ( ) ) ; Table table = catalog_ . getOrLoadTable ( dbName , tblName ) ; Assert . assertTrue ( table . isLoaded ( ) ) ; Assert . assertEquals ( ticker . now_ , table . getLastUsedTime ( ) ) ; long previousTriggerCount = catalog_ . getCatalogdTableInvalidator ( ) . triggerCount_ . get ( ) ;
",,,"@Test public void testCatalogdTableInvalidator ( ) throws CatalogException , InterruptedException { Reference < Boolean > tblWasRemoved = new Reference < > ( ) ; Reference < Boolean > dbWasAdded = new Reference < > ( ) ; String dbName = ""functional"" ; String tblName = ""alltypes"" ; catalog_ . invalidateTable ( new TTableName ( dbName , tblName ) , tblWasRemoved , dbWasAdded ) ; MockTicker ticker = new MockTicker ( ) ; CatalogdTableInvalidator . TIME_SOURCE = ticker ; catalog_ . setCatalogdTableInvalidator ( new CatalogdTableInvalidator ( catalog_ , /* unusedTableTtlSec =* / 2 , /* invalidateTablesOnMemoryPressure =* / false , /* oldGenFullThreshold =* / 0 . 6 , /* gcInvalidationFraction =* / 0 . 1 ) ) ; Assert . assertFalse ( catalog_ . getDb ( dbName ) . getTable ( tblName ) . isLoaded ( ) ) ; Table table = catalog_ . getOrLoadTable ( dbName , tblName ) ; Assert . assertTrue ( table . isLoaded ( ) ) ; Assert . assertEquals ( ticker . now_ , table . getLastUsedTime ( ) ) ; long previousTriggerCount = catalog_ . getCatalogdTableInvalidator ( ) . triggerCount_ . get ( ) ; long triggerCount ; do { triggerCount = catalog_ . getCatalogdTableInvalidator ( ) . triggerCount_ . get ( ) ; Thread . sleep ( 100 ) ; } while ( triggerCount == previousTriggerCount ) ; Assert . assertEquals ( previousTriggerCount + 1 , triggerCount ) ; }
",,,"} while ( triggerCount == previousTriggerCount ) ; return triggerCount ; } /* * * Test time - based invalidation in CatalogdTableInvalidator . */ @Test public void testCatalogdTableInvalidator ( ) throws CatalogException , InterruptedException { Reference < Boolean > tblWasRemoved = new Reference < > ( ) ; Reference < Boolean > dbWasAdded = new Reference < > ( ) ; String dbName = ""functional"" ; String tblName = ""alltypes"" ; < |startfocus| > catalog_ . invalidateTable ( new TTableName ( dbName , tblName ) , tblWasRemoved , dbWasAdded ) ; < |endfocus| > MockTicker ticker = new MockTicker ( ) ; CatalogdTableInvalidator . TIME_SOURCE = ticker ; catalog_ . setCatalogdTableInvalidator ( new CatalogdTableInvalidator ( catalog_ , /* unusedTableTtlSec =* / 2 , /* invalidateTablesOnMemoryPressure =* / false , /* oldGenFullThreshold =* / 0 . 6 , /* gcInvalidationFraction =* / 0 . 1 ) ) ; Assert . assertFalse ( catalog_ . getDb ( dbName ) . getTable ( tblName ) . isLoaded ( ) ) ; Table table = catalog_ . getOrLoadTable ( dbName , tblName ) ; Assert . assertTrue ( table . isLoaded ( ) ) ; Assert . assertEquals ( ticker . now_ , table . getLastUsedTime ( ) ) ; long previousTriggerCount = catalog_ . getCatalogdTableInvalidator ( ) . triggerCount_ . get ( ) ;
",,
1188,"profile_ = new TRuntimeProfileNode ( ""Frontend"" , /* num_children =* / 0 , /* counters =* / new ArrayList < > ( ) , /* metadata =* /- 1L , // TODO ( todd ) what is this used for ? why is it required ? /* indent =* / false , /* info_strings =* / new HashMap < > ( ) , /* info_strings_display_order */ new ArrayList < > ( ) , /* child_counters_map =* / ImmutableMap . of ( ROOT_COUNTER_NAME , new HashSet < > ( ) ) ) ; } /* * * Create a new profile , setting it as the current thread - local profile for the * length of the current scope . This is meant to be used in a try - with - resources * statement . */ public static Scope createNewWithScope ( ) { return new Scope ( new FrontendProfile ( ) ) ; } /* * * Get the profile attached to the current thread , throw IllegalStateException if there * is none . */ @Nonnull public static FrontendProfile getCurrent ( ) { FrontendProfile prof = THREAD_LOCAL . get ( ) ; Preconditions . checkState ( prof != null , ""no profile in scope"" ) ; return prof ; } /* *
","* Create a new profile , setting it as the current thread - local profile for the
","* Create a new profile, setting it as the current thread-local profile for the
",,,"* Create a new profile, setting it as the current thread-local profile for the
",,,"TRuntimeProfileNode profile_ = new TRuntimeProfileNode ( ""Frontend"" , 0 , new ArrayList < > ( ) , - 1L , false , new HashMap < > ( ) , new ArrayList < > ( ) , ImmutableMap . of ( ROOT_COUNTER_NAME , new HashSet < > ( ) ) ) ; public static Scope createNewWithScope ( ) { return new Scope ( new FrontendProfile ( ) ) ; } @Nonnull public static FrontendProfile getCurrent ( ) { FrontendProfile prof = THREAD_LOCAL . get ( ) ; Preconditions . checkState ( prof != null , ""no profile in scope"" ) ; return prof ; }
",,,"profile_ = new TRuntimeProfileNode ( ""Frontend"" , /* num_children =* / 0 , /* counters =* / new ArrayList < > ( ) , /* metadata =* /- 1L , /* indent =* / false , /* info_strings =* / new HashMap < > ( ) , /* info_strings_display_order */ new ArrayList < > ( ) , /* child_counters_map =* / ImmutableMap . of ( ROOT_COUNTER_NAME , new HashSet < > ( ) ) ) ; public static Scope createNewWithScope ( ) { return new Scope ( new FrontendProfile ( ) ) ; } @Nonnull public static FrontendProfile getCurrent ( ) { FrontendProfile prof = THREAD_LOCAL . get ( ) ; Preconditions . checkState ( prof != null , ""no profile in scope"" ) ; return prof ; }
",,,"profile_ = new TRuntimeProfileNode ( ""Frontend"" , /* num_children =* / 0 , /* counters =* / new ArrayList < > ( ) , /* metadata =* /- 1L , // TODO ( todd ) what is this used for ? why is it required ? /* indent =* / false , /* info_strings =* / new HashMap < > ( ) , /* info_strings_display_order */ new ArrayList < > ( ) , /* child_counters_map =* / ImmutableMap . of ( ROOT_COUNTER_NAME , new HashSet < > ( ) ) ) ; } /* * < |startfocus| > * Create a new profile , setting it as the current thread - local profile for the < |endfocus| > * length of the current scope . This is meant to be used in a try - with - resources * statement . */ public static Scope createNewWithScope ( ) { return new Scope ( new FrontendProfile ( ) ) ; } /* * * Get the profile attached to the current thread , throw IllegalStateException if there * is none . */ @Nonnull public static FrontendProfile getCurrent ( ) { FrontendProfile prof = THREAD_LOCAL . get ( ) ; Preconditions . checkState ( prof != null , ""no profile in scope"" ) ; return prof ; } /* *
",,
1192,"table = catalog_ . removeTable ( params . getTable_name ( ) . db_name , params . getTable_name ( ) . table_name ) ; if ( table == null ) { // Nothing was removed from the catalogd's cache . resp . result . setVersion ( catalog_ . getCatalogVersion ( ) ) ; return ; } resp . result . setVersion ( table . getCatalogVersion ( ) ) ; uncacheTable ( table ) ; } if ( table . getMetaStoreTable ( ) != null ) { updateDatabasePrivileges ( table . getDb ( ) . getName ( ) , table . getName ( ) , params . server_name , table . getMetaStoreTable ( ) . getOwner ( ) , table . getMetaStoreTable ( ) . getOwnerType ( ) , /* newOwner */ null , /* newOwnerType */ null , resp ) ; } removedObject . setType ( TCatalogObjectType . TABLE ) ; removedObject . setTable ( new TTable ( ) ) ; removedObject . getTable ( ) . setTbl_name ( tableName . getTbl ( ) ) ; removedObject . getTable ( ) . setDb_name ( tableName . getDb ( ) ) ; removedObject . setCatalog_version ( resp . result . getVersion ( ) ) ; resp . result . addToRemoved_catalog_objects ( removedObject ) ; } /* *
","updateDatabasePrivileges ( table . getDb ( ) . getName ( ) , table . getName ( ) , params . server_name , table . getMetaStoreTable ( ) . getOwner ( ) , table . getMetaStoreTable ( ) . getOwnerType ( ) , /* newOwner */ null , /* newOwnerType */ null , resp ) ;
","updateDatabasePrivileges(table.getDb().getName(), table.getName(), params.server_name, table.getMetaStoreTable().getOwner(), table.getMetaStoreTable().getOwnerType(), /* newOwner */ null, /* newOwnerType */ null, resp);
",,,"updateDatabasePrivileges(table.getDb().getName(), table.getName(), params.server_name, table.getMetaStoreTable().getOwner(), table.getMetaStoreTable().getOwnerType(), /* newOwner */ null, /* newOwnerType */ null, resp);
",,,"table = catalog_ . removeTable ( params . getTable_name ( ) . db_name , params . getTable_name ( ) . table_name ) ; if ( table == null ) { resp . result . setVersion ( catalog_ . getCatalogVersion ( ) ) ; return ; } resp . result . setVersion ( table . getCatalogVersion ( ) ) ; uncacheTable ( table ) ; if ( table . getMetaStoreTable ( ) != null ) { updateDatabasePrivileges ( table . getDb ( ) . getName ( ) , table . getName ( ) , params . server_name , table . getMetaStoreTable ( ) . getOwner ( ) , table . getMetaStoreTable ( ) . getOwnerType ( ) , null , null , resp ) ; } removedObject . setType ( TCatalogObjectType . TABLE ) ; removedObject . setTable ( new TTable ( ) ) ; removedObject . getTable ( ) . setTbl_name ( tableName . getTbl ( ) ) ; removedObject . getTable ( ) . setDb_name ( tableName . getDb ( ) ) ; removedObject . setCatalog_version ( resp . result . getVersion ( ) ) ; resp . result . addToRemoved_catalog_objects ( removedObject ) ;
",,,"table = catalog_ . removeTable ( params . getTable_name ( ) . db_name , params . getTable_name ( ) . table_name ) ; if ( table == null ) { resp . result . setVersion ( catalog_ . getCatalogVersion ( ) ) ; return ; } resp . result . setVersion ( table . getCatalogVersion ( ) ) ; uncacheTable ( table ) ; if ( table . getMetaStoreTable ( ) != null ) { updateDatabasePrivileges ( table . getDb ( ) . getName ( ) , table . getName ( ) , params . server_name , table . getMetaStoreTable ( ) . getOwner ( ) , table . getMetaStoreTable ( ) . getOwnerType ( ) , /* newOwner */ null , /* newOwnerType */ null , resp ) ; } removedObject . setType ( TCatalogObjectType . TABLE ) ; removedObject . setTable ( new TTable ( ) ) ; removedObject . getTable ( ) . setTbl_name ( tableName . getTbl ( ) ) ; removedObject . getTable ( ) . setDb_name ( tableName . getDb ( ) ) ; removedObject . setCatalog_version ( resp . result . getVersion ( ) ) ; resp . result . addToRemoved_catalog_objects ( removedObject ) ; }
",,,"table = catalog_ . removeTable ( params . getTable_name ( ) . db_name , params . getTable_name ( ) . table_name ) ; if ( table == null ) { // Nothing was removed from the catalogd's cache . resp . result . setVersion ( catalog_ . getCatalogVersion ( ) ) ; return ; } resp . result . setVersion ( table . getCatalogVersion ( ) ) ; uncacheTable ( table ) ; } if ( table . getMetaStoreTable ( ) != null ) { < |startfocus| > updateDatabasePrivileges ( table . getDb ( ) . getName ( ) , table . getName ( ) , params . server_name , table . getMetaStoreTable ( ) . getOwner ( ) , table . getMetaStoreTable ( ) . getOwnerType ( ) , /* newOwner */ null , /* newOwnerType */ null , resp ) ; < |endfocus| > } removedObject . setType ( TCatalogObjectType . TABLE ) ; removedObject . setTable ( new TTable ( ) ) ; removedObject . getTable ( ) . setTbl_name ( tableName . getTbl ( ) ) ; removedObject . getTable ( ) . setDb_name ( tableName . getDb ( ) ) ; removedObject . setCatalog_version ( resp . result . getVersion ( ) ) ; resp . result . addToRemoved_catalog_objects ( removedObject ) ; } /* * * Removes a function from the catalog cache . Also removes all associated privileges . * * @param params * @param resp * @throws ImpalaException */ private void removeFunction ( RemoveFunctionParams params , RemoveFunctionResult resp ) throws ImpalaException { Function desc = Function . fromThrift ( params . fn ) ; if ( desc == null ) { throw new ImpalaRuntimeException ( String . format ( ""Unknown function : % s . % s ( ) "" , params . fn . name . db_name , params . fn . name . function_name ) ) ; } catalog_ . removeFunction ( desc ) ; resp . setVersion ( catalog_ . getCatalogVersion ( ) ) ; TCatalogObject removedObject = new TCatalogObject ( ) ; removedObject . setType ( TCatalogObjectType . FUNCTION ) ; removedObject . setFn ( new org . apache . impala . thrift . TFunction ( ) ) ; removedObject . getFn ( ) . setSignature ( desc . signatureString ( ) ) ; removedObject . setCatalog_version ( resp . getVersion ( ) ) ; resp . addToRemoved_catalog_objects ( removedObject ) ; } /* *
",,
1195,"} if ( ! updatedPrivs . isEmpty ( ) || ! removedPrivs . isEmpty ( ) ) { // If this is a REVOKE statement with hasGrantOpt , only the GRANT OPTION is removed // from the privileges . Otherwise the privileges are removed from the catalog . if ( grantRevokePrivParams . isIs_grant ( ) ) { resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } } else if ( privileges . get ( 0 ) . isHas_grant_opt ( ) ) { if ( ! updatedPrivs . isEmpty ( ) && ! removedPrivs . isEmpty ( ) ) { resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) > removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ? updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) : removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } else { resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion (
","} } else if ( privileges . get ( 0 ) . isHas_grant_opt ( ) ) { if ( ! updatedPrivs . isEmpty ( ) && ! removedPrivs . isEmpty ( ) ) {
","} else if (p privileges.get(0).isHas_grant_opt()) {
",,,"} else if (privileges.get(0).isHas_grant_opt() || privileges.get(1).isHas_grant_opt())) {
",,,"if ( ! updatedPrivs . isEmpty ( ) || ! removedPrivs . isEmpty ( ) ) { if ( grantRevokePrivParams . isIs_grant ( ) ) { resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } else if ( privileges . get ( 0 ) . isHas_grant_opt ( ) ) { resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) > removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ? updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) : removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } else { resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } }
",,,"} if ( ! updatedPrivs . isEmpty ( ) || ! removedPrivs . isEmpty ( ) ) { // If this is a REVOKE statement with hasGrantOpt , only the GRANT OPTION is removed // from the privileges . Otherwise the privileges are removed from the catalog . if ( grantRevokePrivParams . isIs_grant ( ) ) { resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } else if ( privileges . get ( 0 ) . isHas_grant_opt ( ) ) { resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) > removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ? updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) : removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } else { resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion (
",,,"} if ( ! updatedPrivs . isEmpty ( ) || ! removedPrivs . isEmpty ( ) ) { // If this is a REVOKE statement with hasGrantOpt , only the GRANT OPTION is removed // from the privileges . Otherwise the privileges are removed from the catalog . if ( grantRevokePrivParams . isIs_grant ( ) ) { resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; < |startfocus| > } else if ( privileges . get ( 0 ) . isHas_grant_opt ( ) ) { < |endfocus| > resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) > removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ? updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) : removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } else { resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion ( removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } } return resp ; }
",,
1198,"*/ final private Thread daemonThread_ ; /* * * The threshold above which the old gen is considered almost full . */ final private double oldGenFullThreshold_ ; /* * * The ratio of tables to invalidate when the old gen is almost full . */ final private double gcInvalidationFraction_ ; /* * * The number of times the daemon thread wakes up and scans the tables for invalidation . * It's useful for tests to ensure that a scan happened . */ @VisibleForTesting AtomicLong scanCount_ = new AtomicLong ( ) ; private GarbageCollectorMXBean oldGenGcBean_ ; /* * * The name of the old gen memory pool . */ private String oldGcGenName_ ; /* * * The value of oldGenGcBean_ . getCollectionCount ( ) when the last memory - based * invalidation was executed . */ private long lastObservedGcCount_ ; private boolean stopped_ = false ; /* * * Last time an time - based invalidation is executed in nanoseconds . */ private long lastInvalidationTime_ ;
","* It's useful for tests to ensure that a scan happened .
","* It's useful for tests to ensure that a scan happened and to proceed.
",,,"* It's useful for tests to ensure that a scan occurred and to proceed.
",,,"private final Thread daemonThread ; private final double oldGenFullThreshold ; private final double gcInvalidationFraction ; @VisibleForTesting private final AtomicLong scanCount = new AtomicLong ( ) ; private GarbageCollectorMXBean oldGenGcBean ; private String oldGcGenName ; private long lastObservedGcCount ; private boolean stopped = false ; private long lastInvalidationTime ;
",,,"final private Thread daemonThread_ ; final private double oldGenFullThreshold_ ; final private double gcInvalidationFraction_ ; @VisibleForTesting AtomicLong scanCount_ = new AtomicLong ( ) ; private GarbageCollectorMXBean oldGenGcBean_ ; private String oldGcGenName_ ; private long lastObservedGcCount_ ; private boolean stopped_ = false ; private long lastInvalidationTime_ ;
",,,"/* * * The number of times the daemon thread wakes up and scans the tables for invalidation . < |startfocus| > * It's useful for tests to ensure that a scanning occurred and to proceed . < |endfocus| > */ @VisibleForTesting AtomicLong scanCount_ = new AtomicLong ( ) ; private GarbageCollectorMXBean oldGenGcBean_ ; /* * * The name of the old gen memory pool . */ private String oldGcGenName_ ; /* * * The value of oldGenGcBean_ . getCollectionCount ( ) when the last memory - based * invalidation was executed . */ private long lastObservedGcCount_ ; private boolean stopped_ = false ; /* * * Last time an time - based invalidation is executed in nanoseconds . */ private long lastInvalidationTime_ ;
",,
1207,"PrincipalType newOwnerType , TDdlExecResponse resp ) { if ( catalog_ . getSentryProxy ( ) == null || ! catalog_ . getSentryProxy ( ) . isObjectOwnershipEnabled ( ) ) return ; Preconditions . checkNotNull ( serverName ) ; TPrivilege filter ; if ( tableName == null ) { filter = createDatabaseOwnerPrivilegeFilter ( databaseName , serverName ) ; } else { filter = createTableOwnerPrivilegeFilter ( databaseName , tableName , serverName ) ; } if ( oldOwner != null && ! oldOwner . isEmpty ( ) ) { removePrivilegeFromCatalog ( oldOwner , oldOwnerType , filter , resp ) ; } if ( newOwner != null && newOwner . length ( ) > 0 ) { addPrivilegeToCatalog ( newOwner , newOwnerType , filter , resp ) ; } } private void createFunction ( TCreateFunctionParams params , TDdlExecResponse resp ) throws ImpalaException { Function fn = Function . fromThrift ( params . getFn ( ) ) ; if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( String . format ( ""Adding % s : % s"" , fn . getClass ( ) . getSimpleName ( ) , fn . signatureString ( ) ) ) ; } boolean isPersistentJavaFn =
","if ( oldOwner != null && ! oldOwner . isEmpty ( ) ) {
","if (oldOwner != null && oldOwner.length() > 0) {
",,,"if (oldOwner != null && oldOwner.length() > 0) {
",,,"public void changeObjectOwner ( String serverName , String databaseName , String tableName , String oldOwner , PrincipalType oldOwnerType , String newOwner , PrincipalType newOwnerType , TDdlExecResponse resp ) { if ( catalog_ . getSentryProxy ( ) == null || ! catalog_ . getSentryProxy ( ) . isObjectOwnershipEnabled ( ) ) { return ; } Preconditions . checkNotNull ( serverName ) ; TPrivilege filter ; if ( tableName == null ) { filter = createDatabaseOwnerPrivilegeFilter ( databaseName , serverName ) ; } else { filter = createTableOwnerPrivilegeFilter ( databaseName , tableName , serverName ) ; } if ( oldOwner != null && ! oldOwner . isEmpty ( ) ) { removePrivilegeFromCatalog ( oldOwner , oldOwnerType , filter , resp ) ; } if ( newOwner != null && ! newOwner . isEmpty ( ) ) { addPrivilegeToCatalog ( newOwner , newOwnerType , filter , resp ) ; } } private void createFunction ( TCreateFunctionParams params , TDdlExecResponse resp ) throws ImpalaException { Function fn = Function . fromThrift ( params . getFn ( ) ) ; if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( String . format ( ""Adding % s : % s"" , fn . getClass ( ) . getSimpleName ( ) , fn . signatureString ( ) ) ) ; } boolean isPersistentJavaFn = false ; // Code to create function }
",,,"PrincipalType newOwnerType , TDdlExecResponse resp ) { if ( catalog_ . getSentryProxy ( ) == null || ! catalog_ . getSentryProxy ( ) . isObjectOwnershipEnabled ( ) ) return ; Preconditions . checkNotNull ( serverName ) ; TPrivilege filter ; if ( tableName == null ) { filter = createDatabaseOwnerPrivilegeFilter ( databaseName , serverName ) ; } else { filter = createTableOwnerPrivilegeFilter ( databaseName , tableName , serverName ) ; } if ( oldOwner != null && oldOwner . length ( ) > 0 ) { removePrivilegeFromCatalog ( oldOwner , oldOwnerType , filter , resp ) ; } if ( newOwner != null && newOwner . length ( ) > 0 ) { addPrivilegeToCatalog ( newOwner , newOwnerType , filter , resp ) ; } } private void createFunction ( TCreateFunctionParams params , TDdlExecResponse resp ) throws ImpalaException { Function fn = Function . fromThrift ( params . getFn ( ) ) ; if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( String . format ( ""Adding % s : % s"" , fn . getClass ( ) . getSimpleName ( ) , fn . signatureString ( ) ) ) ; } boolean isPersistentJavaFn = false ; if ( fn instanceof ScalarFunction ) { isPersistentJavaFn = ( ( ScalarFunction ) fn ) . isPersistentJavaFunction ( ) ; } else if ( fn instanceof AggregateFunction ) { isPersistentJavaFn = ( ( AggregateFunction ) fn ) . isPersistentJavaFunction ( ) ; } if ( isPersistentJavaFn ) { // Add the function to the catalog catalog_ . addJavaFunction ( ( JavaFunction ) fn ) ; } else { // Add the function to the local catalog catalog_ . addFunction ( fn ) ; } resp . setResult ( new TCreateFunctionResult ( ) ) ; }
",,,"PrincipalType newOwnerType , TDdlExecResponse resp ) { if ( catalog_ . getSentryProxy ( ) == null || ! catalog_ . getSentryProxy ( ) . isObjectOwnershipEnabled ( ) ) return ; Preconditions . checkNotNull ( serverName ) ; TPrivilege filter ; if ( tableName == null ) { filter = createDatabaseOwnerPrivilegeFilter ( databaseName , serverName ) ; } else { filter = createTableOwnerPrivilegeFilter ( databaseName , tableName , serverName ) ; } < |startfocus| > if ( oldOwner != null && oldOwner . length ( ) > 0 ) { < |endfocus| > removePrivilegeFromCatalog ( oldOwner , oldOwnerType , filter , resp ) ; } if ( newOwner != null && newOwner . length ( ) > 0 ) { addPrivilegeToCatalog ( newOwner , newOwnerType , filter , resp ) ; } } private void createFunction ( TCreateFunctionParams params , TDdlExecResponse resp ) throws ImpalaException { Function fn = Function . fromThrift ( params . getFn ( ) ) ; if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( String . format ( ""Adding % s : % s"" , fn . getClass ( ) . getSimpleName ( ) , fn . signatureString ( ) ) ) ; } boolean isPersistentJavaFn = fn . getBinaryType ( ) == TFunctionBinaryType . JAVA ;
",,
1208,"TPrivilege filter , TDdlExecResponse response ) { try { Principal owner = catalog_ . getAuthPolicy ( ) . getPrincipal ( ownerString , ownerType == PrincipalType . ROLE ? TPrincipalType . ROLE : TPrincipalType . USER ) ; if ( owner != null ) { PrincipalPrivilege privilege = owner . getPrivilege ( filter . getPrivilege_name ( ) ) ; if ( privilege != null ) { PrincipalPrivilege removedPrivilege = catalog_ . getAuthPolicy ( ) . removePrivilege ( privilege ) ; removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; response . result . addToRemoved_catalog_objects ( removedPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } } catch ( CatalogException e ) { LOG . error ( ""Error removing privilege : "" , e ) ; } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ;
","< |del| > owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ;
","removedPrivilege.setCatalogVersion(catalog_.incrementAndGetCatalogVersion());
",,,"<|del|>
",,,"TPrivilege filter , TDdlExecResponse response ) { try { Principal owner = catalog_ . getAuthPolicy ( ) . getPrincipal ( ownerString , ownerType == PrincipalType . ROLE ? TPrincipalType . ROLE : TPrincipalType . USER ) ; if ( owner != null ) { PrincipalPrivilege privilege = owner . getPrivilege ( filter . getPrivilege_name ( ) ) ; if ( privilege != null ) { PrincipalPrivilege removedPrivilege = catalog_ . getAuthPolicy ( ) . removePrivilege ( privilege ) ; removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; response . result . addToRemoved_catalog_objects ( removedPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } } catch ( CatalogException e ) { LOG . error ( ""Error removing privilege : "" , e ) ; } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ; // code to add privilege to catalog } catch ( CatalogException e ) { LOG . error ( ""Error adding privilege : "" , e ) ; } }
",,,"TPrivilege filter , TDdlExecResponse response ) { try { Principal owner = catalog_ . getAuthPolicy ( ) . getPrincipal ( ownerString , ownerType == PrincipalType . ROLE ? TPrincipalType . ROLE : TPrincipalType . USER ) ; if ( owner != null ) { PrincipalPrivilege privilege = owner . getPrivilege ( filter . getPrivilege_name ( ) ) ; if ( privilege != null ) { PrincipalPrivilege removedPrivilege = catalog_ . getAuthPolicy ( ) . removePrivilege ( privilege ) ; removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; response . result . addToRemoved_catalog_objects ( removedPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } } catch ( CatalogException e ) { LOG . error ( ""Error removing privilege : "" , e ) ; } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ; // code here } catch ( CatalogException e ) { LOG . error ( ""Error adding privilege : "" , e ) ; } }
",,,"TPrivilege filter , TDdlExecResponse response ) { try { Principal owner = catalog_ . getAuthPolicy ( ) . getPrincipal ( ownerString , ownerType == PrincipalType . ROLE ? TPrincipalType . ROLE : TPrincipalType . USER ) ; if ( owner != null ) { PrincipalPrivilege privilege = owner . getPrivilege ( filter . getPrivilege_name ( ) ) ; if ( privilege != null ) { PrincipalPrivilege removedPrivilege = catalog_ . getAuthPolicy ( ) . removePrivilege ( privilege ) ; removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; < |startfocus| > removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; < |endfocus| > response . result . addToRemoved_catalog_objects ( removedPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } } catch ( CatalogException e ) { LOG . error ( ""Error removing privilege : "" , e ) ; } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ;
",,
1218,"} /* * * Throws a CatalogException if the Sentry Service is not enabled . */ private void verifySentryServiceEnabled ( ) throws CatalogException { if ( catalog_ . getSentryProxy ( ) == null ) { throw new CatalogException ( ""Sentry Service is not enabled on the "" + ""CatalogServer . "" ) ; } } /* * * Checks if with grant is enabled for object ownership in Sentry . */ private boolean isObjectOwnershipGrantEnabled ( ) { return catalog_ . getSentryProxy ( ) == null ? false : catalog_ . getSentryProxy ( ) . isObjectOwnershipGrantEnabled ( ) ; } /* * * Alters partitions in batches of size 'MAX_PARTITION_UPDATES_PER_RPC' . This * reduces the time spent in a single update and helps avoid metastore client * timeouts . */ private void bulkAlterPartitions ( String dbName , String tableName , List < HdfsPartition > modifiedParts ) throws ImpalaException { List < org . apache . hadoop . hive . metastore . api . Partition > hmsPartitions = Lists . newArrayList ( ) ; for ( HdfsPartition p : modifiedParts ) {
","return catalog_ . getSentryProxy ( ) == null ? false : catalog_ . getSentryProxy ( ) . isObjectOwnershipGrantEnabled ( ) ;
","return catalog_.getSentryProxy().isObjectOwnershipGrantEnabled();
",,,"return catalog_.getSentryProxy() != null && catalog_.getSentryProxy().isObjectOwnershipGrantEnabled();
",,,"private void verifySentryServiceEnabled ( ) throws CatalogException { if ( catalog_ . getSentryProxy ( ) == null ) { throw new CatalogException ( ""Sentry Service is not enabled on the CatalogServer . "" ) ; } } private boolean isObjectOwnershipGrantEnabled ( ) { return ( catalog_ . getSentryProxy ( ) != null ) ? catalog_ . getSentryProxy ( ) . isObjectOwnershipGrantEnabled ( ) : false ; } private void bulkAlterPartitions ( String dbName , String tableName , List < HdfsPartition > modifiedParts ) throws ImpalaException { List < org . apache . hadoop . hive . metastore . api . Partition > hmsPartitions = Lists . newArrayList ( ) ; for ( HdfsPartition p : modifiedParts ) { // code for altering partitions } }
",,,"private boolean isObjectOwnershipGrantEnabled ( ) { return catalog_ . getSentryProxy ( ) != null && catalog_ . getSentryProxy ( ) . isObjectOwnershipGrantEnabled ( ) ; }
",,,"} /* * * Throws a CatalogException if the Sentry Service is not enabled . */ private void verifySentryServiceEnabled ( ) throws CatalogException { if ( catalog_ . getSentryProxy ( ) == null ) { throw new CatalogException ( ""Sentry Service is not enabled on the "" + ""CatalogServer . "" ) ; } } /* * * Checks if with grant is enabled for object ownership in Sentry . */ private boolean isObjectOwnershipGrantEnabled ( ) { < |startfocus| > return catalog_ . getSentryProxy ( ) != null ? catalog_ . getSentryProxy ( ) . isObjectOwnershipGrantEnabled ( ) : false ; < |endfocus| > } /* * * Alters partitions in batches of size 'MAX_PARTITION_UPDATES_PER_RPC' . This * reduces the time spent in a single update and helps avoid metastore client * timeouts . */ private void bulkAlterPartitions ( String dbName , String tableName , List < HdfsPartition > modifiedParts ) throws ImpalaException { List < org . apache . hadoop . hive . metastore . api . Partition > hmsPartitions = Lists . newArrayList ( ) ; for ( HdfsPartition p : modifiedParts ) {
",,
1236,"public void testFloat ( ) { final BloomFilter bf = BloomFilter . BySizeAndFPRate ( nBytes , fpRate ) ; // Put floats into bloomfilter by random Random rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { bf . put ( rand . nextFloat ( ) ) ; } // Reset the rand and check existence of the keys . rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { assertTrue ( bf . mayContain ( rand . nextFloat ( ) ) ) ; }
","public void testFloat ( ) {
","public void testFLoat() {
",,,"public void testFloatLoat() {
",,,"public void testFloat ( ) { final BloomFilter bf = BloomFilter . BySizeAndFPRate ( nBytes , fpRate ) ; Random rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { bf . put ( rand . nextFloat ( ) ) ; } rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { assertTrue ( bf . mayContain ( rand . nextFloat ( ) ) ) ; } }
",,,"public void testFloat ( ) { final BloomFilter bf = BloomFilter . BySizeAndFPRate ( nBytes , fpRate ) ; Random rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { bf . put ( rand . nextFloat ( ) ) ; } rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { assertTrue ( bf . mayContain ( rand . nextFloat ( ) ) ) ; } }
",,,"< |startfocus| > public void testFloat ( ) { < |endfocus| > final BloomFilter bf = BloomFilter . BySizeAndFPRate ( nBytes , fpRate ) ; // Put floats into bloomfilter by random Random rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { bf . put ( rand . nextFloat ( ) ) ; } // Reset the rand and check existence of the keys . rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { assertTrue ( bf . mayContain ( rand . nextFloat ( ) ) ) ; }
",,
1255,"* @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize ( int nBytes ) { return BySizeAndFPRate ( nBytes , DEFAULT_FP_RATE ) ; } /* * * Generate bloom filter , default hashing is { @code Murmur2 } . * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been { @code put } into the { @code BloomFilter } . */ public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate ) { return BySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; } /* * * Generate bloom filter . * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been { @code put } into the { @code BloomFilter } . * @param hashFunction hashing used when updating or checking containment , user should pick * the hashing function from { @code HashFunctions }
","* ever been { @code put } into the { @code BloomFilter } .
","* ever been {@code put} into the {@code BloomFilter}.
",,,"* ever been {@code put} into the {@code BloomFilter}. * @param fpRate the probability that TServer will erroneously return a record that has not * ever been {@code put} into the {@code BloomFilter}.
",,,"/* * * Generate bloom filter by specifying the size in bytes . * @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize ( int nBytes ) { return BySizeAndFPRate ( nBytes , DEFAULT_FP_RATE ) ; } /* * * Generate bloom filter by specifying the size in bytes and the false positive rate . * Default hashing is { @code Murmur2 } . * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been put into the BloomFilter . */ public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate ) { return BySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; } /* * * Generate bloom filter by specifying the size in bytes , the false positive rate , and the hashing function . * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been put into the BloomFilter . * @param hashFunction hashing used when updating or checking containment , user should pick * the hashing function from { @code HashFunctions } */ public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate , HashFunction hashFunction ) { // implementation }
",,,"/* * * Generate bloom filter , default hashing is { @code Murmur2 } . * * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been { @code put } into the { @code BloomFilter } . */ public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate ) { return BySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; } /* * * Generate bloom filter . * * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been { @code put } into the { @code BloomFilter } . * @param hashFunction hashing used when updating or checking containment , user should pick * the hashing function from { @code HashFunctions } */ public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate , HashFunction hashFunction ) { // implementation } /* * * Generate bloom filter , default hashing is { @code Murmur2 } . * * @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize ( int nBytes ) { return BySizeAndFPRate ( nBytes , DEFAULT_FP_RATE ) ; }
",,,"* @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize ( int nBytes ) { return BySizeAndFPRate ( nBytes , DEFAULT_FP_RATE ) ; } /* * * Generate bloom filter , default hashing is { @code Murmur2 } . * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been { @code put } into the { @code BloomFilter } . */ public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate ) { return BySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; } /* * * Generate bloom filter . * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been { @code put } into the { @code BloomFilter } . * @param hashFunction hashing used when updating or checking containment , user should pick * the hashing function from { @code HashFunctions }
",,
1260,"private static String findBinaryDir ( ) { // First check the system property , which is our standard override . String kuduHomeProp = System . getProperty ( KUDU_BIN_DIR_PROP ) ; if ( kuduHomeProp != null ) { LOG . info ( ""Using Kudu binary directory specified by system property ' { } ' : { } "" , KUDU_BIN_DIR_PROP , kuduHomeProp ) ; return kuduHomeProp ; } // Next , check the environment variable . String kuduHomeVar = System . getenv ( KUDU_HOME_VAR ) ; if ( kuduHomeVar != null ) { LOG . info ( ""Using Kudu home directory specified by environment variable ' { } ' : { } "" , KUDU_HOME_VAR , kuduHomeVar ) ; String kuduBinDir = new File ( kuduHomeVar , ""bin"" ) . getPath ( ) ; return kuduBinDir ; } // Last , use the kudu that is available on the path . try { Runtime runtime = Runtime . getRuntime ( ) ; Process process = runtime . exec ( ""which kudu"" ) ; int errorCode = process . waitFor ( ) ; if ( errorCode == 0 ) {
","LOG . info ( ""Using Kudu binary directory specified by system property ' { } ' : { } "" , KUDU_BIN_DIR_PROP , kuduHomeProp ) ;
","LOG.info(""Using Kudu binary directory specified by system property '{}': {}"", KUDU_BIN_DIR_PROP, kuduHomeProp);
",,,"LOG.info(""Using Kudu binary directory specified by system property '{}': {}"", KUDU_BIN_DIR_PROP, kuduHomeProp);
",,,"private static String findBinaryDir ( ) { String kuduHomeProp = System . getProperty ( KUDU_BIN_DIR_PROP ) ; if ( kuduHomeProp != null ) { LOG . info ( ""Using Kudu binary directory specified by system property ' { } ' : { } "" , KUDU_BIN_DIR_PROP , kuduHomeProp ) ; return kuduHomeProp ; } String kuduHomeVar = System . getenv ( KUDU_HOME_VAR ) ; if ( kuduHomeVar != null ) { LOG . info ( ""Using Kudu home directory specified by environment variable ' { } ' : { } "" , KUDU_HOME_VAR , kuduHomeVar ) ; String kuduBinDir = new File ( kuduHomeVar , ""bin"" ) . getPath ( ) ; return kuduBinDir ; } try { Runtime runtime = Runtime . getRuntime ( ) ; Process process = runtime . exec ( ""which kudu"" ) ; int errorCode = process . waitFor ( ) ; if ( errorCode == 0 ) { return new BufferedReader ( new InputStreamReader ( process . getInputStream ( ) ) ) . readLine ( ) . trim ( ) ; } } catch ( IOException | InterruptedException e ) { LOG . warn ( ""Failed to determine Kudu binary directory using 'which kudu'"" , e ) ; } LOG . warn ( ""Unable to determine Kudu binary directory , using default : { } "" , DEFAULT_KUDU_BIN_DIR ) ; return DEFAULT_KUDU_BIN_DIR ; }
",,,"private static String findBinaryDir ( ) { String kuduHomeProp = System . getProperty ( KUDU_BIN_DIR_PROP ) ; if ( kuduHomeProp != null ) { LOG . info ( ""Using Kudu binary directory specified by system property ' { } ' : { } "" , KUDU_BIN_DIR_PROP , kuduHomeProp ) ; return kuduHomeProp ; } String kuduHomeVar = System . getenv ( KUDU_HOME_VAR ) ; if ( kuduHomeVar != null ) { LOG . info ( ""Using Kudu home directory specified by environment variable ' { } ' : { } "" , KUDU_HOME_VAR , kuduHomeVar ) ; String kuduBinDir = new File ( kuduHomeVar , ""bin"" ) . getPath ( ) ; return kuduBinDir ; } try { Runtime runtime = Runtime . getRuntime ( ) ; Process process = runtime . exec ( ""which kudu"" ) ; int errorCode = process . waitFor ( ) ; if ( errorCode == 0 ) { // kudu is available on the path BufferedReader reader = new BufferedReader ( new InputStreamReader ( process . getInputStream ( ) ) ) ; String kuduPath = reader . readLine ( ) ; LOG . info ( ""Using Kudu binary directory found on the path : { } "" , kuduPath ) ; return new File ( kuduPath ) . getParent ( ) ; } } catch ( IOException | InterruptedException e ) { LOG . warn ( ""Failed to determine Kudu binary directory : { } "" , e . getMessage ( ) ) ; } LOG . warn ( ""Unable to find Kudu binary directory . Defaulting to current working directory . "" ) ; return System . getProperty ( ""user . dir"" ) ; }
",,,"private static String findBinaryDir ( ) { // First check the system property , which is our standard override . String kuduHomeProp = System . getProperty ( KUDU_BIN_DIR_PROP ) ; if ( kuduHomeProp != null ) { < |startfocus| > LOG . info ( ""Using Kudu binary directory specified by system property ' { } ' : { } "" , KUDU_BIN_DIR_PROP , kuduHomeProp ) ; < |endfocus| > return kuduHomeProp ; } // Next , check the environment variable . String kuduHomeVar = System . getenv ( KUDU_HOME_VAR ) ; if ( kuduHomeVar != null ) { LOG . info ( ""Using Kudu home directory specified by environment variable ' { } ' : { } "" , KUDU_HOME_VAR , kuduHomeVar ) ; String kuduBinDir = new File ( kuduHomeVar , ""bin"" ) . getPath ( ) ; return kuduBinDir ; } // Last , use the kudu that is available on the path . try { Runtime runtime = Runtime . getRuntime ( ) ; Process process = runtime . exec ( ""which kudu"" ) ; int errorCode = process . waitFor ( ) ; if ( errorCode == 0 ) { < |startfocus| > BufferedReader reader = new BufferedReader ( new InputStreamReader ( process . getInputStream ( ) ) ) ; String kuduBinDir = reader . readLine ( ) ; LOG . info ( ""Using Kudu binary directory specified by 'which kudu' : { } "" , kuduBinDir ) ; < |endfocus| > return kuduBinDir ; } } catch ( IOException e ) { LOG . warn ( ""Failed to execute 'which kudu'"" , e ) ; } catch ( InterruptedException e ) { LOG . warn ( ""Interrupted while executing 'which kudu'"" , e ) ; } return null ; }
",,
1266,"import static org . junit . Assert . assertArrayEquals ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; import java . net . InetAddress ; import java . net . InetSocketAddress ; import java . util . Arrays ; import java . util . List ; import org . apache . kudu . client . HostAndPort ; import org . junit . Test ; /* * * Test for { @link NetUtil } . */ public class TestNetUtil { /* * * Tests parsing strings into { @link HostAndPort } objects with and without specifying * the port in the string . */ @Test public void testParseString ( ) { String aStringWithPort = ""1 . 2 . 3 . 4 : 1234"" ; HostAndPort hostAndPortForAStringWithPort = NetUtil . parseString ( aStringWithPort , 0 ) ; assertEquals ( hostAndPortForAStringWithPort . getHost ( ) , ""1 . 2 . 3 . 4"" ) ; assertEquals ( hostAndPortForAStringWithPort . getPort ( ) , 1234 ) ; String aStringWithoutPort = ""1 . 2 . 3 . 4"" ; HostAndPort hostAndPortForAStringWithoutPort = NetUtil . parseString ( aStringWithoutPort , 12345 ) ;
","* Tests parsing strings into { @link HostAndPort } objects with and without specifying
","* Tests parsing strings into {@link InetSocketAddress} objects with and without specifying
",,,"* Tests parsing strings into {@link HostAndPort} objects with and without specifying
",,,"import static org . junit . Assert . assertArrayEquals ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; import java . net . InetAddress ; import java . net . InetSocketAddress ; import java . util . Arrays ; import java . util . List ; import org . apache . kudu . client . HostAndPort ; import org . junit . Test ; public class TestNetUtil { @Test public void testParseString ( ) { String aStringWithPort = ""1 . 2 . 3 . 4 : 1234"" ; HostAndPort hostAndPortForAStringWithPort = HostAndPort . fromString ( aStringWithPort ) ; assertEquals ( hostAndPortForAStringWithPort . getHostText ( ) , ""1 . 2 . 3 . 4"" ) ; assertEquals ( hostAndPortForAStringWithPort . getPort ( ) , 1234 ) ; String aStringWithoutPort = ""1 . 2 . 3 . 4"" ; HostAndPort hostAndPortForAStringWithoutPort = HostAndPort . fromString ( aStringWithoutPort + "" : 12345"" ) ; assertEquals ( hostAndPortForAStringWithoutPort . getHostText ( ) , ""1 . 2 . 3 . 4"" ) ; assertEquals ( hostAndPortForAStringWithoutPort . getPort ( ) , 12345 ) ; } }
",,,"import static org . junit . Assert . assertArrayEquals ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; import java . net . InetAddress ; import java . net . InetSocketAddress ; import java . util . Arrays ; import java . util . List ; import org . apache . kudu . client . HostAndPort ; import org . junit . Test ; public class TestNetUtil { @Test public void testParseString ( ) { String aStringWithPort = ""1 . 2 . 3 . 4 : 1234"" ; HostAndPort hostAndPortForAStringWithPort = NetUtil . parseString ( aStringWithPort , 0 ) ; assertEquals ( hostAndPortForAStringWithPort . getHost ( ) , ""1 . 2 . 3 . 4"" ) ; assertEquals ( hostAndPortForAStringWithPort . getPort ( ) , 1234 ) ; String aStringWithoutPort = ""1 . 2 . 3 . 4"" ; HostAndPort hostAndPortForAStringWithoutPort = NetUtil . parseString ( aStringWithoutPort , 12345 ) ; assertEquals ( hostAndPortForAStringWithoutPort . getHost ( ) , ""1 . 2 . 3 . 4"" ) ; assertEquals ( hostAndPortForAStringWithoutPort . getPort ( ) , 12345 ) ; } }
",,,"import static org . junit . Assert . assertArrayEquals ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; import java . net . InetAddress ; import java . net . InetSocketAddress ; import java . util . Arrays ; import java . util . List ; import org . apache . kudu . client . HostAndPort ; import org . junit . Test ; /* * * Test for { @link NetUtil } . */ public class TestNetUtil { /* * < |startfocus| > * Tests parsing strings into { @link InetSocketAddress } objects with and without specifying < |endfocus| > * the port in the string . */ @Test public void testParseString ( ) { String aStringWithPort = ""1 . 2 . 3 . 4 : 1234"" ; HostAndPort hostAndPortForAStringWithPort = NetUtil . parseString ( aStringWithPort , 0 ) ; assertEquals ( hostAndPortForAStringWithPort . getHost ( ) , ""1 . 2 . 3 . 4"" ) ; assertEquals ( hostAndPortForAStringWithPort . getPort ( ) , 1234 ) ; String aStringWithoutPort = ""1 . 2 . 3 . 4"" ; HostAndPort hostAndPortForAStringWithoutPort = NetUtil . parseString ( aStringWithoutPort , 12345 ) ;
",,
1278,"FunctionCallExpr mergeAggInputFn ) { super ( ) ; fnName_ = fnName ; params_ = params ; mergeAggInputFn_ = mergeAggInputFn == null ? null : ( FunctionCallExpr ) mergeAggInputFn . clone ( ) ; if ( params . exprs ( ) != null ) children_ = Lists . newArrayList ( params_ . exprs ( ) ) ; } /* * * Returns an Expr that evaluates the function call < fnName > ( < params > ) . The returned * Expr is not necessarily a FunctionCallExpr ( example : DECODE ( ) ) */ public static Expr createExpr ( FunctionName fnName , FunctionParams params ) throws AnalysisException { FunctionCallExpr functionCallExpr = new FunctionCallExpr ( fnName , params ) ; if ( fnName . getFnNamePath ( ) . size ( ) == 1 && fnName . getFnNamePath ( ) . get ( 0 ) . equalsIgnoreCase ( ""decode"" ) || fnName . getFnNamePath ( ) . size ( ) == 2 && fnName . getFnNamePath ( ) . get ( 0 ) . equalsIgnoreCase ( Catalog . BUILTINS_DB ) && fnName . getFnNamePath ( ) . get ( 1 ) . equalsIgnoreCase ( ""decode"" ) ) { return new CaseExpr ( functionCallExpr ) ; } return functionCallExpr ; }
","public static Expr createExpr ( FunctionName fnName , FunctionParams params ) throws AnalysisException {
","public static Expr createExpr(FunctionName fnName, FunctionParams params) { Preconditions.checkNotNull(params);
",,,"public static Expr createExpr(FunctionName fnName, FunctionParams params) {
",,,"public static Expr createExpr ( FunctionName fnName , FunctionParams params , FunctionCallExpr mergeAggInputFn ) { fnName_ = fnName ; params_ = params ; mergeAggInputFn_ = mergeAggInputFn == null ? null : ( FunctionCallExpr ) mergeAggInputFn . clone ( ) ; if ( params == null || params . exprs ( ) == null ) { children_ = null ; } else { children_ = Lists . newArrayList ( params . exprs ( ) ) ; } FunctionCallExpr functionCallExpr = new FunctionCallExpr ( fnName_ , params_ ) ; if ( fnName_ . getFnNamePath ( ) . size ( ) == 1 && fnName_ . getFnNamePath ( ) . get ( 0 ) . equalsIgnoreCase ( ""decode"" ) || fnName_ . getFnNamePath ( ) . size ( ) == 2 && fnName_ . getFnNamePath ( ) . get ( 0 ) . equalsIgnoreCase ( Catalog . BUILTINS_DB ) && fnName_ . getFnNamePath ( ) . get ( 1 ) . equalsIgnoreCase ( ""decode"" ) ) { return new CaseExpr ( functionCallExpr ) ; } return functionCallExpr ; }
",,,"FunctionCallExpr mergeAggInputFn ) { super ( ) ; fnName_ = fnName ; params_ = params ; mergeAggInputFn_ = mergeAggInputFn == null ? null : ( FunctionCallExpr ) mergeAggInputFn . clone ( ) ; if ( params . exprs ( ) != null ) { children_ = Lists . newArrayList ( params_ . exprs ( ) ) ; } } public static Expr createExpr ( FunctionName fnName , FunctionParams params ) { FunctionCallExpr functionCallExpr = new FunctionCallExpr ( fnName , params ) ; if ( fnName . getFnNamePath ( ) . size ( ) == 1 && fnName . getFnNamePath ( ) . get ( 0 ) . equalsIgnoreCase ( ""decode"" ) || fnName . getFnNamePath ( ) . size ( ) == 2 && fnName . getFnNamePath ( ) . get ( 0 ) . equalsIgnoreCase ( Catalog . BUILTINS_DB ) && fnName . getFnNamePath ( ) . get ( 1 ) . equalsIgnoreCase ( ""decode"" ) ) { return new CaseExpr ( functionCallExpr ) ; } return functionCallExpr ; }
",,,"FunctionCallExpr mergeAggInputFn ) { super ( ) ; fnName_ = fnName ; params_ = params ; mergeAggInputFn_ = mergeAggInputFn == null ? null : ( FunctionCallExpr ) mergeAggInputFn . clone ( ) ; if ( params . exprs ( ) != null ) children_ = Lists . newArrayList ( params_ . exprs ( ) ) ; } /* * * Returns an Expr that evaluates the function call < fnName > ( < params > ) . The returned * Expr is not necessarily a FunctionCallExpr ( example : DECODE ( ) ) */ < |startfocus| > public static Expr createExpr ( FunctionName fnName , FunctionParams params ) { < |endfocus| > FunctionCallExpr functionCallExpr = new FunctionCallExpr ( fnName , params ) ; if ( fnName . getFnNamePath ( ) . size ( ) == 1 && fnName . getFnNamePath ( ) . get ( 0 ) . equalsIgnoreCase ( ""decode"" ) || fnName . getFnNamePath ( ) . size ( ) == 2 && fnName . getFnNamePath ( ) . get ( 0 ) . equalsIgnoreCase ( Catalog . BUILTINS_DB ) && fnName . getFnNamePath ( ) . get ( 1 ) . equalsIgnoreCase ( ""decode"" ) ) { return new CaseExpr ( functionCallExpr ) ; } return functionCallExpr ; }
",,
1299,"import org . apache . impala . catalog . Type ; import org . apache . impala . common . AnalysisException ; import org . apache . impala . thrift . TExprNode ; import org . apache . impala . thrift . TExprNodeType ; import org . apache . impala . thrift . TSlotRef ; import com . google . common . base . Joiner ; import com . google . common . base . Objects ; import com . google . common . base . Preconditions ; public class SlotRef extends Expr { // Magic number to use to decide whether to adjust the // reported NDV value to account for possible null values . // Above this number , the adjustment is not that helpful . // Further , a higher value causes TPC - H plan tests to // fail because that has several two - value , non - nullable // fields that are marked as nullable . private static final int NULL_ADJUST_THRESHOLD = 1 ; private final List < String > rawPath_ ; private final String label_ ; // printed in toSql ( ) // Results of analysis . private SlotDescriptor desc_ ; public SlotRef ( ArrayList < String > rawPath ) { super ( ) ; rawPath_ = rawPath ; label_ = ToSqlUtils . getPathSql ( rawPath_ ) ; }
","// Above this number , the adjustment is not that helpful . // Further , a higher value causes TPC - H plan tests to
","// above this number, theAdjustment does not add value. // making this value any higher causes Tpc-H plan tests to
",,,"// Above this number, the adjustment does not add value. // Making this value any higher causes TPC-H plan tests to
",,,"import org . apache . impala . catalog . Type ; import org . apache . impala . common . AnalysisException ; import org . apache . impala . thrift . TExprNode ; import org . apache . impala . thrift . TExprNodeType ; import org . apache . impala . thrift . TSlotRef ; import com . google . common . base . Joiner ; import com . google . common . base . Objects ; import com . google . common . base . Preconditions ; public class SlotRef extends Expr { private static final int NULL_ADJUST_THRESHOLD = 1 ; private final List < String > rawPath_ ; private final String label_ ; private SlotDescriptor desc_ ; public SlotRef ( ArrayList < String > rawPath ) { super ( ) ; rawPath_ = rawPath ; label_ = ToSqlUtils . getPathSql ( rawPath_ ) ; } }
",,,"import org . apache . impala . catalog . Type ; import org . apache . impala . common . AnalysisException ; import org . apache . impala . thrift . TExprNode ; import org . apache . impala . thrift . TExprNodeType ; import org . apache . impala . thrift . TSlotRef ; import com . google . common . base . Joiner ; import com . google . common . base . Objects ; import com . google . common . base . Preconditions ; public class SlotRef extends Expr { private static final int NULL_ADJUST_THRESHOLD = 1 ; private final List < String > rawPath_ ; private final String label_ ; private SlotDescriptor desc_ ; public SlotRef ( ArrayList < String > rawPath ) { super ( ) ; rawPath_ = rawPath ; label_ = ToSqlUtils . getPathSql ( rawPath_ ) ; } }
",,,"import org . apache . impala . catalog . Type ; import org . apache . impala . common . AnalysisException ; import org . apache . impala . thrift . TExprNode ; import org . apache . impala . thrift . TExprNodeType ; import org . apache . impala . thrift . TSlotRef ; import com . google . common . base . Joiner ; import com . google . common . base . Objects ; import com . google . common . base . Preconditions ; public class SlotRef extends Expr { // Magic number to use to decide whether to adjust the // reported NDV value to account for possible null values . < |startfocus| > // Above this number , the adjustment does not make sense . // Making this value any higher causes TPC - H plan tests to < |endfocus| > // fail because that has several two - value , non - nullable // fields that are marked as nullable . private static final int NULL_ADJUST_THRESHOLD = 1 ; private final List < String > rawPath_ ; private final String label_ ; // printed in toSql ( ) // Results of analysis . private SlotDescriptor desc_ ; public SlotRef ( ArrayList < String > rawPath ) { super ( ) ; rawPath_ = rawPath ; label_ = ToSqlUtils . getPathSql ( rawPath_ ) ; }
",,
1329,"Lists . newArrayList ( new CaseWhenClause ( // WHEN cond THEN thenExpr expr . getChild ( 0 ) , expr . getChild ( 1 ) ) ) , expr . getChild ( 2 ) ) ; // ELSE elseExpr END } /* * * Rewrites IFNULL ( a , x ) , which is an alias * for ISNULL ( a , x ) and NVL ( a , x ) . * * IFNULL ( NULL , x ) -- > x * IFNULL ( a , x ) -- > a , if a is a non - null literal * IFNULL ( a , x ) -- > * CASE WHEN a IS NULL THEN x ELSE a END */ private Expr rewriteIfNullFn ( FunctionCallExpr expr ) { Preconditions . checkState ( expr . getChildren ( ) . size ( ) == 2 ) ; Expr child0 = expr . getChild ( 0 ) ; return new CaseExpr ( null , // CASE Lists . newArrayList ( new CaseWhenClause ( // WHEN a IS NULL new IsNullPredicate ( child0 , false ) , expr . getChild ( 1 ) ) ) , // THEN x child0 . clone ( ) ) ; // ELSE a END } /* *
","* IFNULL ( a , x ) -- >
","* IFNULL(a, x) --> x
",,,"* IFNULL(a, x) --> <br> *
",,,"Lists . newArrayList ( new CaseWhenClause ( new IsNullPredicate ( expr . getChild ( 0 ) , false ) , expr . getChild ( 1 ) ) , expr . getChild ( 0 ) . clone ( ) ) ;
",,,"Lists . newArrayList ( new CaseWhenClause ( expr . getChild ( 0 ) , expr . getChild ( 1 ) ) ) , expr . getChild ( 2 ) ) ; // ELSE elseExpr END /* * * Rewrites IFNULL ( a , x ) , which is an alias * for ISNULL ( a , x ) and NVL ( a , x ) . * * IFNULL ( NULL , x ) -- > x * IFNULL ( a , x ) -- > a , if a is a non - null literal * IFNULL ( a , x ) -- > * CASE WHEN a IS NULL THEN x ELSE a END */ private Expr rewriteIfNullFn ( FunctionCallExpr expr ) { Preconditions . checkState ( expr . getChildren ( ) . size ( ) == 2 ) ; Expr child0 = expr . getChild ( 0 ) ; return new CaseExpr ( null , // CASE Lists . newArrayList ( new CaseWhenClause ( new IsNullPredicate ( child0 , false ) , expr . getChild ( 1 ) ) ) , // THEN x child0 . clone ( ) // ELSE a ) ; }
",,,"Lists . newArrayList ( new CaseWhenClause ( // WHEN cond THEN thenExpr expr . getChild ( 0 ) , expr . getChild ( 1 ) ) ) , expr . getChild ( 2 ) ) ; // ELSE elseExpr END } /* * * Rewrites IFNULL ( a , x ) , which is an alias * for ISNULL ( a , x ) and NVL ( a , x ) . * * IFNULL ( NULL , x ) -- > x * IFNULL ( a , x ) -- > a , if a is a non - null literal < |startfocus| > * IFNULL ( a , x ) -- > < |endfocus| > * CASE WHEN a IS NULL THEN x ELSE a END */ private Expr rewriteIfNullFn ( FunctionCallExpr expr ) { Preconditions . checkState ( expr . getChildren ( ) . size ( ) == 2 ) ; Expr child0 = expr . getChild ( 0 ) ; return new CaseExpr ( null , // CASE Lists . newArrayList ( new CaseWhenClause ( // WHEN a IS NULL new IsNullPredicate ( child0 , false ) , expr . getChild ( 1 ) ) ) , // THEN x child0 . clone ( ) ) ; // ELSE a END } /* *
",,
1334,"return ret ; } } public Expr RewritesOk ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOk ( ""functional . alltypessmall"" , exprStr , rule , expectedExprStr ) ; } public Expr RewritesOk ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOk ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } public Expr RewritesOk ( String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { return RewritesOk ( ""functional . alltypessmall"" , exprStr , rules , expectedExprStr ) ; } public Expr RewritesOk ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = ""select "" + exprStr + "" from "" + tableName ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getSelectList ( ) . getItems ( ) . get ( 0 ) . getExpr ( ) ;
","public Expr RewritesOk ( String exprStr , List < ExprRewriteRule > rules , String expectedExprStr )
","public ExprRewritesOk(String exprStr, List<ExprRewriteRule> rules, String expectedExprStr)
",,,"public Expr RewritesOk(String exprStr, List<ExprRewriteRule> rules, String expectedExprStr)
",,,"public Expr RewritesOk ( String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { return RewritesOk ( ""functional . alltypessmall"" , exprStr , rules , expectedExprStr ) ; } public Expr RewritesOk ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = ""select "" + exprStr + "" from "" + tableName ; SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getSelectList ( ) . getItems ( ) . get ( 0 ) . getExpr ( ) ; return ret ; }
",,,"public Expr RewritesOk ( String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { return RewritesOk ( ""functional . alltypessmall"" , exprStr , rules , expectedExprStr ) ; } public Expr RewritesOk ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = ""select "" + exprStr + "" from "" + tableName ; SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getSelectList ( ) . getItems ( ) . get ( 0 ) . getExpr ( ) ; Expr rewrittenExpr = origExpr ; for ( ExprRewriteRule rule : rules ) { rewrittenExpr = rule . apply ( rewrittenExpr , analyzer_ ) ; } String rewrittenExprStr = rewrittenExpr . toSql ( ) ; Assert . assertEquals ( expectedExprStr , rewrittenExprStr ) ; return rewrittenExpr ; }
",,,"return ret ; } } public Expr RewritesOk ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOk ( ""functional . alltypessmall"" , exprStr , rule , expectedExprStr ) ; } public Expr RewritesOk ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOk ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } < |startfocus| > public Expr RewritesOk ( String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) < |endfocus| > throws ImpalaException { return RewritesOk ( ""functional . alltypessmall"" , exprStr , rules , expectedExprStr ) ; } public Expr RewritesOk ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = ""select "" + exprStr + "" from "" + tableName ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getSelectList ( ) . getItems ( ) . get ( 0 ) . getExpr ( ) ; Expr expr = origExpr . clone ( ) ;
",,
1345,"private void assertToSqlWithImplicitCasts ( AnalysisContext ctx , String query , String expectedToSqlWithImplicitCasts ) { StatementBase stmt = ( StatementBase ) AnalyzesOk ( query , ctx ) ; String actual = stmt . toSql ( SHOW_IMPLICIT_CASTS ) ; Assert . assertEquals ( ""Bad sql with implicit casts from original query : \n"" + query , expectedToSqlWithImplicitCasts , actual ) ;
","< |del| >/ / AnalyzesOk ( stmt . toSql ( true ) , ctx ) ;
","// AnalyzesOk(stmt.toSql(true), ctx);
",,,"<|del|>
",,,"private void assertToSqlWithImplicitCasts ( AnalysisContext ctx , String query , String expectedToSqlWithImplicitCasts ) { StatementBase stmt = ( StatementBase ) AnalyzesOk ( query , ctx ) ; String actual = stmt . toSql ( SHOW_IMPLICIT_CASTS ) ; Assert . assertEquals ( ""Bad sql with implicit casts from original query : \n"" + query , expectedToSqlWithImplicitCasts , actual ) ; }
",,,"private void assertToSqlWithImplicitCasts ( AnalysisContext ctx , String query , String expectedToSqlWithImplicitCasts ) { StatementBase stmt = ( StatementBase ) AnalyzesOk ( query , ctx ) ; String actual = stmt . toSql ( SHOW_IMPLICIT_CASTS ) ; Assert . assertEquals ( ""Bad sql with implicit casts from original query : \n"" + query , expectedToSqlWithImplicitCasts , actual ) ; }
",,,"private void assertToSqlWithImplicitCasts ( AnalysisContext ctx , String query , String expectedToSqlWithImplicitCasts ) { StatementBase stmt = ( StatementBase ) AnalyzesOk ( query , ctx ) ; < |startfocus| > // AnalyzesOk ( stmt . toSql ( true ) , ctx ) ; < |endfocus| > String actual = stmt . toSql ( SHOW_IMPLICIT_CASTS ) ; Assert . assertEquals ( ""Bad sql with implicit casts from original query : \n"" + query , expectedToSqlWithImplicitCasts , actual ) ;
",,
1346,"ignoreExplainHeader ) ; } catch ( CatalogException e ) { errorLog . append ( String . format ( ""Failed to plan query\n % s\n % s"" , testCase . getQuery ( ) , e . getMessage ( ) ) ) ; } actualOutput . append ( "" == == \n"" ) ; } // Create the actual output file if ( GENERATE_OUTPUT_FILE ) { try { outDir_ . toFile ( ) . mkdirs ( ) ; FileWriter fw = new FileWriter ( outDir_ . resolve ( testFile + "" . test"" ) . toFile ( ) ) ; fw . write ( actualOutput . toString ( ) ) ; fw . close ( ) ; } catch ( IOException e ) { errorLog . append ( ""Unable to create output file : "" + e . getMessage ( ) ) ; } } if ( errorLog . length ( ) != 0 ) { fail ( errorLog . toString ( ) ) ; }
","outDir_ . toFile ( ) . mkdirs ( ) ; FileWriter fw = new FileWriter ( outDir_ . resolve ( testFile + "" . test"" ) . toFile ( ) ) ;
","File outDirFile = new File(outDir_); outDirFile.mkdirs(); FileWriter fw = new FileWriter(outDir_ + testFile + "".test"");
",,,"File outDirFile = new File(outDir_); outDirFile.mkdirs(); FileWriter fw = new FileWriter(outDir_ + testFile + "".test"");
",,,"try { QueryPlan plan = planner . plan ( query , txn ) ; actualOutput . append ( plan . toString ( ) ) ; } catch ( QueryPlannerException e ) { errorLog . append ( String . format ( ""Failed to plan query\n % s\n % s"" , testCase . getQuery ( ) , e . getMessage ( ) ) ) ; } catch ( CatalogException e ) { errorLog . append ( String . format ( ""Failed to plan query\n % s\n % s"" , testCase . getQuery ( ) , e . getMessage ( ) ) ) ; } actualOutput . append ( "" == == \n"" ) ; if ( GENERATE_OUTPUT_FILE ) { try { File outDirFile = new File ( outDir_ ) ; outDirFile . mkdirs ( ) ; FileWriter fw = new FileWriter ( outDir_ + testFile + "" . test"" ) ; fw . write ( actualOutput . toString ( ) ) ; fw . close ( ) ; } catch ( IOException e ) { errorLog . append ( ""Unable to create output file : "" + e . getMessage ( ) ) ; } } if ( errorLog . length ( ) != 0 ) { fail ( errorLog . toString ( ) ) ; }
",,,"import org . apache . hyracks . algebricks . core . algebra . operators . logical . IndexInsertDeleteUpsertOperator ; import org . apache . hyracks . algebricks . core . algebra . operators . logical . InsertDeleteUpsertOperator ; import org . apache . hyracks . algebricks . core . algebra . operators . logical . InsertDeleteUpsertOperator . Kind ; import org . apache . hyracks . algebricks . core . algebra . operators . logical . SinkOperator ; import org . apache . hyracks . algebricks . core . rewriter . base . IAlgebraicRewriteRule ; public class ReplaceSinkOpWithCommitOpRule implements IAlgebraicRewriteRule { @Override public boolean rewritePre ( Mutable < ILogicalOperator > opRef , IOptimizationContext context ) throws AlgebricksException { return false ; } @Override public boolean rewritePost ( Mutable < ILogicalOperator > opRef , IOptimizationContext context ) throws AlgebricksException { AbstractLogicalOperator op = ( AbstractLogicalOperator ) opRef . getValue ( ) ; if ( op . getOperatorTag ( ) != LogicalOperatorTag . SINK ) { return false ; } SinkOperator sinkOperator = ( SinkOperator ) op ; List < Mutable < ILogicalExpression > > primaryKeyExprs = null ; int datasetId = 0 ; AbstractLogicalOperator descendantOp = ( AbstractLogicalOperator ) sinkOperator . getInputs ( ) . get ( 0 ) . getValue ( ) ; LogicalVariable upsertVar = null ; // TODO Auto - generated method stub return false ; } }
",,,"ignoreExplainHeader ) ; } catch ( CatalogException e ) { errorLog . append ( String . format ( ""Failed to plan query\n % s\n % s"" , testCase . getQuery ( ) , e . getMessage ( ) ) ) ; } actualOutput . append ( "" == == \n"" ) ; } if ( GENERATE_OUTPUT_FILE ) { try { < |startfocus| > File outDirFile = new File ( outDir_ ) ; outDirFile . mkdirs ( ) ; FileWriter fw = new FileWriter ( outDir_ + testFile + "" . test"" ) ; < |endfocus| > fw . write ( actualOutput . toString ( ) ) ; fw . close ( ) ; } catch ( IOException e ) { errorLog . append ( ""Unable to create output file : "" + e . getMessage ( ) ) ; } } if ( errorLog . length ( ) != 0 ) { fail ( errorLog . toString ( ) ) ; }
",,
1349,"assertWrap ( ""insert into foo values ( ' "" + "" "" + "" ' ) "" , ""insert into foo values ( ' \n"" + ""' ) "" ) ; // test that long words are broken up for clarity assertWrap ( ""select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" , ""select\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxx"" ) ; } /* * * Check that code that has been wrapped is correctly formatted . * @param expected what it should be */ private void assertWrap ( String input , String expected ) { String actual = PrintUtils . wrapString ( input , WRAP_LENGTH ) ; assertEquals ( expected , actual ) ; assertNoBlankLines ( actual ) ; assertNoTerminatingNewline ( actual ) ; assertNoLongLines ( actual ) ; } /* * * Assert that all lines of wrapped output are 80 chars or less . */ private void assertNoLongLines ( String s ) { for ( String line : s . split ( ""\n"" ) ) {
","* Check that code that has been wrapped is correctly formatted .
","* Check that code that has been wrapped is correctly formatted * @param input input to wrap
",,,"* Check that code that has been wrapped is correctly formatted. * @param input input to wrap
",,,"String input1 = ""insert into foo values ( ' "" + "" "" + "" ' ) "" ; String expected1 = ""insert into foo values ( ' \n"" + ""' ) "" ; String input2 = ""select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" ; String expected2 = ""select\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxx"" ; assertWrap ( input1 , expected1 ) ; assertWrap ( input2 , expected2 ) ; private void assertWrap ( String input , String expected ) { String actual = PrintUtils . wrapString ( input , WRAP_LENGTH ) ; assertEquals ( expected , actual ) ; assertNoBlankLines ( actual ) ; assertNoTerminatingNewline ( actual ) ; assertNoLongLines ( actual ) ; } private void assertNoLongLines ( String s ) { for ( String line : s . split ( ""\n"" ) ) { if ( line . length ( ) > WRAP_LENGTH ) { fail ( ""Line too long : "" + line ) ; } } }
",,,"assertWrap ( ""insert into foo values ( ' "" + "" "" + "" ' ) "" , ""insert into foo values ( ' \n"" + ""' ) "" ) ; // test that long words are broken up for clarity assertWrap ( ""select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" , ""select\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxx"" ) ; private void assertWrap ( String input , String expected ) { String actual = PrintUtils . wrapString ( input , WRAP_LENGTH ) ; assertEquals ( expected , actual ) ; assertNoBlankLines ( actual ) ; assertNoTerminatingNewline ( actual ) ; assertNoLongLines ( actual ) ; } private void assertNoLongLines ( String s ) { for ( String line : s . split ( ""\n"" ) ) { assertTrue ( line . length ( ) <= 80 ) ; } }
",,,"assertWrap ( ""insert into foo values ( ' "" + "" "" + "" ' ) "" , ""insert into foo values ( ' \n"" + ""' ) "" ) ; // test that long words are broken up for clarity assertWrap ( ""select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" , ""select\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxx"" ) ; } /* * < |startfocus| > * Check that code that has been wrapped is correctly formatted * @param input input to wrap < |endfocus| > * @param expected what it should be */ private void assertWrap ( String input , String expected ) { String actual = PrintUtils . wrapString ( input , WRAP_LENGTH ) ; assertEquals ( expected , actual ) ; assertNoBlankLines ( actual ) ; assertNoTerminatingNewline ( actual ) ; assertNoLongLines ( actual ) ; } /* * * Assert that all lines of wrapped output are 80 chars or less . */ private void assertNoLongLines ( String s ) { for ( String line : s . split ( ""\n"" ) ) {
",,
1350,"+ "" "" + "" ' ) "" , ""insert into foo values ( ' \n"" + ""' ) "" ) ; // test that long words are broken up for clarity assertWrap ( ""select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" , ""select\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxx"" ) ; } /* * * Check that code that has been wrapped is correctly formatted . * @param expected what it should be */ private void assertWrap ( String input , String expected ) { String actual = PrintUtils . wrapString ( input , WRAP_LENGTH ) ; assertEquals ( expected , actual ) ; assertNoBlankLines ( actual ) ; assertNoTerminatingNewline ( actual ) ; assertNoLongLines ( actual ) ; } /* * * Assert that all lines of wrapped output are 80 chars or less . */ private void assertNoLongLines ( String s ) { for ( String line : s . split ( ""\n"" ) ) {
","* Check that code that has been wrapped is correctly formatted .
","* Check that code that has been wrapped is correctly formatted * @param input input to wrap
",,,"* Check that code that has been wrapped is correctly formatted * @param input input to wrap
",,,"String query1 = ""insert into foo values ( '"" + longValue . replaceAll ( ""'"" , ""''"" ) + ""' ) "" ; // test that long words are broken up for clarity assertWrap ( ""select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" , ""select\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxx"" ) ; private void assertWrap ( String input , String expected ) { String actual = PrintUtils . wrapString ( input , WRAP_LENGTH ) ; assertEquals ( expected , actual ) ; assertNoBlankLines ( actual ) ; assertNoTerminatingNewline ( actual ) ; assertNoLongLines ( actual ) ; } private void assertNoLongLines ( String s ) { for ( String line : s . split ( ""\n"" ) ) { assertTrue ( line . length ( ) <= WRAP_LENGTH ) ; } }
",,,"public static void openDrawer ( int drawerLayoutId , int gravity ) { onView ( withId ( drawerLayoutId ) ) . perform ( open ( gravity ) ) ; } + "" "" + "" ' ) "" , ""insert into foo values ( ' \n"" + ""' ) "" ) ; // test that long words are broken up for clarity assertWrap ( ""select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" , ""select\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxx"" ) ; private void assertWrap ( String input , String expected ) { String actual = PrintUtils . wrapString ( input , WRAP_LENGTH ) ; assertEquals ( expected , actual ) ; assertNoBlankLines ( actual ) ; assertNoTerminatingNewline ( actual ) ; assertNoLongLines ( actual ) ; } private void assertNoLongLines ( String s ) { for ( String line : s . split ( ""\n"" ) ) { if ( line . length ( ) > MAX_LINE_LENGTH ) { fail ( ""Line exceeds maximum length : "" + line ) ; } } }
",,,"+ "" "" + "" ' ) "" , ""insert into foo values ( ' \n"" + ""' ) "" ) ; // test that long words are broken up for clarity assertWrap ( ""select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"" , ""select\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"" + ""xxxxxxxxxxxxxxxxxxxxxxxxx"" ) ; } /* * < |startfocus| > * Check that code that has been wrapped is correctly formatted * @param input input to wrap < |endfocus| > * @param expected what it should be */ private void assertWrap ( String input , String expected ) { String actual = PrintUtils . wrapString ( input , WRAP_LENGTH ) ; assertEquals ( expected , actual ) ; assertNoBlankLines ( actual ) ; assertNoTerminatingNewline ( actual ) ; assertNoLongLines ( actual ) ; } /* * * Assert that all lines of wrapped output are 80 chars or less . */ private void assertNoLongLines ( String s ) { for ( String line : s . split ( ""\n"" ) ) {
",,
1356,"public static ExprRewriteRule INSTANCE = new FoldConstantsRule ( ) ; @Override public Expr apply ( Expr expr , Analyzer analyzer ) throws AnalysisException { // Avoid calling Expr . isConstant ( ) because that would lead to repeated traversals // of the Expr tree . Assumes the bottom - up application of this rule . Constant // children should have been folded at this point . for ( Expr child : expr . getChildren ( ) ) if ( ! Expr . IS_LITERAL . apply ( child ) ) return expr ; if ( Expr . IS_LITERAL . apply ( expr ) || ! expr . isConstant ( ) ) return expr ; // Do not constant fold cast ( null as dataType ) because we cannot preserve the // cast - to - types and that can lead to query failures , e . g . , CTAS if ( expr instanceof CastExpr ) { CastExpr castExpr = ( CastExpr ) expr ; if ( castExpr . getChild ( 0 ) instanceof NullLiteral ) { return expr ; } } // Analyze constant exprs , if necessary . Note that the 'expr' may become non - constant // after analysis ( e . g . , aggregate functions ) . if ( ! expr . isAnalyzed ( ) ) {
","for ( Expr child : expr . getChildren ( ) ) if ( ! Expr . IS_LITERAL . apply ( child ) ) return expr ; if ( Expr . IS_LITERAL . apply ( expr ) || ! expr . isConstant ( ) ) return expr ;
","if (!expr.getChildren().isEmpty()) return expr;
",,,"if (expr.isLiteral() || expr.isConstant()) return expr;
",,,"public static ExprRewriteRule INSTANCE = new FoldConstantsRule ( ) ; @Override public Expr apply ( Expr expr , Analyzer analyzer ) throws AnalysisException { for ( Expr child : expr . getChildren ( ) ) { if ( ! child . isLiteral ( ) ) { return expr ; } } if ( expr . isLiteral ( ) || ! expr . isConstant ( ) ) { return expr ; } if ( expr instanceof CastExpr ) { CastExpr castExpr = ( CastExpr ) expr ; if ( castExpr . getChild ( 0 ) instanceof NullLiteral ) { return expr ; } } if ( ! expr . isAnalyzed ( ) ) { // Analyze constant exprs , if necessary . Note that the 'expr' may become non - constant // after analysis ( e . g . , aggregate functions ) . } return expr ; }
",,,"public static ExprRewriteRule INSTANCE = new FoldConstantsRule ( ) ; @Override public Expr apply ( Expr expr , Analyzer analyzer ) throws AnalysisException { for ( Expr child : expr . getChildren ( ) ) { if ( ! child . isLiteral ( ) ) { return expr ; } } if ( expr . isLiteral ( ) || ! expr . isConstant ( ) ) { return expr ; } if ( expr instanceof CastExpr ) { CastExpr castExpr = ( CastExpr ) expr ; if ( castExpr . getChild ( 0 ) instanceof NullLiteral ) { return expr ; } } if ( ! expr . isAnalyzed ( ) ) { expr . analyze ( analyzer ) ; } return expr ; }
",,,"public static ExprRewriteRule INSTANCE = new FoldConstantsRule ( ) ; @Override public Expr apply ( Expr expr , Analyzer analyzer ) throws AnalysisException { // Avoid calling Expr . isConstant ( ) because that would lead to repeated traversals // of the Expr tree . Assumes the bottom - up application of this rule . Constant // children should have been folded at this point . < |startfocus| > for ( Expr child : expr . getChildren ( ) ) if ( ! child . isLiteral ( ) ) return expr ; if ( expr . isLiteral ( ) || ! expr . isConstant ( ) ) return expr ; < |endfocus| > // Do not constant fold cast ( null as dataType ) because we cannot preserve the // cast - to - types and that can lead to query failures , e . g . , CTAS if ( expr instanceof CastExpr ) { CastExpr castExpr = ( CastExpr ) expr ; if ( castExpr . getChild ( 0 ) instanceof NullLiteral ) { return expr ; } } // Analyze constant exprs , if necessary . Note that the 'expr' may become non - constant // after analysis ( e . g . , aggregate functions ) . if ( ! expr . isAnalyzed ( ) ) {
",,
1366,"public < C extends TreeNode < NodeType > > boolean contains ( Class < C > cl ) { if ( cl . equals ( getClass ( ) ) ) return true ; for ( NodeType child : children_ ) if ( child . contains ( cl ) ) return true ; return false ;
","public < C extends TreeNode < NodeType > > boolean contains ( Class < C > cl ) {
","boolean contains(Class<? extends TreeNode<NodeType>> cl) {
",,,"public <C extends TreeNode<NodeType>> boolean contains(Class<?> cl) {
",,,"public < C extends TreeNode < NodeType > > boolean contains ( Class < C > cl ) { if ( cl . equals ( getClass ( ) ) ) return true ; for ( NodeType child : children_ ) if ( child . contains ( cl ) ) return true ; return false ; }
",,,"public boolean contains ( Class < ? > cl ) { if ( cl . equals ( getClass ( ) ) ) return true ; for ( NodeType child : children_ ) { if ( child . contains ( cl ) ) return true ; } return false ; }
",,,"< |startfocus| > public < C extends TreeNode < NodeType > > boolean contains ( Class < C > cl ) { < |endfocus| > if ( cl . equals ( getClass ( ) ) ) return true ; for ( NodeType child : children_ ) if ( child . contains ( cl ) ) return true ; return false ;
",,
1371,"Function fn = Function . createFunction ( ""mydb"" , ""fn1"" , args , Type . INT , false , TFunctionBinaryType . JAVA ) ; try { ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; } catch ( UnsupportedOperationException e ) { // Expected } } { // Java function , leave off location and symbol List < Type > args = new ArrayList < > ( ) ; Function fn = new ScalarFunction ( new FunctionName ( ""mydb"" , ""fn1"" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = ""CREATE FUNCTION mydb . fn1\n"" ; assertEquals ( expected , sql ) ; } { // Java function , with location and symbol List < Type > args = new ArrayList < > ( ) ; ScalarFunction fn = new ScalarFunction ( new FunctionName ( ""mydb"" , ""fn1"" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; fn . setLocation ( new HdfsUri ( ""hdfs :/ / foo : 123 / fns / myfunc . jar"" ) ) ;
","Function fn = new ScalarFunction ( new FunctionName ( ""mydb"" , ""fn1"" ) , args , Type . INT , false ) ;
","Function fn = new ScalarFunction(new FunctionName(""mydb"", ""fn1""), args, Type.INT, false);
",,,"Function fn = new ScalarFunction(new FunctionName(""mydb"", ""fn1"", args, Type.INT, false);
",,,"Function fn = new ScalarFunction ( new FunctionName ( ""mydb"" , ""fn1"" ) , new ArrayList < > ( ) , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = ""CREATE FUNCTION mydb . fn1\n"" ; assertEquals ( expected , sql ) ;
",,,"Function fn = Function . createFunction ( ""mydb"" , ""fn1"" , args , Type . INT , false , TFunctionBinaryType . JAVA ) ; try { ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; } catch ( UnsupportedOperationException e ) { // Expected } { // Java function , leave off location and symbol List < Type > args = new ArrayList < > ( ) ; Function fn = new ScalarFunction ( new FunctionName ( ""mydb"" , ""fn1"" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = ""CREATE FUNCTION mydb . fn1\n"" ; assertEquals ( expected , sql ) ; } { // Java function , with location and symbol List < Type > args = new ArrayList < > ( ) ; ScalarFunction fn = new ScalarFunction ( new FunctionName ( ""mydb"" , ""fn1"" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; fn . setLocation ( new HdfsUri ( ""hdfs :/ / foo : 123 / fns / myfunc . jar"" ) ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = ""CREATE FUNCTION mydb . fn1\n"" ; assertEquals ( expected , sql ) ; }
",,,"Function fn = Function . createFunction ( ""mydb"" , ""fn1"" , args , Type . INT , false , TFunctionBinaryType . JAVA ) ; try { ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; } catch ( UnsupportedOperationException e ) { // Expected } } { // Java function , leave off location and symbol List < Type > args = new ArrayList < > ( ) ; < |startfocus| > Function fn = new ScalarFunction ( new FunctionName ( ""mydb"" , ""fn1"" ) , args , Type . INT , false ) ; < |endfocus| > fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = ""CREATE FUNCTION mydb . fn1\n"" ; assertEquals ( expected , sql ) ; } { // Java function , with location and symbol List < Type > args = new ArrayList < > ( ) ; ScalarFunction fn = new ScalarFunction ( new FunctionName ( ""mydb"" , ""fn1"" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; fn . setLocation ( new HdfsUri ( ""hdfs :/ / foo : 123 / fns / myfunc . jar"" ) ) ; fn . setSymbolName ( ""myfunc"" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = ""CREATE FUNCTION mydb . fn1\n"" + ""LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . jar'\n"" + ""SYMBOL = 'myfunc'\n"" ; assertEquals ( expected , sql ) ; } { // Hive function , with location and symbol List < Type > args = new ArrayList < > ( ) ; ScalarFunction fn = new ScalarFunction ( new FunctionName ( ""mydb"" , ""fn1"" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . HIVE ) ; fn . setLocation ( new HdfsUri ( ""hdfs :/ / foo : 123 / fns / myfunc . jar"" ) ) ; fn . setSymbolName ( ""myfunc"" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = ""CREATE FUNCTION mydb . fn1\n"" + ""LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . jar'\n"" + ""SYMBOL = 'myfunc'\n"" + ""PREPARE_FN = 'hdfs :/ / foo : 123 / fns / prepare_myfunc . sh'\n"" + ""CLOSE_FN = 'hdfs :/ / foo : 123 / fns / close_myfunc . sh'\n"" ; assertEquals ( expected , sql ) ; } }
",,
1398,"public Credentials ( String username , String password ) { this . username = requireNonNull ( username , ""username can't be null"" ) ; this . password = requireNonNull ( password , ""password can't be null"" ) ;
","this . username = requireNonNull ( username , ""username can't be null"" ) ; this . password = requireNonNull ( password , ""password can't be null"" ) ;
","this.username = username; this.password = password;
",,,"this.username = username; this.password = password; if (username != null) { this.username = username; this.password = password; }
",,,"public Credentials ( @NotNull String username , @NotNull String password ) { this . username = username ; this . password = password ; }
",,,"public Credentials ( String username , String password ) { this . username = username ; this . password = password ; }
",,,"public Credentials ( String username , String password ) { < |startfocus| > this . username = username ; this . password = password ; < |endfocus| >
",,
1415,"public JsonDocument newDocument ( String id , int expiry , JsonObject content , long cas ) { JsonDocument document = JsonDocument . create ( id , expiry , content , cas ) ; return document ;
","< |del| > document . content ( ) . setEncryptionConfig ( this . encryptionConfig ) ;
","document.content().setEncryptionConfig(this.encryptionConfig); }
",,,"document.content().setEncryptionConfig(encryptionConfig);
",,,"public JsonDocument newDocument ( String id , int expiry , JsonObject content , long cas ) { JsonDocument document = JsonDocument . create ( id , expiry , content , cas ) ; document . content ( ) . setEncryptionConfig ( this . encryptionConfig ) ; return document ; }
",,,"public JsonDocument newDocument ( String id , int expiry , JsonObject content , long cas ) { JsonDocument document = JsonDocument . create ( id , expiry , content , cas ) ; document . content ( ) . setEncryptionConfig ( this . encryptionConfig ) ; return document ; }
",,,"public JsonDocument newDocument ( String id , int expiry , JsonObject content , long cas ) { JsonDocument document = JsonDocument . create ( id , expiry , content , cas ) ; < |startfocus| > document . content ( ) . setEncryptionConfig ( this . encryptionConfig ) ; < |endfocus| > return document ; }
",,
1426,"public String export ( ) { return ""USE HASH ( "" + this . side + "" ) "" ;
","return ""USE HASH ( "" + this . side + "" ) "" ;
","return ""USE HASH("" + this.side + "")"";
",,,"return ""USE HASH("" + this.side + "")"";
",,,"public String export ( ) { return ""USE HASH ( "" + this . side + "" ) "" ; }
",,,"public String export ( ) { return ""USE HASH ( "" + this . side + "" ) "" ; }
",,,"public String export ( ) { < |startfocus| > return ""USE HASH ( "" + this . side + "" ) "" ; < |endfocus| >
",,
1433,"private TmfFilterHelper ( ) { // nothing to do } /* * * Build an event filter from the regex string in parameter * * @param regexes * The filter regex * @param trace * The trace this filter applies to * @return An event filter */ public static @Nullable ITmfFilter buildFilterFromRegex ( Collection < String > regexes , ITmfTrace trace ) { FilterCu compile = FilterCu . compile ( IFilterStrings . mergeFilters ( regexes ) ) ; if ( compile == null ) { Activator . logInfo ( ""buildFilterFromRegex : Invalid regex"" ) ; // $NON - NLS - 1$ return null ; } return compile . getEventFilter ( trace ) ; } /* * * Get the regex that corresponds to this filter . The regex should be in the * filter language described in the * { @link org . eclipse . tracecompass . tmf . filter . parser } plugin . And as it may * be used to filter anything , so it may not be the direct string * representing of the original filter . For instance , a ITmfFilter specific * for events will do a smart conversion , so that the parameters of the
","if ( compile == null ) { Activator . logInfo ( ""buildFilterFromRegex : Invalid regex"" ) ; // $NON - NLS - 1$
","if (compile == null) { logger.warn(""buildFilterFromRegex: invalid regex"");
",,,"if (compile == null) { Activator.logInfo(""buildFilterFromRegex: Invalid regex""); //$NON-NLS-1$
",,,"private TmfFilterHelper ( ) { // nothing to do } /* * * Build an event filter from the regex string in parameter * * @param regexes The filter regex * @param trace The trace this filter applies to * @return An event filter */ public static @Nullable ITmfFilter buildFilterFromRegex ( Collection < String > regexes , ITmfTrace trace ) { FilterCu compile = FilterCu . compile ( IFilterStrings . mergeFilters ( regexes ) ) ; if ( compile == null ) { // Log a warning if the filter compilation fails System . out . println ( ""Failed to compile filter from regexes : "" + regexes ) ; return null ; } return compile . getEventFilter ( trace ) ; } /* * * Get the regex that corresponds to this filter . The regex should be in the * filter language described in the { @link org . eclipse . tracecompass . tmf . filter . parser } * plugin . And as it may be used to filter anything , so it may not be the direct string * representing of the original filter . For instance , a ITmfFilter specific for events * will do a smart conversion , so that the parameters of the */ public static String getRegexFromFilter ( ITmfFilter filter ) { return filter . toString ( ) ; }
",,,"private TmfFilterHelper ( ) { // nothing to do } /* * * Build an event filter from the regex string in parameter * * @param regexes The filter regex * @param trace The trace this filter applies to * @return An event filter */ public static @Nullable ITmfFilter buildFilterFromRegex ( Collection < String > regexes , ITmfTrace trace ) { FilterCu compile = FilterCu . compile ( IFilterStrings . mergeFilters ( regexes ) ) ; if ( compile == null ) { LOGGER . info ( ""Failed to compile event filter from regex"" ) ; return null ; } return compile . getEventFilter ( trace ) ; } /* * * Get the regex that corresponds to this filter . The regex should be in the * filter language described in the { @link org . eclipse . tracecompass . tmf . filter . parser } plugin . * And as it may be used to filter anything , so it may not be the direct string * representing of the original filter . For instance , a ITmfFilter specific * for events will do a smart conversion , so that the parameters of the * filter are not hardcoded in the regex . * * @param filter The filter to get the regex from * @return The regex string */ public static String getRegexFromFilter ( ITmfFilter filter ) { if ( filter instanceof FilterCu ) { return ( ( FilterCu ) filter ) . getRegex ( ) ; } LOGGER . warning ( ""Failed to get regex from filter"" ) ; return null ; }
",,,"private TmfFilterHelper ( ) { // nothing to do } /* * * Build an event filter from the regex string in parameter * * @param regexes * The filter regex * @param trace * The trace this filter applies to * @return An event filter */ public static @Nullable ITmfFilter buildFilterFromRegex ( Collection < String > regexes , ITmfTrace trace ) { FilterCu compile = FilterCu . compile ( IFilterStrings . mergeFilters ( regexes ) ) ; < |startfocus| > if ( compile == null ) { < |endfocus| > return null ; } return compile . getEventFilter ( trace ) ; } /* * * Get the regex that corresponds to this filter . The regex should be in the * filter language described in the * { @link org . eclipse . tracecompass . tmf . filter . parser } plugin . And as it may * be used to filter anything , so it may not be the direct string * representing of the original filter . For instance , a ITmfFilter specific * for events will do a smart conversion , so that the parameters of the * filter are the same as the ones in the original filter . * * @param filter * The filter to convert * @return The regex that corresponds to this filter */ public static String getRegexFromFilter ( ITmfFilter filter ) { if ( filter instanceof ITmfFilterWithRegex ) { return ( ( ITmfFilterWithRegex ) filter ) . getRegex ( ) ; } return filter . toString ( ) ; }
",,
1451,"** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2017 , 2018 THALES GLOBAL SERVICES . * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . business . internal . representation ; import java . util . HashMap ; import java . util . Optional ; import org . eclipse . emf . common . util . URI ; import org . eclipse . emf . ecore . resource . Resource ; import org . eclipse . emf . ecore . util . ECrossReferenceAdapter ; import org . eclipse . sirius . business . api . resource . ResourceDescriptor ; import org . eclipse . sirius . viewpoint . DRepresentation ; import org . eclipse . sirius . viewpoint . DRepresentationDescriptor ; /* * * This class is intended to manage the link between the { @link DRepresentationDescriptor } and its * { @link DRepresentation } through the { @link DRepresentationDescriptor#repPath } attribute . * * @author fbarbin * */ public class DRepresentationDescriptorToDRepresentationLinkManager {
","* This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0
","* All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v 2.0
",,,"* All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v2.0
",,,"/* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2017 , 2018 THALES GLOBAL SERVICES . * All rights reserved . This program and the accompanying materials * are made available under the terms of the Eclipse Public License v2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . eclipse . sirius . business . internal . representation ; import java . util . HashMap ; import java . util . Optional ; import org . eclipse . emf . common . util . URI ; import org . eclipse . emf . ecore . resource . Resource ; import org . eclipse . emf . ecore . util . ECrossReferenceAdapter ; import org . eclipse . sirius . business . api . resource . ResourceDescriptor ; import org . eclipse . sirius . viewpoint . DRepresentation ; import org . eclipse . sirius . viewpoint . DRepresentationDescriptor ; /* * * This class is intended to manage the link between the { @link DRepresentationDescriptor } and its * { @link DRepresentation } through the { @link DRepresentationDescriptor#repPath } attribute . * * @author fbarbin */ public class DRepresentationDescriptorToDRepresentationLinkManager { // code implementation here }
",,,"/* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * Copyright ( c ) 2017 , 2018 THALES GLOBAL SERVICES . * All rights reserved . This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 1 . 0 / * * SPDX - License - Identifier : EPL - 1 . 0 * * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . eclipse . sirius . business . internal . representation ; import java . util . HashMap ; import java . util . Optional ; import org . eclipse . emf . common . util . URI ; import org . eclipse . emf . ecore . resource . Resource ; import org . eclipse . emf . ecore . util . ECrossReferenceAdapter ; import org . eclipse . sirius . business . api . resource . ResourceDescriptor ; import org . eclipse . sirius . viewpoint . DRepresentation ; import org . eclipse . sirius . viewpoint . DRepresentationDescriptor ; /* * * This class is intended to manage the link between the { @link DRepresentationDescriptor } and its * { @link DRepresentation } through the { @link DRepresentationDescriptor#repPath } attribute . * * @author fbarbin */ public class DRepresentationDescriptorToDRepresentationLinkManager { // implementation goes here }
",,,"/* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * Copyright ( c ) 2017 , 2018 THALES GLOBAL SERVICES . * All rights reserved . This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1 . 0 * which accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Thales - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . business . internal . representation ; import java . util . HashMap ; import java . util . Optional ; import org . eclipse . emf . common . util . URI ; import org . eclipse . emf . ecore . resource . Resource ; import org . eclipse . emf . ecore . util . ECrossReferenceAdapter ; import org . eclipse . sirius . business . api . resource . ResourceDescriptor ; import org . eclipse . sirius . viewpoint . DRepresentation ; import org . eclipse . sirius . viewpoint . DRepresentationDescriptor ; /* * * This class is intended to manage the link between the { @link DRepresentationDescriptor } and its * { @link DRepresentation } through the { @link DRepresentationDescriptor#repPath } attribute . * * @author fbarbin * */ public class DRepresentationDescriptorToDRepresentationLinkManager {
",,
1453,"public boolean isMirrored ( ) { Object property = getProperty ( EMFCompareConfiguration . MIRRORED ) ; return property instanceof Boolean && ( ( Boolean ) property ) . booleanValue ( ) ;
","Object property = getProperty ( EMFCompareConfiguration . MIRRORED ) ;
","Object property = getProperty(MIRRORED); //$NON-NLS-1$
",,,"Object property = getProperty(Messages.TmfCommonProjectElement_MIRRORED);
",,,"public boolean isMirrored ( ) { Object property = getProperty ( ""mirrored"" ) ; return property instanceof Boolean && ( Boolean ) property ; }
",,,"public boolean isMirrored ( ) { Object property = getProperty ( ""MIRRORED"" ) ; return property instanceof Boolean && ( ( Boolean ) property ) . booleanValue ( ) ; }
",,,"public boolean isMirrored ( ) { < |startfocus| > Object property = getProperty ( MIRRORED ) ; < |endfocus| > return property instanceof Boolean && ( ( Boolean ) property ) . booleanValue ( ) ;
",,
1463,"} /* * * Get namespace used by bootstrap layer . * * @return namespace used by bootstrap layer , e . g . { @code refs / txn / } . Always * ends in { @code ' / ' } . */ @Nullable public String getTxnNamespace ( ) { return txnNamespace ; } /* * { @inheritDoc } */ @Override public void create ( ) throws IOException { bootstrap . create ( ) ; } /* * { @inheritDoc } */ @Override public boolean performsAtomicTransactions ( ) { return true ; } /* * { @inheritDoc } */ @Override public void refresh ( ) { bootstrap . refresh ( ) ; } /* * { @inheritDoc } */ @Override public void close ( ) { refs = null ; bootstrap . close ( ) ; } /* * { @inheritDoc } */ @Override public Ref getRef ( String name ) throws IOException { String [ ] needle = new String [ SEARCH_PATH . length ] ;
","< |del| > public boolean hasVersioning ( ) { return false ; } /* * { @inheritDoc } */ @Override
","<|del|>
",,,"<|del|>
",,,"/* * * Get namespace used by bootstrap layer . * * @return namespace used by bootstrap layer , e . g . { @code refs / txn / } . Always * ends in { @code ' / ' } . */ @Nullable public String getTxnNamespace ( ) { return txnNamespace ; } /* * { @inheritDoc } */ @Override public void create ( ) throws IOException { bootstrap . create ( ) ; } /* * { @inheritDoc } */ @Override public boolean hasVersioning ( ) { return false ; } /* * { @inheritDoc } */ @Override public boolean performsAtomicTransactions ( ) { return true ; } /* * { @inheritDoc } */ @Override public void refresh ( ) { bootstrap . refresh ( ) ; } /* * { @inheritDoc } */ @Override public void close ( ) { refs = null ; bootstrap . close ( ) ; } /* * { @inheritDoc } */ @Override public Ref getRef ( String name ) throws IOException { String [ ] needle = new String [ SEARCH_PATH . length ] ; // implementation details }
",,,"/* * * Get namespace used by bootstrap layer . * * @return namespace used by bootstrap layer , e . g . { @code refs / txn / } . Always * ends in { @code ' / ' } . */ @Nullable public String getTxnNamespace ( ) { return txnNamespace ; } /* * { @inheritDoc } */ @Override public void create ( ) throws IOException { bootstrap . create ( ) ; } /* * { @inheritDoc } */ @Override public boolean hasVersioning ( ) { return false ; } /* * { @inheritDoc } */ @Override public boolean performsAtomicTransactions ( ) { return true ; } /* * { @inheritDoc } */ @Override public void refresh ( ) { bootstrap . refresh ( ) ; } /* * { @inheritDoc } */ @Override public void close ( ) { refs = null ; bootstrap . close ( ) ; } /* * { @inheritDoc } */ @Override public Ref getRef ( String name ) throws IOException { String [ ] needle = new String [ SEARCH_PATH . length ] ;
",,,"} /* * * Get namespace used by bootstrap layer . * * @return namespace used by bootstrap layer , e . g . { @code refs / txn / } . Always * ends in { @code ' / ' } . */ @Nullable public String getTxnNamespace ( ) { return txnNamespace ; } /* * { @inheritDoc } */ @Override public void create ( ) throws IOException { bootstrap . create ( ) ; } /* * { @inheritDoc } */ @Override < |startfocus| > public boolean hasVersioning ( ) { return false ; } /* * { @inheritDoc } */ @Override < |endfocus| > public boolean performsAtomicTransactions ( ) { return true ; } /* * { @inheritDoc } */ @Override public void refresh ( ) { bootstrap . refresh ( ) ; } /* * { @inheritDoc } */ @Override public void close ( ) { refs = null ; bootstrap . close ( ) ; } /* * { @inheritDoc } */ @Override public Ref getRef ( String name ) throws IOException { String [ ] needle = new String [ SEARCH_PATH . length ] ; < |startfocus| >
",,
1478,"* * @throws java . io . IOException * the database could not be created . */ public abstract void create ( ) throws IOException ; /* * * Close any resources held by this database . */ public abstract void close ( ) ; /* * * With versioning , each reference has a version number that increases on * update . * * @return true whether the implementation assigns update indices to * references . * @since 5 . 3 */ public boolean hasVersioning ( ) { return false ; } /* * * Determine if a proposed reference name overlaps with an existing one . * < p > * Reference names use ' / ' as a component separator , and may be stored in a * hierarchical storage such as a directory on the local filesystem . * < p > * If the reference ""refs / heads / foo"" exists then ""refs / heads / foo / bar"" must * not exist , as a reference cannot have a value and also be a container for * other references at the same time .
","public boolean hasVersioning ( ) { return false ; }
","<|del|>
",,,"public abstract boolean hasVersioning();
",,,"public abstract void create ( ) throws IOException ; public abstract void close ( ) ; public abstract boolean hasVersioning ( ) default false ; public abstract boolean isReferenceNameOverlapping ( String proposedReferenceName ) ;
",,,"public abstract boolean hasVersioning ( ) { return false ; }
",,,"* * @throws java . io . IOException * the database could not be created . */ public abstract void create ( ) throws IOException ; /* * * Close any resources held by this database . */ public abstract void close ( ) ; /* * * With versioning , each reference has a version number that increases on * update . * * @return true whether the implementation assigns update indices to * references . * @since 5 . 3 */ < |startfocus| > public boolean hasVersioning ( ) { return false ; } < |endfocus| > /* * * Determine if a proposed reference name overlaps with an existing one . * < p > * Reference names use ' / ' as a component separator , and may be stored in a * hierarchical storage such as a directory on the local filesystem . * < p > * If the reference ""refs / heads / foo"" exists then ""refs / heads / foo / bar"" must * not exist , as a reference cannot have a value and also be a container for * other references at the same time .
",,
1483,"public void run ( ) { Collection < DRepresentationDescriptor > repDescriptorsToExport = getRepresentationToExport ( ) . stream ( ) . filter ( Objects : : nonNull ) . collect ( Collectors . toList ( ) ) ; // keep only the DRepresentationDescriptor which DRepresentation is not null repDescriptorsToExport = repDescriptorsToExport . stream ( ) . filter ( repDesc - > repDesc . getRepresentation ( ) != null ) . collect ( Collectors . toList ( ) ) ; if ( ! repDescriptorsToExport . isEmpty ( ) ) { DRepresentationDescriptor firstDRepDescriptorToExport = repDescriptorsToExport . iterator ( ) . next ( ) ; // Make sure the representation is loaded firstDRepDescriptorToExport . getRepresentation ( ) ; Session session = getSession ( firstDRepDescriptorToExport ) ; if ( session != null ) { IPath exportPath = getExportPath ( firstDRepDescriptorToExport , session ) ; if ( exportPath != null ) { exportRepresentation ( exportPath , repDescriptorsToExport , session ) ; } } } else { MessageDialog . openInformation ( Display . getCurrent ( ) . getActiveShell ( ) , Messages . ExportRepresentationsAction_noRepresentationsDialog_title , Messages . ExportRepresentationsAction_noRepresentationsDialog_message ) ; }
","// keep only the DRepresentationDescriptor which DRepresentation is not null
","// keep repDesc with representations
",,,"// keep only the repDesc with representations
",,,"public void run ( ) { Collection < DRepresentationDescriptor > repDescriptorsToExport = getRepresentationToExport ( ) . stream ( ) . filter ( repDesc - > repDesc != null && repDesc . getRepresentation ( ) != null ) . collect ( Collectors . toList ( ) ) ; if ( ! repDescriptorsToExport . isEmpty ( ) ) { DRepresentationDescriptor firstDRepDescriptorToExport = repDescriptorsToExport . iterator ( ) . next ( ) ; firstDRepDescriptorToExport . getRepresentation ( ) ; Session session = getSession ( firstDRepDescriptorToExport ) ; if ( session != null ) { IPath exportPath = getExportPath ( firstDRepDescriptorToExport , session ) ; if ( exportPath != null ) { exportRepresentation ( exportPath , repDescriptorsToExport , session ) ; } } } else { MessageDialog . openInformation ( Display . getCurrent ( ) . getActiveShell ( ) , Messages . ExportRepresentationsAction_noRepresentationsDialog_title , Messages . ExportRepresentationsAction_noRepresentationsDialog_message ) ; } }
",,,"public void run ( ) { Collection < DRepresentationDescriptor > repDescriptorsToExport = getRepresentationToExport ( ) . stream ( ) . filter ( Objects : : nonNull ) . filter ( repDesc - > repDesc . getRepresentation ( ) != null ) . collect ( Collectors . toList ( ) ) ; if ( ! repDescriptorsToExport . isEmpty ( ) ) { DRepresentationDescriptor firstDRepDescriptorToExport = repDescriptorsToExport . iterator ( ) . next ( ) ; firstDRepDescriptorToExport . getRepresentation ( ) ; Session session = getSession ( firstDRepDescriptorToExport ) ; if ( session != null ) { IPath exportPath = getExportPath ( firstDRepDescriptorToExport , session ) ; if ( exportPath != null ) { exportRepresentation ( exportPath , repDescriptorsToExport , session ) ; } } } else { MessageDialog . openInformation ( Display . getCurrent ( ) . getActiveShell ( ) , Messages . ExportRepresentationsAction_noRepresentationsDialog_title , Messages . ExportRepresentationsAction_noRepresentationsDialog_message ) ; } }
",,,"public void run ( ) { Collection < DRepresentationDescriptor > repDescriptorsToExport = getRepresentationToExport ( ) . stream ( ) . filter ( Objects : : nonNull ) . collect ( Collectors . toList ( ) ) ; < |startfocus| > // keep only the representations < |endfocus| > repDescriptorsToExport = repDescriptorsToExport . stream ( ) . filter ( repDesc - > repDesc . getRepresentation ( ) != null ) . collect ( Collectors . toList ( ) ) ; if ( ! repDescriptorsToExport . isEmpty ( ) ) { DRepresentationDescriptor firstDRepDescriptorToExport = repDescriptorsToExport . iterator ( ) . next ( ) ; // Make sure the representation is loaded firstDRepDescriptorToExport . getRepresentation ( ) ; Session session = getSession ( firstDRepDescriptorToExport ) ; if ( session != null ) { IPath exportPath = getExportPath ( firstDRepDescriptorToExport , session ) ; if ( exportPath != null ) { exportRepresentation ( exportPath , repDescriptorsToExport , session ) ; } } } else { MessageDialog . openInformation ( Display . getCurrent ( ) . getActiveShell ( ) , Messages . ExportRepresentationsAction_noRepresentationsDialog_title , Messages . ExportRepresentationsAction_noRepresentationsDialog_message ) ; }
",,
1486,"protected IResource getResource ( IPath path ) { if ( path != null ) { IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; // look for files or folders with the given path IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } if ( ! ""jar"" . equalsIgnoreCase ( path . getFileExtension ( ) ) ) { // $NON - NLS - 1$ IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } } return null ;
","// look for files or folders with the given path
","<|del|>
",,,"<|del|>
",,,"protected IResource getResource ( IPath path ) { if ( path == null ) { return null ; } IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } if ( ! ""jar"" . equalsIgnoreCase ( path . getFileExtension ( ) ) ) { IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } return root . findMember ( path ) ; }
",,,"protected IResource getResource ( IPath path ) { if ( path != null ) { IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; if ( path . getDevice ( ) == null ) { // search relative to the workspace if no device present return root . findMember ( path ) ; } IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } if ( ! ""jar"" . equalsIgnoreCase ( path . getFileExtension ( ) ) ) { // $NON - NLS - 1$ IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } } return null ; }
",,,"protected IResource getResource ( IPath path ) { if ( path != null ) { IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } if ( ! ""jar"" . equalsIgnoreCase ( path . getFileExtension ( ) ) ) { // $NON - NLS - 1$ IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } < |startfocus| > if ( path . getDevice ( ) == null ) { // search relative to the workspace if no device present return root . findMember ( path ) ; } < |endfocus| > } return null ;
",,
1488,"IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; // look for files or folders with the given path IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } if ( getType ( ) != ARCHIVE ) { IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } if ( path . getDevice ( ) == null ) { // search relative to the workspace if no device present return root . findMember ( path ) ; } if ( getType ( ) != ARCHIVE ) { @SuppressWarnings ( ""deprecation"" ) IContainer [ ] containers = root . findContainersForLocation ( path ) ; if ( containers . length > 0 ) { return containers [ 0 ] ; } } } return null ;
","} if ( getType ( ) != ARCHIVE ) { @SuppressWarnings ( ""deprecation"" ) IContainer [ ] containers = root . findContainersForLocation ( path ) ; if ( containers . length > 0 ) { return containers [ 0 ] ; } }
","} return container;
",,,"} if (getType() != ARCHIVE) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } return null;
",,,"IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } return root . findMember ( path ) ;
",,,"IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; // look for files or folders with the given path IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } if ( getType ( ) != ARCHIVE ) { IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } if ( path . getDevice ( ) == null ) { // search relative to the workspace if no device present return root . findMember ( path ) ; } return null ;
",,,"IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; // look for files or folders with the given path IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } if ( getType ( ) != ARCHIVE ) { IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } if ( path . getDevice ( ) == null ) { // search relative to the workspace if no device present return root . findMember ( path ) ; } return null ;
",,
1489,"} } static int read ( ReadableChannel rc , ByteBuffer buf ) throws IOException { int n ; do { n = rc . read ( buf ) ; } while ( 0 < n && buf . hasRemaining ( ) ) ; return buf . position ( ) ; } static long elapsedMicros ( long start ) { return ( System . nanoTime ( ) - start ) / 1000L ; } /* * * A supplier of readable channel that opens the channel lazily . */ private static class LazyChannel implements AutoCloseable , DfsBlockCache . ReadableChannelSupplier { private final DfsReader ctx ; private final DfsPackDescription desc ; private final PackExt ext ; LazyChannel ( DfsReader ctx ) { this . ctx = ctx ; } @Override public ReadableChannel get ( ) throws IOException { if ( rc == null ) { synchronized ( this ) { if ( rc == null ) { rc = ctx . db . openFile ( desc , ext ) ; } } } return rc ; } @Override public void close ( ) throws IOException { if ( rc != null ) { rc . close ( ) ; } } } }
","private static class LazyChannel implements AutoCloseable , DfsBlockCache . ReadableChannelSupplier { private final DfsReader ctx ; private final DfsPackDescription desc ; private final PackExt ext ;
","private static class lazyChannel implements AutoCloseable, DfsBlockCache.ReadableChannelSupplier { final DfsReader ctx; ReadableChannel rc;
",,,"private static class LazyChannel implements AutoCloseable { final DfsReader ctx; final ReadableChannel rc;
",,,"static class LazyChannel implements AutoCloseable , DfsBlockCache . ReadableChannelSupplier { final DfsReader ctx ; ReadableChannel rc = null ; LazyChannel ( DfsReader ctx ) { this . ctx = ctx ; } @Override public ReadableChannel get ( ) throws IOException { if ( rc == null ) { synchronized ( this ) { if ( rc == null ) { rc = ctx . db . openFile ( desc , ext ) ; } } } return rc ; } @Override public void close ( ) throws IOException { if ( rc != null ) { rc . close ( ) ; } } } static int read ( ReadableChannel rc , ByteBuffer buf ) throws IOException { int n ; do { n = rc . read ( buf ) ; } while ( 0 < n && buf . hasRemaining ( ) ) ; return buf . position ( ) ; } static long elapsedMicros ( long start ) { return ( System . nanoTime ( ) - start ) / 1000L ; }
",,,"static int read ( ReadableChannel rc , ByteBuffer buf ) throws IOException { int n ; do { n = rc . read ( buf ) ; } while ( 0 < n && buf . hasRemaining ( ) ) ; return buf . position ( ) ; } static long elapsedMicros ( long start ) { return ( System . nanoTime ( ) - start ) / 1000L ; } /* * * A supplier of readable channel that opens the channel lazily . */ private static class LazyChannel implements AutoCloseable , DfsBlockCache . ReadableChannelSupplier { final DfsReader ctx ; ReadableChannel rc = null ; LazyChannel ( DfsReader ctx ) { this . ctx = ctx ; } @Override public ReadableChannel get ( ) throws IOException { if ( rc == null ) { synchronized ( this ) { if ( rc == null ) { rc = ctx . db . openFile ( desc , ext ) ; } } } return rc ; } @Override public void close ( ) throws IOException { if ( rc != null ) { rc . close ( ) ; } } }
",,,"} } static int read ( ReadableChannel rc , ByteBuffer buf ) throws IOException { int n ; do { n = rc . read ( buf ) ; } while ( 0 < n && buf . hasRemaining ( ) ) ; return buf . position ( ) ; } static long elapsedMicros ( long start ) { return ( System . nanoTime ( ) - start ) / 1000L ; } /* * * A supplier of readable channel that opens the channel lazily . */ < |startfocus| > private static class LazyChannel implements AutoCloseable , DfsBlockCache . ReadableChannelSupplier { final DfsReader ctx ; ReadableChannel rc = null ; < |endfocus| > LazyChannel ( DfsReader ctx ) { this . ctx = ctx ; } @Override public ReadableChannel get ( ) throws IOException { if ( rc == null ) { synchronized ( this ) { if ( rc == null ) { rc = ctx . db . openFile ( desc , ext ) ; } } } return rc ; } @Override public void close ( ) throws IOException { if ( rc != null ) { rc . close ( ) ; } } } }
",,
1498,"import org . junit . runners . Parameterized . Parameters ; import org . mockito . ArgumentCaptor ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @RunWith ( ParameterizedPlatformTestRunner . class ) public class JmsMomImplementorTest { private static final Logger LOG = LoggerFactory . getLogger ( JmsMomImplementorTest . class ) ; @ClassRule public static final ArtemisJmsBrokerTestRule ARTEMIS_RULE = new ArtemisJmsBrokerTestRule ( ) ; private IBean < ? extends JmsTestMom > m_momBean ; private IBean < ? extends IJmsMessageHandler > m_messageHandlerBean ; private List < IDisposable > m_disposables ; private String m_testJobExecutionHint ; @Rule public TestName m_testName = new TestName ( ) ; public long m_t0 ; private static final AtomicInteger MOM_COUNTER = new AtomicInteger ( 0 ) ; @Parameters public static List < IScoutTestParameter > getParameters ( ) { List < IScoutTestParameter > parametersList = new LinkedList < IScoutTestParameter > ( ) ; // We do not need jmx for unit testing . Also we must disable watchTopicAdvisories else some concurrent issues with broker recreation will happen
","< |del| > private IJmsMessageHandler m_messageHandler ;
","<|del|>
",,,"<|del|>
",,,"import org . junit . ClassRule ; import org . junit . Rule ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . mockito . ArgumentCaptor ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import java . util . LinkedList ; import java . util . List ; import java . util . concurrent . atomic . AtomicInteger ; import static org . junit . Assert . assertNotNull ; @RunWith ( ParameterizedPlatformTestRunner . class ) public class JmsMomImplementorTest { private static final Logger LOG = LoggerFactory . getLogger ( JmsMomImplementorTest . class ) ; @ClassRule public static final ArtemisJmsBrokerTestRule ARTEMIS_RULE = new ArtemisJmsBrokerTestRule ( ) ; private IBean < ? extends JmsTestMom > m_momBean ; private IBean < ? extends IJmsMessageHandler > m_messageHandlerBean ; private List < IDisposable > m_disposables ; private String m_testJobExecutionHint ; @Rule public TestName m_testName = new TestName ( ) ; public long m_t0 ; private static final AtomicInteger MOM_COUNTER = new AtomicInteger ( 0 ) ; @Parameters public static List < IScoutTestParameter > getParameters ( ) { List < IScoutTestParameter > parametersList = new LinkedList < IScoutTestParameter > ( ) ; // We do not need jmx for unit testing . Also we must disable watchTopicAdvisories else some concurrent issues with broker recreation will happen return parametersList ; } @Test public void test ( ) throws Exception { m_t0 = System . currentTimeMillis ( ) ; LOG . info ( ""Starting test : { } "" , m_testName . getMethodName ( ) ) ; JmsTestMom mom = m_momBean . getInstance ( ) ; assertNotNull ( mom ) ; IJmsMessageHandler messageHandler = m_messageHandlerBean . getInstance ( ) ; assertNotNull ( messageHandler ) ; mom . setJmsMessageHandler ( messageHandler ) ; m_disposables . add ( mom ) ; mom . start ( ) ; // Wait for the MOM to start Thread . sleep ( 1000 ) ; // Send a message to the MOM mom . sendMessage ( ""test message"" ) ; // Wait for the message to be received Thread . sleep ( 1000 ) ; ArgumentCaptor < String > messageCaptor = ArgumentCaptor . forClass ( String . class ) ; verify ( messageHandler ) . handleMessage ( messageCaptor . capture ( ) ) ; String receivedMessage = messageCaptor . getValue ( ) ; assertNotNull ( receivedMessage ) ; } }
",,,"import org . junit . runners . Parameterized . Parameters ; import org . mockito . ArgumentCaptor ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @RunWith ( ParameterizedPlatformTestRunner . class ) public class JmsMomImplementorTest { private static final Logger LOG = LoggerFactory . getLogger ( JmsMomImplementorTest . class ) ; @ClassRule public static final ArtemisJmsBrokerTestRule ARTEMIS_RULE = new ArtemisJmsBrokerTestRule ( ) ; private IBean < ? extends JmsTestMom > m_momBean ; private IBean < ? extends IJmsMessageHandler > m_messageHandlerBean ; private List < IDisposable > m_disposables ; private String m_testJobExecutionHint ; @Rule public TestName m_testName = new TestName ( ) ; public long m_t0 ; private static final AtomicInteger MOM_COUNTER = new AtomicInteger ( 0 ) ; @Parameters public static List < IScoutTestParameter > getParameters ( ) { List < IScoutTestParameter > parametersList = new LinkedList < IScoutTestParameter > ( ) ; // We do not need jmx for unit testing . Also we must disable watchTopicAdvisories else some concurrent issues with broker recreation will happen // . . . } }
",,,"import org . junit . runners . Parameterized . Parameters ; import org . mockito . ArgumentCaptor ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @RunWith ( ParameterizedPlatformTestRunner . class ) public class JmsMomImplementorTest { private static final Logger LOG = LoggerFactory . getLogger ( JmsMomImplementorTest . class ) ; @ClassRule public static final ArtemisJmsBrokerTestRule ARTEMIS_RULE = new ArtemisJmsBrokerTestRule ( ) ; private IBean < ? extends JmsTestMom > m_momBean ; private IBean < ? extends IJmsMessageHandler > m_messageHandlerBean ; private List < IDisposable > m_disposables ; private String m_testJobExecutionHint ; @Rule public TestName m_testName = new TestName ( ) ; public long m_t0 ; private static final AtomicInteger MOM_COUNTER = new AtomicInteger ( 0 ) ; @Parameters public static List < IScoutTestParameter > getParameters ( ) { List < IScoutTestParameter > parametersList = new LinkedList < IScoutTestParameter > ( ) ; // We do not need jmx for unit testing . Also we must disable watchTopicAdvisories else some concurrent issues with broker recreation will happen
",,
1499,"try { Jobs . getJobManager ( ) . awaitDone ( testJobsFilter , 10 , TimeUnit . SECONDS ) ; LOG . info ( ""All jobs have finished after { } ms"" , StringUtility . formatNanos ( System . nanoTime ( ) - t0 ) ) ; } catch ( TimedOutError e ) { LOG . warn ( ""Some cancelled jobs are still running after { } ms ! Please check their implementation . "" , StringUtility . formatNanos ( System . nanoTime ( ) - t0 ) ) ; } } uninstallTestMessagehandler ( ) ; uninstallTestMom ( ) ; // ensure activeMQ is stopped BrokerService brokerService = BrokerRegistry . getInstance ( ) . findFirst ( ) ; if ( brokerService != null ) { brokerService . stop ( ) ; brokerService . waitUntilStopped ( ) ; } LOG . info ( ""Finished test in { } ms"" , StringUtility . formatNanos ( System . nanoTime ( ) - m_t0 ) ) ; LOG . info ( "" </ { } > "" , m_testName . getMethodName ( ) ) ; } @Test @NonParameterized public void testInstanceScoped ( ) { JmsMomImplementor mom1 = BEANS . get ( JmsMomImplementor . class ) ;
","uninstallTestMessagehandler ( ) ;
","BeanTestingHelper.get().unregisterBean(m_messageHandlerBean); m_messageHandlerBean = null;
",,,"<|del|>
",,,"try { Jobs . getJobManager ( ) . awaitDone ( testJobsFilter , 10 , TimeUnit . SECONDS ) ; LOG . info ( ""All jobs have finished after { } ms"" , StringUtility . formatNanos ( System . nanoTime ( ) - t0 ) ) ; } catch ( TimedOutError e ) { LOG . warn ( ""Some cancelled jobs are still running after { } ms ! Please check their implementation . "" , StringUtility . formatNanos ( System . nanoTime ( ) - t0 ) ) ; } BeanTestingHelper . get ( ) . unregisterBean ( m_messageHandlerBean ) ; m_messageHandlerBean = null ; uninstallTestMessagehandler ( ) ; uninstallTestMom ( ) ; // ensure activeMQ is stopped BrokerService brokerService = BrokerRegistry . getInstance ( ) . findFirst ( ) ; if ( brokerService != null ) { brokerService . stop ( ) ; brokerService . waitUntilStopped ( ) ; } LOG . info ( ""Finished test in { } ms"" , StringUtility . formatNanos ( System . nanoTime ( ) - m_t0 ) ) ; LOG . info ( "" </ { } > "" , m_testName . getMethodName ( ) ) ; @Test @NonParameterized public void testInstanceScoped ( ) { JmsMomImplementor mom1 = BEANS . get ( JmsMomImplementor . class ) ; }
",,,"try { Jobs . getJobManager ( ) . awaitDone ( testJobsFilter , 10 , TimeUnit . SECONDS ) ; LOG . info ( ""All jobs have finished after { } ms"" , StringUtility . formatNanos ( System . nanoTime ( ) - t0 ) ) ; } catch ( TimedOutError e ) { LOG . warn ( ""Some cancelled jobs are still running after { } ms ! Please check their implementation . "" , StringUtility . formatNanos ( System . nanoTime ( ) - t0 ) ) ; } BeanTestingHelper . get ( ) . unregisterBean ( m_messageHandlerBean ) ; m_messageHandlerBean = null ; uninstallTestMom ( ) ; // ensure activeMQ is stopped BrokerService brokerService = BrokerRegistry . getInstance ( ) . findFirst ( ) ; if ( brokerService != null ) { brokerService . stop ( ) ; brokerService . waitUntilStopped ( ) ; } LOG . info ( ""Finished test in { } ms"" , StringUtility . formatNanos ( System . nanoTime ( ) - m_t0 ) ) ; LOG . info ( "" </ { } > "" , m_testName . getMethodName ( ) ) ; } @Test @NonParameterized public void testInstanceScoped ( ) { JmsMomImplementor mom1 = BEANS . get ( JmsMomImplementor . class ) ; }
",,,"try { Jobs . getJobManager ( ) . awaitDone ( testJobsFilter , 10 , TimeUnit . SECONDS ) ; LOG . info ( ""All jobs have finished after { } ms"" , StringUtility . formatNanos ( System . nanoTime ( ) - t0 ) ) ; } catch ( TimedOutError e ) { LOG . warn ( ""Some cancelled jobs are still running after { } ms ! Please check their implementation . "" , StringUtility . formatNanos ( System . nanoTime ( ) - t0 ) ) ; } } < |startfocus| > uninstallTestMessagehandler ( ) ; < |endfocus| > uninstallTestMom ( ) ; // ensure activeMQ is stopped BrokerService brokerService = BrokerRegistry . getInstance ( ) . findFirst ( ) ; if ( brokerService != null ) { brokerService . stop ( ) ; brokerService . waitUntilStopped ( ) ; } LOG . info ( ""Finished test in { } ms"" , StringUtility . formatNanos ( System . nanoTime ( ) - m_t0 ) ) ; LOG . info ( "" </ { } > "" , m_testName . getMethodName ( ) ) ; } @Test @NonParameterized public void testInstanceScoped ( ) { JmsMomImplementor mom1 = BEANS . get ( JmsMomImplementor . class ) ;
",,
1504,"* Writes the given { @link Map } as message properties . * * @see JmsMessageReader#readContext ( String ) */ protected JmsMessageWriter writeContext ( final String property , final Map < String , String > context ) throws JMSException { if ( context . isEmpty ( ) ) { return this ; } final String json = ( String ) BEANS . get ( JsonMarshaller . class ) . marshall ( context , new HashMap < > ( ) ) ; writeProperty ( property , json ) ; return this ; } /* * * Finish writing and get the message . * < p > * If the message is a { @link javax . jms . BytesMessage } , the message body is put in read - only mode and repositions the * stream of bytes to the beginning . * * @return the JMS message in read - only mode * @see BytesMessage#reset ( ) */ public Message build ( ) throws JMSException { writeContext ( JMS_PROP_MARSHALLER_CONTEXT , m_marshallerContext ) ; if ( m_message instanceof BytesMessage ) { ( ( BytesMessage ) m_message ) . reset ( ) ; } return m_message ; } /* *
","* If the message is a { @link javax . jms . BytesMessage } , the message body is put in read - only mode and repositions the * stream of bytes to the beginning .
","* If the message is a {@link javax. queues.BytesMessage}, ... its message * body is put in read-only mode and repositions the stream of bytes to * the beginning.
",,,"* If the message is a {@link javax.jms.BytesMessage}, the message body is put in read-only mode and repositions the stream of bytes to * the beginning of the message.
",,,"/* * * Writes the given { @link Map } as message properties . * If the message is a { @link javax . jms . BytesMessage } , the message body is put in read - only mode and repositions the stream of bytes to the beginning . * * @param property the name of the property to write * @param context the map of context to write as properties * @return this JmsMessageWriter instance * @throws JMSException if an error occurs while writing the properties * @see JmsMessageReader#readContext ( String ) * @see BytesMessage#reset ( ) */ protected JmsMessageWriter writeContext ( final String property , final Map < String , String > context ) throws JMSException { if ( context . isEmpty ( ) ) { return this ; } final String json = ( String ) BEANS . get ( JsonMarshaller . class ) . marshall ( context , new HashMap < > ( ) ) ; writeProperty ( property , json ) ; return this ; } /* * * Finish writing and get the message . * * @return the JMS message in read - only mode * @throws JMSException if an error occurs while building the message * @see BytesMessage#reset ( ) */ public Message build ( ) throws JMSException { writeContext ( JMS_PROP_MARSHALLER_CONTEXT , m_marshallerContext ) ; if ( m_message instanceof BytesMessage ) { ( ( BytesMessage ) m_message ) . reset ( ) ; } return m_message ; }
",,,"protected JmsMessageWriter writeContext ( final String property , final Map < String , String > context ) throws JMSException { if ( context . isEmpty ( ) ) { return this ; } final String json = ( String ) BEANS . get ( JsonMarshaller . class ) . marshall ( context , new HashMap < > ( ) ) ; writeProperty ( property , json ) ; return this ; } public Message build ( ) throws JMSException { writeContext ( JMS_PROP_MARSHALLER_CONTEXT , m_marshallerContext ) ; if ( m_message instanceof BytesMessage ) { ( ( BytesMessage ) m_message ) . reset ( ) ; } return m_message ; }
",,,"* Writes the given { @link Map } as message properties . * * @see JmsMessageReader#readContext ( String ) */ protected JmsMessageWriter writeContext ( final String property , final Map < String , String > context ) throws JMSException { if ( context . isEmpty ( ) ) { return this ; } final String json = ( String ) BEANS . get ( JsonMarshaller . class ) . marshall ( context , new HashMap < > ( ) ) ; writeProperty ( property , json ) ; return this ; } /* * * Finish writing and get the message . * < p > * If the message is a { @link javax . jms . BytesMessage } , its message body is put in read - only mode and repositions the * stream of bytes to the beginning . * * @return the JMS message in read - only mode * @see BytesMessage#reset ( ) */ public Message build ( ) throws JMSException { writeContext ( JMS_PROP_MARSHALLER_CONTEXT , m_marshallerContext ) ; if ( m_message instanceof BytesMessage ) { ( ( BytesMessage ) m_message ) . reset ( ) ; } return m_message ; } /* *
",,
1517,"public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object selectedElement = iterator . next ( ) ; if ( selectedElement instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) selectedElement ) ; } else { result = false ; } } return result ;
","final Object selectedElement = iterator . next ( ) ; if ( selectedElement instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) selectedElement ) ;
","final Object selectedElement = iterator.next(); if (selectedElement instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) selectedElement);
",,,"if (selectedElement instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) selectedElement);
",,,"public static boolean isActive ( IStructuredSelection selectedElement ) { boolean result = true ; final Iterator < ? > iterator = selectedElement . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) next ) ; } else { result = false ; } } return result ; }
",,,"public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) next ) ; } else { result = false ; } } return result ; }
",,,"public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { < |startfocus| > final Object selectedElement = iterator . next ( ) ; if ( selectedElement instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) selectedElement ) ; < |endfocus| > } else { result = false ; } } return result ;
",,
1527,"* the reference space cannot be accessed . * @since 5 . 2 */ @NonNull public List < Ref > getRefsByPrefix ( String . . . prefixes ) throws IOException { List < Ref > result = new ArrayList < > ( ) ; for ( String prefix : prefixes ) { result . addAll ( getRefsByPrefix ( prefix ) ) ; } return Collections . unmodifiableList ( result ) ; } /* * * Returns all refs that resolve directly to the given { @link ObjectId } . * Includes peeled { @linkObjectId } s . This is the inverse lookup of * { @link #exactRef ( String . . . ) } . * * < p > * The default implementation uses a linear scan . Implementors of * { @link RefDatabase } should override this method directly if a better * implementation is possible . * * @param id * { @link ObjectId } to resolve * @return a { @link Set } of { @link Ref } s whose tip points to the provided * id . * @throws java . io . IOException * the reference space cannot be accessed .
","* Includes peeled { @linkObjectId } s . This is the inverse lookup of
","* Includes peeled {@linkObjectId}s. This is the inverse lookup if
",,,"* Includes peeled {@link ObjectId}s. This is the inverse lookup of
",,,"/* * * Returns a list of refs that match the given prefixes . * * @param prefixes the prefixes to match * @return a list of matching refs * @throws IOException if the reference space cannot be accessed * @since 5 . 2 */ @NonNull public List < Ref > getRefsByPrefix ( String . . . prefixes ) throws IOException { List < Ref > result = new ArrayList < > ( ) ; for ( String prefix : prefixes ) { result . addAll ( getRefsByPrefixInternal ( prefix ) ) ; } return Collections . unmodifiableList ( result ) ; } /* * * Returns all refs that resolve directly to the given { @link ObjectId } . * Includes peeled { @link ObjectId } s . This is the inverse lookup of * { @link #exactRef ( String . . . ) } . * * < p > * The default implementation uses a linear scan . Implementors of * { @link RefDatabase } should override this method directly if a better * implementation is possible . * * @param id { @link ObjectId } to resolve * @return a { @link Set } of { @link Ref } s whose tip points to the provided id . * @throws IOException if the reference space cannot be accessed */ public Set < Ref > getRefsByObjectId ( ObjectId id ) throws IOException { Set < Ref > matchingRefs = new HashSet < > ( ) ; for ( Ref ref : getAllRefs ( ) ) { if ( ref . getObjectId ( ) != null && ref . getObjectId ( ) . equals ( id ) ) { matchingRefs . add ( ref ) ; } else if ( ref . getPeeledObjectId ( ) != null && ref . getPeeledObjectId ( ) . equals ( id ) ) { matchingRefs . add ( ref ) ; } } return Collections . unmodifiableSet ( matchingRefs ) ; } /* * * Returns the ref with the exact name given . * * @param names the name of the ref to find * @return the ref with the exact name given * @throws IOException if the reference space cannot be accessed */ public Ref exactRef ( String . . . names ) throws IOException { Ref ref = null ; for ( String name : names ) { ref = getRef ( name ) ; if ( ref != null ) { break ; } } return ref ; }
",,,"import java . io . IOException ; import java . util . ArrayList ; import java . util . Collections ; import java . util . List ; import org . eclipse . jgit . annotations . NonNull ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . RefDatabase ; /* * * This class provides methods to retrieve references from a reference space . * * @since 5 . 2 */ @NonNull public class RefUtils { /* * * Returns a list of references that have the given prefixes . * * @param prefixes the prefixes to match * @return a list of matching references * @throws IOException if the reference space cannot be accessed */ public List < Ref > getRefsByPrefix ( String . . . prefixes ) throws IOException { List < Ref > result = new ArrayList < > ( ) ; for ( String prefix : prefixes ) { result . addAll ( getRefsByPrefix ( prefix ) ) ; } return Collections . unmodifiableList ( result ) ; } /* * * Returns all references that resolve directly to the given { @link ObjectId } . * Includes peeled { @link ObjectId } s . This is the inverse lookup of * { @link #exactRef ( String . . . ) } . * * < p > * The default implementation uses a linear scan . Implementors of { @link RefDatabase } should * override this method directly if a better implementation is possible . * * @param id the { @link ObjectId } to resolve * @return a { @link List } of { @link Ref } s whose tip points to the provided id * @throws IOException if the reference space cannot be accessed */ public List < Ref > getRefsByObjectId ( ObjectId id ) throws IOException { List < Ref > result = new ArrayList < > ( ) ; // Implementation goes here return Collections . unmodifiableList ( result ) ; } }
",,,"* the reference space cannot be accessed . * @since 5 . 2 */ @NonNull public List < Ref > getRefsByPrefix ( String . . . prefixes ) throws IOException { List < Ref > result = new ArrayList < > ( ) ; for ( String prefix : prefixes ) { result . addAll ( getRefsByPrefix ( prefix ) ) ; } return Collections . unmodifiableList ( result ) ; } /* * * Returns all refs that resolve directly to the given { @link ObjectId } . < |startfocus| > * Includes peeled { @linkObjectId } s . This is the inverse lookup if < |endfocus| > * { @link #exactRef ( String . . . ) } . * * < p > * The default implementation uses a linear scan . Implementors of * { @link RefDatabase } should override this method directly if a better * implementation is possible . * * @param id * { @link ObjectId } to resolve * @return a { @link Set } of { @link Ref } s whose tip points to the provided * id . * @throws java . io . IOException * the reference space cannot be accessed . * @since 5 . 2 */ @NonNull public List < Ref > getRefsByPrefix ( String . . . prefixes ) throws IOException { List < Ref > result = new ArrayList < > ( ) ; for ( String prefix : prefixes ) { result . addAll ( getRefsByPrefix ( prefix ) ) ; } return Collections . unmodifiableList ( result ) ; } /* * * Returns all refs that resolve directly to the given { @link ObjectId } . < |startfocus| > * Includes peeled { @linkObjectId } s . This is the inverse lookup if < |endfocus| > * { @link #exactRef ( String . . . ) } . * * < p > * The default implementation uses a linear scan . Implementors of * { @link RefDatabase } should override this method directly if a better * implementation is possible . * * @param id * { @link ObjectId } to resolve * @return a { @link Set } of { @link Ref } s whose tip points to the provided * id . * @throws java . io . IOException * the reference space cannot be accessed .
",,
1535,"if ( ! destinationFile . exists ( ) ) { destinationFile . mkdirs ( ) ; } while ( entries . hasMoreElements ( ) ) { ZipEntry entry = entries . nextElement ( ) ; File outputFile = new File ( destinationFile , entry . getName ( ) ) ; if ( entry . isDirectory ( ) && ! outputFile . exists ( ) ) { outputFile . mkdirs ( ) ; continue ; } if ( ! outputFile . getParentFile ( ) . exists ( ) ) { outputFile . getParentFile ( ) . mkdirs ( ) ; } try ( InputStream inputStream = new BufferedInputStream ( zipFile . getInputStream ( entry ) ) ; OutputStream outStream = new BufferedOutputStream ( new FileOutputStream ( outputFile ) ) ) { copyStream ( inputStream , outStream ) ; } outputFiles . add ( outputFile ) ; if ( monitor != null ) { monitor . worked ( 1 ) ; } } return outputFiles ; } } private static void copyStream ( InputStream in , OutputStream out ) throws IOException { Assert . isNotNull ( in ) ; Assert . isNotNull ( out ) ; byte [ ] buffer = new byte [ 4096 ] ; int readCount ;
","try ( InputStream inputStream = new BufferedInputStream ( zipFile . getInputStream ( entry ) ) ; OutputStream outStream = new BufferedOutputStream ( new FileOutputStream ( outputFile ) ) ) { copyStream ( inputStream , outStream ) ;
","copyStream(inputStream, outStream);
",,,"try (InputStream inputStream = new BufferedInputStream(zipFile.getInputStream(entry))) { try (OutputStream outStream = new BufferedOutputStream(new FileOutputStream(outputFile))) { copyStream(inputStream, outStream); }
",,,"if ( ! destinationFile . exists ( ) ) { destinationFile . mkdirs ( ) ; } while ( entries . hasMoreElements ( ) ) { ZipEntry entry = entries . nextElement ( ) ; File outputFile = new File ( destinationFile , entry . getName ( ) ) ; if ( entry . isDirectory ( ) && ! outputFile . exists ( ) ) { outputFile . mkdirs ( ) ; continue ; } if ( ! outputFile . getParentFile ( ) . exists ( ) ) { outputFile . getParentFile ( ) . mkdirs ( ) ; } try ( InputStream inputStream = new BufferedInputStream ( zipFile . getInputStream ( entry ) ) ; OutputStream outStream = new BufferedOutputStream ( new FileOutputStream ( outputFile ) ) ) { copyStream ( inputStream , outStream ) ; } outputFiles . add ( outputFile ) ; if ( monitor != null ) { monitor . worked ( 1 ) ; } } return outputFiles ; private static void copyStream ( InputStream in , OutputStream out ) throws IOException { Assert . isNotNull ( in ) ; Assert . isNotNull ( out ) ; byte [ ] buffer = new byte [ 4096 ] ; int readCount ; while ( ( readCount = in . read ( buffer ) ) != - 1 ) { out . write ( buffer , 0 , readCount ) ; } }
",,,"if ( ! destinationFile . exists ( ) ) { destinationFile . mkdirs ( ) ; } while ( entries . hasMoreElements ( ) ) { ZipEntry entry = entries . nextElement ( ) ; File outputFile = new File ( destinationFile , entry . getName ( ) ) ; if ( entry . isDirectory ( ) && ! outputFile . exists ( ) ) { outputFile . mkdirs ( ) ; continue ; } if ( ! outputFile . getParentFile ( ) . exists ( ) ) { outputFile . getParentFile ( ) . mkdirs ( ) ; } try ( InputStream inputStream = new BufferedInputStream ( zipFile . getInputStream ( entry ) ) ; OutputStream outStream = new BufferedOutputStream ( new FileOutputStream ( outputFile ) ) ) { copyStream ( inputStream , outStream ) ; } outputFiles . add ( outputFile ) ; if ( monitor != null ) { monitor . worked ( 1 ) ; } } return outputFiles ; } private static void copyStream ( InputStream in , OutputStream out ) throws IOException { Assert . isNotNull ( in ) ; Assert . isNotNull ( out ) ; byte [ ] buffer = new byte [ 4096 ] ; int readCount ; while ( ( readCount = in . read ( buffer ) ) != - 1 ) { out . write ( buffer , 0 , readCount ) ; } }
",,,"if ( ! destinationFile . exists ( ) ) { destinationFile . mkdirs ( ) ; } while ( entries . hasMoreElements ( ) ) { ZipEntry entry = entries . nextElement ( ) ; File outputFile = new File ( destinationFile , entry . getName ( ) ) ; if ( entry . isDirectory ( ) && ! outputFile . exists ( ) ) { outputFile . mkdirs ( ) ; continue ; } if ( ! outputFile . getParentFile ( ) . exists ( ) ) { outputFile . getParentFile ( ) . mkdirs ( ) ; } < |startfocus| > try ( InputStream inputStream = new BufferedInputStream ( zipFile . getInputStream ( entry ) ) ; OutputStream outStream = new BufferedOutputStream ( new FileOutputStream ( outputFile ) ) ) { copyStream ( inputStream , outStream ) ; } < |endfocus| > outputFiles . add ( outputFile ) ; if ( monitor != null ) { monitor . worked ( 1 ) ; } } return outputFiles ; } } private static void copyStream ( InputStream in , OutputStream out ) throws IOException { Assert . isNotNull ( in ) ; Assert . isNotNull ( out ) ; byte [ ] buffer = new byte [ 4096 ] ; int readCount ;
",,
1539,"* http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Tasktop Technologies - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . mylyn . monitor . core ; import java . io . File ; import java . io . FileOutputStream ; import java . io . IOException ; import org . eclipse . core . runtime . IStatus ; import org . eclipse . core . runtime . Status ; import org . eclipse . mylyn . commons . core . StatusHandler ; import org . eclipse . mylyn . internal . monitor . core . IMonitorCoreConstants ; /* * * Used for logging interaction events . * * @author Mik Kersten * @since 2 . 0 */ public abstract class AbstractMonitorLog { protected File outputFile ; protected FileOutputStream outputStream ; protected boolean started = false ; public AbstractMonitorLog ( ) { super ( ) ; } public void startMonitoring ( ) { synchronized ( this ) { if ( started ) { return ; } else { started = true ; } } try { if ( ! outputFile . exists ( ) ) { outputFile . createNewFile ( ) ; } outputStream = new FileOutputStream ( outputFile , true ) ; } catch ( Exception e ) {
","*
","*
",,,"* * <p>This is a copy of the {@link AbstractMonitorLog} class, with some * effort, could be refactored to avoid duplication. *
",,,"package org . eclipse . mylyn . monitor . core ; import java . io . File ; import java . io . FileOutputStream ; import java . io . IOException ; import org . eclipse . core . runtime . IStatus ; import org . eclipse . core . runtime . Status ; import org . eclipse . mylyn . commons . core . StatusHandler ; import org . eclipse . mylyn . internal . monitor . core . IMonitorCoreConstants ; /* * * Used for logging interaction events . * * @author Mik Kersten * @since 2 . 0 */ public abstract class AbstractMonitorLog { protected File outputFile ; protected FileOutputStream outputStream ; protected boolean started = false ; public AbstractMonitorLog ( ) { super ( ) ; } public void startMonitoring ( ) { synchronized ( this ) { if ( started ) { return ; } else { started = true ; } } try { if ( ! outputFile . exists ( ) ) { outputFile . createNewFile ( ) ; } outputStream = new FileOutputStream ( outputFile , true ) ; } catch ( Exception e ) { StatusHandler . log ( new Status ( IStatus . ERROR , IMonitorCoreConstants . ID_PLUGIN , ""Could not create monitor log file"" , e ) ) ; } } public void stopMonitoring ( ) { synchronized ( this ) { if ( ! started ) { return ; } else { started = false ; } } try { outputStream . close ( ) ; } catch ( IOException e ) { StatusHandler . log ( new Status ( IStatus . ERROR , IMonitorCoreConstants . ID_PLUGIN , ""Could not close monitor log file"" , e ) ) ; } } }
",,,"package org . eclipse . mylyn . monitor . core ; import java . io . File ; import java . io . FileOutputStream ; import java . io . IOException ; import org . eclipse . core . runtime . IStatus ; import org . eclipse . core . runtime . Status ; import org . eclipse . mylyn . commons . core . StatusHandler ; import org . eclipse . mylyn . internal . monitor . core . IMonitorCoreConstants ; /* * * Used for logging interaction events . * * @author Mik Kersten * @since 2 . 0 */ public abstract class AbstractMonitorLog { protected File outputFile ; protected FileOutputStream outputStream ; protected boolean started = false ; public AbstractMonitorLog ( ) { super ( ) ; } public void startMonitoring ( ) { synchronized ( this ) { if ( started ) { return ; } else { started = true ; } } try { if ( ! outputFile . exists ( ) ) { outputFile . createNewFile ( ) ; } outputStream = new FileOutputStream ( outputFile , true ) ; } catch ( Exception e ) { StatusHandler . log ( new Status ( IStatus . ERROR , IMonitorCoreConstants . ID_PLUGIN , ""Failed to start monitoring"" , e ) ) ; } } }
",,,"* http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Tasktop Technologies - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . mylyn . monitor . core ; import java . io . File ; import java . io . FileOutputStream ; import java . io . IOException ; import org . eclipse . core . runtime . IStatus ; import org . eclipse . core . runtime . Status ; import org . eclipse . mylyn . commons . core . StatusHandler ; import org . eclipse . mylyn . internal . monitor . core . IMonitorCoreConstants ; /* * * Used for logging interaction events . < |startfocus| > * < |endfocus| > * @author Mik Kersten * @since 2 . 0 */ public abstract class AbstractMonitorLog { protected File outputFile ; protected FileOutputStream outputStream ; protected boolean started = false ; public AbstractMonitorLog ( ) { super ( ) ; } public void startMonitoring ( ) { synchronized ( this ) { if ( started ) { return ; } else { started = true ; } } try { if ( ! outputFile . exists ( ) ) { outputFile . createNewFile ( ) ; } outputStream = new FileOutputStream ( outputFile , true ) ; } catch ( Exception e ) {
",,
1571,"fHideWorkspaceFilterAction . setChecked ( ! hideWorkspace ) ; fHideExtEnabledFilterAction . setChecked ( ! hideEnabledExternal ) ; fHideExtDisabledFilterAction . setChecked ( ! hideDisabledExternal ) ; // when TP state is already initialized apply the SourcePluginFilter // directly , // otherwise defer state initialization to a background job and apply // the filter // when it is available . if ( PDECore . getDefault ( ) . getModelManager ( ) . isInitialized ( ) ) { PDEState state = PDECore . getDefault ( ) . getModelManager ( ) . getState ( ) ; fSourcePluginFilter = new SourcePluginFilter ( state ) ; fTreeViewer . addFilter ( fSourcePluginFilter ) ; } else { Job . createSystem ( """" , monitor - > { // $NON - NLS - 1$ PDEState state = TargetPlatformHelper . getPDEState ( ) ; Tree tree = fTreeViewer . getTree ( ) ; if ( ! tree . isDisposed ( ) ) { tree . getDisplay ( ) . asyncExec ( ( ) - > { fSourcePluginFilter = new SourcePluginFilter ( state ) ; fTreeViewer . addFilter ( fSourcePluginFilter ) ; } ) ; } } ) . schedule ( ) ; }
","fSourcePluginFilter = new SourcePluginFilter ( state ) ; fTreeViewer . addFilter ( fSourcePluginFilter ) ;
","fSourcePluginFilter = new SourcePluginFilter(state);
",,,"fSourcePluginFilter = new SourcePluginFilter(state);
",,,"fHideWorkspaceFilterAction . setChecked ( ! hideWorkspace ) ; fHideExtEnabledFilterAction . setChecked ( ! hideEnabledExternal ) ; fHideExtDisabledFilterAction . setChecked ( ! hideDisabledExternal ) ; if ( PDECore . getDefault ( ) . getModelManager ( ) . isInitialized ( ) ) { PDEState state = PDECore . getDefault ( ) . getModelManager ( ) . getState ( ) ; fSourcePluginFilter = new SourcePluginFilter ( state ) ; } else { Job . createSystem ( """" , monitor - > { PDEState state = TargetPlatformHelper . getPDEState ( ) ; Tree tree = fTreeViewer . getTree ( ) ; if ( ! tree . isDisposed ( ) ) { tree . getDisplay ( ) . asyncExec ( ( ) - > { fSourcePluginFilter = new SourcePluginFilter ( state ) ; fTreeViewer . addFilter ( fSourcePluginFilter ) ; } ) ; } } ) . schedule ( ) ; }
",,,"private long size = 0 ; private Path tmpFile ; public CleanFilter ( Repository db , InputStream in , OutputStream out ) throws IOException { super ( in , out ) ; lfsUtil = new LfsUtil ( db . getDirectory ( ) . toPath ( ) . resolve ( ""lfs"" ) ) ; Files . createDirectories ( lfsUtil . getLfsTmpDir ( ) ) ; tmpFile = lfsUtil . createTmpFile ( ) ; this . out = out ; } return rule ; private final Map < Project . NameKey , ProjectState > all ; private final ProjectCache projectCache ; private final CapabilityControl . Factory capabilityControlFactory ; private final ChangeControl . AssistedFactory changeControlFactory ; private final PermissionCollection . Factory sectionSorter ; private final InMemoryRepositoryManager repoManager ; private final GroupControl . Factory controlFactory ; private final GroupJson json ; private final Provider < ListIncludedGroups > listIncludes ; private final AllProjectsName allProjectsName = new AllProjectsName ( ""All - Projects"" ) ; private final ProjectConfig allProjects ; @SuppressWarnings ( ""unchecked"" ) public Util ( ) { all = new HashMap < > ( ) ; repoManager = new InMemoryRepositoryManager ( ) ; try { Repository repo = repoManager . createRepository ( allProjectsName ) ; allProjects = new ProjectConfig ( new Project . NameKey ( allProjectsName . get ( ) ) ) ; allProjects . load ( repo ) ; allProjects . getLabelSections ( ) . put ( CR . getName ( ) , CR ) ; add ( allProjects ) ; } catch ( IOException | ConfigInvalidException e ) { throw new RuntimeException ( e ) ; } projectCache = new ProjectCache ( ) { @Override protected ProjectState get ( Project . NameKey projectName ) { return all . get ( projectName ) ; } } ; } public ProjectTagsScreen ( Project . NameKey toShow ) { super ( toShow ) ; } fHideWorkspaceFilterAction . setChecked ( ! hideWorkspace ) ; fHideExtEnabledFilterAction . setChecked ( ! hideEnabledExternal ) ; fHideExtDisabledFilterAction . setChecked ( ! hideDisabledExternal ) ; if ( PDECore . getDefault ( ) . getModelManager ( ) . isInitialized ( ) ) { PDEState state = PDECore . getDefault ( ) . getModelManager ( ) . getState ( ) ; fSourcePluginFilter = new SourcePluginFilter ( state ) ; } else { Job . createSystem ( """" , monitor - > { PDEState state = TargetPlatformHelper . getPDEState ( ) ; Tree tree = fTreeViewer . getTree ( ) ; if ( ! tree . isDisposed ( ) ) { tree . getDisplay ( ) . asyncExec ( ( ) - > { fSourcePluginFilter = new SourcePluginFilter ( state ) ; fTreeViewer . addFilter ( fSourcePluginFilter ) ; } ) ;
",,,"fHideWorkspaceFilterAction . setChecked ( ! hideWorkspace ) ; fHideExtEnabledFilterAction . setChecked ( ! hideEnabledExternal ) ; fHideExtDisabledFilterAction . setChecked ( ! hideDisabledExternal ) ; // when TP state is already initialized apply the SourcePluginFilter // directly , // otherwise defer state initialization to a background job and apply // the filter // when it is available . if ( PDECore . getDefault ( ) . getModelManager ( ) . isInitialized ( ) ) { PDEState state = PDECore . getDefault ( ) . getModelManager ( ) . getState ( ) ; < |startfocus| > fSourcePluginFilter = new SourcePluginFilter ( state ) ; fTreeViewer . addFilter ( fSourcePluginFilter ) ; < |endfocus| > } else { Job . createSystem ( """" , monitor - > { // $NON - NLS - 1$ PDEState state = TargetPlatformHelper . getPDEState ( ) ; Tree tree = fTreeViewer . getTree ( ) ; if ( ! tree . isDisposed ( ) ) { tree . getDisplay ( ) . asyncExec ( ( ) - > { fSourcePluginFilter = new SourcePluginFilter ( state ) ; fTreeViewer . addFilter ( fSourcePluginFilter ) ; } ) ; } } ) . schedule ( ) ; }
",,
1595,"* the display to search for potential controls * @param locationToFind * the position , in display coordinates , to be located * @return the most specific SWT control at the given location */ public static Control findControl ( Display displayToSearch , Point locationToFind ) { Shell [ ] shells = displayToSearch . getShells ( ) ; fixShellOrder ( displayToSearch , shells ) ; return findControl ( shells , locationToFind ) ; } /* * * Finds the active shell and moves it to the end of the given array , so that * findControl ( ) will find the controls from the active shell first . */ private static void fixShellOrder ( Display display , Shell [ ] shells ) { if ( shells . length <= 1 ) { return ; } Shell activeShell = display . getActiveShell ( ) ; int lastIndex = shells . length - 1 ; if ( activeShell == null || shells [ lastIndex ] == activeShell ) { return ; } // find the index of the active shell and exchange last one with active
","* Finds the active shell and moves it to the end of the given array , so that * findControl ( ) will find the controls from the active shell first .
","* Finds the active shell and move it to the end of the given array, so the * findControl() will find the controls from the active shell first
",,,"* Finds the active shell and moves it to the end of the given array, so that * findControl() will find the controls from the active shell first
",,,"public static Control findControl ( Display displayToSearch , Point locationToFind ) { Shell [ ] shells = displayToSearch . getShells ( ) ; fixShellOrder ( displayToSearch , shells ) ; return findControl ( shells , locationToFind ) ; } private static void fixShellOrder ( Display display , Shell [ ] shells ) { if ( shells . length <= 1 ) { return ; } Shell activeShell = display . getActiveShell ( ) ; int lastIndex = shells . length - 1 ; if ( activeShell == null || shells [ lastIndex ] == activeShell ) { return ; } // find the index of the active shell and exchange last one with active }
",,,"/* * * Finds the active shell and moves it to the end of the given array , so the * findControl ( ) will find the controls from the active shell first */ private static void fixShellOrder ( Display display , Shell [ ] shells ) { if ( shells . length <= 1 ) { return ; } Shell activeShell = display . getActiveShell ( ) ; int lastIndex = shells . length - 1 ; if ( activeShell == null || shells [ lastIndex ] == activeShell ) { return ; } // find the index of the active shell and exchange last one with active int activeShellIndex = - 1 ; for ( int i = 0 ; i < shells . length ; i ++ ) { if ( shells [ i ] == activeShell ) { activeShellIndex = i ; break ; } } if ( activeShellIndex != - 1 ) { Shell temp = shells [ lastIndex ] ; shells [ lastIndex ] = shells [ activeShellIndex ] ; shells [ activeShellIndex ] = temp ; } }
",,,"* the display to search for potential controls * @param locationToFind * the position , in display coordinates , to be located * @return the most specific SWT control at the given location */ public static Control findControl ( Display displayToSearch , Point locationToFind ) { Shell [ ] shells = displayToSearch . getShells ( ) ; fixShellOrder ( displayToSearch , shells ) ; return findControl ( shells , locationToFind ) ; } /* * < |startfocus| > * Finds the active shell and moves it to the end of the given array , so that * findControl ( ) will find the controls from the active shell first < |endfocus| > */ private static void fixShellOrder ( Display display , Shell [ ] shells ) { if ( shells . length <= 1 ) { return ; } Shell activeShell = display . getActiveShell ( ) ; int lastIndex = shells . length - 1 ; if ( activeShell == null || shells [ lastIndex ] == activeShell ) { return ; } // find the index of the active shell and exchange last one with active
",,
1604,"private static void collectMatchingIUs ( Map < String , ? > indexToUse , String name , Collection < IInstallableUnit > collector ) { Object v = indexToUse . get ( name ) ; if ( v == null ) return ; if ( v instanceof IInstallableUnit ) collector . add ( ( IInstallableUnit ) v ) ; else collector . addAll ( ( Collection < IInstallableUnit > ) v ) ;
","private static void collectMatchingIUs ( Map < String , ? > indexToUse , String name , Collection < IInstallableUnit > collector ) {
","private static void collectMatchingIUs(Map<String, ?> indexToUse, String name, Collection<IInstallableUnit> collector) {
",,,"private static void collectMatchingIUs(Map<String, ?> indexToUse, String name, Collection<IInstallableUnit> collector) {
",,,"public static void collectMatchingIUs ( Map < String , ? > indexToUse , String name , Collection < IInstallableUnit > collector ) { Object v = indexToUse . get ( name ) ; if ( v == null ) return ; if ( v instanceof IInstallableUnit ) collector . add ( ( IInstallableUnit ) v ) ; else collector . addAll ( ( Collection < IInstallableUnit > ) v ) ; }
",,,"private static void collectMatchingIUs ( Map < String , ? > indexToUse , String name , Collection < IInstallableUnit > collector ) { Object v = indexToUse . get ( name ) ; if ( v == null ) return ; if ( v instanceof IInstallableUnit ) collector . add ( ( IInstallableUnit ) v ) ; else collector . addAll ( ( Collection < IInstallableUnit > ) v ) ; }
",,,"< |startfocus| > private static void collectMatchingIUs ( Map < String , ? > indexToUse , String name , Collection < IInstallableUnit > collector ) { < |endfocus| > Object v = indexToUse . get ( name ) ; if ( v == null ) return ; if ( v instanceof IInstallableUnit ) collector . add ( ( IInstallableUnit ) v ) ; else collector . addAll ( ( Collection < IInstallableUnit > ) v ) ;
",,
1607,"public void createArtifact ( @Nullable ArtifactToken parent , ArtifactToken artifact ) { ArtifactToken art = createArtifact ( artifact ) ; if ( parent != null ) { addChild ( parent , art ) ; }
","if ( parent != null ) { addChild ( parent , art ) ; }
","if (parent == null) { return; } addChild(parent, art);
",,,"if (parent != null) { addChild(parent, art); } else { removeChild(parent); }
",,,"public void createArtifact ( @Nullable ArtifactToken parent , ArtifactToken artifact ) { ArtifactToken art = createArtifact ( artifact ) ; if ( parent != null ) { addChild ( parent , art ) ; } }
",,,"public void createArtifact ( @Nullable ArtifactToken parent , ArtifactToken artifact ) { ArtifactToken art = createArtifact ( artifact ) ; if ( parent != null ) { addChild ( parent , art ) ; } }
",,,"public void createArtifact ( @Nullable ArtifactToken parent , ArtifactToken artifact ) { ArtifactToken art = createArtifact ( artifact ) ; < |startfocus| > if ( parent != null ) { addChild ( parent , art ) ; } < |endfocus| >
",,
1611,"breakStatement . setSourceRange ( statement . sourceStart , statement . sourceEnd - statement . sourceStart + 1 ) ; } if ( statement . label != null ) { final SimpleName name = new SimpleName ( this . ast ) ; name . internalSetIdentifier ( new String ( statement . label ) ) ; retrieveIdentifierAndSetPositions ( statement . sourceStart , statement . sourceEnd , name ) ; breakStatement . setLabel ( name ) ; } else if ( statement . expression != null && this . ast . apiLevel >= AST . JLS12_INTERNAL ) { final Expression expression = convert ( statement . expression ) ; breakStatement . setExpression ( expression ) ; int sourceEnd = statement . sourceEnd ; if ( sourceEnd == - 1 ) { breakStatement . setSourceRange ( statement . sourceStart , statement . sourceEnd - statement . sourceStart + 2 ) ; } else { breakStatement . setSourceRange ( statement . sourceStart , sourceEnd - statement . sourceStart + 1 ) ; } } return breakStatement ;
","int sourceEnd = statement . sourceEnd ;
","<|del|>
",,,"int sourceEnd = retrieveSemiColonPosition(expression);
",,,"breakStatement . setSourceRange ( statement . getStartPosition ( ) , statement . getLength ( ) ) ; if ( statement . getLabel ( ) != null ) { final SimpleName name = new SimpleName ( this . ast ) ; name . setIdentifier ( statement . getLabel ( ) . getIdentifier ( ) ) ; retrieveIdentifierAndSetPositions ( statement . getStartPosition ( ) , statement . getEndPosition ( ) , name ) ; breakStatement . setLabel ( name ) ; } else if ( statement . getExpression ( ) != null && this . ast . apiLevel >= AST . JLS12_INTERNAL ) { final Expression expression = convert ( statement . getExpression ( ) ) ; breakStatement . setExpression ( expression ) ; int sourceEnd = retrieveSemiColonPosition ( expression ) ; if ( sourceEnd == - 1 ) { breakStatement . setSourceRange ( statement . getStartPosition ( ) , statement . getLength ( ) + 2 ) ; } else { breakStatement . setSourceRange ( statement . getStartPosition ( ) , sourceEnd - statement . getStartPosition ( ) + 1 ) ; } } return breakStatement ;
",,,"breakStatement . setSourceRange ( statement . sourceStart , statement . sourceEnd - statement . sourceStart + 1 ) ; if ( statement . label != null ) { final SimpleName name = new SimpleName ( this . ast ) ; name . internalSetIdentifier ( new String ( statement . label ) ) ; retrieveIdentifierAndSetPositions ( statement . sourceStart , statement . sourceEnd , name ) ; breakStatement . setLabel ( name ) ; } else if ( statement . expression != null && this . ast . apiLevel >= AST . JLS12_INTERNAL ) { final Expression expression = convert ( statement . expression ) ; breakStatement . setExpression ( expression ) ; int sourceEnd = retrieveSemiColonPosition ( expression ) ; if ( sourceEnd == - 1 ) { breakStatement . setSourceRange ( statement . sourceStart , statement . sourceEnd - statement . sourceStart + 2 ) ; } else { breakStatement . setSourceRange ( statement . sourceStart , sourceEnd - statement . sourceStart + 1 ) ; } } return breakStatement ;
",,,"breakStatement . setSourceRange ( statement . sourceStart , statement . sourceEnd - statement . sourceStart + 1 ) ; } if ( statement . label != null ) { final SimpleName name = new SimpleName ( this . ast ) ; name . internalSetIdentifier ( new String ( statement . label ) ) ; retrieveIdentifierAndSetPositions ( statement . sourceStart , statement . sourceEnd , name ) ; breakStatement . setLabel ( name ) ; } else if ( statement . expression != null && this . ast . apiLevel >= AST . JLS12_INTERNAL ) { final Expression expression = convert ( statement . expression ) ; breakStatement . setExpression ( expression ) ; < |startfocus| > int sourceEnd = statement . sourceEnd ; < |endfocus| > if ( sourceEnd == - 1 ) { breakStatement . setSourceRange ( statement . sourceStart , statement . sourceEnd - statement . sourceStart + 2 ) ; } else { breakStatement . setSourceRange ( statement . sourceStart , sourceEnd - statement . sourceStart + 1 ) ; } } return breakStatement ;
",,
1618,"long /* int */ [ ] len = new long /* int */ [ 1 ] ; if ( type == null ) SWT . error ( SWT . ERROR_UNSUPPORTED_FORMAT ) ; GDK . gdk_pixbuf_save_to_bufferv ( pixbuf , buffer , len , type , null , null , null ) ; byte [ ] byteArray = new byte [ ( int ) len [ 0 ] ] ; C . memmove ( byteArray , buffer [ 0 ] , byteArray . length ) ; try { stream . write ( byteArray ) ; } catch ( IOException e ) { SWT . error ( SWT . ERROR_IO ) ; }
","< |del| >/ / FileFormat . save ( stream , format , this ) ;
","FileFormat.save(stream, format, this);
",,,"<|del|>
",,,"long [ ] len = new long [ 1 ] ; if ( type == null ) { SWT . error ( SWT . ERROR_UNSUPPORTED_FORMAT ) ; } GDK . gdk_pixbuf_save_to_bufferv ( pixbuf , buffer , len , type , null , null , null ) ; byte [ ] byteArray = new byte [ ( int ) len [ 0 ] ] ; C . memmove ( byteArray , buffer [ 0 ] , byteArray . length ) ; try { stream . write ( byteArray ) ; } catch ( IOException e ) { SWT . error ( SWT . ERROR_IO ) ; } FileFormat . save ( stream , format , this ) ;
",,,"long /* int */ [ ] len = new long /* int */ [ 1 ] ; if ( type == null ) SWT . error ( SWT . ERROR_UNSUPPORTED_FORMAT ) ; GDK . gdk_pixbuf_save_to_bufferv ( pixbuf , buffer , len , type , null , null , null ) ; byte [ ] byteArray = new byte [ ( int ) len [ 0 ] ] ; C . memmove ( byteArray , buffer [ 0 ] , byteArray . length ) ; try { stream . write ( byteArray ) ; } catch ( IOException e ) { SWT . error ( SWT . ERROR_IO ) ; } // FileFormat . save ( stream , format , this ) ;
",,,"long /* int */ [ ] len = new long /* int */ [ 1 ] ; if ( type == null ) SWT . error ( SWT . ERROR_UNSUPPORTED_FORMAT ) ; GDK . gdk_pixbuf_save_to_bufferv ( pixbuf , buffer , len , type , null , null , null ) ; byte [ ] byteArray = new byte [ ( int ) len [ 0 ] ] ; C . memmove ( byteArray , buffer [ 0 ] , byteArray . length ) ; try { stream . write ( byteArray ) ; } catch ( IOException e ) { SWT . error ( SWT . ERROR_IO ) ; } < |startfocus| > // FileFormat . save ( stream , format , this ) ; < |endfocus| >
",,
1620,"private void disposeIfExited ( final Control control , Event e ) { if ( ! control . isDisposed ( ) ) { Point pt = control . toDisplay ( e . x , e . y ) ; Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; if ( ! bounds . contains ( pt ) && ! fInitialDeadzone . contains ( pt ) ) { tipShell . dispose ( ) ; Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; }
","< |del| > if ( bounds . x == 0 && bounds . y == 0 ) { Point offset = tipShell . toDisplay ( bounds . x , bounds . y ) ; bounds . x = offset . x ; bounds . y = offset . y ; }
","<|del|>
",,,"<|del|>
",,,"private void disposeIfExited ( final Control control , Event e ) { if ( ! control . isDisposed ( ) ) { Point pt = control . toDisplay ( e . x , e . y ) ; Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; Point offset = tipShell . getLocation ( ) ; bounds . x = offset . x ; bounds . y = offset . y ; bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; if ( ! bounds . contains ( pt ) && ! fInitialDeadzone . contains ( pt ) ) { tipShell . dispose ( ) ; Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } }
",,,"private void disposeIfExited ( final Control control , Event e ) { if ( ! control . isDisposed ( ) ) { Point pt = control . toDisplay ( e . x , e . y ) ; Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; if ( bounds . x == 0 && bounds . y == 0 ) { Point offset = tipShell . toDisplay ( bounds . x , bounds . y ) ; bounds . x = offset . x ; bounds . y = offset . y ; } bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; if ( ! bounds . contains ( pt ) && ! fInitialDeadzone . contains ( pt ) ) { tipShell . dispose ( ) ; Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } }
",,,"private void disposeIfExited ( final Control control , Event e ) { if ( ! control . isDisposed ( ) ) { Point pt = control . toDisplay ( e . x , e . y ) ; Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; if ( ! bounds . contains ( pt ) && ! fInitialDeadzone . contains ( pt ) ) { tipShell . dispose ( ) ; Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; }
",,
1621,"Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; if ( bounds . x == 0 && bounds . y == 0 ) { Point offset = tipShell . toDisplay ( bounds . x , bounds . y ) ; bounds . x = offset . x ; bounds . y = offset . y ; } bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; if ( ! bounds . contains ( pt ) && ! fInitialDeadzone . contains ( pt ) ) { tipShell . dispose ( ) ; Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; }
","< |del| >
","<|del|>
",,,"Point pt = tipShell.getBounds();
",,,"Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; if ( ! bounds . contains ( pt ) ) { tipShell . dispose ( ) ; Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; }
",,,"Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; if ( bounds . x == 0 && bounds . y == 0 ) { Point offset = tipShell . toDisplay ( bounds . x , bounds . y ) ; bounds . x = offset . x ; bounds . y = offset . y ; } bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; if ( ! bounds . contains ( pt ) && ! fInitialDeadzone . contains ( pt ) ) { tipShell . dispose ( ) ; Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; }
",,,"Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; if ( bounds . x == 0 && bounds . y == 0 ) { Point offset = tipShell . toDisplay ( bounds . x , bounds . y ) ; bounds . x = offset . x ; bounds . y = offset . y ; } bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; < |startfocus| > < |endfocus| > if ( ! bounds . contains ( pt ) ) { tipShell . dispose ( ) ; Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; }
",,
1628,"import org . eclipse . sirius . viewpoint . Messages ; import com . google . common . base . Preconditions ; /* * * A class providing useful methods for refresh . * * @author mbats */ public final class RefreshHelper { private static List < Predicate < Notification > > impactingNotificationPredicates = new ArrayList < > ( ) ; /* * * Prevent instantiation . */ private RefreshHelper ( ) { } /* * * Checks whether at least one change of which we are notified , concerns a semantic model or a specific graphical * change ( registered through { @link #registerImpactingNotification ( Predicate ) } ) . * * @param notifications * the model changes . * @return < code > true </ code > if the changes impact a semantic model or a specific graphical change . */ public static boolean isImpactingNotification ( final Collection < Notification > notifications ) { boolean isImpactingNotification = false ; Set < EObject > alreadyDoneNotifiers = new HashSet < > ( ) ; for ( Notification notification : notifications ) { Object notifier = notification . getNotifier ( ) ; if ( notifier instanceof EObject ) { EObject eObjectNotifier = ( EObject ) notifier ;
","* Checks whether at least one change of which we are notified , concerns a semantic model or a specific graphical
","* Checks whether at least one changes of which we are notified, concern a semantic model or a specific graphical
",,,"* Checks whether at least one changes of which we are notified, concerns a semantic model or a specific graphical
",,,"import org . eclipse . sirius . viewpoint . Messages ; import com . google . common . base . Preconditions ; import java . util . ArrayList ; import java . util . Collection ; import java . util . HashSet ; import java . util . List ; import java . util . Set ; import org . eclipse . emf . common . notify . Notification ; import org . eclipse . emf . ecore . EObject ; import com . google . common . base . Predicate ; public final class RefreshHelper { private static List < Predicate < Notification > > impactingNotificationPredicates = new ArrayList < > ( ) ; private RefreshHelper ( ) { } public static boolean isImpactingNotification ( final Collection < Notification > notifications ) { boolean isImpactingNotification = false ; Set < EObject > alreadyDoneNotifiers = new HashSet < > ( ) ; for ( Notification notification : notifications ) { Object notifier = notification . getNotifier ( ) ; if ( notifier instanceof EObject ) { EObject eObjectNotifier = ( EObject ) notifier ; if ( ! alreadyDoneNotifiers . contains ( eObjectNotifier ) ) { alreadyDoneNotifiers . add ( eObjectNotifier ) ; if ( isImpactingNotification ( eObjectNotifier ) ) { isImpactingNotification = true ; break ; } } } } return isImpactingNotification ; } private static boolean isImpactingNotification ( EObject eObjectNotifier ) { for ( Predicate < Notification > predicate : impactingNotificationPredicates ) { if ( predicate . apply ( eObjectNotifier ) ) { return true ; } } return false ; } public static void registerImpactingNotification ( Predicate < Notification > predicate ) { Preconditions . checkNotNull ( predicate ) ; impactingNotificationPredicates . add ( predicate ) ; } }
",,,"import org . eclipse . sirius . viewpoint . Messages ; import com . google . common . base . Preconditions ; import java . util . ArrayList ; import java . util . Collection ; import java . util . HashSet ; import java . util . List ; import java . util . Set ; import java . util . function . Predicate ; /* * * A class providing useful methods for refresh . * * @author mbats */ public final class RefreshHelper { private static List < Predicate < Notification > > impactingNotificationPredicates = new ArrayList < > ( ) ; /* * * Prevent instantiation . */ private RefreshHelper ( ) { } /* * * Checks whether at least one changes of which we are notified , concern a semantic model or a specific graphical * change ( registered through { @link #registerImpactingNotification ( Predicate ) } ) . * * @param notifications the model changes . * @return < code > true </ code > if the changes impact a semantic model or a specific graphical change . */ public static boolean isImpactingNotification ( final Collection < Notification > notifications ) { boolean isImpactingNotification = false ; Set < EObject > alreadyDoneNotifiers = new HashSet < > ( ) ; for ( Notification notification : notifications ) { Object notifier = notification . getNotifier ( ) ; if ( notifier instanceof EObject ) { EObject eObjectNotifier = ( EObject ) notifier ; // Check if the notifier is already processed if ( alreadyDoneNotifiers . contains ( eObjectNotifier ) ) { continue ; } alreadyDoneNotifiers . add ( eObjectNotifier ) ; if ( isImpactingSemanticChange ( eObjectNotifier ) || isImpactingGraphicalChange ( notification ) ) { isImpactingNotification = true ; break ; } } } return isImpactingNotification ; } /* * * Checks if the given EObject is an impacting semantic change . * * @param eObject the EObject to check . * @return < code > true </ code > if the EObject is an impacting semantic change , < code > false </ code > otherwise . */ private static boolean isImpactingSemanticChange ( EObject eObject ) { // TODO : Implement the logic to check if the EObject is an impacting semantic change return false ; } /* * * Checks if the given notification is an impacting graphical change . * * @param notification the notification to check . * @return < code > true </ code > if the notification is an impacting graphical change , < code > false </ code >
",,,"import org . eclipse . sirius . viewpoint . Messages ; import com . google . common . base . Preconditions ; /* * * A class providing useful methods for refresh . * * @author mbats */ public final class RefreshHelper { private static List < Predicate < Notification > > impactingNotificationPredicates = new ArrayList < > ( ) ; /* * * Prevent instantiation . */ private RefreshHelper ( ) { } /* * < |startfocus| > * Checks whether at least one changes of which we are notified , concern a semantic model or a specific graphical < |endfocus| > * change ( registered through { @link #registerImpactingNotification ( Predicate ) } ) . * * @param notifications * the model changes . * @return < code > true </ code > if the changes impact a semantic model or a specific graphical change . */ public static boolean isImpactingNotification ( final Collection < Notification > notifications ) { boolean isImpactingNotification = false ; Set < EObject > alreadyDoneNotifiers = new HashSet < > ( ) ; for ( Notification notification : notifications ) { Object notifier = notification . getNotifier ( ) ; if ( notifier instanceof EObject ) { EObject eObjectNotifier = ( EObject ) notifier ; if ( ! alreadyDoneNotifiers . contains ( eObjectNotifier ) ) { alreadyDoneNotifiers . add ( eObjectNotifier ) ; isImpactingNotification = isImpactingNotification || isImpactingNotification ( notification ) ; } } } return isImpactingNotification ; } /* * * Checks whether the change of which we are notified , concern a semantic model or a specific graphical change ( registered < |startfocus| > * through { @link #registerImpactingNotification ( Predicate ) } ) . * * @param notification * the model change . * @return < code > true </ code > if the change impact a semantic model or a specific graphical change . */ public static boolean isImpactingNotification ( final Notification notification ) { boolean isImpactingNotification = false ; for ( Predicate < Notification > impactingNotificationPredicate : impactingNotificationPredicates ) { isImpactingNotification = isImpactingNotification || impactingNotificationPredicate . apply ( notification ) ; } return isImpactingNotification ; } /* * * Registers a predicate to check whether a notification is impacting or not . * * @param impactingNotificationPredicate * the predicate to register . */ public static void registerImpactingNotification ( Predicate < Notification > impactingNotificationPredicate ) { impactingNotificationPredicates . add ( impactingNotificationPredicate ) ; } /* * * Unregisters a predicate to check whether a notification is impacting or not . * * @param impactingNotificationPredicate * the predicate to unregister . */ public static void unregisterImpactingNotification ( Predicate < Notification > impactingNotificationPredicate ) { impactingNotificationPredicates . remove ( impactingNotificationPredicate ) ; } }
",,
1633,"public static void cleanUp ( ) { SWTBotUtils . closeViewById ( UML2DVIEW_ID , fBot ) ; fFileLocation . delete ( ) ; SWTBotUtils . deleteProject ( PROJECT_NAME , fBot ) ; fLogger . removeAllAppenders ( ) ;
","fFileLocation . delete ( ) ; SWTBotUtils . deleteProject ( PROJECT_NAME , fBot ) ;
","<|del|>
",,,"<|del|>
",,,"public static void cleanUp ( ) { SWTBotUtils . closeViewById ( UML2DVIEW_ID , fBot ) ; fLogger . removeAllAppenders ( ) ; if ( fProject != null ) { fProject . delete ( true , true , null ) ; } if ( fFileLocation != null ) { fFileLocation . delete ( ) ; } }
",,,"public static void cleanUp ( ) { SWTBotUtils . closeViewById ( UML2DVIEW_ID , fBot ) ; fFileLocation . delete ( ) ; fLogger . removeAllAppenders ( ) ; tearDown ( ) ; }
",,,"public static void cleanUp ( ) { SWTBotUtils . closeViewById ( UML2DVIEW_ID , fBot ) ; < |startfocus| > fFileLocation . delete ( ) ; fLogger . removeAllAppenders ( ) ; < |endfocus| >
",,
1655,"** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2010 - 2019 , Tamas Szabo , itemis AG , Gabor Bergmann , IncQuery Labs Ltd . * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v . 2 . 0 which is available at * http :/ / www . eclipse . org / legal / epl - v20 . html . * * SPDX - License - Identifier : EPL - 2 . 0 ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . viatra . query . runtime . matchers . memories ; /* * * Represents a replacement between timestamps . * Either the old or the new timestamp can be null , but not at the same time . * * @author Tamas Szabo */ public class TimestampReplacement < Timestamp extends Comparable < Timestamp > > { public final Timestamp oldValue ; public final Timestamp newValue ; public TimestampReplacement ( final Timestamp oldValue , final Timestamp newValue ) { if ( oldValue == null && newValue == null ) { throw new IllegalArgumentException ( ""Old and new cannot be both null at the same time ! "" ) ; } this . oldValue = oldValue ; this . newValue = newValue ; } }
","* Represents a replacement between timestamps . * Either the old or the new timestamp can be null , but not at the same time .
","* Represents that a replacement between timestamps. Either old or new can be * null, but not at the same time.
",,,"* Represents that a replacement between timestamps.
",,,"package org . eclipse . viatra . query . runtime . matchers . memories ; /* * * Represents a replacement between timestamps . * Either old or new can be null , but not both at the same time . * * @author Tamas Szabo */ public class TimestampReplacement < Timestamp extends Comparable < Timestamp > > { public final Timestamp oldValue ; public final Timestamp newValue ; public TimestampReplacement ( final Timestamp oldValue , final Timestamp newValue ) { if ( oldValue == null && newValue == null ) { throw new IllegalArgumentException ( ""Old and new cannot be both null at the same time ! "" ) ; } this . oldValue = oldValue ; this . newValue = newValue ; } }
",,,"/* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** **
",,,"** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2010 - 2019 , Tamas Szabo , itemis AG , Gabor Bergmann , IncQuery Labs Ltd . * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v . 2 . 0 which is available at * http :/ / www . eclipse . org / legal / epl - v20 . html . * * SPDX - License - Identifier : EPL - 2 . 0 ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . viatra . query . runtime . matchers . memories ; /* * < |startfocus| > * Represents a replacement between timestamps . * Either old or new can be null , but not at the same time . < |endfocus| > * * @author Tamas Szabo */ public class TimestampReplacement < Timestamp extends Comparable < Timestamp > > { public final Timestamp oldValue ; public final Timestamp newValue ; public TimestampReplacement ( final Timestamp oldValue , final Timestamp newValue ) { if ( oldValue == null && newValue == null ) { throw new IllegalArgumentException ( ""Old and new cannot be both null at the same time ! "" ) ; } this . oldValue = oldValue ; this . newValue = newValue ; } }
",,
1662,"protected boolean hasJREInClassPath ( IJavaProject javaProject ) { if ( javaProject != null ) { try { IClasspathEntry [ ] oldClasspaths = javaProject . getRawClasspath ( ) ; for ( int i = 0 ; i < oldClasspaths . length ; i ++ ) { if ( isJREContainer ( oldClasspaths [ i ] . getPath ( ) ) ) { return true ; } } } catch ( JavaModelException e ) { // do nothing } } return false ;
","// do nothing
","<|del|>
",,,"return false;
",,,"protected boolean hasJREInClassPath ( IJavaProject javaProject ) { if ( javaProject != null ) { try { IClasspathEntry [ ] oldClasspaths = javaProject . getRawClasspath ( ) ; for ( int i = 0 ; i < oldClasspaths . length ; i ++ ) { if ( isJREContainer ( oldClasspaths [ i ] . getPath ( ) ) ) { return true ; } } } catch ( JavaModelException e ) { e . printStackTrace ( ) ; } } return false ; }
",,,"protected boolean hasJREInClassPath ( IJavaProject javaProject ) { if ( javaProject != null ) { try { IClasspathEntry [ ] oldClasspaths = javaProject . getRawClasspath ( ) ; for ( int i = 0 ; i < oldClasspaths . length ; i ++ ) { if ( isJREContainer ( oldClasspaths [ i ] . getPath ( ) ) ) { return true ; } } } catch ( JavaModelException e ) { e . printStackTrace ( ) ; } } return false ; }
",,,"protected boolean hasJREInClassPath ( IJavaProject javaProject ) { if ( javaProject != null ) { try { IClasspathEntry [ ] oldClasspaths = javaProject . getRawClasspath ( ) ; for ( int i = 0 ; i < oldClasspaths . length ; i ++ ) { if ( isJREContainer ( oldClasspaths [ i ] . getPath ( ) ) ) { return true ; } } } catch ( JavaModelException e ) { < |startfocus| > // TODO Auto - generated catch block e . printStackTrace ( ) ; < |endfocus| > } } return false ;
",,
1674,"public boolean add ( @Nullable IEventDeclaration e ) { synchronized ( this ) { fInnerEvents . put ( fSize , e ) ; fSize ++ ; } return true ;
","fInnerEvents . put ( fSize , e ) ; fSize ++ ;
","fInnerEvents.put(fLastAdded, e); fLastAdded++;
",,,"fInnerEvents.put(fLastAdded, e);
",,,"public boolean add ( @Nullable IEventDeclaration e ) { synchronized ( this ) { fInnerEvents . put ( fNextAdded , e ) ; fNextAdded ++ ; } return true ; }
",,,"public boolean add ( @Nullable IEventDeclaration e ) { synchronized ( this ) { fInnerEvents . put ( fNextAdded , e ) ; fNextAdded ++ ; } return true ; }
",,,"public boolean add ( @Nullable IEventDeclaration e ) { synchronized ( this ) { < |startfocus| > fInnerEvents . put ( fNextAdded , e ) ; fNextAdded ++ ; < |endfocus| > } return true ;
",,
1678,"* header until end of trailer . * * @return time in milliseconds spent writing the pack output , from start of * header until end of trailer . The transfer speed can be * approximated by dividing { @link #getTotalBytes ( ) } by this value . */ public long getTimeWriting ( ) { return statistics . timeWriting ; } /* * * @return number of trees traversed in the walk when writing the pack . * @since 5 . 4 */ public long getTreesTraversed ( ) { return statistics . treesTraversed ; } /* * * Get total time spent processing this pack . * * @return total time spent processing this pack . */ public long getTimeTotal ( ) { return statistics . timeCounting + statistics . timeSearchingForReuse + statistics . timeSearchingForSizes + statistics . timeCompressing + statistics . timeWriting ; } /* * * Get the average output speed in terms of bytes - per - second . *
","< |del| >* Get Number of trees traversed in the walk when writing the pack . *
","<|del|>
",,,"* Get Number of trees traversed in the walk when writing the pack. *
",,,"/* * * Get the time in milliseconds spent writing the pack output , from start of header until end of trailer . * The transfer speed can be approximated by dividing { @link #getTotalBytes ( ) } by this value . * * @return time in milliseconds spent writing the pack output . */ public long getTimeWriting ( ) { return statistics . timeWriting ; } /* * * Get the number of trees traversed in the walk when writing the pack . * * @return number of trees traversed in the walk when writing the pack . * @since 5 . 4 */ public long getTreesTraversed ( ) { return statistics . treesTraversed ; } /* * * Get the total time spent processing this pack . * * @return total time spent processing this pack . */ public long getTimeTotal ( ) { return statistics . timeCounting + statistics . timeSearchingForReuse + statistics . timeSearchingForSizes + statistics . timeCompressing + statistics . timeWriting ; } /* * * Get the average output speed in terms of bytes - per - second . * * @return average output speed in terms of bytes - per - second . */ public long getAverageOutputSpeed ( ) { return getTotalBytes ( ) / getTimeWriting ( ) ; }
",,,"public long getTimeWriting ( ) { return statistics . timeWriting ; } public long getTreesTraversed ( ) { return statistics . treesTraversed ; } public long getTimeTotal ( ) { return statistics . timeCounting + statistics . timeSearchingForReuse + statistics . timeSearchingForSizes + statistics . timeCompressing + statistics . timeWriting ; }
",,,"* header until end of trailer . * * @return time in milliseconds spent writing the pack output , from start of * header until end of trailer . The transfer speed can be * approximated by dividing { @link #getTotalBytes ( ) } by this value . */ public long getTimeWriting ( ) { return statistics . timeWriting ; } /* * < |startfocus| > * Get Number of trees traversed in the walk when writing the pack . * < |endfocus| > * @return number of trees traversed in the walk when writing the pack . * @since 5 . 4 */ public long getTreesTraversed ( ) { return statistics . treesTraversed ; } /* * * Get total time spent processing this pack . * * @return total time spent processing this pack . */ public long getTimeTotal ( ) { return statistics . timeCounting + statistics . timeSearchingForReuse + statistics . timeSearchingForSizes + statistics . timeCompressing + statistics . timeWriting ; } /* * * Get the average output speed in terms of bytes - per - second . * < |startfocus| > * @return the average output speed in terms of bytes - per - second . * < |endfocus| > */ public long getAverageBytesPerSecond ( ) { return getTotalBytes ( ) / getTimeTotal ( ) ; } /* * * Get the total number of bytes written to the output stream . * * @return total number of bytes written to the output stream . */ public long getTotalBytes ( ) { return statistics . totalBytes ; } /* * * Get the total number of objects written to the output stream . * * @return total number of objects written to the output stream . */ public long getTotalObjects ( ) { return statistics . totalObjects ; } /* * * Get the total number of deltas written to the output stream . * * @return total number of deltas written to the output stream . */ public long getTotalDeltas ( ) { return statistics . totalDeltas ; } /* * * Get the total number of reused objects written to the output stream . * * @return total number of reused objects written to the output stream . */ public long getTotalReused ( ) { return statistics . totalReused ; } /* * * Get the total number of reused deltas written to the output stream . * * @return total number of reused deltas written to the output stream . */ public long getTotalReusedDeltas ( ) { return statistics . totalReusedDeltas ; } /* * * Get the total number of reused objects that were not found in the * local repository . * * @return total number of reused objects that were not found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were not found in the * local repository . * * @return total number of reused deltas that were not found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedIn
",,
1685,"** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2015 , 2019 Obeo . * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . tests . sample . component . service ; import java . util . ArrayList ; import java . util . Collection ; import java . util . HashSet ; import java . util . List ; import java . util . function . Predicate ; import org . eclipse . emf . common . notify . Notification ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . gmf . runtime . notation . DrawerStyle ; import org . eclipse . gmf . runtime . notation . Node ; import org . eclipse . gmf . runtime . notation . NotationPackage ; import org . eclipse . sirius . diagram . DDiagram ; import org . eclipse . sirius . diagram . DDiagramElement ; import org . eclipse . sirius . diagram . DNodeContainer ; import org . eclipse . sirius . diagram . business . api . query . EObjectQuery ; import org . eclipse . sirius . diagram . ui . business . api . view . SiriusGMFHelper ; import org . eclipse . sirius . ext . base . Option ;
","* Copyright ( c ) 2015 , 2019 Obeo .
","* Copyright (c) 2015, 2019 Obeo.
",,,"* Copyright (c) 2015, 2019 Obeo.
",,,"/* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2015 Obeo . * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . tests . sample . component . service ; import java . util . ArrayList ; import java . util . Collection ; import java . util . HashSet ; import java . util . List ; import java . util . function . Predicate ; import org . eclipse . emf . common . notify . Notification ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . gmf . runtime . notation . DrawerStyle ; import org . eclipse . gmf . runtime . notation . Node ; import org . eclipse . gmf . runtime . notation . NotationPackage ; import org . eclipse . sirius . diagram . DDiagram ; import org . eclipse . sirius . diagram . DDiagramElement ; import org . eclipse . sirius . diagram . DNodeContainer ; import org . eclipse . sirius . diagram . business . api . query . EObjectQuery ; import org . eclipse . sirius . diagram . ui . business . api . view . SiriusGMFHelper ; import org . eclipse . sirius . ext . base . Option ; public class ComponentService { public void someMethod ( DDiagram diagram ) { Collection < DNodeContainer > nodeContainers = new ArrayList < > ( ) ; nodeContainers . addAll ( diagram . getContainers ( ) ) ; nodeContainers . addAll ( diagram . getEdges ( ) ) ; List < DNodeContainer > sortedContainers = new ArrayList < > ( nodeContainers ) ; sortedContainers . sort ( ( c1 , c2 ) - > { int c1Depth = new EObjectQuery ( c1 ) . getDepth ( ) ; int c2Depth = new EObjectQuery ( c2 ) . getDepth ( ) ; return c1Depth - c2Depth ; } ) ; for ( DNodeContainer container : sortedContainers ) { Option < Node > gmfNode = SiriusGMFHelper . getGmfNode ( diagram , container ) ; if ( gmfNode . some ( ) ) { Node node = gmfNode . get ( ) ; DrawerStyle drawerStyle = ( DrawerStyle ) node . getStyle ( NotationPackage . eINSTANCE . getDrawerStyle ( ) ) ; if ( drawerStyle != null ) { boolean isCollapsed = drawerStyle . isCollapsed ( ) ; if ( isCollapsed ) { drawerStyle . setCollapsed ( false ) ; node . refresh ( ) ; } } } } } }
",,,"/* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * Copyright ( c ) 2019 Obeo . * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . tests . sample . component . service ; import java . util . ArrayList ; import java . util . Collection ; import java . util . HashSet ; import java . util . List ; import java . util . function . Predicate ; import org . eclipse . emf . common . notify . Notification ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . gmf . runtime . notation . DrawerStyle ; import org . eclipse . gmf . runtime . notation . Node ; import org . eclipse . gmf . runtime . notation . NotationPackage ; import org . eclipse . sirius . diagram . DDiagram ; import org . eclipse . sirius . diagram . DDiagramElement ; import org . eclipse . sirius . diagram . DNodeContainer ; import org . eclipse . sirius . diagram . business . api . query . EObjectQuery ; import org . eclipse . sirius . diagram . ui . business . api . view . SiriusGMFHelper ; import org . eclipse . sirius . ext . base . Option ;
",,,"** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * < |startfocus| > * Copyright ( c ) 2015 Obeo . < |endfocus| > * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . tests . sample . component . service ; import java . util . ArrayList ; import java . util . Collection ; import java . util . HashSet ; import java . util . List ; import java . util . function . Predicate ; import org . eclipse . emf . common . notify . Notification ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . gmf . runtime . notation . DrawerStyle ; import org . eclipse . gmf . runtime . notation . Node ; import org . eclipse . gmf . runtime . notation . NotationPackage ; import org . eclipse . sirius . diagram . DDiagram ; import org . eclipse . sirius . diagram . DDiagramElement ; import org . eclipse . sirius . diagram . DNodeContainer ; import org . eclipse . sirius . diagram . business . api . query . EObjectQuery ; import org . eclipse . sirius . diagram . ui . business . api . view . SiriusGMFHelper ; import org . eclipse . sirius . ext . base . Option ;
",,
1703,"assertNotNull ( obj ) ; assertNotEquals ( fIterator , obj ) ; CtfLocation ctfLocation1 = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; obj . setLocation ( ctfLocation1 ) ; obj . increaseRank ( ) ; assertEquals ( fIterator , obj ) ; } CtfTmfTrace trace = CtfTmfTestTraceUtils . getTrace ( CtfTestTrace . FUNKY_TRACE ) ; assertNotNull ( trace ) ; try ( CtfIterator funky = ( CtfIterator ) trace . createIterator ( ) ) { assertNotEquals ( fIterator , funky ) ; } try ( CtfIterator iter = ( CtfIterator ) fTrace . createIterator ( ) ; ) { CTFTrace otherTrace = new CTFTrace ( fTrace . getPath ( ) ) ; try ( CTFTraceReader tr = new CTFTraceReader ( otherTrace ) ) { assertNotEquals ( iter , tr ) ; } } trace . dispose ( ) ; try ( CtfIterator iter1 = ( CtfIterator ) fTrace . createIterator ( ) ; CtfIterator iter2 = ( CtfIterator ) fTrace . createIterator ( ) ) { assertEquals ( iter1 , iter2 ) ; iter2 . setRank ( 2 ) ; assertNotEquals ( iter1 , iter2 ) ; } } /* * * Run the boolean equals ( Object ) method test . Compare with an empty object . */ @Test public void testEquals_empty ( ) {
","try ( CtfIterator iter = ( CtfIterator ) fTrace . createIterator ( ) ; ) {
","try (CtfIterator iter = (CtfIterator) fTrace.createIterator();) {
",,,"try (CtfIterator iter = (CtfIterator) fTrace.createIterator()) {
",,,"assertNotNull ( obj ) ; assertNotEquals ( fIterator , obj ) ; CtfLocation ctfLocation1 = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; obj . setLocation ( ctfLocation1 ) ; obj . increaseRank ( ) ; assertEquals ( fIterator , obj ) ; CtfTmfTrace trace = CtfTmfTestTraceUtils . getTrace ( CtfTestTrace . FUNKY_TRACE ) ; assertNotNull ( trace ) ; try ( CtfIterator funky = ( CtfIterator ) trace . createIterator ( ) ) { assertNotEquals ( fIterator , funky ) ; } try ( CtfIterator iter = ( CtfIterator ) fTrace . createIterator ( ) ; ) { CTFTrace otherTrace = new CTFTrace ( fTrace . getPath ( ) ) ; try ( CTFTraceReader tr = new CTFTraceReader ( otherTrace ) ) { assertNotEquals ( iter , tr ) ; } } trace . dispose ( ) ; try ( CtfIterator iter1 = ( CtfIterator ) fTrace . createIterator ( ) ; CtfIterator iter2 = ( CtfIterator ) fTrace . createIterator ( ) ) { assertEquals ( iter1 , iter2 ) ; iter2 . setRank ( 2 ) ; assertNotEquals ( iter1 , iter2 ) ; } @Test public void testEquals_empty ( ) {
",,,"assertNotNull ( obj ) ; assertNotEquals ( fIterator , obj ) ; CtfLocation ctfLocation1 = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; obj . setLocation ( ctfLocation1 ) ; obj . increaseRank ( ) ; assertEquals ( fIterator , obj ) ; } CtfTmfTrace trace = CtfTmfTestTraceUtils . getTrace ( CtfTestTrace . FUNKY_TRACE ) ; assertNotNull ( trace ) ; try ( CtfIterator funky = ( CtfIterator ) trace . createIterator ( ) ) { assertNotEquals ( fIterator , funky ) ; } try ( CtfIterator iter = ( CtfIterator ) fTrace . createIterator ( ) ) { CTFTrace otherTrace = new CTFTrace ( fTrace . getPath ( ) ) ; try ( CTFTraceReader tr = new CTFTraceReader ( otherTrace ) ) { assertNotEquals ( iter , tr ) ; } } trace . dispose ( ) ; try ( CtfIterator iter1 = ( CtfIterator ) fTrace . createIterator ( ) ; CtfIterator iter2 = ( CtfIterator ) fTrace . createIterator ( ) ) { assertEquals ( iter1 , iter2 ) ; iter2 . setRank ( 2 ) ; assertNotEquals ( iter1 , iter2 ) ; } /* * * Run the boolean equals ( Object ) method test . Compare with an empty object . */ @Test public void testEquals_empty ( ) {
",,,"assertNotNull ( obj ) ; assertNotEquals ( fIterator , obj ) ; CtfLocation ctfLocation1 = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; obj . setLocation ( ctfLocation1 ) ; obj . increaseRank ( ) ; assertEquals ( fIterator , obj ) ; } CtfTmfTrace trace = CtfTmfTestTraceUtils . getTrace ( CtfTestTrace . FUNKY_TRACE ) ; assertNotNull ( trace ) ; try ( CtfIterator funky = ( CtfIterator ) trace . createIterator ( ) ) { assertNotEquals ( fIterator , funky ) ; } < |startfocus| > try ( CtfIterator iter = ( CtfIterator ) fTrace . createIterator ( ) ; ) { < |endfocus| > CTFTrace otherTrace = new CTFTrace ( fTrace . getPath ( ) ) ; try ( CTFTraceReader tr = new CTFTraceReader ( otherTrace ) ) { assertNotEquals ( iter , tr ) ; } } trace . dispose ( ) ; try ( CtfIterator iter1 = ( CtfIterator ) fTrace . createIterator ( ) ; CtfIterator iter2 = ( CtfIterator ) fTrace . createIterator ( ) ) { assertEquals ( iter1 , iter2 ) ; iter2 . setRank ( 2 ) ; assertNotEquals ( iter1 , iter2 ) ; } } /* * * Run the boolean equals ( Object ) method test . Compare with an empty object . */ @Test public void testEquals_empty ( ) {
",,
1709,"import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameters ; import org . junit . runners . Parameterized . Parameter ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; @RunWith ( Parameterized . class ) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats ; @Parameters ( name = ""core . trustfolderstat = { 0 } "" ) public static Iterable < ? extends Object > data ( ) { return Arrays . asList ( Boolean . TRUE , Boolean . FALSE ) ; } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory ( ) throws Exception { ExecutorService e = Executors . newCachedThreadPool ( ) ; for ( int i = 0 ; i < 100 ; ++ i ) { ObjectDirectory dir = createBareRepository ( ) . getObjectDatabase ( ) ; for ( Future f : e . invokeAll ( blobInsertersForTheSameFanOutDir ( dir ) ) ) { f . get ( ) ; } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime ( ) throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile ( ) ; ObjectDirectory dir = bareRepository . getObjectDatabase ( ) ;
","return Arrays . asList ( Boolean . TRUE , Boolean . FALSE ) ;
","return Arrays.asList(true, false);
",,,"return Arrays.asList(Boolean.TRUE, Boolean.FALSE);
",,,"import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameters ; import org . junit . runners . Parameterized . Parameter ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; import java . util . Arrays ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . Future ; @RunWith ( Parameterized . class ) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public boolean trustFolderStats ; @Parameters ( name = ""core . trustfolderstat = { 0 } "" ) public static Iterable < Object [ ] > data ( ) { return Arrays . asList ( new Object [ ] [ ] { { true } , { false } } ) ; } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory ( ) throws Exception { ExecutorService e = Executors . newCachedThreadPool ( ) ; for ( int i = 0 ; i < 100 ; ++ i ) { ObjectDirectory dir = createBareRepository ( ) . getObjectDatabase ( ) ; for ( Future < ? > f : e . invokeAll ( blobInsertersForTheSameFanOutDir ( dir ) ) ) { f . get ( ) ; } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime ( ) throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile ( ) ; ObjectDirectory dir = bareRepository . getObjectDatabase ( ) ; assertTrue ( dir . hasPackedObjects ( ) ) ; assertFalse ( dir . hasPackedObjects ( ) ) ; } }
",,,"import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameters ; import org . junit . runners . Parameterized . Parameter ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; import java . util . Arrays ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . Future ; @RunWith ( Parameterized . class ) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats ; @Parameters ( name = ""core . trustfolderstat = { 0 } "" ) public static Iterable < ? extends Object > data ( ) { return Arrays . asList ( Boolean . TRUE , Boolean . FALSE ) ; } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory ( ) throws Exception { ExecutorService e = Executors . newCachedThreadPool ( ) ; for ( int i = 0 ; i < 100 ; ++ i ) { ObjectDirectory dir = createBareRepository ( ) . getObjectDatabase ( ) ; for ( Future f : e . invokeAll ( blobInsertersForTheSameFanOutDir ( dir ) ) ) { f . get ( ) ; } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime ( ) throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile ( ) ; ObjectDirectory dir = bareRepository . getObjectDatabase ( ) ; // test code continues . . . } }
",,,"import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameters ; import org . junit . runners . Parameterized . Parameter ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; @RunWith ( Parameterized . class ) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats ; @Parameters ( name = ""core . trustfolderstat = { 0 } "" ) public static Iterable < ? extends Object > data ( ) { < |startfocus| > return Arrays . asList ( Boolean . TRUE , Boolean . FALSE ) ; < |endfocus| > } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory ( ) throws Exception { ExecutorService e = Executors . newCachedThreadPool ( ) ; for ( int i = 0 ; i < 100 ; ++ i ) { ObjectDirectory dir = createBareRepository ( ) . getObjectDatabase ( ) ; for ( Future f : e . invokeAll ( blobInsertersForTheSameFanOutDir ( dir ) ) ) { f . get ( ) ; } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime ( ) throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile ( ) ; ObjectDirectory dir = bareRepository . getObjectDatabase ( ) ;
",,
1717,"block . scope = this . scope ; // ( upper scope ) see Block . resolve ( ) for similar } else { Statement [ ] newArray = new Statement [ l + 1 ] ; System . arraycopy ( block . statements , 0 , newArray , 0 , l ) ; newArray [ l ] = breakStatement ; block . statements = newArray ; } return BREAKING ; } } return FALLTHROUGH ; } protected void completeNormallyCheck ( BlockScope blockScope ) { // do nothing } protected boolean checkNullDefaultFlow ( ) { return true ; } @Override public FlowInfo analyseCode ( BlockScope currentScope , FlowContext flowContext , FlowInfo flowInfo ) { try { flowInfo = this . expression . analyseCode ( currentScope , flowContext , flowInfo ) ; if ( ( this . expression . implicitConversion & TypeIds . UNBOXING ) != 0 || ( this . expression . resolvedType != null && ( this . expression . resolvedType . id == T_JavaLangString || this . expression . resolvedType . isEnum ( ) ) ) ) { this . expression . checkNPE ( currentScope , flowContext , flowInfo , 1 ) ; } SwitchFlowContext switchContext =
","return true ;
","if (!this.switchLabeledRules) { return false; } return true;
",,,"return !this.switchLabeledRules;
",,,"block . scope = this . scope ; if ( l >= block . statements . length ) { Statement [ ] newArray = new Statement [ l + 1 ] ; System . arraycopy ( block . statements , 0 , newArray , 0 , l ) ; newArray [ l ] = breakStatement ; block . statements = newArray ; } else { block . statements [ l ] = breakStatement ; } return BREAKING ; } } return FALLTHROUGH ; } protected void completeNormallyCheck ( BlockScope blockScope ) { // do nothing } protected boolean checkNullDefaultFlow ( ) { return ! this . switchLabeledRules ; } @Override public FlowInfo analyseCode ( BlockScope currentScope , FlowContext flowContext , FlowInfo flowInfo ) { try { flowInfo = this . expression . analyseCode ( currentScope , flowContext , flowInfo ) ; if ( ( this . expression . implicitConversion & TypeIds . UNBOXING ) != 0 || ( this . expression . resolvedType != null && ( this . expression . resolvedType . id == T_JavaLangString || this . expression . resolvedType . isEnum ( ) ) ) ) { this . expression . checkNPE ( currentScope , flowContext , flowInfo , 1 ) ; } SwitchFlowContext switchContext = this . getSwitchFlowContext ( ) ; if ( switchContext != null ) { switchContext . recordExpression ( this . expression , flowInfo ) ; } return flowInfo ; } catch ( AbortMethod e ) { this . scope . problemReporter ( ) . abortDueToInternalError ( e ) ; return FlowInfo . DEAD_END ; } }
",,,"private boolean checkNullDefaultFlow ( ) { return ! this . switchLabeledRules ; } @Override public FlowInfo analyseCode ( BlockScope currentScope , FlowContext flowContext , FlowInfo flowInfo ) { try { flowInfo = this . expression . analyseCode ( currentScope , flowContext , flowInfo ) ; if ( ( this . expression . implicitConversion & TypeIds . UNBOXING ) != 0 || ( this . expression . resolvedType != null && ( this . expression . resolvedType . id == T_JavaLangString || this . expression . resolvedType . isEnum ( ) ) ) ) { this . expression . checkNPE ( currentScope , flowContext , flowInfo , 1 ) ; } SwitchFlowContext switchContext = ( SwitchFlowContext ) flowContext ; if ( this . expression . resolvedType != null && this . expression . resolvedType . isBaseType ( ) ) { flowInfo = flowInfo . mergedWith ( switchContext . initsOnBreak ) ; } if ( this . expression . constant != Constant . NotAConstant ) { flowInfo = flowInfo . mergedWith ( switchContext . initsOnBreak ) ; } if ( this . expression . resolvedType != null && this . expression . resolvedType . isEnum ( ) ) { flowInfo = flowInfo . mergedWith ( switchContext . initsOnBreak ) ; } if ( this . expression . resolvedType != null && this . expression . resolvedType . isEnum ( ) ) { flowInfo = flowInfo . mergedWith ( switchContext . initsOnBreak ) ; } if ( this . expression . resolvedType != null && this . expression . resolvedType . isEnum ( ) ) { flowInfo = flowInfo . mergedWith ( switchContext . initsOnBreak ) ; } if ( this . expression . resolvedType != null && this . expression . resolvedType . isEnum ( ) ) { flowInfo = flowInfo . mergedWith ( switchContext . initsOnBreak ) ; } if ( this . expression . resolvedType != null && this . expression . resolvedType . isEnum ( ) ) { flowInfo = flowInfo . mergedWith ( switchContext . initsOnBreak ) ; } if ( this . expression . resolvedType != null && this . expression . resolvedType . isEnum ( ) ) { flowInfo = flowInfo . mergedWith ( switchContext . initsOnBreak ) ; } if ( this . expression . resolvedType != null && this . expression . resolvedType . isEnum ( ) ) { flowInfo = flowInfo . mergedWith ( switchContext . initsOnBreak ) ; } if ( this . expression . res
",,,"block . scope = this . scope ; // ( upper scope ) see Block . resolve ( ) for similar } else { Statement [ ] newArray = new Statement [ l + 1 ] ; System . arraycopy ( block . statements , 0 , newArray , 0 , l ) ; newArray [ l ] = breakStatement ; block . statements = newArray ; } return BREAKING ; } } return FALLTHROUGH ; } protected void completeNormallyCheck ( BlockScope blockScope ) { // do nothing } protected boolean checkNullDefaultFlow ( ) { < |startfocus| > return ! this . switchLabeledRules ; < |endfocus| > } @Override public FlowInfo analyseCode ( BlockScope currentScope , FlowContext flowContext , FlowInfo flowInfo ) { try { flowInfo = this . expression . analyseCode ( currentScope , flowContext , flowInfo ) ; if ( ( this . expression . implicitConversion & TypeIds . UNBOXING ) != 0 || ( this . expression . resolvedType != null && ( this . expression . resolvedType . id == T_JavaLangString || this . expression . resolvedType . isEnum ( ) ) ) ) { this . expression . checkNPE ( currentScope , flowContext , flowInfo , 1 ) ; } SwitchFlowContext switchContext = new SwitchFlowContext ( flowContext , this , this . expression . nullStatus ( flowInfo ) , this . expression . resolvedType ) ;
",,
1722,"* * @author Matthew Khouzam * */ abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute ( ExecutionEvent event ) throws ExecutionException { // Check if we are closing down IWorkbenchWindow window = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) ; if ( window == null ) { return null ; } IWorkbenchPart part = HandlerUtil . getActivePart ( event ) ; if ( part instanceof TmfView ) { execute ( ( TmfView ) part ) ; } return null ; } public abstract void execute ( TmfView view ) ; }
","public abstract void execute ( TmfView view ) ;
","<|del|>
",,,"public abstract void execute(TmfView view);
",,,"abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute ( ExecutionEvent event ) throws ExecutionException { IWorkbenchWindow window = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) ; if ( window == null ) { return null ; } IWorkbenchPart part = HandlerUtil . getActivePart ( event ) ; if ( part instanceof TmfView ) { execute ( ( TmfView ) part ) ; } return null ; } public abstract void execute ( TmfView view ) ; }
",,,"abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute ( ExecutionEvent event ) throws ExecutionException { IWorkbenchWindow window = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) ; if ( window == null ) { return null ; } IWorkbenchPart part = HandlerUtil . getActivePart ( event ) ; if ( part instanceof TmfView ) { execute ( ( TmfView ) part ) ; } return null ; } public abstract void execute ( TmfView view ) ; }
",,,"* * @author Matthew Khouzam * */ abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute ( ExecutionEvent event ) throws ExecutionException { // Check if we are closing down IWorkbenchWindow window = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) ; if ( window == null ) { return null ; } IWorkbenchPart part = HandlerUtil . getActivePart ( event ) ; if ( part instanceof TmfView ) { execute ( ( TmfView ) part ) ; } return null ; } < |startfocus| > public abstract void execute ( TmfView view ) ; < |endfocus| > }
",,
1725,"} /* * * Run the void setRank ( ) method test . */ @Test public void testSetRank ( ) { long rank = fIterator . getRank ( ) ; fIterator . increaseRank ( ) ; assertEquals ( rank + 1 , fIterator . getRank ( ) ) ; fIterator . setRank ( rank ) ; assertEquals ( rank , fIterator . getRank ( ) ) ; } /* * * Run the boolean seek ( long ) method test . */ @Test public void testSeek ( ) { // Trace 2 has duplicate time stamps CtfTmfTrace trace = CtfTmfTestTraceUtils . getTrace ( CtfTestTrace . TRACE2 ) ; try ( CtfIterator iterator = ( CtfIterator ) trace . createIterator ( ) ) { assertTrue ( iterator . seek ( 1L ) ) ; CtfTmfEvent event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247314038062L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247314038062L , iterator . getCurrentTimestamp ( ) ) ; assertFalse ( iterator . seek ( Long . MAX_VALUE ) ) ; assertNull ( getCurrentEvent ( iterator ) ) ; assertEquals ( 0L , iterator . getCurrentTimestamp ( ) ) ; assertFalse ( iterator . advance ( ) ) ; // seek to a time after trace start .
","// Trace 2 has duplicate time stamps
","// good old trace 2. You may just be perfect!
",,,"<|del|>
",,,"@Test public void testSetRank ( ) { long rank = fIterator . getRank ( ) ; fIterator . increaseRank ( ) ; assertEquals ( rank + 1 , fIterator . getRank ( ) ) ; fIterator . setRank ( rank ) ; assertEquals ( rank , fIterator . getRank ( ) ) ; } @Test public void testSeek ( ) { CtfTmfTrace trace = CtfTmfTestTraceUtils . getTrace ( CtfTestTrace . TRACE2 ) ; try ( CtfIterator iterator = ( CtfIterator ) trace . createIterator ( ) ) { assertTrue ( iterator . seek ( 1L ) ) ; CtfTmfEvent event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247314038062L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247314038062L , iterator . getCurrentTimestamp ( ) ) ; assertFalse ( iterator . seek ( Long . MAX_VALUE ) ) ; assertNull ( getCurrentEvent ( iterator ) ) ; assertEquals ( 0L , iterator . getCurrentTimestamp ( ) ) ; assertFalse ( iterator . advance ( ) ) ; } }
",,,"import org . eclipse . egerrit . core . rest . CommentRange ; import com . google . gwtorm . client . Column ; public class CommentRange { @Column ( id = 1 ) protected int startLine ; @Column ( id = 2 ) protected int startCharacter ; @Column ( id = 3 ) protected int endLine ; @Column ( id = 4 ) protected int endCharacter ; public CommentRange ( ) { } public CommentRange ( int sl , int sc , int el , int ec ) { startLine = sl ; startCharacter = sc ; endLine = el ; endCharacter = ec ; } public int getStartLine ( ) { return startLine ; } public int getStartCharacter ( ) { return startCharacter ; } public int getEndLine ( ) { return endLine ; } public int getEndCharacter ( ) { return endCharacter ; } public void setStartLine ( int sl ) { startLine = sl ; } public void setStartCharacter ( int sc ) { startCharacter = sc ; } public void setEndLine ( int el ) { endLine = el ; } public void setEndCharacter ( int ec ) { endCharacter = ec ; } }
",,,"} /* * * Run the void setRank ( ) method test . */ @Test public void testSetRank ( ) { long rank = fIterator . getRank ( ) ; fIterator . increaseRank ( ) ; assertEquals ( rank + 1 , fIterator . getRank ( ) ) ; fIterator . setRank ( rank ) ; assertEquals ( rank , fIterator . getRank ( ) ) ; } /* * * Run the boolean seek ( long ) method test . */ @Test public void testSeek ( ) { < |startfocus| > // Good old trace 2 . You may just be perfect ! < |endfocus| > CtfTmfTrace trace = CtfTmfTestTraceUtils . getTrace ( CtfTestTrace . TRACE2 ) ; try ( CtfIterator iterator = ( CtfIterator ) trace . createIterator ( ) ) { assertTrue ( iterator . seek ( 1L ) ) ; CtfTmfEvent event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247314038062L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247314038062L , iterator . getCurrentTimestamp ( ) ) ; assertFalse ( iterator . seek ( Long . MAX_VALUE ) ) ; assertNull ( getCurrentEvent ( iterator ) ) ; assertEquals ( 0L , iterator . getCurrentTimestamp ( ) ) ; assertFalse ( iterator . advance ( ) ) ; // seek to a time after trace start .
",,
1728,"CtfLocationInfo duplicateLocationOutOfBounds = new CtfLocationInfo ( 1331668247328921944L , 4L ) ; assertTrue ( iterator . seek ( duplicateLocationOutOfBounds ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( ""sys_poll"" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; CtfLocationInfo duplicateLocationIndexHuge = new CtfLocationInfo ( 1331668247328921944L , 9001000000L ) ; assertTrue ( iterator . seek ( duplicateLocationIndexHuge ) ) ; event = iterator . getCurrentEvent ( ) ; assertNotNull ( event ) ; assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( ""sys_poll"" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; assertFalse ( iterator . seek ( CtfLocation . INVALID_LOCATION ) ) ; // last valid seek location assertEquals ( event , getCurrentEvent ( iterator ) ) ; } trace . dispose ( ) ; }
","CtfLocationInfo duplicateLocationIndexHuge = new CtfLocationInfo ( 1331668247328921944L , 9001000000L ) ; assertTrue ( iterator . seek ( duplicateLocationIndexHuge ) ) ; event = iterator . getCurrentEvent ( ) ;
","CtfLocationInfo duplicateLocationIndexedOver9000 = new CtfLocationInfo(1331668ien328921944L, 9000L); assertTrue(iterator.seek(duplicateLocationIndexedOver9000)); event = getCurrentEvent(iterator);
",,,"CtfLocationInfo duplicateLocationIndexedOver9000 = new CtfLocationInfo(1331668247328921944L, 9000L); assertTrue(iterator.seek(duplicateLocationIndexedOver9000)); event = getCurrentEvent(iterator);
",,,"CtfLocationInfo duplicateLocationOutOfBounds = new CtfLocationInfo ( 1331668247328921944L , 4L ) ; assertTrue ( iterator . seek ( duplicateLocationOutOfBounds ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( ""sys_poll"" , event . getName ( ) ) ; CtfLocationInfo duplicateLocationIndexed = new CtfLocationInfo ( 1331668247328921944L , 9001000000L ) ; assertTrue ( iterator . seek ( duplicateLocationIndexed ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( ""sys_poll"" , event . getName ( ) ) ; assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; assertFalse ( iterator . seek ( CtfLocation . INVALID_LOCATION ) ) ; assertEquals ( event , getCurrentEvent ( iterator ) ) ; trace . dispose ( ) ;
",,,"Rectangle getBoundsInPixels ( ) { computeRuns ( null ) ; int width = 0 ; if ( wrapWidth != - 1 ) { width = wrapWidth ; } else { for ( int line = 0 ; line < runs . length ; line ++ ) { width = Math . max ( width , lineWidth [ line ] + getLineIndent ( line ) ) ; } } return new Rectangle ( 0 , 0 , width , lineY [ lineY . length - 1 ] ) ; } package com . google . gerrit . server . query . change ; import com . google . gerrit . reviewdb . client . Change ; import com . google . gerrit . server . index . ChangeField ; import com . google . gerrit . server . index . IndexPredicate ; import com . google . gwtorm . server . OrmException ; public class DependsOnPredicate extends IndexPredicate < ChangeData > { DependsOnPredicate ( String prefix ) { super ( ChangeField . DEPENDS_ON , prefix ) ; } @Override public boolean match ( ChangeData object ) throws OrmException { Change c = object . change ( ) ; try { for ( FooterLine f : c . commitFooters ( ) ) { if ( f . getKey ( ) . equals ( ) ) { return f . getValue ( ) ; } } } catch ( NoSuchChangeException | IOException e ) { } return null ; } @Override public int getCost ( ) { return 1 ; } } } progress . endTask ( ) ; return new SiteIndexer . Result ( sw , ok . get ( ) , done . get ( ) , failed . get ( ) ) ; } private List < Project . NameKey > collectProjects ( ProgressMonitor progress ) throws OrmException { progress . beginTask ( ""Collecting projects"" , ProgressMonitor . UNKNOWN ) ; List < Project . NameKey > names = new ArrayList < > ( ) ; for ( Project . NameKey nameKey : projectCache . all ( ) ) { names . add ( nameKey ) ; } progress . endTask ( ) ; return names ; } CtfLocationInfo duplicateLocationOutOfBounds = new CtfLocationInfo ( 1331668247328921944L , 4L ) ; assertTrue ( iterator . seek ( duplicateLocationOutOfBounds ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( ""sys_poll"" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; Ctf
",,,"CtfLocationInfo duplicateLocationOutOfBounds = new CtfLocationInfo ( 1331668247328921944L , 4L ) ; assertTrue ( iterator . seek ( duplicateLocationOutOfBounds ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( ""sys_poll"" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; < |startfocus| > CtfLocationInfo duplicateLocationIndexedOver9000 = new CtfLocationInfo ( 1331668247328921944L , 9001000000L ) ; assertTrue ( iterator . seek ( duplicateLocationIndexedOver9000 ) ) ; event = getCurrentEvent ( iterator ) ; < |endfocus| > assertNotNull ( event ) ; assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( ""sys_poll"" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; assertFalse ( iterator . seek ( CtfLocation . INVALID_LOCATION ) ) ; // last valid seek location assertEquals ( event , getCurrentEvent ( iterator ) ) ; } trace . dispose ( ) ; }
",,
1729,"assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( ""sys_poll"" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; assertFalse ( iterator . seek ( CtfLocation . INVALID_LOCATION ) ) ; // last valid seek location assertEquals ( event , getCurrentEvent ( iterator ) ) ; } trace . dispose ( ) ; } /* * * Run the void setLocation ( ITmfLocation < ? > ) method test . */ @Test public void testSetLocation ( ) { CtfLocation location = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; fIterator . setLocation ( location ) ; } }
","< |del| > private static CtfTmfEvent getCurrentEvent ( CtfIterator iterator ) { return iterator . getCurrentEvent ( ) ; } private static long getTimestampInNanos ( CtfTmfEvent event ) { return event . getTimestamp ( ) . toNanos ( ) ; }
","<|del|>
",,,"<|del|>
",,,"private static CtfTmfEvent getCurrentEvent ( CtfIterator iterator ) { return iterator . getCurrentEvent ( ) ; } private static long getTimestampInNanos ( CtfTmfEvent event ) { return event . getTimestamp ( ) . toNanos ( ) ; } @Test public void testSetLocation ( ) { CtfLocation location = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; fIterator . setLocation ( location ) ; }
",,,"import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertFalse ; import org . eclipse . tracecompass . ctf . core . event . CtfTmfEvent ; import org . eclipse . tracecompass . ctf . core . iterator . CtfIterator ; import org . eclipse . tracecompass . ctf . core . trace . CtfLocation ; import org . eclipse . tracecompass . ctf . core . trace . CtfLocationInfo ; import org . eclipse . tracecompass . ctf . core . trace . CtfLocation . INVALID_LOCATION ; import org . eclipse . tracecompass . ctf . core . trace . CtfTmfTrace ; import org . junit . After ; import org . junit . Before ; import org . junit . Test ; public class CtfIteratorTest { private CtfIterator fIterator ; private CtfTmfTrace fTrace ; @Before public void setUp ( ) throws Exception { fTrace = new CtfTmfTrace ( ) ; fIterator = new CtfIterator ( fTrace ) ; } @After public void tearDown ( ) throws Exception { fIterator . dispose ( ) ; fTrace . dispose ( ) ; } @Test public void testGetCurrentEvent ( ) { CtfTmfEvent event = new CtfTmfEvent ( ) ; fIterator . setCurrentEvent ( event ) ; assertEquals ( event , fIterator . getCurrentEvent ( ) ) ; } @Test public void testGetTimestampInNanos ( ) { CtfTmfEvent event = new CtfTmfEvent ( ) ; event . setTimestamp ( 1331668247328925363L ) ; assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; } @Test public void testSetLocation ( ) { CtfLocation location = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; fIterator . setLocation ( location ) ; } private static long getTimestampInNanos ( CtfTmfEvent event ) { return event . getTimestamp ( ) . toNanos ( ) ; } }
",,,"assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( ""sys_poll"" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; assertFalse ( iterator . seek ( CtfLocation . INVALID_LOCATION ) ) ; // last valid seek location assertEquals ( event , getCurrentEvent ( iterator ) ) ; } trace . dispose ( ) ; } < |startfocus| > private static CtfTmfEvent getCurrentEvent ( CtfIterator iterator ) { return iterator . getCurrentEvent ( ) ; } private static long getTimestampInNanos ( CtfTmfEvent event ) { return event . getTimestamp ( ) . toNanos ( ) ; } < |endfocus| > /* * * Run the void setLocation ( ITmfLocation < ? > ) method test . */ @Test public void testSetLocation ( ) { CtfLocation location = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; fIterator . setLocation ( location ) ; } }
",,
1736,"} @Override protected void tearDown ( ) throws Exception { assertEquals ( ""Test triggered errors . "" , 0 , loggedErrors . get ( ) ) ; Platform . removeLogListener ( errorLogListener ) ; super . tearDown ( ) ; } /* * * Test if two byte UTF - 8 characters get disrupted on there way from process * console to the runtime process . * < p > * This test starts every two byte character on an even byte offset . * </ p > */ public void testUTF8InputEven ( ) throws Exception { // 5000 characters result in 10000 bytes which should be more than most // common buffer sizes . processConsoleUTF8Input ( """" , 5000 ) ; } /* * * Test if two byte UTF - 8 characters get disrupted on there way from process * console to the runtime process . * < p > * This test starts every two byte character on an odd byte offset . * </ p > * * @throws Exception if the test gets in trouble
","< |del| >* * @throws Exception if the test gets in trouble
","<|del|>
",,,"<|del|>
",,,"@Override protected void tearDown ( ) throws Exception { assertEquals ( 0 , loggedErrors . get ( ) ) ; Platform . removeLogListener ( errorLogListener ) ; super . tearDown ( ) ; } public void testUTF8InputEven ( ) throws Exception { processConsoleUTF8Input ( """" , 5000 ) ; } public void testUTF8InputOdd ( ) throws Exception { processConsoleUTF8Input ( """" , 5001 ) ; }
",,,"@Override protected void tearDown ( ) throws Exception { assertEquals ( ""Test triggered errors . "" , 0 , loggedErrors . get ( ) ) ; Platform . removeLogListener ( errorLogListener ) ; super . tearDown ( ) ; } public void testUTF8InputEven ( ) throws Exception { processConsoleUTF8Input ( """" , 5000 ) ; } public void testUTF8InputOdd ( ) throws Exception { processConsoleUTF8Input ( """" , 5001 ) ; }
",,,"} @Override protected void tearDown ( ) throws Exception { assertEquals ( ""Test triggered errors . "" , 0 , loggedErrors . get ( ) ) ; Platform . removeLogListener ( errorLogListener ) ; super . tearDown ( ) ; } /* * * Test if two byte UTF - 8 characters get disrupted on there way from process * console to the runtime process . * < p > * This test starts every two byte character on an even byte offset . * </ p > < |startfocus| > * * @throws Exception if the test gets in trouble < |endfocus| > */ public void testUTF8InputEven ( ) throws Exception { // 5000 characters result in 10000 bytes which should be more than most // common buffer sizes . processConsoleUTF8Input ( """" , 5000 ) ; } /* * * Test if two byte UTF - 8 characters get disrupted on there way from process * console to the runtime process . * < p > * This test starts every two byte character on an odd byte offset . * </ p > * * @throws Exception if the test gets in trouble
",,
1744,"* < li > { @link #clear ( ) } </ li > * < li > { @link #iterator ( ) } </ li > * < li > { @link #isEmpty ( ) } </ li > * < li > { @link #toArray ( ) } </ li > * < li > { @link #toArray ( Object [ ] ) } </ li > * < li > { @link #set ( int , Object ) } </ li > * < li > { @link #lastIndexOf ( Object ) } </ li > * </ ul > * * TODO : Keep an eye out for a better datastructure . . . this is fine , but if it * can be replaced by an externally maintained datastructure , that would be * better . * * @author Matthew Khouzam * @param < E > * the element type */ public class SparseList < E > implements List < E > { private final Map < Integer , E > fInnerEvents = new HashMap < > ( ) ; private int fSize = 0 ; /* * * Copy constructor * * @param events * list of events */ public SparseList ( List < E > events ) { ensureSize ( events . size ( ) ) ; for ( int i = 0 ; i < events . size ( ) ; i ++ ) { E element = events . get ( i ) ;
","* TODO : Keep an eye out for a better datastructure . . . this is fine , but if it * can be replaced by an externally maintained datastructure , that would be * better .
","<|del|>
",,,"<|del|>
",,,"public class SparseList < E > implements List < E > { private final Map < Integer , E > fInnerEvents = new HashMap < > ( ) ; private int fSize = 0 ; public SparseList ( List < E > events ) { ensureSize ( events . size ( ) ) ; for ( int i = 0 ; i < events . size ( ) ; i ++ ) { E element = events . get ( i ) ; if ( element != null ) { fInnerEvents . put ( i , element ) ; } } } private void ensureSize ( int size ) { if ( size > fSize ) { fSize = size ; } } @Override public int size ( ) { return fSize ; } @Override public boolean isEmpty ( ) { return fInnerEvents . isEmpty ( ) ; } @Override public boolean contains ( Object o ) { return fInnerEvents . containsValue ( o ) ; } @Override public Iterator < E > iterator ( ) { return fInnerEvents . values ( ) . iterator ( ) ; } @Override public Object [ ] toArray ( ) { return fInnerEvents . values ( ) . toArray ( ) ; } @Override public < T > T [ ] toArray ( T [ ] a ) { return fInnerEvents . values ( ) . toArray ( a ) ; } @Override public boolean add ( E e ) { throw new UnsupportedOperationException ( ) ; } @Override public boolean remove ( Object o ) { throw new UnsupportedOperationException ( ) ; } @Override public boolean containsAll ( Collection < ? > c ) { return fInnerEvents . values ( ) . containsAll ( c ) ; } @Override public boolean addAll ( Collection < ? extends E > c ) { throw new UnsupportedOperationException ( ) ; } @Override public boolean addAll ( int index , Collection < ? extends E > c ) { throw new UnsupportedOperationException ( ) ; } @Override public boolean removeAll ( Collection < ? > c ) { throw new UnsupportedOperationException ( ) ; } @Override public boolean retainAll ( Collection < ? > c ) { throw new UnsupportedOperationException ( ) ; } @Override public void clear ( ) { fInnerEvents . clear ( ) ; } @Override public E get ( int index ) { return fInnerEvents . get ( index ) ; } @Override public E set ( int index , E element ) { if ( element == null ) { return fInnerEvents . remove ( index ) ; } ensureSize ( index + 1 ) ; return
",,,"public class SparseList < E > implements List < E > { private final Map < Integer , E > fInnerEvents = new HashMap < > ( ) ; private int fSize = 0 ; public SparseList ( List < E > events ) { ensureSize ( events . size ( ) ) ; for ( int i = 0 ; i < events . size ( ) ; i ++ ) { E element = events . get ( i ) ; fInnerEvents . put ( i , element ) ; } } // other methods . . . }
",,,"* < li > { @link #clear ( ) } </ li > * < li > { @link #iterator ( ) } </ li > * < li > { @link #isEmpty ( ) } </ li > * < li > { @link #toArray ( ) } </ li > * < li > { @link #toArray ( Object [ ] ) } </ li > * < li > { @link #set ( int , Object ) } </ li > * < li > { @link #lastIndexOf ( Object ) } </ li > * </ ul > * < |startfocus| > * TODO : remove when a public ( open source ) sparselist is available . < |endfocus| > * * @author Matthew Khouzam * @param < E > * the element type */ public class SparseList < E > implements List < E > { private final Map < Integer , E > fInnerEvents = new HashMap < > ( ) ; private int fSize = 0 ; /* * * Copy constructor * * @param events * list of events */ public SparseList ( List < E > events ) { ensureSize ( events . size ( ) ) ; for ( int i = 0 ; i < events . size ( ) ; i ++ ) { E element = events . get ( i ) ;
",,
1746,"public boolean contains ( Object o ) { return fInnerElements . containsValue ( o ) ;
","return fInnerElements . containsValue ( o ) ;
","return !fInnerEvents.containsValue(o);
",,,"if (fInnerEvents != null) { return fInnerEvents.containsValue(o); } return false;
",,,"public boolean contains ( Object o ) { if ( o == null ) { for ( Object obj : fInnerEvents . values ( ) ) { if ( obj == null ) { return true ; } } } else { return fInnerEvents . containsValue ( o ) ; } return false ; }
",,,"public boolean contains ( Object o ) { return fInnerEvents . containsValue ( o ) ; }
",,,"public boolean contains ( Object o ) { < |startfocus| > return fInnerEvents . containsValue ( o ) ; < |endfocus| > }
",,
1761,"public boolean isNoexcept ( boolean inCalledContext ) { assert false ; // Shouldn't exist outside of a dependent context return true ;
","assert false ; // Shouldn't exist outside of a dependent context
","<|del|>
",,,"// TODO(kudu-merge): this assert is hit
",,,"public boolean isNoexcept ( boolean inCalledContext ) { // assert false ; }
",,,"public boolean isNoexcept ( boolean inCalledContext ) { return true ; }
",,,"public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > // assert false ; // TODO this assert is hit < |endfocus| > return true ; }
",,
1772,"public boolean contains ( Object o ) { return ( o == null && size ( ) > fInnerElements . size ( ) ) || fInnerElements . containsValue ( o ) ;
","return ( o == null && size ( ) > fInnerElements . size ( ) ) || fInnerElements . containsValue ( o ) ;
","return fInnerElements != null && fInnerElements.containsValue(o);
",,,"return fInnerElements != null && fInnerElements.containsValue(o);
",,,"public boolean contains ( Object o ) { if ( o == null ) { return fInnerElements . size ( ) != 0 ; } return fInnerElements . containsValue ( o ) ; }
",,,"public boolean contains ( Object o ) { return fInnerElements . containsValue ( o ) ; }
",,,"public boolean contains ( Object o ) { < |startfocus| > return fInnerElements . containsValue ( o ) ; < |endfocus| > }
",,
1775,"public int lastIndexOf ( Object o ) { int last = - 1 ; if ( o == null && contains ( null ) ) { for ( int i = size ( ) - 1 ; i >= 0 ; i -- ) { if ( ! fInnerElements . containsKey ( i ) ) { return i ; } } } for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( Objects . equals ( entry . getValue ( ) , o ) ) { last = Math . max ( last , entry . getKey ( ) ) ; } } return last ;
","int last = - 1 ; if ( o == null && contains ( null ) ) { for ( int i = size ( ) - 1 ; i >= 0 ; i -- ) { if ( ! fInnerElements . containsKey ( i ) ) { return i ; } } }
","int last = -1;
",,,"<|del|>
",,,"public int lastIndexOf ( Object o ) { int last = - 1 ; if ( o == null ) { for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( entry . getValue ( ) == null ) { last = Math . max ( last , entry . getKey ( ) ) ; } } } else { for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( o . equals ( entry . getValue ( ) ) ) { last = Math . max ( last , entry . getKey ( ) ) ; } } } return last ; }
",,,"public int lastIndexOf ( Object o ) { int last = - 1 ; for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( Objects . equals ( entry . getValue ( ) , o ) ) { last = Math . max ( last , entry . getKey ( ) ) ; } } return last ; }
",,,"public int lastIndexOf ( Object o ) { < |startfocus| > int last = - 1 ; < |endfocus| > for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( entry . getValue ( ) == null ? o == null : entry . getValue ( ) . equals ( o ) ) { last = Math . max ( last , entry . getKey ( ) ) ; } } return last ;
",,
1784,"public boolean hasNext ( ) { return nextIndex ( ) < fList . size ( ) ;
","return nextIndex ( ) < fList . size ( ) ;
","return fCursor.getLocation() < fEnd;
",,,"return nextIndex() < fEnd + 1;
",,,"public boolean hasNext ( ) { return fCursor < fList . size ( ) ; }
",,,"public boolean hasNext ( ) { return fCursor < fEnd ; }
",,,"public boolean hasNext ( ) { < |startfocus| > return fCursor < fEnd ; < |endfocus| >
",,
1788,"public int indexOf ( Object o ) { if ( o == null && contains ( null ) ) { for ( int i = 0 ; i < size ( ) ; i ++ ) { if ( ! fInnerElements . containsKey ( i ) ) { return i ; } } } for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( Objects . equals ( entry . getValue ( ) , o ) ) { first = Math . min ( entry . getKey ( ) , first ) ; } } return - 1 ;
","first = Math . min ( entry . getKey ( ) , first ) ;
","return entry.getKey().indexOf(Objects.lastIndexOf(entry.getKey()));
",,,"return entry.getKey();
",,,"public int indexOf ( Object o ) { for ( int i = size ( ) - 1 ; i >= 0 ; i -- ) { if ( ! fInnerElements . containsKey ( i ) ) { continue ; } E element = fInnerElements . get ( i ) ; if ( Objects . equals ( element , o ) ) { return i ; } } if ( o == null && contains ( null ) ) { return 0 ; } return - 1 ; }
",,,"public int indexOf ( Object o ) { if ( o == null && contains ( null ) ) { for ( int i = 0 ; i < size ( ) ; i ++ ) { if ( ! fInnerElements . containsKey ( i ) ) { return i ; } } } for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( Objects . equals ( entry . getValue ( ) , o ) ) { return entry . getKey ( ) ; } } return - 1 ; }
",,,"public int indexOf ( Object o ) { if ( o == null && contains ( null ) ) { for ( int i = 0 ; i < size ( ) ; i ++ ) { if ( ! fInnerElements . containsKey ( i ) ) { return i ; } } } for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( Objects . equals ( entry . getValue ( ) , o ) ) { < |startfocus| > return entry . getKey ( ) ; < |endfocus| > } } return - 1 ;
",,
1794,"public boolean addAll ( int index , Collection < ? extends E > c ) { throw new UnsupportedOperationException ( ""No addAll ( int , Collection < ? extends E > ) in "" + this . getClass ( ) . getName ( ) ) ; // $NON - NLS - 1$
","throw new UnsupportedOperationException ( ""No addAll ( int , Collection < ? extends E > ) in "" + this . getClass ( ) . getName ( ) ) ; // $NON - NLS - 1$
","throw new UnsupportedOperationException(""No addAll(index) in "" + this.getClass().getName()); //$NON-NLS-1$
",,,"throw new UnsupportedOperationException(""No addAll(int, Collection) in "" + this.getClass().getName()); //$NON-NLS-1$
",,,"public boolean addAll ( int index , Collection < ? extends E > c ) { throw new UnsupportedOperationException ( ""No addAll ( index ) in "" + this . getClass ( ) . getName ( ) ) ; }
",,,"public boolean addAll ( int index , Collection < ? extends E > c ) { throw new UnsupportedOperationException ( ""No addAll ( index ) in "" + this . getClass ( ) . getName ( ) ) ; // $NON - NLS - 1$ }
",,,"public boolean addAll ( int index , Collection < ? extends E > c ) { < |startfocus| > throw new UnsupportedOperationException ( ""No addAll ( index ) in "" + this . getClass ( ) . getName ( ) ) ; // $NON - NLS - 1$ < |endfocus| >
",,
1802,"if ( mapping == null ) continue ; ResourceTraversal [ ] traversals = null ; try { traversals = mapping . getTraversals ( ResourceMappingContext . LOCAL_CONTEXT , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { StatusManager . getManager ( ) . handle ( e , IDEWorkbenchPlugin . IDE_WORKBENCH ) ; } if ( traversals != null ) { IResource [ ] resources = null ; for ( ResourceTraversal traversal : traversals ) { resources = traversal . getResources ( ) ; if ( resources != null ) { result . addAll ( Arrays . asList ( resources ) ) ; } } } } else result . add ( resource ) ; } // all that can be converted are done , answer new selection if ( result . isEmpty ( ) ) { return StructuredSelection . EMPTY ; } return new StructuredSelection ( result . toArray ( ) ) ;
","result . addAll ( Arrays . asList ( resources ) ) ;
","result.addAll(Arrays.asList(resources));
",,,"result.addAll(Arrays.asList(resources));
",,,"if ( mapping == null ) { continue ; } ResourceTraversal [ ] traversals = null ; try { traversals = mapping . getTraversals ( ResourceMappingContext . LOCAL_CONTEXT , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { StatusManager . getManager ( ) . handle ( e , IDEWorkbenchPlugin . IDE_WORKBENCH ) ; } if ( traversals != null ) { List < IResource > result = new ArrayList < > ( ) ; for ( ResourceTraversal traversal : traversals ) { IResource [ ] resources = traversal . getResources ( ) ; if ( resources != null ) { result . addAll ( Arrays . asList ( resources ) ) ; } } if ( ! result . isEmpty ( ) ) { return new StructuredSelection ( result . toArray ( ) ) ; } } return StructuredSelection . EMPTY ;
",,,"if ( mapping == null ) continue ; ResourceTraversal [ ] traversals = null ; try { traversals = mapping . getTraversals ( ResourceMappingContext . LOCAL_CONTEXT , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { StatusManager . getManager ( ) . handle ( e , IDEWorkbenchPlugin . IDE_WORKBENCH ) ; } if ( traversals != null ) { IResource [ ] resources = null ; for ( ResourceTraversal traversal : traversals ) { resources = traversal . getResources ( ) ; if ( resources != null ) { result . addAll ( Arrays . asList ( resources ) ) ; } } } else { result . add ( resource ) ; } // all that can be converted are done , answer new selection if ( result . isEmpty ( ) ) { return StructuredSelection . EMPTY ; } return new StructuredSelection ( result . toArray ( ) ) ;
",,,"if ( mapping == null ) continue ; ResourceTraversal [ ] traversals = null ; try { traversals = mapping . getTraversals ( ResourceMappingContext . LOCAL_CONTEXT , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { StatusManager . getManager ( ) . handle ( e , IDEWorkbenchPlugin . IDE_WORKBENCH ) ; } if ( traversals != null ) { IResource [ ] resources = null ; for ( ResourceTraversal traversal : traversals ) { resources = traversal . getResources ( ) ; if ( resources != null ) { < |startfocus| > result . addAll ( Arrays . asList ( resources ) ) ; < |endfocus| > } } } } else result . add ( resource ) ; } // all that can be converted are done , answer new selection if ( result . isEmpty ( ) ) { return StructuredSelection . EMPTY ; } return new StructuredSelection ( result . toArray ( ) ) ;
",,
1806,"public void addEvent ( ITimeEvent event ) { if ( ! ( event instanceof TimeLineEvent ) ) { throw new IllegalArgumentException ( ""Needs to be a TimeLineEvent"" ) ; // $NON - NLS - 1$ } super . addEvent ( event ) ;
","throw new IllegalArgumentException ( ""Needs to be a TimeLineEvent"" ) ; // $NON - NLS - 1$
","throw new IllegalArgumentException("" Needs a TimeLineEvent""); //$NON-NLS-1$
",,,"throw new IllegalArgumentException(""Need a TimeLineEvent""); //$NON-NLS-1$
",,,"public void addEvent ( ITimeEvent event ) { if ( ! ( event instanceof TimeLineEvent ) ) { throw new IllegalArgumentException ( ""Need to be a TimeLineEvent"" ) ; } super . addEvent ( event ) ; }
",,,"public void addEvent ( ITimeEvent event ) { if ( ! ( event instanceof TimeLineEvent ) ) { throw new IllegalArgumentException ( ""Need to be a TimeLineEvent"" ) ; } super . addEvent ( event ) ; }
",,,"public void addEvent ( ITimeEvent event ) { if ( ! ( event instanceof TimeLineEvent ) ) { < |startfocus| > throw new IllegalArgumentException ( ""Needs to be a TimeLineEvent"" ) ; // $NON - NLS - 1$ < |endfocus| > } super . addEvent ( event ) ;
",,
1807,"public TimeLineEvent ( ITimeGraphEntry entry , long time ) { this ( entry , time , new ArrayList < > ( ) ) ;
","public TimeLineEvent ( ITimeGraphEntry entry , long time ) { this ( entry , time , new ArrayList < > ( ) ) ;
","public TimeLineEvent(ITimeGraphEntry entry, long time, long duration) { this(entry, time, duration, new ArrayList<>());
",,,"public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, 0, new ArrayList<>());
",,,"public TimeLineEvent ( ITimeGraphEntry entry , long time ) { super ( entry , time , 0 , new ArrayList < > ( ) ) ; }
",,,"public TimeLineEvent ( ITimeGraphEntry entry , long time ) { super ( entry , time , 0 ) ; }
",,,"< |startfocus| > public TimeLineEvent ( ITimeGraphEntry entry , long time , long duration ) { this ( entry , time , 0 , new ArrayList < > ( ) ) ; < |endfocus| >
",,
1821,"long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } for ( TimeLineEvent ref : refs ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( ref ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < nbSeries ; i ++ ) { RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ;
","for ( TimeLineEvent ref : refs ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( ref ) ;
","for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i));
",,,"for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i));
",,,"long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; if ( refs . isEmpty ( ) ) { return ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( 0 ) ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < nbSeries ; i ++ ) { RGBA rgba = colors . get ( 0 ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ; }
",,,"long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } if ( refs . isEmpty ( ) ) { return ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < nbSeries ; i ++ ) { RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ; }
",,,"long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } < |startfocus| > for ( int i = 0 ; i < nbSeries ; i ++ ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; < |endfocus| > int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < nbSeries ; i ++ ) { RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ; gc . setForeground ( color ) ;
",,
1822,"Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < seriesModel . size ( ) ; i ++ ) { RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ; gc . setForeground ( color ) ; List < LongPoint > series = toDraw . get ( i ) ; int [ ] points = new int [ series . size ( ) * 2 ] ; for ( int point = 0 ; point < series . size ( ) ; point ++ ) { LongPoint longPoint = series . get ( point ) ; points [ point * 2 ] = longPoint . x ;
","for ( int i = 0 ; i < seriesModel . size ( ) ; i ++ ) {
","for (int i = 0; i < toDraw.size(); i++) {
",,,"for (int i = 0; i < toDraw.size(); i++) {
",,,"Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < toDraw . size ( ) ; i ++ ) { RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ; gc . setForeground ( color ) ; List < LongPoint > series = toDraw . get ( i ) ; int [ ] points = new int [ series . size ( ) * 2 ] ; for ( int point = 0 ; point < series . size ( ) ; point ++ ) { LongPoint longPoint = series . get ( point ) ; points [ point * 2 ] = longPoint . x ;
",,,"Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < toDraw . size ( ) ; i ++ ) { RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ; gc . setForeground ( color ) ; List < LongPoint > series = toDraw . get ( i ) ; int [ ] points = new int [ series . size ( ) * 2 ] ; for ( int point = 0 ; point < series . size ( ) ; point ++ ) { LongPoint longPoint = series . get ( point ) ; points [ point * 2 ] = longPoint . x ; // rest of the code } }
",,,"Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; < |startfocus| > for ( int i = 0 ; i < toDraw . size ( ) ; i ++ ) { < |endfocus| > RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ; gc . setForeground ( color ) ; List < LongPoint > series = toDraw . get ( i ) ; int [ ] points = new int [ series . size ( ) * 2 ] ; for ( int point = 0 ; point < series . size ( ) ; point ++ ) { LongPoint longPoint = series . get ( point ) ; points [ point * 2 ] = longPoint . x ;
",,
1828,"if ( mapping == null ) continue ; ResourceTraversal [ ] traversals = null ; try { traversals = mapping . getTraversals ( ResourceMappingContext . LOCAL_CONTEXT , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { StatusManager . getManager ( ) . handle ( e , IDEWorkbenchPlugin . IDE_WORKBENCH ) ; } if ( traversals != null ) { IResource [ ] resources = null ; for ( ResourceTraversal traversal : traversals ) { resources = traversal . getResources ( ) ; if ( resources != null ) { result . addAll ( Arrays . asList ( resources ) ) ; } } } } else result . add ( resource ) ; } // all that can be converted are done , answer new selection if ( result . isEmpty ( ) ) { return StructuredSelection . EMPTY ; } return new StructuredSelection ( result . toArray ( ) ) ;
","result . addAll ( Arrays . asList ( resources ) ) ;
","result.addAll(Arrays.asList(resources));
",,,"result.addAll(Arrays.asList(resources));
",,,"if ( mapping == null ) { continue ; } ResourceTraversal [ ] traversals = null ; try { traversals = mapping . getTraversals ( ResourceMappingContext . LOCAL_CONTEXT , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { StatusManager . getManager ( ) . handle ( e , IDEWorkbenchPlugin . IDE_WORKBENCH ) ; } if ( traversals != null ) { List < IResource > result = new ArrayList < > ( ) ; for ( ResourceTraversal traversal : traversals ) { IResource [ ] resources = traversal . getResources ( ) ; if ( resources != null ) { result . addAll ( Arrays . asList ( resources ) ) ; } } if ( ! result . isEmpty ( ) ) { return new StructuredSelection ( result . toArray ( ) ) ; } } return StructuredSelection . EMPTY ;
",,,"if ( mapping == null ) continue ; ResourceTraversal [ ] traversals = null ; try { traversals = mapping . getTraversals ( ResourceMappingContext . LOCAL_CONTEXT , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { StatusManager . getManager ( ) . handle ( e , IDEWorkbenchPlugin . IDE_WORKBENCH ) ; } if ( traversals != null ) { IResource [ ] resources = null ; for ( ResourceTraversal traversal : traversals ) { resources = traversal . getResources ( ) ; if ( resources != null ) { result . addAll ( Arrays . asList ( resources ) ) ; } } } else { result . add ( resource ) ; } // all that can be converted are done , answer new selection if ( result . isEmpty ( ) ) { return StructuredSelection . EMPTY ; } return new StructuredSelection ( result . toArray ( ) ) ;
",,,"if ( mapping == null ) continue ; ResourceTraversal [ ] traversals = null ; try { traversals = mapping . getTraversals ( ResourceMappingContext . LOCAL_CONTEXT , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { StatusManager . getManager ( ) . handle ( e , IDEWorkbenchPlugin . IDE_WORKBENCH ) ; } if ( traversals != null ) { IResource [ ] resources = null ; for ( ResourceTraversal traversal : traversals ) { resources = traversal . getResources ( ) ; if ( resources != null ) { < |startfocus| > result . addAll ( Arrays . asList ( resources ) ) ; < |endfocus| > } } } } else result . add ( resource ) ; } // all that can be converted are done , answer new selection if ( result . isEmpty ( ) ) { return StructuredSelection . EMPTY ; } return new StructuredSelection ( result . toArray ( ) ) ;
",,
1835,"queuedEvents . add ( prefId ) ; return ; } if ( listeners != null ) { listeners . firePropertyChange ( prefId ) ; } } @Override public final void addListener ( String [ ] eventsOfInterest , IPropertyMapListener listener ) { if ( listeners == null ) { listeners = new PropertyListenerList ( ) ; attachListener ( ) ; } listeners . add ( eventsOfInterest , listener ) ; } protected final void firePropertyChange ( String [ ] prefIds ) { if ( ignoreCount > 0 ) { queuedEvents . addAll ( Arrays . asList ( prefIds ) ) ; return ; } if ( listeners != null ) { listeners . firePropertyChange ( prefIds ) ; } } public final void startTransaction ( ) { ignoreCount ++ ; } public final void endTransaction ( ) { ignoreCount -- ; if ( ignoreCount == 0 && ! queuedEvents . isEmpty ( ) ) { if ( listeners != null ) { listeners . firePropertyChange ( ( String [ ] ) queuedEvents . toArray ( new String [ queuedEvents . size ( ) ] ) ) ; } queuedEvents . clear ( ) ; } } @Override public boolean equals ( Object toCompare ) {
","queuedEvents . addAll ( Arrays . asList ( prefIds ) ) ;
","queuedEvents.addAll(Arrays.asList(prefIds));
",,,"queuedEvents.addAll(Arrays.asList(prefIds));
",,,"queuedEvents . add ( prefId ) ; return ; } if ( listeners != null ) { listeners . firePropertyChange ( prefId ) ; } @Override public final void addListener ( String [ ] eventsOfInterest , IPropertyMapListener listener ) { if ( listeners == null ) { listeners = new PropertyListenerList ( ) ; attachListener ( ) ; } listeners . add ( eventsOfInterest , listener ) ; } protected final void firePropertyChange ( String [ ] prefIds ) { if ( ignoreCount > 0 ) { queuedEvents . addAll ( Arrays . asList ( prefIds ) ) ; return ; } if ( listeners != null ) { listeners . firePropertyChange ( prefIds ) ; } } public final void startTransaction ( ) { ignoreCount ++ ; } public final void endTransaction ( ) { ignoreCount -- ; if ( ignoreCount == 0 && ! queuedEvents . isEmpty ( ) ) { if ( listeners != null ) { listeners . firePropertyChange ( ( String [ ] ) queuedEvents . toArray ( new String [ queuedEvents . size ( ) ] ) ) ; } queuedEvents . clear ( ) ; } } @Override public boolean equals ( Object toCompare ) {
",,,"queuedEvents . add ( prefId ) ; return ; if ( listeners != null ) { listeners . firePropertyChange ( prefId ) ; } @Override public final void addListener ( String [ ] eventsOfInterest , IPropertyMapListener listener ) { if ( listeners == null ) { listeners = new PropertyListenerList ( ) ; attachListener ( ) ; } listeners . add ( eventsOfInterest , listener ) ; } protected final void firePropertyChange ( String [ ] prefIds ) { if ( ignoreCount > 0 ) { queuedEvents . addAll ( Arrays . asList ( prefIds ) ) ; return ; } if ( listeners != null ) { listeners . firePropertyChange ( prefIds ) ; } } public final void startTransaction ( ) { ignoreCount ++ ; } public final void endTransaction ( ) { ignoreCount -- ; if ( ignoreCount == 0 && ! queuedEvents . isEmpty ( ) ) { if ( listeners != null ) { listeners . firePropertyChange ( ( String [ ] ) queuedEvents . toArray ( new String [ queuedEvents . size ( ) ] ) ) ; } queuedEvents . clear ( ) ; } } @Override public boolean equals ( Object toCompare ) {
",,,"queuedEvents . add ( prefId ) ; return ; } if ( listeners != null ) { listeners . firePropertyChange ( prefId ) ; } } @Override public final void addListener ( String [ ] eventsOfInterest , IPropertyMapListener listener ) { if ( listeners == null ) { listeners = new PropertyListenerList ( ) ; attachListener ( ) ; } listeners . add ( eventsOfInterest , listener ) ; } protected final void firePropertyChange ( String [ ] prefIds ) { if ( ignoreCount > 0 ) { < |startfocus| > queuedEvents . addAll ( Arrays . asList ( prefIds ) ) ; < |endfocus| > return ; } if ( listeners != null ) { listeners . firePropertyChange ( prefIds ) ; } } public final void startTransaction ( ) { ignoreCount ++ ; } public final void endTransaction ( ) { ignoreCount -- ; if ( ignoreCount == 0 && ! queuedEvents . isEmpty ( ) ) { if ( listeners != null ) { listeners . firePropertyChange ( ( String [ ] ) queuedEvents . toArray ( new String [ queuedEvents . size ( ) ] ) ) ; } queuedEvents . clear ( ) ; } } @Override public boolean equals ( Object toCompare ) {
",,
1843,"kage org . eclipse . scout . rt . mail . smtp ; import javax . mail . Session ; import javax . mail . Transport ; import org . eclipse . scout . rt . platform . Bean ; @Bean public class SmtpConnectionPoolEntry { private String m_name ; private SmtpServerConfig m_smtpServerConfig ; private Session m_session ; private Transport m_transport ; // creation time of this pool entry object in milliseconds private long m_createTime ; private long m_idleSince ; public SmtpConnectionPoolEntry withName ( String name ) { m_name = name ; return this ; } public SmtpConnectionPoolEntry withSmtpServerConfig ( SmtpServerConfig smtpServerConfig ) { m_smtpServerConfig = smtpServerConfig ; return this ; } public SmtpConnectionPoolEntry withSession ( Session session ) { m_session = session ; return this ; } public SmtpConnectionPoolEntry withTransport ( Transport transport ) { m_transport = transport ; return this ; } public SmtpConnectionPoolEntry withCreateTime ( long createTime ) { m_createTime = createTime ; return this ; } public SmtpConnectionPoolEntry withIdleSince ( long idleSince ) { m_idleSince = idleSince ; return this ; } public Session getSession ( ) {
","private Transport m_transport ; // creation time of this pool entry object in milliseconds
","<|del|>
",,,"private Transport m_transport; /** The idle time (in milliseconds since January 1, 1970 00:00:00 UTC) */
",,,"package org . eclipse . scout . rt . mail . smtp ; import javax . mail . Session ; import javax . mail . Transport ; import org . eclipse . scout . rt . platform . Bean ; @Bean public class SmtpConnectionPoolEntry { private String name ; private SmtpServerConfig smtpServerConfig ; private Session session ; private Transport transport ; private long createTimeMillis ; private long idleSinceMillis ; public SmtpConnectionPoolEntry withName ( String name ) { this . name = name ; return this ; } public SmtpConnectionPoolEntry withSmtpServerConfig ( SmtpServerConfig smtpServerConfig ) { this . smtpServerConfig = smtpServerConfig ; return this ; } public SmtpConnectionPoolEntry withSession ( Session session ) { this . session = session ; return this ; } public SmtpConnectionPoolEntry withTransport ( Transport transport ) { this . transport = transport ; return this ; } public SmtpConnectionPoolEntry withCreateTimeMillis ( long createTimeMillis ) { this . createTimeMillis = createTimeMillis ; return this ; } public SmtpConnectionPoolEntry withIdleSinceMillis ( long idleSinceMillis ) { this . idleSinceMillis = idleSinceMillis ; return this ; } public Session getSession ( ) { return session ; } public Transport getTransport ( ) { return transport ; } public String getName ( ) { return name ; } public SmtpServerConfig getSmtpServerConfig ( ) { return smtpServerConfig ; } public long getCreateTimeMillis ( ) { return createTimeMillis ; } public long getIdleSinceMillis ( ) { return idleSinceMillis ; } }
",,,"package org . eclipse . scout . rt . mail . smtp ; import javax . mail . Session ; import javax . mail . Transport ; import org . eclipse . scout . rt . platform . Bean ; @Bean public class SmtpConnectionPoolEntry { private String m_name ; private SmtpServerConfig m_smtpServerConfig ; private Session m_session ; private Transport m_transport ; private long m_createTime ; private long m_idleSince ; public SmtpConnectionPoolEntry withName ( String name ) { m_name = name ; return this ; } public SmtpConnectionPoolEntry withSmtpServerConfig ( SmtpServerConfig smtpServerConfig ) { m_smtpServerConfig = smtpServerConfig ; return this ; } public SmtpConnectionPoolEntry withSession ( Session session ) { m_session = session ; return this ; } public SmtpConnectionPoolEntry withTransport ( Transport transport ) { m_transport = transport ; return this ; } public SmtpConnectionPoolEntry withCreateTime ( long createTime ) { m_createTime = createTime ; return this ; } public SmtpConnectionPoolEntry withIdleSince ( long idleSince ) { m_idleSince = idleSince ; return this ; } public Session getSession ( ) { return m_session ; } public Transport getTransport ( ) { return m_transport ; } public long getCreateTime ( ) { return m_createTime ; } public long getIdleSince ( ) { return m_idleSince ; } }
",,,"package org . eclipse . scout . rt . mail . smtp ; import javax . mail . Session ; import javax . mail . Transport ; import org . eclipse . scout . rt . platform . Bean ; @Bean public class SmtpConnectionPoolEntry { private String m_name ; private SmtpServerConfig m_smtpServerConfig ; private Session m_session ; < |startfocus| > private Transport m_transport ; < |endfocus| > private long m_createTime ; private long m_idleSince ; public SmtpConnectionPoolEntry withName ( String name ) { m_name = name ; return this ; } public SmtpConnectionPoolEntry withSmtpServerConfig ( SmtpServerConfig smtpServerConfig ) { m_smtpServerConfig = smtpServerConfig ; return this ; } public SmtpConnectionPoolEntry withSession ( Session session ) { m_session = session ; return this ; } public SmtpConnectionPoolEntry withTransport ( Transport transport ) { m_transport = transport ; return this ; } public SmtpConnectionPoolEntry withCreateTime ( long createTime ) { m_createTime = createTime ; return this ; } public SmtpConnectionPoolEntry withIdleSince ( long idleSince ) { m_idleSince = idleSince ; return this ; } public Session getSession ( ) {
",,
1844,"} public Map < String , String > getAdditionalSessionProperties ( ) { return m_additionalSessionProperties ; } /* * * These properties are added after the other properties , thus can override predefined properties such as host , port * or user . * * @param additionalSessionProperties * Additional properties used to create { @link Session } for SMTP server connection . */ public SmtpServerConfig withAdditionalSessionProperties ( Map < String , String > additionalSessionProperties ) { m_additionalSessionProperties = additionalSessionProperties ; return this ; } /* * * @return Returns the poolSize specified for this { @link SmtpServerConfig } object . */ public int getPoolSize ( ) { return m_poolSize ; } /* * * @param poolSize * Specifies the size of the connection pool to use with this { @link SmtpServerConfig# } . If 0 , smtp * connection pooling is disabled . */ public SmtpServerConfig withPoolSize ( int poolSize ) { m_poolSize = poolSize ; return this ; } @Override public int hashCode ( ) { final int prime = 31 ; int result = 1 ;
","/* * * @return Returns the poolSize specified for this { @link SmtpServerConfig } object . */
","/** * The pool size of the SmtpServerConfig. * * @param poolSize * Specifies the size of the connection pool to use with this {@link SmtpServerConfig#}. If 0, smtp connection pooling * is disabled. */ public SmtpServerConfig withPoolSize(int poolSize) { m_poolSize = poolSize; return this; }
",,,"/** * Returns the size of the connection pool to use with this {@link SmtpServerConfig#withPoolSize(int)}. */
",,,"/* * * Represents the configuration for an SMTP server . */ public class SmtpServerConfig { private Map < String , String > m_additionalSessionProperties ; private int m_poolSize ; /* * * Gets the additional session properties for the SMTP server connection . * These properties are added after the other properties , thus can override predefined properties such as host , port or user . * * @return The additional session properties . */ public Map < String , String > getAdditionalSessionProperties ( ) { return m_additionalSessionProperties ; } /* * * Sets the additional session properties for the SMTP server connection . * * @param additionalSessionProperties Additional properties used to create { @link Session } for SMTP server connection . * @return This SMTP server configuration . */ public SmtpServerConfig withAdditionalSessionProperties ( Map < String , String > additionalSessionProperties ) { m_additionalSessionProperties = additionalSessionProperties ; return this ; } /* * * Gets the size of the connection pool to use with this SMTP server configuration . * If 0 , SMTP connection pooling is disabled . * * @return The pool size . */ public int getPoolSize ( ) { return m_poolSize ; } /* * * Sets the size of the connection pool to use with this SMTP server configuration . * * @param poolSize The pool size . * @return This SMTP server configuration . */ public SmtpServerConfig withPoolSize ( int poolSize ) { m_poolSize = poolSize ; return this ; } @Override public int hashCode ( ) { final int prime = 31 ; int result = 1 ; // . . . return result ; } }
",,,"public Map < String , String > getAdditionalSessionProperties ( ) { return m_additionalSessionProperties ; } /* * * These properties are added after the other properties , thus can override predefined properties such as host , port * or user . * * @param additionalSessionProperties * Additional properties used to create { @link Session } for SMTP server connection . */ public SmtpServerConfig withAdditionalSessionProperties ( Map < String , String > additionalSessionProperties ) { m_additionalSessionProperties = additionalSessionProperties ; return this ; } public int getPoolSize ( ) { return m_poolSize ; } /* * * @param poolSize * Specifies the size of the connection pool to use with this { @link SmtpServerConfig# } . If 0 , smtp * connection pooling is disabled . */ public SmtpServerConfig withPoolSize ( int poolSize ) { m_poolSize = poolSize ; return this ; } @Override public int hashCode ( ) { final int prime = 31 ; int result = 1 ; // . . . rest of the code }
",,,"} public Map < String , String > getAdditionalSessionProperties ( ) { return m_additionalSessionProperties ; } /* * * These properties are added after the other properties , thus can override predefined properties such as host , port * or user . * * @param additionalSessionProperties * Additional properties used to create { @link Session } for SMTP server connection . */ public SmtpServerConfig withAdditionalSessionProperties ( Map < String , String > additionalSessionProperties ) { m_additionalSessionProperties = additionalSessionProperties ; return this ; } < |startfocus| > < |endfocus| > public int getPoolSize ( ) { return m_poolSize ; } /* * * @param poolSize * Specifies the size of the connection pool to use with this { @link SmtpServerConfig# } . If 0 , smtp * connection pooling is disabled . */ public SmtpServerConfig withPoolSize ( int poolSize ) { m_poolSize = poolSize ; return this ; } @Override public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( m_additionalSessionProperties == null ) ? 0 : m_additionalSessionProperties . hashCode ( ) ) ; result = prime * result + ( ( m_host == null ) ? 0 : m_host . hashCode ( ) ) ; result = prime * result + m_port ; result = prime * result + m_poolSize ; result = prime * result + ( ( m_user == null ) ? 0 : m_user . hashCode ( ) ) ; return result ; } @Override public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( obj == null ) return false ; if ( getClass ( ) != obj . getClass ( ) ) return false ; SmtpServerConfig other = ( SmtpServerConfig ) obj ; if ( m_additionalSessionProperties == null ) { if ( other . m_additionalSessionProperties != null ) return false ; } else if ( ! m_additionalSessionProperties . equals ( other . m_additionalSessionProperties ) ) return false ; if ( m_host == null ) { if ( other . m_host != null ) return false ; } else if ( ! m_host . equals ( other . m_host ) ) return false ; if ( m_port != other . m_port ) return false ; if ( m_poolSize != other . m_poolSize ) return false ; if ( m_user == null ) { if ( other . m_user != null ) return false ; } else if ( ! m_user . equals ( other . m_user ) ) return false ; return true ; } }
",,
1846,"// event is out of bounds continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; if ( nbSeries == - 1 ) { nbSeries = values . size ( ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { seriesModel . add ( new ArrayList < > ( ) ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = 0 ; seriesModel . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } for ( TimeLineEvent ref : refs ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( ref ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; }
","min = 0 ;
","min = Math.min(Math.abs(val), min); }
",,,"min = Math.min(Math.abs(val), min); if (max < min) { throw new IndexOutOfBoundsException(val, max); }
",,,"// if ( event . getEnd ( ) < event . getStart ( ) ) { continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; if ( nbSeries == - 1 ) { nbSeries = values . size ( ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { seriesModel . add ( new ArrayList < > ( ) ) ; } long max = Long . MIN_VALUE ; long min = Long . MAX_VALUE ; for ( int i = 0 ; i < nbSeries ; i ++ ) { if ( i < values . size ( ) ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; seriesModel . get ( i ) . add ( new LongPoint ( x , val ) ) ; } } if ( seriesModel . isEmpty ( ) ) { return ; } for ( TimeLineEvent ref : refs ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( ref ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; }
",,,"// event is out of bounds continue ; TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; if ( nbSeries == - 1 ) { nbSeries = values . size ( ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { seriesModel . add ( new ArrayList < > ( ) ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; seriesModel . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } if ( refs . isEmpty ( ) ) { return ; } for ( TimeLineEvent ref : refs ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( ref ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; }
",,,"// event is out of bounds continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; if ( nbSeries == - 1 ) { nbSeries = values . size ( ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { seriesModel . add ( new ArrayList < > ( ) ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; < |startfocus| > min = Math . min ( Math . abs ( val ) , min ) ; < |endfocus| > seriesModel . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } for ( TimeLineEvent ref : refs ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( ref ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; }
",,
1859,"public boolean visit ( LambdaExpression lambdaExpression ) { IMethodBinding binding = lambdaExpression . resolveMethodBinding ( ) ; IVariableBinding [ ] synVars = binding . getSyntheticOuterLocals ( ) ; if ( synVars == null || synVars . length == 0 ) { // name cannot be updated if Synthetic Outer Locals are not available return true ; } List < Field > allFields = underlyingThisObject . referenceType ( ) . fields ( ) ; ListIterator < Field > listIterator = allFields . listIterator ( ) ; int i = 0 ; if ( getUnderlyingMethod ( ) . isStatic ( ) ) { if ( synVars . length == allFields . size ( ) ) { while ( listIterator . hasNext ( ) ) { FieldImpl field = ( FieldImpl ) listIterator . next ( ) ; String newName = synVars [ i ] . getName ( ) ; FieldImpl newField = new FieldImpl ( ( VirtualMachineImpl ) field . virtualMachine ( ) , ( ReferenceTypeImpl ) field . declaringType ( ) , field . getFieldID ( ) , newName , field . signature ( ) , field . genericSignature ( ) , field . modifiers ( ) ) ; listIterator . set ( newField ) ; } } } else { if ( synVars . length + 1 == allFields . size ( ) ) { while ( listIterator . hasNext ( ) ) { FieldImpl field = ( FieldImpl ) listIterator . next ( ) ; String newName = field . name ( ) ;
","IVariableBinding [ ] synVars = binding . getSyntheticOuterLocals ( ) ; if ( synVars == null || synVars . length == 0 ) { // name cannot be updated if Synthetic Outer Locals are not available return true ; }
","IVariableBinding[] synVars = binding.getSyntheticOuterLocals();
",,,"IVariableBinding[] synVars = binding.getSyntheticOuterLocals();
",,,"public boolean visit ( LambdaExpression lambdaExpression ) { IMethodBinding binding = lambdaExpression . resolveMethodBinding ( ) ; IVariableBinding [ ] synVars = binding . getSyntheticOuterLocals ( ) ; List < Field > allFields = underlyingThisObject . referenceType ( ) . fields ( ) ; ListIterator < Field > listIterator = allFields . listIterator ( ) ; int i = 0 ; if ( getUnderlyingMethod ( ) . isStatic ( ) ) { if ( synVars != null && synVars . length == allFields . size ( ) ) { while ( listIterator . hasNext ( ) ) { FieldImpl field = ( FieldImpl ) listIterator . next ( ) ; String newName = synVars [ i ] . getName ( ) ; FieldImpl newField = new FieldImpl ( ( VirtualMachineImpl ) field . virtualMachine ( ) , ( ReferenceTypeImpl ) field . declaringType ( ) , field . getFieldID ( ) , newName , field . signature ( ) , field . genericSignature ( ) , field . modifiers ( ) ) ; listIterator . set ( newField ) ; i ++ ; } } } else { if ( synVars != null && synVars . length + 1 == allFields . size ( ) ) { while ( listIterator . hasNext ( ) ) { FieldImpl field = ( FieldImpl ) listIterator . next ( ) ; String newName = field . name ( ) ; FieldImpl newField = new FieldImpl ( ( VirtualMachineImpl ) field . virtualMachine ( ) , ( ReferenceTypeImpl ) field . declaringType ( ) , field . getFieldID ( ) , newName , field . signature ( ) , field . genericSignature ( ) , field . modifiers ( ) ) ; listIterator . set ( newField ) ; i ++ ; } } } return true ; }
",,,"public boolean visit ( LambdaExpression lambdaExpression ) { IMethodBinding binding = lambdaExpression . resolveMethodBinding ( ) ; IVariableBinding [ ] synVars = binding . getSyntheticOuterLocals ( ) ; List < Field > allFields = underlyingThisObject . referenceType ( ) . fields ( ) ; ListIterator < Field > listIterator = allFields . listIterator ( ) ; int i = 0 ; if ( getUnderlyingMethod ( ) . isStatic ( ) ) { if ( synVars . length == allFields . size ( ) ) { while ( listIterator . hasNext ( ) ) { FieldImpl field = ( FieldImpl ) listIterator . next ( ) ; String newName = synVars [ i ] . getName ( ) ; FieldImpl newField = new FieldImpl ( ( VirtualMachineImpl ) field . virtualMachine ( ) , ( ReferenceTypeImpl ) field . declaringType ( ) , field . getFieldID ( ) , newName , field . signature ( ) , field . genericSignature ( ) , field . modifiers ( ) ) ; listIterator . set ( newField ) ; } } } else { if ( synVars . length + 1 == allFields . size ( ) ) { while ( listIterator . hasNext ( ) ) { FieldImpl field = ( FieldImpl ) listIterator . next ( ) ; String newName = field . name ( ) ; // rest of the code } } } }
",,,"public boolean visit ( LambdaExpression lambdaExpression ) { IMethodBinding binding = lambdaExpression . resolveMethodBinding ( ) ; < |startfocus| > IVariableBinding [ ] synVars = binding . getSyntheticOuterLocals ( ) ; < |endfocus| > List < Field > allFields = underlyingThisObject . referenceType ( ) . fields ( ) ; ListIterator < Field > listIterator = allFields . listIterator ( ) ; int i = 0 ; if ( getUnderlyingMethod ( ) . isStatic ( ) ) { if ( synVars . length == allFields . size ( ) ) { while ( listIterator . hasNext ( ) ) { FieldImpl field = ( FieldImpl ) listIterator . next ( ) ; String newName = synVars [ i ] . getName ( ) ; FieldImpl newField = new FieldImpl ( ( VirtualMachineImpl ) field . virtualMachine ( ) , ( ReferenceTypeImpl ) field . declaringType ( ) , field . getFieldID ( ) , newName , field . signature ( ) , field . genericSignature ( ) , field . modifiers ( ) ) ; listIterator . set ( newField ) ; } } } else { if ( synVars . length + 1 == allFields . size ( ) ) { while ( listIterator . hasNext ( ) ) { FieldImpl field = ( FieldImpl ) listIterator . next ( ) ; String newName = field . name ( ) ; if ( synVars [ i ] . getName ( ) . equals ( newName ) ) { FieldImpl newField = new FieldImpl ( ( VirtualMachineImpl ) field . virtualMachine ( ) , ( ReferenceTypeImpl ) field . declaringType ( ) , field . getFieldID ( ) , newName , field . signature ( ) , field . genericSignature ( ) , field . modifiers ( ) ) ; listIterator . set ( newField ) ; } } } } return false ; }
",,
1888,"public void init ( IWorkbench workbench ) { setDescription ( PREFERENCE_PAGE_DESCRIPTION ) ; setPreferenceStore ( new ScopedPreferenceStore ( InstanceScope . INSTANCE , CAPRA_PREFERENCE_PAGE_ID ) ) ;
","setDescription ( PREFERENCE_PAGE_DESCRIPTION ) ;
","Description(""Eclipse Capra UI Preferences"");
",,,"setDescription(Messages.Capra_UIPreferences);
",,,"public void init ( IWorkbench workbench ) { setDescription ( Messages . CAPRA_UI_PREFERENCES_DESCRIPTION ) ; setPreferenceStore ( new ScopedPreferenceStore ( InstanceScope . INSTANCE , CAPRA_PREFERENCE_PAGE_ID ) ) ; } where `CAPRA_PREFERENCE_PAGE_ID` is a constant and `Messages . CAPRA_UI_PREFERENCES_DESCRIPTION` is a string externalized to a constant with the value ""Eclipse Capra UI Preferences"" .
",,,"public void init ( IWorkbench workbench ) { setDescription ( Messages . CapraGenericPreferences_description ) ; setPreferenceStore ( new ScopedPreferenceStore ( InstanceScope . INSTANCE , CAPRA_PREFERENCE_PAGE_ID ) ) ; }
",,,"public void init ( IWorkbench workbench ) { < |startfocus| > setDescription ( CAPRA_PREFERENCE_PAGE_DESCRIPTION ) ; < |endfocus| > setPreferenceStore ( new ScopedPreferenceStore ( InstanceScope . INSTANCE , CAPRA_PREFERENCE_PAGE_ID ) ) ;
",,
1897,"public void setEventList ( List < ITimeEvent > eventList ) { if ( eventList != null ) { // Sets a filtered list super . setEventList ( eventList . stream ( ) . map ( timeEvent - > isValidEvent ( timeEvent ) ? timeEvent : null ) . collect ( Collectors . toList ( ) ) ) ; }
","if ( eventList != null ) { // Sets a filtered list super . setEventList ( eventList . stream ( ) . map ( timeEvent - > isValidEvent ( timeEvent ) ? timeEvent : null ) . collect ( Collectors . toList ( ) ) ) ;
","if (eventList != null && eventList.stream().anyMatch(TimeGraphLineEntry::isValidEvent)) { super.setEventList(eventList);
",,,"if (eventList != null && eventList.stream().anyMatch(TimeGraphLineEntry::isValidEvent)) { super.setEventList(eventList);
",,,"public void setEventList ( List < ITimeEvent > eventList ) { if ( eventList != null ) { List < ITimeEvent > filteredList = eventList . stream ( ) . filter ( TimeGraphLineEntry : : isValidEvent ) . collect ( Collectors . toList ( ) ) ; super . setEventList ( filteredList ) ; } }
",,,"public void setEventList ( List < ITimeEvent > eventList ) { if ( eventList != null ) { List < ITimeEvent > filteredList = eventList . stream ( ) . filter ( TimeGraphLineEntry : : isValidEvent ) . collect ( Collectors . toList ( ) ) ; super . setEventList ( filteredList ) ; } }
",,,"public void setEventList ( List < ITimeEvent > eventList ) { < |startfocus| > if ( eventList != null ) { super . setEventList ( eventList . stream ( ) . filter ( TimeGraphLineEntry : : isValidEvent ) . collect ( Collectors . toList ( ) ) ) ; < |endfocus| > }
",,
1908,"* accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . tmf . ui . widgets . timegraph . model ; import java . text . NumberFormat ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; import java . util . Objects ; import java . util . StringJoiner ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model . ITimeGraphEntry ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model . TimeEvent ; /* * * Generic TimeLineEvent implementation , basically a point with multiple * potential Y values and one X * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { private final List < Long > fValues ; private String fLabel = null ; /* * * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent ( ITimeGraphEntry entry , long time ) { this ( entry , time , new ArrayList < > ( ) ) ; } /* * * Standard constructor * * @param entry * The entry matching this event
","* Generic TimeLineEvent implementation , basically a point with multiple * potential Y values and one X
","* TimeLineEvent implementation
",,,"* Generic TimeEvent implementation *
",,,"I'm sorry , but the provided code is incomplete and contains errors . Can you please provide the complete code so that I can refactor it ?
",,,"package org . eclipse . tracecompass . internal . tmf . ui . widgets . timegraph . model ; import java . text . NumberFormat ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; import java . util . Objects ; import java . util . StringJoiner ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model . ITimeGraphEntry ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model . TimeEvent ; /* * * Generic TimeEvent implementation * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { private final List < Long > fValues ; private String fLabel = null ; /* * * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent ( ITimeGraphEntry entry , long time ) { this ( entry , time , new ArrayList < > ( ) ) ; } /* * * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values * The values associated with this event */ public TimeLineEvent ( ITimeGraphEntry entry , long time , List < Long > values ) { super ( entry , time ) ; fValues = values ; } /* * * Get the values associated with this event * * @return The values associated with this event */ public List < Long > getValues ( ) { return fValues ; } /* * * Set the label for this event * * @param label * The label for this event */ public void setLabel ( String label ) { fLabel = label ; } /* * * Get the label for this event * * @return The label for this event */ public String getLabel ( ) { return fLabel ; } @Override public String toString ( ) { StringJoiner joiner = new StringJoiner ( "" , "" , "" [ "" , "" ] "" ) ; for ( Long value : fValues ) { joiner . add ( NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) . format ( value ) ) ; } return super . toString ( ) + "" "" + joiner . toString ( ) ; } @Override public int hashCode ( )
",,,"* accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . tmf . ui . widgets . timegraph . model ; import java . text . NumberFormat ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; import java . util . Objects ; import java . util . StringJoiner ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model . ITimeGraphEntry ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model . TimeEvent ; /* * < |startfocus| > * Generic TimeEvent implementation < |endfocus| > * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { private final List < Long > fValues ; private String fLabel = null ; /* * * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent ( ITimeGraphEntry entry , long time ) { this ( entry , time , new ArrayList < > ( ) ) ; } /* * * Standard constructor * * @param entry * The entry matching this event
",,
1913,"public String getLabel ( ) { String label = fLabel ; if ( label == null ) { StringJoiner sj = new StringJoiner ( "" , "" ) ; // $NON - NLS - 1$ getValues ( ) . forEach ( ( Long value ) - > sj . add ( value == null ? String . valueOf ( value ) : NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) . format ( value ) ) ) ; label = sj . toString ( ) ; fLabel = label ; } return label ;
","getValues ( ) . forEach ( ( Long value ) - > sj . add ( value == null ? String . valueOf ( value ) : NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) . format ( value ) ) ) ;
","getValues().forEach((Long value) -> sj.add(NumberFormat.getNumberInstance(Locale.getDefault()).format(value)));
",,,"Arrays.stream(getValues()) .forEach((Long value) -> sj.add(NumberFormat.getNumberInstance(Locale.getDefault()).format(value)));
",,,"public String getLabel ( ) { String label = fLabel ; if ( label == null ) { StringJoiner sj = new StringJoiner ( "" , "" ) ; List < Long > values = getValues ( ) ; if ( values == null ) { throw new IllegalArgumentException ( ""Values cannot be null"" ) ; } values . forEach ( ( Long value ) - > sj . add ( NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) . format ( value ) ) ) ; label = sj . toString ( ) ; fLabel = label ; } return label ; }
",,,"public String getLabel ( ) { String label = fLabel ; if ( label == null ) { StringJoiner sj = new StringJoiner ( "" , "" ) ; getValues ( ) . forEach ( ( Long value ) - > sj . add ( NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) . format ( value ) ) ) ; label = sj . toString ( ) ; fLabel = label ; } return label ; }
",,,"public String getLabel ( ) { String label = fLabel ; if ( label == null ) { StringJoiner sj = new StringJoiner ( "" , "" ) ; // $NON - NLS - 1$ < |startfocus| > getValues ( ) . forEach ( ( Long value ) - > sj . add ( NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) . format ( value ) ) ) ; < |endfocus| > label = sj . toString ( ) ; fLabel = label ; } return label ;
",,
1922,"public static boolean containsMatchingProperty ( Set < IConfigurationProperty > existingProperties , String name , String os , String arch ) { for ( IConfigurationProperty property : existingProperties ) { if ( name . equals ( property . getName ( ) . trim ( ) ) ) { // check if os / arch is different String propOs = property . getOs ( ) != null ? property . getOs ( ) . trim ( ) : ALL_OS ; if ( ALL_OS . equals ( propOs ) || ALL_OS . equals ( os ) || propOs . equals ( os ) ) { String propArch = property . getArch ( ) != null ? property . getArch ( ) . trim ( ) : """" ; // $NON - NLS - 1$ if ( propArch . equals ( arch ) || ALL_ARCH . equals ( arch ) || ALL_ARCH . equals ( propArch ) ) { return true ; } } } } return false ;
","String propOs = property . getOs ( ) != null ? property . getOs ( ) . trim ( ) : ALL_OS ;
","String propOs = property.getOs() != null ? property.getOs().trim() : """"; //$NON-NLS-1$
",,,"String propOs = property.getOs() != null ? property.getOs().trim() : ALL_OS;
",,,"public static boolean containsMatchingProperty ( Set < IConfigurationProperty > existingProperties , String name , String os , String arch ) { for ( IConfigurationProperty property : existingProperties ) { if ( name . equals ( property . getName ( ) . trim ( ) ) ) { String propOs = property . getOs ( ) != null ? property . getOs ( ) . trim ( ) : """" ; if ( propOs . equals ( ALL_OS ) || propOs . equals ( os ) || ALL_OS . equals ( os ) ) { String propArch = property . getArch ( ) != null ? property . getArch ( ) . trim ( ) : """" ; if ( propArch . equals ( arch ) || propArch . equals ( ALL_ARCH ) || ALL_ARCH . equals ( arch ) ) { return true ; } } } } return false ; }
",,,"public static boolean containsMatchingProperty ( Set < IConfigurationProperty > existingProperties , String name , String os , String arch ) { for ( IConfigurationProperty property : existingProperties ) { if ( name . equals ( property . getName ( ) . trim ( ) ) ) { String propOs = property . getOs ( ) != null ? property . getOs ( ) . trim ( ) : """" ; if ( ALL_OS . equals ( propOs ) || ALL_OS . equals ( os ) || propOs . equals ( os ) ) { String propArch = property . getArch ( ) != null ? property . getArch ( ) . trim ( ) : """" ; if ( propArch . equals ( arch ) || ALL_ARCH . equals ( arch ) || ALL_ARCH . equals ( propArch ) ) { return true ; } } } } return false ; }
",,,"public static boolean containsMatchingProperty ( Set < IConfigurationProperty > existingProperties , String name , String os , String arch ) { for ( IConfigurationProperty property : existingProperties ) { if ( name . equals ( property . getName ( ) . trim ( ) ) ) { // check if os / arch is different < |startfocus| > String propOs = property . getOs ( ) != null ? property . getOs ( ) . trim ( ) : ALL_OS ; // $NON - NLS - 1$ < |endfocus| > if ( ALL_OS . equals ( propOs ) || ALL_OS . equals ( os ) || propOs . equals ( os ) ) { String propArch = property . getArch ( ) != null ? property . getArch ( ) . trim ( ) : """" ; // $NON - NLS - 1$ if ( propArch . equals ( arch ) || ALL_ARCH . equals ( arch ) || ALL_ARCH . equals ( propArch ) ) { return true ; } } } } return false ;
",,
1930,"// content / chksum but have same name , size and lastmodified . // Since this is done with standard gc ( which creates new tmp files and // renames them ) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime ( ) throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; // don't use mtime of the parent folder to detect file modification . config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; // Pack to create initial packfile PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; AnyObjectId chk1 = pf . getPackChecksum ( ) ; String name = pf . getPackName ( ) ; Long length = Long . valueOf ( pf . getPackFile ( ) . length ( ) ) ; long m1 = packFilePath . toFile ( ) . lastModified ( ) ;
","// don't use mtime of the parent folder to detect file modification .
","// tell JGit not to used mtime of the parent folder to detect file // modification.
",,,"// tell JGit not to used mtime of the parent folder to detect file modification.
",,,"@Test public void testDetectModificationAlthoughSameSizeAndModificationTime ( ) throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; AnyObjectId chk1 = pf . getPackChecksum ( ) ; String name = pf . getPackName ( ) ; Long length = Long . valueOf ( pf . getPackFile ( ) . length ( ) ) ; long m1 = packFilePath . toFile ( ) . lastModified ( ) ; }
",,,"@Test public void testDetectModificationAlthoughSameSizeAndModificationTime ( ) throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; AnyObjectId chk1 = pf . getPackChecksum ( ) ; String name = pf . getPackName ( ) ; Long length = Long . valueOf ( pf . getPackFile ( ) . length ( ) ) ; long m1 = packFilePath . toFile ( ) . lastModified ( ) ; }
",,,"// Copyright ( C ) 2009 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . git ; import static com . google . common . base . Preconditions . checkArgument ; import static com . google . common . base . Preconditions . checkState ; import static com . google . common . collect . ImmutableList . toImmutableList ; import static com . google . common . collect . ImmutableSet . toImmutableSet ; import static com . google . common . collect . Iterables . getOnlyElement ; import static com . google . common . collect . Sets . difference ; import static com . google . common . collect . Sets . union ; import static com . google . gerrit . git . ObjectIds . abbreviateName ; import static com . google . gerrit . server . git . MultiProgressMonitor . UNKNOWN ; import static java . util . Comparator . comparing ; import static java . util . stream . Collectors . toList ; import static java . util . stream . Collectors . toSet ; import com . google . common . collect . ImmutableList ; import com . google . common . collect . ImmutableSet ; import com . google . common . collect . Iterables ; import com . google . common . collect . Lists ; import com . google . common . collect . Sets ; import com . google . common . flogger . FluentLogger ; import com . google . gerrit . common . Nullable ; import com . google . gerrit . common . data . ReceiveCommitsAdvice ; import com . google . gerrit . entities . BranchNameKey ; import com . google . gerrit . entities . Project ; import com . google . gerrit . entities . RefNames ; import com . google . gerrit . exceptions . StorageException ; import com . google . gerrit . extensions . api . GerritApi ; import com . google . gerrit . extensions . api . changes . NotifyHandling ; import com . google . gerrit . extensions . api . projects . BranchInput ; import com . google . gerrit . extensions . restapi . AuthException ; import com . google . gerrit . extensions . restapi . ResourceConflictException ; import com . google . gerrit . extensions . restapi . ResourceNotFoundException ; import com . google . gerrit . extensions . restapi . RestApiException ; import com . google . gerrit . server . GerritPersonIdent ; import com . google . gerrit . server . IdentifiedUser ; import com . google . gerrit . server . config . AllProjectsName ; import com . google . gerrit . server . config . AllUsersName ; import com . google . gerrit . server . config . GerritServerConfig ; import com . google . gerrit . server . git . MultiProgressMonitor . Task ; import com . google . gerrit . server . git . validators . CommitValidationException ; import com . google . gerrit . server . git . validators . CommitValidationListener ; import com . google . gerrit . server . git . validators . CommitValidationMessage ; import com . google . gerrit . server . git . validators . CommitValidators ; import com . google . gerrit . server . notedb . ChangeNotes ; import com . google . gerrit . server . permissions . PermissionBackendException ; import com . google . gerrit . server . project . NoSuchProjectException ; import com . google . gerrit . server . project . ProjectCache ; import com . google . gerrit . server . project . ProjectState ; import com . google . gerrit . server . query . change . ChangeData ; import com . google . gerrit . server . query . change . InternalChangeQuery ; import com . google . gerrit . server . update . BatchUpdate ; import com . google . gerrit . server . update . BatchUpdateOp ; import com . google . gerrit . server . update . ChangeContext ; import com . google . gerrit . server . update . Context ; import com . google . gerrit . server . update . RetryHelper ; import com . google . gerrit . server . update . RetryingRestModifyView ; import com . google . gerrit . server . update . UpdateException ; import com . google . gerrit . server . util . time . TimeUtil ; import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . Singleton ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collection ; import java . util . Collections ; import java . util . HashSet ; import java . util . List ; import java . util . Set ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . errors . IncorrectObjectTypeException ; import org . eclipse . jgit . errors . MissingObjectException ; import org . eclipse . jgit . lib . CommitBuilder ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectInserter ; import org . eclipse . jgit . lib . PersonIdent ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . RefUpdate ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . transport . ReceiveCommand ; import org . eclipse . jgit . transport . ReceiveCommand . Result ; import org . eclipse . jgit . transport . ReceiveCommand . Type ; /* * * Validates that the commit message of a change is not empty . * * < p > This validator is enabled by default . */ @Singleton public class EmptyCommitValidationListener implements CommitValidationListener { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; @Override public List < CommitValidationMessage > onCommitReceived ( CommitReceivedEvent receiveEvent , @Nullable ProjectState projectState ) throws CommitValidationException { if ( receiveEvent . commit
",,
1932,". getPackChecksum ( ) ) ; assumeTrue ( m3 == m2 ) ; } // Try repacking so fast that you get two new packs which differ only in // content / chksum but have same name , size and lastmodified . // To avoid that JGit detects modifications by checking the filekey create // two new packfiles upfront and create copies of them . Then modify the // packfiles inplace by opening them for write and copy content . @Test public void testDetectModificationAlthoughSameSizeAndModificationtimeAndFileKey ( ) throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; // Pack to create initial packfile . Make a copy of it PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; Path packFileBasePath = packFilePath . resolveSibling (
","public void testDetectModificationAlthoughSameSizeAndModificationtimeAndFileKey ( )
","public void testDetetctModificationAlthoughtSameSizeAndModificationtimeAndFileKey()
",,,"public void testDetectModificationAlthoughtSameSizeAndModificationtimeAndFileKey()
",,,"@Test public void testDetectModificationAlthoughSameSizeAndModificationTimeAndFileKey ( ) throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; Path packFileBasePath = packFilePath . resolveSibling ( ""pack"" ) ; Path newPackFilePath1 = packFileBasePath . resolve ( ""new1 . pack"" ) ; Path newPackFilePath2 = packFileBasePath . resolve ( ""new2 . pack"" ) ; Files . copy ( packFilePath , newPackFilePath1 ) ; Files . copy ( packFilePath , newPackFilePath2 ) ; modifyPackFile ( newPackFilePath1 ) ; modifyPackFile ( newPackFilePath2 ) ; try ( Repository repo = createRepository ( ) ) { Git git = new Git ( repo ) ; git . gc ( ) . call ( ) ; ObjectId m1 = repo . resolve ( Constants . HEAD + "" ^ { tree } "" ) ; git . add ( ) . addFilepattern ( "" . "" ) . call ( ) ; git . commit ( ) . setMessage ( ""commit"" ) . call ( ) ; ObjectId m2 = repo . resolve ( Constants . HEAD + "" ^ { tree } "" ) ; git . add ( ) . addFilepattern ( "" . "" ) . call ( ) ; git . commit ( ) . setMessage ( ""commit"" ) . call ( ) ; ObjectId m3 = repo . resolve ( Constants . HEAD + "" ^ { tree } "" ) ; assertEquals ( m1 , m3 ) ; assertNotEquals ( m1 , m2 ) ; } } private void modifyPackFile ( Path packFilePath ) throws IOException { try ( RandomAccessFile raf = new RandomAccessFile ( packFilePath . toFile ( ) , ""rw"" ) ) { raf . seek ( raf . length ( ) - 20 ) ; raf . write ( new byte [ ] { 0x01 , 0x02 , 0x03 , 0x04 } ) ; } } private PackFile repackAndCheck ( int compressionLevel , String indexVersion , String packConfig , String repackConfig ) throws Exception { try ( Repository repo = createRepository ( ) ) { Git git = new Git ( repo ) ; git . gc ( ) . call ( ) ; PackConfig pc = new PackConfig ( repo ) ; if ( packConfig != null ) { pc . fromConfigString ( packConfig ) ;
",,,"@Test public void testDetetctModificationAlthoughtSameSizeAndModificationtimeAndFileKey ( ) throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; Path packFileBasePath = packFilePath . resolveSibling ( ) ; // Create two new packfiles upfront and create copies of them Path packFile1Path = packFileBasePath . resolve ( ""pack - 1 . pack"" ) ; Path packFile2Path = packFileBasePath . resolve ( ""pack - 2 . pack"" ) ; Files . copy ( packFilePath , packFile1Path ) ; Files . copy ( packFilePath , packFile2Path ) ; // Modify the packfiles inplace by opening them for write and copying content try ( FileChannel packFile1Channel = FileChannel . open ( packFile1Path , StandardOpenOption . WRITE ) ; FileChannel packFile2Channel = FileChannel . open ( packFile2Path , StandardOpenOption . WRITE ) ) { packFile1Channel . transferFrom ( packFilePath , 0 , packFile1Channel . size ( ) ) ; packFile2Channel . transferFrom ( packFilePath , 0 , packFile2Channel . size ( ) ) ; } // Verify that JGit detects modifications assumeFalse ( pf . hasObjectFile ( packFile1Path . toFile ( ) ) ) ; assumeFalse ( pf . hasObjectFile ( packFile2Path . toFile ( ) ) ) ; }
",,,". getPackChecksum ( ) ) ; assumeTrue ( m3 == m2 ) ; } // Try repacking so fast that you get two new packs which differ only in // content / chksum but have same name , size and lastmodified . // To avoid that JGit detects modifications by checking the filekey create // two new packfiles upfront and create copies of them . Then modify the // packfiles inplace by opening them for write and copy content . @Test < |startfocus| > public void testDetectModificationAlthoughtSameSizeAndModificationtimeAndFileKey ( ) < |endfocus| > throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; // Pack to create initial packfile . Make a copy of it PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; Path packFileBasePath = packFilePath . resolveSibling (
",,
1938,"public void addEntries ( ISourceContainer [ ] entries ) { int index = 0 ; IStructuredSelection sel = getStructuredSelection ( ) ; if ( ! sel . isEmpty ( ) ) { index = fEntries . indexOf ( sel . getFirstElement ( ) ) ; } for ( int i = 0 ; i < entries . length ; i ++ ) { if ( ! fEntries . contains ( entries [ i ] ) ) { fEntries . add ( index , entries [ i ] ) ; index ++ ; } } refresh ( ) ; if ( entries . length > 0 ) { setSelection ( new StructuredSelection ( entries ) ) ; } fPanel . setDirty ( true ) ; fPanel . updateLaunchConfigurationDialog ( ) ;
","index = fEntries . indexOf ( sel . getFirstElement ( ) ) ; } for ( int i = 0 ; i < entries . length ; i ++ ) { if ( ! fEntries . contains ( entries [ i ] ) ) { fEntries . add ( index , entries [ i ] ) ;
","for (ISourceContainer entry : entries) { if (!fEntries.contains(entry)) { fEntries.add(entry.getFirstElement());
",,,"for (ISourceContainer entry : entries) { if (!fEntries.contains(entry)) { fEntries.add(index, entry); }
",,,"public void addEntries ( ISourceContainer [ ] entries ) { int index = 0 ; IStructuredSelection sel = getStructuredSelection ( ) ; if ( ! sel . isEmpty ( ) ) { index = fEntries . indexOf ( sel . getFirstElement ( ) ) ; } for ( ISourceContainer entry : entries ) { if ( ! fEntries . contains ( entry ) ) { fEntries . add ( index , entry ) ; index ++ ; } } refresh ( ) ; if ( entries . length > 0 ) { setSelection ( new StructuredSelection ( entries ) ) ; } fPanel . setDirty ( true ) ; fPanel . updateLaunchConfigurationDialog ( ) ; }
",,,"public void addEntries ( ISourceContainer [ ] entries ) { int index = 0 ; IStructuredSelection sel = getStructuredSelection ( ) ; if ( ! sel . isEmpty ( ) ) { index = fEntries . indexOf ( sel . getFirstElement ( ) ) ; } for ( ISourceContainer entry : entries ) { if ( ! fEntries . contains ( entry ) ) { fEntries . add ( index , entry ) ; index ++ ; } } refresh ( ) ; if ( entries . length > 0 ) { setSelection ( new StructuredSelection ( entries ) ) ; } fPanel . setDirty ( true ) ; fPanel . updateLaunchConfigurationDialog ( ) ; }
",,,"public void addEntries ( ISourceContainer [ ] entries ) { int index = 0 ; IStructuredSelection sel = getStructuredSelection ( ) ; if ( ! sel . isEmpty ( ) ) { < |startfocus| > index = fEntries . indexOf ( sel . getFirstElement ( ) ) ; } for ( ISourceContainer entrie : entries ) { if ( ! fEntries . contains ( entrie ) ) { fEntries . add ( index , entrie ) ; < |endfocus| > index ++ ; } } refresh ( ) ; if ( entries . length > 0 ) { setSelection ( new StructuredSelection ( entries ) ) ; } fPanel . setDirty ( true ) ; fPanel . updateLaunchConfigurationDialog ( ) ;
",,
1950,"* * Contributors : * EclipseSource Munich - initial API and implementation */ package org . eclipse . emf . ecp . view . internal . table . swt . cell ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . emf . ecore . EReference ; import org . eclipse . emf . ecore . EStructuralFeature ; import org . eclipse . emf . ecp . edit . spi . swt . table . ECPCellEditorTester ; import org . eclipse . emf . ecp . view . spi . context . ViewModelContext ; /* * * Single reference cell editor tester . * * @author Mat Hansen < mhansen@eclipsesource . com > * @author Eugen Neufeld < eneufeld@eclipsesource . com > * @since 1 . 22 * */ public class SingleReferenceCellEditorTester implements ECPCellEditorTester { @Override public int isApplicable ( EObject eObject , EStructuralFeature eStructuralFeature , ViewModelContext viewModelContext ) { if ( ! EReference . class . isInstance ( eStructuralFeature ) ) { return NOT_APPLICABLE ; } final EReference eReference = EReference . class . cast ( eStructuralFeature ) ; if ( eReference . getUpperBound ( ) == 1 ) { return 10 ; } return NOT_APPLICABLE ; } }
","* @author Eugen Neufeld < eneufeld@eclipsesource . com > * @since 1 . 22
","* @since 1.2.6
",,,"* @since 1.16
",,,"package org . eclipse . emf . ecp . view . internal . table . swt . cell ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . emf . ecore . EReference ; import org . eclipse . emf . ecore . EStructuralFeature ; import org . eclipse . emf . ecp . edit . spi . swt . table . ECPCellEditorTester ; import org . eclipse . emf . ecp . view . spi . context . ViewModelContext ; public class SingleReferenceCellEditorTester implements ECPCellEditorTester { @Override public int isApplicable ( EObject eObject , EStructuralFeature eStructuralFeature , ViewModelContext viewModelContext ) { if ( ! ( eStructuralFeature instanceof EReference ) ) { return NOT_APPLICABLE ; } final EReference eReference = ( EReference ) eStructuralFeature ; if ( eReference . getUpperBound ( ) == 1 ) { return 10 ; } return NOT_APPLICABLE ; } }
",,,"package org . eclipse . emf . ecp . view . internal . table . swt . cell ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . emf . ecore . EReference ; import org . eclipse . emf . ecore . EStructuralFeature ; import org . eclipse . emf . ecp . edit . spi . swt . table . ECPCellEditorTester ; import org . eclipse . emf . ecp . view . spi . context . ViewModelContext ; /* * * Single reference cell editor tester . * * @author Mat Hansen < mhansen@eclipsesource . com > * @since 1 . 21 */ public class SingleReferenceCellEditorTester implements ECPCellEditorTester { @Override public int isApplicable ( EObject eObject , EStructuralFeature eStructuralFeature , ViewModelContext viewModelContext ) { if ( ! EReference . class . isInstance ( eStructuralFeature ) ) { return NOT_APPLICABLE ; } final EReference eReference = EReference . class . cast ( eStructuralFeature ) ; if ( eReference . getUpperBound ( ) == 1 ) { return 10 ; } return NOT_APPLICABLE ; } }
",,,"* * Contributors : * EclipseSource Munich - initial API and implementation */ package org . eclipse . emf . ecp . view . internal . table . swt . cell ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . emf . ecore . EReference ; import org . eclipse . emf . ecore . EStructuralFeature ; import org . eclipse . emf . ecp . edit . spi . swt . table . ECPCellEditorTester ; import org . eclipse . emf . ecp . view . spi . context . ViewModelContext ; /* * * Single reference cell editor tester . * * @author Mat Hansen < mhansen@eclipsesource . com > < |startfocus| > * @since 1 . 21 < |endfocus| > * */ public class SingleReferenceCellEditorTester implements ECPCellEditorTester { @Override public int isApplicable ( EObject eObject , EStructuralFeature eStructuralFeature , ViewModelContext viewModelContext ) { if ( ! EReference . class . isInstance ( eStructuralFeature ) ) { return NOT_APPLICABLE ; } final EReference eReference = EReference . class . cast ( eStructuralFeature ) ; if ( eReference . getUpperBound ( ) == 1 ) { return 10 ; } return NOT_APPLICABLE ; } }
",,
1970,"produce = false ; else { if ( filter . requiresCommitBody ( ) ) c . parseBody ( walker ) ; produce = filter . include ( walker , c ) ; } for ( int i = 0 ; i < c . parents . length ; i ++ ) { RevCommit p = c . parents [ i ] ; if ( ( p . flags & SEEN ) != 0 ) continue ; if ( ( p . flags & PARSED ) == 0 ) p . parseHeaders ( walker ) ; p . flags | = SEEN ; pending . add ( p ) ; } walker . carryFlagsImpl ( c ) ; if ( ( c . flags & UNINTERESTING ) != 0 ) { if ( pending . everbodyHasFlag ( UNINTERESTING ) ) { final RevCommit n = pending . peek ( ) ; if ( n != null && n . commitTime >= last . commitTime ) { // This is too close to call . The next commit we // would pop is dated after the last one produced . // We have to keep going to ensure that we carry // flags as much as necessary . //
","< |del| > if ( firstParent && i > 0 ) { continue ; }
","<|del|>
",,,"<|del|>
",,,"produce = false ; else { if ( filter . requiresCommitBody ( ) ) c . parseBody ( walker ) ; produce = filter . include ( walker , c ) ; } for ( int i = 0 ; i < c . parents . length ; i ++ ) { RevCommit p = c . parents [ i ] ; if ( ( p . flags & SEEN ) != 0 ) continue ; if ( ( p . flags & PARSED ) == 0 ) p . parseHeaders ( walker ) ; p . flags | = SEEN ; if ( firstParent && i > 0 ) { continue ; } pending . add ( p ) ; } walker . carryFlagsImpl ( c ) ; if ( ( c . flags & UNINTERESTING ) != 0 ) { if ( pending . everbodyHasFlag ( UNINTERESTING ) ) { final RevCommit n = pending . peek ( ) ; if ( n != null && n . commitTime >= last . commitTime ) { // This is too close to call . The next commit we // would pop is dated after the last one produced . // We have to keep going to ensure that we carry // flags as much as necessary . // } } }
",,,"// produce = false ; else { if ( filter . requiresCommitBody ( ) ) c . parseBody ( walker ) ; produce = filter . include ( walker , c ) ; } for ( int i = 0 ; i < c . parents . length ; i ++ ) { RevCommit p = c . parents [ i ] ; if ( ( p . flags & SEEN ) != 0 ) continue ; if ( ( p . flags & PARSED ) == 0 ) p . parseHeaders ( walker ) ; p . flags | = SEEN ; if ( firstParent && i > 0 ) { continue ; } pending . add ( p ) ; } walker . carryFlagsImpl ( c ) ; if ( ( c . flags & UNINTERESTING ) != 0 ) { if ( pending . everbodyHasFlag ( UNINTERESTING ) ) { final RevCommit n = pending . peek ( ) ; if ( n != null && n . commitTime >= last . commitTime ) { // This is too close to call . The next commit we // would pop is dated after the last one produced . // We have to keep going to ensure that we carry // flags as much as necessary . // continue ; } } }
",,,"produce = false ; else { if ( filter . requiresCommitBody ( ) ) c . parseBody ( walker ) ; produce = filter . include ( walker , c ) ; } for ( int i = 0 ; i < c . parents . length ; i ++ ) { RevCommit p = c . parents [ i ] ; if ( ( p . flags & SEEN ) != 0 ) continue ; if ( ( p . flags & PARSED ) == 0 ) p . parseHeaders ( walker ) ; p . flags | = SEEN ; < |startfocus| > if ( firstParent && i > 0 ) { continue ; } < |endfocus| > pending . add ( p ) ; } walker . carryFlagsImpl ( c ) ; if ( ( c . flags & UNINTERESTING ) != 0 ) { if ( pending . everbodyHasFlag ( UNINTERESTING ) ) { final RevCommit n = pending . peek ( ) ; if ( n != null && n . commitTime >= last . commitTime ) { // This is too close to call . The next commit we // would pop is dated after the last one produced . // We have to keep going to ensure that we carry // flags as much as necessary . //
",,
1972,"RevCommit a = commit ( ) ; RevCommit b1 = commit ( a ) ; RevCommit b2 = commit ( a ) ; RevCommit c1 = commit ( b1 ) ; RevCommit c2 = commit ( b2 ) ; RevCommit d = commit ( c1 , c2 ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( d ) ; assertCommit ( d , rw . next ( ) ) ; assertCommit ( c1 , rw . next ( ) ) ; assertCommit ( b1 , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; } @Test public void testSecondParentAncestorOfFirstParent ( ) throws Exception { RevCommit a = commit ( ) ; RevCommit b = commit ( a ) ; RevCommit c = commit ( b , a ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( c ) ; assertCommit ( c , rw . next ( ) ) ; assertCommit ( b , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; } @Test public void testFirstParentMultipleOccurrences ( ) throws Exception { RevCommit a = commit ( ) ; RevCommit b = commit ( a ) ; RevCommit c = commit ( b ) ;
","< |del| >
","<|del|>
",,,"<|del|>
",,,"RevCommit a = commit ( ) ; RevCommit b1 = commit ( a ) ; RevCommit b2 = commit ( a ) ; RevCommit c1 = commit ( b1 ) ; RevCommit c2 = commit ( b2 ) ; RevCommit d = commit ( c1 , c2 ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( d ) ; assertCommit ( d , rw . next ( ) ) ; assertCommit ( c1 , rw . next ( ) ) ; assertCommit ( b1 , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; @Test public void testSecondParentAncestorOfFirstParent ( ) throws Exception { RevCommit a = commit ( ) ; RevCommit b = commit ( a ) ; RevCommit c = commit ( b , a ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( c ) ; assertCommit ( c , rw . next ( ) ) ; assertCommit ( b , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; } @Test public void testFirstParentMultipleOccurrences ( ) throws Exception { RevCommit a = commit ( ) ; RevCommit b = commit ( a ) ; RevCommit c = commit ( b ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( c ) ; assertCommit ( c , rw . next ( ) ) ; assertCommit ( b , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; }
",,,"RevCommit a = commit ( ) ; RevCommit b1 = commit ( a ) ; RevCommit b2 = commit ( a ) ; RevCommit c1 = commit ( b1 ) ; RevCommit c2 = commit ( b2 ) ; RevCommit d = commit ( c1 , c2 ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( d ) ; assertCommit ( d , rw . next ( ) ) ; assertCommit ( c1 , rw . next ( ) ) ; assertCommit ( b1 , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; @Test public void testSecondParentAncestorOfFirstParent ( ) throws Exception { RevCommit a = commit ( ) ; RevCommit b = commit ( a ) ; RevCommit c = commit ( b , a ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( c ) ; assertCommit ( c , rw . next ( ) ) ; assertCommit ( b , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; } @Test public void testFirstParentMultipleOccurrences ( ) throws Exception { RevCommit a = commit ( ) ; RevCommit b = commit ( a ) ; RevCommit c = commit ( b ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( c ) ; assertCommit ( c , rw . next ( ) ) ; assertCommit ( b , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; }
",,,"RevCommit a = commit ( ) ; RevCommit b1 = commit ( a ) ; RevCommit b2 = commit ( a ) ; RevCommit c1 = commit ( b1 ) ; RevCommit c2 = commit ( b2 ) ; RevCommit d = commit ( c1 , c2 ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( d ) ; assertCommit ( d , rw . next ( ) ) ; assertCommit ( c1 , rw . next ( ) ) ; assertCommit ( b1 , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; } < |startfocus| > < |endfocus| > @Test public void testSecondParentAncestorOfFirstParent ( ) throws Exception { RevCommit a = commit ( ) ; RevCommit b = commit ( a ) ; RevCommit c = commit ( b , a ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( c ) ; assertCommit ( c , rw . next ( ) ) ; assertCommit ( b , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; } @Test public void testFirstParentMultipleOccurrences ( ) throws Exception { RevCommit a = commit ( ) ; RevCommit b = commit ( a ) ; RevCommit c = commit ( b ) ;
",,
1979,"* < code > ILabelProvider </ code > . If it is an * < code > ITableLabelProvider </ code > , then it provides a separate label * text and image for each column . If it is an < code > ILabelProvider </ code > , * then it provides only the label text and image for the first column , and * any remaining columns are blank . */ @Override public IBaseLabelProvider getLabelProvider ( ) { return super . getLabelProvider ( ) ; } @SuppressWarnings ( ""rawtypes"" ) @Override protected List getSelectionFromWidget ( ) { if ( virtualManager != null ) { return getVirtualSelection ( ) ; } Widget [ ] items = doGetSelection ( ) ; List < Object > list = new ArrayList < > ( items . length ) ; for ( Widget item : items ) { Object e = item . getData ( ) ; if ( e != null ) { list . add ( e ) ; } } return list ; } /* * * Get the virtual selection . Avoid calling SWT whenever possible to prevent * extra widget creation . * * @return List of Object */
","@SuppressWarnings ( ""rawtypes"" )
","@SuppressWarnings(""rawtypes"")
",,,"@SuppressWarnings(""rawtypes"")
",,,"@Override public IBaseLabelProvider getLabelProvider ( ) { return super . getLabelProvider ( ) ; } @SuppressWarnings ( ""rawtypes"" ) @Override protected List getSelectionFromWidget ( ) { if ( virtualManager != null ) { return getVirtualSelection ( ) ; } Widget [ ] items = doGetSelection ( ) ; List < Object > list = new ArrayList < > ( items . length ) ; for ( Widget item : items ) { Object e = item . getData ( ) ; if ( e != null ) { list . add ( e ) ; } } return list ; } /* * * Get the virtual selection . Avoid calling SWT whenever possible to prevent * extra widget creation . * * @return List of Object */
",,,"@Override public IBaseLabelProvider getLabelProvider ( ) { return super . getLabelProvider ( ) ; } @SuppressWarnings ( { ""rawtypes"" } ) @Override protected List getSelectionFromWidget ( ) { if ( virtualManager != null ) { return getVirtualSelection ( ) ; } Widget [ ] items = doGetSelection ( ) ; List < Object > list = new ArrayList < > ( items . length ) ; for ( Widget item : items ) { Object e = item . getData ( ) ; if ( e != null ) { list . add ( e ) ; } } return list ; }
",,,"* < code > ILabelProvider </ code > . If it is an * < code > ITableLabelProvider </ code > , then it provides a separate label * text and image for each column . If it is an < code > ILabelProvider </ code > , * then it provides only the label text and image for the first column , and * any remaining columns are blank . */ @Override public IBaseLabelProvider getLabelProvider ( ) { return super . getLabelProvider ( ) ; } < |startfocus| > @SuppressWarnings ( ""rawtypes"" ) < |endfocus| > @Override protected List getSelectionFromWidget ( ) { if ( virtualManager != null ) { return getVirtualSelection ( ) ; } Widget [ ] items = doGetSelection ( ) ; List < Object > list = new ArrayList < > ( items . length ) ; for ( Widget item : items ) { Object e = item . getData ( ) ; if ( e != null ) { list . add ( e ) ; } } return list ; } /* * * Get the virtual selection . Avoid calling SWT whenever possible to prevent * extra widget creation . * * @return List of Object */
",,
1993,"public int getRed ( ) { if ( isDisposed ( ) ) SWT . error ( SWT . ERROR_GRAPHIC_DISPOSED ) ; /* * Conversion formula comes from Cairo's _cairo_color_double_to_short ( ) * and color_to_pixel ( ) functions . See bug 549181 and 549101 for more info . */ int r = ( ( ( int ) ( handle . red * 65535 . 0 + 0 . 5 ) ) > > 8 ) ; return Math . min ( r , 255 ) ;
","if ( isDisposed ( ) ) SWT . error ( SWT . ERROR_GRAPHIC_DISPOSED ) ; /* * Conversion formula comes from Cairo's _cairo_color_double_to_short ( ) * and color_to_pixel ( ) functions . See bug 549181 and 549101 for more info . */
","if (isDisposed()) SWT.error(SWT.ERROR_GRAPHIC_DISPOSED);
",,,"<|del|>
",,,"public int getRed ( ) { // Convert color from double to short using _cairo_color_double_to_short in Cairo // Convert short to pixel using color_to_pixel in Cairo if ( isDisposed ( ) ) SWT . error ( SWT . ERROR_GRAPHIC_DISPOSED ) ; int r = ( ( ( int ) ( handle . red * 65535 . 0 + 0 . 5 ) ) > > 8 ) ; return Math . min ( r , 255 ) ; }
",,,"public int getRed ( ) { if ( isDisposed ( ) ) { SWT . error ( SWT . ERROR_GRAPHIC_DISPOSED ) ; } // Convert the red value from double to short int r = ( ( ( int ) ( handle . red * 65535 . 0 + 0 . 5 ) ) > > 8 ) ; return Math . min ( r , 255 ) ; }
",,,"public int getRed ( ) { < |startfocus| > if ( isDisposed ( ) ) SWT . error ( SWT . ERROR_GRAPHIC_DISPOSED ) ; < |endfocus| > int r = ( ( ( int ) ( handle . red * 65535 . 0 + 0 . 5 ) ) > > 8 ) ; return Math . min ( r , 255 ) ; }
",,
2047,"import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . VppInterfaceAugmentation ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . Routing ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . RoutingBuilder ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; public class InterfaceRoutingCustomizerTest extends WriterCustomizerTest { private static final String IFACE_CTX_NAME = ""interface - ctx"" ; private static final String IF_NAME = ""eth1"" ; private static final int IF_INDEX = 1 ; private static final InstanceIdentifier < Routing > IID = InstanceIdentifier . create ( Interfaces . class ) . child ( Interface . class , new InterfaceKey ( IF_NAME ) ) . augmentation ( VppInterfaceAugmentation . class ) . child ( Routing . class ) ; private InterfaceRoutingCustomizer customizer ; @Override protected void setUpTest ( ) throws Exception { customizer = new InterfaceRoutingCustomizer ( api , new NamingContext ( ""ifacePrefix"" , IFACE_CTX_NAME ) ) ;
","< |del| > import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . fib . table . management . rev180521 . VniReference ;
","<|del|>
",,,"<|del|>
",,,"import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . VppInterfaceAugmentation ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . Routing ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . RoutingBuilder ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . fib . table . management . rev180521 . VniReference ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; public class InterfaceRoutingCustomizerTest extends WriterCustomizerTest { private static final String IFACE_CTX_NAME = ""interface - ctx"" ; private static final String IF_NAME = ""eth1"" ; private static final int IF_INDEX = 1 ; private static final InstanceIdentifier < Routing > IID = InstanceIdentifier . create ( Interfaces . class ) . child ( Interface . class , new InterfaceKey ( IF_NAME ) ) . augmentation ( VppInterfaceAugmentation . class ) . child ( Routing . class ) ; private InterfaceRoutingCustomizer customizer ; @Override protected void setUpTest ( ) throws Exception { customizer = new InterfaceRoutingCustomizer ( api , new NamingContext ( ""ifacePrefix"" , IFACE_CTX_NAME ) ) ; } }
",,,"import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . VppInterfaceAugmentation ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . Routing ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . RoutingBuilder ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . fib . table . management . rev180521 . VniReference ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; public class InterfaceRoutingCustomizerTest extends WriterCustomizerTest { private static final String IFACE_CTX_NAME = ""interface - ctx"" ; private static final String IF_NAME = ""eth1"" ; private static final int IF_INDEX = 1 ; private static final InstanceIdentifier < Routing > IID = InstanceIdentifier . create ( Interfaces . class ) . child ( Interface . class , new InterfaceKey ( IF_NAME ) ) . augmentation ( VppInterfaceAugmentation . class ) . child ( Routing . class ) ; private InterfaceRoutingCustomizer customizer ; @Override protected void setUpTest ( ) throws Exception { customizer = new InterfaceRoutingCustomizer ( api , new NamingContext ( ""ifacePrefix"" , IFACE_CTX_NAME ) ) ; } }
",,,"import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . VppInterfaceAugmentation ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . Routing ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . RoutingBuilder ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . fib . table . management . rev180521 . VniReference ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; public class InterfaceRoutingCustomizerTest extends WriterCustomizerTest { private static final String IFACE_CTX_NAME = ""interface - ctx"" ; private static final String IF_NAME = ""eth1"" ; private static final int IF_INDEX = 1 ; private static final InstanceIdentifier < Routing > IID = InstanceIdentifier . create ( Interfaces . class ) . child ( Interface . class , new InterfaceKey ( IF_NAME ) ) . augmentation ( VppInterfaceAugmentation . class ) . child ( Routing . class ) ; private InterfaceRoutingCustomizer customizer ; @Override protected void setUpTest ( ) throws Exception { customizer = new InterfaceRoutingCustomizer ( api , new NamingContext ( ""ifacePrefix"" , IFACE_CTX_NAME ) ) ;
",,
2060,"} } } @Override public void updateCurrentAttributes ( @Nonnull final InstanceIdentifier < IkeGlobalConfiguration > id , @Nonnull final IkeGlobalConfiguration dataBefore , @Nonnull final IkeGlobalConfiguration dataAfter , @Nonnull final WriteContext writeContext ) throws WriteFailedException { writeCurrentAttributes ( id , dataAfter , writeContext ) ; } @Override public void deleteCurrentAttributes ( @Nonnull final InstanceIdentifier < IkeGlobalConfiguration > id , @Nonnull final IkeGlobalConfiguration dataBefore , @Nonnull final WriteContext writeContext ) throws WriteFailedException { // VPP doesn't support deletion of local key file } }
","// VPP doesn't support deletion of local key file
","<|del|>
",,,"writeCurrentAttributes(id, dataBefore, dataAfter, writeContext);
",,,"@Override public void updateCurrentAttributes ( @Nonnull final InstanceIdentifier < IkeGlobalConfiguration > id , @Nonnull final IkeGlobalConfiguration dataBefore , @Nonnull final IkeGlobalConfiguration dataAfter , @Nonnull final WriteContext writeContext ) throws WriteFailedException { writeCurrentAttributes ( id , dataAfter , writeContext ) ; } @Override public void deleteCurrentAttributes ( @Nonnull final InstanceIdentifier < IkeGlobalConfiguration > id , @Nonnull final IkeGlobalConfiguration dataBefore , @Nonnull final WriteContext writeContext ) throws WriteFailedException { // This method is intentionally left blank as there is no need to perform any delete operation for this configuration . }
",,,"} } } @Override public void updateCurrentAttributes ( @Nonnull final InstanceIdentifier < IkeGlobalConfiguration > id , @Nonnull final IkeGlobalConfiguration dataBefore , @Nonnull final IkeGlobalConfiguration dataAfter , @Nonnull final WriteContext writeContext ) throws WriteFailedException { writeCurrentAttributes ( id , dataAfter , writeContext ) ; } @Override public void deleteCurrentAttributes ( @Nonnull final InstanceIdentifier < IkeGlobalConfiguration > id , @Nonnull final IkeGlobalConfiguration dataBefore , @Nonnull final WriteContext writeContext ) throws WriteFailedException { // TODO Auto - generated method stub }
",,,"} } } @Override public void updateCurrentAttributes ( @Nonnull final InstanceIdentifier < IkeGlobalConfiguration > id , @Nonnull final IkeGlobalConfiguration dataBefore , @Nonnull final IkeGlobalConfiguration dataAfter , @Nonnull final WriteContext writeContext ) throws WriteFailedException { writeCurrentAttributes ( id , dataAfter , writeContext ) ; } @Override public void deleteCurrentAttributes ( @Nonnull final InstanceIdentifier < IkeGlobalConfiguration > id , @Nonnull final IkeGlobalConfiguration dataBefore , @Nonnull final WriteContext writeContext ) throws WriteFailedException { < |startfocus| > // TODO : implement < |endfocus| > } }
",,
2061,"String name = id . firstKeyOf ( Policy . class ) . getName ( ) ; if ( dataAfter . getLocal ( ) != null ) { setProfileId ( id , name , dataAfter . getLocal ( ) . getIdentity ( ) , true ) ; } if ( dataAfter . getRemote ( ) != null ) { setProfileId ( id , name , dataAfter . getRemote ( ) . getIdentity ( ) , false ) ; } } @Override public void updateCurrentAttributes ( @Nonnull final InstanceIdentifier < Identity > id , @Nonnull final Identity dataBefore , @Nonnull final Identity dataAfter , @Nonnull final WriteContext writeContext ) throws WriteFailedException { writeCurrentAttributes ( id , dataAfter , writeContext ) ; } private void setProfileId ( final InstanceIdentifier < Identity > id , final String profileName , final org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . hc2vpp . ipsec . rev181214 . identity . grouping . Identity data , final boolean isLocalId ) throws WriteFailedException {
","< |del| > public void deleteCurrentAttributes ( @Nonnull final InstanceIdentifier < Identity > id , @Nonnull final Identity dataBefore , @Nonnull final WriteContext writeContext ) throws WriteFailedException { } @Override
","<|del|>
",,,"<|del|>
",,,"// Implementation for deleteCurrentAttributes method @Override public void deleteCurrentAttributes ( @Nonnull final InstanceIdentifier < Identity > id , @Nonnull final Identity dataBefore , @Nonnull final WriteContext writeContext ) throws WriteFailedException { // TODO : Implement the deleteCurrentAttributes method } for updateCurrentAttributes method @Override public void updateCurrentAttributes ( @Nonnull final InstanceIdentifier < Identity > id , @Nonnull final Identity dataBefore , @Nonnull final Identity dataAfter , @Nonnull final WriteContext writeContext ) throws WriteFailedException { String name = id . firstKeyOf ( Policy . class ) . getName ( ) ; if ( dataAfter . getLocal ( ) != null ) { setProfileId ( id , name , dataAfter . getLocal ( ) . getIdentity ( ) , true ) ; } if ( dataAfter . getRemote ( ) != null ) { setProfileId ( id , name , dataAfter . getRemote ( ) . getIdentity ( ) , false ) ; } writeCurrentAttributes ( id , dataAfter , writeContext ) ; } private void setProfileId ( final InstanceIdentifier < Identity > id , final String profileName , final org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . hc2vpp . ipsec . rev181214 . identity . grouping . Identity data , final boolean isLocalId ) throws WriteFailedException { // TODO : Implement the setProfileId method }
",,,"String name = id . firstKeyOf ( Policy . class ) . getName ( ) ; if ( dataAfter . getLocal ( ) != null ) { setProfileId ( id , name , dataAfter . getLocal ( ) . getIdentity ( ) , true ) ; } if ( dataAfter . getRemote ( ) != null ) { setProfileId ( id , name , dataAfter . getRemote ( ) . getIdentity ( ) , false ) ; } @Override public void deleteCurrentAttributes ( @Nonnull final InstanceIdentifier < Identity > id , @Nonnull final Identity dataBefore , @Nonnull final WriteContext writeContext ) throws WriteFailedException { } @Override public void updateCurrentAttributes ( @Nonnull final InstanceIdentifier < Identity > id , @Nonnull final Identity dataBefore , @Nonnull final Identity dataAfter , @Nonnull final WriteContext writeContext ) throws WriteFailedException { writeCurrentAttributes ( id , dataAfter , writeContext ) ; } private void setProfileId ( final InstanceIdentifier < Identity > id , final String profileName , final org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . hc2vpp . ipsec . rev181214 . identity . grouping . Identity data , final boolean isLocalId ) throws WriteFailedException { // implementation goes here }
",,,"String name = id . firstKeyOf ( Policy . class ) . getName ( ) ; if ( dataAfter . getLocal ( ) != null ) { setProfileId ( id , name , dataAfter . getLocal ( ) . getIdentity ( ) , true ) ; } if ( dataAfter . getRemote ( ) != null ) { setProfileId ( id , name , dataAfter . getRemote ( ) . getIdentity ( ) , false ) ; } } @Override < |startfocus| > public void deleteCurrentAttributes ( @Nonnull final InstanceIdentifier < Identity > id , @Nonnull final Identity dataBefore , @Nonnull final WriteContext writeContext ) throws WriteFailedException { } @Override < |endfocus| > public void updateCurrentAttributes ( @Nonnull final InstanceIdentifier < Identity > id , @Nonnull final Identity dataBefore , @Nonnull final Identity dataAfter , @Nonnull final WriteContext writeContext ) throws WriteFailedException { writeCurrentAttributes ( id , dataAfter , writeContext ) ; } private void setProfileId ( final InstanceIdentifier < Identity > id , final String profileName , final org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . hc2vpp . ipsec . rev181214 . identity . grouping . Identity data , final boolean isLocalId ) throws WriteFailedException {
",,
2062,"IpsecSadEntriesAugmentation augment = dataAfter . augmentation ( IpsecSadEntriesAugmentation . class ) ; if ( augment != null && augment . getSaId ( ) != null ) { entry . sadId = augment . getSaId ( ) ; } if ( dataAfter . getSpi ( ) != null ) { entry . spi = dataAfter . getSpi ( ) . intValue ( ) ; } if ( dataAfter . getAntiReplayWindow ( ) != null ) { entry . useAntiReplay = dataAfter . getAntiReplayWindow ( ) > 0 ? BYTE_TRUE : BYTE_FALSE ; } if ( dataAfter . getSaMode ( ) != null ) { entry . isTunnel = Integer . valueOf ( dataAfter . getSaMode ( ) . getIntValue ( ) ) . byteValue ( ) ; } entry . isAdd = adding ? ByteDataTranslator . BYTE_TRUE : ByteDataTranslator . BYTE_FALSE ; if ( dataAfter . getEsp ( ) != null ) { entry . protocol = 1 ; fillEspAuthentication ( entry , dataAfter . getEsp ( ) ) ; fillEspEncryption ( entry , dataAfter . getEsp ( ) ) ; } else if ( dataAfter . getAh ( ) != null ) { entry . protocol = 0 ;
","entry . useAntiReplay = dataAfter . getAntiReplayWindow ( ) > 0 ? BYTE_TRUE : BYTE_FALSE ;
","entry.useAntiReplay = dataAfter.getAntiReplayWindow() > 0 ? BYTE_TRUE : BYTE_FALSE;
",,,"entry.useAntiReplay = dataAfter.getAntiReplayWindow() > 0 ? BYTE_TRUE : BYTE_FALSE;
",,,"IpsecSadEntriesAugmentation augment = dataAfter . augmentation ( IpsecSadEntriesAugmentation . class ) ; if ( augment != null && augment . getSaId ( ) != null ) { entry . sadId = augment . getSaId ( ) ; } if ( dataAfter . getSpi ( ) != null ) { entry . spi = dataAfter . getSpi ( ) . intValue ( ) ; } entry . useAntiReplay = dataAfter . getAntiReplayWindow ( ) > 0 ? BYTE_TRUE : BYTE_FALSE ; if ( dataAfter . getSaMode ( ) != null ) { entry . isTunnel = Integer . valueOf ( dataAfter . getSaMode ( ) . getIntValue ( ) ) . byteValue ( ) ; } entry . isAdd = adding ? ByteDataTranslator . BYTE_TRUE : ByteDataTranslator . BYTE_FALSE ; if ( dataAfter . getEsp ( ) != null ) { entry . protocol = 1 ; fillEspAuthentication ( entry , dataAfter . getEsp ( ) ) ; fillEspEncryption ( entry , dataAfter . getEsp ( ) ) ; } else if ( dataAfter . getAh ( ) != null ) { entry . protocol = 0 ; }
",,,"IpsecSadEntriesAugmentation augment = dataAfter . augmentation ( IpsecSadEntriesAugmentation . class ) ; if ( augment != null && augment . getSaId ( ) != null ) { entry . sadId = augment . getSaId ( ) ; } if ( dataAfter . getSpi ( ) != null ) { entry . spi = dataAfter . getSpi ( ) . intValue ( ) ; } if ( dataAfter . getAntiReplayWindow ( ) != null ) { entry . useAntiReplay = dataAfter . getAntiReplayWindow ( ) > 0 ? BYTE_TRUE : BYTE_FALSE ; } if ( dataAfter . getSaMode ( ) != null ) { entry . isTunnel = Integer . valueOf ( dataAfter . getSaMode ( ) . getIntValue ( ) ) . byteValue ( ) ; } entry . isAdd = adding ? ByteDataTranslator . BYTE_TRUE : ByteDataTranslator . BYTE_FALSE ; if ( dataAfter . getEsp ( ) != null ) { entry . protocol = 1 ; fillEspAuthentication ( entry , dataAfter . getEsp ( ) ) ; fillEspEncryption ( entry , dataAfter . getEsp ( ) ) ; } else if ( dataAfter . getAh ( ) != null ) { entry . protocol = 0 ; }
",,,"IpsecSadEntriesAugmentation augment = dataAfter . augmentation ( IpsecSadEntriesAugmentation . class ) ; if ( augment != null && augment . getSaId ( ) != null ) { entry . sadId = augment . getSaId ( ) ; } if ( dataAfter . getSpi ( ) != null ) { entry . spi = dataAfter . getSpi ( ) . intValue ( ) ; } if ( dataAfter . getAntiReplayWindow ( ) != null ) { < |startfocus| > entry . useAntiReplay = dataAfter . getAntiReplayWindow ( ) > 0 ? BYTE_TRUE : BYTE_FALSE ; < |endfocus| > } if ( dataAfter . getSaMode ( ) != null ) { entry . isTunnel = Integer . valueOf ( dataAfter . getSaMode ( ) . getIntValue ( ) ) . byteValue ( ) ; } entry . isAdd = adding ? ByteDataTranslator . BYTE_TRUE : ByteDataTranslator . BYTE_FALSE ; if ( dataAfter . getEsp ( ) != null ) { entry . protocol = 1 ; fillEspAuthentication ( entry , dataAfter . getEsp ( ) ) ; fillEspEncryption ( entry , dataAfter . getEsp ( ) ) ; } else if ( dataAfter . getAh ( ) != null ) { entry . protocol = 0 ;
",,
2074,". get ( replyId ) ; if ( completableFuture == null ) { // reply received before writer created future , // create new future , and put into map to notify sender that reply is already received , // following details replies will add information to this future completableFuture = new io . fd . jvpp . stats . future . AbstractFutureJVppInvoker . CompletableDumpFuture < > ( replyId , new InterfaceStatisticsDetailsReplyDump ( ) ) ; requests . put ( replyId , completableFuture ) ; } completableFuture . getReplyDump ( ) . interfaceStatisticsDetails = reply ; } } }
","< |del| >
","<|del|>
",,,"<|del|>
",,,". get ( replyId ) ; if ( completableFuture == null ) { completableFuture = new io . fd . jvpp . stats . future . AbstractFutureJVppInvoker . CompletableDumpFuture < > ( replyId , new InterfaceStatisticsDetailsReplyDump ( ) ) ; requests . put ( replyId , completableFuture ) ; } completableFuture . getReplyDump ( ) . interfaceStatisticsDetails = reply ;
",,,". get ( replyId ) ; if ( completableFuture == null ) { // reply received before writer created future , // create new future , and put into map to notify sender that reply is already received , // following details replies will add information to this future completableFuture = new io . fd . jvpp . stats . future . AbstractFutureJVppInvoker . CompletableDumpFuture < > ( replyId , new InterfaceStatisticsDetailsReplyDump ( ) ) ; requests . put ( replyId , completableFuture ) ; } completableFuture . getReplyDump ( ) . interfaceStatisticsDetails = reply ; }
",,,". get ( replyId ) ; if ( completableFuture == null ) { // reply received before writer created future , // create new future , and put into map to notify sender that reply is already received , // following details replies will add information to this future completableFuture = new io . fd . jvpp . stats . future . AbstractFutureJVppInvoker . CompletableDumpFuture < > ( replyId , new InterfaceStatisticsDetailsReplyDump ( ) ) ; requests . put ( replyId , completableFuture ) ; } completableFuture . getReplyDump ( ) . interfaceStatisticsDetails = reply ; } } < |startfocus| > < |endfocus| > }
",,
2079,"public VxlanValidator ( @Nonnull final NamingContext interfaceNamingContext , @Nonnull final DisabledInterfacesManager interfaceDisableContext ) { checkNotNull ( interfaceNamingContext , ""interfaceContext should not be null"" ) ; checkNotNull ( disabledInterfacesManager , ""disabledInterfacesManager should not be null"" ) ;
","checkNotNull ( disabledInterfacesManager , ""disabledInterfacesManager should not be null"" ) ;
","checkNotNull(interfaceDisableContext, ""DisabledInterfacesManager should not be null"");
",,,"checkNotNull(interfaceDisableContext, ""interfaceDisableContext should not be null"");
",,,"public VxlanValidator ( @Nonnull final NamingContext interfaceNamingContext , @Nonnull final DisabledInterfacesManager disabledInterfacesManager ) { checkNotNull ( interfaceNamingContext , ""interfaceContext should not be null"" ) ; checkNotNull ( disabledInterfacesManager , ""disabledInterfacesManager should not be null"" ) ; }
",,,"public VxlanValidator ( @Nonnull final NamingContext interfaceNamingContext , @Nonnull final DisabledInterfacesManager disabledInterfacesManager ) { checkNotNull ( interfaceNamingContext , ""interfaceContext should not be null"" ) ; checkNotNull ( disabledInterfacesManager , ""DisabledInterfacesManager should not be null"" ) ; }
",,,"public VxlanValidator ( @Nonnull final NamingContext interfaceNamingContext , @Nonnull final DisabledInterfacesManager disabledInterfacesManager ) { checkNotNull ( interfaceNamingContext , ""interfaceContext should not be null"" ) ; < |startfocus| > checkNotNull ( disabledInterfacesManager , ""DisabledInterfacesManager should not be null"" ) ; < |endfocus| >
",,
2091,"public void setMatrix ( double [ ] data ) { mMatrix = MatrixHelper . createMatrix ( data ) ;
","mMatrix = MatrixHelper . createMatrix ( data ) ;
","<|del|>
",,,"mMatrix = MatrixHelper.createMatrix(data);
",,,"public void setMatrix ( double [ ] data ) { if ( data == null ) { mMatrix = MatrixHelper . createMatrix ( ) ; } else { mMatrix = MatrixHelper . createMatrix ( data ) ; } }
",,,"public void setMatrix ( double [ ] data ) { if ( data != null ) { mMatrix = MatrixHelper . createMatrix ( data ) ; } else { mMatrix = MatrixHelper . createMatrix ( ) ; } }
",,,"public void setMatrix ( double [ ] data ) { < |startfocus| > if ( data != null ) { mMatrix = MatrixHelper . createMatrix ( data ) ; } else { // Null matrix means identity . mMatrix = MatrixHelper . createMatrix ( ) ; } < |endfocus| >
",,
2102,"} public static SceneGraphPart getSceneGraphPart ( ) { if ( SceneGraphPart . sActiveInstance == null ) { createPart ( ""com . samsung . dali . modelconverter . part . scenegraph"" ) ; assert SceneGraphPart . sActiveInstance != null ; } return SceneGraphPart . sActiveInstance ; } public static NodePropertiesPart getNodePropertiesPart ( ) { if ( NodePropertiesPart . sActiveInstance == null ) { createPart ( ""com . samsung . dali . modelconverter . part . nodeproperties"" ) ; assert NodePropertiesPart . sActiveInstance != null ; } return NodePropertiesPart . sActiveInstance ; } static void createPart ( String id ) { Bundle bundle = FrameworkUtil . getBundle ( EPartService . class ) ; BundleContext bundleContext = bundle . getBundleContext ( ) ; IEclipseContext eclipseContext = EclipseContextFactory . getServiceContext ( bundleContext ) ; EPartService partService = ( EPartService ) eclipseContext . get ( EPartService . class ) ; partService . showPart ( id , PartState . CREATE ) ; } }
","static void createPart ( String id ) {
","static void createPart(String id) {
",,,"static void createPart(String id) {
",,,"public static SceneGraphPart getSceneGraphPart ( ) { if ( SceneGraphPart . sActiveInstance == null ) { createPart ( ""com . samsung . dali . modelconverter . part . scenegraph"" ) ; assert SceneGraphPart . sActiveInstance != null ; } return SceneGraphPart . sActiveInstance ; } public static NodePropertiesPart getNodePropertiesPart ( ) { if ( NodePropertiesPart . sActiveInstance == null ) { createPart ( ""com . samsung . dali . modelconverter . part . nodeproperties"" ) ; assert NodePropertiesPart . sActiveInstance != null ; } return NodePropertiesPart . sActiveInstance ; } static void createPart ( String id ) { Bundle bundle = FrameworkUtil . getBundle ( EPartService . class ) ; BundleContext bundleContext = bundle . getBundleContext ( ) ; IEclipseContext eclipseContext = EclipseContextFactory . getServiceContext ( bundleContext ) ; EPartService partService = ( EPartService ) eclipseContext . get ( EPartService . class ) ; partService . showPart ( id , PartState . CREATE ) ; }
",,,"public static SceneGraphPart getSceneGraphPart ( ) { if ( SceneGraphPart . sActiveInstance == null ) { createPart ( ""com . samsung . dali . modelconverter . part . scenegraph"" ) ; assert SceneGraphPart . sActiveInstance != null ; } return SceneGraphPart . sActiveInstance ; } public static NodePropertiesPart getNodePropertiesPart ( ) { if ( NodePropertiesPart . sActiveInstance == null ) { createPart ( ""com . samsung . dali . modelconverter . part . nodeproperties"" ) ; assert NodePropertiesPart . sActiveInstance != null ; } return NodePropertiesPart . sActiveInstance ; } static void createPart ( String id ) { Bundle bundle = FrameworkUtil . getBundle ( EPartService . class ) ; BundleContext bundleContext = bundle . getBundleContext ( ) ; IEclipseContext eclipseContext = EclipseContextFactory . getServiceContext ( bundleContext ) ; EPartService partService = ( EPartService ) eclipseContext . get ( EPartService . class ) ; partService . showPart ( id , PartState . CREATE ) ; }
",,,"} public static SceneGraphPart getSceneGraphPart ( ) { if ( SceneGraphPart . sActiveInstance == null ) { createPart ( ""com . samsung . dali . modelconverter . part . scenegraph"" ) ; assert SceneGraphPart . sActiveInstance != null ; } return SceneGraphPart . sActiveInstance ; } public static NodePropertiesPart getNodePropertiesPart ( ) { if ( NodePropertiesPart . sActiveInstance == null ) { createPart ( ""com . samsung . dali . modelconverter . part . nodeproperties"" ) ; assert NodePropertiesPart . sActiveInstance != null ; } return NodePropertiesPart . sActiveInstance ; } < |startfocus| > static void createPart ( String id ) { < |endfocus| > Bundle bundle = FrameworkUtil . getBundle ( EPartService . class ) ; BundleContext bundleContext = bundle . getBundleContext ( ) ; IEclipseContext eclipseContext = EclipseContextFactory . getServiceContext ( bundleContext ) ; EPartService partService = ( EPartService ) eclipseContext . get ( EPartService . class ) ; partService . showPart ( id , PartState . CREATE ) ; } }
",,
2110,"kage com . samsung . dali . modelconverter . controller ; import java . util . ArrayList ; import org . eclipse . jface . viewers . ITreeContentProvider ; import com . samsung . dali . modelconverter . data . document . Document ; /* * Provides descriptions of a given list of resources . */ public class ResourceContentProvider implements ITreeContentProvider { public ResourceContentProvider ( Document doc , Class < ? > type ) { mDocument = doc ; mType = type ; } public Object getDocument ( ) { return mDocument ; } /* * Get the top level nodes from an element , which should only be the Document * that the provider was created with . The nodes are meshes . */ @Override public Object [ ] getElements ( Object inputElement ) { assert inputElement == mDocument ; ArrayList < Object > kids = new ArrayList < Object > ( ) ; return kids . toArray ( ) ; } @Override public Object [ ] getChildren ( Object parentElement ) { return null ; } @Override public Object getParent ( Object element ) { return null ; } @Override public boolean hasChildren ( Object element ) { return false ; } private Document mDocument ;
","* Provides descriptions of a given list of resources .
","* Provides descriptions of a given list of resources.
",,,"* Provides descriptions of a given list of resources.
",,,"package com . samsung . dali . modelconverter . controller ; import java . util . ArrayList ; import org . eclipse . jface . viewers . ITreeContentProvider ; import com . samsung . dali . modelconverter . data . document . Document ; public class ResourceContentProvider implements ITreeContentProvider { private Document mDocument ; private Class < ? > mType ; public ResourceContentProvider ( Document document , Class < ? > type ) { mDocument = document ; mType = type ; } @Override public Object [ ] getElements ( Object inputElement ) { assert inputElement == mDocument ; ArrayList < Object > kids = new ArrayList < Object > ( ) ; // Get the top level nodes from an element , which should only be the Document that the provider was created with . The nodes are meshes . return kids . toArray ( ) ; } @Override public Object [ ] getChildren ( Object parentElement ) { return null ; } @Override public Object getParent ( Object element ) { return null ; } @Override public boolean hasChildren ( Object element ) { return false ; } public Object getDocument ( ) { return mDocument ; } }
",,,"package com . samsung . dali . modelconverter . controller ; import java . util . ArrayList ; import org . eclipse . jface . viewers . ITreeContentProvider ; import com . samsung . dali . modelconverter . data . document . Document ; public class ResourceContentProvider implements ITreeContentProvider { private Document mDocument ; private Class < ? > mType ; public ResourceContentProvider ( Document doc , Class < ? > type ) { mDocument = doc ; mType = type ; } public Object getDocument ( ) { return mDocument ; } @Override public Object [ ] getElements ( Object inputElement ) { assert inputElement == mDocument ; ArrayList < Object > kids = new ArrayList < Object > ( ) ; return kids . toArray ( ) ; } @Override public Object [ ] getChildren ( Object parentElement ) { return null ; } @Override public Object getParent ( Object element ) { return null ; } @Override public boolean hasChildren ( Object element ) { return false ; } }
",,,"package com . samsung . dali . modelconverter . controller ; import java . util . ArrayList ; import org . eclipse . jface . viewers . ITreeContentProvider ; import com . samsung . dali . modelconverter . data . document . Document ; /* < |startfocus| > * Provides descriptions of the meshes . < |endfocus| > */ public class ResourceContentProvider implements ITreeContentProvider { public ResourceContentProvider ( Document doc , Class < ? > type ) { mDocument = doc ; mType = type ; } public Object getDocument ( ) { return mDocument ; } /* * Get the top level nodes from an element , which should only be the Document * that the provider was created with . The nodes are meshes . */ @Override public Object [ ] getElements ( Object inputElement ) { assert inputElement == mDocument ; ArrayList < Object > kids = new ArrayList < Object > ( ) ; return kids . toArray ( ) ; } @Override public Object [ ] getChildren ( Object parentElement ) { return null ; } @Override public Object getParent ( Object element ) { return null ; } @Override public boolean hasChildren ( Object element ) { return false ; } private Document mDocument ;
",,
2119,"wrList_recv . add ( recvWR ) ; // it's important to post those receive operations before connecting // otherwise the server may issue a send operation and which cannot be received // this class wraps soem of the RDMA data operations VerbsTools commRdma = new VerbsTools ( context , compChannel , qp , cq ) ; commRdma . initSGRecv ( wrList_recv ) ; // now let's connect to the server RdmaConnParam connParam = new RdmaConnParam ( ) ; connParam . setRetry_count ( ( byte ) 2 ) ; ret = idPriv . connect ( connParam ) ; if ( ret < 0 ) { System . out . println ( ""VerbsClient : : connect failed"" ) ; return ; } // wait until we are really connected cmEvent = cmChannel . getCmEvent ( - 1 ) ; if ( cmEvent == null ) { System . out . println ( ""VerbsClient : : cmEvent null"" ) ; return ; } else if ( cmEvent . getEvent ( ) != RdmaCmEvent . EventType . RDMA_CM_EVENT_ESTABLISHED . ordinal ( ) ) {
","< |del| >/ / connParam . setInitiator_depth ( ( byte ) 5 ) ; // connParam . setResponder_resources ( ( byte ) 5 ) ;
","<|del|>
",,,"<|del|>
",,,"wrList_recv . add ( recvWR ) ; VerbsTools commRdma = new VerbsTools ( context , compChannel , qp , cq ) ; commRdma . initSGRecv ( wrList_recv ) ; RdmaConnParam connParam = new RdmaConnParam ( ) ; connParam . setRetry_count ( ( byte ) 2 ) ; ret = idPriv . connect ( connParam ) ; if ( ret < 0 ) { System . out . println ( ""VerbsClient : : connect failed"" ) ; return ; } cmEvent = cmChannel . getCmEvent ( - 1 ) ; if ( cmEvent == null || cmEvent . getEvent ( ) != RdmaCmEvent . EventType . RDMA_CM_EVENT_ESTABLISHED . ordinal ( ) ) { System . out . println ( ""VerbsClient : : cmEvent null"" ) ; return ; }
",,,"wrList_recv . add ( recvWR ) ; VerbsTools commRdma = new VerbsTools ( context , compChannel , qp , cq ) ; commRdma . initSGRecv ( wrList_recv ) ; RdmaConnParam connParam = new RdmaConnParam ( ) ; connParam . setRetry_count ( ( byte ) 2 ) ; ret = idPriv . connect ( connParam ) ; if ( ret < 0 ) { System . out . println ( ""VerbsClient : : connect failed"" ) ; return ; } cmEvent = cmChannel . getCmEvent ( - 1 ) ; if ( cmEvent == null ) { System . out . println ( ""VerbsClient : : cmEvent null"" ) ; return ; } else if ( cmEvent . getEvent ( ) != RdmaCmEvent . EventType . RDMA_CM_EVENT_ESTABLISHED . ordinal ( ) ) {
",,,"wrList_recv . add ( recvWR ) ; // it's important to post those receive operations before connecting // otherwise the server may issue a send operation and which cannot be received // this class wraps soem of the RDMA data operations VerbsTools commRdma = new VerbsTools ( context , compChannel , qp , cq ) ; commRdma . initSGRecv ( wrList_recv ) ; // now let's connect to the server RdmaConnParam connParam = new RdmaConnParam ( ) ; < |startfocus| > < |endfocus| > connParam . setRetry_count ( ( byte ) 2 ) ; ret = idPriv . connect ( connParam ) ; if ( ret < 0 ) { System . out . println ( ""VerbsClient : : connect failed"" ) ; return ; } // wait until we are really connected cmEvent = cmChannel . getCmEvent ( - 1 ) ; if ( cmEvent == null ) { System . out . println ( ""VerbsClient : : cmEvent null"" ) ; return ; } else if ( cmEvent . getEvent ( ) != RdmaCmEvent . EventType . RDMA_CM_EVENT_ESTABLISHED . ordinal ( ) ) {
",,
2139,"} } if ( aid != null && adn != null ) { throw new Exception ( "" -- issuer - id and -- issuer - dn options are mutually exclusive"" ) ; } MainCLI mainCLI = ( MainCLI ) parent . getParent ( ) ; File certDatabase = mainCLI . certDatabase ; String password = mainCLI . config . getCertPassword ( ) ; if ( password == null ) { throw new Exception ( ""Missing security database password . "" ) ; } String csr ; PKIClient client ; if ( ""pkcs10"" . equals ( requestType ) ) { if ( ""rsa"" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , Integer . toString ( length ) , subjectDN ) ; } else if ( ""ecc"" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , curve , subjectDN ) ; } else { throw new Exception ( ""Invalid algorithm specified . "" ) ; } // initialize database after PKCS10Client to avoid conflict mainCLI . init ( ) ; client = getClient ( ) ; } else if ( ""crmf"" . equals ( requestType ) ) { // initialize database before CRMFPopClient to load transport certificate
","if ( ""rsa"" . equals ( algorithm ) ) {
","if (""rsa"".equals(algorithm)) {
",,,"if (""rsa"".equals(algorithm)) {
",,,"} if ( aid != null && adn != null ) { throw new Exception ( "" -- issuer - id and -- issuer - dn options are mutually exclusive"" ) ; } MainCLI mainCLI = ( MainCLI ) parent . getParent ( ) ; File certDatabase = mainCLI . certDatabase ; String password = mainCLI . config . getCertPassword ( ) ; if ( password == null ) { throw new Exception ( ""Missing security database password . "" ) ; } String csr ; PKIClient client ; if ( ""pkcs10"" . equals ( requestType ) ) { if ( ""rsa"" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , Integer . toString ( length ) , subjectDN ) ; } else if ( ""ecc"" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , curve , subjectDN ) ; } else { throw new Exception ( ""Invalid algorithm specified . "" ) ; } // initialize database after PKCS10Client to avoid conflict mainCLI . init ( ) ; client = getClient ( ) ; } else if ( ""crmf"" . equals ( requestType ) ) { // initialize database before CRMFPopClient to load transport certificate mainCLI . init ( ) ; client = getClient ( ) ; }
",,,"} } if ( aid != null && adn != null ) { throw new Exception ( "" -- issuer - id and -- issuer - dn options are mutually exclusive"" ) ; } MainCLI mainCLI = ( MainCLI ) parent . getParent ( ) ; File certDatabase = mainCLI . certDatabase ; String password = mainCLI . config . getCertPassword ( ) ; if ( password == null ) { throw new Exception ( ""Missing security database password . "" ) ; } String csr ; PKIClient client ; if ( ""pkcs10"" . equals ( requestType ) ) { if ( ""rsa"" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , Integer . toString ( length ) , subjectDN ) ; } else if ( ""ecc"" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , curve , subjectDN ) ; } else { throw new Exception ( ""Invalid algorithm specified . "" ) ; } // initialize database after PKCS10Client to avoid conflict mainCLI . init ( ) ; client = getClient ( ) ; } else if ( ""crmf"" . equals ( requestType ) ) { // initialize database before CRMFPopClient to load transport certificate
",,,"} } if ( aid != null && adn != null ) { throw new Exception ( "" -- issuer - id and -- issuer - dn options are mutually exclusive"" ) ; } MainCLI mainCLI = ( MainCLI ) parent . getParent ( ) ; File certDatabase = mainCLI . certDatabase ; String password = mainCLI . config . getCertPassword ( ) ; if ( password == null ) { throw new Exception ( ""Missing security database password . "" ) ; } String csr ; PKIClient client ; if ( ""pkcs10"" . equals ( requestType ) ) { < |startfocus| > if ( ""rsa"" . equals ( algorithm ) ) { < |endfocus| > csr = generatePkcs10Request ( certDatabase , password , algorithm , Integer . toString ( length ) , subjectDN ) ; } else if ( ""ecc"" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , curve , subjectDN ) ; } else { throw new Exception ( ""Invalid algorithm specified . "" ) ; } // initialize database after PKCS10Client to avoid conflict mainCLI . init ( ) ; client = getClient ( ) ; } else if ( ""crmf"" . equals ( requestType ) ) { // initialize database before CRMFPopClient to load transport certificate
",,
2146,"* * But we do still want to check that the input looks something * like a profile configuration . So we use java . util . Properties * to do that . */ public static void checkConfiguration ( byte [ ] in , boolean requireProfileId , boolean requireDisabled ) throws PKIException { Properties p = new Properties ( ) ; try { p . load ( new ByteArrayInputStream ( in ) ) ; } catch ( IOException e ) { throw new PKIException ( ""Failed to parse profile configuration"" , e ) ; } if ( requireProfileId && p . getProperty ( ""profileId"" ) == null ) throw new PKIException ( ""Missing profileId property in profile data . "" ) ; String enabled = p . getProperty ( ""enable"" ) ; if ( requireDisabled && Boolean . valueOf ( enabled ) ) { throw new PKIException ( ""Cannot edit profile . Profile must be disabled . "" ) ; } } public static void saveEnrollmentTemplateToFile ( String filename , CertEnrollmentRequest request ) throws JAXBException , FileNotFoundException { JAXBContext context = JAXBContext . newInstance ( CertEnrollmentRequest . class ) ; Marshaller marshaller = context . createMarshaller ( ) ;
","throw new PKIException ( ""Failed to parse profile configuration"" , e ) ;
","throw new PKIException(""Failed to parse profile configuration"", e);
",,,"throw new PKIException(""Failed to parse profile configuration"", e);
",,,"public static void checkConfiguration ( byte [ ] in , boolean requireProfileId , boolean requireDisabled ) throws PKIException { Properties p = new Properties ( ) ; try { p . load ( new ByteArrayInputStream ( in ) ) ; } catch ( IOException e ) { throw new PKIException ( ""Failed to parse profile configuration"" , e ) ; } if ( requireProfileId && p . getProperty ( ""profileId"" ) == null ) { throw new PKIException ( ""Missing profileId property in profile data . "" ) ; } String enabled = p . getProperty ( ""enable"" ) ; if ( requireDisabled && Boolean . valueOf ( enabled ) ) { throw new PKIException ( ""Cannot edit profile . Profile must be disabled . "" ) ; } } public static void saveEnrollmentTemplateToFile ( String filename , CertEnrollmentRequest request ) throws JAXBException , FileNotFoundException { JAXBContext context = JAXBContext . newInstance ( CertEnrollmentRequest . class ) ; Marshaller marshaller = context . createMarshaller ( ) ; marshaller . marshal ( request , new FileOutputStream ( filename ) ) ; }
",,,"private static Properties readProperties ( ) throws IOException { FileInputStream in = new FileInputStream ( "" / etc / pki / pki . conf"" ) ; Properties props = new Properties ( ) ; props . load ( in ) ; return props ; } public void setVerbose ( boolean verbose ) { this . verbose = verbose ; } public boolean isVerbose ( ) { return verbose ; } public KeyPair generateECCKeyPair ( CryptoToken token , String curve , boolean sslECDH , boolean temporary , int sensitive , int extractable ) throws Exception { org . mozilla . jss . crypto . KeyPairGeneratorSpi . Usage [ ] usagesMaskECDH = { org . mozilla . jss . crypto . KeyPairGeneratorSpi . Usage . SIGN , . . . } ; // Rest of the code } if ( password == null ) { throw new Exception ( ""Missing security database password . "" ) ; } String csr ; PKIClient client ; if ( ""pkcs10"" . equals ( requestType ) ) { if ( ""rsa"" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , Integer . toString ( length ) , subjectDN ) ; } else if ( ""ecc"" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , curve , subjectDN ) ; } else { throw new Exception ( ""Invalid algorithm : "" + algorithm ) ; } mainCLI . init ( ) ; client = getClient ( ) ; } else if ( ""crmf"" . equals ( requestType ) ) { mainCLI . init ( ) ; client = getClient ( ) ; String encoded ; if ( transportCertFilename == null ) { SystemCertClient certClient = new SystemCertClient ( client , ""ca"" ) ; encoded = certClient . getTransportCert ( ) . getEncoded ( ) ; } else { encoded = new String ( Files . readAllBytes ( Paths . get ( transportCertFilename ) ) ) ; } // Rest of the code } public static void checkConfiguration ( byte [ ] in , boolean requireProfileId , boolean requireDisabled ) throws PKIException { Properties p = new Properties ( ) ; try { p . load ( new ByteArrayInputStream ( in ) ) ; } catch ( IOException e ) { throw new PKIException ( ""Failed to parse profile configuration : "" + e . toString ( ) ) ; } if ( requireProfileId && p . getProperty ( ""profileId"" ) == null ) { throw new PKIException ( ""Missing profileId property in profile data . "" ) ; } String enabled = p . getProperty ( ""enable"" ) ; if ( requireDisabled && Boolean . valueOf ( enabled ) ) { throw new PKIException ( ""Cannot edit profile
",,,"* * But we do still want to check that the input looks something * like a profile configuration . So we use java . util . Properties * to do that . */ public static void checkConfiguration ( byte [ ] in , boolean requireProfileId , boolean requireDisabled ) throws PKIException { Properties p = new Properties ( ) ; try { p . load ( new ByteArrayInputStream ( in ) ) ; } catch ( IOException e ) { < |startfocus| > throw new PKIException ( ""Failed to parse profile configuration : "" + e . toString ( ) , e ) ; < |endfocus| > } if ( requireProfileId && p . getProperty ( ""profileId"" ) == null ) throw new PKIException ( ""Missing profileId property in profile data . "" ) ; String enabled = p . getProperty ( ""enable"" ) ; if ( requireDisabled && Boolean . valueOf ( enabled ) ) { throw new PKIException ( ""Cannot edit profile . Profile must be disabled . "" ) ; } } public static void saveEnrollmentTemplateToFile ( String filename , CertEnrollmentRequest request ) throws JAXBException , FileNotFoundException { JAXBContext context = JAXBContext . newInstance ( CertEnrollmentRequest . class ) ; Marshaller marshaller = context . createMarshaller ( ) ;
",,
2155,"Optional < Checker > checker = getChecker ( checkerUuid ) ; checkState ( checker . isPresent ( ) , ""Tried to get a non - existing test checker as CheckerInfo"" ) ; return checkerJson . format ( checker . get ( ) ) ; } public TestCheckerUpdate . Builder forUpdate ( ) { return TestCheckerUpdate . builder ( this : : updateChecker ) ; } private void updateChecker ( TestCheckerUpdate testCheckerUpdate ) throws Exception { CheckerUpdate checkerUpdate = toCheckerUpdate ( testCheckerUpdate ) ; checkersUpdate . updateChecker ( checkerUuid , checkerUpdate ) ; if ( testCheckerUpdate . forceInvalidConfig ( ) ) { try ( Repository repo = repoManager . openRepository ( allProjectsName ) ) { new TestRepository < > ( repo ) . branch ( CheckerRef . refsCheckers ( checkerUuid ) ) . commit ( ) . add ( CheckerConfig . CHECKER_CONFIG_FILE , ""invalid - config"" ) . create ( ) ; } } } private CheckerUpdate toCheckerUpdate ( TestCheckerUpdate checkerUpdate ) { CheckerUpdate . Builder builder = CheckerUpdate . builder ( ) ; checkerUpdate . name ( ) . ifPresent ( builder : : setName ) ; checkerUpdate . description ( ) . ifPresent ( builder : : setDescription ) ; checkerUpdate . url ( ) . ifPresent ( builder : : setUrl ) ;
","if ( testCheckerUpdate . forceInvalidConfig ( ) ) {
","if (testCheckerUpdate.forceInvalidConfig().orElse(false)) {
",,,"if (testCheckerUpdate.forceInvalidConfig().orElse(true)) {
",,,"Optional < Checker > checker = getChecker ( checkerUuid ) ; checkState ( checker . isPresent ( ) , ""Tried to get a non - existing test checker as CheckerInfo"" ) ; return checkerJson . format ( checker . get ( ) ) ; public TestCheckerUpdate . Builder forUpdate ( ) { return TestCheckerUpdate . builder ( this : : updateChecker ) ; } private void updateChecker ( TestCheckerUpdate testCheckerUpdate ) throws Exception { CheckerUpdate checkerUpdate = toCheckerUpdate ( testCheckerUpdate ) ; checkersUpdate . updateChecker ( checkerUuid , checkerUpdate ) ; if ( testCheckerUpdate . forceInvalidConfig ( ) . orElse ( false ) ) { try ( Repository repo = repoManager . openRepository ( allProjectsName ) ) { new TestRepository < > ( repo ) . branch ( CheckerRef . refsCheckers ( checkerUuid ) ) . commit ( ) . add ( CheckerConfig . CHECKER_CONFIG_FILE , ""invalid - config"" ) . create ( ) ; } } } private CheckerUpdate toCheckerUpdate ( TestCheckerUpdate checkerUpdate ) { CheckerUpdate . Builder builder = CheckerUpdate . builder ( ) ; checkerUpdate . name ( ) . ifPresent ( builder : : setName ) ; checkerUpdate . description ( ) . ifPresent ( builder : : setDescription ) ; checkerUpdate . url ( ) . ifPresent ( builder : : setUrl ) ; return builder . build ( ) ; }
",,,"Optional < Checker > checker = getChecker ( checkerUuid ) ; checkState ( checker . isPresent ( ) , ""Tried to get a non - existing test checker as CheckerInfo"" ) ; return checkerJson . format ( checker . get ( ) ) ; public TestCheckerUpdate . Builder forUpdate ( ) { return TestCheckerUpdate . builder ( this : : updateChecker ) ; } private void updateChecker ( TestCheckerUpdate testCheckerUpdate ) throws Exception { CheckerUpdate checkerUpdate = toCheckerUpdate ( testCheckerUpdate ) ; checkersUpdate . updateChecker ( checkerUuid , checkerUpdate ) ; if ( testCheckerUpdate . forceInvalidConfig ( ) . orElse ( false ) ) { try ( Repository repo = repoManager . openRepository ( allProjectsName ) ) { new TestRepository < > ( repo ) . branch ( CheckerRef . refsCheckers ( checkerUuid ) ) . commit ( ) . add ( CheckerConfig . CHECKER_CONFIG_FILE , ""invalid - config"" ) . create ( ) ; } } } private CheckerUpdate toCheckerUpdate ( TestCheckerUpdate checkerUpdate ) { CheckerUpdate . Builder builder = CheckerUpdate . builder ( ) ; checkerUpdate . name ( ) . ifPresent ( builder : : setName ) ; checkerUpdate . description ( ) . ifPresent ( builder : : setDescription ) ; checkerUpdate . url ( ) . ifPresent ( builder : : setUrl ) ; }
",,,"public TestCheckerUpdate . Builder forUpdate ( ) { return TestCheckerUpdate . builder ( this : : updateChecker ) ; } private void updateChecker ( TestCheckerUpdate testCheckerUpdate ) throws Exception { CheckerUpdate checkerUpdate = toCheckerUpdate ( testCheckerUpdate ) ; checkersUpdate . updateChecker ( checkerUuid , checkerUpdate ) ; < |startfocus| > if ( testCheckerUpdate . forceInvalidConfig ( ) . orElse ( false ) ) { < |endfocus| > try ( Repository repo = repoManager . openRepository ( allProjectsName ) ) { new TestRepository < > ( repo ) . branch ( CheckerRef . refsCheckers ( checkerUuid ) ) . commit ( ) . add ( CheckerConfig . CHECKER_CONFIG_FILE , ""invalid - config"" ) . create ( ) ; } } } private CheckerUpdate toCheckerUpdate ( TestCheckerUpdate checkerUpdate ) { CheckerUpdate . Builder builder = CheckerUpdate . builder ( ) ; checkerUpdate . name ( ) . ifPresent ( builder : : setName ) ; checkerUpdate . description ( ) . ifPresent ( builder : : setDescription ) ; checkerUpdate . url ( ) . ifPresent ( builder : : setUrl ) ;
",,
2160,"private final Counter0 timeouts ; @Inject Metrics ( MetricMaker metricMaker ) { changes = metricMaker . newHistogram ( ""receivecommits / changes"" , new Description ( ""number of changes uploaded in a single push . "" ) . setCumulative ( ) , Field . ofEnum ( ResultChangeIds . Key . class , ""type"" , ""type of push ( replace , create , autoclose ) "" ) ) ; latencyPerChange = metricMaker . newTimer ( ""receivecommits / latency"" , new Description ( ""Processing delay per push divided by the number of changes in said push . ( Only includes pushes which contain changes . ) "" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( ""type"" , ""type of push ( create / replace , autoclose ) "" ) ) ; latencyPerPush = metricMaker . newTimer ( ""receivecommits / push_latency"" , new Description ( ""processing delay for a processing single push"" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( ""type"" , ""type of push ( create / replace , autoclose , normal ) "" ) ) ; timeouts = metricMaker . newCounter ( ""receivecommits / timeout"" , new Description ( ""rate of push timeouts"" ) . setRate ( ) ) ;
","""Processing delay per push divided by the number of changes in said push . ( Only includes pushes which contain changes . ) "" )
","""Processing delay per push divided by the number of changes in said push."")
",,,"""Processing delay per push divided by the number of changes in a push."")
",,,"private final Counter0 timeouts ; @Inject Metrics ( MetricMaker metricMaker ) { changes = metricMaker . newHistogram ( ""receivecommits / changes"" , new Description ( ""Number of changes uploaded in a single push . "" ) . setCumulative ( ) , Field . ofEnum ( ResultChangeIds . Key . class , ""type"" , ""Type of push ( replace , create , autoclose ) "" ) ) ; latencyPerChange = metricMaker . newTimer ( ""receivecommits / latency"" , new Description ( ""Processing delay per push divided by the number of changes in said push . ( Only includes pushes which contain changes . ) "" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( ""type"" , ""Type of push ( create / replace , autoclose ) "" ) ) ; latencyPerPush = metricMaker . newTimer ( ""receivecommits / push_latency"" , new Description ( ""Processing delay for a processing single push"" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( ""type"" , ""Type of push ( create / replace , autoclose , normal ) "" ) ) ; timeouts = metricMaker . newCounter ( ""receivecommits / timeout"" , new Description ( ""Rate of push timeouts"" ) . setRate ( ) ) ; }
",,,"private final Counter0 timeouts ; @Inject Metrics ( MetricMaker metricMaker ) { changes = metricMaker . newHistogram ( ""receivecommits / changes"" , new Description ( ""Number of changes uploaded in a single push . "" ) . setCumulative ( ) , Field . ofEnum ( ResultChangeIds . Key . class , ""type"" , ""Type of push ( replace , create , autoclose ) "" ) ) ; latencyPerChange = metricMaker . newTimer ( ""receivecommits / latency"" , new Description ( ""Processing delay per push , averaged over the updated changes in a push . "" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( ""type"" , ""Type of push ( create / replace , autoclose ) "" ) ) ; latencyPerPush = metricMaker . newTimer ( ""receivecommits / push_latency"" , new Description ( ""Processing delay for a single push"" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( ""type"" , ""Type of push ( create / replace , autoclose , normal ) "" ) ) ; timeouts = metricMaker . newCounter ( ""receivecommits / timeout"" , new Description ( ""Rate of push timeouts"" ) . setRate ( ) ) ; }
",,,"private final Counter0 timeouts ; @Inject Metrics ( MetricMaker metricMaker ) { changes = metricMaker . newHistogram ( ""receivecommits / changes"" , new Description ( ""number of changes uploaded in a single push . "" ) . setCumulative ( ) , Field . ofEnum ( ResultChangeIds . Key . class , ""type"" , ""type of push ( replace , create , autoclose ) "" ) ) ; latencyPerChange = metricMaker . newTimer ( ""receivecommits / latency"" , new Description ( < |startfocus| > ""processing delay per push divided by the number of changes in said push . ( Only includes pushes which contain changes . ) "" ) < |endfocus| > . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( ""type"" , ""type of push ( create / replace , autoclose ) "" ) ) ; latencyPerPush = metricMaker . newTimer ( ""receivecommits / push_latency"" , new Description ( ""processing delay for a processing single push"" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( ""type"" , ""type of push ( create / replace , autoclose , normal ) "" ) ) ; timeouts = metricMaker . newCounter ( ""receivecommits / timeout"" , new Description ( ""rate of push timeouts"" ) . setRate ( ) ) ;
",,
2161,"private static ProjectAccessInput createAccessInput ( String accessSection , String permissionName ) { ProjectAccessInput accessInput = new ProjectAccessInput ( ) ; PermissionRuleInfo ruleInfo = new PermissionRuleInfo ( PermissionRuleInfo . Action . ALLOW , false ) ; PermissionInfo email = new PermissionInfo ( null , null ) ; email . rules = ImmutableMap . of ( SystemGroupBackend . REGISTERED_USERS . get ( ) , ruleInfo ) ; AccessSectionInfo accessSectionInfo = new AccessSectionInfo ( ) ; accessSectionInfo . permissions = ImmutableMap . of ( permissionNameInConfig , email ) ; accessInput . add = ImmutableMap . of ( accessSection , accessSectionInfo ) ; return accessInput ;
","private static ProjectAccessInput createAccessInput ( String accessSection , String permissionName ) {
","private static ProjectAccessInput createAccessInput( String accessSection, String permissionName) {
",,,"private static ProjectAccessInput createAccessInput(String accessSection, String permissionName) {
",,,"private static ProjectAccessInput createAccessInput ( String accessSection , String permissionName ) { ProjectAccessInput accessInput = new ProjectAccessInput ( ) ; PermissionRuleInfo ruleInfo = new PermissionRuleInfo ( PermissionRuleInfo . Action . ALLOW , false ) ; PermissionInfo email = new PermissionInfo ( null , null ) ; email . rules = ImmutableMap . of ( SystemGroupBackend . REGISTERED_USERS . get ( ) , ruleInfo ) ; AccessSectionInfo accessSectionInfo = new AccessSectionInfo ( ) ; accessSectionInfo . permissions = ImmutableMap . of ( permissionName , email ) ; accessInput . add = ImmutableMap . of ( accessSection , accessSectionInfo ) ; return accessInput ; }
",,,"private static ProjectAccessInput createAccessInput ( String accessSection , String permissionName ) { ProjectAccessInput accessInput = new ProjectAccessInput ( ) ; PermissionRuleInfo ruleInfo = new PermissionRuleInfo ( PermissionRuleInfo . Action . ALLOW , false ) ; PermissionInfo email = new PermissionInfo ( null , null ) ; email . rules = ImmutableMap . of ( SystemGroupBackend . REGISTERED_USERS . get ( ) , ruleInfo ) ; AccessSectionInfo accessSectionInfo = new AccessSectionInfo ( ) ; accessSectionInfo . permissions = ImmutableMap . of ( permissionName , email ) ; accessInput . add = ImmutableMap . of ( accessSection , accessSectionInfo ) ; return accessInput ; }
",,,"< |startfocus| > private static ProjectAccessInput createAccessInput ( String accessSection , String permissionName ) { < |endfocus| > ProjectAccessInput accessInput = new ProjectAccessInput ( ) ; PermissionRuleInfo ruleInfo = new PermissionRuleInfo ( PermissionRuleInfo . Action . ALLOW , false ) ; PermissionInfo email = new PermissionInfo ( null , null ) ; email . rules = ImmutableMap . of ( SystemGroupBackend . REGISTERED_USERS . get ( ) , ruleInfo ) ; AccessSectionInfo accessSectionInfo = new AccessSectionInfo ( ) ; accessSectionInfo . permissions = ImmutableMap . of ( permissionName , email ) ; accessInput . add = ImmutableMap . of ( accessSection , accessSectionInfo ) ; return accessInput ;
",,
2177,"if ( cache == null ) { throw new CacheNotFoundException ( entry . getPluginName ( ) , entry . getCacheName ( ) ) ; } try { Context . setForwardedEvent ( true ) ; if ( Constants . PROJECT_LIST . equals ( entry . getCacheName ( ) ) ) { // One key is holding the list of projects cache . invalidateAll ( ) ; multisiteLog . debug ( ""Invalidated cache { } "" , entry . getCacheName ( ) ) ; } else { cache . invalidate ( entry . getKey ( ) ) ; log . debug ( ""Invalidated cache { } [ { } ] "" , entry . getCacheName ( ) , entry . getKey ( ) ) ; } } finally { Context . unsetForwardedEvent ( ) ; } } }
","log . debug ( ""Invalidated cache { } [ { } ] "" , entry . getCacheName ( ) , entry . getKey ( ) ) ;
","multisiteLog.error(""Invalidated cache {}[{}]"", entry.getCacheName(), entry.getKey());
",,,"multisiteLog.debug( ""Invalidated cache {}[{}]"", entry.getCacheName(), entry.getKey());
",,,"if ( cache == null ) { throw new CacheNotFoundException ( entry . getPluginName ( ) , entry . getCacheName ( ) ) ; } try { Context . setForwardedEvent ( true ) ; if ( Constants . PROJECT_LIST . equals ( entry . getCacheName ( ) ) ) { cache . invalidateAll ( ) ; multisiteLog . debug ( ""Invalidated cache { } "" , entry . getCacheName ( ) ) ; } else { cache . invalidate ( entry . getKey ( ) ) ; multisiteLog . debug ( ""Invalidated cache { } [ { } ] "" , entry . getCacheName ( ) , entry . getKey ( ) ) ; } } finally { Context . unsetForwardedEvent ( ) ; }
",,,"Buggy public CachedPage ( int cpid , ByteBuffer buffer , IPageReplacementStrategy pageReplacementStrategy ) { this . cpid = cpid ; this . buffer = buffer ; this . pageReplacementStrategy = pageReplacementStrategy ; pinCount = new AtomicInteger ( ) ; dirty = new AtomicBoolean ( ) ; latch = new ReentrantReadWriteLock ( true ) ; replacementStrategyObject = pageReplacementStrategy . createPerPageStrategyObject ( cpid ) ; dpid = - 1 ; valid = false ; confiscated = new AtomicBoolean ( false ) ; queueInfo = null ; ctorStack = new Throwable ( ) . getStackTrace ( ) ; } public CachedPage ( int cpid , ByteBuffer buffer , IPageReplacementStrategy pageReplacementStrategy ) { this . cpid = cpid ; this . buffer = buffer ; this . pageReplacementStrategy = pageReplacementStrategy ; pinCount = new AtomicInteger ( ) ; dirty = new AtomicBoolean ( ) ; latch = new ReentrantReadWriteLock ( true ) ; replacementStrategyObject = pageReplacementStrategy . createPerPageStrategyObject ( cpid ) ; dpid = - 1 ; valid = false ; confiscated = new AtomicBoolean ( false ) ; queueInfo = null ; }
",,,"if ( cache == null ) { throw new CacheNotFoundException ( entry . getPluginName ( ) , entry . getCacheName ( ) ) ; } try { Context . setForwardedEvent ( true ) ; if ( Constants . PROJECT_LIST . equals ( entry . getCacheName ( ) ) ) { // One key is holding the list of projects cache . invalidateAll ( ) ; multisiteLog . debug ( ""Invalidated cache { } "" , entry . getCacheName ( ) ) ; } else { cache . invalidate ( entry . getKey ( ) ) ; < |startfocus| > multisiteLog . debug ( ""Invalidated cache { } [ { } ] "" , entry . getCacheName ( ) , entry . getKey ( ) ) ; < |endfocus| > } } finally { Context . unsetForwardedEvent ( ) ; } } }
",,
2189,"Copyright ( C ) 2019 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . server . git . validators . RefOperationValidationListener ; import com . google . inject . AbstractModule ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . NoOpDfsRefDatabase ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . SharedRefDatabase ; public class ValidationModule extends AbstractModule { @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ;
","Copyright ( C ) 2019 The Android Open Source Project
","Copyright (C) 2019 The Android Open Source Project
",,,"Copyright (C) 2019 The Android Open Source Project
",,,"// Copyright ( C ) 2018 The Android Open Source Project // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . server . git . validators . RefOperationValidationListener ; import com . google . inject . AbstractModule ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . NoOpDfsRefDatabase ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . SharedRefDatabase ; public class ValidationModule extends AbstractModule { @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ; } }
",,,"Copyright ( C ) 2019 The Android Open Source Project // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . server . git . validators . RefOperationValidationListener ; import com . google . inject . AbstractModule ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . NoOpDfsRefDatabase ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . SharedRefDatabase ; public class ValidationModule extends AbstractModule { @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ; } }
",,,"< |startfocus| > Copyright ( C ) 2018 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . server . git . validators . RefOperationValidationListener ; import com . google . inject . AbstractModule ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . NoOpDfsRefDatabase ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . SharedRefDatabase ; public class ValidationModule extends AbstractModule { @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ;
",,
2203,"import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . Singleton ; import java . util . List ; import java . util . stream . Stream ; @Singleton public class PendingChecksImpl implements PendingChecks { private final Provider < ListPendingChecks > listPendingChecksProvider ; @Inject PendingChecksImpl ( Provider < ListPendingChecks > listPendingChecksProvider ) { this . listPendingChecksProvider = listPendingChecksProvider ; } @Override public List < PendingChecksInfo > list ( String checkerUuidString , CheckState . . . checkStates ) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider . get ( ) ; listPendingChecks . setChecker ( checkerUuid ) ; if ( checkStates != null ) { Stream . of ( checkStates ) . forEach ( listPendingChecks : : addState ) ; } return listPendingChecks . apply ( TopLevelResource . INSTANCE ) ; } catch ( Exception e ) { throw asRestApiException ( ""Cannot list pending checks"" , e ) ; } } @Override
","< |del| > CheckerUuid checkerUuid = CheckerUuid . tryParse ( checkerUuidString ) . orElseThrow ( ( ) - > new BadRequestException ( String . format ( ""invalid checker UUID : % s"" , checkerUuidString ) ) ) ;
","List<PendingChecksInfo> list(CheckerUuid, CheckState... checkStates) throws RestApiException {
",,,"<|del|>
",,,"import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . Singleton ; import java . util . List ; import java . util . stream . Stream ; @Singleton public class PendingChecksImpl implements PendingChecks { private final Provider < ListPendingChecks > listPendingChecksProvider ; @Inject PendingChecksImpl ( Provider < ListPendingChecks > listPendingChecksProvider ) { this . listPendingChecksProvider = listPendingChecksProvider ; } @Override public List < PendingChecksInfo > list ( CheckerUuid checkerUuid , CheckState . . . checkStates ) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider . get ( ) ; listPendingChecks . setChecker ( checkerUuid ) ; if ( checkStates != null ) { Stream . of ( checkStates ) . forEach ( listPendingChecks : : addState ) ; } return listPendingChecks . apply ( TopLevelResource . INSTANCE ) ; } catch ( Exception e ) { throw asRestApiException ( ""Cannot list pending checks"" , e ) ; } } }
",,,"import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . Singleton ; import java . util . List ; import java . util . stream . Stream ; @Singleton public class PendingChecksImpl implements PendingChecks { private final Provider < ListPendingChecks > listPendingChecksProvider ; @Inject PendingChecksImpl ( Provider < ListPendingChecks > listPendingChecksProvider ) { this . listPendingChecksProvider = listPendingChecksProvider ; } @Override public List < PendingChecksInfo > list ( String checkerUuidString , CheckState . . . checkStates ) throws RestApiException { CheckerUuid checkerUuid = CheckerUuid . tryParse ( checkerUuidString ) . orElseThrow ( ( ) - > new BadRequestException ( String . format ( ""invalid checker UUID : % s"" , checkerUuidString ) ) ) ; try { ListPendingChecks listPendingChecks = listPendingChecksProvider . get ( ) ; listPendingChecks . setChecker ( checkerUuid ) ; if ( checkStates != null ) { Stream . of ( checkStates ) . forEach ( listPendingChecks : : addState ) ; } return listPendingChecks . apply ( TopLevelResource . INSTANCE ) ; } catch ( Exception e ) { throw asRestApiException ( ""Cannot list pending checks"" , e ) ; } } @Override // other methods }
",,,"import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . Singleton ; import java . util . List ; import java . util . stream . Stream ; @Singleton public class PendingChecksImpl implements PendingChecks { private final Provider < ListPendingChecks > listPendingChecksProvider ; @Inject PendingChecksImpl ( Provider < ListPendingChecks > listPendingChecksProvider ) { this . listPendingChecksProvider = listPendingChecksProvider ; } @Override public List < PendingChecksInfo > list ( String checkerUuidString , CheckState . . . checkStates ) throws RestApiException { < |startfocus| > CheckerUuid checkerUuid = CheckerUuid . tryParse ( checkerUuidString ) . orElseThrow ( ( ) - > new BadRequestException ( String . format ( ""invalid checker UUID : % s"" , checkerUuidString ) ) ) ; < |endfocus| > return list ( checkerUuid , checkStates ) ; } @Override public List < PendingChecksInfo > list ( CheckerUuid checkerUuid , CheckState . . . checkStates ) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider . get ( ) ; listPendingChecks . setChecker ( checkerUuid ) ; if ( checkStates != null ) { Stream . of ( checkStates ) . forEach ( listPendingChecks : : addState ) ; } return listPendingChecks . apply ( TopLevelResource . INSTANCE ) ; } catch ( Exception e ) { throw asRestApiException ( ""Cannot list pending checks"" , e ) ; } } @Override
",,
2215,"} finally { w . sendMessages ( ) ; } long deltaNanos = System . nanoTime ( ) - startNanos ; int totalChanges = 0 ; String pushType ; if ( resultChangeIds . isMagicPush ( ) ) { pushType = ""CREATE_REPLACE"" ; List < Change . Id > created = resultChangeIds . get ( ResultChangeIds . Key . CREATED ) ; List < Change . Id > replaced = resultChangeIds . get ( ResultChangeIds . Key . REPLACED ) ; metrics . changes . record ( pushType , created . size ( ) + replaced . size ( ) ) ; totalChanges = replaced . size ( ) + created . size ( ) ; } else { List < Change . Id > autoclosed = resultChangeIds . get ( ResultChangeIds . Key . AUTOCLOSED ) ; if ( ! autoclosed . isEmpty ( ) ) { pushType = ResultChangeIds . Key . AUTOCLOSED . name ( ) ; metrics . changes . record ( ResultChangeIds . Key . AUTOCLOSED . name ( ) , autoclosed . size ( ) ) ; totalChanges += autoclosed . size ( ) ; } else { pushType = ""NORMAL"" ; } } if ( totalChanges > 0 ) { metrics . latencyPerChange . record ( pushType , deltaNanos / totalChanges , NANOSECONDS ) ; } metrics . latencyPerPush . record ( pushType , deltaNanos , NANOSECONDS ) ;
","totalChanges = replaced . size ( ) + created . size ( ) ;
","totalChanges += replaced.size() + created.size();
",,,"totalChanges += replaced.size() + created.size();
",,,"} finally { w . sendMessages ( ) ; } long deltaNanos = System . nanoTime ( ) - startNanos ; int totalChanges = 0 ; String pushType ; if ( resultChangeIds . isMagicPush ( ) ) { pushType = ""CREATE_REPLACE"" ; List < Change . Id > created = resultChangeIds . get ( ResultChangeIds . Key . CREATED ) ; List < Change . Id > replaced = resultChangeIds . get ( ResultChangeIds . Key . REPLACED ) ; metrics . changes . record ( pushType , created . size ( ) + replaced . size ( ) ) ; totalChanges = replaced . size ( ) + created . size ( ) ; } else { List < Change . Id > autoclosed = resultChangeIds . get ( ResultChangeIds . Key . AUTOCLOSED ) ; if ( ! autoclosed . isEmpty ( ) ) { pushType = ResultChangeIds . Key . AUTOCLOSED . name ( ) ; metrics . changes . record ( pushType , autoclosed . size ( ) ) ; totalChanges = autoclosed . size ( ) ; } else { pushType = ""NORMAL"" ; } } if ( totalChanges > 0 ) { metrics . latencyPerChange . record ( pushType , deltaNanos / totalChanges , NANOSECONDS ) ; } metrics . latencyPerPush . record ( pushType , deltaNanos , NANOSECONDS ) ;
",,,"} finally { w . sendMessages ( ) ; } long deltaNanos = System . nanoTime ( ) - startNanos ; int totalChanges = 0 ; String pushType ; if ( resultChangeIds . isMagicPush ( ) ) { pushType = ""CREATE_REPLACE"" ; List < Change . Id > created = resultChangeIds . get ( ResultChangeIds . Key . CREATED ) ; List < Change . Id > replaced = resultChangeIds . get ( ResultChangeIds . Key . REPLACED ) ; metrics . changes . record ( pushType , created . size ( ) + replaced . size ( ) ) ; totalChanges = replaced . size ( ) + created . size ( ) ; } else { List < Change . Id > autoclosed = resultChangeIds . get ( ResultChangeIds . Key . AUTOCLOSED ) ; if ( ! autoclosed . isEmpty ( ) ) { pushType = ResultChangeIds . Key . AUTOCLOSED . name ( ) ; metrics . changes . record ( ResultChangeIds . Key . AUTOCLOSED . name ( ) , autoclosed . size ( ) ) ; totalChanges = autoclosed . size ( ) ; } else { pushType = ""NORMAL"" ; } } if ( totalChanges > 0 ) { metrics . latencyPerChange . record ( pushType , deltaNanos / totalChanges , NANOSECONDS ) ; } metrics . latencyPerPush . record ( pushType , deltaNanos , NANOSECONDS ) ;
",,,"} finally { w . sendMessages ( ) ; } long deltaNanos = System . nanoTime ( ) - startNanos ; int totalChanges = 0 ; String pushType ; if ( resultChangeIds . isMagicPush ( ) ) { pushType = ""CREATE_REPLACE"" ; List < Change . Id > created = resultChangeIds . get ( ResultChangeIds . Key . CREATED ) ; List < Change . Id > replaced = resultChangeIds . get ( ResultChangeIds . Key . REPLACED ) ; metrics . changes . record ( pushType , created . size ( ) + replaced . size ( ) ) ; < |startfocus| > totalChanges = replaced . size ( ) + created . size ( ) ; < |endfocus| > } else { List < Change . Id > autoclosed = resultChangeIds . get ( ResultChangeIds . Key . AUTOCLOSED ) ; if ( ! autoclosed . isEmpty ( ) ) { pushType = ResultChangeIds . Key . AUTOCLOSED . name ( ) ; metrics . changes . record ( ResultChangeIds . Key . AUTOCLOSED . name ( ) , autoclosed . size ( ) ) ; totalChanges = autoclosed . size ( ) ; } else { pushType = ""NORMAL"" ; } } if ( totalChanges > 0 ) { metrics . latencyPerChange . record ( pushType , deltaNanos / totalChanges , NANOSECONDS ) ; } metrics . latencyPerPush . record ( pushType , deltaNanos , NANOSECONDS ) ;
",,
2219,"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . extensions . client ; import java . lang . reflect . InvocationTargetException ; import java . util . EnumSet ; /* * Enum that can be expressed as a bitset in query parameters . */ public interface ListOption { int getValue ( ) ; static < T extends Enum < T > & ListOption > EnumSet < T > fromBits ( Class < T > clazz , int v ) { EnumSet < T > r = EnumSet . noneOf ( clazz ) ; T [ ] values ; try { @SuppressWarnings ( ""unchecked"" ) O [ ] tmp = ( O [ ] ) clazz . getMethod ( ""values"" ) . invoke ( null ) ; values = tmp ; } catch ( IllegalAccessException | NoSuchMethodException | InvocationTargetException e ) { throw new IllegalStateException ( e ) ; } for ( O o : values ) { if ( ( v & ( 1 < < o . getValue ( ) ) ) != 0 ) { r . add ( o ) ; v &= ~ ( 1 < < o . getValue ( ) ) ; }
","static < T extends Enum < T > & ListOption > EnumSet < T > fromBits ( Class < T > clazz , int v ) { EnumSet < T > r = EnumSet . noneOf ( clazz ) ; T [ ] values ;
","static <T extends Enum<T> & ListOption> EnumSet<T> fromBits(Class<T> clazz, int v) { EnumSet<T> r = EnumSet.noneOf(clazz); T[] values;
",,,"static <T extends Enum<T> & ListOption> EnumSet<T> fromBits(Class<T> clazz, int v) { EnumSet<T> r = EnumSet.noneOf(clazz); T[] values;
",,,"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . extensions . client ; import java . lang . reflect . InvocationTargetException ; import java . util . EnumSet ; /* * Enum that can be expressed as a bitset in query parameters . */ public interface ListOption { int getValue ( ) ; static < T extends Enum < T > & ListOption > EnumSet < T > fromBits ( Class < T > clazz , int v ) { EnumSet < T > r = EnumSet . noneOf ( clazz ) ; T [ ] values ; try { @SuppressWarnings ( ""unchecked"" ) T [ ] tmp = ( T [ ] ) clazz . getMethod ( ""values"" ) . invoke ( null ) ; values = tmp ; } catch ( IllegalAccessException | NoSuchMethodException | InvocationTargetException e ) { throw new IllegalStateException ( e ) ; } for ( T o : values ) { if ( ( v & ( 1 < < o . getValue ( ) ) ) != 0 ) { r . add ( o ) ; v &= ~ ( 1 < < o . getValue ( ) ) ; } } return r ; } }
",,,"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . extensions . client ; import java . lang . reflect . InvocationTargetException ; import java . util . EnumSet ; /* * * Enum that can be expressed as a bitset in query parameters . */ public interface ListOption { int getValue ( ) ; static < T extends Enum < T > & ListOption > EnumSet < T > fromBits ( Class < T > clazz , int v ) { EnumSet < T > r = EnumSet . noneOf ( clazz ) ; T [ ] values ; try { @SuppressWarnings ( ""unchecked"" ) T [ ] tmp = ( T [ ] ) clazz . getMethod ( ""values"" ) . invoke ( null ) ; values = tmp ; } catch ( IllegalAccessException | NoSuchMethodException | InvocationTargetException e ) { throw new IllegalStateException ( e ) ; } for ( T o : values ) { if ( ( v & ( 1 < < o . getValue ( ) ) ) != 0 ) { r . add ( o ) ; v &= ~ ( 1 < < o . getValue ( ) ) ; } } if ( v != 0 ) { throw new IllegalArgumentException ( ""Unknown bits set in "" + v ) ; } return r ; } }
",,,"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . extensions . client ; import java . lang . reflect . InvocationTargetException ; import java . util . EnumSet ; /* * Enum that can be expressed as a bitset in query parameters . */ public interface ListOption { int getValue ( ) ; < |startfocus| > static < T extends Enum < T > & ListOption > EnumSet < T > fromBits ( Class < T > clazz , int v ) { EnumSet < T > r = EnumSet . noneOf ( clazz ) ; T [ ] values ; < |endfocus| > try { @SuppressWarnings ( ""unchecked"" ) T [ ] tmp = ( T [ ] ) clazz . getMethod ( ""values"" ) . invoke ( null ) ; values = tmp ; } catch ( IllegalAccessException | NoSuchMethodException | InvocationTargetException e ) { throw new IllegalStateException ( e ) ; } for ( T o : values ) { if ( ( v & ( 1 < < o . getValue ( ) ) ) != 0 ) { r . add ( o ) ; v &= ~ ( 1 < < o . getValue ( ) ) ; }
",,
2223,"private final LoadingCache < PureRevertKeyProto , Boolean > cache ; private final PatchSetUtil psUtil ; private final ChangeNotes . Factory notesFactory ; @Inject PureRevertCache ( @Named ( ID_CACHE ) LoadingCache < PureRevertKeyProto , Boolean > cache , PatchSetUtil psUtil , ChangeNotes . Factory notesFactory ) { this . cache = cache ; this . psUtil = psUtil ; this . notesFactory = notesFactory ; } /* * * Returns { @code true } if { @code claimedRevert } is a pure ( clean ) revert of the change that is * referenced in { @link com . google . gerrit . reviewdb . client . Change#getRevertOf ( ) } . * * @return { @code true } if { @code claimedRevert } is a pure ( clean ) revert of { @code * claimedOriginal } . * @throws IOException if there was a priblem with the storage layer * @throws OrmException if there was a priblem with the storage layer * @throws BadRequestException if there is a problem with the provided { @link ChangeNotes } */ public boolean isPureRevert ( ChangeNotes claimedRevert ) throws OrmException , IOException , BadRequestException {
","* Returns { @code true } if { @code claimedRevert } is a pure ( clean ) revert of the change that is * referenced in { @link com . google . gerrit . reviewdb . client . Change#getRevertOf ( ) } .
","* Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code claimedOriginal}.
",,,"* Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code claimedRevert}.
",,,"private final LoadingCache < PureRevertKeyProto , Boolean > cache ; private final PatchSetUtil psUtil ; private final ChangeNotes . Factory notesFactory ; @Inject PureRevertCache ( @Named ( ID_CACHE ) LoadingCache < PureRevertKeyProto , Boolean > cache , PatchSetUtil psUtil , ChangeNotes . Factory notesFactory ) { this . cache = cache ; this . psUtil = psUtil ; this . notesFactory = notesFactory ; } /* * * Returns { @code true } if { @code claimedRevert } is a pure ( clean ) revert of { @code claimedOriginal } . * * @param claimedRevert the ChangeNotes object representing the claimed revert * @return { @code true } if { @code claimedRevert } is a pure ( clean ) revert of { @code claimedOriginal } * @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided { @link ChangeNotes } */ public boolean isPureRevert ( ChangeNotes claimedRevert ) throws OrmException , IOException , BadRequestException { // implementation }
",,,"private final LoadingCache < PureRevertKeyProto , Boolean > cache ; private final PatchSetUtil psUtil ; private final ChangeNotes . Factory notesFactory ; @Inject PureRevertCache ( @Named ( ID_CACHE ) LoadingCache < PureRevertKeyProto , Boolean > cache , PatchSetUtil psUtil , ChangeNotes . Factory notesFactory ) { this . cache = cache ; this . psUtil = psUtil ; this . notesFactory = notesFactory ; } /* * * Returns { @code true } if { @code claimedRevert } is a pure ( clean ) revert of { @code claimedOriginal } . * * @param claimedRevert the claimed revert to check * @return { @code true } if { @code claimedRevert } is a pure ( clean ) revert of { @code claimedOriginal } * @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided { @link ChangeNotes } */ public boolean isPureRevert ( ChangeNotes claimedRevert ) throws OrmException , IOException , BadRequestException { // implementation }
",,,"private final LoadingCache < PureRevertKeyProto , Boolean > cache ; private final PatchSetUtil psUtil ; private final ChangeNotes . Factory notesFactory ; @Inject PureRevertCache ( @Named ( ID_CACHE ) LoadingCache < PureRevertKeyProto , Boolean > cache , PatchSetUtil psUtil , ChangeNotes . Factory notesFactory ) { this . cache = cache ; this . psUtil = psUtil ; this . notesFactory = notesFactory ; } /* * < |startfocus| > * Returns { @code true } if { @code claimedRevert } is a pure ( clean ) revert . < |endfocus| > * * @return { @code true } if { @code claimedRevert } is a pure ( clean ) revert . * @throws IOException if there was a priblem with the storage layer * @throws OrmException if there was a priblem with the storage layer * @throws BadRequestException if there is a problem with the provided { @link ChangeNotes } */ public boolean isPureRevert ( ChangeNotes claimedRevert ) throws OrmException , IOException , BadRequestException {
",,
2248,"import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . gerrit . reviewdb . client . Project ; import org . junit . Before ; import org . junit . Test ; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId ; private PatchSet . Id testPatchSetId ; private CheckerUuid testCheckerUuid ; @Before public void setUp ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; result . assertOkStatus ( ) ; testChangeId = result . getChangeId ( ) ; testPatchSetId = result . getPatchSetId ( ) ; testChangeId = result . getChangeId ( ) ; // Approves ""Code - Review"" label so that the change only needs to meet the submit requirements // about checks . approve ( testChangeId ) ; // Creates a test Checker which is enabled and required for the test repository . testCheckerUuid = checkerOperations . newChecker ( ) . repository ( project ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) . status ( CheckerStatus . ENABLED ) . create ( ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getStatus ( ) ) . isEqualTo ( CheckerStatus . ENABLED ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getBlockingConditions ( ) ) . containsExactly ( BlockingCondition . STATE_NOT_PASSING ) ;
","testPatchSetId = result . getPatchSetId ( ) ; testChangeId = result . getChangeId ( ) ;
","testPatchSetId = result.getPatchSetId();
",,,"<|del|>
",,,"import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . gerrit . reviewdb . client . Project ; import org . junit . Before ; import org . junit . Test ; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private PatchSet . Id testPatchSetId ; private CheckerUuid testCheckerUuid ; @Before public void setUp ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; result . assertOkStatus ( ) ; testPatchSetId = result . getPatchSetId ( ) ; // Approves ""Code - Review"" label so that the change only needs to meet the submit requirements // about checks . approve ( result . getChangeId ( ) ) ; // Creates a test Checker which is enabled and required for the test repository . testCheckerUuid = checkerOperations . newChecker ( ) . repository ( project ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) . status ( CheckerStatus . ENABLED ) . create ( ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getStatus ( ) ) . isEqualTo ( CheckerStatus . ENABLED ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getBlockingConditions ( ) ) . containsExactly ( BlockingCondition . STATE_NOT_PASSING ) ; } @Test public void testSubmitRule ( ) throws Exception { // Test submit rule with the created Checker . setSubmitRule ( testPatchSetId , testCheckerUuid , SubmitRecord . Status . OK ) ; } }
",,,"import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . gerrit . reviewdb . client . Project ; import org . junit . Before ; import org . junit . Test ; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private PatchSet . Id testPatchSetId ; private CheckerUuid testCheckerUuid ; @Before public void setUp ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; result . assertOkStatus ( ) ; testPatchSetId = result . getPatchSetId ( ) ; // Approves ""Code - Review"" label so that the change only needs to meet the submit requirements // about checks . approve ( result . getChangeId ( ) ) ; // Creates a test Checker which is enabled and required for the test repository . testCheckerUuid = checkerOperations . newChecker ( ) . repository ( project ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) . status ( CheckerStatus . ENABLED ) . create ( ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getStatus ( ) ) . isEqualTo ( CheckerStatus . ENABLED ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getBlockingConditions ( ) ) . containsExactly ( BlockingCondition . STATE_NOT_PASSING ) ; } }
",,,"import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . gerrit . reviewdb . client . Project ; import org . junit . Before ; import org . junit . Test ; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private PatchSet . Id testPatchSetId ; private CheckerUuid testCheckerUuid ; @Before public void setUp ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; result . assertOkStatus ( ) ; < |startfocus| > testPatchSetId = result . getPatchSetId ( ) ; < |endfocus| > // Approves ""Code - Review"" label so that the change only needs to meet the submit requirements // about checks . approve ( testPatchSetId . changeId ( ) ) ; // Creates a test Checker which is enabled and required for the test repository . testCheckerUuid = checkerOperations . newChecker ( ) . repository ( project ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) . status ( CheckerStatus . ENABLED ) . create ( ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getStatus ( ) ) . isEqualTo ( CheckerStatus . ENABLED ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getBlockingConditions ( ) ) . containsExactly ( BlockingCondition . STATE_NOT_PASSING ) ;
",,
2254,"} } /* * * Find and parse an included file and append data to the 'result' . * For an 'include' statement , parsed data is all append to the given result parameter . * For a 'file : ' statement or directive , only owner emails are appended . * If the project + file name is found in the stored result set , the stored result is reused . * The inclusion is skipped if the to be included file is already on the including file stack . * * @param result to where the included file data should be added . * @param dir the including file's directory or glob . * @param num source code line number * @param parsedKPF the parsed line of include or file directive . * @param addAll to add all parsed data into result or not . */ private void includeFile ( Result result , String dir , int num , String [ ] parsedKPF , boolean addAll ) { String keyword = parsedKPF [ 0 ] ; String project = parsedKPF [ 1 ] ;
","* The inclusion is skipped if the to be included file is already on the including file stack .
","* The inclusion is skipped if to be included file is already on the including file stack.
",,,"* The inclusion is skipped if to be included file is already on the including file stack.
",,,"private void includeFile ( Result result , String dir , int num , String [ ] parsedKPF , boolean addAll ) { String keyword = parsedKPF [ 0 ] ; String project = parsedKPF [ 1 ] ; // Check if the file is already included if ( result . getFiles ( ) . contains ( project ) ) { return ; } // Add the file to the included files list result . getFiles ( ) . add ( project ) ; // Parse the file and append data to the result if ( keyword . equals ( ""include"" ) ) { // Parse the included file and append data to the result parseFile ( result , dir , num , project , addAll ) ; } else if ( keyword . equals ( ""file : "" ) ) { // Only append owner emails to the result appendOwnerEmails ( result , dir , num , project ) ; } } /* * * Parse the included file and append data to the 'result' . * * @param result to where the included file data should be added . * @param dir the including file's directory or glob . * @param num source code line number * @param project the project + file name to be parsed . * @param addAll to add all parsed data into result or not . */ private void parseFile ( Result result , String dir , int num , String project , boolean addAll ) { // Parse the file and append data to the result } /* * * Append owner emails to the 'result' . * * @param result to where the owner emails should be added . * @param dir the including file's directory or glob . * @param num source code line number * @param project the project + file name to be parsed . */ private void appendOwnerEmails ( Result result , String dir , int num , String project ) { // Append owner emails to the result }
",,,"} } /* * * Find and parse an included file and append data to the 'result' . * For an 'include' statement , parsed data is all append to the given result parameter . * For a 'file : ' statement or directive , only owner emails are appended . * If the project + file name is found in the stored result set , the stored result is reused . * The inclusion is skipped if to be included file is already on the including file stack . * * @param result to where the included file data should be added . * @param dir the including file's directory or glob . * @param num source code line number * @param parsedKPF the parsed line of include or file directive . * @param addAll to add all parsed data into result or not . */ private void includeFile ( Result result , String dir , int num , String [ ] parsedKPF , boolean addAll ) { String keyword = parsedKPF [ 0 ] ; String project = parsedKPF [ 1 ] ;
",,,"/* * * Find and parse an included file and append data to the 'result' . * For an 'include' statement , parsed data is all append to the given result parameter . * For a 'file : ' statement or directive , only owner emails are appended . * If the project + file name is found in the stored result set , the stored result is reused . < |startfocus| > * The inclusion is skipped if to be included file is already on the including file stack . < |endfocus| > * * @param result to where the included file data should be added . * @param dir the including file's directory or glob . * @param num source code line number * @param parsedKPF the parsed line of include or file directive . * @param addAll to add all parsed data into result or not . */ private void includeFile ( Result result , String dir , int num , String [ ] parsedKPF , boolean addAll ) { String keyword = parsedKPF [ 0 ] ; String project = parsedKPF [ 1 ] ;
",,
2260,"public Collection < SubmitRecord > evaluate ( ChangeData cd , SubmitRuleOptions options ) { ProjectState projectState = projectCache . get ( cd . project ( ) ) ; PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ; EnforcementLevel enforce_level = pluginConfig . getEnum ( EnforcementLevel . CONFIG_NAME , EnforcementLevel . DISABLED ) ; if ( enforce_level == EnforcementLevel . DISABLED ) { return ImmutableList . of ( ) ; } Checker checker = new Checker ( repoManager , pluginConfigFactory , projectState , cd , 1 ) ; int result ; try { OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ; result = checker . findApproval ( accounts , db ) ; } catch ( OrmException | IOException e ) { this . logger . atSevere ( ) . withCause ( e ) . log ( ""Exception for % s"" , Config . getChangeId ( cd ) ) ; SubmitRecord rec = new SubmitRecord ( ) ; rec . status = SubmitRecord . Status . RULE_ERROR ; rec . errorMessage = LOOKUP_ERROR_MSG ; return ImmutableList . of ( rec ) ; }
","PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ;
","PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance(projectState, pluginName);
",,,"PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance(projectState, pluginName);
",,,"public Collection < SubmitRecord > evaluate ( ChangeData cd , SubmitRuleOptions options ) { ProjectState projectState = projectCache . get ( cd . project ( ) ) ; PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ; EnforcementLevel enforce_level = pluginConfig . getEnum ( EnforcementLevel . CONFIG_NAME , EnforcementLevel . DISABLED ) ; if ( enforce_level == EnforcementLevel . DISABLED ) { return ImmutableList . of ( ) ; } Checker checker = new Checker ( repoManager , pluginConfigFactory , projectState , cd , 1 ) ; int result ; try { OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ; result = checker . findApproval ( accounts , db ) ; } catch ( OrmException | IOException e ) { this . logger . atSevere ( ) . withCause ( e ) . log ( ""Exception for % s"" , Config . getChangeId ( cd ) ) ; SubmitRecord rec = new SubmitRecord ( ) ; rec . status = SubmitRecord . Status . RULE_ERROR ; rec . errorMessage = LOOKUP_ERROR_MSG ; return ImmutableList . of ( rec ) ; } }
",,,"generateSshHostKeys ( ) ; remover . remove ( ""bc ( pg|pkix|prov ) - .* [ . ] jar"" ) ; private static boolean isOff ( String listenHostname ) { return ""off"" . equalsIgnoreCase ( listenHostname ) || ""none"" . equalsIgnoreCase ( listenHostname ) || ""no"" . equalsIgnoreCase ( listenHostname ) ; } private void generateSshHostKeys ( ) throws InterruptedException , IOException { if ( ! exists ( site . ssh_key ) && ( ! exists ( site . ssh_rsa ) || ! exists ( site . ssh_dsa ) || ! exists ( site . ssh_ed25519 ) || ! exists ( site . ssh_ecdsa ) ) ) { System . err . print ( ""Generating SSH host key . . . "" ) ; System . err . flush ( ) ; // Generate the SSH daemon host key using ssh - keygen . // final String comment = ""gerrit - code - review@"" + hostname ( ) ; // Workaround for JDK - 6518827 - zero - length argument ignored on Win32 String emptyPassphraseArg = HostPlatform . isWin32 ( ) ? ""\""\"""" : """" ; if ( ! exists ( site . ssh_rsa ) ) { System . err . print ( "" rsa . . . "" ) ; System . err . flush ( ) ; new ProcessBuilder ( Review : This should be formatted with gjf . generateSshHostKeys ( ) ; remover . remove ( ""bc ( pg|pkix|prov ) - .* [ . ] jar"" ) ; private static boolean isOff ( String listenHostname ) { return ""off"" . equalsIgnoreCase ( listenHostname ) || ""none"" . equalsIgnoreCase ( listenHostname ) || ""no"" . equalsIgnoreCase ( listenHostname ) ; } private void generateSshHostKeys ( ) throws InterruptedException , IOException { if ( ! exists ( site . ssh_key ) && ( ! exists ( site . ssh_rsa ) || ! exists ( site . ssh_dsa ) || ! exists ( site . ssh_ed25519 ) || ! exists ( site . ssh_ecdsa ) ) ) { System . err . print ( ""Generating SSH host key . . . "" ) ; System . err . flush ( ) ; // Generate the SSH daemon host key using ssh - keygen . // final String comment = ""gerrit - code - review@"" + hostname ( ) ; // Workaround for JDK - 6518827 - zero - length argument ignored on Win32 String emptyPassphraseArg = HostPlatform . isWin32 ( ) ? ""\""\"""" : """" ; if ( ! exists ( site . ssh_rsa ) ) { System . err . print ( "" rsa . . . "" ) ; System . err . flush ( ) ; new ProcessBuilder ( Buggy private String keyToString ( Object key ) { if ( key instanceof StringKey ) { return ( ( String
",,,"public Collection < SubmitRecord > evaluate ( ChangeData cd , SubmitRuleOptions options ) { 	ProjectState projectState = projectCache . get ( cd . project ( ) ) ; 	 < |startfocus| > PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ; < |endfocus| > 	EnforcementLevel enforce_level = pluginConfig . getEnum ( EnforcementLevel . CONFIG_NAME , EnforcementLevel . DISABLED ) ; 	if ( enforce_level == EnforcementLevel . DISABLED ) { 		return ImmutableList . of ( ) ; 	 } 	Checker checker = new Checker ( repoManager , pluginConfigFactory , projectState , cd , 1 ) ; 	int result ; 	try { 		OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ; 		result = checker . findApproval ( accounts , db ) ; 	 } catch ( OrmException | IOException e ) { 		this . logger . atSevere ( ) . withCause ( e ) . log ( ""Exception for % s"" , Config . getChangeId ( cd ) ) ; 		SubmitRecord rec = new SubmitRecord ( ) ; 		rec . status = SubmitRecord . Status . RULE_ERROR ; 		rec . errorMessage = LOOKUP_ERROR_MSG ; 		return ImmutableList . of ( rec ) ; 	 } }
",,
2262,"public Collection < SubmitRecord > evaluate ( ChangeData cd , SubmitRuleOptions options ) { ProjectState projectState = projectCache . get ( cd . project ( ) ) ; PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ; EnforcementLevel enforce_level = pluginConfig . getEnum ( EnforcementLevel . CONFIG_NAME , EnforcementLevel . DISABLED ) ; if ( enforce_level == EnforcementLevel . DISABLED ) { return ImmutableList . of ( ) ; } Checker checker = new Checker ( repoManager , pluginConfigFactory , projectState , cd , 1 ) ; int result ; try { OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ; result = checker . findApproval ( accounts , db ) ; } catch ( OrmException | IOException e ) { this . logger . atSevere ( ) . withCause ( e ) . log ( ""Exception for % s"" , Config . getChangeId ( cd ) ) ; SubmitRecord rec = new SubmitRecord ( ) ; rec . status = SubmitRecord . Status . RULE_ERROR ; rec . errorMessage = LOOKUP_ERROR_MSG ; return ImmutableList . of ( rec ) ; }
","OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ;
","OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager).get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd);
",,,"OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager).get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd);
",,,"public Collection < SubmitRecord > evaluate ( ChangeData cd , SubmitRuleOptions options ) { ProjectState projectState = projectCache . get ( cd . project ( ) ) ; PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ; EnforcementLevel enforceLevel = pluginConfig . getEnum ( EnforcementLevel . CONFIG_NAME , EnforcementLevel . DISABLED ) ; if ( enforceLevel == EnforcementLevel . DISABLED ) { return ImmutableList . of ( ) ; } Checker checker = new Checker ( repoManager , pluginConfigFactory , projectState , cd , 1 ) ; SubmitRecord rec = new SubmitRecord ( ) ; try { OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ; int result = checker . findApproval ( accounts , db ) ; rec . status = SubmitRecord . Status . values ( ) [ result ] ; } catch ( OrmException | IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( ""Exception for % s"" , Config . getChangeId ( cd ) ) ; rec . status = SubmitRecord . Status . RULE_ERROR ; rec . errorMessage = LOOKUP_ERROR_MSG ; } return ImmutableList . of ( rec ) ; }
",,,"public Collection < SubmitRecord > evaluate ( ChangeData cd , SubmitRuleOptions options ) { ProjectState projectState = projectCache . get ( cd . project ( ) ) ; PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ; EnforcementLevel enforceLevel = pluginConfig . getEnum ( EnforcementLevel . CONFIG_NAME , EnforcementLevel . DISABLED ) ; if ( enforceLevel == EnforcementLevel . DISABLED ) { return ImmutableList . of ( ) ; } Checker checker = new Checker ( repoManager , pluginConfigFactory , projectState , cd , 1 ) ; int result ; try { OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ; result = checker . findApproval ( accounts , db ) ; } catch ( OrmException | IOException e ) { this . logger . atSevere ( ) . withCause ( e ) . log ( ""Exception for % s"" , Config . getChangeId ( cd ) ) ; SubmitRecord rec = new SubmitRecord ( ) ; rec . status = SubmitRecord . Status . RULE_ERROR ; rec . errorMessage = LOOKUP_ERROR_MSG ; return ImmutableList . of ( rec ) ; } }
",,,"public Collection < SubmitRecord > evaluate ( ChangeData cd , SubmitRuleOptions options ) { ProjectState projectState = projectCache . get ( cd . project ( ) ) ; PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ; EnforcementLevel enforce_level = pluginConfig . getEnum ( EnforcementLevel . CONFIG_NAME , EnforcementLevel . DISABLED ) ; if ( enforce_level == EnforcementLevel . DISABLED ) { return ImmutableList . of ( ) ; } Checker checker = new Checker ( repoManager , pluginConfigFactory , projectState , cd , 1 ) ; int result ; try { < |startfocus| > OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ; < |endfocus| > result = checker . findApproval ( accounts , db ) ; } catch ( OrmException | IOException e ) { this . logger . atSevere ( ) . withCause ( e ) . log ( ""Exception for % s"" , Config . getChangeId ( cd ) ) ; SubmitRecord rec = new SubmitRecord ( ) ; rec . status = SubmitRecord . Status . RULE_ERROR ; rec . errorMessage = LOOKUP_ERROR_MSG ; return ImmutableList . of ( rec ) ; }
",,
2270,"} } public static String pathFor ( String projectName , Ref ref ) { return pathFor ( projectName , ref . getName ( ) ) ; } public static String pathFor ( String projectName , String refName ) { return "" / "" + projectName + "" / "" + refName ; } public static ObjectId readObjectId ( byte [ ] value ) { return ObjectId . fromRaw ( value ) ; } static byte [ ] writeObjectId ( ObjectId value ) throws IOException { final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; final DataOutputStream stream = new DataOutputStream ( out ) ; value . copyRawTo ( stream ) ; return out . toByteArray ( ) ; } }
","static byte [ ] writeObjectId ( ObjectId value ) throws IOException {
","private static byte[] writeObjectId(ObjectId value) throws IOException {
",,,"private static byte[] writeObjectId(ObjectId value) throws IOException {
",,,"private static byte [ ] writeObjectId ( ObjectId value ) throws IOException { final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; final DataOutputStream stream = new DataOutputStream ( out ) ; value . copyRawTo ( stream ) ; return out . toByteArray ( ) ; }
",,,"private static class Helper { public static String pathFor ( String projectName , Ref ref ) { return pathFor ( projectName , ref . getName ( ) ) ; } public static String pathFor ( String projectName , String refName ) { return "" / "" + projectName + "" / "" + refName ; } public static ObjectId readObjectId ( byte [ ] value ) { return ObjectId . fromRaw ( value ) ; } public static byte [ ] writeObjectId ( ObjectId value ) throws IOException { final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; final DataOutputStream stream = new DataOutputStream ( out ) ; value . copyRawTo ( stream ) ; return out . toByteArray ( ) ; } }
",,,"} } public static String pathFor ( String projectName , Ref ref ) { return pathFor ( projectName , ref . getName ( ) ) ; } public static String pathFor ( String projectName , String refName ) { return "" / "" + projectName + "" / "" + refName ; } public static ObjectId readObjectId ( byte [ ] value ) { return ObjectId . fromRaw ( value ) ; } < |startfocus| > private static byte [ ] writeObjectId ( ObjectId value ) throws IOException { < |endfocus| > final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; final DataOutputStream stream = new DataOutputStream ( out ) ; value . copyRawTo ( stream ) ; return out . toByteArray ( ) ; } }
",,
2283,"String . format ( ""checker % s not found"" , checkerUuid ) ) ) ; if ( checker . getStatus ( ) == CheckerStatus . DISABLED ) { return ImmutableList . of ( ) ; } // The query system can only match against the current patch set ; ignore non - current patch sets // for now . List < ChangeData > changes = queryMatchingChangesFor ( checker ) ; List < PendingChecksInfo > pendingChecks = new ArrayList < > ( changes . size ( ) ) ; for ( ChangeData cd : changes ) { getPostFilteredPendingChecks ( cd . project ( ) , cd . currentPatchSet ( ) . getId ( ) ) . ifPresent ( pendingChecks : : add ) ; } return pendingChecks ; } private List < ChangeData > queryMatchingChangesFor ( Checker checker ) throws ConfigInvalidException , OrmException { Predicate < ChangeData > predicate = new ProjectPredicate ( checker . getRepository ( ) . get ( ) ) ; if ( checker . getQuery ( ) . isPresent ( ) ) { String query = checker . getQuery ( ) . get ( ) ; try { predicate = Predicate . and ( predicate , queryBuilderProvider . get ( ) . parse ( query ) ) ; } catch ( QueryParseException e ) { logger . atWarning ( ) . withCause ( e ) . log (
","getPostFilteredPendingChecks ( cd . project ( ) , cd . currentPatchSet ( ) . getId ( ) )
","getMatchingPendingChecks(cd.project(), cd.currentPatchSet().getId())
",,,"getPostFilteredPendingChecks(cd.project(), cd.currentPatchSet().getId())
",,,"String . format ( ""checker % s not found"" , checkerUuid ) ) ) ; if ( checker . getStatus ( ) == CheckerStatus . DISABLED ) { return ImmutableList . of ( ) ; } List < ChangeData > changes = queryMatchingChangesFor ( checker ) ; List < PendingChecksInfo > pendingChecks = new ArrayList < > ( changes . size ( ) ) ; for ( ChangeData cd : changes ) { getMatchingPendingChecks ( cd . project ( ) , cd . currentPatchSet ( ) . getId ( ) ) . ifPresent ( pendingChecks : : add ) ; } return pendingChecks ; } private List < ChangeData > queryMatchingChangesFor ( Checker checker ) throws ConfigInvalidException , OrmException { Predicate < ChangeData > predicate = new ProjectPredicate ( checker . getRepository ( ) . get ( ) ) ; if ( checker . getQuery ( ) . isPresent ( ) ) { String query = checker . getQuery ( ) . get ( ) ; try { predicate = Predicate . and ( predicate , queryBuilderProvider . get ( ) . parse ( query ) ) ; } catch ( QueryParseException e ) { logger . atWarning ( ) . withCause ( e ) . log ( ""Invalid query for checker % s : % s"" , checker . getUuid ( ) , query ) ; } } return queryProvider . get ( ) . query ( predicate ) ; }
",,,"String . format ( ""checker % s not found"" , checkerUuid ) ) ) ; if ( checker . getStatus ( ) == CheckerStatus . DISABLED ) { return ImmutableList . of ( ) ; } List < ChangeData > changes = queryMatchingChangesFor ( checker ) ; List < PendingChecksInfo > pendingChecks = new ArrayList < > ( changes . size ( ) ) ; for ( ChangeData cd : changes ) { getMatchingPendingChecks ( cd . project ( ) , cd . currentPatchSet ( ) . getId ( ) ) . ifPresent ( pendingChecks : : add ) ; } return pendingChecks ; } private List < ChangeData > queryMatchingChangesFor ( Checker checker ) throws ConfigInvalidException , OrmException { Predicate < ChangeData > predicate = new ProjectPredicate ( checker . getRepository ( ) . get ( ) ) ; if ( checker . getQuery ( ) . isPresent ( ) ) { String query = checker . getQuery ( ) . get ( ) ; try { predicate = Predicate . and ( predicate , queryBuilderProvider . get ( ) . parse ( query ) ) ; } catch ( QueryParseException e ) { logger . atWarning ( ) . withCause ( e ) . log ( ""Invalid query for checker % s : % s"" , checker . getUuid ( ) , query ) ; } } return queryProvider . get ( ) . query ( predicate ) ; }
",,,"String . format ( ""checker % s not found"" , checkerUuid ) ) ) ; if ( checker . getStatus ( ) == CheckerStatus . DISABLED ) { return ImmutableList . of ( ) ; } // The query system can only match against the current patch set ; ignore non - current patch sets // for now . List < ChangeData > changes = queryMatchingChangesFor ( checker ) ; List < PendingChecksInfo > pendingChecks = new ArrayList < > ( changes . size ( ) ) ; for ( ChangeData cd : changes ) { < |startfocus| > getPostFilteredPendingChecks ( cd . project ( ) , cd . currentPatchSet ( ) . getId ( ) ) < |endfocus| > . ifPresent ( pendingChecks : : add ) ; } return pendingChecks ; } private List < ChangeData > queryMatchingChangesFor ( Checker checker ) throws ConfigInvalidException , OrmException { Predicate < ChangeData > predicate = new ProjectPredicate ( checker . getRepository ( ) . get ( ) ) ; if ( checker . getQuery ( ) . isPresent ( ) ) { String query = checker . getQuery ( ) . get ( ) ; try { predicate = Predicate . and ( predicate , queryBuilderProvider . get ( ) . parse ( query ) ) ; } catch ( QueryParseException e ) { logger . atWarning ( ) . withCause ( e ) . log (
",,
2290,"RefUpdate refUpdate = repo . updateRef ( refName ) ; refUpdate . setExpectedOldObjectId ( parent ) ; refUpdate . setNewObjectId ( newCommitId ) ; refUpdate . setRefLogIdent ( personIdent ) ; refUpdate . setRefLogMessage ( message , false ) ; refUpdate . update ( ) ; RefUpdateUtil . checkResult ( refUpdate ) ; try { combinedCheckStateCache . reload ( checkKey . project ( ) , checkKey . patchSet ( ) ) ; } catch ( OrmException e ) { logger . atWarning ( ) . withCause ( e ) . log ( ""failed to reload CombinedCheckState for % s"" , checkKey ) ; } gitRefUpdated . fire ( checkKey . repository ( ) , refUpdate , currentUser . map ( user - > user . state ( ) ) . orElse ( null ) ) ; return readSingleCheck ( checkKey , repo , rw , newCommitId ) ; } } private void assertCheckerIsPresent ( CheckerUuid checkerUuid ) throws ConfigInvalidException , IOException { checkers . getChecker ( checkerUuid ) . orElseThrow ( ( ) - > new IOException ( checkerUuid + "" missing"" ) ) ; } private boolean updateNotesMap ( CheckKey checkKey , CheckUpdate checkUpdate , Repository repo , RevWalk rw , ObjectInserter ins , ObjectId curr ,
","checkKey . repository ( ) , refUpdate , currentUser . map ( user - > user . state ( ) ) . orElse ( null ) ) ;
","checkKey.project(), refUpdate, currentUser.map(user -> user.state()).orElse(null));
",,,"checkKey.project(), refUpdate, currentUser.map(user -> user.state()).orElse(null));
",,,"RefUpdate refUpdate = repo . updateRef ( refName ) ; refUpdate . setExpectedOldObjectId ( parent ) ; refUpdate . setNewObjectId ( newCommitId ) ; refUpdate . setRefLogIdent ( personIdent ) ; refUpdate . setRefLogMessage ( message , false ) ; refUpdate . update ( ) ; RefUpdateUtil . checkResult ( refUpdate ) ; try { combinedCheckStateCache . reload ( checkKey . project ( ) , checkKey . patchSet ( ) ) ; } catch ( OrmException e ) { logger . atWarning ( ) . withCause ( e ) . log ( ""failed to reload CombinedCheckState for % s"" , checkKey ) ; } gitRefUpdated . fire ( checkKey . project ( ) , refUpdate , currentUser . map ( user - > user . state ( ) ) . orElse ( null ) ) ; return readSingleCheck ( checkKey , repo , rw , newCommitId ) ; } private void assertCheckerIsPresent ( CheckerUuid checkerUuid ) throws ConfigInvalidException , IOException { checkers . getChecker ( checkerUuid ) . orElseThrow ( ( ) - > new IOException ( checkerUuid + "" missing"" ) ) ; } private boolean updateNotesMap ( CheckKey checkKey , CheckUpdate checkUpdate , Repository repo , RevWalk rw , ObjectInserter ins , ObjectId curr ) { // implementation }
",,,"RefUpdate refUpdate = repo . updateRef ( refName ) ; refUpdate . setExpectedOldObjectId ( parent ) ; refUpdate . setNewObjectId ( newCommitId ) ; refUpdate . setRefLogIdent ( personIdent ) ; refUpdate . setRefLogMessage ( message , false ) ; refUpdate . update ( ) ; RefUpdateUtil . checkResult ( refUpdate ) ; try { combinedCheckStateCache . reload ( checkKey . project ( ) , checkKey . patchSet ( ) ) ; } catch ( OrmException e ) { logger . atWarning ( ) . withCause ( e ) . log ( ""failed to reload CombinedCheckState for % s"" , checkKey ) ; } gitRefUpdated . fire ( checkKey . project ( ) , refUpdate , currentUser . map ( user - > user . state ( ) ) . orElse ( null ) ) ; return readSingleCheck ( checkKey , repo , rw , newCommitId ) ; } private void assertCheckerIsPresent ( CheckerUuid checkerUuid ) throws ConfigInvalidException , IOException { checkers . getChecker ( checkerUuid ) . orElseThrow ( ( ) - > new IOException ( checkerUuid + "" missing"" ) ) ; } private boolean updateNotesMap ( CheckKey checkKey , CheckUpdate checkUpdate , Repository repo , RevWalk rw , ObjectInserter ins , ObjectId curr , ObjectId newCommitId ) throws IOException { try ( ObjectReader reader = rw . getObjectReader ( ) ) { NoteMap noteMap = NoteMap . read ( reader , curr ) ; Note note = noteMap . get ( checkKey . patchSet ( ) ) ; if ( note == null ) { return false ; } CheckState oldState = note . getState ( ) ; CheckState newState = checkUpdate . getState ( ) ; if ( oldState == newState ) { return false ; } note . setState ( newState ) ; noteMap . set ( checkKey . patchSet ( ) , note ) ; noteMap . write ( reader , ins ) ; return true ; } }
",,,"RefUpdate refUpdate = repo . updateRef ( refName ) ; refUpdate . setExpectedOldObjectId ( parent ) ; refUpdate . setNewObjectId ( newCommitId ) ; refUpdate . setRefLogIdent ( personIdent ) ; refUpdate . setRefLogMessage ( message , false ) ; refUpdate . update ( ) ; RefUpdateUtil . checkResult ( refUpdate ) ; try { combinedCheckStateCache . reload ( checkKey . project ( ) , checkKey . patchSet ( ) ) ; } catch ( OrmException e ) { logger . atWarning ( ) . withCause ( e ) . log ( ""failed to reload CombinedCheckState for % s"" , checkKey ) ; } gitRefUpdated . fire ( < |startfocus| > checkKey . project ( ) , refUpdate , currentUser . map ( user - > user . state ( ) ) . orElse ( null ) ) ; < |endfocus| > return readSingleCheck ( checkKey , repo , rw , newCommitId ) ; } } private void assertCheckerIsPresent ( CheckerUuid checkerUuid ) throws ConfigInvalidException , IOException { checkers . getChecker ( checkerUuid ) . orElseThrow ( ( ) - > new IOException ( checkerUuid + "" missing"" ) ) ; } private boolean updateNotesMap ( CheckKey checkKey , CheckUpdate checkUpdate , Repository repo , RevWalk rw , ObjectInserter ins , ObjectId curr ,
",,
2294,"// See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . server . git . validators . RefOperationValidationListener ; import com . google . inject . AbstractModule ; import com . google . inject . name . Names ; import com . googlesource . gerrit . plugins . multisite . Configuration ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . SharedRefDatabase ; public class ValidationModule extends AbstractModule { private Configuration cfg ; public ValidationModule ( Configuration cfg ) { this . cfg = cfg ; } @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ; bind ( SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; bind ( CuratorFramework . class ) . toInstance ( cfg . getSplitBrain ( ) . getZookeeper ( ) . buildCurator ( ) ) ; bind ( RetryPolicy . class ) . annotatedWith ( Names . named ( ""ZkLockRetryPolicy"" ) )
","< |del| > import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . zookeeper . ZkSharedRefDatabase ; import org . apache . curator . RetryPolicy ; import org . apache . curator . framework . CuratorFramework ;
","<|del|>
",,,"<|del|>
",,,"// See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . server . git . validators . RefOperationValidationListener ; import com . google . inject . AbstractModule ; import com . google . inject . name . Names ; import com . googlesource . gerrit . plugins . multisite . Configuration ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . SharedRefDatabase ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . zookeeper . ZkSharedRefDatabase ; import org . apache . curator . RetryPolicy ; import org . apache . curator . framework . CuratorFramework ; public class ValidationModule extends AbstractModule { private final Configuration cfg ; public ValidationModule ( Configuration cfg ) { this . cfg = cfg ; } @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ; bind ( SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; bind ( CuratorFramework . class ) . toInstance ( cfg . getSplitBrain ( ) . getZookeeper ( ) . buildCurator ( ) ) ; bind ( RetryPolicy . class ) . annotatedWith ( Names . named ( ""ZkLockRetryPolicy"" ) ) . toInstance ( cfg . getSplitBrain ( ) . getZookeeper ( ) . buildRetryPolicy ( ) ) ; } }
",,,"// See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . server . git . validators . RefOperationValidationListener ; import com . google . inject . AbstractModule ; import com . google . inject . name . Names ; import com . googlesource . gerrit . plugins . multisite . Configuration ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . SharedRefDatabase ; public class ValidationModule extends AbstractModule { private Configuration cfg ; public ValidationModule ( Configuration cfg ) { this . cfg = cfg ; } @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ; bind ( SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; bind ( CuratorFramework . class ) . toInstance ( cfg . getSplitBrain ( ) . getZookeeper ( ) . buildCurator ( ) ) ; bind ( RetryPolicy . class ) . annotatedWith ( Names . named ( ""ZkLockRetryPolicy"" ) ) ; } }
",,,"// See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . server . git . validators . RefOperationValidationListener ; import com . google . inject . AbstractModule ; import com . google . inject . name . Names ; import com . googlesource . gerrit . plugins . multisite . Configuration ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . SharedRefDatabase ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . zookeeper . ZkSharedRefDatabase ; import org . apache . curator . RetryPolicy ; import org . apache . curator . framework . CuratorFramework ; public class ValidationModule extends AbstractModule { private Configuration cfg ; public ValidationModule ( Configuration cfg ) { this . cfg = cfg ; } @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ; bind ( SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; bind ( CuratorFramework . class ) . toInstance ( cfg . getSplitBrain ( ) . getZookeeper ( ) . buildCurator ( ) ) ; bind ( RetryPolicy . class ) . annotatedWith ( Names . named ( ""ZkLockRetryPolicy"" ) )
",,
2298,"public static Check newBackfilledCheck ( Project . NameKey project , PatchSet ps , Checker checker ) { return Check . builder ( CheckKey . create ( project , ps . getId ( ) , checker . getUuid ( ) ) ) . setState ( CheckState . NOT_STARTED ) . setCreated ( ps . getCreatedOn ( ) ) . setUpdated ( ps . getCreatedOn ( ) ) . build ( ) ;
","public static Check newBackfilledCheck ( Project . NameKey project , PatchSet ps , Checker checker ) { return Check . builder ( CheckKey . create ( project , ps . getId ( ) , checker . getUuid ( ) ) )
","public static Check newBackfilledCheck(ChangeData cd, PatchSet ps, Checker checker) { return Check.builder(CheckKey.create(cd.project(), ps.getId(), checker.getUuid()))
",,,"public static Check newBackfilledCheck(Project.NameKey cd, PatchSet ps) { return new Check.Builder(CheckKey.create(cd.project(), ps.getId()), checker.getUuid()))
",,,"public static Check newBackfilledCheck ( Project . NameKey project , PatchSet ps , Checker checker ) { return Check . builder ( CheckKey . create ( project , ps . getId ( ) , checker . getUuid ( ) ) ) . setState ( CheckState . NOT_STARTED ) . setCreated ( ps . getCreatedOn ( ) ) . setUpdated ( ps . getCreatedOn ( ) ) . build ( ) ; }
",,,"for ( GitReferenceUpdatedListener . Update u : event . getUpdates ( ) ) { if ( u . getRefName ( ) . startsWith ( ""refs / changes / "" ) ) { cache . invalidate ( new Project . NameKey ( event . getProjectName ( ) ) ) ; break ; } } static class Loader extends CacheLoader < Project . NameKey , List < Change > > { private final SchemaFactory < ReviewDb > schema ; @Inject Loader ( SchemaFactory < ReviewDb > schema ) { this . schema = schema ; } @Override public List < Change > load ( Project . NameKey key ) throws Exception { final ReviewDb db = schema . open ( ) ; try { return Collections . unmodifiableList ( db . changes ( ) . byProject ( key ) . toList ( ) ) ; } finally { db . close ( ) ; } } } }
",,,"< |startfocus| > public static Check newBackfilledCheck ( Project . NameKey project , PatchSet ps , Checker checker ) { return Check . builder ( CheckKey . create ( project , ps . getId ( ) , checker . getUuid ( ) ) ) < |endfocus| > . setState ( CheckState . NOT_STARTED ) . setCreated ( ps . getCreatedOn ( ) ) . setUpdated ( ps . getCreatedOn ( ) ) . build ( ) ;
",,
2304,"} @Test public void insertCheckerTwice ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; CheckerUuid checkerUuid = CheckerUuid . parse ( ""foo : bar"" ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; assertThat ( getRefsMetaCheckersState ( ) ) . isEqualTo ( commitId ) ; } @Test public void removeCheckers ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( ""bar : baz"" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( ""foo : bar"" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( ""foo : baz"" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) )
","assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; assertThat ( getRefsMetaCheckersState ( ) ) . isEqualTo ( commitId ) ;
","assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid);
",,,"assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid); assertThat(checkersByRepositoryNotes.get(project).commit didn't change)
",,,"@Test public void insertCheckerTwice ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; CheckerUuid checkerUuid = CheckerUuid . parse ( ""foo : bar"" ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; } @Test public void removeCheckers ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( ""bar : baz"" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( ""foo : bar"" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( ""foo : baz"" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 , checkerUuid3 ) ; }
",,,"@Test public void insertCheckerTwice ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; CheckerUuid checkerUuid = CheckerUuid . parse ( ""foo : bar"" ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; } @Test public void removeCheckers ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( ""bar : baz"" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( ""foo : bar"" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( ""foo : baz"" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) ; }
",,,"} @Test public void insertCheckerTwice ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; CheckerUuid checkerUuid = CheckerUuid . parse ( ""foo : bar"" ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; < |startfocus| > assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; < |endfocus| > } @Test public void removeCheckers ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( ""bar : baz"" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( ""foo : bar"" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( ""foo : baz"" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 , checkerUuid3 ) ; checkersByRepositoryNotes . remove ( checkerUuid2 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid3 ) ; } @Test public void removeCheckersFromEmptyRepository ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; CheckerUuid checkerUuid = CheckerUuid . parse ( ""foo : bar"" ) ; checkersByRepositoryNotes . remove ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . isEmpty ( ) ; } @Test public void removeCheckersFromNonExistingRepository ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; CheckerUuid checkerUuid = CheckerUuid . parse ( ""foo : bar"" ) ; checkersByRepositoryNotes . remove ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . isEmpty ( ) ; } @Test public void removeCheckersFromNonExistingChecker ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( ""bar : baz"" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( ""foo : bar"" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( ""foo : baz"" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 , checkerUuid3 ) ; checkersByRepositoryNotes . remove ( CheckerUuid . parse ( ""foo : baz"" ) , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 ) ; } @Test public void removeCheckersFromNonExistingCheckerAndRepository ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( ""bar : baz"" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( ""foo : bar"" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( ""foo : baz"" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 , checkerUuid3 ) ; checkersByRepositoryNotes . remove ( CheckerUuid . parse ( ""foo : baz"" ) , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 ) ; } @Test public void removeCheckersFromNonExistingCheckerAndRepository2 ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( ""bar : baz"" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( ""foo : bar"" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( ""foo : baz"" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 , checkerUuid3 ) ; checkersByRepositoryNotes . remove ( CheckerUuid . parse ( ""foo : baz"" ) , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 ) ; } @Test public void removeCheckersFromNonExistingCheckerAndRepository3 ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( ""some - project"" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( ""bar : baz"" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( ""foo : bar"" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( ""foo : baz"" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerU
",,
2312,"protected void configure ( ) { factory ( MultiSiteRepository . Factory . class ) ; factory ( MultiSiteRefDatabase . Factory . class ) ; factory ( MultiSiteRefUpdate . Factory . class ) ; bind ( GitRepositoryManager . class ) . to ( MultiSiteGitRepositoryManager . class ) ; install ( new ZkValidationModule ( cfg ) ) ;
","bind ( GitRepositoryManager . class ) . to ( MultiSiteGitRepositoryManager . class ) ;
","<|del|>
",,,"DynamicSet.bind(binder(), GitRepositoryManager.class) .to(MultiSiteGitRepositoryManager.class); DynamicSet.bind(binder(), SharedRefDatabase.class) .to(ZkSharedRefDatabase.class);
",,,"protected void configure ( ) { factory ( MultiSiteRepository . Factory . class ) ; factory ( MultiSiteRefDatabase . Factory . class ) ; factory ( MultiSiteRefUpdate . Factory . class ) ; install ( new ZkModule ( ) ) ; } @ZookeeperSpecific private static class ZkModule extends AbstractModule { @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , GitRepositoryManager . class ) . to ( MultiSiteGitRepositoryManager . class ) ; DynamicSet . bind ( binder ( ) , SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; install ( new ZkValidationModule ( cfg ) ) ; } }
",,,"protected void configure ( ) { factory ( MultiSiteRepository . Factory . class ) ; factory ( MultiSiteRefDatabase . Factory . class ) ; factory ( MultiSiteRefUpdate . Factory . class ) ; DynamicSet . bind ( binder ( ) , GitRepositoryManager . class ) . to ( MultiSiteGitRepositoryManager . class ) ; DynamicSet . bind ( binder ( ) , SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; install ( new ZkValidationModule ( cfg ) ) ; }
",,,"protected void configure ( ) { factory ( MultiSiteRepository . Factory . class ) ; factory ( MultiSiteRefDatabase . Factory . class ) ; factory ( MultiSiteRefUpdate . Factory . class ) ; < |startfocus| > DynamicSet . bind ( binder ( ) , GitRepositoryManager . class ) . to ( MultiSiteGitRepositoryManager . class ) ; DynamicSet . bind ( binder ( ) , SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; install ( new ZkValidationModule ( cfg ) ) ; < |endfocus| >
",,
2313,"doReturn ( oldRef ) . when ( refUpdate ) . getRef ( ) ; doReturn ( ""refs / heads / master"" ) . when ( refUpdate ) . getName ( ) ; doReturn ( AN_OBJECT_ID_2 ) . when ( refUpdate ) . getNewObjectId ( ) ; doReturn ( newRef ) . when ( sharedRefDb ) . newRef ( ""refs / heads / master"" , AN_OBJECT_ID_2 ) ; } @Test public void newUpdateShouldValidateAndSucceed ( ) throws IOException { setMockRequiredReturnValues ( ) ; // When compareAndPut succeeds doReturn ( true ) . when ( sharedRefDb ) . compareAndPut ( A_TEST_PROJECT_NAME , oldRef , newRef ) ; doReturn ( Result . NEW ) . when ( refUpdate ) . update ( ) ; MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate ( sharedRefDb , ""ProjectName"" , refUpdate ) ; assertThat ( multiSiteRefUpdate . update ( ) ) . isEqualTo ( Result . NEW ) ; } @Test ( expected = IOException . class ) public void newUpdateShouldValidateAndFailWithIOException ( ) throws IOException { setMockRequiredReturnValues ( ) ; // When compareAndPut fails doReturn ( false ) . when ( sharedRefDb ) . compareAndPut ( ""ProjectName"" , oldRef , newRef ) ; MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate ( sharedRefDb , ""ProjectName"" , refUpdate ) ;
","doReturn ( true ) . when ( sharedRefDb ) . compareAndPut ( A_TEST_PROJECT_NAME , oldRef , newRef ) ;
","doReturn(true).when(sharedRefDb).compareAndPut(""ProjectName"", oldRef, newRef);
",,,"doReturn(true).when(sharedRefDb).compareAndPut(A_TEST_PROJECT_NAME, oldRef, newRef);
",,,"doReturn ( oldRef ) . when ( refUpdate ) . getRef ( ) ; doReturn ( ""refs / heads / master"" ) . when ( refUpdate ) . getName ( ) ; doReturn ( AN_OBJECT_ID_2 ) . when ( refUpdate ) . getNewObjectId ( ) ; doReturn ( newRef ) . when ( sharedRefDb ) . newRef ( ""refs / heads / master"" , AN_OBJECT_ID_2 ) ; @Test public void newUpdateShouldValidateAndSucceed ( ) throws IOException { setMockRequiredReturnValues ( ) ; // When compareAndPut succeeds doReturn ( true ) . when ( sharedRefDb ) . compareAndPut ( A_TEST_PROJECT_NAME , oldRef , newRef ) ; doReturn ( Result . NEW ) . when ( refUpdate ) . update ( ) ; MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate ( sharedRefDb , A_TEST_PROJECT_NAME , refUpdate ) ; assertThat ( multiSiteRefUpdate . update ( ) ) . isEqualTo ( Result . NEW ) ; } @Test ( expected = IOException . class ) public void newUpdateShouldValidateAndFailWithIOException ( ) throws IOException { setMockRequiredReturnValues ( ) ; // When compareAndPut fails doReturn ( false ) . when ( sharedRefDb ) . compareAndPut ( A_TEST_PROJECT_NAME , oldRef , newRef ) ; MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate ( sharedRefDb , A_TEST_PROJECT_NAME , refUpdate ) ; multiSiteRefUpdate . update ( ) ; }
",,,"import com . google . gerrit . reviewdb . client . Project . SubmitType ; import com . google . gerrit . server . CurrentUser ; import com . google . gerrit . server . config . AllProjectsName ; import com . google . gerrit . server . project . PerformCreateProject ; import com . google . gerrit . server . project . CreateProject . Input ; import com . google . gwtorm . server . OrmException ; import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . assistedinject . Assisted ; import java . util . Collections ; @RequiresCapability ( GlobalCapability . CREATE_PROJECT ) class CreateProject implements RestModifyView < TopLevelResource , Input > { static class Input { String name ; String parent ; boolean permissionsOnly ; boolean createEmptyCommit ; } static class ProjectInfo { final String kind = ""gerritcodereview#project"" ; String id ; Input createdWith ; void finish ( Input input , final AllProjectsName allProjectName ) { createdWith = input ; id = Url . encode ( createdWith . name ) ; if ( Strings . isNullOrEmpty ( createdWith . parent ) ) { createdWith . parent = allProjectName . get ( ) ; } } } static interface Factory { CreateProject create ( String name ) ; } private final PerformCreateProject . Factory createProjectFactory ; }
",,,"doReturn ( oldRef ) . when ( refUpdate ) . getRef ( ) ; doReturn ( ""refs / heads / master"" ) . when ( refUpdate ) . getName ( ) ; doReturn ( AN_OBJECT_ID_2 ) . when ( refUpdate ) . getNewObjectId ( ) ; doReturn ( newRef ) . when ( sharedRefDb ) . newRef ( ""refs / heads / master"" , AN_OBJECT_ID_2 ) ; } @Test public void newUpdateShouldValidateAndSucceed ( ) throws IOException { setMockRequiredReturnValues ( ) ; // When compareAndPut succeeds < |startfocus| > doReturn ( true ) . when ( sharedRefDb ) . compareAndPut ( A_TEST_PROJECT_NAME , oldRef , newRef ) ; < |endfocus| > doReturn ( Result . NEW ) . when ( refUpdate ) . update ( ) ; MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate ( sharedRefDb , A_TEST_PROJECT_NAME , refUpdate ) ; assertThat ( multiSiteRefUpdate . update ( ) ) . isEqualTo ( Result . NEW ) ; } @Test ( expected = IOException . class ) public void newUpdateShouldValidateAndFailWithIOException ( ) throws IOException { setMockRequiredReturnValues ( ) ; // When compareAndPut fails doReturn ( false ) . when ( sharedRefDb ) . compareAndPut ( A_TEST_PROJECT_NAME , oldRef , newRef ) ; MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate ( sharedRefDb , A_TEST_PROJECT_NAME , refUpdate ) ;
",,
2325,"public void run ( ) { try { dispatcher . get ( ) . postEvent ( new HeartbeatEvent ( ) ) ; } catch ( OrmException e ) { logger . error ( ""Failed to post heartbeat event : { } "" , e . getMessage ( ) , e ) ; }
","logger . error ( ""Failed to post heartbeat event : { } "" , e . getMessage ( ) , e ) ;
","logger.error(""Failed to post heartbeat event: {}"", e.getMessage(), e);
",,,"logger.error(""Failed to post heartbeat event: {}"", e.getMessage(), e);
",,,"public void run ( ) { try { dispatcher . get ( ) . postEvent ( new HeartbeatEvent ( ) ) ; } catch ( OrmException e ) { logger . error ( ""Failed to post heartbeat event : { } "" , e . getMessage ( ) , e ) ; } }
",,,"public void run ( ) { try { dispatcher . get ( ) . postEvent ( new HeartbeatEvent ( ) ) ; } catch ( OrmException e ) { logger . error ( ""Failed to post heartbeat event : { } "" , e . getMessage ( ) , e ) ; } }
",,,"public void run ( ) { try { dispatcher . get ( ) . postEvent ( new HeartbeatEvent ( ) ) ; } catch ( OrmException e ) { < |startfocus| > logger . error ( ""Failed to post heartbeat event : { } "" , e . getMessage ( ) , e ) ; < |endfocus| > }
",,
2335,"AdministrateCheckersPermission permission ) { this . self = self ; this . permissionBackend = permissionBackend ; this . listCheckers = listCheckers ; this . checkers = checkers ; this . views = views ; this . permission = permission ; } @Override public RestView < TopLevelResource > list ( ) throws RestApiException { return listCheckers ; } @Override public CheckerResource parse ( TopLevelResource parent , IdString id ) throws AuthException , ResourceNotFoundException , PermissionBackendException , IOException , ConfigInvalidException { if ( ! self . get ( ) . isIdentifiedUser ( ) ) { throw new AuthException ( ""Authentication required"" ) ; } permissionBackend . currentUser ( ) . check ( permission ) ; Checker checker = checkers . getChecker ( id . get ( ) ) . orElseThrow ( ( ) - > new ResourceNotFoundException ( id ) ) ; return new CheckerResource ( checker ) ; } @Override public DynamicMap < RestView < CheckerResource > > views ( ) { return views ; } }
","if ( ! self . get ( ) . isIdentifiedUser ( ) ) {
","if (!self.get().isIdentifiedUser()) {
",,,"if (!self.get().isIdentifiedUser()) {
",,,"AdministrateCheckersPermission permission ) { this . self = self ; this . permissionBackend = permissionBackend ; this . listCheckers = listCheckers ; this . checkers = checkers ; this . views = views ; this . permission = permission ; } @Override public RestView < TopLevelResource > list ( ) throws RestApiException { return listCheckers ; } @Override public CheckerResource parse ( TopLevelResource parent , IdString id ) throws AuthException , ResourceNotFoundException , PermissionBackendException , IOException , ConfigInvalidException { if ( ! self . get ( ) . isIdentifiedUser ( ) ) { throw new AuthException ( ""Authentication required"" ) ; } permissionBackend . currentUser ( ) . check ( permission ) ; Checker checker = checkers . getChecker ( id . get ( ) ) . orElseThrow ( ( ) - > new ResourceNotFoundException ( id ) ) ; return new CheckerResource ( checker ) ; } @Override public DynamicMap < RestView < CheckerResource > > views ( ) { return views ; }
",,,"public class ExampleClass { private Self self ; private PermissionBackend permissionBackend ; private RestView < TopLevelResource > listCheckers ; private Checkers checkers ; private DynamicMap < RestView < CheckerResource > > views ; private AdministrateCheckersPermission permission ; public ExampleClass ( Self self , PermissionBackend permissionBackend , RestView < TopLevelResource > listCheckers , Checkers checkers , DynamicMap < RestView < CheckerResource > > views , AdministrateCheckersPermission permission ) { this . self = self ; this . permissionBackend = permissionBackend ; this . listCheckers = listCheckers ; this . checkers = checkers ; this . views = views ; this . permission = permission ; } @Override public RestView < TopLevelResource > list ( ) throws RestApiException { return listCheckers ; } @Override public CheckerResource parse ( TopLevelResource parent , IdString id ) throws AuthException , ResourceNotFoundException , PermissionBackendException , IOException , ConfigInvalidException { if ( ! self . get ( ) . isIdentifiedUser ( ) ) { throw new AuthException ( ""Authentication required"" ) ; } permissionBackend . currentUser ( ) . check ( permission ) ; Checker checker = checkers . getChecker ( id . get ( ) ) . orElseThrow ( ( ) - > new ResourceNotFoundException ( id ) ) ; return new CheckerResource ( checker ) ; } @Override public DynamicMap < RestView < CheckerResource > > views ( ) { return views ; } }
",,,"AdministrateCheckersPermission permission ) { this . self = self ; this . permissionBackend = permissionBackend ; this . listCheckers = listCheckers ; this . checkers = checkers ; this . views = views ; this . permission = permission ; } @Override public RestView < TopLevelResource > list ( ) throws RestApiException { return listCheckers ; } @Override public CheckerResource parse ( TopLevelResource parent , IdString id ) throws AuthException , ResourceNotFoundException , PermissionBackendException , IOException , ConfigInvalidException { < |startfocus| > if ( ! self . get ( ) . isIdentifiedUser ( ) ) { < |endfocus| > throw new AuthException ( ""Authentication required"" ) ; } permissionBackend . currentUser ( ) . check ( permission ) ; Checker checker = checkers . getChecker ( id . get ( ) ) . orElseThrow ( ( ) - > new ResourceNotFoundException ( id ) ) ; return new CheckerResource ( checker ) ; } @Override public DynamicMap < RestView < CheckerResource > > views ( ) { return views ; } }
",,
2360,"public static final String GLOBAL_CAPABILITIES = ""GLOBAL_CAPABILITIES"" ; /* * Pattern that matches all references in a project . */ public static final String ALL = ""refs /* "" ; /* * Pattern that matches all branches in a project . */ public static final String HEADS = ""refs / heads /* "" ; /* * Prefix that triggers a regular expression pattern . */ public static final String REGEX_PREFIX = "" ^ "" ; /* * Name of the access section . It could be a ref pattern or something else . */ private String name ; private List < Permission > permissions ; public AccessSection ( String name ) { this . name = name ; this . permissions = new ArrayList < > ( ) ; } /* * @return true if the name is likely to be a valid reference section name . */ public static boolean isValidRefSectionName ( String name ) { return name . startsWith ( ""refs / "" ) || name . startsWith ( "" ^ refs / "" ) ; } public String getName ( ) { return name ; } public ImmutableList < Permission > getPermissions ( ) {
","/* * Name of the access section . It could be a ref pattern or something else . */
","/** Name of the access section. It could be a ref pattern or else. */
",,,"/** Name of the access section. It could be a ref pattern or else. */
",,,"public static final String GLOBAL_CAPABILITIES = ""GLOBAL_CAPABILITIES"" ; public static final String ALL = ""refs /* "" ; public static final String HEADS = ""refs / heads /* "" ; public static final String REGEX_PREFIX = "" ^ "" ; private String refPattern ; private List < Permission > permissions ; public AccessSection ( String refPattern ) { this . refPattern = refPattern ; this . permissions = new ArrayList < > ( ) ; } public static boolean isValidRefSectionName ( String refPattern ) { return refPattern . startsWith ( ""refs / "" ) || refPattern . startsWith ( "" ^ refs / "" ) ; } public String getRefPattern ( ) { return refPattern ; } public ImmutableList < Permission > getPermissions ( ) { return ImmutableList . copyOf ( permissions ) ; }
",,,"public static final String GLOBAL_CAPABILITIES = ""GLOBAL_CAPABILITIES"" ; /* * Pattern that matches all references in a project . */ public static final String ALL = ""refs /* "" ; /* * Pattern that matches all branches in a project . */ public static final String HEADS = ""refs / heads /* "" ; /* * Prefix that triggers a regular expression pattern . */ public static final String REGEX_PREFIX = "" ^ "" ; /* * Name of the ref pattern or access section . */ private String refPattern ; private List < Permission > permissions ; public AccessSection ( String refPattern ) { this . refPattern = refPattern ; this . permissions = new ArrayList < > ( ) ; } /* * @return true if the ref pattern is likely to be a valid reference section name . */ public static boolean isValidRefSectionName ( String refPattern ) { return refPattern . startsWith ( ""refs / "" ) || refPattern . startsWith ( "" ^ refs / "" ) ; } public String getRefPattern ( ) { return refPattern ; } public ImmutableList < Permission > getPermissions ( ) { // implementation }
",,,"public static final String GLOBAL_CAPABILITIES = ""GLOBAL_CAPABILITIES"" ; /* * Pattern that matches all references in a project . */ public static final String ALL = ""refs /* "" ; /* * Pattern that matches all branches in a project . */ public static final String HEADS = ""refs / heads /* "" ; /* * Prefix that triggers a regular expression pattern . */ public static final String REGEX_PREFIX = "" ^ "" ; < |startfocus| > /* * Name of the access section . It could be a ref pattern or else . */ < |endfocus| > private String name ; private List < Permission > permissions ; public AccessSection ( String name ) { this . name = name ; this . permissions = new ArrayList < > ( ) ; } /* * @return true if the name is likely to be a valid reference section name . */ public static boolean isValidRefSectionName ( String name ) { return name . startsWith ( ""refs / "" ) || name . startsWith ( "" ^ refs / "" ) ; } public String getName ( ) { return name ; } public ImmutableList < Permission > getPermissions ( ) { return ImmutableList . copyOf ( permissions ) ; }
",,
2364,"// Project name is scoped by test , so we need to get it from our initial change Project . NameKey projectNameKey = initialResult . getChange ( ) . project ( ) ; String projectName = projectNameKey . get ( ) ; createBranch ( new Branch . NameKey ( projectName , ""ds_one"" ) ) ; createBranch ( new Branch . NameKey ( projectName , ""ds_two"" ) ) ; initialResult . assertOkStatus ( ) ; merge ( initialResult ) ; // Create normalUserGroup , containing user , and contextUserGroup , containing contextUser String normalUserGroup = groupOperations . newGroup ( ) . name ( ""normalUserGroup"" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( normalUserGroup ) . addMembers ( user . id ( ) . toString ( ) ) ; AccountApi contextUserApi = gApi . accounts ( ) . create ( ""someContextUser"" ) ; String contextUserGroup = groupOperations . newGroup ( ) . name ( ""contextUserGroup"" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( contextUserGroup ) . addMembers ( contextUserApi . get ( ) . name ) ; // Grant exclusive + 2 to context user grantLabel ( ""Code - Review"" , - 2 , 2 , projectNameKey , ""refs / heads / ds_one"" , false ,
","// Create normalUserGroup , containing user , and contextUserGroup , containing contextUser
","// Create normalUserGroup, containing current user, and contextUserGroup, containing contextUser
",,,"// Create normalUserGroup, containing current user, and contextUserGroup, containing contextUser
",,,"// Get the project name from the initial result Project . NameKey projectNameKey = initialResult . getChange ( ) . getProject ( ) ; String projectName = projectNameKey . get ( ) ; // Create two branches createBranch ( new Branch . NameKey ( projectName , ""ds_one"" ) ) ; createBranch ( new Branch . NameKey ( projectName , ""ds_two"" ) ) ; // Assert the initial result status initialResult . assertOkStatus ( ) ; // Create normalUserGroup and add the current user as a member String normalUserGroup = groupOperations . newGroup ( ) . name ( ""normalUserGroup"" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( normalUserGroup ) . addMembers ( user . id ( ) . toString ( ) ) ; // Create contextUserGroup and add the contextUser as a member Account . Id contextUserId = gApi . accounts ( ) . create ( ""someContextUser"" ) . get ( ) . _accountId ; String contextUserGroup = groupOperations . newGroup ( ) . name ( ""contextUserGroup"" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( contextUserGroup ) . addMembers ( contextUserId . toString ( ) ) ; // Grant exclusive + 2 to context user for Code - Review label on ds_one branch grantLabel ( ""Code - Review"" , - 2 , 2 , projectNameKey , ""refs / heads / ds_one"" , false , contextUserGroup ) ;
",,,"// Project name is scoped by test , so we need to get it from our initial change Project . NameKey projectNameKey = initialResult . getChange ( ) . project ( ) ; String projectName = projectNameKey . get ( ) ; createBranch ( new Branch . NameKey ( projectName , ""ds_one"" ) ) ; createBranch ( new Branch . NameKey ( projectName , ""ds_two"" ) ) ; initialResult . assertOkStatus ( ) ; // Create normalUserGroup , containing current user , and contextUserGroup , containing contextUser String normalUserGroup = groupOperations . newGroup ( ) . name ( ""normalUserGroup"" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( normalUserGroup ) . addMembers ( user . id ( ) . toString ( ) ) ; AccountApi contextUserApi = gApi . accounts ( ) . create ( ""someContextUser"" ) ; String contextUserGroup = groupOperations . newGroup ( ) . name ( ""contextUserGroup"" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( contextUserGroup ) . addMembers ( contextUserApi . get ( ) . name ) ; // Grant exclusive + 2 to context user grantLabel ( ""Code - Review"" , - 2 , 2 , projectNameKey , ""refs / heads / ds_one"" , false ,
",,,"// Project name is scoped by test , so we need to get it from our initial change Project . NameKey projectNameKey = initialResult . getChange ( ) . project ( ) ; String projectName = projectNameKey . get ( ) ; createBranch ( new Branch . NameKey ( projectName , ""ds_one"" ) ) ; createBranch ( new Branch . NameKey ( projectName , ""ds_two"" ) ) ; initialResult . assertOkStatus ( ) ; merge ( initialResult ) ; < |startfocus| > // Create normalUserGroup , containing current user , and contextUserGroup , containing contextUser < |endfocus| > String normalUserGroup = groupOperations . newGroup ( ) . name ( ""normalUserGroup"" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( normalUserGroup ) . addMembers ( user . id ( ) . toString ( ) ) ; AccountApi contextUserApi = gApi . accounts ( ) . create ( ""someContextUser"" ) ; String contextUserGroup = groupOperations . newGroup ( ) . name ( ""contextUserGroup"" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( contextUserGroup ) . addMembers ( contextUserApi . get ( ) . name ) ; // Grant exclusive + 2 to context user grantLabel ( ""Code - Review"" , - 2 , 2 , projectNameKey , ""refs / heads / ds_one"" , false , ""refs / heads / ds_two"" , false ,
",,
2370,"// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . sshd ; import com . google . gerrit . extensions . annotations . ExtensionPoint ; import java . util . List ; @ExtensionPoint public interface SshExecuteCommandInterceptor { /* * * Check the command and return false if this command must not be run . * * @param command the command * @param arguments the list of arguments * @return whether or not this command with this arguments can be executed */ boolean accept ( String command , List < String > arguments ) ; default String name ( ) { return this . getClass ( ) . getSimpleName ( ) ; } }
","* @return whether or not this command with this arguments can be executed
","* @return whether or not this command with this arguments can be executed
",,,"* @return whether or not this command with this arguments can be executed
",,,"// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . sshd ; import com . google . gerrit . extensions . annotations . ExtensionPoint ; import java . util . List ; @ExtensionPoint public interface SshExecuteCommandInterceptor { /* * * Check if the command with the given arguments can be executed . * * @param command the command * @param arguments the list of arguments * @return true if the command can be executed , false otherwise */ boolean accept ( String command , List < String > arguments ) ; default String name ( ) { return this . getClass ( ) . getSimpleName ( ) ; } }
",,,"// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . sshd ; import com . google . gerrit . extensions . annotations . ExtensionPoint ; import java . util . List ; @ExtensionPoint public interface SshExecuteCommandInterceptor { /* * * Check the command and return false if this command must not be run . * * @param command the command * @param arguments the list of arguments * @return whether or not this command with these arguments can be executed */ boolean accept ( String command , List < String > arguments ) ; default String name ( ) { return this . getClass ( ) . getSimpleName ( ) ; } }
",,,"// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . sshd ; import com . google . gerrit . extensions . annotations . ExtensionPoint ; import java . util . List ; @ExtensionPoint public interface SshExecuteCommandInterceptor { /* * * Check the command and return false if this command must not be run . * * @param command the command * @param arguments the list of arguments < |startfocus| > * @return whether or not this command with this arguments can be executed < |endfocus| > */ boolean accept ( String command , List < String > arguments ) ; default String name ( ) { return this . getClass ( ) . getSimpleName ( ) ; } }
",,
2379,"if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . user ( self ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } IdentifiedUser user = rsrc . getUser ( ) ; authorizedKeys . deleteKey ( user . getAccountId ( ) , rsrc . getSshKey ( ) . getKey ( ) . get ( ) ) ; try { deleteKeyFactory . create ( rsrc . getUser ( ) , ""SSH"" ) . send ( ) ; } catch ( EmailException e ) { log . error ( ""Cannot send SSH key deletion message to { } "" , user . getAccount ( ) . getPreferredEmail ( ) , e ) ; } sshKeyCache . evict ( user . getUserName ( ) ) ; return Response . none ( ) ; } }
","""Cannot send SSH key deletion message to { } "" , user . getAccount ( ) . getPreferredEmail ( ) , e ) ;
","""Cannot send SSH key deletion message to "" + user.getAccount().getPreferredEmail(), e);
",,,"""Cannot send SSH key deletion message to {}"", user.getAccount().getPreferredEmail(), e);
",,,"if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . user ( self ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } IdentifiedUser user = rsrc . getUser ( ) ; authorizedKeys . deleteKey ( user . getAccountId ( ) , rsrc . getSshKey ( ) . getKey ( ) . get ( ) ) ; try { deleteKeyFactory . create ( user , ""SSH"" ) . send ( ) ; } catch ( EmailException e ) { log . error ( ""Cannot send SSH key deletion message to { } "" , user . getAccount ( ) . getPreferredEmail ( ) , e ) ; } sshKeyCache . evict ( user . getUserName ( ) ) ; return Response . none ( ) ;
",,,"if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . user ( self ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } IdentifiedUser user = rsrc . getUser ( ) ; authorizedKeys . deleteKey ( user . getAccountId ( ) , rsrc . getSshKey ( ) . getKey ( ) . get ( ) ) ; try { deleteKeyFactory . create ( rsrc . getUser ( ) , ""SSH"" ) . send ( ) ; } catch ( EmailException e ) { log . error ( ""Cannot send SSH key deletion message to { } "" , user . getAccount ( ) . getPreferredEmail ( ) , e ) ; } sshKeyCache . evict ( user . getUserName ( ) ) ; return Response . none ( ) ;
",,,"if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . user ( self ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } IdentifiedUser user = rsrc . getUser ( ) ; authorizedKeys . deleteKey ( user . getAccountId ( ) , rsrc . getSshKey ( ) . getKey ( ) . get ( ) ) ; try { deleteKeyFactory . create ( rsrc . getUser ( ) , ""SSH"" ) . send ( ) ; } catch ( EmailException e ) { log . error ( < |startfocus| > ""Cannot send SSH key deletion message to { } "" , user . getAccount ( ) . getPreferredEmail ( ) , e ) ; < |endfocus| > } sshKeyCache . evict ( user . getUserName ( ) ) ; return Response . none ( ) ; } }
",,
2385,"Ref nonNullRef = refPair . oldRef == sharedRefDb . NULL_REF || refPair . oldRef == null ? refPair . newRef : refPair . oldRef ; // Doesn't have to be the actual Path we lock but just a unique identifier of the ref String resourceLockKey = String . format ( "" % s - % s"" , projectName , nonNullRef . getName ( ) ) ; locks . addResourceIfNotExist ( resourceLockKey , ( ) - > sharedRefDb . lockRef ( projectName , nonNullRef ) ) ; boolean isInSync ; if ( refPair . oldRef != sharedRefDb . NULL_REF && refPair . oldRef != null ) { isInnSync = sharedRefDb . isMostRecentRefVersion ( projectName , refPair . oldRef ) ; } else { isInnSync = ! sharedRefDb . isPresent ( projectName , refPair . getName ( ) ) ; } if ( ! isInnSync ) { String errorMessage = String . format ( ""Ref % s not in sync with sharedDb , aborting batch"" , refPair . oldRef . getName ( ) ) ; logger . atWarning ( ) . log ( errorMessage ) ; throw new Exception ( errorMessage ) ; } } }
","boolean isInSync ;
","boolean isInnSync;
",,,"boolean isInSync;
",,,"Ref nonNullRef = refPair . oldRef == sharedRefDb . NULL_REF || refPair . oldRef == null ? refPair . newRef : refPair . oldRef ; String resourceLockKey = String . format ( "" % s - % s"" , projectName , nonNullRef . getName ( ) ) ; locks . addResourceIfNotExist ( resourceLockKey , ( ) - > sharedRefDb . lockRef ( projectName , nonNullRef ) ) ; boolean isInSync ; if ( refPair . oldRef != sharedRefDb . NULL_REF && refPair . oldRef != null ) { isInSync = sharedRefDb . isMostRecentRefVersion ( projectName , refPair . oldRef ) ; } else { isInSync = ! sharedRefDb . isPresent ( projectName , refPair . getName ( ) ) ; } if ( ! isInSync ) { String errorMessage = String . format ( ""Ref % s not in sync with sharedDb , aborting batch"" , refPair . oldRef . getName ( ) ) ; logger . atWarning ( ) . log ( errorMessage ) ; throw new Exception ( errorMessage ) ; }
",,,"Ref nonNullRef = refPair . oldRef == sharedRefDb . NULL_REF || refPair . oldRef == null ? refPair . newRef : refPair . oldRef ; String resourceLockKey = String . format ( "" % s - % s"" , projectName , nonNullRef . getName ( ) ) ; locks . addResourceIfNotExist ( resourceLockKey , ( ) - > sharedRefDb . lockRef ( projectName , nonNullRef ) ) ; boolean isInSync ; if ( refPair . oldRef != sharedRefDb . NULL_REF && refPair . oldRef != null ) { isInSync = sharedRefDb . isMostRecentRefVersion ( projectName , refPair . oldRef ) ; } else { isInSync = ! sharedRefDb . isPresent ( projectName , refPair . getName ( ) ) ; } if ( ! isInSync ) { String errorMessage = String . format ( ""Ref % s not in sync with sharedDb , aborting batch"" , refPair . oldRef . getName ( ) ) ; logger . atWarning ( ) . log ( errorMessage ) ; throw new Exception ( errorMessage ) ; }
",,,"Ref nonNullRef = refPair . oldRef == sharedRefDb . NULL_REF || refPair . oldRef == null ? refPair . newRef : refPair . oldRef ; // Doesn't have to be the actual Path we lock but just a unique identifier of the ref String resourceLockKey = String . format ( "" % s - % s"" , projectName , nonNullRef . getName ( ) ) ; locks . addResourceIfNotExist ( resourceLockKey , ( ) - > sharedRefDb . lockRef ( projectName , nonNullRef ) ) ; < |startfocus| > boolean isInSync ; < |endfocus| > if ( refPair . oldRef != sharedRefDb . NULL_REF && refPair . oldRef != null ) { isInSync = sharedRefDb . isMostRecentRefVersion ( projectName , refPair . oldRef ) ; } else { isInSync = ! sharedRefDb . isPresent ( projectName , refPair . getName ( ) ) ; } if ( ! isInSync ) { String errorMessage = String . format ( ""Ref % s not in sync with sharedDb , aborting batch"" , refPair . oldRef . getName ( ) ) ; logger . atWarning ( ) . log ( errorMessage ) ; throw new Exception ( errorMessage ) ; } } }
",,
2406,"} @FunctionalInterface private interface Func { void call ( ) throws Exception ; } private static void assertRuntimeException ( Func func ) throws Exception { try { func . call ( ) ; assert_ ( ) . fail ( ""Expected RuntimeException"" ) ; } catch ( RuntimeException e ) { // Expected . } } private static ObjectReader newReaderWithAmbiguousIds ( ) throws Exception { // Recipe for creating ambiguous IDs courtesy of git core : // https :/ / github . com / git / git / blob / df799f5d99ac51d4fc791d546de3f936088582fc / t / t1512 - rev - parse - disambiguation . sh TestRepository < ? > tr = new TestRepository < > ( new InMemoryRepository ( new DfsRepositoryDescription ( ""repo"" ) ) ) ; String blobData = ""0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nb1rwzyc3\n"" ; RevBlob blob = tr . blob ( blobData ) ; assertThat ( blob . name ( ) ) . isEqualTo ( AMBIGUOUS_BLOB_ID . name ( ) ) ; assertThat ( tr . tree ( tr . file ( ""a0blgqsjc"" , blob ) ) . name ( ) ) . isEqualTo ( AMBIGUOUS_TREE_ID . name ( ) ) ; return tr . getRevWalk ( ) . getObjectReader ( ) ; } }
","// Recipe for creating ambiguous IDs courtesy of git core : // https :/ / github . com / git / git / blob / df799f5d99ac51d4fc791d546de3f936088582fc / t / t1512 - rev - parse - disambiguation . sh
","//recipe for creating ambiguous IDs courtesy of t1512-rev-parse-disambiguation.sh in git core.
",,,"// Recipe for creating ambiguous IDs courtesy of t1512-rev-parse-disambiguation.sh in git core. // See https://code.google.com/p/android/issues/detail?id=1512
",,,"@FunctionalInterface private interface Func { void call ( ) throws Exception ; } private static void assertRuntimeException ( Func func ) throws Exception { try { func . call ( ) ; assert_ ( ) . fail ( ""Expected RuntimeException"" ) ; } catch ( RuntimeException e ) { // Expected . } } private static ObjectReader newReaderWithAmbiguousIds ( ) throws Exception { // Recipe for creating ambiguous IDs courtesy of t1512 - rev - parse - disambiguation . sh in git core . TestRepository < ? > tr = new TestRepository < > ( new InMemoryRepository ( new DfsRepositoryDescription ( ""repo"" ) ) ) ; String blobData = ""0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nb1rwzyc3\n"" ; RevBlob blob = tr . blob ( blobData ) ; assertThat ( blob . name ( ) ) . isEqualTo ( AMBIGUOUS_BLOB_ID . name ( ) ) ; assertThat ( tr . tree ( tr . file ( ""a0blgqsjc"" , blob ) ) . name ( ) ) . isEqualTo ( AMBIGUOUS_TREE_ID . name ( ) ) ; return tr . getRevWalk ( ) . getObjectReader ( ) ; }
",,,"} @FunctionalInterface private interface Func { void call ( ) throws Exception ; } private static void assertRuntimeException ( Func func ) throws Exception { try { func . call ( ) ; assert_ ( ) . fail ( ""Expected RuntimeException"" ) ; } catch ( RuntimeException e ) { // Expected . } } private static ObjectReader newReaderWithAmbiguousIds ( ) throws Exception { // Recipe for creating ambiguous IDs courtesy of t1512 - rev - parse - disambiguation . sh in git core . TestRepository < ? > tr = new TestRepository < > ( new InMemoryRepository ( new DfsRepositoryDescription ( ""repo"" ) ) ) ; String blobData = ""0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nb1rwzyc3\n"" ; RevBlob blob = tr . blob ( blobData ) ; assertThat ( blob . name ( ) ) . isEqualTo ( AMBIGUOUS_BLOB_ID . name ( ) ) ; assertThat ( tr . tree ( tr . file ( ""a0blgqsjc"" , blob ) ) . name ( ) ) . isEqualTo ( AMBIGUOUS_TREE_ID . name ( ) ) ; return tr . getRevWalk ( ) . getObjectReader ( ) ; }
",,,"} @FunctionalInterface private interface Func { void call ( ) throws Exception ; } private static void assertRuntimeException ( Func func ) throws Exception { try { func . call ( ) ; assert_ ( ) . fail ( ""Expected RuntimeException"" ) ; } catch ( RuntimeException e ) { // Expected . } } private static ObjectReader newReaderWithAmbiguousIds ( ) throws Exception { < |startfocus| > // Recipe for creating ambiguous IDs courtesy of t1512 - rev - parse - disambiguation . sh in git core . < |endfocus| > TestRepository < ? > tr = new TestRepository < > ( new InMemoryRepository ( new DfsRepositoryDescription ( ""repo"" ) ) ) ; String blobData = ""0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nb1rwzyc3\n"" ; RevBlob blob = tr . blob ( blobData ) ; assertThat ( blob . name ( ) ) . isEqualTo ( AMBIGUOUS_BLOB_ID . name ( ) ) ; assertThat ( tr . tree ( tr . file ( ""a0blgqsjc"" , blob ) ) . name ( ) ) . isEqualTo ( AMBIGUOUS_TREE_ID . name ( ) ) ; return tr . getRevWalk ( ) . getObjectReader ( ) ; } }
",,
2458,"return ; } try { delegateValidation . apply ( batchRefUpdate , gitUpdateFun ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } } protected RefUpdate . Result executeRefUpdateWithPolicy ( String errorMessage , RefValidationWrapper delegateValidation , RefUpdate refUpdate , NoParameterFunction < RefUpdate . Result > gitUpdateFun ) throws IOException { if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . IGNORED ) { return gitUpdateFun . apply ( ) ; } try { return delegateValidation . apply ( gitUpdateFun , refUpdate ) ; } catch ( IOException e ) { if ( e . getClass ( ) == SharedDbSplitBrainException . class ) { validationMetrics . incrementSplitBrain ( ) ; } logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } return null ; }
","< |del| >/ / If ignored we just do the GIT update
","<|del|>
",,,"<|del|>
",,,"return ; try { delegateValidation . apply ( batchRefUpdate , gitUpdateFun ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } protected RefUpdate . Result executeRefUpdateWithPolicy ( String errorMessage , RefValidationWrapper delegateValidation , RefUpdate refUpdate , NoParameterFunction < RefUpdate . Result > gitUpdateFun ) throws IOException { if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . IGNORED ) { return gitUpdateFun . apply ( ) ; } try { return delegateValidation . apply ( gitUpdateFun , refUpdate ) ; } catch ( IOException e ) { if ( e . getClass ( ) == SharedDbSplitBrainException . class ) { validationMetrics . incrementSplitBrain ( ) ; } logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } return null ; }
",,,"return ; try { delegateValidation . apply ( batchRefUpdate , gitUpdateFun ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } } protected RefUpdate . Result executeRefUpdateWithPolicy ( String errorMessage , RefValidationWrapper delegateValidation , RefUpdate refUpdate , NoParameterFunction < RefUpdate . Result > gitUpdateFun ) throws IOException { if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . IGNORED ) { return gitUpdateFun . apply ( ) ; } try { return delegateValidation . apply ( gitUpdateFun , refUpdate ) ; } catch ( IOException e ) { if ( e . getClass ( ) == SharedDbSplitBrainException . class ) { validationMetrics . incrementSplitBrain ( ) ; } logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } return null ; }
",,,"return ; } try { delegateValidation . apply ( batchRefUpdate , gitUpdateFun ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } } protected RefUpdate . Result executeRefUpdateWithPolicy ( String errorMessage , RefValidationWrapper delegateValidation , RefUpdate refUpdate , NoParameterFunction < RefUpdate . Result > gitUpdateFun ) throws IOException { < |startfocus| > if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . IGNORED ) { return gitUpdateFun . apply ( ) ; } < |endfocus| > try { return delegateValidation . apply ( gitUpdateFun , refUpdate ) ; } catch ( IOException e ) { if ( e . getClass ( ) == SharedDbSplitBrainException . class ) { validationMetrics . incrementSplitBrain ( ) ; } logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } return null ; }
",,
2472,"String staticPath = """" ; if ( cdnPath != null ) { staticPath = cdnPath ; } else if ( canonicalPath != null ) { staticPath = canonicalPath ; } // The resource path must be typed as safe for use in a script src . // TODO ( wyatta ) : Upgrade this to use an appropriate safe URL type . SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer . ordainAsSafe ( staticPath , SanitizedContent . ContentKind . TRUSTED_RESOURCE_URI ) ; Map < String , Object > data = new HashMap < > ( ) ; data . put ( ""canonicalPath"" , canonicalPath ) ; data . put ( ""staticResourcePath"" , sanitizedStaticPath ) ; data . put ( ""faviconPath"" , faviconPath ) ; return data ; } }
","Map < String , Object > data = new HashMap < > ( ) ;
","Map<String, Object> data = new HashMap<>();
",,,"Map<String, Object> data = new HashMap<>();
",,,"String staticPath = """" ; if ( cdnPath != null ) { staticPath = cdnPath ; } else if ( canonicalPath != null ) { staticPath = canonicalPath ; } SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer . ordainAsSafe ( staticPath , SanitizedContent . ContentKind . TRUSTED_RESOURCE_URI ) ; Map < String , ? > data = new HashMap < > ( ) ; data . put ( ""canonicalPath"" , canonicalPath ) ; data . put ( ""staticResourcePath"" , sanitizedStaticPath ) ; data . put ( ""faviconPath"" , faviconPath ) ; return data ;
",,,"String staticPath = """" ; if ( cdnPath != null ) { staticPath = cdnPath ; } else if ( canonicalPath != null ) { staticPath = canonicalPath ; } Map < String , Object > data = new HashMap < > ( ) ; data . put ( ""canonicalPath"" , canonicalPath ) ; data . put ( ""staticResourcePath"" , staticPath ) ; data . put ( ""faviconPath"" , faviconPath ) ; return data ;
",,,"String staticPath = """" ; if ( cdnPath != null ) { staticPath = cdnPath ; } else if ( canonicalPath != null ) { staticPath = canonicalPath ; } // The resource path must be typed as safe for use in a script src . // TODO ( wyatta ) : Upgrade this to use an appropriate safe URL type . SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer . ordainAsSafe ( staticPath , SanitizedContent . ContentKind . TRUSTED_RESOURCE_URI ) ; < |startfocus| > Map < String , Object > data = new HashMap < > ( ) ; < |endfocus| > data . put ( ""canonicalPath"" , canonicalPath ) ; data . put ( ""staticResourcePath"" , sanitizedStaticPath ) ; data . put ( ""faviconPath"" , faviconPath ) ; return data ; } }
",,
2478,"// you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // https :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gitiles ; /* * Assertion methods for Gitiles . */ public class MoreAssert { private MoreAssert ( ) { } /* * Simple version of assertThrows that will be introduced in JUnit 4 . 13 . */ public static < T extends Throwable > T assertThrows ( Class < T > expected , ThrowingRunnable r ) { try { r . run ( ) ; throw new AssertionError ( ""Expected "" + expected . getSimpleName ( ) + "" to be thrown"" ) ; } catch ( Throwable actual ) { if ( expected . isAssignableFrom ( actual . getClass ( ) ) ) { return ( T ) actual ; } throw new AssertionError (
","/* * Assertion methods for Gitiles . */
","/** * More tests for {@link MoreAssert}. */
",,,"import java.io.IOException; import java.util.ArrayList; import java.util.Collections; import java.util.Iterator; import java.util.List; import java.util.Set;
",,,"/* * * This class provides additional assertion methods . */ public class MoreAssert { private MoreAssert ( ) { } /* * * Asserts that the specified exception is thrown when executing the provided code block . * This method is a simplified version of assertThrows that will be introduced in JUnit 4 . 13 . * * @param expected the expected exception class * @param r the code block to execute * @return the thrown exception * @throws AssertionError if the expected exception is not thrown or if it is not assignable from the actual exception */ public static < T extends Throwable > T assertThrows ( Class < T > expected , ThrowingRunnable r ) { try { r . run ( ) ; throw new AssertionError ( ""Expected "" + expected . getSimpleName ( ) + "" to be thrown"" ) ; } catch ( Throwable actual ) { if ( expected . isAssignableFrom ( actual . getClass ( ) ) ) { return ( T ) actual ; } throw new AssertionError ( ""Expected "" + expected . getSimpleName ( ) + "" but got "" + actual . getClass ( ) . getSimpleName ( ) , actual ) ; } } }
",,,"// you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // https :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gitiles ; public class MoreAssert { private MoreAssert ( ) { } /* * * Simple version of assertThrows that will be introduced in JUnit 4 . 13 . */ public static < T extends Throwable > T assertThrows ( Class < T > expected , ThrowingRunnable r ) { try { r . run ( ) ; throw new AssertionError ( ""Expected "" + expected . getSimpleName ( ) + "" to be thrown"" ) ; } catch ( Throwable actual ) { if ( expected . isAssignableFrom ( actual . getClass ( ) ) ) { return ( T ) actual ; } throw new AssertionError ( ""Expected "" + expected . getSimpleName ( ) + "" to be thrown , but got "" + actual . getClass ( ) . getSimpleName ( ) ) ; } } }
",,,"// you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // https :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gitiles ; < |startfocus| > < |endfocus| > public class MoreAssert { private MoreAssert ( ) { } /* * Simple version of assertThrows that will be introduced in JUnit 4 . 13 . */ public static < T extends Throwable > T assertThrows ( Class < T > expected , ThrowingRunnable r ) { try { r . run ( ) ; throw new AssertionError ( ""Expected "" + expected . getSimpleName ( ) + "" to be thrown"" ) ; } catch ( Throwable actual ) { if ( expected . isAssignableFrom ( actual . getClass ( ) ) ) { return ( T ) actual ; } throw new AssertionError ( actual ) ; } } /* * Functional interface for code that may throw an exception . */ @FunctionalInterface public interface ThrowingRunnable { void run ( ) throws Exception ; } }
",,
2493,"private final DynamicItem < UrlFormatter > urlFormatter ; private final Optional < Schedule > schedule ; private final long abandonAfter ; private final boolean abandonIfMergeable ; private final String abandonMessage ; @Inject ChangeCleanupConfig ( @GerritServerConfig Config cfg , DynamicItem < UrlFormatter > urlFormatter ) { this . urlFormatter = urlFormatter ; schedule = ScheduleConfig . createSchedule ( cfg , SECTION ) ; abandonAfter = readAbandonAfter ( cfg ) ; abandonIfMergeable = cfg . getBoolean ( SECTION , null , KEY_ABANDON_IF_MERGEABLE , true ) ; cleanupAccountPatchReview = cfg . getBoolean ( SECTION , null , KEY_CLEANUP_ACCOUNT_PATCH_REVIEW , false ) ; abandonMessage = readAbandonMessage ( cfg ) ; } private long readAbandonAfter ( Config cfg ) { long abandonAfter = ConfigUtil . getTimeUnit ( cfg , SECTION , null , KEY_ABANDON_AFTER , 0 , TimeUnit . MILLISECONDS ) ; return abandonAfter >= 0 ? abandonAfter : 0 ; } private String readAbandonMessage ( Config cfg ) { String abandonMessage = cfg . getString ( SECTION , null , KEY_ABANDON_MESSAGE ) ; return Strings . isNullOrEmpty ( abandonMessage ) ? DEFAULT_ABANDON_MESSAGE : abandonMessage ; } public Optional < Schedule > getSchedule ( ) { return schedule ; } public long getAbandonAfter ( ) { return abandonAfter ; }
","abandonIfMergeable = cfg . getBoolean ( SECTION , null , KEY_ABANDON_IF_MERGEABLE , true ) ; cleanupAccountPatchReview = cfg . getBoolean ( SECTION , null , KEY_CLEANUP_ACCOUNT_PATCH_REVIEW , false ) ;
","abandonIfMergeable = cfg.getBoolean(SECTION, null, KEY_ABANDON_IF_MERGEABLE, false);
",,,"abandonIfMergeable = cfg.getBoolean(SECTION, null, KEY_ABANDON_IF_MERGEABLE, false);
",,,"private final DynamicItem < UrlFormatter > urlFormatter ; private final Optional < Schedule > schedule ; private final long abandonAfter ; private final boolean abandonIfMergeable = false ; // default value private final String abandonMessage ; @Inject ChangeCleanupConfig ( @GerritServerConfig Config cfg , DynamicItem < UrlFormatter > urlFormatter ) { this . urlFormatter = urlFormatter ; schedule = ScheduleConfig . createSchedule ( cfg , SECTION ) ; abandonAfter = readAbandonAfter ( cfg ) ; abandonMessage = readAbandonMessage ( cfg ) ; } private long readAbandonAfter ( Config cfg ) { long abandonAfter = ConfigUtil . getTimeUnit ( cfg , SECTION , null , KEY_ABANDON_AFTER , 0 , TimeUnit . MILLISECONDS ) ; return abandonAfter >= 0 ? abandonAfter : 0 ; } private String readAbandonMessage ( Config cfg ) { String abandonMessage = cfg . getString ( SECTION , null , KEY_ABANDON_MESSAGE ) ; return Strings . isNullOrEmpty ( abandonMessage ) ? DEFAULT_ABANDON_MESSAGE : abandonMessage ; } public Optional < Schedule > getSchedule ( ) { return schedule ; } public long getAbandonAfter ( ) { return abandonAfter ; } public boolean getAbandonIfMergeable ( ) { return abandonIfMergeable ; }
",,,"private final DynamicItem < UrlFormatter > urlFormatter ; private final Optional < Schedule > schedule ; private final long abandonAfter ; private final boolean abandonIfMergeable ; private final String abandonMessage ; @Inject ChangeCleanupConfig ( @GerritServerConfig Config cfg , DynamicItem < UrlFormatter > urlFormatter ) { this . urlFormatter = urlFormatter ; schedule = ScheduleConfig . createSchedule ( cfg , SECTION ) ; abandonAfter = readAbandonAfter ( cfg ) ; abandonIfMergeable = cfg . getBoolean ( SECTION , null , KEY_ABANDON_IF_MERGEABLE , true ) ; abandonMessage = readAbandonMessage ( cfg ) ; } private long readAbandonAfter ( Config cfg ) { long abandonAfter = ConfigUtil . getTimeUnit ( cfg , SECTION , null , KEY_ABANDON_AFTER , 0 , TimeUnit . MILLISECONDS ) ; return abandonAfter >= 0 ? abandonAfter : 0 ; } private String readAbandonMessage ( Config cfg ) { String abandonMessage = cfg . getString ( SECTION , null , KEY_ABANDON_MESSAGE ) ; return Strings . isNullOrEmpty ( abandonMessage ) ? DEFAULT_ABANDON_MESSAGE : abandonMessage ; } public Optional < Schedule > getSchedule ( ) { return schedule ; } public long getAbandonAfter ( ) { return abandonAfter ; }
",,,"private final DynamicItem < UrlFormatter > urlFormatter ; private final Optional < Schedule > schedule ; private final long abandonAfter ; private final boolean abandonIfMergeable ; private final String abandonMessage ; @Inject ChangeCleanupConfig ( @GerritServerConfig Config cfg , DynamicItem < UrlFormatter > urlFormatter ) { this . urlFormatter = urlFormatter ; schedule = ScheduleConfig . createSchedule ( cfg , SECTION ) ; abandonAfter = readAbandonAfter ( cfg ) ; < |startfocus| > abandonIfMergeable = cfg . getBoolean ( SECTION , null , KEY_ABANDON_IF_MERGEABLE , false ) ; < |endfocus| > abandonMessage = readAbandonMessage ( cfg ) ; } private long readAbandonAfter ( Config cfg ) { long abandonAfter = ConfigUtil . getTimeUnit ( cfg , SECTION , null , KEY_ABANDON_AFTER , 0 , TimeUnit . MILLISECONDS ) ; return abandonAfter >= 0 ? abandonAfter : 0 ; } private String readAbandonMessage ( Config cfg ) { String abandonMessage = cfg . getString ( SECTION , null , KEY_ABANDON_MESSAGE ) ; return Strings . isNullOrEmpty ( abandonMessage ) ? DEFAULT_ABANDON_MESSAGE : abandonMessage ; } public Optional < Schedule > getSchedule ( ) { return schedule ; } public long getAbandonAfter ( ) { return abandonAfter ; }
",,
2498,"public class DeleteGpgKey implements RestModifyView < GpgKey , Input > { private static final Logger log = LoggerFactory . getLogger ( DeleteGpgKey . class ) ; public static class Input { } private final Provider < PersonIdent > serverIdent ; private final Provider < PublicKeyStore > storeProvider ; private final ExternalIdsUpdate . User externalIdsUpdateFactory ; private final DeleteKeySender . Factory deleteKeyFactory ; @Inject DeleteGpgKey ( @GerritPersonIdent Provider < PersonIdent > serverIdent , Provider < PublicKeyStore > storeProvider , ExternalIdsUpdate . User externalIdsUpdateFactory , DeleteKeySender . Factory deleteKeySenderFactory ) { this . serverIdent = serverIdent ; this . storeProvider = storeProvider ; this . externalIdsUpdateFactory = externalIdsUpdateFactory ; this . deleteKeyFactory = deleteKeyFactory ; } @Override public Response < ? > apply ( GpgKey rsrc , Input input ) throws ResourceConflictException , PGPException , OrmException , IOException , ConfigInvalidException { PGPPublicKey key = rsrc . getKeyRing ( ) . getPublicKey ( ) ; externalIdsUpdateFactory . create ( ) . delete ( rsrc . getUser ( ) . getAccountId ( ) , ExternalId . Key . create ( SCHEME_GPGKEY , BaseEncoding . base16 ( ) . encode ( key . getFingerprint ( ) ) ) ) ;
","DeleteKeySender . Factory deleteKeySenderFactory ) {
","DeleteKeySender.Factory senderFactory) {
",,,"DeleteKeySender.Factory deleteKeySenderFactory) {
",,,"public class DeleteGpgKey implements RestModifyView < GpgKey , Input > { private static final Logger log = LoggerFactory . getLogger ( DeleteGpgKey . class ) ; public static class Input { } private final Provider < PersonIdent > serverIdent ; private final Provider < PublicKeyStore > storeProvider ; private final ExternalIdsUpdate . User externalIdsUpdateFactory ; private final DeleteKeySender . Factory deleteKeySenderFactory ; @Inject DeleteGpgKey ( @GerritPersonIdent Provider < PersonIdent > serverIdent , Provider < PublicKeyStore > storeProvider , ExternalIdsUpdate . User externalIdsUpdateFactory , DeleteKeySender . Factory deleteKeySenderFactory ) { this . serverIdent = serverIdent ; this . storeProvider = storeProvider ; this . externalIdsUpdateFactory = externalIdsUpdateFactory ; this . deleteKeySenderFactory = deleteKeySenderFactory ; } @Override public Response < ? > apply ( GpgKey rsrc , Input input ) throws ResourceConflictException , PGPException , OrmException , IOException , ConfigInvalidException { PGPPublicKey key = rsrc . getKeyRing ( ) . getPublicKey ( ) ; externalIdsUpdateFactory . create ( ) . delete ( rsrc . getUser ( ) . getAccountId ( ) , ExternalId . Key . create ( SCHEME_GPGKEY , BaseEncoding . base16 ( ) . encode ( key . getFingerprint ( ) ) ) ) ; deleteKeySenderFactory . create ( ) . send ( rsrc . getUser ( ) . getAccountId ( ) , key ) ; return Response . none ( ) ; } }
",,,"public class DeleteGpgKey implements RestModifyView < GpgKey , Input > { private static final Logger log = LoggerFactory . getLogger ( DeleteGpgKey . class ) ; public static class Input { } private final Provider < PersonIdent > serverIdent ; private final Provider < PublicKeyStore > storeProvider ; private final ExternalIdsUpdate . User externalIdsUpdateFactory ; private final DeleteKeySender . Factory deleteKeySenderFactory ; @Inject DeleteGpgKey ( @GerritPersonIdent Provider < PersonIdent > serverIdent , Provider < PublicKeyStore > storeProvider , ExternalIdsUpdate . User externalIdsUpdateFactory , DeleteKeySender . Factory deleteKeySenderFactory ) { this . serverIdent = serverIdent ; this . storeProvider = storeProvider ; this . externalIdsUpdateFactory = externalIdsUpdateFactory ; this . deleteKeySenderFactory = deleteKeySenderFactory ; } @Override public Response < ? > apply ( GpgKey rsrc , Input input ) throws ResourceConflictException , PGPException , OrmException , IOException , ConfigInvalidException { PGPPublicKey key = rsrc . getKeyRing ( ) . getPublicKey ( ) ; externalIdsUpdateFactory . create ( ) . delete ( rsrc . getUser ( ) . getAccountId ( ) , ExternalId . Key . create ( SCHEME_GPGKEY , BaseEncoding . base16 ( ) . encode ( key . getFingerprint ( ) ) ) ) ; // Rest of the method implementation } }
",,,"public class DeleteGpgKey implements RestModifyView < GpgKey , Input > { private static final Logger log = LoggerFactory . getLogger ( DeleteGpgKey . class ) ; public static class Input { } private final Provider < PersonIdent > serverIdent ; private final Provider < PublicKeyStore > storeProvider ; private final ExternalIdsUpdate . User externalIdsUpdateFactory ; private final DeleteKeySender . Factory deleteKeySenderFactory ; @Inject DeleteGpgKey ( @GerritPersonIdent Provider < PersonIdent > serverIdent , Provider < PublicKeyStore > storeProvider , ExternalIdsUpdate . User externalIdsUpdateFactory , < |startfocus| > DeleteKeySender . Factory deleteKeySenderFactory ) { < |endfocus| > this . serverIdent = serverIdent ; this . storeProvider = storeProvider ; this . externalIdsUpdateFactory = externalIdsUpdateFactory ; this . deleteKeySenderFactory = deleteKeySenderFactory ; } @Override public Response < ? > apply ( GpgKey rsrc , Input input ) throws ResourceConflictException , PGPException , OrmException , IOException , ConfigInvalidException { PGPPublicKey key = rsrc . getKeyRing ( ) . getPublicKey ( ) ; externalIdsUpdateFactory . create ( ) . delete ( rsrc . getUser ( ) . getAccountId ( ) , ExternalId . Key . create ( SCHEME_GPGKEY , BaseEncoding . base16 ( ) . encode ( key . getFingerprint ( ) ) ) ) ;
",,
2506,"public DeleteKeySender ( EmailArguments ea , PermissionBackend permissionBackend , IdentifiedUser callingUser , @Assisted IdentifiedUser user , @Assisted List < String > gpgKey ) { super ( ea , ""deletekey"" ) ; this . permissionBackend = permissionBackend ; this . callingUser = callingUser ; this . user = user ; this . gpgKeyFingerprints = gpgKeyFingerprints ; this . sshKey = null ;
","this . gpgKeyFingerprints = gpgKeyFingerprints ;
","<|del|>
",,,"this.gpgKeys = checkNotNull(gpgKeys);
",,,"public DeleteKeySender ( EmailArguments ea , PermissionBackend permissionBackend , IdentifiedUser callingUser , @Assisted IdentifiedUser user , @Assisted List < String > gpgKeys ) { super ( ea , ""deletekey"" ) ; this . permissionBackend = permissionBackend ; this . callingUser = callingUser ; this . user = user ; this . gpgKeys = gpgKeys ; this . sshKey = null ; }
",,,"public DeleteKeySender ( EmailArguments ea , PermissionBackend permissionBackend , IdentifiedUser callingUser , @Assisted IdentifiedUser user , @Assisted List < String > gpgKeys ) { super ( ea , ""deletekey"" ) ; this . permissionBackend = permissionBackend ; this . callingUser = callingUser ; this . user = user ; this . gpgKeys = gpgKeys ; this . sshKey = null ; }
",,,"public DeleteKeySender ( EmailArguments ea , PermissionBackend permissionBackend , IdentifiedUser callingUser , @Assisted IdentifiedUser user , @Assisted List < String > gpgKey ) { super ( ea , ""deletekey"" ) ; this . permissionBackend = permissionBackend ; this . callingUser = callingUser ; this . user = user ; < |startfocus| > this . gpgKeys = gpgKey ; < |endfocus| > this . sshKey = null ;
",,
2516,"drainQueue ( droppedEventsQueue ) ; ChangeData change = createChange ( ) . getChange ( ) ; String project = change . project ( ) . get ( ) ; int changeNum = change . getId ( ) . get ( ) ; String changeNotesRef = change . notes ( ) . getRefName ( ) ; int patchsetNum = change . currentPatchSet ( ) . getPatchSetId ( ) ; String patchsetRevision = change . currentPatchSet ( ) . getRevision ( ) . get ( ) ; String patchsetRef = change . currentPatchSet ( ) . getRefName ( ) ; Map < String , List < Event > > eventsByType = receiveEventsByType ( droppedEventsQueue ) ; assertThat ( eventsByType ) . isNotEmpty ( ) ; assertThat ( eventsByType . get ( ""change - index"" ) ) . containsExactly ( createChangeIndexEvent ( project , changeNum , getParentCommit ( change ) ) ) ; assertThat ( eventsByType . get ( ""ref - updated"" ) . stream ( ) . map ( e - > ( ( RefUpdatedEvent ) e ) . getRefName ( ) ) . collect ( toSet ( ) ) ) . containsAllOf ( changeNotesRef , patchsetRef ) ; // 'refs / sequences / changes' not always updated thus not checked List < Event > patchSetCreatedEvents = eventsByType . get ( ""patchset - created"" ) ; assertThat ( patchSetCreatedEvents ) . hasSize ( 1 ) ; assertPatchSetAttributes (
","Map < String , List < Event > > eventsByType = receiveEventsByType ( droppedEventsQueue ) ; assertThat ( eventsByType ) . isNotEmpty ( ) ;
","Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue, sharedDirConfig);
",,,"Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue, sharedDirConfig);
",,,"Map < String , List < Event > > eventsByType = receiveEventsByType ( droppedEventsQueue ) ; ChangeData change = createChange ( ) . getChange ( ) ; String project = change . project ( ) . get ( ) ; int changeNum = change . getId ( ) . get ( ) ; String changeNotesRef = change . notes ( ) . getRefName ( ) ; int patchsetNum = change . currentPatchSet ( ) . getPatchSetId ( ) ; String patchsetRevision = change . currentPatchSet ( ) . getRevision ( ) . get ( ) ; String patchsetRef = change . currentPatchSet ( ) . getRefName ( ) ; assertThat ( eventsByType . get ( ""change - index"" ) ) . containsExactly ( createChangeIndexEvent ( project , changeNum , getParentCommit ( change ) ) ) ; assertThat ( eventsByType . get ( ""ref - updated"" ) . stream ( ) . map ( e - > ( ( RefUpdatedEvent ) e ) . getRefName ( ) ) . collect ( toSet ( ) ) ) . containsAllOf ( changeNotesRef , patchsetRef ) ; List < Event > patchSetCreatedEvents = eventsByType . get ( ""patchset - created"" ) ; assertThat ( patchSetCreatedEvents ) . hasSize ( 1 ) ; assertPatchSetAttributes ( patchSetCreatedEvents . get ( 0 ) , project , changeNum , patchsetNum , patchsetRevision , patchsetRef ) ;
",,,"drainQueue ( droppedEventsQueue ) ; ChangeData change = createChange ( ) . getChange ( ) ; String project = change . project ( ) . get ( ) ; int changeNum = change . getId ( ) . get ( ) ; String changeNotesRef = change . notes ( ) . getRefName ( ) ; int patchsetNum = change . currentPatchSet ( ) . getPatchSetId ( ) ; String patchsetRevision = change . currentPatchSet ( ) . getRevision ( ) . get ( ) ; String patchsetRef = change . currentPatchSet ( ) . getRefName ( ) ; Map < String , List < Event > > eventsByType = receiveEventsByType ( droppedEventsQueue ) ; assertThat ( eventsByType . get ( ""change - index"" ) ) . containsExactly ( createChangeIndexEvent ( project , changeNum , getParentCommit ( change ) ) ) ; assertThat ( eventsByType . get ( ""ref - updated"" ) . stream ( ) . map ( e - > ( ( RefUpdatedEvent ) e ) . getRefName ( ) ) . collect ( toSet ( ) ) ) . containsAllOf ( changeNotesRef , patchsetRef ) ; // 'refs / sequences / changes' not always updated thus not checked List < Event > patchSetCreatedEvents = eventsByType . get ( ""patchset - created"" ) ; assertThat ( patchSetCreatedEvents ) . hasSize ( 1 ) ; assertPatchSetAttributes ( patchSetCreatedEvents . get ( 0 ) , project , changeNum , patchsetNum , patchsetRevision , patchsetRef ) ;
",,,"drainQueue ( droppedEventsQueue ) ; ChangeData change = createChange ( ) . getChange ( ) ; String project = change . project ( ) . get ( ) ; int changeNum = change . getId ( ) . get ( ) ; String changeNotesRef = change . notes ( ) . getRefName ( ) ; int patchsetNum = change . currentPatchSet ( ) . getPatchSetId ( ) ; String patchsetRevision = change . currentPatchSet ( ) . getRevision ( ) . get ( ) ; String patchsetRef = change . currentPatchSet ( ) . getRefName ( ) ; < |startfocus| > Map < String , List < Event > > eventsByType = receiveEventsByType ( droppedEventsQueue ) ; < |endfocus| > assertThat ( eventsByType . get ( ""change - index"" ) ) . containsExactly ( createChangeIndexEvent ( project , changeNum , getParentCommit ( change ) ) ) ; assertThat ( eventsByType . get ( ""ref - updated"" ) . stream ( ) . map ( e - > ( ( RefUpdatedEvent ) e ) . getRefName ( ) ) . collect ( toSet ( ) ) ) . containsAllOf ( changeNotesRef , patchsetRef ) ; // 'refs / sequences / changes' not always updated thus not checked List < Event > patchSetCreatedEvents = eventsByType . get ( ""patchset - created"" ) ; assertThat ( patchSetCreatedEvents ) . hasSize ( 1 ) ; assertPatchSetAttributes ( patchSetCreatedEvents . get ( 0 ) , project , changeNum , patchsetNum , patchsetRevision ) ;
",,
2528,"} public static String supportedVersions ( ) { return Joiner . on ( "" , "" ) . join ( ElasticVersion . values ( ) ) ; } public boolean isV6 ( ) { return isVersion ( 6 ) ; } public boolean isV6OrLater ( ) { return isAtLeastVersion ( 6 ) ; } public boolean isV7OrLater ( ) { return isAtLeastVersion ( 7 ) ; } private boolean isAtLeastVersion ( int v ) { return Integer . valueOf ( version . split ( ""\\ . "" ) [ 0 ] ) >= v ; } private Integer getMajor ( ) { return Integer . valueOf ( version . split ( ""\\ . "" ) [ 0 ] ) ; } @Override public String toString ( ) { return version ; } }
","private Integer getMajor ( ) { return Integer . valueOf ( version . split ( ""\\ . "" ) [ 0 ] ) ;
","private boolean isVersion(int v) { return Integer.valueOf(version.split(""\\."")[0]) == v;
",,,"private boolean isVersion(int v) { return Integer.valueOf(version.split(""\\."")[0]) >= v;
",,,"public class ElasticVersion { private final String version ; public ElasticVersion ( String version ) { this . version = version ; } public static ElasticVersion of ( String version ) { return new ElasticVersion ( version ) ; } public static String supportedVersions ( ) { return Joiner . on ( "" , "" ) . join ( ElasticVersion . values ( ) ) ; } public boolean isV6 ( ) { return isVersion ( 6 ) ; } public boolean isV6OrLater ( ) { return isAtLeastVersion ( 6 ) ; } public boolean isV7OrLater ( ) { return isAtLeastVersion ( 7 ) ; } private boolean isAtLeastVersion ( int v ) { return Integer . valueOf ( version . split ( ""\\ . "" ) [ 0 ] ) >= v ; } private boolean isVersion ( int v ) { return Integer . valueOf ( version . split ( ""\\ . "" ) [ 0 ] ) == v ; } @Override public String toString ( ) { return version ; } }
",,,"public class ElasticVersion { private String version ; public ElasticVersion ( String version ) { this . version = version ; } public static String supportedVersions ( ) { return Joiner . on ( "" , "" ) . join ( ElasticVersion . values ( ) ) ; } public boolean isV6 ( ) { return isVersion ( 6 ) ; } public boolean isV6OrLater ( ) { return isAtLeastVersion ( 6 ) ; } public boolean isV7OrLater ( ) { return isAtLeastVersion ( 7 ) ; } private boolean isAtLeastVersion ( int v ) { return Integer . valueOf ( version . split ( ""\\ . "" ) [ 0 ] ) >= v ; } private boolean isVersion ( int v ) { return Integer . valueOf ( version . split ( ""\\ . "" ) [ 0 ] ) == v ; } @Override public String toString ( ) { return version ; } }
",,,"} public static String supportedVersions ( ) { return Joiner . on ( "" , "" ) . join ( ElasticVersion . values ( ) ) ; } public boolean isV6 ( ) { return isVersion ( 6 ) ; } public boolean isV6OrLater ( ) { return isAtLeastVersion ( 6 ) ; } public boolean isV7OrLater ( ) { return isAtLeastVersion ( 7 ) ; } private boolean isAtLeastVersion ( int v ) { return Integer . valueOf ( version . split ( ""\\ . "" ) [ 0 ] ) >= v ; } < |startfocus| > private boolean isVersion ( int v ) { return Integer . valueOf ( version . split ( ""\\ . "" ) [ 0 ] ) == v ; } @Override public String toString ( ) { return version ; } }
",,
2540,"projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefInLocal_Fails ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . update ( ) ; projectOperations . project ( localKey ) . forUpdate ( ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlag ( ) throws Exception { projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ;
",". add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . update ( ) ; projectOperations . project ( localKey ) . forUpdate ( )
",".add(block(PUSH).ref(""refs/heads/*"").group(ANONYMOUS_USERS))
",,,".add(block(PUSH).ref(""refs/heads/*"").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref(""refs/heads/master"").group(DEVS))
",,,"projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . update ( ) ; projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ;
",,,"projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; @Test public void unblockMoreSpecificRefInLocal_Fails ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlag ( ) throws Exception { projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ;
",,,"projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefInLocal_Fails ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) < |startfocus| > . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) < |endfocus| > . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlag ( ) throws Exception { projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCanUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails2 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails3 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails4 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails5 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails6 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails7 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails8 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails9 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails10 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( ""refs / heads /* "" ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( ""refs / heads / master"" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( ""refs / heads / master"" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( ""refs / heads / master"" , u
",,
2547,"public class BranchCommitValidator { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private final CommitValidators . Factory commitValidatorsFactory ; private final IdentifiedUser user ; private final PermissionBackend . ForProject permissions ; private final Project project ; private final BranchNameKey branch ; private final SshInfo sshInfo ; interface Factory { BranchCommitValidator create ( ProjectState projectState , BranchNameKey branch , IdentifiedUser user ) ; } /* * A boolean validation status and a list of additional messages . */ @AutoValue abstract static class Result { static Result create ( boolean isValid , ImmutableList < CommitValidationMessage > messages ) { return new AutoValue_BranchCommitValidator_Result ( isValid , messages ) ; } /* * Whether the commit is valid . */ abstract boolean isValid ( ) ; /* * * A list of messages related to the validation . Messages may be present regardless of the * { @link #isValid ( ) } status . */ abstract List < CommitValidationMessage > messages ( ) ; } @Inject BranchCommitValidator ( CommitValidators . Factory commitValidatorsFactory , PermissionBackend permissionBackend , SshInfo sshInfo ,
","abstract static class Result { static Result create ( boolean isValid , ImmutableList < CommitValidationMessage > messages ) {
","abstract class Result { static Result create(boolean isValid, List<CommitValidationMessage> messages) {
",,,"public static abstract class Result { static Result create(boolean isValid, List<CommitValidationMessage> messages) {
",,,"import java . util . List ; import com . google . common . flogger . FluentLogger ; import com . google . gerrit . entities . BranchNameKey ; import com . google . gerrit . entities . Project ; import com . google . gerrit . entities . ProjectState ; import com . google . gerrit . extensions . api . access . PermissionBackend ; import com . google . gerrit . extensions . common . CommitValidationMessage ; import com . google . gerrit . extensions . config . FactoryModule ; import com . google . gerrit . extensions . restapi . SshInfo ; import com . google . gerrit . server . IdentifiedUser ; import com . google . gerrit . server . validators . CommitValidators ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import com . google . inject . assistedinject . Assisted ; import com . google . inject . assistedinject . AssistedInject ; import com . google . inject . internal . util . ImmutableList ; @Singleton public class BranchCommitValidator { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private final CommitValidators . Factory commitValidatorsFactory ; private final IdentifiedUser user ; private final PermissionBackend . ForProject permissions ; private final Project project ; private final BranchNameKey branch ; private final SshInfo sshInfo ; interface Factory { BranchCommitValidator create ( ProjectState projectState , BranchNameKey branch , IdentifiedUser user ) ; } @AssistedInject public BranchCommitValidator ( CommitValidators . Factory commitValidatorsFactory , PermissionBackend permissionBackend , SshInfo sshInfo , @Assisted ProjectState projectState , @Assisted BranchNameKey branch , @Assisted IdentifiedUser user ) { this . commitValidatorsFactory = commitValidatorsFactory ; this . user = user ; this . permissions = permissionBackend . user ( user ) . project ( projectState . getNameKey ( ) ) ; this . project = projectState . getProject ( ) ; this . branch = branch ; this . sshInfo = sshInfo ; } /* * A boolean validation status and a list of additional messages . */ public static class Result { private final boolean isValid ; private final ImmutableList < CommitValidationMessage > messages ; public Result ( boolean isValid , List < CommitValidationMessage > messages ) { this . isValid = isValid ; this . messages = ImmutableList . copyOf ( messages ) ; } /* * Whether the commit is valid . */ public boolean isValid ( ) { return isValid ; } /* * * A list of messages related to the validation . Messages may be present regardless of the * { @link #isValid ( ) } status .
",,,"public class BranchCommitValidator { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private final CommitValidators . Factory commitValidatorsFactory ; private final IdentifiedUser user ; private final PermissionBackend . ForProject permissions ; private final Project project ; private final BranchNameKey branch ; private final SshInfo sshInfo ; interface Factory { BranchCommitValidator create ( ProjectState projectState , BranchNameKey branch , IdentifiedUser user ) ; } public static class Result { static Result create ( boolean isValid , List < CommitValidationMessage > messages ) { return new Result ( isValid , messages ) ; } private final boolean isValid ; private final List < CommitValidationMessage > messages ; private Result ( boolean isValid , List < CommitValidationMessage > messages ) { this . isValid = isValid ; this . messages = messages ; } public boolean isValid ( ) { return isValid ; } public List < CommitValidationMessage > messages ( ) { return messages ; } } @Inject public BranchCommitValidator ( CommitValidators . Factory commitValidatorsFactory , PermissionBackend permissionBackend , SshInfo sshInfo ) { this . commitValidatorsFactory = commitValidatorsFactory ; this . user = user ; this . permissions = permissions ; this . project = project ; this . branch = branch ; this . sshInfo = sshInfo ; } }
",,,"public class BranchCommitValidator { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private final CommitValidators . Factory commitValidatorsFactory ; private final IdentifiedUser user ; private final PermissionBackend . ForProject permissions ; private final Project project ; private final BranchNameKey branch ; private final SshInfo sshInfo ; interface Factory { BranchCommitValidator create ( ProjectState projectState , BranchNameKey branch , IdentifiedUser user ) ; } /* * A boolean validation status and a list of additional messages . */ @AutoValue < |startfocus| > public static abstract class Result { static Result create ( boolean isValid , List < CommitValidationMessage > messages ) { < |endfocus| > return new AutoValue_BranchCommitValidator_Result ( isValid , messages ) ; } /* * Whether the commit is valid . */ abstract boolean isValid ( ) ; /* * * A list of messages related to the validation . Messages may be present regardless of the * { @link #isValid ( ) } status . */ abstract List < CommitValidationMessage > messages ( ) ; } @Inject BranchCommitValidator ( CommitValidators . Factory commitValidatorsFactory , PermissionBackend permissionBackend , SshInfo sshInfo ,
",,
2566,"import com . google . gerrit . server . git . validators . ValidationMessage ; import com . google . gerrit . server . project . ProjectConfig ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightPatterns ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightPatterns . UnknownPatternName ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightScanner ; import java . util . ArrayList ; import java . util . Collection ; import java . util . LinkedHashSet ; import java . util . Objects ; import java . util . function . Consumer ; import java . util . regex . Pattern ; import java . util . regex . PatternSyntaxException ; /* * Configuration state for { @link CopyrightValidator } from All - Projects project . config file . */ class ScannerConfig { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; public static final String KEY_ENABLE = ""enable"" ; static final String KEY_TIME_TEST_MAX = ""timeTestMax"" ; static final String DEFAULT_REVIEW_LABEL = ""Copyright - Review"" ; static final String KEY_REVIEWER = ""reviewer"" ; static final String KEY_CC = ""cc"" ; static final String KEY_FROM = ""fromAccountId"" ; static final String KEY_REVIEW_LABEL = ""reviewLabel"" ; static final String KEY_EXCLUDE = ""exclude"" ;
","/* * Configuration state for { @link CopyrightValidator } from All - Projects project . config file . */
","/** Configuration state for {@link CopyrightValidator}. */
",,,"/** Configuration state for {@link CopyrightValidator}. */
",,,"import com . google . gerrit . server . git . validators . ValidationMessage ; import com . google . gerrit . server . project . ProjectConfig ; import com . googlesource . gerrit . plugins . copyright . lib .* ; import java . util .* ; /* * * Configuration state for the CopyrightValidator . */ class ScannerConfig { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; public static final String KEY_ENABLE = ""enable"" ; static final String KEY_TIME_TEST_MAX = ""timeTestMax"" ; static final String DEFAULT_REVIEW_LABEL = ""Copyright - Review"" ; static final String KEY_REVIEWER = ""reviewer"" ; static final String KEY_CC = ""cc"" ; static final String KEY_FROM = ""fromAccountId"" ; static final String KEY_REVIEW_LABEL = ""reviewLabel"" ; static final String KEY_EXCLUDE = ""exclude"" ; }
",,,"import com . google . gerrit . server . git . validators . ValidationMessage ; import com . google . gerrit . server . project . ProjectConfig ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightPatterns ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightPatterns . UnknownPatternName ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightScanner ; import java . util . ArrayList ; import java . util . Collection ; import java . util . LinkedHashSet ; import java . util . Objects ; import java . util . function . Consumer ; import java . util . regex . Pattern ; import java . util . regex . PatternSyntaxException ; class ScannerConfig { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; public static final String KEY_ENABLE = ""enable"" ; static final String KEY_TIME_TEST_MAX = ""timeTestMax"" ; static final String DEFAULT_REVIEW_LABEL = ""Copyright - Review"" ; static final String KEY_REVIEWER = ""reviewer"" ; static final String KEY_CC = ""cc"" ; static final String KEY_FROM = ""fromAccountId"" ; static final String KEY_REVIEW_LABEL = ""reviewLabel"" ; static final String KEY_EXCLUDE = ""exclude"" ; }
",,,"import com . google . gerrit . server . git . validators . ValidationMessage ; import com . google . gerrit . server . project . ProjectConfig ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightPatterns ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightPatterns . UnknownPatternName ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightScanner ; import java . util . ArrayList ; import java . util . Collection ; import java . util . LinkedHashSet ; import java . util . Objects ; import java . util . function . Consumer ; import java . util . regex . Pattern ; import java . util . regex . PatternSyntaxException ; < |startfocus| > /* * Configuration state for { @link CopyrightValidator } . */ < |endfocus| > class ScannerConfig { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; public static final String KEY_ENABLE = ""enable"" ; static final String KEY_TIME_TEST_MAX = ""timeTestMax"" ; static final String DEFAULT_REVIEW_LABEL = ""Copyright - Review"" ; static final String KEY_REVIEWER = ""reviewer"" ; static final String KEY_CC = ""cc"" ; static final String KEY_FROM = ""fromAccountId"" ; static final String KEY_REVIEW_LABEL = ""reviewLabel"" ; static final String KEY_EXCLUDE = ""exclude"" ; < |startfocus| > /* * * The state of the scanner . */ < |endfocus| > enum State { /* * * The scanner is disabled . */ DISABLED , /* * * The scanner is enabled . */ ENABLED , /* * * The scanner is enabled , but the configuration is invalid . */ INVALID }
",,
2573,"} else if ( input . httpPassword == null ) { newPassword = null ; } else { // Only administrators can explicitly set the password . permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; newPassword = input . httpPassword ; } return apply ( rsrc . getUser ( ) , newPassword ) ; } // Used by the admin console plugin // TODO ( dpursehouse ) : Replace comment with @UsedAt public Response < String > apply ( IdentifiedUser user , String newPassword ) throws ResourceNotFoundException , ResourceConflictException , IOException , ConfigInvalidException { String userName = user . getUserName ( ) . orElseThrow ( ( ) - > new ResourceConflictException ( ""username must be set"" ) ) ; Optional < ExternalId > optionalExtId = externalIds . get ( ExternalId . Key . create ( SCHEME_USERNAME , userName ) ) ; ExternalId extId = optionalExtId . orElseThrow ( ResourceNotFoundException : : new ) ; accountsUpdateProvider . get ( ) . update ( ""Set HTTP Password via API"" , extId . accountId ( ) , u - > u . updateExternalId ( ExternalId . createWithPassword (
","throws ResourceNotFoundException , ResourceConflictException , IOException ,
","throws ResourceNotFoundException, ResourceConflictException, OrmException, IOException, PermissionBackendException,
",,,"throws BadRequestException, OrmException, IOException,
",,,"if ( input . httpPassword == null ) { newPassword = null ; } else { // Only administrators can explicitly set the password . permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; newPassword = input . httpPassword ; } return apply ( rsrc . getUser ( ) , newPassword ) ; @UsedAt public Response < String > apply ( IdentifiedUser user , String newPassword ) throws RestApiException , IOException , ConfigInvalidException { String userName = user . getUserName ( ) . orElseThrow ( ( ) - > new ResourceNotFoundException ( ""username must be set"" ) ) ; ExternalId . Key extIdKey = ExternalId . Key . create ( SCHEME_USERNAME , userName ) ; ExternalId extId = externalIds . get ( extIdKey ) . orElseThrow ( ResourceNotFoundException : : new ) ; accountsUpdateProvider . get ( ) . update ( ""Set HTTP Password via API"" , extId . accountId ( ) , u - > u . updateExternalId ( ExternalId . createWithPassword ( extIdKey , extId . email ( ) , newPassword ) ) ) ; return Response . ok ( ""Password updated"" ) ; }
",,,"} else if ( input . httpPassword == null ) { newPassword = null ; } else { permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; newPassword = input . httpPassword ; } return apply ( rsrc . getUser ( ) , newPassword ) ; public Response < String > apply ( IdentifiedUser user , String newPassword ) throws ResourceNotFoundException , ResourceConflictException , OrmException , IOException , ConfigInvalidException { String userName = user . getUserName ( ) . orElseThrow ( ( ) - > new ResourceConflictException ( ""username must be set"" ) ) ; Optional < ExternalId > optionalExtId = externalIds . get ( ExternalId . Key . create ( SCHEME_USERNAME , userName ) ) ; ExternalId extId = optionalExtId . orElseThrow ( ResourceNotFoundException : : new ) ; accountsUpdateProvider . get ( ) . update ( ""Set HTTP Password via API"" , extId . accountId ( ) , u - > u . updateExternalId ( ExternalId . createWithPassword ( extId . key ( ) , extId . accountId ( ) , extId . email ( ) , newPassword ) ) ) ; return Response . ok ( ""Password updated"" ) ; }
",,,"} else if ( input . httpPassword == null ) { newPassword = null ; } else { // Only administrators can explicitly set the password . permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; newPassword = input . httpPassword ; } return apply ( rsrc . getUser ( ) , newPassword ) ; } // Used by the admin console plugin // TODO ( dpursehouse ) : Replace comment with @UsedAt public Response < String > apply ( IdentifiedUser user , String newPassword ) < |startfocus| > throws ResourceNotFoundException , ResourceConflictException , OrmException , IOException , < |endfocus| > ConfigInvalidException { String userName = user . getUserName ( ) . orElseThrow ( ( ) - > new ResourceConflictException ( ""username must be set"" ) ) ; Optional < ExternalId > optionalExtId = externalIds . get ( ExternalId . Key . create ( SCHEME_USERNAME , userName ) ) ; ExternalId extId = optionalExtId . orElseThrow ( ResourceNotFoundException : : new ) ; accountsUpdateProvider . get ( ) . update ( ""Set HTTP Password via API"" , extId . accountId ( ) , u - > u . updateExternalId ( ExternalId . createWithPassword (
",,
2591,"""revision % s : error adding reviewer % s : % s"" , event . getChange ( ) . currentRevision , entry . getKey ( ) , arr . error ) ; metrics . addReviewerErrors . increment ( event . getChange ( ) . project ) ; metrics . errors . increment ( ) ; } } } private String readFileContents ( Repository repo , ObjectId objectId , String filename ) throws IOException { try ( RevWalk rw = new RevWalk ( repo ) ; TreeWalk tw = TreeWalk . forPath ( rw . getObjectReader ( ) , filename , rw . parseTree ( objectId ) ) ) { ObjectLoader loader = repo . open ( tw . getObjectId ( 0 ) , Constants . OBJ_BLOB ) ; return new String ( loader . getCachedBytes ( ) , UTF_8 ) ; } } }
","try ( RevWalk rw = new RevWalk ( repo ) ; TreeWalk tw = TreeWalk . forPath ( rw . getObjectReader ( ) , filename , rw . parseTree ( objectId ) ) ) {
","try (TreeWalk tw = TreeWalk.forPath(rw.getObjectReader(), filename, objectId)) {
",,,"try (TreeWalk tw = TreeWalk.forPath(repo, filename, null)) {
",,,"try ( RevWalk rw = new RevWalk ( repo ) ) { RevTree tree = rw . parseTree ( objectId ) ; TreeWalk tw = TreeWalk . forPath ( rw . getObjectReader ( ) , filename , tree ) ; if ( tw == null ) { throw new FileNotFoundException ( ""File not found in tree"" ) ; } ObjectLoader loader = repo . open ( tw . getObjectId ( 0 ) , Constants . OBJ_BLOB ) ; return new String ( loader . getCachedBytes ( ) , UTF_8 ) ; } catch ( IOException e ) { throw new IOException ( ""Error reading file contents"" , e ) ; }
",,,"private String readFileContents ( Repository repo , ObjectId objectId , String filename ) throws IOException { RevWalk rw = new RevWalk ( repo ) ; RevTree tree = rw . parseTree ( objectId ) ; try ( TreeWalk tw = TreeWalk . forPath ( rw . getObjectReader ( ) , filename , tree ) ) { if ( tw != null ) { ObjectLoader loader = repo . open ( tw . getObjectId ( 0 ) , Constants . OBJ_BLOB ) ; return new String ( loader . getCachedBytes ( ) , UTF_8 ) ; } } return null ; }
",,,"""revision % s : error adding reviewer % s : % s"" , event . getChange ( ) . currentRevision , entry . getKey ( ) , arr . error ) ; metrics . addReviewerErrors . increment ( event . getChange ( ) . project ) ; metrics . errors . increment ( ) ; } } } private String readFileContents ( Repository repo , ObjectId objectId , String filename ) throws IOException { RevWalk rw = new RevWalk ( repo ) ; RevTree tree = rw . parseTree ( objectId ) ; try ( TreeWalk tw = TreeWalk . forPath ( rw . getObjectReader ( ) , filename , tree ) ) { if ( tw == null ) { return null ; } ObjectLoader loader = repo . open ( tw . getObjectId ( 0 ) , Constants . OBJ_BLOB ) ; return new String ( loader . getCachedBytes ( ) , UTF_8 ) ; } } }
",,
2594,"import org . apache . curator . retry . BoundedExponentialBackoffRetry ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class ZookeeperConfig { private static final Logger log = LoggerFactory . getLogger ( ZookeeperConfig . class ) ; public static final int defaultSessionTimeoutMs ; public static final int defaultConnectionTimeoutMs ; public static final String DEFAULT_ZK_CONNECT = ""localhost : 2181"" ; private final int DEFAULT_RETRY_POLICY_BASE_SLEEP_TIME_MS = 1000 ; private final int DEFAULT_RETRY_POLICY_MAX_SLEEP_TIME_MS = 3000 ; private final int DEFAULT_RETRY_POLICY_MAX_RETRIES = 3 ; private final int DEFAULT_CAS_RETRY_POLICY_BASE_SLEEP_TIME_MS = 100 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_SLEEP_TIME_MS = 300 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3 ;
","< |del| >/ / TODO Read from different config file when moving it into a plugin public static final String ZOOKEEPER_MS_CONFIG = ""multi - site . config"" ;
","<|del|>
",,,"public static final String ZOOKEEPER_MS_CONFIG = ""multi-site.config"";
",,,"import org . apache . curator . retry . BoundedExponentialBackoffRetry ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class ZookeeperConfig { private static final Logger log = LoggerFactory . getLogger ( ZookeeperConfig . class ) ; public static final String ZOOKEEPER_MS_CONFIG = ""multi - site . config"" ; public static final int defaultSessionTimeoutMs = 30000 ; public static final int defaultConnectionTimeoutMs = 15000 ; public static final String DEFAULT_ZK_CONNECT = ""localhost : 2181"" ; private final int DEFAULT_RETRY_POLICY_BASE_SLEEP_TIME_MS = 1000 ; private final int DEFAULT_RETRY_POLICY_MAX_SLEEP_TIME_MS = 3000 ; private final int DEFAULT_RETRY_POLICY_MAX_RETRIES = 3 ; private final int DEFAULT_CAS_RETRY_POLICY_BASE_SLEEP_TIME_MS = 100 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_SLEEP_TIME_MS = 300 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3 ; }
",,,"import org . apache . curator . retry . BoundedExponentialBackoffRetry ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class ZookeeperConfig { private static final Logger log = LoggerFactory . getLogger ( ZookeeperConfig . class ) ; public static final String ZOOKEEPER_MS_CONFIG = ""multi - site . config"" ; public static final int defaultSessionTimeoutMs ; public static final int defaultConnectionTimeoutMs ; public static final String DEFAULT_ZK_CONNECT = ""localhost : 2181"" ; private final int DEFAULT_RETRY_POLICY_BASE_SLEEP_TIME_MS = 1000 ; private final int DEFAULT_RETRY_POLICY_MAX_SLEEP_TIME_MS = 3000 ; private final int DEFAULT_RETRY_POLICY_MAX_RETRIES = 3 ; private final int DEFAULT_CAS_RETRY_POLICY_BASE_SLEEP_TIME_MS = 100 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_SLEEP_TIME_MS = 300 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3 ; }
",,,"import org . apache . curator . retry . BoundedExponentialBackoffRetry ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class ZookeeperConfig { private static final Logger log = LoggerFactory . getLogger ( ZookeeperConfig . class ) ; < |startfocus| > // TODO Read from different config file when moving it into a plugin public static final String ZOOKEEPER_MS_CONFIG = ""multi - site . config"" ; < |endfocus| > public static final int defaultSessionTimeoutMs ; public static final int defaultConnectionTimeoutMs ; public static final String DEFAULT_ZK_CONNECT = ""localhost : 2181"" ; private final int DEFAULT_RETRY_POLICY_BASE_SLEEP_TIME_MS = 1000 ; private final int DEFAULT_RETRY_POLICY_MAX_SLEEP_TIME_MS = 3000 ; private final int DEFAULT_RETRY_POLICY_MAX_RETRIES = 3 ; private final int DEFAULT_CAS_RETRY_POLICY_BASE_SLEEP_TIME_MS = 100 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_SLEEP_TIME_MS = 300 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3 ;
",,
2632,"} /* * Returns the URL for viewing a comment in a file in a given patch set of a change . */ default Optional < String > getInlineCommentView ( Change change , int patchsetId , String filename , short side , int startLine ) { return getPatchFileView ( change , patchsetId , filename ) . map ( url - > url + String . format ( ""@ % s % d"" , side == 0 ? ""a"" : """" , startLine ) ) ; } /* * Returns a URL pointing to a section of the settings page . */ default Optional < String > getSettingsUrl ( @Nullable String section ) { return getWebUrl ( ) . map ( url - > url + ""settings"" + ( Strings . isNullOrEmpty ( section ) ? """" : ""#"" + section ) ) ; } /* * Returns a URL pointing to a documentation page , at a given named anchor . */ default Optional < String > getDocUrl ( String page , String anchor ) { return getWebUrl ( ) . map ( url - > url + ""Documentation / "" + page + ""#"" + anchor ) ; }
","/* * Returns a URL pointing to a section of the settings page . */
","/** Returns a URL pointing to the settings page. */
",,,"/** Returns a URL pointing to a section of the settings page. */
",,,"/* * * Returns the URL for viewing a comment in a file in a given patch set of a change . */ default Optional < String > getInlineCommentView ( Change change , int patchsetId , String filename , short side , int startLine ) { return getPatchFileView ( change , patchsetId , filename ) . map ( url - > url + String . format ( ""@ % s % d"" , side == 0 ? ""a"" : """" , startLine ) ) ; } /* * * Returns a URL pointing to the settings page . */ default Optional < String > getSettingsUrl ( @Nullable String section ) { return getWebUrl ( ) . map ( url - > url + ""settings"" + ( Strings . isNullOrEmpty ( section ) ? """" : ""#"" + section ) ) ; } /* * * Returns a URL pointing to a documentation page , at a given named anchor . */ default Optional < String > getDocUrl ( String page , String anchor ) { return getWebUrl ( ) . map ( url - > url + ""Documentation / "" + page + ""#"" + anchor ) ; }
",,,"/* * Returns the URL for viewing a comment in a file in a given patch set of a change . */ default Optional < String > getInlineCommentView ( Change change , int patchsetId , String filename , short side , int startLine ) { return getPatchFileView ( change , patchsetId , filename ) . map ( url - > url + String . format ( ""@ % s % d"" , side == 0 ? ""a"" : """" , startLine ) ) ; } /* * * Returns a URL pointing to the settings page . */ default Optional < String > getSettingsUrl ( @Nullable String section ) { return getWebUrl ( ) . map ( url - > url + ""settings"" + ( Strings . isNullOrEmpty ( section ) ? """" : ""#"" + section ) ) ; } /* * Returns a URL pointing to a documentation page , at a given named anchor . */ default Optional < String > getDocUrl ( String page , String anchor ) { return getWebUrl ( ) . map ( url - > url + ""Documentation / "" + page + ""#"" + anchor ) ; }
",,,"} /* * Returns the URL for viewing a comment in a file in a given patch set of a change . */ default Optional < String > getInlineCommentView ( Change change , int patchsetId , String filename , short side , int startLine ) { return getPatchFileView ( change , patchsetId , filename ) . map ( url - > url + String . format ( ""@ % s % d"" , side == 0 ? ""a"" : """" , startLine ) ) ; } < |startfocus| > /* * Returns a URL pointing to the settings page . */ < |endfocus| > default Optional < String > getSettingsUrl ( @Nullable String section ) { return getWebUrl ( ) . map ( url - > url + ""settings"" + ( Strings . isNullOrEmpty ( section ) ? """" : ""#"" + section ) ) ; } /* * Returns a URL pointing to a documentation page , at a given named anchor . */ default Optional < String > getDocUrl ( String page , String anchor ) { return getWebUrl ( ) . map ( url - > url + ""Documentation / "" + page + ""#"" + anchor ) ; } /* * Returns the URL for viewing a comment in a file in a given patch set of a change . */ default Optional < String > getInlineCommentView ( Change change , int patchsetId , String filename , short side , int startLine ) { return getPatchFileView ( change , patchsetId , filename ) . map ( url - > url + String . format ( ""@ % s % d"" , side == 0 ? ""a"" : """" , startLine ) ) ; }
",,
2634,"public void connect ( ) { if ( isOpen ( ) ) { LOGGER . debug ( ""Already connected . "" ) ; return ; } /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader ( ) ; producer = new KafkaProducer < > ( properties . kafkaPublisher ( ) ) ; LOGGER . info ( ""Connection established . "" ) ;
","producer = new KafkaProducer < > ( properties . kafkaPublisher ( ) ) ;
","producer = producerProvider.get();
",,,"producer = producerProvider.get(); producer.start();
",,,"public void connect ( ) { if ( isOpen ( ) ) { LOGGER . debug ( ""Already connected . "" ) ; return ; } setConnectionClassLoader ( ) ; producer = producerProvider . get ( ) ; LOGGER . info ( ""Connection established . "" ) ; }
",,,"public void connect ( ) { if ( isOpen ( ) ) { LOGGER . debug ( ""Already connected . "" ) ; return ; } setConnectionClassLoader ( ) ; producer = producerProvider . get ( ) ; LOGGER . info ( ""Connection established . "" ) ; }
",,,"public void connect ( ) { if ( isOpen ( ) ) { LOGGER . debug ( ""Already connected . "" ) ; return ; } /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader ( ) ; < |startfocus| > producer = producerProvider . get ( ) ; < |endfocus| > LOGGER . info ( ""Connection established . "" ) ; }
",,
2645,"package com . google . gerrit . metrics ; import static com . google . common . base . Preconditions . checkArgument ; import com . google . auto . value . AutoValue ; import java . util . Optional ; import java . util . function . Function ; /* * * Describes a bucketing field used by a metric . * * @param < T > type of field */ @AutoValue public abstract class Field < T > { /* * * Break down metrics by boolean true / false . * * @param name field name * @return builder for the boolean field */ public static Field . Builder < Boolean > ofBoolean ( String name , BiConsumer < Metadata . Builder , Boolean > metadataMapper ) { return new AutoValue_Field . Builder < Boolean > ( ) . valueType ( Boolean . class ) . formatter ( Object : : toString ) . name ( name ) ; } /* * * Break down metrics by cases of an enum . * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static < E extends Enum < E > > Field . Builder < E > ofEnum ( Class < E > enumType , String name ) {
","public static Field . Builder < Boolean > ofBoolean ( String name , BiConsumer < Metadata . Builder , Boolean > metadataMapper ) {
","public static Field.Builder<Boolean> ofBoolean(String name) {
",,,"public static Field.Builder<Boolean> ofBoolean(String name) {
",,,"package com . google . gerrit . metrics ; import static com . google . common . base . Preconditions . checkArgument ; import com . google . auto . value . AutoValue ; import java . util . Optional ; import java . util . function . Function ; /* * * Describes a bucketing field used by a metric . * * @param < T > type of field */ @AutoValue public abstract class Field < T > { /* * * Break down metrics by boolean true / false . * * @param name field name * @return builder for the boolean field */ public static < T > Builder < T > of ( String name , Class < T > valueType , Function < T , String > formatter ) { checkArgument ( valueType != null , ""valueType must not be null"" ) ; checkArgument ( formatter != null , ""formatter must not be null"" ) ; return new AutoValue_Field . Builder < T > ( ) . valueType ( valueType ) . formatter ( formatter ) . name ( name ) ; } /* * * Break down metrics by boolean true / false . * * @param name field name * @return builder for the boolean field */ public static Builder < Boolean > ofBoolean ( String name ) { return of ( name , Boolean . class , Object : : toString ) ; } /* * * Break down metrics by cases of an enum . * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static < E extends Enum < E > > Builder < E > ofEnum ( Class < E > enumType , String name ) { return of ( name , enumType , Enum : : name ) ; } public abstract String name ( ) ; public abstract Class < T > valueType ( ) ; public abstract Function < T , String > formatter ( ) ; public abstract Optional < T > value ( ) ; public abstract Builder < T > toBuilder ( ) ; @AutoValue . Builder public abstract static class Builder < T > { public abstract Builder < T > name ( String name ) ; public abstract Builder < T > valueType ( Class < T > valueType ) ; public abstract Builder < T > formatter ( Function < T , String > formatter ) ; public abstract Builder < T > value ( T value ) ; public abstract Field < T > build ( ) ; } }
",,,"package com . google . gerrit . metrics ; import static com . google . common . base . Preconditions . checkArgument ; import com . google . auto . value . AutoValue ; import java . util . Optional ; import java . util . function . Function ; /* * * Describes a bucketing field used by a metric . * * @param < T > type of field */ @AutoValue public abstract class Field < T > { /* * * Break down metrics by boolean true / false . * * @param name field name * @return builder for the boolean field */ public static Field . Builder < Boolean > ofBoolean ( String name ) { return new AutoValue_Field . Builder < Boolean > ( ) . valueType ( Boolean . class ) . formatter ( Object : : toString ) . name ( name ) ; } /* * * Break down metrics by cases of an enum . * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static < E extends Enum < E > > Field . Builder < E > ofEnum ( Class < E > enumType , String name ) { return new AutoValue_Field . Builder < E > ( ) . valueType ( enumType ) . formatter ( Enum : : name ) . name ( name ) ; } // Builder class public abstract static class Builder < T > { public abstract Builder < T > valueType ( Class < T > valueType ) ; public abstract Builder < T > formatter ( Function < T , String > formatter ) ; public abstract Builder < T > name ( String name ) ; public abstract Field < T > build ( ) ; } }
",,,"package com . google . gerrit . metrics ; import static com . google . common . base . Preconditions . checkArgument ; import com . google . auto . value . AutoValue ; import java . util . Optional ; import java . util . function . BiConsumer ; import java . util . function . Function ; /* * * Describes a bucketing field used by a metric . * * @param < T > type of field */ @AutoValue public abstract class Field < T > { /* * * Break down metrics by boolean true / false . * * @param name field name * @return builder for the boolean field */ < |startfocus| > public static Field . Builder < Boolean > ofBoolean ( String name ) { < |endfocus| > return new AutoValue_Field . Builder < Boolean > ( ) . valueType ( Boolean . class ) . formatter ( Object : : toString ) . name ( name ) ; } /* * * Break down metrics by cases of an enum . * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static < E extends Enum < E > > Field . Builder < E > ofEnum ( Class < E > enumType , String name ) {
",,
2656,"return get ( Arrays . asList ( options ) ) ; } /* * * { @link #get ( ListChangesOption . . . ) } with all options included , except for the following . * * < ul > * < li > { @code CHECK } is omitted , to skip consistency checks . * < li > { @code SKIP_MERGEABLE } is omitted , so the { @code mergeable } bit < em > is </ em > set . * < li > { @code SKIP_DIFFSTAT } is omitted to skip diffstat calculations . * </ ul > */ default ChangeInfo get ( ) throws RestApiException { return get ( EnumSet . complementOf ( EnumSet . of ( ListChangesOption . CHECK , ListChangesOption . SKIP_MERGEABLE , ListChangesOption . SKIP_DIFFSTAT ) ) ) ; } /* * { @link #get ( ListChangesOption . . . ) } with no options included . */ default ChangeInfo info ( ) throws RestApiException { return get ( EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link
","* < li > { @code SKIP_DIFFSTAT } is omitted to skip diffstat calculations .
","* <li>{@code SKIP_DIFFSTAT} is omitted to skip consistency checks.
",,,"* <li>{@code SKIP_DIFFSTAT} is omitted to skip diffstat calculations.
",,,"return get ( Arrays . asList ( options ) ) ; } /* * * { @link #get ( ListChangesOption . . . ) } with all options included , except for the following . * * < ul > * < li > { @code CHECK } is omitted , to skip consistency checks . * < li > { @code SKIP_MERGEABLE } is omitted , so the { @code mergeable } bit < em > is </ em > set . * < li > { @code SKIP_DIFFSTAT } is omitted to ensure diffstat calculations . * </ ul > */ default ChangeInfo get ( ) throws RestApiException { return get ( EnumSet . complementOf ( EnumSet . of ( ListChangesOption . CHECK , ListChangesOption . SKIP_MERGEABLE , ListChangesOption . SKIP_DIFFSTAT ) ) ) ; } /* * { @link #get ( ListChangesOption . . . ) } with no options included . */ default ChangeInfo info ( ) throws RestApiException { return get ( EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link */ return get ( Arrays . asList ( options ) ) ; } /* * * Retrieves all options except for CHECK , SKIP_MERGEABLE , and SKIP_DIFFSTAT . */ default ChangeInfo get ( ) throws RestApiException { return get ( EnumSet . complementOf ( EnumSet . of ( ListChangesOption . CHECK , ListChangesOption . SKIP_MERGEABLE , ListChangesOption . SKIP_DIFFSTAT ) ) ) ; } /* * * Retrieves no options . */ default ChangeInfo info ( ) throws RestApiException { return get ( EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieves change edit when it exists . * Deprecated : Replaced by ChangeApi . edit ( ) in combination with . . . */
",,,"import java . util . Arrays ; import java . util . EnumSet ; import java . util . List ; public interface ChangeApi { ChangeInfo get ( List < ListChangesOption > options ) throws RestApiException ; default ChangeInfo get ( ListChangesOption . . . options ) throws RestApiException { return get ( Arrays . asList ( options ) ) ; } default ChangeInfo get ( ) throws RestApiException { return get ( EnumSet . complementOf ( EnumSet . of ( ListChangesOption . CHECK , ListChangesOption . SKIP_MERGEABLE , ListChangesOption . SKIP_DIFFSTAT ) ) ) ; } default ChangeInfo info ( ) throws RestApiException { return get ( EnumSet . noneOf ( ListChangesOption . class ) ) ; } @Deprecated default ChangeEditApi edit ( ) throws RestApiException { return new ChangeEditApi ( this ) ; } }
",,,"return get ( Arrays . asList ( options ) ) ; } /* * * { @link #get ( ListChangesOption . . . ) } with all options included , except for the following . * * < ul > * < li > { @code CHECK } is omitted , to skip consistency checks . * < li > { @code SKIP_MERGEABLE } is omitted , so the { @code mergeable } bit < em > is </ em > set . < |startfocus| > * < li > { @code SKIP_DIFFSTAT } is omitted to ensure diffstat calculations . < |endfocus| > * </ ul > */ default ChangeInfo get ( ) throws RestApiException { return get ( EnumSet . complementOf ( EnumSet . of ( ListChangesOption . CHECK , ListChangesOption . SKIP_MERGEABLE , ListChangesOption . SKIP_DIFFSTAT ) ) ) ; } /* * { @link #get ( ListChangesOption . . . ) } with no options included . */ default ChangeInfo info ( ) throws RestApiException { return get ( EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( ) throws RestApiException { return edit ( EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( EnumSet ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( EnumSet < ListChangesOption > options ) throws RestApiException { return edit ( options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( ListChangesOption . . . options ) throws RestApiException { return edit ( Arrays . asList ( options ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( List ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( List < ListChangesOption > options ) throws RestApiException { return edit ( options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base ) throws RestApiException { return edit ( base , EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , EnumSet ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , EnumSet < ListChangesOption > options ) throws RestApiException { return edit ( base , options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , ListChangesOption . . . options ) throws RestApiException { return edit ( base , Arrays . asList ( options ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , List ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , List < ListChangesOption > options ) throws RestApiException { return edit ( base , options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path ) throws RestApiException { return edit ( base , path , EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , EnumSet ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , EnumSet < ListChangesOption > options ) throws RestApiException { return edit ( base , path , options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , ListChangesOption . . . options ) throws RestApiException { return edit ( base , path , Arrays . asList ( options ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , List ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , List < ListChangesOption > options ) throws RestApiException { return edit ( base , path , options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , String ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , String revision ) throws RestApiException { return edit ( base , path , revision , EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , String , EnumSet ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , String revision , EnumSet < ListChangesOption > options ) throws RestApiException { return edit ( base , path , revision , options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , String , ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , String revision , ListChangesOption . . . options ) throws RestApiException { return edit ( base , path , revision , Arrays . asList ( options ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , String , List ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , String revision , List < ListChangesOption > options ) throws RestApiException { return edit ( base , path , revision , options . toArray ( new ListChangesOption [
",,
2665,"} return Optional . empty ( ) ; } private Optional < Project . NameKey > getProjectNameForChangeId ( String changeId ) { Optional < Project . NameKey > projectName = extractProjectNameFromChangeId ( changeId ) ; if ( projectName . isPresent ( ) ) { return projectName ; } try { List < ChangeData > changeData = globals . queryProvider . get ( ) . setRequestedFields ( ChangeField . PROJECT ) . setLimit ( 2 ) . query ( globals . changeQueryBuilder . change ( changeId ) ) ; if ( changeData . size ( ) != 1 ) { // no change found ( size = 0 ) or changeId was ambiguous ( size > 1 ) return Optional . empty ( ) ; } return Optional . of ( changeData . get ( 0 ) . project ( ) ) ; } catch ( QueryParseException e ) { return Optional . empty ( ) ; } } @VisibleForTesting static Optional < Project . NameKey > extractProjectNameFromChangeId ( String changeId ) { int projectEndPosition = changeId . indexOf ( '~' ) ; if ( projectEndPosition <= 0 ) { return Optional . empty ( ) ; } return Optional . of ( Project . nameKey ( IdString . fromUrl ( changeId . substring ( 0 , projectEndPosition ) ) . get ( ) ) ) ; } private boolean isDelete ( HttpServletRequest req ) {
","if ( changeData . size ( ) != 1 ) { // no change found ( size = 0 ) or changeId was ambiguous ( size > 1 )
","if (changeData.size() != 1) {
",,,"if (changeData.isEmpty()) {
",,,"private Optional < Project . NameKey > getProjectNameForChangeId ( String changeId ) { Optional < Project . NameKey > projectName = extractProjectNameFromChangeId ( changeId ) ; if ( projectName . isPresent ( ) ) { return projectName ; } try { List < ChangeData > changeData = globals . queryProvider . get ( ) . setRequestedFields ( ChangeField . PROJECT ) . setLimit ( 1 ) . query ( globals . changeQueryBuilder . change ( changeId ) ) ; if ( changeData . isEmpty ( ) ) { return Optional . empty ( ) ; } return Optional . of ( changeData . get ( 0 ) . project ( ) ) ; } catch ( QueryParseException e ) { return Optional . empty ( ) ; } } @VisibleForTesting static Optional < Project . NameKey > extractProjectNameFromChangeId ( String changeId ) { int projectEndPosition = changeId . indexOf ( '~' ) ; if ( projectEndPosition <= 0 ) { return Optional . empty ( ) ; } return Optional . of ( Project . nameKey ( IdString . fromUrl ( changeId . substring ( 0 , projectEndPosition ) ) . get ( ) ) ) ; } private boolean isDelete ( HttpServletRequest req ) { // implementation }
",,,"} return Optional . empty ( ) ; } private Optional < Project . NameKey > getProjectNameForChangeId ( String changeId ) { Optional < Project . NameKey > projectName = extractProjectNameFromChangeId ( changeId ) ; if ( projectName . isPresent ( ) ) { return projectName ; } try { List < ChangeData > changeData = globals . queryProvider . get ( ) . setRequestedFields ( ChangeField . PROJECT ) . setLimit ( 1 ) . query ( globals . changeQueryBuilder . change ( changeId ) ) ; if ( changeData . isEmpty ( ) ) { return Optional . empty ( ) ; } return Optional . of ( changeData . get ( 0 ) . project ( ) ) ; } catch ( QueryParseException e ) { return Optional . empty ( ) ; } } @VisibleForTesting static Optional < Project . NameKey > extractProjectNameFromChangeId ( String changeId ) { int projectEndPosition = changeId . indexOf ( '~' ) ; if ( projectEndPosition <= 0 ) { return Optional . empty ( ) ; } return Optional . of ( Project . nameKey ( IdString . fromUrl ( changeId . substring ( 0 , projectEndPosition ) ) . get ( ) ) ) ; } private boolean isDelete ( HttpServletRequest req )
",,,"} return Optional . empty ( ) ; } private Optional < Project . NameKey > getProjectNameForChangeId ( String changeId ) { Optional < Project . NameKey > projectName = extractProjectNameFromChangeId ( changeId ) ; if ( projectName . isPresent ( ) ) { return projectName ; } try { List < ChangeData > changeData = globals . queryProvider . get ( ) . setRequestedFields ( ChangeField . PROJECT ) . setLimit ( 2 ) . query ( globals . changeQueryBuilder . change ( changeId ) ) ; < |startfocus| > if ( changeData . isEmpty ( ) ) { < |endfocus| > return Optional . empty ( ) ; } return Optional . of ( changeData . get ( 0 ) . project ( ) ) ; } catch ( QueryParseException e ) { return Optional . empty ( ) ; } } @VisibleForTesting static Optional < Project . NameKey > extractProjectNameFromChangeId ( String changeId ) { int projectEndPosition = changeId . indexOf ( '~' ) ; if ( projectEndPosition <= 0 ) { return Optional . empty ( ) ; } return Optional . of ( Project . nameKey ( IdString . fromUrl ( changeId . substring ( 0 , projectEndPosition ) ) . get ( ) ) ) ; } private boolean isDelete ( HttpServletRequest req ) {
",,
2680,"return java . nio . file . Files . createTempDirectory ( prefix ) ; } @Test public void shouldLoadNotEmptyInitialReplicationConfig ( ) throws Exception { FileBasedConfig replicationConfig = newReplicationConfig ( ) ; replicationConfig . setString ( ""remote"" , ""foo"" , ""url"" , ""ssh :/ / git@git . somewhere . com / $ { name } "" ) ; replicationConfig . save ( ) ; autoReloadConfig = new AutoReloadConfigDecorator ( sitePaths , destinationFactoryMock , Providers . of ( replicationQueueMock ) , pluginDataPath , ""replication"" , workQueueMock ) ; assertThat ( autoReloadConfig . getDestinations ( FilterType . ALL ) ) . hasSize ( 1 ) ; } @Test public void shouldAutoReloadReplicationConfig ( ) throws Exception { FileBasedConfig replicationConfig = newReplicationConfig ( ) ; replicationConfig . setBoolean ( ""gerrit"" , null , ""autoReload"" , true ) ; replicationConfig . setString ( ""remote"" , ""foo"" , ""url"" , ""ssh :/ / git@git . foo . com / $ { name } "" ) ; replicationConfig . save ( ) ; autoReloadConfig = new AutoReloadConfigDecorator ( sitePaths , destinationFactoryMock , Providers . of ( replicationQueueMock ) , pluginDataPath , ""replication"" , workQueueMock ) ; autoReloadConfig . startup ( workQueueMock ) ;
","assertThat ( autoReloadConfig . getDestinations ( FilterType . ALL ) ) . hasSize ( 1 ) ;
","Assert.assertTrue(autoReloadConfig.getDestinations(FilterType.ALL)).isNotEmpty();
",,,"assertThat(autoReloadConfig.getDestinations(FilterType.ALL)).isNotEmpty(); assertThat(autoReloadConfig.getDestinations(FilterType.ALL).size()).isEqualTo(1);
",,,"return java . nio . file . Files . createTempDirectory ( prefix ) ; } @Test public void shouldLoadNotEmptyInitialReplicationConfig ( ) throws Exception { FileBasedConfig replicationConfig = newReplicationConfig ( ) ; replicationConfig . setString ( ""remote"" , ""foo"" , ""url"" , ""ssh :/ / git@somewhere . com / $ { name } "" ) ; replicationConfig . save ( ) ; autoReloadConfig = new AutoReloadConfigDecorator ( sitePaths , destinationFactoryMock , Providers . of ( replicationQueueMock ) , pluginDataPath , ""replication"" , workQueueMock ) ; assertThat ( autoReloadConfig . getDestinations ( FilterType . REMOTE , ""foo"" ) ) . hasSize ( 1 ) ; } @Test public void shouldAutoReloadReplicationConfig ( ) throws Exception { FileBasedConfig replicationConfig = newReplicationConfig ( ) ; replicationConfig . setBoolean ( ""gerrit"" , null , ""autoReload"" , true ) ; replicationConfig . setString ( ""remote"" , ""foo"" , ""url"" , ""ssh :/ / git . foo . com / $ { name } "" ) ; replicationConfig . save ( ) ; autoReloadConfig = new AutoReloadConfigDecorator ( sitePaths , destinationFactoryMock , Providers . of ( replicationQueueMock ) , pluginDataPath , ""replication"" , workQueueMock ) ; autoReloadConfig . startup ( workQueueMock ) ; }
",,,"return java . nio . file . Files . createTempDirectory ( prefix ) ; } @Test public void shouldLoadNotEmptyInitialReplicationConfig ( ) throws Exception { FileBasedConfig replicationConfig = newReplicationConfig ( ) ; replicationConfig . setString ( ""remote"" , ""foo"" , ""url"" , ""ssh :/ / git@git . somewhere . com / $ { name } "" ) ; replicationConfig . save ( ) ; autoReloadConfig = new AutoReloadConfigDecorator ( sitePaths , destinationFactoryMock , Providers . of ( replicationQueueMock ) , pluginDataPath , ""replication"" , workQueueMock ) ; assertThat ( autoReloadConfig . getDestinations ( FilterType . ALL ) ) . isNotEmpty ( ) ; } @Test public void shouldAutoReloadReplicationConfig ( ) throws Exception { FileBasedConfig replicationConfig = newReplicationConfig ( ) ; replicationConfig . setBoolean ( ""gerrit"" , null , ""autoReload"" , true ) ; replicationConfig . setString ( ""remote"" , ""foo"" , ""url"" , ""ssh :/ / git@git . foo . com / $ { name } "" ) ; replicationConfig . save ( ) ; autoReloadConfig = new AutoReloadConfigDecorator ( sitePaths , destinationFactoryMock , Providers . of ( replicationQueueMock ) , pluginDataPath , ""replication"" , workQueueMock ) ; autoReloadConfig . startup ( workQueueMock ) ; }
",,,"return java . nio . file . Files . createTempDirectory ( prefix ) ; } @Test public void shouldLoadNotEmptyInitialReplicationConfig ( ) throws Exception { FileBasedConfig replicationConfig = newReplicationConfig ( ) ; replicationConfig . setString ( ""remote"" , ""foo"" , ""url"" , ""ssh :/ / git@git . somewhere . com / $ { name } "" ) ; replicationConfig . save ( ) ; autoReloadConfig = new AutoReloadConfigDecorator ( sitePaths , destinationFactoryMock , Providers . of ( replicationQueueMock ) , pluginDataPath , ""replication"" , workQueueMock ) ; < |startfocus| > assertThat ( autoReloadConfig . getDestinations ( FilterType . ALL ) ) . hasSize ( 1 ) ; < |endfocus| > } @Test public void shouldAutoReloadReplicationConfig ( ) throws Exception { FileBasedConfig replicationConfig = newReplicationConfig ( ) ; replicationConfig . setBoolean ( ""gerrit"" , null , ""autoReload"" , true ) ; replicationConfig . setString ( ""remote"" , ""foo"" , ""url"" , ""ssh :/ / git@git . foo . com / $ { name } "" ) ; replicationConfig . save ( ) ; autoReloadConfig = new AutoReloadConfigDecorator ( sitePaths , destinationFactoryMock , Providers . of ( replicationQueueMock ) , pluginDataPath , ""replication"" , workQueueMock ) ; autoReloadConfig . startup ( workQueueMock ) ;
",,
2681,"Copyright ( C ) 2019 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . index ; import java . util . Optional ; public class OnlineReindexMode { private static ThreadLocal < Boolean > isOnlineReindex = new ThreadLocal < > ( ) ; public static boolean get ( ) { return Optional . ofNullable ( isOnlineReindex . get ( ) ) . orElse ( Boolean . FALSE ) ; } public static void begin ( ) { isOnlineReindex . set ( Boolean . TRUE ) ; } public static void end ( ) { isOnlineReindex . set ( Boolean . FALSE ) ; } }
","Copyright ( C ) 2019 The Android Open Source Project
","Copyright (C) 2019 The Android Open Source Project
",,,"Copyright (C) 2019 The Android Open Source Project
",,,"/* * Copyright ( C ) 2010 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an ""AS IS"" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . google . gerrit . server . index ; import java . util . Optional ; public class OnlineReindexMode { private static ThreadLocal < Boolean > isOnlineReindex = new ThreadLocal < > ( ) ; public static boolean get ( ) { return Optional . ofNullable ( isOnlineReindex . get ( ) ) . orElse ( Boolean . FALSE ) ; } public static void begin ( ) { isOnlineReindex . set ( Boolean . TRUE ) ; } public static void end ( ) { isOnlineReindex . set ( Boolean . FALSE ) ; } }
",,,"Copyright ( C ) 2019 The Android Open Source Project // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . index ; import java . util . Optional ; public class OnlineReindexMode { private static ThreadLocal < Boolean > isOnlineReindex = new ThreadLocal < > ( ) ; public static boolean get ( ) { return Optional . ofNullable ( isOnlineReindex . get ( ) ) . orElse ( Boolean . FALSE ) ; } public static void begin ( ) { isOnlineReindex . set ( Boolean . TRUE ) ; } public static void end ( ) { isOnlineReindex . set ( Boolean . FALSE ) ; } }
",,,"< |startfocus| > Copyright ( C ) 2010 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . index ; import java . util . Optional ; public class OnlineReindexMode { private static ThreadLocal < Boolean > isOnlineReindex = new ThreadLocal < > ( ) ; public static boolean get ( ) { return Optional . ofNullable ( isOnlineReindex . get ( ) ) . orElse ( Boolean . FALSE ) ; } public static void begin ( ) { isOnlineReindex . set ( Boolean . TRUE ) ; } public static void end ( ) { isOnlineReindex . set ( Boolean . FALSE ) ; } }
",,
2708,"public void onProjectDeleted ( Event event ) { String projectName = event . getProjectName ( ) ; logger . atInfo ( ) . log ( ""Deleting project ' % s' . Will perform a cleanup in Shared - Ref database . "" , projectName ) ; try { sharedDb . removeProject ( projectName ) ; sharedRefLogger . logProjectDelete ( projectName ) ; } catch ( IOException e ) { validationMetrics . incrementSplitBrain ( ) ; logger . atSevere ( ) . withCause ( e ) . log ( ""Project ' % s' deleted from GIT but it was not able to cleanup"" + "" from Shared - Ref database"" , projectName ) ; }
","sharedRefLogger . logProjectDelete ( projectName ) ;
","sharedDb.removeProject(projectName);
",,,"<|del|>
",,,"public void onProjectDeleted ( Event event ) { String projectName = event . getProjectName ( ) ; logger . atInfo ( ) . log ( ""Deleting project ' % s' . Will perform a cleanup in Shared - Ref database . "" , projectName ) ; try { sharedDb . removeProject ( projectName ) ; sharedRefLogger . logDeletion ( projectName ) ; } catch ( IOException e ) { validationMetrics . incrementSplitBrain ( ) ; logger . atSevere ( ) . withCause ( e ) . log ( ""Project ' % s' deleted from GIT but it was not able to cleanup from Shared - Ref database"" , projectName ) ; } }
",,,"public void onProjectDeleted ( Event event ) { String projectName = event . getProjectName ( ) ; logger . atInfo ( ) . log ( ""Deleting project ' % s' . Will perform a cleanup in Shared - Ref database . "" , projectName ) ; try { sharedDb . removeProject ( projectName ) ; sharedRefLogger . logDeletion ( projectName ) ; } catch ( IOException e ) { validationMetrics . incrementSplitBrain ( ) ; logger . atSevere ( ) . withCause ( e ) . log ( ""Project ' % s' deleted from GIT but it was not able to cleanup from Shared - Ref database"" , projectName ) ; } }
",,,"public void onProjectDeleted ( Event event ) { String projectName = event . getProjectName ( ) ; logger . atInfo ( ) . log ( ""Deleting project ' % s' . Will perform a cleanup in Shared - Ref database . "" , projectName ) ; try { sharedDb . removeProject ( projectName ) ; < |startfocus| > sharedRefLogger . logDeletion ( projectName ) ; < |endfocus| > } catch ( IOException e ) { validationMetrics . incrementSplitBrain ( ) ; logger . atSevere ( ) . withCause ( e ) . log ( ""Project ' % s' deleted from GIT but it was not able to cleanup"" + "" from Shared - Ref database"" , projectName ) ; } }
",,
2711,"public void cancel ( ) { repLog . info ( ""Replication { } was canceled"" , getURI ( ) ) ; canceledByReplication ( ) ; pool . pushWasCanceled ( this ) ;
","repLog . info ( ""Replication { } was canceled"" , getURI ( ) ) ;
","repLog.info(""Replication [{}] to {} was canceled"", getURI());
",,,"repLog.info(""Replication {} was canceled"", getURI());
",,,"public void cancel ( ) { repLog . info ( ""Replication [ { } ] to { } was canceled"" , HexFormat . fromInt ( id ) , getURI ( ) ) ; canceledByReplication ( ) ; pool . pushWasCanceled ( this ) ; }
",,,"public void cancel ( ) { repLog . info ( ""Replication [ { } ] to { } was canceled"" , IdGenerator . format ( id ) , getURI ( ) ) ; canceledByReplication ( ) ; pool . pushWasCanceled ( this ) ; }
",,,"public void cancel ( ) { < |startfocus| > repLog . info ( ""Replication [ { } ] to { } was canceled"" , HexFormat . fromInt ( id ) , getURI ( ) ) ; < |endfocus| > canceledByReplication ( ) ; pool . pushWasCanceled ( this ) ;
",,
2719,"/* * Java API to interact with single { @code Check } s . */ public interface CheckApi { /* * Returns a { @link CheckInfo } for the scoped resource with the given options . */ CheckInfo get ( ListChecksOption . . . options ) throws RestApiException ; /* * Updates a check and returns the { @link CheckInfo } for the updated resource . */ CheckInfo update ( CheckInput input ) throws RestApiException ; /* * * A default implementation which allows source compatibility when adding new methods to the * interface . */ class NotImplemented implements CheckApi { @Override public CheckInfo get ( ListChecksOption . . . options ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo update ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo rerun ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } } }
","< |del| >/ ** reruns the check and returns the CheckInfo for the updated check . Input ignores ""state"" . */ CheckInfo rerun ( CheckInput input ) throws RestApiException ;
","/** reruns the check and returns the {@link CheckInfo} for the updated check. Input ignores ""state"". */ CheckInfo rerun(CheckInput input) throws RestApiException;
",,,"/** * reruns the check and returns the CheckInfo for the updated check. Input ignores ""state"". */ CheckInfo rerun(CheckInput input) throws RestApiException;
",,,"/* * * Java API to interact with single { @code Check } s . */ public interface CheckApi { /* * * Returns a { @link CheckInfo } for the scoped resource with the given options . */ CheckInfo get ( ListChecksOption . . . options ) throws RestApiException ; /* * * Updates a check and returns the { @link CheckInfo } for the updated resource . */ CheckInfo update ( CheckInput input ) throws RestApiException ; /* * * Reruns the check and returns the CheckInfo for the updated check . Input ignores ""state"" . */ CheckInfo rerun ( CheckInput input ) throws RestApiException ; /* * * A default implementation which allows source compatibility when adding new methods to the * interface . */ class NotImplemented implements CheckApi { @Override public CheckInfo get ( ListChecksOption . . . options ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo update ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo rerun ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } } }
",,,"try ( MetaDataUpdate md = metaDataUpdateUser . create ( rsrc . getNameKey ( ) ) ) { ProjectConfig config = ProjectConfig . read ( md ) ; setAccess . validateChanges ( config , removals , additions ) ; setAccess . applyChanges ( config , removals , additions ) ; try { setAccess . setParentName ( identifiedUser . get ( ) , config , rsrc . getNameKey ( ) , newParentProjectName , false ) ; } catch ( AuthException e ) { throw new IllegalStateException ( e ) ; } md . setMessage ( ""Review access change"" ) ; md . setInsertChangeId ( true ) ; Change . Id changeId = new Change . Id ( seq . nextChangeId ( ) ) ; RevCommit commit = config . commitToNewRef ( md , new PatchSet . Id ( changeId , Change . INITIAL_PATCH_SET_ID ) . toRefName ( ) ) ; try ( ObjectInserter objInserter = md . getRepository ( ) . newObjectInserter ( ) ; ObjectReader objReader = objInserter . newReader ( ) ; RevWalk rw = new RevWalk ( objReader ) ; BatchUpdate bu = updateFactory . create ( db . get ( ) , config . getProject ( ) . getNameKey ( ) , projectControl . getUser ( ) ,
",,,"/* * Java API to interact with single { @code Check } s . */ public interface CheckApi { /* * Returns a { @link CheckInfo } for the scoped resource with the given options . */ CheckInfo get ( ListChecksOption . . . options ) throws RestApiException ; /* * Updates a check and returns the { @link CheckInfo } for the updated resource . */ CheckInfo update ( CheckInput input ) throws RestApiException ; < |startfocus| > /* * Reruns the check and returns the CheckInfo for the updated check . Input ignores ""state"" . */ CheckInfo rerun ( CheckInput input ) throws RestApiException ; < |endfocus| > /* * * A default implementation which allows source compatibility when adding new methods to the * interface . */ class NotImplemented implements CheckApi { @Override public CheckInfo get ( ListChecksOption . . . options ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo update ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo rerun ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } } }
",,
2726,"PermissionBackend permissionBackend , ExternalIds externalIds , @ServerInitiated Provider < AccountsUpdate > accountsUpdateProvider , SshKeyCache sshKeyCache , Realm realm ) { this . self = self ; this . permissionBackend = permissionBackend ; this . externalIds = externalIds ; this . accountsUpdateProvider = accountsUpdateProvider ; this . sshKeyCache = sshKeyCache ; this . realm = realm ; } @Override public String apply ( AccountResource rsrc , UsernameInput input ) throws RestApiException , IOException , ConfigInvalidException , PermissionBackendException { if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } if ( ! realm . allowsEdit ( AccountFieldName . USER_NAME ) ) { throw new MethodNotAllowedException ( ""realm does not allow editing username"" ) ; } Account . Id accountId = rsrc . getUser ( ) . getAccountId ( ) ; if ( ! externalIds . byAccount ( accountId , SCHEME_USERNAME ) . isEmpty ( ) ) { throw new MethodNotAllowedException ( ""Username cannot be changed . "" ) ; }
","throws RestApiException , IOException , ConfigInvalidException , PermissionBackendException {
","throws RestApiException, PermissionBackendException {
",,,"throws RestApiException, PermissionBackendException {
",,,"RestApiException permissionException = new AuthException ( ""Not authenticated"" ) ; RestApiException badRequestException = new BadRequestException ( ""Bad request"" ) ; RestApiException methodNotAllowedException = new MethodNotAllowedException ( ""Method not allowed"" ) ; RestApiException unprocessableEntityException = new UnprocessableEntityException ( ""Unprocessable entity"" ) ; RestApiException resourceConflictException = new ResourceConflictException ( ""Resource conflict"" ) ; RestApiException ioException = new IOException ( ""IO exception"" ) ; RestApiException configInvalidException = new ConfigInvalidException ( ""Config invalid"" ) ; RestApiException permissionBackendException = new PermissionBackendException ( ""Permission backend exception"" ) ; PermissionBackend permissionBackend ; ExternalIds externalIds ; @ServerInitiated Provider < AccountsUpdate > accountsUpdateProvider ; SshKeyCache sshKeyCache ; Realm realm ; public MyClass ( Provider < Account . Id > self , PermissionBackend permissionBackend , ExternalIds externalIds , @ServerInitiated Provider < AccountsUpdate > accountsUpdateProvider , SshKeyCache sshKeyCache , Realm realm ) throws RestApiException { this . self = self ; this . permissionBackend = permissionBackend ; this . externalIds = externalIds ; this . accountsUpdateProvider = accountsUpdateProvider ; this . sshKeyCache = sshKeyCache ; this . realm = realm ; } @Override public String apply ( AccountResource rsrc , UsernameInput input ) throws RestApiException , IOException { if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { throw permissionException ; } if ( ! realm . allowsEdit ( AccountFieldName . USER_NAME ) ) { throw methodNotAllowedException ; } Account . Id accountId = rsrc . getUser ( ) . getAccountId ( ) ; if ( ! externalIds . byAccount ( accountId , SCHEME_USERNAME ) . isEmpty ( ) ) { throw methodNotAllowedException ; } return ""Success"" ; }
",,,"PermissionBackend permissionBackend ; ExternalIds externalIds ; @ServerInitiated Provider < AccountsUpdate > accountsUpdateProvider ; SshKeyCache sshKeyCache ; Realm realm ; public MyClass ( Self self , PermissionBackend permissionBackend , ExternalIds externalIds , @ServerInitiated Provider < AccountsUpdate > accountsUpdateProvider , SshKeyCache sshKeyCache , Realm realm ) { this . self = self ; this . permissionBackend = permissionBackend ; this . externalIds = externalIds ; this . accountsUpdateProvider = accountsUpdateProvider ; this . sshKeyCache = sshKeyCache ; this . realm = realm ; } @Override public String apply ( AccountResource rsrc , UsernameInput input ) throws RestApiException { if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } if ( ! realm . allowsEdit ( AccountFieldName . USER_NAME ) ) { throw new MethodNotAllowedException ( ""realm does not allow editing username"" ) ; } Account . Id accountId = rsrc . getUser ( ) . getAccountId ( ) ; if ( ! externalIds . byAccount ( accountId , SCHEME_USERNAME ) . isEmpty ( ) ) { throw new MethodNotAllowedException ( ""Username cannot be changed . "" ) ; } // rest of the code }
",,,"PermissionBackend permissionBackend , ExternalIds externalIds , @ServerInitiated Provider < AccountsUpdate > accountsUpdateProvider , SshKeyCache sshKeyCache , Realm realm ) { this . self = self ; this . permissionBackend = permissionBackend ; this . externalIds = externalIds ; this . accountsUpdateProvider = accountsUpdateProvider ; this . sshKeyCache = sshKeyCache ; this . realm = realm ; } @Override public String apply ( AccountResource rsrc , UsernameInput input ) < |startfocus| > throws AuthException , BadRequestException , MethodNotAllowedException , UnprocessableEntityException , ResourceConflictException , IOException , ConfigInvalidException , PermissionBackendException { < |endfocus| > if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } if ( ! realm . allowsEdit ( AccountFieldName . USER_NAME ) ) { throw new MethodNotAllowedException ( ""realm does not allow editing username"" ) ; } Account . Id accountId = rsrc . getUser ( ) . getAccountId ( ) ; if ( ! externalIds . byAccount ( accountId , SCHEME_USERNAME ) . isEmpty ( ) ) { throw new MethodNotAllowedException ( ""Username cannot be changed . "" ) ; }
",,
2736,"&& compareField ( ref . getStatus ( ) , expectedRef . getStatus ( ) ) && compareField ( ref . getExpectedOldObjectId ( ) , expectedRef . getExpectedOldObjectId ( ) ) && compareField ( ref . getNewObjectId ( ) , expectedRef . getNewObjectId ( ) ) && compareField ( ref . isFastForward ( ) , expectedRef . isFastForward ( ) ) && compareField ( ref . getSrcRef ( ) , expectedRef . getSrcRef ( ) ) && compareField ( ref . isForceUpdate ( ) , expectedRef . isForceUpdate ( ) ) && compareField ( ref . getMessage ( ) , expectedRef . getMessage ( ) ) ; } } }
","< |del| > private boolean compareField ( Object obj , Object expectedObj ) { return obj != null ? obj . equals ( expectedObj ) : expectedObj == null ; }
","<|del|>
",,,"<|del|>
",,,"&& ref . getStatus ( ) . equals ( expectedRef . getStatus ( ) ) && ref . getExpectedOldObjectId ( ) . equals ( expectedRef . getExpectedOldObjectId ( ) ) && ref . getNewObjectId ( ) . equals ( expectedRef . getNewObjectId ( ) ) && ref . isFastForward ( ) == expectedRef . isFastForward ( ) && ref . getSrcRef ( ) . equals ( expectedRef . getSrcRef ( ) ) && ref . isForceUpdate ( ) == expectedRef . isForceUpdate ( ) && Objects . equals ( ref . getMessage ( ) , expectedRef . getMessage ( ) ) ;
",,,"private boolean compareField ( Object obj , Object expectedObj ) { return obj != null ? obj . equals ( expectedObj ) : expectedObj == null ; }
",,,"&& compareField ( ref . getStatus ( ) , expectedRef . getStatus ( ) ) && compareField ( ref . getExpectedOldObjectId ( ) , expectedRef . getExpectedOldObjectId ( ) ) && compareField ( ref . getNewObjectId ( ) , expectedRef . getNewObjectId ( ) ) && compareField ( ref . isFastForward ( ) , expectedRef . isFastForward ( ) ) && compareField ( ref . getSrcRef ( ) , expectedRef . getSrcRef ( ) ) && compareField ( ref . isForceUpdate ( ) , expectedRef . isForceUpdate ( ) ) && compareField ( ref . getMessage ( ) , expectedRef . getMessage ( ) ) ; } < |startfocus| > private boolean compareField ( Object obj , Object expectedObj ) { return obj != null ? obj . equals ( expectedObj ) : expectedObj == null ; } < |endfocus| > } }
",,
2740,"import org . eclipse . jgit . diff . DiffEntry ; import org . eclipse . jgit . diff . DiffFormatter ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectReader ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . util . io . DisabledOutputStream ; /* * Loads cache values for the external ID cache using either a full or a partial reload . */ @Singleton public class ExternalIdCacheLoader extends CacheLoader < ObjectId , AllExternalIds > { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; // Maximum number of prior states we inspect to find a base for differential . If no cached state // is found within this number of parents , , we fall back to reading everything from scratch . private static final int MAX_HISTORY_LOOKBACK = 10 ; // Maximum number of changes we perform using the differential approach . If more updates need to
","/* * Loads cache values for the external ID cache using either a full or a partial reload . */ @Singleton
","/** * Loads cache values for the external ID cache using either a full or a partial reload. */
",,,"/** Loads cache values for the external ID cache using either a full or a partial reload. */ @Singleton
",,,"import org . eclipse . jgit . diff . DiffEntry ; import org . eclipse . jgit . diff . DiffFormatter ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectReader ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . util . io . DisabledOutputStream ; /* * * Loads cache values for the external ID cache using either a full or a partial reload . */ @Singleton public class ExternalIdCacheLoader extends CacheLoader < ObjectId , AllExternalIds > { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; // Maximum number of prior states we inspect to find a base for differential . If no cached state // is found within this number of parents , we fall back to reading everything from scratch . private static final int MAX_HISTORY_LOOKBACK = 10 ; // Maximum number of changes we perform using the differential approach . If more updates need to // be performed , we fall back to reading everything from scratch . private static final int MAX_DIFFERENTIAL_CHANGES = 100 ; private final Repository repo ; private final ExternalIdReader externalIdReader ; private final ExternalIdCache externalIdCache ; @Inject ExternalIdCacheLoader ( Repository repo , ExternalIdReader externalIdReader , ExternalIdCache externalIdCache ) { this . repo = repo ; this . externalIdReader = externalIdReader ; this . externalIdCache = externalIdCache ; } @Override public AllExternalIds load ( ObjectId key ) throws Exception { AllExternalIds allExternalIds = new AllExternalIds ( ) ; try ( ObjectReader reader = repo . newObjectReader ( ) ; RevWalk revWalk = new RevWalk ( reader ) ) { RevCommit commit = revWalk . parseCommit ( key ) ; if ( commit . getParentCount ( ) == 0 ) { // This is the initial commit , so we need to read everything from scratch . externalIdReader . readAll ( allExternalIds ) ; return allExternalIds ; } // Try to find a cached state to use as a base for differential updates . ObjectId baseId = findBaseId ( commit , reader ) ; if ( baseId == null ) { // No cached state found within the
",,,"import org . eclipse . jgit . diff . DiffEntry ; import org . eclipse . jgit . diff . DiffFormatter ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectReader ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . util . io . DisabledOutputStream ; public class ExternalIdCacheLoader extends CacheLoader < ObjectId , AllExternalIds > { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private static final int MAX_HISTORY_LOOKBACK = 10 ; private static final int MAX_DIFFERENTIAL_CHANGES = 100 ; public ExternalIdCacheLoader ( ) { } @Override public AllExternalIds load ( ObjectId key ) throws Exception { try ( Repository repo = openRepository ( ) ) { RevWalk walk = new RevWalk ( repo ) ; RevCommit commit = walk . parseCommit ( key ) ; walk . markStart ( commit ) ; AllExternalIds externalIds = new AllExternalIds ( ) ; for ( RevCommit revCommit : walk ) { if ( externalIds . isFull ( ) ) { break ; } externalIds . updateFromCommit ( revCommit ) ; } if ( ! externalIds . isFull ( ) ) { externalIds . updateFromFullReload ( repo ) ; } return externalIds ; } } private Repository openRepository ( ) throws IOException { // Open the repository // . . . } }
",,,"import com . google . common . cache . CacheLoader ; import com . google . common . flogger . FluentLogger ; import com . google . gerrit . server . cache . proto . Cache . AllExternalIds ; import com . google . gerrit . server . cache . proto . Cache . ExternalIdCacheEntry ; import com . google . gerrit . server . cache . serialize . CacheSerializer ; import com . google . gerrit . server . cache . serialize . ObjectIdCacheSerializer ; import com . google . gerrit . server . cache . serialize . ObjectIdSerializer ; import com . google . gerrit . server . config . GerritServerConfig ; import com . google . gerrit . server . git . GitRepositoryManager ; import com . google . gerrit . server . git . meta . MetaDataUpdate ; import com . google . gerrit . server . logging . TraceContext ; import com . google . gerrit . server . logging . TraceContext . TraceTimer ; import com . google . gerrit . server . notedb . ChangeNotes ; import com . google . gerrit . server . notedb . ChangeUpdate ; import com . google . gerrit . server . notedb . NotesMigration ; import com . google . gerrit . server . notedb . Sequences ; import com . google . gerrit . server . notedb . rebuild . ChangeRebuilder ; import com . google . gerrit . server . project . ProjectCache ; import com . google . gerrit . server . project . ProjectState ; import com . google . gerrit . server . query . change . ChangeData ; import com . google . gerrit . server . query . change . InternalChangeQuery ; import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . Singleton ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collection ; import java . util . List ; import java . util . Optional ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectReader ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . util . io . DisabledOutputStream ; < |startfocus| > /* * Loads cache values for the external ID cache using either a full or a partial reload . */ < |endfocus| > public class ExternalIdCacheLoader extends CacheLoader < ObjectId , AllExternalIds > { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; // Maximum number of prior states we inspect to find a base for differential . If no cached state // is found within this number of parents , , we fall back to reading everything from scratch . private static final int MAX_HISTORY_LOOKBACK = 10 ; // Maximum number of changes we perform using the differential approach . If more updates need to
",,
2745,"private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; // Maximum number of prior states we inspect to find a base for differential . If no cached state // is found within this number of parents , we fall back to reading everything from scratch . private static final int MAX_HISTORY_LOOKBACK = 10 ; // Maximum number of changes we perform using the differential approach . If more updates need to // be applied , we fall back to reading everything from scratch . private static final int MAX_DIFF_UPDATES = 50 ; private final ExternalIdReader externalIdReader ; private final Provider < Cache < ObjectId , AllExternalIds > > externalIdCache ; private final GitRepositoryManager gitRepositoryManager ; private final AllUsersName allUsersName ; private final Counter1 < Boolean > reloadCounter ; private final Timer0 reloadDifferential ; private final boolean enablePartialReloads ; @Inject ExternalIdCacheLoader ( GitRepositoryManager gitRepositoryManager , AllUsersName allUsersName , ExternalIdReader externalIdReader , @Named ( ExternalIdCacheImpl . CACHE_NAME ) Provider < Cache < ObjectId , AllExternalIds > > externalIdCache , MetricMaker metricMaker ,
","// is found within this number of parents , we fall back to reading everything from scratch .
","// is found within this number of parents, we fall back to reading everything from scratch.
",,,"// is found within this number of parents, we fall back to reading everything from scratch. // TODO(kudu-merge): Maximum number of changes we inspect to find a base for differential.
",,,"// Maximum number of prior states we inspect to find a base for differential . If no cached state is found within this number of parents , we fall back to reading everything from scratch . private static final int MAX_HISTORY_LOOKBACK = 10 ; // Maximum number of changes we perform using the differential approach . If more updates need to be applied , we fall back to reading everything from scratch . private static final int MAX_DIFF_UPDATES = 50 ; private final ExternalIdReader externalIdReader ; private final Provider < Cache < ObjectId , AllExternalIds > > externalIdCache ; private final GitRepositoryManager gitRepositoryManager ; private final AllUsersName allUsersName ; private final Counter1 < Boolean > reloadCounter ; private final Timer0 reloadDifferential ; private final boolean enablePartialReloads ; @Inject ExternalIdCacheLoader ( GitRepositoryManager gitRepositoryManager , AllUsersName allUsersName , ExternalIdReader externalIdReader , @Named ( ExternalIdCacheImpl . CACHE_NAME ) Provider < Cache < ObjectId , AllExternalIds > > externalIdCache , MetricMaker metricMaker ) { this . gitRepositoryManager = gitRepositoryManager ; this . allUsersName = allUsersName ; this . externalIdReader = externalIdReader ; this . externalIdCache = externalIdCache ; this . reloadCounter = metricMaker . newCounter ( ""external_ids / reload"" , ""successful"" , ""true / false"" ) ; this . reloadDifferential = metricMaker . newTimer ( ""external_ids / reload_differential"" ) ; this . enablePartialReloads = true ; }
",,,"import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . transport . BundleWriter ; import org . eclipse . jgit . transport . ReceiveCommand ; import org . kohsuke . args4j . Option ; import java . io . ByteArrayOutputStream ; import java . io . IOException ; import java . io . OutputStream ; import java . util . Collection ; import java . util . Set ; @Singleton public class PreviewSubmit implements RestReadView < RevisionResource > { private final Provider < ReviewDb > dbProvider ; private final Provider < MergeOp > mergeOpProvider ; private final AllowedFormats allowedFormats ; private String format ; @Option ( name = "" -- format"" ) public void setFormat ( String f ) { this . format = f ; } @Inject PreviewSubmit ( Provider < ReviewDb > dbProvider , Provider < MergeOp > mergeOpProvider , AllowedFormats allowedFormats ) { this . dbProvider = dbProvider ; this . mergeOpProvider = mergeOpProvider ; this . allowedFormats = allowedFormats ; } @Override public BinaryResult apply ( RevisionResource rsrc ) throws RestApiException { if ( Strings . isNullOrEmpty ( format ) ) { // Review : Should this be configurable ? } // Rest of the code } } public LazyArrayListStore ( ) { fUniqueId = TraceCompassLogUtils . traceObjectCreation ( LOGGER , Level . FINE , this ) ; } // Rest of the code // Rest of the code private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private static final int MAX_HISTORY_LOOKBACK = 10 ; private static final int MAX_DIFF_UPDATES = 50 ; private final ExternalIdReader externalIdReader ; private final Provider < Cache < ObjectId , AllExternalIds > > externalIdCache ; private final GitRepositoryManager gitRepositoryManager ; private final AllUsersName allUsersName ; private final Counter1 < Boolean > reloadCounter ; private final Timer0 reloadDifferential ; private final boolean enablePartialReloads ; @Inject ExternalIdCacheLoader ( GitRepositoryManager gitRepositoryManager , AllUsersName allUsersName , ExternalIdReader externalIdReader , @Named ( ExternalIdCacheImpl . CACHE_NAME ) Provider < Cache < ObjectId , AllExternalIds > > externalIdCache , MetricMaker metricMaker ) { this . gitRepositoryManager = gitRepositoryManager ; this . allUsersName = allUsersName ; this . externalIdReader = externalIdReader ; this . externalIdCache = externalIdCache ; this . reloadCounter = metricMaker
",,,"private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; // Maximum number of prior states we inspect to find a base for differential . If no cached state < |startfocus| > // is found within this number of parents , , we fall back to reading everything from scratch . < |endfocus| > private static final int MAX_HISTORY_LOOKBACK = 10 ; // Maximum number of changes we perform using the differential approach . If more updates need to // be applied , we fall back to reading everything from scratch . private static final int MAX_DIFF_UPDATES = 50 ; private final ExternalIdReader externalIdReader ; private final Provider < Cache < ObjectId , AllExternalIds > > externalIdCache ; private final GitRepositoryManager gitRepositoryManager ; private final AllUsersName allUsersName ; private final Counter1 < Boolean > reloadCounter ; private final Timer0 reloadDifferential ; private final boolean enablePartialReloads ; @Inject ExternalIdCacheLoader ( GitRepositoryManager gitRepositoryManager , AllUsersName allUsersName , ExternalIdReader externalIdReader , @Named ( ExternalIdCacheImpl . CACHE_NAME ) Provider < Cache < ObjectId , AllExternalIds > > externalIdCache , MetricMaker metricMaker , Config cfg ,
",,
2753,"import org . eclipse . jgit . lib . RefUpdate . Result ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . lib . RepositoryCache . FileKey ; import org . eclipse . jgit . util . FS ; public class AccountsOnInit { private final InitFlags flags ; private final SitePaths site ; private final String allUsers ; @Inject public AccountsOnInit ( InitFlags flags , SitePaths site , AllUsersNameOnInitProvider allUsers ) { this . flags = flags ; this . site = site ; this . allUsers = allUsers . get ( ) ; } public void insert ( Account . Builder account ) throws IOException { File path = getPath ( ) ; if ( path != null ) { try ( Repository repo = new FileRepository ( path ) ; ObjectInserter oi = repo . newObjectInserter ( ) ) { PersonIdent ident = new PersonIdent ( new GerritPersonIdentProvider ( flags . cfg ) . get ( ) , account . registeredOn ( ) ) ; Config accountConfig = new Config ( ) ; AccountProperties . writeToAccountConfig ( InternalAccountUpdate . builder ( ) . setActive ( account . isActive ( ) ) . setFullName ( account . fullName ( ) ) . setPreferredEmail ( account . preferredEmail ( ) ) . setStatus ( account . status ( ) ) . build ( ) ,
","public void insert ( Account . Builder account ) throws IOException {
","public Account.Builder insert(Account account) throws IOException {
",,,"public void insert(Account account) throws IOException, ConfigInvalidException {
",,,"import org . eclipse . jgit . lib . RefUpdate . Result ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . lib . RepositoryCache . FileKey ; import org . eclipse . jgit . util . FS ; public class AccountsOnInit { private final InitFlags flags ; private final SitePaths site ; private final String allUsers ; @Inject public AccountsOnInit ( InitFlags flags , SitePaths site , AllUsersNameOnInitProvider allUsers ) { this . flags = flags ; this . site = site ; this . allUsers = allUsers . get ( ) ; } public Account insert ( Account . Builder accountBuilder ) throws IOException { File path = getPath ( ) ; if ( path != null ) { try ( Repository repo = new FileRepository ( path ) ; ObjectInserter oi = repo . newObjectInserter ( ) ) { PersonIdent ident = new PersonIdent ( new GerritPersonIdentProvider ( flags . cfg ) . get ( ) , accountBuilder . getRegisteredOn ( ) ) ; Config accountConfig = new Config ( ) ; AccountProperties . writeToAccountConfig ( InternalAccountUpdate . builder ( ) . setActive ( accountBuilder . isActive ( ) ) . setFullName ( accountBuilder . getFullName ( ) ) . setPreferredEmail ( accountBuilder . getPreferredEmail ( ) ) . setStatus ( accountBuilder . getStatus ( ) ) . build ( ) , accountConfig ) ; ObjectId accountId = oi . insert ( Constants . OBJ_BLOB , accountConfig . toText ( ) . getBytes ( UTF_8 ) ) ; oi . flush ( ) ; RefUpdate ru = repo . updateRef ( Accounts . REFS_ACCOUNTS + accountBuilder . getAccountId ( ) . get ( ) ) ; ru . setExpectedOldObjectId ( ObjectId . zeroId ( ) ) ; ru . setNewObjectId ( accountId ) ; ru . setRefLogIdent ( ident ) ; ru . setRefLogMessage ( ""Create Account"" , false ) ; Result result = ru . update ( ) ; switch ( result ) { case NEW : case FORCED : break ; default : throw new IOException ( String . format ( ""Failed to create account % s : % s"" , accountBuilder . getAccountId ( ) , result . name ( ) ) ) ; } return accountBuilder . build ( ) ; } } throw new IOException ( ""Failed to create account : repository not found"" ) ; } private File getPath ( ) { File path = site . resolve ( Accounts . REFS_ACCOUNTS ) . toFile ( ) ; if ( RepositoryCache . FileKey . isGitRepository ( path , FS . DETECTED ) ) { return path ; } return null ; } }
",,,"import org . eclipse . jgit . lib . RefUpdate . Result ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . lib . RepositoryCache . FileKey ; import org . eclipse . jgit . util . FS ; public class AccountsOnInit { private final InitFlags flags ; private final SitePaths site ; private final String allUsers ; @Inject public AccountsOnInit ( InitFlags flags , SitePaths site , AllUsersNameOnInitProvider allUsers ) { this . flags = flags ; this . site = site ; this . allUsers = allUsers . get ( ) ; } public Account insert ( Account . Builder account ) throws IOException { File path = getPath ( ) ; if ( path != null ) { try ( Repository repo = new FileRepository ( path ) ; ObjectInserter oi = repo . newObjectInserter ( ) ) { PersonIdent ident = new PersonIdent ( new GerritPersonIdentProvider ( flags . cfg ) . get ( ) , account . registeredOn ( ) ) ; Config accountConfig = new Config ( ) ; AccountProperties . writeToAccountConfig ( InternalAccountUpdate . builder ( ) . setActive ( account . isActive ( ) ) . setFullName ( account . fullName ( ) ) . setPreferredEmail ( account . preferredEmail ( ) ) . setStatus ( account . status ( ) ) . build ( ) , accountConfig , oi , ident ) ; Account . Id accountId = account . id ( ) ; FileKey fileKey = FileKey . exact ( path , FS . DETECTED ) ; try ( RepositoryCache . FileKeyRepositoryCache repoCache = new RepositoryCache . FileKeyRepositoryCache ( fileKey , repo ) ) { AccountConfig accountCfg = new AccountConfig ( accountId , repo ) ; accountCfg . setAccountConfig ( accountConfig ) ; accountCfg . commit ( ident , oi ) ; } return account . build ( ) ; } } return null ; } }
",,,"import org . eclipse . jgit . lib . RefUpdate . Result ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . lib . RepositoryCache . FileKey ; import org . eclipse . jgit . util . FS ; public class AccountsOnInit { private final InitFlags flags ; private final SitePaths site ; private final String allUsers ; @Inject public AccountsOnInit ( InitFlags flags , SitePaths site , AllUsersNameOnInitProvider allUsers ) { this . flags = flags ; this . site = site ; this . allUsers = allUsers . get ( ) ; } < |startfocus| > public Account insert ( Account . Builder account ) throws IOException { < |endfocus| > File path = getPath ( ) ; if ( path != null ) { try ( Repository repo = new FileRepository ( path ) ; ObjectInserter oi = repo . newObjectInserter ( ) ) { PersonIdent ident = new PersonIdent ( new GerritPersonIdentProvider ( flags . cfg ) . get ( ) , account . registeredOn ( ) ) ; Config accountConfig = new Config ( ) ; AccountProperties . writeToAccountConfig ( InternalAccountUpdate . builder ( ) . setActive ( account . isActive ( ) ) . setFullName ( account . fullName ( ) ) . setPreferredEmail ( account . preferredEmail ( ) ) . setStatus ( account . status ( ) ) . build ( ) ,
",,
2760,"String email = readEmail ( sshKey ) ; List < ExternalId > extIds = new ArrayList < > ( 2 ) ; extIds . add ( ExternalId . createUsername ( username , id , httpPassword ) ) ; if ( email != null ) { extIds . add ( ExternalId . createEmail ( id , email ) ) ; } externalIds . insert ( ""Add external IDs for initial admin user"" , extIds ) ; Account persistedAccount = accounts . insert ( Account . builder ( id , TimeUtil . nowTs ( ) ) . setFullName ( name ) . setPreferredEmail ( email ) ) ; // Only two groups should exist at this point in time and hence iterating over all of them // is cheap . Optional < GroupReference > adminGroupReference = groupsOnInit . getAllGroupReferences ( ) . filter ( group - > group . getName ( ) . equals ( ""Administrators"" ) ) . findAny ( ) ; if ( ! adminGroupReference . isPresent ( ) ) { throw new NoSuchGroupException ( ""Administrators"" ) ; } GroupReference adminGroup = adminGroupReference . get ( ) ; groupsOnInit . addGroupMember ( adminGroup . getUUID ( ) , persistedAccount ) ; if ( sshKey != null ) {
","Account persistedAccount = accounts . insert ( Account . builder ( id , TimeUtil . nowTs ( ) ) . setFullName ( name ) . setPreferredEmail ( email ) ) ;
","Account account = accounts.insert(Account.builder(id, TimeUtil.nowTs()).setFullName(name).setPreferredEmail(email));
",,,"Account account = accounts.insert(Account.builder(id, TimeUtil.nowTs()).setFullName(name).setPreferredEmail(email));
",,,"Account account = accounts . insert ( Account . builder ( id , TimeUtil . nowTs ( ) ) . setFullName ( name ) . setPreferredEmail ( email ) . build ( ) ) ; GroupReference adminGroup = groupsOnInit . getAllGroupReferences ( ) . filter ( group - > group . getName ( ) . equals ( ""Administrators"" ) ) . findAny ( ) . orElseThrow ( ( ) - > new NoSuchGroupException ( ""Administrators"" ) ) ; groupsOnInit . addGroupMember ( adminGroup . getUUID ( ) , account ) ; if ( sshKey != null ) { String username = account . getUserName ( ) . orElse ( null ) ; if ( username != null ) { SshKey sshKeyObj = SshKey . createWithAutoGeneratedPublicKey ( username , sshKey ) ; sshKeys . insert ( account . getId ( ) , sshKeyObj ) ; } }
",,,"String email = readEmail ( sshKey ) ; List < ExternalId > extIds = new ArrayList < > ( 2 ) ; extIds . add ( ExternalId . createUsername ( username , id , httpPassword ) ) ; if ( email != null ) { extIds . add ( ExternalId . createEmail ( id , email ) ) ; } externalIds . insert ( ""Add external IDs for initial admin user"" , extIds ) ; Account . Builder a = Account . builder ( id , TimeUtil . nowTs ( ) ) . setFullName ( name ) . setPreferredEmail ( email ) ; Account persistedAccount = a . build ( ) ; accounts . insert ( a ) ; // Only two groups should exist at this point in time and hence iterating over all of them // is cheap . Optional < GroupReference > adminGroupReference = groupsOnInit . getAllGroupReferences ( ) . filter ( group - > group . getName ( ) . equals ( ""Administrators"" ) ) . findAny ( ) ; if ( ! adminGroupReference . isPresent ( ) ) { throw new NoSuchGroupException ( ""Administrators"" ) ; } GroupReference adminGroup = adminGroupReference . get ( ) ; groupsOnInit . addGroupMember ( adminGroup . getUUID ( ) , persistedAccount ) ; if ( sshKey != null ) { // . . . ( remaining code ) . . . }
",,,"String email = readEmail ( sshKey ) ; List < ExternalId > extIds = new ArrayList < > ( 2 ) ; extIds . add ( ExternalId . createUsername ( username , id , httpPassword ) ) ; if ( email != null ) { extIds . add ( ExternalId . createEmail ( id , email ) ) ; } externalIds . insert ( ""Add external IDs for initial admin user"" , extIds ) ; < |startfocus| > Account persistedAccount = accounts . insert ( Account . builder ( id , TimeUtil . nowTs ( ) ) . setFullName ( name ) . setPreferredEmail ( email ) ) ; < |endfocus| > // Only two groups should exist at this point in time and hence iterating over all of them // is cheap . Optional < GroupReference > adminGroupReference = groupsOnInit . getAllGroupReferences ( ) . filter ( group - > group . getName ( ) . equals ( ""Administrators"" ) ) . findAny ( ) ; if ( ! adminGroupReference . isPresent ( ) ) { throw new NoSuchGroupException ( ""Administrators"" ) ; } GroupReference adminGroup = adminGroupReference . get ( ) ; groupsOnInit . addGroupMember ( adminGroup . getUUID ( ) , persistedAccount ) ; if ( sshKey != null ) {
",,
2769,"assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 1 ) ) . all ( head ) ; } @Test public void fallsBackToFullReloadOnManyUpdatesOnBranch ( ) throws Exception { insertExternalId ( 1 , 1 ) ; ObjectId head = null ; for ( int i = 2 ; i < 20 ; i ++ ) { head = insertExternalId ( i , i ) ; } assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 1 ) ) . all ( head ) ; } @Test public void doesFullReloadWhenNoCacheStateIsFound ( ) throws Exception { ObjectId head = insertExternalId ( 1 , 1 ) ; assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 1 ) ) . all ( head ) ; } @Test public void handlesDeletionInPartialReload ( ) throws Exception { ObjectId firstState = insertExternalId ( 1 , 1 ) ; ObjectId head = deleteExternalId ( 1 , 1 ) ; assertThat ( allFromGit ( head ) . byAccount ( ) . size ( ) ) . isEqualTo ( 0 ) ; when ( externalIdCache . getIfPresent ( firstState ) ) . thenReturn ( allFromGit ( firstState ) ) ; assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verifyZeroInteractions ( externalIdReaderSpy ) ; } @Test public void handlesModifyInPartialReload ( ) throws Exception { ObjectId firstState = insertExternalId ( 1 , 1 ) ;
","@Test public void doesFullReloadWhenNoCacheStateIsFound ( ) throws Exception { ObjectId head = insertExternalId ( 1 , 1 ) ; assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 1 ) ) . all ( head ) ; } @Test
","@Test
",,,"@Test public void fallsBackToFullReloadOnManyUpdatesOnBranch() throws Exception { insertExternalId(1, 1); ObjectId head = deleteExternalId(1, 1); assertThat(loader.load(head)).isEqualTo(allFromGit(head)); verify(externalIdReaderSpy, times(1)).all(head); } @Test
",,,"@Test public void handlesDeletionInPartialReload ( ) throws Exception { ObjectId firstState = insertExternalId ( 1 , 1 ) ; ObjectId head = deleteExternalId ( 1 , 1 ) ; assertThat ( allFromGit ( head ) . byAccount ( ) . size ( ) ) . isEqualTo ( 0 ) ; when ( externalIdCache . getIfPresent ( firstState ) ) . thenReturn ( allFromGit ( firstState ) ) ; assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verifyZeroInteractions ( externalIdReaderSpy ) ; } @Test public void handlesModifyInPartialReload ( ) throws Exception { ObjectId firstState = insertExternalId ( 1 , 1 ) ; ObjectId head = modifyExternalId ( 1 , 1 ) ; assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 1 ) ) . all ( head ) ; } @Test public void handlesMissingStateInPartialReload ( ) throws Exception { ObjectId head = insertExternalId ( 1 , 1 ) ; for ( int i = 2 ; i < 17 ; i ++ ) { head = insertExternalId ( i , i ) ; } ObjectId missingState = insertExternalId ( 17 , 17 ) ; deleteExternalId ( 17 , 17 ) ; head = insertExternalId ( 18 , 18 ) ; assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 1 ) ) . all ( head ) ; when ( externalIdCache . getIfPresent ( missingState ) ) . thenReturn ( null ) ; assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 2 ) ) . all ( head ) ; }
",,,"@Test public void testBuildAndMergeNormalFrameInMem ( ) throws HyracksDataException { int tableSize = 101 ; int numFrames = 50 ; int frameSize = 256 ; int minDataSize = frameSize ; int minRecordSize = 20 ; int maxRecordSize = 50 ; testBuildAndMerge ( tableSize , numFrames , frameSize , minDataSize , minRecordSize , maxRecordSize , null ) ; } @Test public void testBuildAndMergeNormalFrameSpill ( ) throws HyracksDataException { int tableSize = 101 ; int numFrames = 50 ; int frameSize = 256 ; int minDataSize = frameSize * 4 ; int minRecordSize = 20 ; int maxRecordSize = 50 ; testBuildAndMerge ( tableSize , numFrames , frameSize , minDataSize , minRecordSize , maxRecordSize , null ) ; } @Test public void testBuildAndMergeBigObj ( ) throws HyracksDataException { int tableSize = 101 ; int numFrames = 50 ; int frameSize = 256 ; int minDataSize = frameSize * 80 ; int minRecordSize = 20 ; int maxRecordSize = 50 ; testBuildAndMerge ( tableSize , numFrames , frameSize , minDataSize , minRecordSize , maxRecordSize , null ) ; } } for ( int i = 0 ; i < splitRow . size ( ) ; ++ i ) { LiteralExpr expr = splitRow . get ( i ) ; ColumnDef colDef = pkColumnDefByName_ . get ( colNames_ . get ( i ) ) ; org . apache . impala . catalog . Type colType = colDef . getType ( ) ; Preconditions . checkState ( KuduUtil . isSupportedKeyType ( colType ) ) ; expr . analyze ( analyzer ) ; org . apache . impala . catalog . Type exprType = expr . getType ( ) ; if ( exprType . isNull ( ) ) { throw new AnalysisException ( ""Split values cannot be NULL . Split row : "" + splitRowToString ( splitRow ) ) ; } if ( ! org . apache . impala . catalog . Type . isImplicitlyCastable ( exprType , colType , true ) ) { throw new AnalysisException ( String . format ( ""Split value % s ( type : % s ) is "" + ""not type compatible with column ' % s' ( type : % s ) . "" , expr . toSql ( ) , exprType , colDef
",,,"assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 1 ) ) . all ( head ) ; } @Test public void fallsBackToFullReloadOnManyUpdatesOnBranch ( ) throws Exception { insertExternalId ( 1 , 1 ) ; ObjectId head = null ; for ( int i = 2 ; i < 20 ; i ++ ) { head = insertExternalId ( i , i ) ; } assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 1 ) ) . all ( head ) ; } @Test public void handlesDeletionInPartialReload ( ) throws Exception { ObjectId firstState = insertExternalId ( 1 , 1 ) ; ObjectId head = deleteExternalId ( 1 , 1 ) ; assertThat ( allFromGit ( head ) . byAccount ( ) . size ( ) ) . isEqualTo ( 0 ) ; when ( externalIdCache . getIfPresent ( firstState ) ) . thenReturn ( allFromGit ( firstState ) ) ; assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verifyZeroInteractions ( externalIdReaderSpy ) ; } < |startfocus| > @Test < |endfocus| > public void handlesModifyInPartialReload ( ) throws Exception { ObjectId firstState = insertExternalId ( 1 , 1 ) ;
",,
2771,". add ( allow ( Permission . PUSH ) . ref ( other ) . group ( adminGroupUuid ( ) ) ) . update ( ) ; RevCommit masterRev = projectOperations . project ( project ) . getHead ( ""master"" ) ; pushCommitTo ( masterRev , other ) ; PushOneCommit . Result r = createChange ( ) ; r . assertOkStatus ( ) ; RevCommit commit = r . getCommit ( ) ; pushCommitTo ( commit , master ) ; assertCommit ( project , master ) ; ChangeData cd = Iterables . getOnlyElement ( queryProvider . get ( ) . byKey ( new Change . Key ( r . getChangeId ( ) ) ) ) ; assertThat ( cd . change ( ) . getStatus ( ) ) . isEqualTo ( Change . Status . MERGED ) ; RemoteRefUpdate . Status status = pushCommitTo ( commit , ""refs / for / other"" ) ; assertThat ( status ) . isEqualTo ( RemoteRefUpdate . Status . OK ) ; pushCommitTo ( commit , other ) ; assertCommit ( project , other ) ; for ( ChangeData c : queryProvider . get ( ) . byKey ( Change . key ( r . getChangeId ( ) ) ) ) { if ( c . change ( ) . getDest ( ) . branch ( ) . equals ( other ) ) { assertThat ( c . change ( ) . isMerged ( ) ) . isTrue ( ) ; } } } private RemoteRefUpdate . Status pushCommitTo ( RevCommit commit , String ref )
","Iterables . getOnlyElement ( queryProvider . get ( ) . byKey ( new Change . Key ( r . getChangeId ( ) ) ) ) ; assertThat ( cd . change ( ) . getStatus ( ) ) . isEqualTo ( Change . Status . MERGED ) ;
","Iterables.getOnlyElement(queryProvider.get().byKey(Change.key(r.getChangeId())) .change().isMerged()).isTrue();
",,,"Iterables.getOnlyElement(queryProvider.get().byKey(Change.key(r.getChangeId()))); assertThat(cd.change().isMerged()).isTrue();
",,,". add ( allow ( Permission . PUSH ) . ref ( other ) . group ( adminGroupUuid ( ) ) ) . update ( ) ; RevCommit masterRev = projectOperations . project ( project ) . getHead ( ""master"" ) ; pushCommitTo ( masterRev . commitId ( ) , other ) ; PushOneCommit . Result r = createChange ( ) ; r . assertOkStatus ( ) ; RevCommit commit = r . getCommit ( ) ; pushCommitTo ( commit . commitId ( ) , master ) ; assertCommit ( project , master ) ; ChangeData cd = Iterables . getOnlyElement ( queryProvider . get ( ) . byKey ( Change . key ( r . getChangeId ( ) ) ) ) ; assertThat ( cd . change ( ) . isMerged ( ) ) . isTrue ( ) ; RemoteRefUpdate . Status status = pushCommitTo ( commit . commitId ( ) , ""refs / for / other"" ) ; assertThat ( status ) . isEqualTo ( RemoteRefUpdate . Status . OK ) ; pushCommitTo ( commit . commitId ( ) , other ) ; assertCommit ( project , other ) ; for ( ChangeData c : queryProvider . get ( ) . byKey ( Change . key ( r . getChangeId ( ) ) ) ) { if ( c . change ( ) . getDest ( ) . branch ( ) . equals ( other ) ) { assertThat ( c . change ( ) . isMerged ( ) ) . isTrue ( ) ; } } private RemoteRefUpdate . Status pushCommitTo ( ObjectId commitId , String ref ) { try ( Repository repo = repoManager . openRepository ( project ) ; Git git = new Git ( repo ) ) { return git . push ( ) . setRefSpecs ( new RefSpec ( commitId . name ( ) + "" : "" + ref ) ) . setCredentialsProvider ( credentialsProvider ) . call ( ) . getRemoteUpdates ( ) . stream ( ) . findFirst ( ) . orElseThrow ( IllegalStateException : : new ) . getStatus ( ) ; } catch ( GitAPIException | IOException e ) { throw new RuntimeException ( e ) ; } }
",,,"private void queueSuccessMessages ( List < CreateRequest > newChanges ) { // adjacency list for commit = > parent Map < String , String > adjList = new HashMap < > ( ) ; List < String > outOfOrderCommits = new ArrayList < > ( ) ; for ( CreateRequest cr : newChanges ) { String parent = cr . commit . getParentCount ( ) < 1 ? start : cr . commit . getParent ( 0 ) . name ( ) ; adjList . put ( parent , cr . commit . name ( ) ) ; } for ( ReplaceRequest rr : replaceByChange . values ( ) ) { try { RevCommit revCommit = receivePack . getRevWalk ( ) . parseCommit ( rr . newCommitId ) ; String parent = revCommit . getParentCount ( ) < 1 ? start : revCommit . getParent ( 0 ) . name ( ) ; adjList . put ( parent , rr . newCommitId . name ( ) ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( ""failed to parse commit % s for success message . "" , rr . newCommitId . name ( ) ) ; outOfOrderCommits . add ( rr . newCommitId . name ( ) ) ; } } if ( adjList . get ( start ) == null ) { // Handle the case when the start commit is not found in the adjacency list } } private List < SubmitRecord > getSubmitRecords ( ChangeData cd ) { if ( projectState == null || projectState . hasPrologRules ( ) ) { return Collections . emptyList ( ) ; } SubmitRecord submitRecord = new SubmitRecord ( ) ; submitRecord . status = SubmitRecord . Status . OK ; List < LabelType > labelTypes ; List < PatchSetApproval > approvals ; try { labelTypes = cd . getLabelTypes ( ) . getLabelTypes ( ) ; approvals = cd . currentApprovals ( ) ; } catch ( OrmException e ) { log . error ( ""Unable to fetch labels and approvals for change { } : { } "" , cd . getId ( ) , e ) ; submitRecord . errorMessage = ""Unable to fetch labels and approvals for the change"" ; submitRecord . status = SubmitRecord . Status . RULE_ERROR ; return Collections . singletonList ( submitRecord ) ; } submitRecord . labels = new ArrayList < > ( labelTypes . size ( ) ) ; for ( LabelType t : labelTypes ) { LabelFunction labelFunction = t . getFunction ( ) ; if ( labelFunction == null ) { log . error ( ""Unable to find the LabelFunction for label { } , change { } "" , t . getName ( ) , cd . getId ( ) ) ; // Handle the case when the LabelFunction is not found } } // Process the submit records and
",,,". add ( allow ( Permission . PUSH ) . ref ( other ) . group ( adminGroupUuid ( ) ) ) . update ( ) ; RevCommit masterRev = projectOperations . project ( project ) . getHead ( ""master"" ) ; pushCommitTo ( masterRev , other ) ; PushOneCommit . Result r = createChange ( ) ; r . assertOkStatus ( ) ; RevCommit commit = r . getCommit ( ) ; pushCommitTo ( commit , master ) ; assertCommit ( project , master ) ; ChangeData cd = < |startfocus| > Iterables . getOnlyElement ( queryProvider . get ( ) . byKey ( Change . key ( r . getChangeId ( ) ) ) ) ; assertThat ( cd . change ( ) . isMerged ( ) ) . isTrue ( ) ; < |endfocus| > RemoteRefUpdate . Status status = pushCommitTo ( commit , ""refs / for / other"" ) ; assertThat ( status ) . isEqualTo ( RemoteRefUpdate . Status . OK ) ; pushCommitTo ( commit , other ) ; assertCommit ( project , other ) ; for ( ChangeData c : queryProvider . get ( ) . byKey ( Change . key ( r . getChangeId ( ) ) ) ) { if ( c . change ( ) . getDest ( ) . branch ( ) . equals ( other ) ) { assertThat ( c . change ( ) . isMerged ( ) ) . isTrue ( ) ; } } } private RemoteRefUpdate . Status pushCommitTo ( RevCommit commit , String ref ) throws Exception {
",,
2772,"// from the cache . Extend the cache size by 1 to cover this case , but expire the extra // object after a short period of time , since it may be a potentially large amount of // memory . // When loading a new value because the primary data advanced , we want to leverage the old // cache state to recompute only what changed . This doesn't affect cache size though as // Guava calls the loader first and evicts later on . . maximumWeight ( 2 ) . expireFromMemoryAfterAccess ( Duration . ofMinutes ( 5 ) ) . loader ( ExternalIdCacheLoader . class ) . diskLimit ( - 1 ) . version ( 1 ) . keySerializer ( ObjectIdCacheSerializer . INSTANCE ) . valueSerializer ( AllExternalIds . Serializer . INSTANCE ) ; bind ( ExternalIdCacheImpl . class ) ; bind ( ExternalIdCache . class ) . to ( ExternalIdCacheImpl . class ) ;
","< |del| >/ / memory .
","// memory.
",,,"// memory.
",,,". maximumWeight ( 2 ) . expireFromMemoryAfterAccess ( Duration . ofMinutes ( 5 ) ) . loader ( ExternalIdCacheLoader . class ) . diskLimit ( - 1 ) . version ( 1 ) . keySerializer ( ObjectIdCacheSerializer . INSTANCE ) . valueSerializer ( AllExternalIds . Serializer . INSTANCE ) ; bind ( ExternalIdCacheImpl . class ) ; bind ( ExternalIdCache . class ) . to ( ExternalIdCacheImpl . class ) ;
",,,"// from the cache . Extend the cache size by 1 to cover this case , but expire the extra // object after a short period of time , since it may be a potentially large amount of // memory . // When loading a new value because the primary data advanced , we want to leverage the old // cache state to recompute only what changed . This doesn't affect cache size though as // Guava calls the loader first and evicts later on . . maximumWeight ( 2 ) . expireFromMemoryAfterAccess ( Duration . ofMinutes ( 5 ) ) . loader ( ExternalIdCacheLoader . class ) . diskLimit ( - 1 ) . version ( 1 ) . keySerializer ( ObjectIdCacheSerializer . INSTANCE ) . valueSerializer ( AllExternalIds . Serializer . INSTANCE ) ; bind ( ExternalIdCacheImpl . class ) ; bind ( ExternalIdCache . class ) . to ( ExternalIdCacheImpl . class ) ;
",,,"// from the cache . Extend the cache size by 1 to cover this case , but expire the extra // object after a short period of time , since it may be a potentially large amount of // memory . // When loading a new value because the primary data advanced , we want to leverage the old // cache state to recompute only what changed . This doesn't affect cache size though as // Guava calls the loader first and evicts later on . < |startfocus| > // memory . < |endfocus| > . maximumWeight ( 2 ) . expireFromMemoryAfterAccess ( Duration . ofMinutes ( 5 ) ) . loader ( ExternalIdCacheLoader . class ) . diskLimit ( - 1 ) . version ( 1 ) . keySerializer ( ObjectIdCacheSerializer . INSTANCE ) . valueSerializer ( AllExternalIds . Serializer . INSTANCE ) ; bind ( ExternalIdCacheImpl . class ) ; bind ( ExternalIdCache . class ) . to ( ExternalIdCacheImpl . class ) ;
",,
2780,"config . getBoolean ( ""cache"" , ExternalIdCacheImpl . CACHE_NAME , ""enablePartialReloads"" , false ) ; } @Override public AllExternalIds load ( ObjectId notesRev ) throws IOException , ConfigInvalidException { if ( ! enablePartialReloads ) { logger . atInfo ( ) . log ( ""Partial reloads of "" + ExternalIdCacheImpl . CACHE_NAME + "" disabled . Falling back to full reload . "" ) ; return reloadAllExternalIds ( notesRev ) ; } // The requested value was not in the cache ( hence , this loader was invoked ) . Therefore , try to // create this entry from a past value using the minimal amount of Git operations possible to // reduce latency . // // First , try to find the most recent state we have in the persistent cache . Most of the time , // this will be the state before the last update happened , but it can also date further back . We // try a best effort approach and check the last 10 states . If nothing is found , we default to // loading the value from scratch . //
","// The requested value was not in the cache ( hence , this loader was invoked ) . Therefore , try to // create this entry from a past value using the minimal amount of Git operations possible to // reduce latency .
","// We failed to load the requested value from the cache (hence, this loader was invoked). // Therefore, try to create this entry from a past value using the minimal amount of Git // operations possible to reduce latency.
",,,"// We failed to load the requested value from the cache (hence, this loader was invoked). // Therefore, try to create this entry from a past value using the minimal amount of Git // operations possible to reduce latency.
",,,"config . getBoolean ( ""cache"" , ExternalIdCacheImpl . CACHE_NAME , ""enablePartialReloads"" , false ) ; @Override public AllExternalIds load ( ObjectId notesRev ) throws IOException , ConfigInvalidException { if ( ! enablePartialReloads ) { logger . atInfo ( ) . log ( ""Partial reloads of "" + ExternalIdCacheImpl . CACHE_NAME + "" disabled . Falling back to full reload . "" ) ; return reloadAllExternalIds ( notesRev ) ; } // We failed to load the requested value from the cache ( hence , this loader was invoked ) . // Therefore , try to create this entry from a past value using the minimal amount of Git // operations possible to reduce latency . // // First , try to find the most recent state we have in the persistent cache . Most of the time , // this will be the state before the last update happened , but it can also date further back . We // try a best effort approach and check the last 10 states . If nothing is found , we default to // loading the value from scratch . }
",,,"import com . google . gerrit . server . IdentifiedUser ; import com . google . gerrit . server . OutputFormat ; import com . google . gerrit . server . util . SystemLog ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import org . apache . log4j . Level ; import org . apache . log4j . LogManager ; import org . apache . log4j . Logger ; import org . apache . log4j . spi . LoggingEvent ; @Singleton class DeleteLog implements LifecycleListener { private static final String DELETE_LOG_NAME = ""delete_log"" ; private static final Logger log = LogManager . getLogger ( DELETE_LOG_NAME ) ; public static String ACCOUNT_ID = ""accountId"" ; public static String USER_NAME = ""userName"" ; public static String PROJECT_NAME = ""projectName"" ; public static String OPTIONS = ""options"" ; public static String ERROR = ""error"" ; private final SystemLog systemLog ; private final ServerInformation serverInfo ; private static boolean started ; @Inject public DeleteLog ( SystemLog systemLog , ServerInformation serverInfo ) { this . systemLog = systemLog ; this . serverInfo = serverInfo ; } public void onDelete ( IdentifiedUser user , Project . NameKey project , . . . ) { // implementation } } private void initNoteDb ( ) { ui . message ( ""Use experimental NoteDb for change metadata ? \n"" + ""NoteDb is not recommended for production servers . "" + ""Please familiarize yourself with the documentation : \n"" + ""https :/ / gerrit - review . googlesource . com / Documentation / dev - note - db . html\n"" ) ; if ( ! ui . yesno ( false , ""Enable"" ) ) { return ; } Config defaultConfig = ConfigNotesMigration . allEnabledConfig ( ) ; for ( String name : defaultConfig . getNames ( SECTION_NOTE_DB , CHANGES . key ( ) ) ) { noteDbChanges . set ( name , defaultConfig . getString ( SECTION_NOTE_DB , CHANGES . key ( ) , name ) ) ; } } /* * * Scans the plugin for declared public annotated classes * * @param pluginName the plugin name * @param annotations annotations declared by the plugin classes * @return map of annotations and associated plugin classes found * @throws InvalidPluginException if the plugin is not valid or corrupted */ Map < Class < ? extends Annotation > , Iterable < ExtensionMetaData > > scan ( String pluginName , Iterable < Class < ? extends Annotation > > annotations ) throws InvalidPluginException ; /* * * Return the plugin resource
",,,"config . getBoolean ( ""cache"" , ExternalIdCacheImpl . CACHE_NAME , ""enablePartialReloads"" , false ) ; } @Override public AllExternalIds load ( ObjectId notesRev ) throws IOException , ConfigInvalidException { if ( ! enablePartialReloads ) { logger . atInfo ( ) . log ( ""Partial reloads of "" + ExternalIdCacheImpl . CACHE_NAME + "" disabled . Falling back to full reload . "" ) ; return reloadAllExternalIds ( notesRev ) ; } < |startfocus| > // We failed to load the requested value from the cache ( hence , this loader was invoked ) . // Therefore , try to create this entry from a past value using the minimal amount of Git // operations possible to reduce latency . < |endfocus| > // // First , try to find the most recent state we have in the persistent cache . Most of the time , // this will be the state before the last update happened , but it can also date further back . We // try a best effort approach and check the last 10 states . If nothing is found , we default to // loading the value from scratch . //
",,
2783,"private final TypeAdapter < T > defaultEnumAdapter ; public EnumTypeAdapter ( TypeAdapter < T > defaultEnumAdapter ) { this . defaultEnumAdapter = defaultEnumAdapter ; } @Override public T read ( JsonReader in ) throws IOException { // Still handle null values . - > Check them first . if ( in . peek ( ) == JsonToken . NULL ) { in . nextNull ( ) ; return null ; } T enumValue = defaultEnumAdapter . read ( in ) ; if ( enumValue == null ) { logger . atWarning ( ) . log ( ""Expected an existing value for enum % s . "" , typeToken ) ; } return enumValue ; } @Override public void write ( JsonWriter out , T value ) throws IOException { defaultEnumAdapter . write ( out , value ) ; } } }
","logger . atWarning ( ) . log ( ""Expected an existing value for enum % s . "" , typeToken ) ;
","throw new JsonSyntaxException(""Invalid value 'THREE' for enum TestEnum: "" + enumValue);
",,,"throw new JsonSyntaxException(""Invalid value of the enum '"" + enum.getName() + ""' expected an existing enum value."");
",,,"private final TypeAdapter < T > defaultEnumAdapter ; public EnumTypeAdapter ( TypeAdapter < T > defaultEnumAdapter ) { this . defaultEnumAdapter = defaultEnumAdapter ; } @Override public T read ( JsonReader in ) throws IOException { if ( in . peek ( ) == JsonToken . NULL ) { in . nextNull ( ) ; return null ; } T enumValue = defaultEnumAdapter . read ( in ) ; if ( enumValue == null ) { throw new JsonSyntaxException ( ""Invalid value '"" + in . nextString ( ) + ""' for enum "" + defaultEnumAdapter . getClass ( ) . getSimpleName ( ) ) ; } return enumValue ; } @Override public void write ( JsonWriter out , T value ) throws IOException { defaultEnumAdapter . write ( out , value ) ; }
",,,"private final TypeAdapter < T > defaultEnumAdapter ; public EnumTypeAdapter ( TypeAdapter < T > defaultEnumAdapter ) { this . defaultEnumAdapter = defaultEnumAdapter ; } @Override public T read ( JsonReader in ) throws IOException { if ( in . peek ( ) == JsonToken . NULL ) { in . nextNull ( ) ; return null ; } T enumValue = defaultEnumAdapter . read ( in ) ; if ( enumValue == null ) { throw new JsonSyntaxException ( String . format ( ""Invalid value ' % s' for enum % s"" , in . nextString ( ) , defaultEnumAdapter . getClass ( ) . getSimpleName ( ) ) ) ; } return enumValue ; } @Override public void write ( JsonWriter out , T value ) throws IOException { defaultEnumAdapter . write ( out , value ) ; }
",,,"private final TypeAdapter < T > defaultEnumAdapter ; public EnumTypeAdapter ( TypeAdapter < T > defaultEnumAdapter ) { this . defaultEnumAdapter = defaultEnumAdapter ; } @Override public T read ( JsonReader in ) throws IOException { // Still handle null values . - > Check them first . if ( in . peek ( ) == JsonToken . NULL ) { in . nextNull ( ) ; return null ; } T enumValue = defaultEnumAdapter . read ( in ) ; if ( enumValue == null ) { < |startfocus| > throw new JsonSyntaxException ( ""Expected an existing enum value . "" ) ; < |endfocus| > } return enumValue ; } @Override public void write ( JsonWriter out , T value ) throws IOException { defaultEnumAdapter . write ( out , value ) ; } } }
",,
2787,"* RestCollectionModifyViews this is usually { code 200 OK } , but other 2XX or 3XX status codes are * also possible ( e . g . { code 201 Created } if a resource was created , { code 202 Accepted } if a * background task was scheduled , { @code 204 No Content } if no content is returned , { @code 302 * Found } for a redirect ) . * * < p > Throwing a subclass of { @link RestApiException } results in a 4XX response to the client . For * any other exception the client will get a { @code 500 Internal Server Error } response . * * @param parentResource the collection resource on which the modification is done * @return response to return to the client * @throws Exception the implementation of the view failed . The exception will be logged and HTTP * 500 Internal Server Error will be returned to the client .
","< |del| >* < p > Further properties like caching behavior ( see { @link CacheControl } ) can be optionally set on * the returned response . *
","<|del|>
",,,"<|del|>
",,,"/* * * Modifies a collection resource and returns a response to the client . The response status code is usually 200 OK , but other 2XX or 3XX status codes are also possible ( e . g . 201 Created if a resource was created , 202 Accepted if a background task was scheduled , 204 No Content if no content is returned , 302 Found for a redirect ) . * Further properties like caching behavior ( see { @link CacheControl } ) can be optionally set on the returned response . * Throwing a subclass of { @link RestApiException } results in a 4XX response to the client . For any other exception the client will get a 500 Internal Server Error response . * * @param parentResource the collection resource on which the modification is done * @return response to return to the client , if the response type allows this * @throws UnsupportedOperationException if the response type does not allow this * @throws Exception the implementation of the view failed . The exception will be logged and HTTP 500 Internal Server Error will be returned to the client . */
",,,"/* * * RestCollectionModifyViews this is usually { code 200 OK } , but other 2XX or 3XX status codes are * also possible ( e . g . { code 201 Created } if a resource was created , { code 202 Accepted } if a * background task was scheduled , { @code 204 No Content } if no content is returned , { @code 302 * Found } for a redirect ) . * < p > Further properties like caching behavior ( see { @link CacheControl } ) can be optionally set on * the returned response . * < p > Throwing a subclass of { @link RestApiException } results in a 4XX response to the client . For * any other exception the client will get a { @code 500 Internal Server Error } response . * * @param parentResource the collection resource on which the modification is done * @return response to return to the client * @throws Exception the implementation of the view failed . The exception will be logged and HTTP * 500 Internal Server Error will be returned to the client . * @throws UnsupportedOperationException if the response type does not support this operation */
",,,"* RestCollectionModifyViews this is usually { code 200 OK } , but other 2XX or 3XX status codes are * also possible ( e . g . { code 201 Created } if a resource was created , { code 202 Accepted } if a * background task was scheduled , { @code 204 No Content } if no content is returned , { @code 302 * Found } for a redirect ) . * < p > Further properties like caching behavior ( see { @link CacheControl } ) can be optionally set on * the returned response . * < p > Throwing a subclass of { @link RestApiException } results in a 4XX response to the client . For * any other exception the client will get a { @code 500 Internal Server Error } response . * * @param parentResource the collection resource on which the modification is done * @return response to return to the client * @throws Exception the implementation of the view failed . The exception will be logged and HTTP * 500 Internal Server Error will be returned to the client .
",,
2792,"private final Configuration cfg ; private final HideProject hideProject ; @Inject DeleteProject ( FilesystemDeleteHandler fsHandler , CacheDeleteHandler cacheHandler , Provider < CurrentUser > userProvider , DeleteLog deleteLog , DeletePreconditions preConditions , Configuration cfg , HideProject hideProject ) { this . fsHandler = fsHandler ; this . cacheHandler = cacheHandler ; this . userProvider = userProvider ; this . deleteLog = deleteLog ; this . preConditions = preConditions ; this . cfg = cfg ; this . hideProject = hideProject ; } @Override public Object apply ( ProjectResource rsrc , Input input ) throws IOException , RestApiException { preConditions . assertDeletePermission ( rsrc ) ; preConditions . assertCanBeDeleted ( rsrc , input ) ; doDelete ( rsrc , input ) ; return Response . none ( ) ; } public void doDelete ( ProjectResource rsrc , Input input ) throws IOException , RestApiException { Project project = rsrc . getProjectState ( ) . getProject ( ) ; boolean preserve = input != null && input . preserve ; Exception ex = null ; try { if ( ! preserve || ! cfg . projectOnPreserveHidden ( ) ) { try {
","public Object apply ( ProjectResource rsrc , Input input ) throws IOException , RestApiException {
","public Response<?> apply(ProjectResource rsrc, Input input) throws OrmException, IOException, RestApiException {
",,,"public Response<?> apply(ProjectResource rsrc, Input input) throws IOException, RestApiException {
",,,"private final Configuration cfg ; private final HideProject hideProject ; private final FilesystemDeleteHandler fsHandler ; private final CacheDeleteHandler cacheHandler ; private final Provider < CurrentUser > userProvider ; private final DeleteLog deleteLog ; private final DeletePreconditions preConditions ; @Inject public DeleteProject ( FilesystemDeleteHandler fsHandler , CacheDeleteHandler cacheHandler , Provider < CurrentUser > userProvider , DeleteLog deleteLog , DeletePreconditions preConditions , Configuration cfg , HideProject hideProject ) { this . fsHandler = fsHandler ; this . cacheHandler = cacheHandler ; this . userProvider = userProvider ; this . deleteLog = deleteLog ; this . preConditions = preConditions ; this . cfg = cfg ; this . hideProject = hideProject ; } @Override public Response < ? > apply ( ProjectResource rsrc , Input input ) throws OrmException , IOException , RestApiException { preConditions . assertDeletePermission ( rsrc ) ; preConditions . assertCanBeDeleted ( rsrc , input ) ; doDelete ( rsrc , input ) ; return Response . none ( ) ; } public void doDelete ( ProjectResource rsrc , Input input ) throws IOException , RestApiException { Project project = rsrc . getProjectState ( ) . getProject ( ) ; boolean preserve = input != null && input . preserve ; Exception ex = null ; try { if ( ! preserve || ! cfg . projectOnPreserveHidden ( ) ) { try { hideProject . unhideAll ( project . getNameKey ( ) ) ; } catch ( Exception e ) { log . warn ( ""Failed to unhide project "" + project . getName ( ) , e ) ; } } fsHandler . delete ( project . getNameKey ( ) ) ; cacheHandler . evict ( project . getNameKey ( ) ) ; deleteLog . onDeleteProject ( project . getNameKey ( ) ) ; } catch ( Exception e ) { ex = e ; throw e ; } finally { if ( ex != null ) { try { cacheHandler . evict ( project . getNameKey ( ) ) ; fsHandler . rollback ( project . getNameKey ( ) ) ; } catch ( Exception e ) { log . warn ( ""Failed to rollback project deletion "" + project . getName ( ) , e ) ; } } } }
",,,"// limitations under the License . package com . google . gerrit . acceptance . testsuite . project ; import static com . google . common . truth . Truth . assertThat ; import static java . util . stream . Collectors . toList ; import com . google . common . collect . ImmutableList ; import com . google . gerrit . acceptance . AbstractDaemonTest ; import com . google . gerrit . extensions . api . projects . BranchInfo ; import com . google . gerrit . reviewdb . client . Project ; import com . google . inject . Inject ; import java . util . List ; import org . junit . Test ; public class ProjectOperationsImplTest extends AbstractDaemonTest { @Inject private ProjectOperations projectOperations ; @Test public void defaultName ( ) throws Exception { Project . NameKey name = projectOperations . newProject ( ) . create ( ) ; gApi . projects ( ) . name ( name . get ( ) ) ; Project . NameKey name2 = projectOperations . newProject ( ) . create ( ) ; assertThat ( name2 ) . isNotEqualTo ( name ) ; } @Test public void specifiedName ( ) throws Exception { String name = ""somename"" ; Project . NameKey key = projectOperations . newProject ( ) . name ( name ) . create ( ) ; assertThat ( key . get ( ) ) . isEqualTo ( name ) ; } @Test public void emptyCommit ( ) throws Exception { // Test code here } } import org . eclipse . osee . orcs . data . ArtifactReadable ; /* * * @author Donald G . Dunne * @author David W . Miller */ @Path ( ""program"" ) public class ProgramResource extends AbstractConfigResource { @Context private UriInfo uriInfo ; public void setUriInfo ( UriInfo uriInfo ) { this . uriInfo = uriInfo ; } public ProgramResource ( IAtsServer atsServer ) { super ( AtsArtifactTypes . Program , atsServer ) ; } @GET @Path ( "" { uuid } / insertion"" ) @Produces ( MediaType . APPLICATION_JSON ) public Response getProgramInsertions ( @PathParam ( ""uuid"" ) long uuid ) throws Exception { ArtifactReadable programArt = atsServer . getArtifactByUuid ( uuid ) ; if ( programArt == null ) { throw new OseeCoreException ( ""Given uuid not found"" ) ; } if ( ! programArt . getArtifactType ( ) . equals ( AtsArtifactTypes . Program ) ) { throw new OseeCoreException ( ""Given uuid not program type"" ) ; } // get the insertions related to the given program ResultSet < ArtifactReadable > results = programArt . getRelated ( AtsRelationTypes . ProgramToInsertion_Insertion ) ;
",,,"private final Configuration cfg ; private final HideProject hideProject ; @Inject DeleteProject ( FilesystemDeleteHandler fsHandler , CacheDeleteHandler cacheHandler , Provider < CurrentUser > userProvider , DeleteLog deleteLog , DeletePreconditions preConditions , Configuration cfg , HideProject hideProject ) { this . fsHandler = fsHandler ; this . cacheHandler = cacheHandler ; this . userProvider = userProvider ; this . deleteLog = deleteLog ; this . preConditions = preConditions ; this . cfg = cfg ; this . hideProject = hideProject ; } @Override < |startfocus| > public Response < ? > apply ( ProjectResource rsrc , Input input ) throws OrmException , IOException , RestApiException { < |endfocus| > preConditions . assertDeletePermission ( rsrc ) ; preConditions . assertCanBeDeleted ( rsrc , input ) ; doDelete ( rsrc , input ) ; return Response . none ( ) ; } public void doDelete ( ProjectResource rsrc , Input input ) throws IOException , RestApiException { Project project = rsrc . getProjectState ( ) . getProject ( ) ; boolean preserve = input != null && input . preserve ; Exception ex = null ; try { if ( ! preserve || ! cfg . projectOnPreserveHidden ( ) ) { try {
",,
2794,"this . accountInfoFactory = infoFactory ; this . projectCache = projectCache ; this . prologRule = prologRule ; } @Override public Response < List < TestSubmitRuleInfo > > apply ( RevisionResource rsrc , TestSubmitRuleInput input ) throws AuthException , PermissionBackendException , BadRequestException { if ( input == null ) { input = new TestSubmitRuleInput ( ) ; } if ( input . rule == null ) { throw new BadRequestException ( ""rule is required"" ) ; } if ( ! rules . isProjectRulesEnabled ( ) ) { throw new AuthException ( ""project rules are disabled"" ) ; } input . filters = MoreObjects . firstNonNull ( input . filters , filters ) ; SubmitRuleOptions opts = SubmitRuleOptions . builder ( ) . skipFilters ( input . filters == Filters . SKIP ) . rule ( input . rule ) . logErrors ( false ) . build ( ) ; ProjectState projectState = projectCache . get ( rsrc . getProject ( ) ) ; if ( projectState == null ) { throw new BadRequestException ( ""project not found"" ) ; }
","< |del| > if ( input . rule == null ) { throw new BadRequestException ( ""rule is required"" ) ; }
","<|del|>
",,,"<|del|>
",,,"this . accountInfoFactory = infoFactory ; this . projectCache = projectCache ; this . prologRule = prologRule ; @Override public Response < List < TestSubmitRuleInfo > > apply ( RevisionResource rsrc , TestSubmitRuleInput input ) throws AuthException , PermissionBackendException , BadRequestException { input = MoreObjects . firstNonNull ( input , new TestSubmitRuleInput ( ) ) ; if ( input . rule == null ) { throw new BadRequestException ( ""rule is required"" ) ; } if ( ! rules . isProjectRulesEnabled ( ) ) { throw new AuthException ( ""project rules are disabled"" ) ; } input . filters = MoreObjects . firstNonNull ( input . filters , filters ) ; SubmitRuleOptions opts = SubmitRuleOptions . builder ( ) . skipFilters ( input . filters == Filters . SKIP ) . rule ( input . rule ) . logErrors ( false ) . build ( ) ; ProjectState projectState = projectCache . get ( rsrc . getProject ( ) ) ; if ( projectState == null ) { throw new BadRequestException ( ""project not found"" ) ; } }
",,,"this . accountInfoFactory = infoFactory ; this . projectCache = projectCache ; this . prologRule = prologRule ; @Override public Response < List < TestSubmitRuleInfo > > apply ( RevisionResource rsrc , TestSubmitRuleInput input ) throws AuthException , PermissionBackendException , BadRequestException { if ( input == null ) { input = new TestSubmitRuleInput ( ) ; } if ( input . rule == null ) { throw new BadRequestException ( ""rule is required"" ) ; } if ( ! rules . isProjectRulesEnabled ( ) ) { throw new AuthException ( ""project rules are disabled"" ) ; } input . filters = MoreObjects . firstNonNull ( input . filters , filters ) ; SubmitRuleOptions opts = SubmitRuleOptions . builder ( ) . skipFilters ( input . filters == Filters . SKIP ) . rule ( input . rule ) . logErrors ( false ) . build ( ) ; ProjectState projectState = projectCache . get ( rsrc . getProject ( ) ) ; if ( projectState == null ) { throw new BadRequestException ( ""project not found"" ) ; } }
",,,"this . accountInfoFactory = infoFactory ; this . projectCache = projectCache ; this . prologRule = prologRule ; } @Override public Response < List < TestSubmitRuleInfo > > apply ( RevisionResource rsrc , TestSubmitRuleInput input ) throws AuthException , PermissionBackendException , BadRequestException { if ( input == null ) { input = new TestSubmitRuleInput ( ) ; } if ( input . rule == null ) { throw new BadRequestException ( ""rule is required"" ) ; } < |startfocus| > if ( input . rule == null ) { throw new BadRequestException ( ""rule is required"" ) ; } < |endfocus| > if ( ! rules . isProjectRulesEnabled ( ) ) { throw new AuthException ( ""project rules are disabled"" ) ; } input . filters = MoreObjects . firstNonNull ( input . filters , filters ) ; SubmitRuleOptions opts = SubmitRuleOptions . builder ( ) . skipFilters ( input . filters == Filters . SKIP ) . rule ( input . rule ) . logErrors ( false ) . build ( ) ; ProjectState projectState = projectCache . get ( rsrc . getProject ( ) ) ; if ( projectState == null ) { throw new BadRequestException ( ""project not found"" ) ; }
",,
2798,"public List < RemoteRefUpdate > filter ( String projectName , List < RemoteRefUpdate > remoteUpdatesList ) { return Collections . emptyList ( ) ;
","return Collections . emptyList ( ) ;
","return Collections.emptyList();
",,,"return remoteUpdatesList;
",,,"public List < RemoteRefUpdate > filter ( String projectName , List < RemoteRefUpdate > remoteUpdatesList ) { remoteUpdatesList . clear ( ) ; return remoteUpdatesList ; }
",,,"public List < RemoteRefUpdate > filter ( String projectName , List < RemoteRefUpdate > remoteUpdatesList ) { return Collections . emptyList ( ) ; }
",,,"public List < RemoteRefUpdate > filter ( String projectName , List < RemoteRefUpdate > remoteUpdatesList ) { < |startfocus| > return Collections . emptyList ( ) ; < |endfocus| >
",,
2811,"@NoHttpd public class NoUnresolvedCommentsRuleIT extends LightweightPluginDaemonTest { private static final String FILENAME = ""my . file"" ; @Before public void enableRuleBeforeTest ( ) throws Exception { enableRule ( true ) ; } @Test public void blocksWithUnresolvedComments ( ) throws Exception { ReviewInput . CommentInput comment = newFileComment ( ) ; comment . unresolved = true ; PushOneCommit . Result r = createChangeWithComment ( comment ) ; Optional < SubmitRecord > submitRecords = evaluate ( r . getChange ( ) ) ; assertThat ( submitRecords ) . isPresent ( ) ; SubmitRecord result = submitRecords . get ( ) ; assertThat ( result . status ) . isEqualTo ( SubmitRecord . Status . NOT_READY ) ; assertThat ( result . labels ) . isNull ( ) ; assertThat ( result . requirements ) . hasSize ( 1 ) ; } @Test public void doesNotBlockWithNoComments ( ) throws Exception { ReviewInput . CommentInput comment = newFileComment ( ) ; comment . unresolved = false ; PushOneCommit . Result r = createChangeWithComment ( comment ) ; Optional < SubmitRecord > submitRecords = evaluate ( r . getChange ( ) ) ; assertThat ( submitRecords . isPresent ( ) ) . isTrue ( ) ; SubmitRecord result = submitRecords . get ( ) ;
","assertThat ( submitRecords ) . isPresent ( ) ;
","Assert.assertTrue(submitRecords.isPresent());
",,,"assertThat(submitRecords.isPresent()).isTrue();
",,,"import com . google . common . truth . Truth8 ; import org . junit . Before ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . mockito . junit . MockitoJUnitRunner ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import java . util . Optional ; import static com . google . common . truth . Truth . assertThat ; @RunWith ( MockitoJUnitRunner . class ) public class NoUnresolvedCommentsRuleIT extends LightweightPluginDaemonTest { private static final Logger log = LoggerFactory . getLogger ( NoUnresolvedCommentsRuleIT . class ) ; private static final String FILENAME = ""my . file"" ; @Before public void enableRuleBeforeTest ( ) throws Exception { enableRule ( true ) ; } @Test public void blocksWithUnresolvedComments ( ) throws Exception { ReviewInput . CommentInput comment = newFileComment ( ) ; comment . unresolved = true ; PushOneCommit . Result r = createChangeWithComment ( comment ) ; Optional < SubmitRecord > submitRecords = evaluate ( r . getChange ( ) ) ; Truth8 . assertThat ( submitRecords ) . isPresent ( ) ; SubmitRecord result = submitRecords . get ( ) ; assertThat ( result . status ) . isEqualTo ( SubmitRecord . Status . NOT_READY ) ; assertThat ( result . labels ) . isNull ( ) ; assertThat ( result . requirements ) . hasSize ( 1 ) ; } @Test public void doesNotBlockWithNoComments ( ) throws Exception { ReviewInput . CommentInput comment = newFileComment ( ) ; comment . unresolved = false ; PushOneCommit . Result r = createChangeWithComment ( comment ) ; Optional < SubmitRecord > submitRecords = evaluate ( r . getChange ( ) ) ; assertThat ( submitRecords ) . isPresent ( ) ; SubmitRecord result = submitRecords . get ( ) ; assertThat ( result . status ) . isEqualTo ( SubmitRecord . Status . OK ) ; assertThat ( result . labels ) . isNull ( ) ; assertThat ( result . requirements ) . isEmpty ( ) ; } }
",,,"@NoHttpd public class NoUnresolvedCommentsRuleIT extends LightweightPluginDaemonTest { private static final String FILENAME = ""my . file"" ; @Before public void enableRuleBeforeTest ( ) throws Exception { enableRule ( true ) ; } @Test public void blocksWithUnresolvedComments ( ) throws Exception { ReviewInput . CommentInput comment = newFileComment ( ) ; comment . unresolved = true ; PushOneCommit . Result r = createChangeWithComment ( comment ) ; Optional < SubmitRecord > submitRecords = evaluate ( r . getChange ( ) ) ; assertThat ( submitRecords ) . isPresent ( ) ; SubmitRecord result = submitRecords . get ( ) ; assertThat ( result . status ) . isEqualTo ( SubmitRecord . Status . NOT_READY ) ; assertThat ( result . labels ) . isNull ( ) ; assertThat ( result . requirements ) . hasSize ( 1 ) ; } @Test public void doesNotBlockWithNoComments ( ) throws Exception { PushOneCommit . Result r = createChange ( ) ; Optional < SubmitRecord > submitRecords = evaluate ( r . getChange ( ) ) ; assertThat ( submitRecords ) . isPresent ( ) ; SubmitRecord result = submitRecords . get ( ) ; assertThat ( result . status ) . isEqualTo ( SubmitRecord . Status . OK ) ; assertThat ( result . labels ) . isNull ( ) ; assertThat ( result . requirements ) . isNull ( ) ; } }
",,,"@NoHttpd public class NoUnresolvedCommentsRuleIT extends LightweightPluginDaemonTest { private static final String FILENAME = ""my . file"" ; @Before public void enableRuleBeforeTest ( ) throws Exception { enableRule ( true ) ; } @Test public void blocksWithUnresolvedComments ( ) throws Exception { ReviewInput . CommentInput comment = newFileComment ( ) ; comment . unresolved = true ; PushOneCommit . Result r = createChangeWithComment ( comment ) ; Optional < SubmitRecord > submitRecords = evaluate ( r . getChange ( ) ) ; < |startfocus| > assertThat ( submitRecords ) . isPresent ( ) ; < |endfocus| > SubmitRecord result = submitRecords . get ( ) ; assertThat ( result . status ) . isEqualTo ( SubmitRecord . Status . NOT_READY ) ; assertThat ( result . labels ) . isNull ( ) ; assertThat ( result . requirements ) . hasSize ( 1 ) ; } @Test public void doesNotBlockWithNoComments ( ) throws Exception { ReviewInput . CommentInput comment = newFileComment ( ) ; comment . unresolved = false ; PushOneCommit . Result r = createChangeWithComment ( comment ) ; Optional < SubmitRecord > submitRecords = evaluate ( r . getChange ( ) ) ; assertThat ( submitRecords ) . isPresent ( ) ; SubmitRecord result = submitRecords . get ( ) ;
",,
2851,"public void delete ( String project , String ref , URIish uri , String remote ) { ReplicateRefUpdate r = new ReplicateRefUpdate ( ) ; r . project = project ; r . ref = ref ; r . uri = uri . toASCIIString ( ) ; r . remote = remote ; String taskJson = GSON . toJson ( r ) + ""\n"" ; String taskKey = sha1 ( taskJson ) . name ( ) ; try { logger . atFiner ( ) . log ( ""DELETE % s : % s = > % s"" , project , ref , uri ) ; Files . delete ( refUpdates ( ) . resolve ( eventKey ) ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( ""Error while deleting event % s"" , eventKey ) ; }
","String taskJson = GSON . toJson ( r ) + ""\n"" ; String taskKey = sha1 ( taskJson ) . name ( ) ;
","String taskJson = gson.toJson(r) + ""\n""; String eventKey = sha1(taskJson).name();
",,,"String taskJson = GSON.toJson(r) + ""\n""; String eventKey = sha1(taskJson).name();
",,,"public void delete ( String project , String ref , URIish uri , String remote ) { ReplicateRefUpdate r = new ReplicateRefUpdate ( ) ; r . project = project ; r . ref = ref ; r . uri = uri . toASCIIString ( ) ; r . remote = remote ; String eventJson = new Gson ( ) . toJson ( r ) + ""\n"" ; String eventKey = DigestUtils . sha1Hex ( eventJson ) ; try { logger . atFiner ( ) . log ( ""DELETE % s : % s = > % s"" , project , ref , uri ) ; Files . delete ( refUpdates ( ) . resolve ( eventKey ) ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( ""Error while deleting event % s"" , eventKey ) ; } }
",,,"public void delete ( String project , String ref , URIish uri , String remote ) { ReplicateRefUpdate r = new ReplicateRefUpdate ( ) ; r . project = project ; r . ref = ref ; r . uri = uri . toASCIIString ( ) ; r . remote = remote ; String eventJson = GSON . toJson ( r ) + ""\n"" ; String eventKey = sha1 ( eventJson ) . name ( ) ; try { logger . atFiner ( ) . log ( ""DELETE % s : % s = > % s"" , project , ref , uri ) ; Files . delete ( refUpdates ( ) . resolve ( eventKey ) ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( ""Error while deleting event % s"" , eventKey ) ; } }
",,,"public void delete ( String project , String ref , URIish uri , String remote ) { ReplicateRefUpdate r = new ReplicateRefUpdate ( ) ; r . project = project ; r . ref = ref ; r . uri = uri . toASCIIString ( ) ; r . remote = remote ; < |startfocus| > String taskJson = GSON . toJson ( r ) + ""\n"" ; String taskKey = sha1 ( taskJson ) . name ( ) ; < |endfocus| > try { logger . atFiner ( ) . log ( ""DELETE % s : % s = > % s"" , project , ref , uri ) ; Files . delete ( refUpdates ( ) . resolve ( taskKey ) ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( ""Error while deleting event % s"" , taskKey ) ; }
",,
2860,"e . printStackTrace ( ) ; return null ; } } private void setReplicationDestination ( String remoteName , String replicaSuffix , int replicationDelay ) throws IOException { setReplicationDestination ( remoteName , Arrays . asList ( replicaSuffix ) , replicationDelay ) ; } private void setReplicationDestination ( String remoteName , List < String > replicaSuffixes , int replicationDelay ) throws IOException { List < String > replicaUrls = replicaSuffixes . stream ( ) . map ( suffix - > gitPath . resolve ( ""$ { name } "" + suffix + "" . git"" ) . toString ( ) ) . collect ( toList ( ) ) ; config . setStringList ( ""remote"" , remoteName , ""url"" , replicaUrls ) ; config . setInt ( ""remote"" , remoteName , ""replicationDelay"" , replicationDelay ) ; config . save ( ) ; reloadConfig ( ) ; } private void waitUntil ( Supplier < Boolean > waitCondition ) throws InterruptedException { Stopwatch stopwatch = Stopwatch . createStarted ( ) ; while ( ! waitCondition . get ( ) && stopwatch . elapsed ( ) . compareTo ( TEST_TIMEMOUT ) < 0 ) { TimeUnit . SECONDS . sleep ( 1 ) ; } } private void reloadConfig ( ) { plugin . getSysInjector ( ) . getInstance ( AutoReloadConfigDecorator . class ) . forceReload ( ) ; } }
",". collect ( toList ( ) ) ;
",".collect(toList());
",,,".collect(toList());
",,,"import static java . util . stream . Collectors . toList ; . . . e . printStackTrace ( ) ; return null ; } private void setReplicationDestination ( String remoteName , String replicaSuffix , int replicationDelay ) throws IOException { setReplicationDestination ( remoteName , Arrays . asList ( replicaSuffix ) , replicationDelay ) ; } private void setReplicationDestination ( String remoteName , List < String > replicaSuffixes , int replicationDelay ) throws IOException { List < String > replicaUrls = replicaSuffixes . stream ( ) . map ( suffix - > gitPath . resolve ( ""$ { name } "" + suffix + "" . git"" ) . toString ( ) ) . collect ( toList ( ) ) ; config . setStringList ( ""remote"" , remoteName , ""url"" , replicaUrls ) ; config . setInt ( ""remote"" , remoteName , ""replicationDelay"" , replicationDelay ) ; config . save ( ) ; reloadConfig ( ) ; } private void waitUntil ( Supplier < Boolean > waitCondition ) throws InterruptedException { Stopwatch stopwatch = Stopwatch . createStarted ( ) ; while ( ! waitCondition . get ( ) && stopwatch . elapsed ( ) . compareTo ( TEST_TIMEMOUT ) < 0 ) { TimeUnit . SECONDS . sleep ( 1 ) ; } } private void reloadConfig ( ) { plugin . getSysInjector ( ) . getInstance ( AutoReloadConfigDecorator . class ) . forceReload ( ) ; }
",,,"import static java . util . stream . Collectors . toList ; e . printStackTrace ( ) ; return null ; } private void setReplicationDestination ( String remoteName , String replicaSuffix , int replicationDelay ) throws IOException { setReplicationDestination ( remoteName , Arrays . asList ( replicaSuffix ) , replicationDelay ) ; } private void setReplicationDestination ( String remoteName , List < String > replicaSuffixes , int replicationDelay ) throws IOException { List < String > replicaUrls = replicaSuffixes . stream ( ) . map ( suffix - > gitPath . resolve ( ""$ { name } "" + suffix + "" . git"" ) . toString ( ) ) . collect ( toList ( ) ) ; config . setStringList ( ""remote"" , remoteName , ""url"" , replicaUrls ) ; config . setInt ( ""remote"" , remoteName , ""replicationDelay"" , replicationDelay ) ; config . save ( ) ; reloadConfig ( ) ; } private void waitUntil ( Supplier < Boolean > waitCondition ) throws InterruptedException { Stopwatch stopwatch = Stopwatch . createStarted ( ) ; while ( ! waitCondition . get ( ) && stopwatch . elapsed ( ) . compareTo ( TEST_TIMEMOUT ) < 0 ) { TimeUnit . SECONDS . sleep ( 1 ) ; } } private void reloadConfig ( ) { plugin . getSysInjector ( ) . getInstance ( AutoReloadConfigDecorator . class ) . forceReload ( ) ; }
",,,"e . printStackTrace ( ) ; return null ; } } private void setReplicationDestination ( String remoteName , String replicaSuffix , int replicationDelay ) throws IOException { setReplicationDestination ( remoteName , Arrays . asList ( replicaSuffix ) , replicationDelay ) ; } private void setReplicationDestination ( String remoteName , List < String > replicaSuffixes , int replicationDelay ) throws IOException { List < String > replicaUrls = replicaSuffixes . stream ( ) . map ( suffix - > gitPath . resolve ( ""$ { name } "" + suffix + "" . git"" ) . toString ( ) ) < |startfocus| > . collect ( toList ( ) ) ; < |endfocus| > config . setStringList ( ""remote"" , remoteName , ""url"" , replicaUrls ) ; config . setInt ( ""remote"" , remoteName , ""replicationDelay"" , replicationDelay ) ; config . save ( ) ; reloadConfig ( ) ; } private void waitUntil ( Supplier < Boolean > waitCondition ) throws InterruptedException { Stopwatch stopwatch = Stopwatch . createStarted ( ) ; while ( ! waitCondition . get ( ) && stopwatch . elapsed ( ) . compareTo ( TEST_TIMEMOUT ) < 0 ) { TimeUnit . SECONDS . sleep ( 1 ) ; } } private void reloadConfig ( ) { plugin . getSysInjector ( ) . getInstance ( AutoReloadConfigDecorator . class ) . forceReload ( ) ; } }
",,
2861,"private static class RefReplicationStatus { private final String project ; private final String ref ; private int nodesToReplicateCount ; private int replicatedNodesCount ; RefReplicationStatus ( String project , String ref ) { this . project = project ; this . ref = ref ; } public boolean allDone ( ) { return replicatedNodesCount == nodesToReplicateCount ; } } private final Table < String , String , RefReplicationStatus > statusByProjectRef ; private int totalPushTasksCount ; private int finishedPushTasksCount ; ReplicationState ( PushResultProcessing processing ) { pushResultProcessing = processing ; statusByProjectRef = HashBasedTable . create ( ) ; } public void increasePushTaskCount ( String project , String ref ) { countingLock . lock ( ) ; try { getRefStatus ( project , ref ) . nodesToReplicateCount ++ ; totalPushTasksCount ++ ; } finally { countingLock . unlock ( ) ; } } public boolean hasPushTask ( ) { return totalPushTasksCount != 0 ; } public void notifyRefReplicated ( String project , String ref , URIish uri , RefPushResult status ,
","ReplicationState ( PushResultProcessing processing ) {
","private ReplicationState(@Assisted PushResultProcessing processing) {
",,,"ReplicationState(@Assisted PushResultProcessing processing) {
",,,"private static class RefReplicationStatus { private final String project ; private final String ref ; private int nodesToReplicateCount ; private int replicatedNodesCount ; RefReplicationStatus ( String project , String ref ) { this . project = project ; this . ref = ref ; } public boolean allDone ( ) { return replicatedNodesCount == nodesToReplicateCount ; } } private final Table < String , String , RefReplicationStatus > statusByProjectRef ; private int totalPushTasksCount ; private int finishedPushTasksCount ; @AssistedInject ReplicationState ( @Assisted PushResultProcessing processing ) { pushResultProcessing = processing ; statusByProjectRef = HashBasedTable . create ( ) ; } public void increasePushTaskCount ( String project , String ref ) { countingLock . lock ( ) ; try { getRefStatus ( project , ref ) . nodesToReplicateCount ++ ; totalPushTasksCount ++ ; } finally { countingLock . unlock ( ) ; } } public boolean hasPushTask ( ) { return totalPushTasksCount != 0 ; } public void notifyRefReplicated ( String project , String ref , URIish uri , RefPushResult status , @Nullable String message ) { countingLock . lock ( ) ; try { RefReplicationStatus refStatus = getRefStatus ( project , ref ) ; refStatus . replicatedNodesCount ++ ; if ( status == RefPushResult . OK ) { pushResultProcessing . onSuccess ( project , ref , uri ) ; } else { pushResultProcessing . onFailure ( project , ref , uri , message ) ; } if ( refStatus . allDone ( ) ) { statusByProjectRef . remove ( project , ref ) ; finishedPushTasksCount ++ ; } } finally { countingLock . unlock ( ) ; } } private RefReplicationStatus getRefStatus ( String project , String ref ) { RefReplicationStatus refStatus = statusByProjectRef . get ( project , ref ) ; if ( refStatus == null ) { refStatus = new RefReplicationStatus ( project , ref ) ; statusByProjectRef . put ( project , ref , refStatus ) ; } return refStatus ; }
",,,"private static class RefReplicationStatus { private final String project ; private final String ref ; private int nodesToReplicateCount ; private int replicatedNodesCount ; RefReplicationStatus ( String project , String ref ) { this . project = project ; this . ref = ref ; } public boolean allDone ( ) { return replicatedNodesCount == nodesToReplicateCount ; } } private final Table < String , String , RefReplicationStatus > statusByProjectRef ; private int totalPushTasksCount ; private int finishedPushTasksCount ; @AssistedInject ReplicationState ( @Assisted PushResultProcessing processing ) { pushResultProcessing = processing ; statusByProjectRef = HashBasedTable . create ( ) ; } public void increasePushTaskCount ( String project , String ref ) { countingLock . lock ( ) ; try { getRefStatus ( project , ref ) . nodesToReplicateCount ++ ; totalPushTasksCount ++ ; } finally { countingLock . unlock ( ) ; } } public boolean hasPushTask ( ) { return totalPushTasksCount != 0 ; } public void notifyRefReplicated ( String project , String ref , URIish uri , RefPushResult status , @Nullable Throwable error ) { countingLock . lock ( ) ; try { RefReplicationStatus refStatus = getRefStatus ( project , ref ) ; refStatus . replicatedNodesCount ++ ; finishedPushTasksCount ++ ; if ( refStatus . allDone ( ) ) { statusByProjectRef . remove ( project , ref ) ; } } finally { countingLock . unlock ( ) ; } pushResultProcessing . processPushResult ( project , ref , uri , status , error ) ; }
",,,"private static class RefReplicationStatus { private final String project ; private final String ref ; private int nodesToReplicateCount ; private int replicatedNodesCount ; RefReplicationStatus ( String project , String ref ) { this . project = project ; this . ref = ref ; } public boolean allDone ( ) { return replicatedNodesCount == nodesToReplicateCount ; } } private final Table < String , String , RefReplicationStatus > statusByProjectRef ; private int totalPushTasksCount ; private int finishedPushTasksCount ; < |startfocus| > @AssistedInject ReplicationState ( @Assisted PushResultProcessing processing ) { < |endfocus| > pushResultProcessing = processing ; statusByProjectRef = HashBasedTable . create ( ) ; } public void increasePushTaskCount ( String project , String ref ) { countingLock . lock ( ) ; try { getRefStatus ( project , ref ) . nodesToReplicateCount ++ ; totalPushTasksCount ++ ; } finally { countingLock . unlock ( ) ; } } public boolean hasPushTask ( ) { return totalPushTasksCount != 0 ; } public void notifyRefReplicated ( String project , String ref , URIish uri , RefPushResult status , String message ) { countingLock . lock ( ) ; try { RefReplicationStatus refStatus = getRefStatus ( project , ref ) ; refStatus . replicatedNodesCount ++ ; finishedPushTasksCount ++ ; pushResultProcessing . process ( project , ref , uri , status , message ) ; } finally { countingLock . unlock ( ) ; } } public boolean allDone ( ) { return finishedPushTasksCount == totalPushTasksCount ; } private RefReplicationStatus getRefStatus ( String project , String ref ) { RefReplicationStatus refStatus = statusByProjectRef . get ( project , ref ) ; if ( refStatus == null ) { refStatus = new RefReplicationStatus ( project , ref ) ; statusByProjectRef . put ( project , ref , refStatus ) ; } return refStatus ; } }
",,
2882,"+ JUSTWORKS_SERVER_UNOWNED_CBOR_02 + "" 1"" ; public static final String START_PRE_CONFIG_SERVER_01 = "" ./ iotivity_pm_server "" + PRECONFIG_SERVER_UNOWNED_CBOR_01 + "" 3"" ; public static final String START_RE_SERVER = "" ./ iotivity_re_server"" ; public static final String PROVISION_DB_FILE = "" ./ Pdm . db"" ; public static final String DEVICE_PROP_CBOR_FILE = "" ./ device_properties . dat"" ; private TestBroadCast mTestBroadCast ; protected RIHelperCommon ( IoTivityTc iotivityTcObj ) { s_helperContext = iotivityTcObj . getInstrumentation ( ) . getTargetContext ( ) ; s_filePath = s_helperContext . getFilesDir ( ) . getPath ( ) ; s_sqLPath = s_helperContext . getFilesDir ( ) . getAbsolutePath ( ) . replace ( FILES , DATABASES ) + File . separator ; mTestBroadCast = new TestBroadCast ( s_helperContext ) ; } public boolean configClientServerPlatform ( ) { PlatformConfig cfg = new PlatformConfig ( s_helperContext , ServiceType . IN_PROC , ModeType . CLIENT_SERVER , ""0 . 0 . 0 . 0"" , 0 , QualityOfService . HIGH ) ; OcPlatform . Configure ( cfg ) ;
","private TestBroadCast mTestBroadCast ;
","private TestBroadCast mTestBroadCast;
",,,"private TestBroadCast mTestBroadCast;
",,,"private TestBroadCast mTestBroadCast ; private RIHelperCommon ( IoTivityTc iotivityTcObj ) { s_helperContext = iotivityTcObj . getInstrumentation ( ) . getTargetContext ( ) ; s_filePath = s_helperContext . getFilesDir ( ) . getPath ( ) ; s_sqLPath = s_helperContext . getFilesDir ( ) . getAbsolutePath ( ) . replace ( FILES , DATABASES ) + File . separator ; mTestBroadCast = new TestBroadCast ( s_helperContext ) ; } public boolean configClientServerPlatform ( ) { PlatformConfig cfg = new PlatformConfig ( s_helperContext , ServiceType . IN_PROC , ModeType . CLIENT_SERVER , ""0 . 0 . 0 . 0"" , 0 , QualityOfService . HIGH ) ; OcPlatform . Configure ( cfg ) ; }
",,,"private static final String START_PRE_CONFIG_SERVER_01 = "" ./ iotivity_pm_server "" + PRECONFIG_SERVER_UNOWNED_CBOR_01 + "" 3"" ; private static final String START_RE_SERVER = "" ./ iotivity_re_server"" ; private static final String PROVISION_DB_FILE = "" ./ Pdm . db"" ; private static final String DEVICE_PROP_CBOR_FILE = "" ./ device_properties . dat"" ; private TestBroadCast mTestBroadCast ; protected RIHelperCommon ( IoTivityTc iotivityTcObj ) { s_helperContext = iotivityTcObj . getInstrumentation ( ) . getTargetContext ( ) ; s_filePath = s_helperContext . getFilesDir ( ) . getPath ( ) ; s_sqLPath = s_helperContext . getFilesDir ( ) . getAbsolutePath ( ) . replace ( FILES , DATABASES ) + File . separator ; mTestBroadCast = new TestBroadCast ( s_helperContext ) ; } public boolean configClientServerPlatform ( ) { PlatformConfig cfg = new PlatformConfig ( s_helperContext , ServiceType . IN_PROC , ModeType . CLIENT_SERVER , ""0 . 0 . 0 . 0"" , 0 , QualityOfService . HIGH ) ; OcPlatform . Configure ( cfg ) ; }
",,,"+ JUSTWORKS_SERVER_UNOWNED_CBOR_02 + "" 1"" ; public static final String START_PRE_CONFIG_SERVER_01 = "" ./ iotivity_pm_server "" + PRECONFIG_SERVER_UNOWNED_CBOR_01 + "" 3"" ; public static final String START_RE_SERVER = "" ./ iotivity_re_server"" ; public static final String PROVISION_DB_FILE = "" ./ Pdm . db"" ; public static final String DEVICE_PROP_CBOR_FILE = "" ./ device_properties . dat"" ; < |startfocus| > TestBroadCast mTestBroadCast ; < |endfocus| > protected RIHelperCommon ( IoTivityTc iotivityTcObj ) { s_helperContext = iotivityTcObj . getInstrumentation ( ) . getTargetContext ( ) ; s_filePath = s_helperContext . getFilesDir ( ) . getPath ( ) ; s_sqLPath = s_helperContext . getFilesDir ( ) . getAbsolutePath ( ) . replace ( FILES , DATABASES ) + File . separator ; mTestBroadCast = new TestBroadCast ( s_helperContext ) ; } public boolean configClientServerPlatform ( ) { PlatformConfig cfg = new PlatformConfig ( s_helperContext , ServiceType . IN_PROC , ModeType . CLIENT_SERVER , ""0 . 0 . 0 . 0"" , 0 , QualityOfService . HIGH ) ; OcPlatform . Configure ( cfg ) ; }
",,
2895,"* // ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * // * // Copyright 2018 Intel Corporation All Rights Reserved . * // * // -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= * // * // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; * // you may not use this file except in compliance with the License . * // You may obtain a copy of the License at * // * // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * // * // Unless required by applicable law or agreed to in writing , software * // distributed under the License is distributed on an ""AS IS"" BASIS , * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * // See the License for the specific language governing permissions and * // limitations under the License . * // * // -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= */ package org . iotivity . base . examples ; import org . iotivity . base . OcException ;
","* // Copyright 2018 Intel Corporation All Rights Reserved .
","* // Copyright 2018 Intel Corporation All Rights Reserved.
",,,"* // Copyright 2018 Intel Corporation All Rights Reserved.
",,,"// ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * // Copyright 2018 Intel Corporation All Rights Reserved . // // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an ""AS IS"" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . // ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * package org . iotivity . base . examples ; import org . iotivity . base . OcException ;
",,,"* // ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * // Copyright 2018 Intel Corporation All Rights Reserved . * // * // -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= * // * // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; * // you may not use this file except in compliance with the License . * // You may obtain a copy of the License at * // * // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * // * // Unless required by applicable law or agreed to in writing , software * // distributed under the License is distributed on an ""AS IS"" BASIS , * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * // See the License for the specific language governing permissions and * // limitations under the License . * // * // -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= */ package org . iotivity . base . examples ; import org . iotivity . base . OcException ;
",,,"* // ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * // < |startfocus| > * // Copyright 2018 Intel Corporation All Rights Reserved . < |endfocus| > * // * // -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= * // * // Licensed under the Apache License , Version 2 . 0 ( the ""License"" ) ; * // you may not use this file except in compliance with the License . * // You may obtain a copy of the License at * // * // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * // * // Unless required by applicable law or agreed to in writing , software * // distributed under the License is distributed on an ""AS IS"" BASIS , * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * // See the License for the specific language governing permissions and * // limitations under the License . * // * // -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= */ package org . iotivity . base . examples ; import org . iotivity . base . OcException ;
",,
2923,"OCRepresentation nativeRep = getValue ( ) . getObject ( ) ; if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( ""Failed to get object"" ) ; } public OcRepresentation getObjectArray ( ) throws OcCborException { OCRepresentation nativeRep = getValue ( ) . getObjectArray ( ) ; if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( ""Failed to get object array"" ) ; } public OCValue getValue ( ) throws OcCborException { OCValue returnValue = nativeRepresentation . getValue ( ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( ""Failed to get value"" ) ; } public Boolean getBoolean ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Boolean returnValue = OCRep . getBoolean ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( ""Failed to get boolean for key "" + key ) ;
","< |del| > OCRep . clearCborErrno ( ) ;
","OCRep.clearCborErrno(); OCRep.clearObjectArray();
",,,"<|del|>
",,,"public OcRepresentation getObject ( ) throws OcCborException { OCRepresentation nativeRep = getValue ( ) . getObject ( ) ; if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( ""Failed to get object"" ) ; } public OcRepresentation getObjectArray ( ) throws OcCborException { OCRepresentation nativeRep = getValue ( ) . getObjectArray ( ) ; if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( ""Failed to get object array"" ) ; } public OCValue getValue ( ) throws OcCborException { OCRep . clearCborErrno ( ) ; OCValue returnValue = nativeRepresentation . getValue ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( ""Failed to get value"" ) ; } public Boolean getBoolean ( String key ) throws OcCborException { Boolean returnValue = OCRep . getBoolean ( nativeRepresentation , key ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( ""Failed to get boolean for key "" + key ) ; }
",,,"OCRepresentation nativeRep = getValue ( ) . getObject ( ) ; if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( ""Failed to get object"" ) ; public OcRepresentation getObjectArray ( ) throws OcCborException { OCRepresentation nativeRep = getValue ( ) . getObjectArray ( ) ; if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( ""Failed to get object array"" ) ; } public OCValue getValue ( ) throws OcCborException { OCValue returnValue = nativeRepresentation . getValue ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( ""Failed to get value"" ) ; } public Boolean getBoolean ( String key ) throws OcCborException { Boolean returnValue = OCRep . getBoolean ( nativeRepresentation , key ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( ""Failed to get boolean for key "" + key ) ; }
",,,"OCRepresentation nativeRep = getValue ( ) . getObject ( ) ; if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( ""Failed to get object"" ) ; } public OcRepresentation getObjectArray ( ) throws OcCborException { OCRepresentation nativeRep = getValue ( ) . getObjectArray ( ) ; if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( ""Failed to get object array"" ) ; } public OCValue getValue ( ) throws OcCborException { < |startfocus| > OCValue returnValue = nativeRepresentation . getValue ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( ""Failed to get value"" ) ; } public Boolean getBoolean ( String key ) throws OcCborException { Boolean returnValue = OCRep . getBoolean ( nativeRepresentation , key ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( ""Failed to get boolean for key "" + key ) ;
",,
2926,"return returnValue ; } throw new OcCborException ( ""Failed to get boolean for key "" + key ) ; } public Long getLong ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Long returnValue = OCRep . getLong ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( ""Failed to get long for key "" + key ) ; } public double getDouble ( String key ) throws OcCborException { Double returnValue = OCRep . getDouble ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( ""Failed to get double for key "" + key ) ; } public String getString ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; String returnValue = OCRep . getString ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; }
","public double getDouble ( String key ) throws OcCborException {
","public double getInt(String key) throws OcCborException { OCRep.clearCborErrno();
",,,"public double getDouble(String key) throws OcCborException {
",,,"public Long getLong ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Long returnValue = OCRep . getLong ( nativeRepresentation , key ) ; if ( returnValue != null && OCRep . getCborErrno ( ) == 0 ) { return returnValue ; } throw new OcCborException ( ""Failed to get long for key "" + key ) ; } public Double getDouble ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; double returnValue = OCRep . getDouble ( nativeRepresentation , key ) ; if ( ! Double . isNaN ( returnValue ) && OCRep . getCborErrno ( ) == 0 ) { return returnValue ; } throw new OcCborException ( ""Failed to get double for key "" + key ) ; } public String getString ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; String returnValue = OCRep . getString ( nativeRepresentation , key ) ; if ( returnValue != null && OCRep . getCborErrno ( ) == 0 ) { return returnValue ; } throw new OcCborException ( ""Failed to get string for key "" + key ) ; }
",,,"return returnValue ; } throw new OcCborException ( ""Failed to get boolean for key "" + key ) ; } public Long getLong ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Long returnValue = OCRep . getLong ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( ""Failed to get long for key "" + key ) ; } public Double getDouble ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Double returnValue = OCRep . getDouble ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( ""Failed to get double for key "" + key ) ; } public String getString ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; String returnValue = OCRep . getString ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; }
",,,"return returnValue ; } throw new OcCborException ( ""Failed to get boolean for key "" + key ) ; } public Long getLong ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Long returnValue = OCRep . getLong ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( ""Failed to get long for key "" + key ) ; } public double getDouble ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; double returnValue = OCRep . getDouble ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( ""Failed to get double for key "" + key ) ; } public String getString ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; String returnValue = OCRep . getString ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; }
",,

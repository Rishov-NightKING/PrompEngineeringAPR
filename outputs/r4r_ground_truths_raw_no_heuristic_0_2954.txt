import java.util.ArrayList; /** * This class provides helper functions for Wifi connectivity related modules to * access WifiNative. It starts with firmware roaming. TODO(b/34819513): Move operations * such as connection to network and legacy framework roaming here. */ public class WifiConnectivityHelper { private static final String TAG = "WifiConnectivityHelper"; private final WifiNative mWifiNative; private boolean mFirmwareRoamingSupported = false; private int mMaxNumBlacklistBssid = INVALID_LIST_SIZE; private int mMaxNumWhitelistSsid = INVALID_LIST_SIZE; WifiConnectivityHelper(WifiNative wifiNative) { mWifiNative = wifiNative; } /** * Query firmware if it supports * {@link android.net.wifi.WifiManager#WIFI_FEATURE_CONTROL_ROAMING}. If yes, get the firmware * roaming capabilities. */ public void getFirmwareRoamingInfo() { int fwFeatureSet = mWifiNative.getSupportedFeatureSet(); Log.d(TAG, "Firmware supported feature set: " + Integer.toHexString(fwFeatureSet)); mFirmwareRoamingSupported = (fwFeatureSet & WIFI_FEATURE_CONTROL_ROAMING) > 0;
mMaxNumWhitelistSsid = -1; if (mFirmwareRoamingSupported) { WifiNative.RoamingCapabilities roamingCap = new WifiNative.RoamingCapabilities(); if (mWifiNative.getRoamingCapabilities(roamingCap)) { mMaxNumBlacklistBssid = roamingCap.maxBlacklistSize; mMaxNumWhitelistSsid = roamingCap.maxWhitelistSize; Log.d(TAG, "Firmware roaming capabilities: max num blacklist bssid=" + mMaxNumBlacklistBssid + " max num whitelist ssid=" + mMaxNumWhitelistSsid); } else { Log.e(TAG, "Failed to get firmware roaming capabilities"); } if (fallbackToFrameworkRoaming) { Log.e(TAG, "Fall back to framework roaming"); mFirmwareRoamingSupported = false; return false; } }
mMaxNumWhitelistSsid = roamingCap.maxWhitelistSize; Log.d(TAG, "Firmware roaming capabilities: max num blacklist bssid=" + mMaxNumBlacklistBssid + " max num whitelist ssid=" + mMaxNumWhitelistSsid); } else { Log.e(TAG, "Failed to get firmware roaming capabilities"); } } } /** * Return if firmware roaming is supported. */ public boolean isFirmwareRoamingSupported() { return mFirmwareRoamingSupported; } /** * Get the maximum size of BSSID blacklist firmware supports. * * @return INVALID_LIST_SIZE if firmware roaming is not supported, or * maximum size of the BSSID blacklist firmware supports. */ public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { Log.e(TAG, "Firmware roaming is not supported"); return -1; } } /** * Return the maximum size of SSID whitelist. */ public int getMaxNumWhitelistSsid() { if (mFirmwareRoamingSupported) { return mMaxNumWhitelistSsid; } else { Log.e(TAG, "Firmware roaming is not supported"); return -1; } } /**
public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { Log.e(TAG, "getMaxNumBlacklistBssid: Firmware roaming is not supported"); return INVALID_LIST_SIZE; }
public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { Log.e(TAG, "getMaxNumBlacklistBssid: Firmware roaming is not supported"); return INVALID_LIST_SIZE; }
public int getMaxNumWhitelistSsid() { if (mFirmwareRoamingSupported) { return mMaxNumWhitelistSsid; } else { Log.e(TAG, "getMaxNumWhitelistSsid: Firmware roaming is not supported"); return INVALID_LIST_SIZE; }
/** Sets up test. */ @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); setupWifiNative(); mWifiConnectivityHelper = new WifiConnectivityHelper(mWifiNative); } /** Cleans up test. */ @After public void cleanup() { validateMockitoUsage(); } private WifiConnectivityHelper mWifiConnectivityHelper; @Mock private WifiNative mWifiNative; @Captor ArgumentCaptor<WifiNative.RoamingConfig> mRoamingConfigCaptor; private int mFeatureSetValue; private static final String TAG = "WifiConnectivityHelperTest"; private static final int MAX_BSSID_BLACKLIST_SIZE = 16; private static final int MAX_SSID_WHITELIST_SIZE = 8; private void setupWifiNative() { // Return firmware roaming feature as supported by default. when(mWifiNative.getSupportedFeatureSet()).thenReturn(WIFI_FEATURE_CONTROL_ROAMING); doAnswer(new AnswerWithArguments() { public boolean answer(WifiNative.RoamingCapabilities roamCap) throws Exception { roamCap.maxBlacklistSize = MAX_BSSID_BLACKLIST_SIZE; roamCap.maxWhitelistSize = MAX_SSID_WHITELIST_SIZE; return true;
public void verifyFirmwareRoamingCapabilityWithFailureNativeCall() { doAnswer(new AnswerWithArguments() { public boolean answer(WifiNative.RoamingCapabilities roamCap) throws Exception { roamCap.maxBlacklistSize = -1; roamCap.maxWhitelistSize = -1; return false; }}).when(mWifiNative).getRoamingCapabilities(anyObject()); assertFalse(mWifiConnectivityHelper.getFirmwareRoamingInfo()); assertFalse(mWifiConnectivityHelper.isFirmwareRoamingSupported()); assertEquals(WifiConnectivityHelper.INVALID_LIST_SIZE, mWifiConnectivityHelper.getMaxNumBlacklistBssid()); assertEquals(WifiConnectivityHelper.INVALID_LIST_SIZE, mWifiConnectivityHelper.getMaxNumWhitelistSsid());
public void verifySetFirmwareRoamingConfigurationWithGoodInput() { assertTrue(mWifiConnectivityHelper.getFirmwareRoamingInfo()); ArrayList<String> blacklist = buildBssidBlacklist(MAX_BSSID_BLACKLIST_SIZE); ArrayList<String> whitelist = buildSsidWhitelist(MAX_SSID_WHITELIST_SIZE); assertTrue(mWifiConnectivityHelper.setFirmwareRoamingConfiguration(blacklist, whitelist));
* [or other varieties of that API]. * * * @hide */ public String createNetworkSpecifierPassphrase(@Nullable PeerHandle peerHandle, @NonNull String passphrase) { if (passphrase == null || passphrase.length() == 0) { throw new IllegalArgumentException("Passphrase must not be null or empty"); } if (mTerminated) { Log.w(TAG, "createNetworkSpecifierPassphrase: called on terminated session"); return null; } int role = this instanceof SubscribeDiscoverySession ? WifiAwareManager.WIFI_AWARE_DATA_PATH_ROLE_INITIATOR : WifiAwareManager.WIFI_AWARE_DATA_PATH_ROLE_RESPONDER; return mgr.createNetworkSpecifier(mClientId, role, mSessionId, peerHandle, null, passphrase); } } /** * Create a {@link android.net.NetworkRequest.Builder#setNetworkSpecifier(String)} for an
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ import java.lang.reflect.Method; public class Main { // Workaround for b/18051191. class InnerClass {} public static void main(String[] args) throws Exception { Class<?> c = Class.forName("IrreducibleLoop"); Method m = c.getMethod("simpleLoop", int.class); Object[] arguments = { 42 }; System.out.println(m.invoke(null, arguments)); } }
boolean waitForCallback(int callback) { synchronized (mLocalLock) { boolean found = mCallbackQueue.remove(callback); if (found) { return true; } mCurrentWaitForCallback = callback; mBlocker = new CountDownLatch(1); } try { return mBlocker.await(WAIT_FOR_AWARE_CHANGE_SECS, TimeUnit.SECONDS); } catch (InterruptedException e) { return false; }
boolean hasCallbackAlreadyHappened(int callback) { synchronized (mLocalLock) { return mCallbackQueue.contains(callback); } return false;
public void testSubscribeDiscoverySuccess() { if (!TestUtils.shouldTestWifiAware(getContext())) { return; } final String serviceName = "ValidName"; WifiAwareSession session = attachAndGetSession(); SubscribeConfig subscribeConfig = new SubscribeConfig.Builder().setServiceName( serviceName).build(); DiscoverySessionCallbackTest discoveryCb = new DiscoverySessionCallbackTest(); // 1. subscribe session.subscribe(subscribeConfig, discoveryCb, null); assertTrue("Subscribe started", discoveryCb.waitForCallback(DiscoverySessionCallbackTest.ON_SUBSCRIBE_STARTED)); SubscribeDiscoverySession discoverySession = discoveryCb.getSubscribeDiscoverySession(); assertNotNull("Subscribe session", discoverySession); // 2. update-subscribe subscribeConfig = new SubscribeConfig.Builder().setServiceName( serviceName).setServiceSpecificInfo("extras".getBytes()).build(); discoverySession.updateSubscribe(subscribeConfig); assertTrue("Subscribe update", discoveryCb.waitForCallback( DiscoverySessionCallbackTest.ON_SESSION_CONFIG_UPDATED)); // 3. destroy assertFalse("Subscribe not terminated", discoveryCb.hasCallbackAlreadyHappened( DiscoverySessionCallbackTest.ON_SESSION_TERMINATED)); discoverySession.destroy();
assertTrue("Incorrect longitude: " + longitude, Math.abs(longitude - LONGITUDE) <= TOLERANCE); retriever.release(); return true; } private void checkOutputExist() { assertTrue(mOutFile.exists()); assertTrue(mOutFile.length() > 0); assertTrue(mOutFile.delete()); } public void testRecorderVideo() throws Exception { if (!hasCamera()) { return; } mCamera = Camera.open(0); setSupportedResolution(mCamera); mCamera.unlock(); mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.CAMERA); mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.DEFAULT); mMediaRecorder.setOutputFile(OUTPUT_PATH2); mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.DEFAULT); mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setVideoSize(mVideoWidth, mVideoHeight); FileOutputStream fos = new FileOutputStream(OUTPUT_PATH2); FileDescriptor fd = fos.getFD(); mMediaRecorder.setOutputFile(fd); long maxFileSize = MAX_FILE_SIZE * 10; recordMedia(maxFileSize, mOutFile2);
assertNotNull(durationStr); return Integer.parseInt(durationStr); } public void testSetMaxFileSize() throws Exception { testSetMaxFileSize(512 * 1024, 50 * 1024); } private void testSetMaxFileSize( long fileSize, long tolerance) throws Exception { if (!hasMicrophone() || !hasCamera() || !hasAmrNb() || !hasH264()) { MediaUtils.skipTest("no microphone, camera, or codecs"); return; } mCamera = Camera.open(0); setSupportedResolution(mCamera); mCamera.unlock(); mMediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC); mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.CAMERA); mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP); mMediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AMR_NB); mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.H264); mMediaRecorder.setVideoSize(mVideoWidth, mVideoHeight); mMediaRecorder.setVideoEncodingBitRate(256000); mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setMaxFileSize(fileSize); mMediaRecorder.prepare(); mMediaRecorder.start();
// Refuse to send SMS if we can't get the calling package name. Rlog.e(TAG, "Can't get calling app package name: refusing to send SMS"); tracker.onFailed(mContext, RESULT_ERROR_GENERIC_FAILURE, 0/*errorCode*/); return; } // Get package info via packagemanager PackageInfo appInfo; try { // XXX this is lossy- apps can share a UID appInfo = pm.getPackageInfoAsUser(packageNames[0], PackageManager.GET_SIGNATURES, Binder.getCallingUid()); } catch (PackageManager.NameNotFoundException e) { Rlog.e(TAG, "Can't get calling app package info: refusing to send SMS"); tracker.onFailed(mContext, RESULT_ERROR_GENERIC_FAILURE, 0/*errorCode*/); return; } // checkDestination() returns true if the destination is not a premium short code or the // sending app is approved to send to short codes. Otherwise, a message is sent to our // handler with the SmsTracker to request user confirmation before sending. if (checkDestination(tracker)) {
mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.DEFAULT); mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setVideoSize(mVideoWidth, mVideoHeight); FileOutputStream fos = new FileOutputStream(OUTPUT_PATH2); FileDescriptor fd = fos.getFD(); mMediaRecorder.setOutputFile(fd); long maxFileSize = MAX_FILE_SIZE * 10; recordMedia(maxFileSize, mOutFile2); assertFalse(checkLocationInFile(OUTPUT_PATH2)); fos.close(); } public void testRecordingAudioInRawFormats() throws Exception { int testsRun = 0; if (hasAmrNb()) { testsRun += testRecordAudioInRawFormat( MediaRecorder.OutputFormat.AMR_NB, MediaRecorder.AudioEncoder.AMR_NB); } if (hasAmrWb()) { testsRun += testRecordAudioInRawFormat( MediaRecorder.OutputFormat.AMR_WB, MediaRecorder.AudioEncoder.AMR_WB); } if (hasAac()) { testsRun += testRecordAudioInRawFormat( MediaRecorder.OutputFormat.AAC_ADTS, MediaRecorder.AudioEncoder.AAC); }
mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setMaxFileSize(fileSize); mMediaRecorder.prepare(); mMediaRecorder.start(); // Recording a scene with moving objects would greatly help reduce // the time for waiting. if (!mMaxFileSizeCond.block(MAX_FILE_SIZE_TIMEOUT_MS)) { fail("timed out waiting for MEDIA_RECORDER_INFO_MAX_FILESIZE_REACHED"); } mMediaRecorder.stop(); checkOutputFileSize(OUTPUT_PATH, fileSize, tolerance); } private void checkOutputFileSize(final String fileName, long fileSize, long tolerance) { assertTrue(mOutFile.exists()); assertEquals(fileSize, mOutFile.length(), tolerance); assertTrue(mOutFile.delete()); } public void testOnErrorListener() throws Exception { if (!hasMicrophone() || !hasAmrNb()) { MediaUtils.skipTest("no audio codecs or microphone"); return; } mMediaRecorder.setAudioSource(MediaRecorder.AudioSource.DEFAULT); mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP);
assertTrue("Incorrect longitude: " + longitude, Math.abs(longitude - LONGITUDE) <= TOLERANCE); retriever.release(); return true; } private void checkOutputExist() { assertTrue(mOutFile.exists()); assertTrue(mOutFile.length() > 0); assertTrue(mOutFile.delete()); } public void testRecorderVideo() throws Exception { if (!hasCamera()) { return; } mCamera = Camera.open(0); setSupportedResolution(mCamera); mCamera.unlock(); mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.CAMERA); mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.DEFAULT); mMediaRecorder.setOutputFile(OUTPUT_PATH2); mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.DEFAULT); mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setVideoSize(mVideoWidth, mVideoHeight); FileOutputStream fos = new FileOutputStream(OUTPUT_PATH2); FileDescriptor fd = fos.getFD(); mMediaRecorder.setOutputFile(fd); long maxFileSize = MAX_FILE_SIZE * 10; recordMedia(maxFileSize, mOutFile2);
|| regState == ServiceState.RIL_REG_STATE_DENIED) { rejectCode = Integer.parseInt(states[13]); } } if (states.length > 14) { if (states[14] != null && states[14].length() > 0) { psc = (int)Long.parseLong(states[14], 16); } } } catch (NumberFormatException ex) { loge("error parsing RegistrationState: " + ex); } } mGsmRoaming = regCodeIsRoaming(registrationState); mNewRejectCode = reasonForDenial; boolean isVoiceCapable = mPhone.getContext().getResources() .getBoolean(com.android.internal.R.bool.config_voice_capable); if ((regState == ServiceState.RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED || regState == ServiceState.RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED || regState == ServiceState.RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED
private int getRegStateFromHalRegState(int regState) { switch (regState) { case RegState.NOT_REG_MT_NOT_SEARCHING_OP: return ServiceState.RIL_REG_STATE_NOT_REG; case RegState.REG_HOME: return ServiceState.RIL_REG_STATE_HOME; case RegState.NOT_REG_MT_SEARCHING_OP: return ServiceState.RIL_REG_STATE_SEARCHING; case RegState.REG_DENIED: return ServiceState.RIL_REG_STATE_DENIED; case RegState.UNKNOWN: return ServiceState.RIL_REG_STATE_UNKNOWN; case RegState.REG_ROAMING: return ServiceState.RIL_REG_STATE_ROAMING; case RegState.NOT_REG_MT_NOT_SEARCHING_OP_EM: return ServiceState.RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED; case RegState.NOT_REG_MT_SEARCHING_OP_EM: return ServiceState.RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED; case RegState.REG_DENIED_EM: return ServiceState.RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED; case RegState.UNKNOWN_EM: return ServiceState.RIL_REG_STATE_UNKNOWN_EMERGENCY_CALL_ENABLED; default: return ServiceState.REGISTRATION_STATE_NOT_REGISTERED_AND_NOT_SEARCHING; }
if (DBG) { log("handlPollVoiceRegResultMessage: regState=" + registrationState + " radioTechnology=" + voiceRegStateResult.rat); } break; } case EVENT_POLL_STATE_GPRS: { DataRegStateResult dataRegStateResult = (DataRegStateResult) ar.result; int regState = convertHalRegStateToServiceState(dataRegStateResult.regState); int dataRegState = regCodeToServiceState(regState); int newDataRat = dataRegStateResult.rat; mNewSS.setDataRegState(dataRegState); mNewSS.setRilDataRadioTechnology(newDataRat); if (mPhone.isPhoneTypeGsm()) { mNewReasonDataDenied = dataRegStateResult.reasonDataDenied; mNewMaxDataCalls = dataRegStateResult.maxDataCalls; mDataRoaming = regCodeIsRoaming(regState); if (DBG) { log("handlPollStateResultMessage: GsmSST setDataRegState=" + dataRegState + " regState=" + regState + " dataRadioTechnology=" + newDataRat); } } else if (mPhone.isPhoneTypeCdma()) {
* <td>TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA</td> * <td>1&ndash;8</td> * <td>1&ndash;8</td> * </tr> * <tr class="deprecated"> * <td>TLS_DHE_RSA_WITH_AES_128_CBC_SHA</td> * <td>9&ndash;TBD</td> * <td>9&ndash;TBD</td> * </tr> * <tr class="deprecated"> * <td>TLS_DHE_RSA_WITH_AES_128_CBC_SHA256</td> * <td>20&ndash;TBD</td> * <td></td> * </tr> * <tr class="deprecated"> * <td>TLS_DHE_RSA_WITH_AES_128_GCM_SHA256</td> * <td>20&ndash;TBD</td> * <td>20&ndash;TBD</td> * </tr> * <tr class="deprecated"> * <td>TLS_DHE_RSA_WITH_AES_256_CBC_SHA</td> * <td>9&ndash;TBD</td> * <td>20&ndash;TBD</td> * </tr> * <tr class="deprecated">
} } } @Test public void testSocketConnectTimeout() throws Exception { // #connect(SocketAddress endpoint, int timeout) checkOperationTimesOut(() -> new Socket(), s -> s.connect(UNREACHABLE_ADDRESS, TIMEOUT_MILLIS)); // Setting SO_TIMEOUT should not affect connect timeout. checkOperationTimesOut(() -> new Socket(), s -> { s.setSoTimeout(TIMEOUT_MILLIS / 2); s.connect(UNREACHABLE_ADDRESS, TIMEOUT_MILLIS); }); } @Test public void testSocketReadTimeout() throws Exception { // #read() try (ServerSocket ss = new ServerSocket(0)) { // The server socket will accept the connection without explicitly calling accept() due // to TCP backlog. checkOperationTimesOut(() -> new Socket(), s -> { s.connect(ss.getLocalSocketAddress()); s.setSoTimeout(TIMEOUT_MILLIS); s.getInputStream().read(); }); } } @Test public void testSocketWriteNeverTimeouts() throws Exception {
writeCompleted.countDown(); } catch (IOException ignored) { } finally { writeCompleted.countDown(); } }); thread.start(); // Wait for the thread to start. assertTrue(threadStarted.await(500, TimeUnit.MILLISECONDS)); // Wait for TIMEOUT_MILLIS + slop. If write does not complete by then, we assume it has // blocked. boolean blocked = !writeCompleted.await(TIMEOUT_MILLIS * 2, TimeUnit.MILLISECONDS); assertTrue(blocked); // Make sure the writing thread completes after the socket is closed. sock.close(); assertTrue(writeCompleted.await(5000, TimeUnit.MILLISECONDS)); } } @Test public void testServerSocketAcceptTimeout() throws Exception { // #accept() checkOperationTimesOut(() -> new ServerSocket(0), s -> { s.setSoTimeout(TIMEOUT_MILLIS); s.accept(); }); } @Test public void testServerSocketChannelAcceptTimeout() throws Exception { // #accept() checkOperationTimesOut(() -> ServerSocketChannel.open(), s -> {
if (roamingCap.maxBlacklistSize < 0 || roamingCap.maxWhitelistSize < 0) { Log.e(TAG, "Invalid firmware roaming capabilities: max num blacklist bssid=" + roamingCap.maxBlacklistSize + " max num whitelist ssid=" + roamingCap.maxWhitelistSize); } else { mFirmwareRoamingSupported = true; mMaxNumBlacklistBssid = roamingCap.maxBlacklistSize; mMaxNumWhitelistSsid = roamingCap.maxWhitelistSize; Log.d(TAG, "Firmware roaming supported with capabilities: max num blacklist bssid=" + mMaxNumBlacklistBssid + " max num whitelist ssid=" + mMaxNumWhitelistSsid); return true; } } else { Log.e(TAG, "Failed to get firmware roaming capabilities"); } return false;
public boolean setFirmwareRoamingConfiguration(ArrayList<String> blacklistBssids, ArrayList<String> whitelistSsids) { if (!mFirmwareRoamingSupported) { Log.e(TAG, "Firmware roaming is not supported"); return false; } if (blacklistBssids == null || whitelistSsids == null) { Log.e(TAG, "Invalid firmware roaming configuration settings"); return false; } int blacklistSize = blacklistBssids.size(); int whitelistSize = whitelistSsids.size(); if (blacklistSize > mMaxNumBlacklistBssid || whitelistSize > mMaxNumWhitelistSsid) { Log.e(TAG, "Invalid BSSID blacklist size " + blacklistSize + " SSID whitelist size " + whitelistSize + ". Max blacklist size: " + mMaxNumBlacklistBssid + ", max whitelist size: " + mMaxNumWhitelistSsid); return false; } WifiNative.RoamingConfig roamConfig = new WifiNative.RoamingConfig(); roamConfig.blacklistBssids = blacklistBssids; roamConfig.whitelistSsids = whitelistSsids; return mWifiNative.configureRoaming(roamConfig);
public boolean requestIcon(String bssid, String fileName) { if (bssid == null || fileName == null) { Log.e(mTAG, "Invalid arguments for Icon request."); return false; } return mSupplicantStaIfaceHal.initiateHs20IconQuery(bssid, fileName);
* limitations under the License. */ package com.android.server.wifi; import static org.junit.Assert.assertTrue; import static org.mockito.Mockito.mock; import android.os.Handler; import android.os.Message; import android.util.SparseArray; import java.util.HashMap; import java.util.Map; /** * Creates a mock WifiMonitor. * WARNING: This does not perfectly mock the behavior of WifiMonitor at the moment * ex. startMonitoring does nothing and will not send a connection/disconnection event */ public class MockWifiMonitor extends WifiMonitor { private final Map<String, SparseArray<Handler>> mHandlerMap = new HashMap<>(); public MockWifiMonitor() { super(mock(WifiInjector.class)); } @Override public void registerHandler(String iface, int what, Handler handler) { SparseArray<Handler> ifaceHandlers = mHandlerMap.get(iface); if (ifaceHandlers == null) { ifaceHandlers = new SparseArray<>(); mHandlerMap.put(iface, ifaceHandlers); } ifaceHandlers.put(what, handler); } @Override
result.setResult(mISupplicantP2pIface.startWpsPinKeypad(groupIfName, pin)); } catch (RemoteException e) { Log.e(TAG, "ISupplicantP2pIface exception: " + e); supplicantServiceDiedHandler(); } return result.isSuccess(); } } /** * Initiate WPS Pin Display setup. * * @param groupIfName Group interface name to use. * @param bssid BSSID of the AP. Use zero'ed bssid to indicate wildcard. * @return generated pin if operation was successful, null otherwise. */ public String startWpsPinDisplay(String groupIfName, String bssid) { if (TextUtils.isEmpty(groupIfName) || TextUtils.isEmpty(bssid)) return null; synchronized (mLock) { if (!checkSupplicantP2pIfaceAndLogFailure("startWpsPinDisplay")) return null; if (groupIfName == null) { Log.e(TAG, "Group name required when requesting WPS KEYPAD."); return null; } // Null values should be fine, since bssid can be empty. byte[] macAddress = null; if (bssid != null) {
public WifiNative(String interfaceName, WifiVendorHal vendorHal, SupplicantStaIfaceHal staIfaceHal, SupplicantP2pIfaceHal p2pIfaceHal, WificondControl condControl) { mTAG = "WifiNative-" + interfaceName; mInterfaceName = interfaceName; mWifiVendorHal = vendorHal; mSupplicantStaIfaceHal = staIfaceHal; mSupplicantP2pIfaceHal = p2pIfaceHal; mWificondControl = condControl; } public String getInterfaceName() { return mInterfaceName; } /** * Enable verbose logging for all sub modules. */ public void enableVerboseLogging(int verbose) { mWificondControl.enableVerboseLogging(verbose > 0 ? true : false); mSupplicantStaIfaceHal.enableVerboseLogging(verbose > 0); mWifiVendorHal.enableVerboseLogging(verbose > 0); } /******************************************************** * Native Initialization/Deinitialization ********************************************************/ /** * Setup wifi native for Client mode operations. * * 1. Starts the Wifi HAL and configures it in client/STA mode. * 2. Setup Wificond to operate in client mode and retrieve the handle to use for client * operations. *
public boolean startFilteringMulticastV4Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.removeRxFilter( SupplicantStaIfaceHal.RX_FILTER_TYPE_V4_MULTICAST) && mSupplicantStaIfaceHal.startRxFilter();
public boolean stopFilteringMulticastV4Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.addRxFilter( SupplicantStaIfaceHal.RX_FILTER_TYPE_V4_MULTICAST) && mSupplicantStaIfaceHal.startRxFilter();
public boolean startFilteringMulticastV6Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.removeRxFilter( SupplicantStaIfaceHal.RX_FILTER_TYPE_V6_MULTICAST) && mSupplicantStaIfaceHal.startRxFilter();
public boolean stopFilteringMulticastV6Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.addRxFilter( SupplicantStaIfaceHal.RX_FILTER_TYPE_V6_MULTICAST) && mSupplicantStaIfaceHal.startRxFilter();
public boolean setSerialNumber(String value) { return mSupplicantStaIfaceHal.setWpsSerialNumber(value); } public void setPowerSave(boolean enabled) { mSupplicantStaIfaceHal.setPowerSave(enabled); } /** * "sta" prioritizes STA connection over P2P and "p2p" prioritizes * P2P connection over STA */ public boolean setConcurrencyPriority(boolean isStaHigherPriority) { return mSupplicantStaIfaceHal.setConcurrencyPriority(isStaHigherPriority); } /** * Migrate all the configured networks from wpa_supplicant. * * @param configs Map of configuration key to configuration objects corresponding to all * the networks. * @param networkExtras Map of extra configuration parameters stored in wpa_supplicant.conf * @return Max priority of all the configs. */ public boolean migrateNetworksFromSupplicant(Map<String, WifiConfiguration> configs, SparseArray<Map<String, String>> networkExtras) { return mSupplicantStaIfaceHal.loadNetworks(configs, networkExtras); } /**
/** * Handler to notify the occurrence of various events during PNO scan. */ public interface PnoEventHandler { /** * Callback to notify when one of the shortlisted networks is found during PNO scan. * @param results List of Scan results received. */ void onPnoNetworkFound(ScanResult[] results); /** * Callback to notify when the PNO scan schedule fails. */ void onPnoScanFailed(); } public static final int WIFI_SCAN_RESULTS_AVAILABLE = 0; public static final int WIFI_SCAN_THRESHOLD_NUM_SCANS = 1; public static final int WIFI_SCAN_THRESHOLD_PERCENT = 2; public static final int WIFI_SCAN_FAILED = 3; public boolean startScan(ScanSettings settings, ScanEventHandler eventHandler) { return mWifiVendorHal.startScan(settings, eventHandler); } public void stopScan() { mWifiVendorHal.stopScan(); } public void pauseScan() { mWifiVendorHal.pauseScan(); }
public void setWifiLinkLayerStats(String iface, int enable) { // TODO(b//36087365) Remove this. Link layer stats is enabled when the HAL is started.
/** * Indicates whether getChannelsForBand is supported. * * @return true if it is. */ public boolean isGetChannelsForBandSupported() { return mWifiVendorHal.isGetChannelsForBandSupported();
void onWifiAlert(int errorCode, byte[] buffer); } public boolean setLoggingEventHandler(WifiLoggerEventHandler handler) { return mWifiVendorHal.setLoggingEventHandler(handler); } public boolean startLoggingRingBuffer(int verboseLevel, int flags, int maxInterval, int minDataSize, String ringName){ return mWifiVendorHal.startLoggingRingBuffer( verboseLevel, flags, maxInterval, minDataSize, ringName); } public int getSupportedLoggerFeatureSet() { return mWifiVendorHal.getSupportedLoggerFeatureSet(); } /** * Stops all logging and resets the logger callback. * This stops both the alerts and ring buffer data collection. */ public boolean resetLogHandler() { return mWifiVendorHal.resetLogHandler(); } public String getDriverVersion() { return mWifiVendorHal.getDriverVersion(); } public String getFirmwareVersion() { return mWifiVendorHal.getFirmwareVersion(); } public static class RingBufferStatus{ String name; int flag; int ringBufferId; int ringBufferByteSize; int verboseLevel; int writtenBytes; int readBytes; int writtenRecords; // Bit masks for interpreting |flag| public static final int HAS_BINARY_ENTRIES = (1 << 0);
* @hide */ public static final String KEY_NOTIFY_INTERNATIONAL_CALL_ON_WFC_BOOL = "notify_international_call_on_wfc_bool"; /** * Offset to be reduced from rsrp threshold while calculating signal strength level. * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int"; /** * Threshold of EARFCN above which signal_strength_offset_int will be applied. * @hide */ public static final String KEY_SIGNAL_STRENGTH_EAFCN_THRESHOD_INT = "signal_strength_earfcn_threshold_int"; /** The default value for every variable. */ private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true);
"notify_international_call_on_wfc_bool"; /** * Offset to be reduced from rsrp threshold while calculating signal strength level. * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int"; /** * Threshold of EARFCN above which signal_strength_offset_int will be applied. * Unit of this value should be in MHz. * @hide */ public static final String KEY_SIGNAL_STRENGTH_EARFCN_THRESHOLD_INT = "signal_strength_earfcn_threshold_int"; /** The default value for every variable. */ private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true); sDefaults.putBoolean(KEY_APN_EXPAND_BOOL, true); sDefaults.putBoolean(KEY_AUTO_RETRY_ENABLED_BOOL, false);
* * <p>Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param AID Application id. See ETSI 102.221 and 101.220. * @param p2 P2 parameter (described in ISO 7816-4). Default value: 0x00 * @return an IccOpenLogicalChannelResponse object. */ public IccOpenLogicalChannelResponse iccOpenLogicalChannel(String AID, int p2) { return iccOpenLogicalChannel(getSubId(), AID, p2); } /** * Opens a logical channel to the ICC card. * * Input parameters equivalent to TS 27.007 AT+CCHO command. * * <p>Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param subId The subscription to use. * @param AID Application id. See ETSI 102.221 and 101.220.
* limitations under the License. */ package com.android.server.wifi.scanner; import android.content.Context; import android.net.wifi.WifiScanner; import android.os.Handler; import android.os.Looper; import android.os.Message; import android.util.Log; import com.android.server.wifi.Clock; import com.android.server.wifi.WifiNative; /** * WifiScanner implementation that takes advantage of the gscan HAL API * The gscan API is used to perform background scans and wificond is used for oneshot scans. * @see com.android.server.wifi.scanner.WifiScannerImpl for more details on each method. */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler.Callback { private static final String TAG = "HalWifiScannerImpl"; private static final boolean DBG = false; private final WifiNative mWifiNative; private final ChannelHelper mChannelHelper; private final WificondScannerImpl mWificondScannerDelegate; private final boolean mHalBasedPnoSupported; public HalWifiScannerImpl(Context context, WifiNative wifiNative, Looper looper, Clock clock) { mWifiNative = wifiNative; mChannelHelper = new HalChannelHelper(wifiNative);
* limitations under the License. */ package com.android.server.wifi.scanner; import android.content.Context; import android.net.wifi.WifiScanner; import android.os.Handler; import android.os.Looper; import android.os.Message; import android.util.Log; import com.android.server.wifi.Clock; import com.android.server.wifi.WifiMonitor; import com.android.server.wifi.WifiNative; /** * WifiScanner implementation that takes advantage of the gscan HAL API * The gscan API is used to perform background scans and wificond is used for oneshot scans. * @see com.android.server.wifi.scanner.WifiScannerImpl for more details on each method. */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler.Callback { private static final String TAG = "HalWifiScannerImpl"; private static final boolean DBG = false; private final WifiNative mWifiNative; private final ChannelHelper mChannelHelper; private final WificondScannerImpl mWificondScannerDelegate; private final boolean mHalBasedPnoSupported; public HalWifiScannerImpl(Context context, WifiNative wifiNative, WifiMonitor wifiMonitor, Looper looper, Clock clock) {
public void describeTo(Description description) { description.appendText(toString());
String[] s; s = params.getCipherSuites(); if (s != null) { setEnabledCipherSuites(s); } s = params.getProtocols(); if (s != null) { setEnabledProtocols(s); } if (params.getNeedClientAuth()) { setNeedClientAuth(true); } else if (params.getWantClientAuth()) { setWantClientAuth(true); } else { setWantClientAuth(false); } } // Android-added: Make toString explicit that this is an SSLServerSocket (http://b/6602228) @Override public String toString() { return "SSL" + super.toString(); } }
*/ public void receivedWnmFrame(WnmData data) { mHandler.notifyWnmFrameReceived(data); } /** * Request the specified icon file |fileName| from the specified AP |bssid|. * @return true if the request is sent successfully, false otherwise */ public boolean queryPasspointIcon(long bssid, String fileName) { return mHandler.requestIcon(bssid, fileName); } /** * Lookup the ANQP elements associated with the given AP from the cache. An empty map * will be returned if no match found in the cache. * * @param scanResult The scan result associated with the AP * @return Map of ANQP elements */ public Map<Constants.ANQPElementType, ANQPElement> getANQPElements(ScanResult scanResult) { // Retrieve the Hotspot 2.0 Vendor Specific IE. InformationElementUtil.Vsa vsa = InformationElementUtil.getHS2VendorSpecificIE(scanResult.informationElements); // Lookup ANQP data in the cache. long bssid = Utils.parseMac(scanResult.BSSID); ANQPData anqpEntry = mAnqpCache.getEntry(ANQPNetworkKey.buildKey(
mHandler.notifyWnmFrameReceived(data); } /** * Request the specified icon file |fileName| from the specified AP |bssid|. * @return true if the request is sent successfully, false otherwise */ public boolean queryPasspointIcon(long bssid, String fileName) { return mHandler.requestIcon(bssid, fileName); } /** * Lookup the ANQP elements associated with the given AP from the cache. An empty map * will be returned if no match found in the cache. * * @param scanResult The scan result associated with the AP * @return Map of ANQP elements */ public Map<Constants.ANQPElementType, ANQPElement> getANQPElements(ScanResult scanResult) { // Retrieve the Hotspot 2.0 Vendor Specific IE. InformationElementUtil.Vsa vsa = InformationElementUtil.getHS2VendorSpecificIE(scanResult.informationElements); // Lookup ANQP data in the cache. long bssid = Utils.parseMac(scanResult.BSSID); ANQPData anqpEntry = mAnqpCache.getEntry(ANQPNetworkKey.buildKey( scanResult.SSID, bssid, scanResult.hessid, vsa.anqpDomainID));
public void enter() { super.enter(); setSpeakerphoneOn(false); // Do not enable SCO audio here, since RING is being sent to the headset. CallAudioState newState = new CallAudioState(mIsMuted, ROUTE_BLUETOOTH, mAvailableRoutes); setSystemAudioState(newState); updateInternalCallAudioState();
* {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param AID Application id. See ETSI 102.221 and 101.220. * @return an IccOpenLogicalChannelResponse object. * @deprecated Replaced by {@link #iccOpenLogicalChannel(String, byte)} */ @Deprecated public IccOpenLogicalChannelResponse iccOpenLogicalChannel(String AID) { return iccOpenLogicalChannel(getSubId(), AID, -1); } /** * Opens a logical channel to the ICC card. * * Input parameters equivalent to TS 27.007 AT+CCHO command. * * <p>Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param AID Application id. See ETSI 102.221 and 101.220. * @param p2 P2 parameter (described in ISO 7816-4). Default value: 0x00
private static LinkProperties getUniqueLocalConfig(byte[] ulp, String ifname) { LinkProperties lp = new LinkProperties(); lp.setInterfaceName(ifname); final IpPrefix local48 = getUniqueLocalPrefix(ulp, (short) 0, 48); lp.addRoute(new RouteInfo(local48, null, null)); final IpPrefix local64 = getUniqueLocalPrefix(ulp, subnetId, 64); lp.addLinkAddress(new LinkAddress(local64.getAddress(), 64)); return lp;
private int mEvdoDbm; // This value is the EVDO RSSI value private int mEvdoEcio; // This value is the EVDO Ec/Io private int mEvdoSnr; // Valid values are 0-8. 8 is the highest signal to noise ratio private int mLteSignalStrength; private int mLteRsrp; private int mLteRsrq; private int mLteRssnr; private int mLteCqi; private int mLteRsrpBoost; // offset to be reduced from the rsrp threshold while calculating // signal strength level private int mTdScdmaRscp; private boolean isGsm; // This value is set by the ServiceStateTracker onSignalStrengthResult /** * Create a new SignalStrength from a intent notifier Bundle * * This method is used by PhoneStateIntentReceiver and maybe by * external applications. * * @param m Bundle from intent notifier * @return newly created SignalStrength * * @hide */ public static SignalStrength newFromBundle(Bundle m) { SignalStrength ret; ret = new SignalStrength(); ret.setFromNotifierBundle(m);
public void setLteRsrpBoost(int lteRsrpBoost) { mLteRsrpBoost = lteRsrpBoost;
*/ int rssiIconLevel = SIGNAL_STRENGTH_NONE_OR_UNKNOWN, rsrpIconLevel = -1, snrIconLevel = -1; int[] threshRsrp = Resources.getSystem().getIntArray( com.android.internal.R.array.config_lteDbmThresholds); if (threshRsrp.length != 6) { Log.wtf(LOG_TAG, "getLteLevel - config_lteDbmThresholds has invalid num of elements." + " Cannot evaluate RSRP signal."); } else { if (mLteRsrp > threshRsrp[5]) { rsrpIconLevel = -1; } else if (mLteRsrp >= (threshRsrp[4] - mLteRsrpBoost)) { rsrpIconLevel = SIGNAL_STRENGTH_GREAT; } else if (mLteRsrp >= (threshRsrp[3] - mLteOffset)) { rsrpIconLevel = SIGNAL_STRENGTH_GOOD; } else if (mLteRsrp >= (threshRsrp[2] - mLteOffset)) { rsrpIconLevel = SIGNAL_STRENGTH_MODERATE; } else if (mLteRsrp >= (threshRsrp[1] - mLteOffset)) { rsrpIconLevel = SIGNAL_STRENGTH_POOR; } else if (mLteRsrp >= threshRsrp[0]) {
"notify_international_call_on_wfc_bool"; /** * Offset to be reduced from rsrp threshold while calculating signal strength level. * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int"; /** * List of EARFCN ranges on which signal_strength_offset_int will be applied. * Format of the String array is expected to be {"erafcn1_start-earfcn1_end", * "earfcn2_start-earfcn2_end" ... } * @hide */ public static final String KEY_SIGNAL_STRENGTH_EARFCNS_LIST_STRING_ARRAY = "signal_strength_earfcn_threshold_int"; /** The default value for every variable. */ private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true);
* @return error a {@code TETHER_ERROR} value indicating success or failure type * * {@hide} */ public int setUsbTethering(boolean enable) { try { return mService.setUsbTethering(enable); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } /** * Request that a local-only Wi-Fi hotspot be started. The supplied Wi-Fi * configuration is used to start the Wi-Fi hotspot, and must be non-null. * * Local-only Wi-Fi hotspot functionality is currently mutually exclusive * with other tethering functionality. * * @param cfg The {@link android.net.wifi.WifiConfiguration} to use. * @return error a {@code TETHER_ERROR} value indicating success or failure * * @hide */ public int startLocalOnlyWifiHotspot(WifiConfiguration cfg) { try { return mService.startLocalOnlyWifiHotspot(cfg); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } /**
public void getFirmwareRoamingInfo() { reset(mWifiConnectivityHelper); // WifiConnectivityManager is on by default mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper).getFirmwareRoamingInfo();
// SSID as the one to be selected. WifiConfiguration currentNetwork = generateWifiConfig( 0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null); when(mWifiConfigManager.getConfiguredNetwork(anyInt())).thenReturn(currentNetwork); // Set WiFi to connected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_CONNECTED); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); verify(mWifiStateMachine).startRoamToNetwork(eq(CANDIDATE_NETWORK_ID), mCandidateScanResultCaptor.capture()); assertEquals(mCandidateScanResultCaptor.getValue().BSSID, CANDIDATE_BSSID);
public void noFrameworkRoamingIfFirmwareControlRoaming() { // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set WiFi to connected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_CONNECTED); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); verify(mWifiStateMachine, times(0)).startRoamToNetwork(anyInt(), anyObject());
* 6. "San Francisco" location card opens. * 7. Select "San Francisco". * 8. Tap on the Drive icon. * Verify: * 1. Map points to San Francisco location. * 2. Navigation overview is displayed. * </pre> */ @Test @TestInfo(id = "145493594") public void testMapsApp() throws Exception { Instrumentation instrumentation = testFramework.getInstrumentation(); UiDevice mDevice = testFramework.getDevice(); AppLauncher.launch(instrumentation, "Maps"); UiObject acceptButton = mDevice.findObject(new UiSelector().textContains("ACCEPT & CONTINUE")); // "Accept & Continue" occurs only on first time Maps gets launched. if (acceptButton.exists()) { acceptButton.clickAndWaitForNewWindow(); } // SKIP button only exist's occurs only on first time Maps gets launched. UiObject skipText = mDevice.findObject(new UiSelector().textContains("SKIP")); if (skipText.exists()) {
scrollView.scrollIntoView(new UiSelector().text(QUERY_STRING)); selectedLocation = scrollView.getChildByText(new UiSelector() .className(TextView.class.getName()), QUERY_STRING); Assert.assertTrue(selectedLocation.exists()); selectedLocation.clickAndWaitForNewWindow(); // Verify the Query String is present after completing search. UiObject searchTextView = searchUiObject.getChild(new UiSelector().className(TextView.class.getName())); Assert.assertTrue(searchTextView.getText().contains(QUERY_STRING)); } else { searchEditText = mDevice.findObject(new UiSelector().className(EditText.class.getName())); searchEditText.setText(QUERY_STRING); UiScrollable listViewSelector = new UiScrollable(new UiSelector().className(ListView.class.getName())); selectedLocation = listViewSelector.getChildByText(new UiSelector() .className(TextView.class.getName()), QUERY_STRING); selectedLocation.clickAndWaitForNewWindow(); // Verify the Query String is present after completing search. Assert.assertTrue(searchEditText.getText().contains(QUERY_STRING)); }
private static final String TAG = "CellBroadcastReceiver"; static final boolean DBG = false; // STOPSHIP: change to false before ship public static final String CELLBROADCAST_START_CONFIG_ACTION = "android.cellbroadcastreceiver.START_CONFIG"; // Key to access the stored reminder interval default value private static final String CURRENT_INTERVAL_DEFAULT = "current_interval_default"; public static final String ACTION_MARK_AS_READ = "com.google.android.clockwork.cmas.intent.action.MARK_AS_READ"; public static final String EXTRA_DELIVERY_TIME = "com.android.cellbroadcastreceiver.intent.extra.ID"; @Override public void onReceive(Context context, Intent intent) { onReceiveWithPrivilege(context, intent, false); } protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) { if (DBG) log("onReceive " + intent); String action = intent.getAction(); final long deliveryTime = intent.getLongExtra(EXTRA_DELIVERY_TIME, -1); if (ACTION_MARK_AS_READ.equals(action)) { new CellBroadcastContentProvider.AsyncCellBroadcastTask(context.getContentResolver())
protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) { if (DBG) log("onReceive " + intent); String action = intent.getAction(); if (ACTION_MARK_AS_READ.equals(action)) { new CellBroadcastContentProvider.AsyncCellBroadcastTask(context.getContentResolver()) .execute(new CellBroadcastContentProvider.CellBroadcastOperation() { @Override public boolean execute(CellBroadcastContentProvider provider) { return provider.markBroadcastRead(CellBroadcasts.DELIVERY_TIME, deliveryTime); } }); } else if (TelephonyIntents.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED.equals(action) || CarrierConfigManager.ACTION_CARRIER_CONFIG_CHANGED.equals(action) || CELLBROADCAST_START_CONFIG_ACTION.equals(action)) { // Todo: Add the service state check once the new get service state API is done. // Do not rely on mServiceState as it gets reset to -1 time to time because // the process of CellBroadcastReceiver gets killed every time once the job is done.
protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) { if (DBG) log("onReceive " + intent); String action = intent.getAction(); final long deliveryTime = intent.getLongExtra(EXTRA_DELIVERY_TIME, -1); if (ACTION_MARK_AS_READ.equals(action)) { final long deliveryTime = intent.getLongExtra(EXTRA_DELIVERY_TIME, -1); new CellBroadcastContentProvider.AsyncCellBroadcastTask(context.getContentResolver()) .execute(new CellBroadcastContentProvider.CellBroadcastOperation() { @Override public boolean execute(CellBroadcastContentProvider provider) { return provider.markBroadcastRead(CellBroadcasts.DELIVERY_TIME, deliveryTime); } }); } else if (TelephonyIntents.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED.equals(action) || CarrierConfigManager.ACTION_CARRIER_CONFIG_CHANGED.equals(action) || CELLBROADCAST_START_CONFIG_ACTION.equals(action)) { // Todo: Add the service state check once the new get service state API is done. // Do not rely on mServiceState as it gets reset to -1 time to time because // the process of CellBroadcastReceiver gets killed every time once the job is done.
/** Intent action to display alert dialog/notification, after verifying the alert is new. */ static final String SHOW_NEW_ALERT_ACTION = "cellbroadcastreceiver.SHOW_NEW_ALERT"; /** Use the same notification ID for non-emergency alerts. */ static final int NOTIFICATION_ID = 1; /** Sticky broadcast for latest area info broadcast received. */ static final String CB_AREA_INFO_RECEIVED_ACTION = "android.cellbroadcastreceiver.CB_AREA_INFO_RECEIVED"; /** Intent extra for passing a SmsCbMessage */ private static final String EXTRA_MESSAGE = "message"; /** * Container for service category, serial number, location, body hash code, and ETWS primary/ * secondary information for duplication detection. */ private static final class MessageServiceCategoryAndScope { private final int mServiceCategory; private final int mSerialNumber; private final SmsCbLocation mLocation; private final int mBodyHash; private final boolean mIsEtwsPrimary; MessageServiceCategoryAndScope(int serviceCategory, int serialNumber, SmsCbLocation location, int bodyHash, boolean isEtwsPrimary) { mServiceCategory = serviceCategory;
ArrayList<CellBroadcastMessage> messageList, Context context, boolean fromSaveState) { int channelTitleId = CellBroadcastResources.getDialogTitleResource(context, message); CharSequence channelName = context.getText(channelTitleId); String messageBody = message.getMessageBody(); // Create intent to show the new messages when user selects the notification. Intent intent; if (context.getPackageManager().hasSystemFeature(PackageManager.FEATURE_WATCH)) { // For FEATURE_WATCH we want to mark as read intent = createMarkAsReadIntent(context, message.getDeliveryTime()); } else { // For phone we handle it differently intent = createDisplayMessageIntent(context, CellBroadcastAlertDialog.class, messageList); } intent.putExtra(CellBroadcastAlertDialog.FROM_NOTIFICATION_EXTRA, true); intent.putExtra(CellBroadcastAlertDialog.FROM_SAVE_STATE_NOTIFICATION_EXTRA, fromSaveState); PendingIntent pi; if (context.getPackageManager().hasSystemFeature(PackageManager.FEATURE_WATCH)) { pi = PendingIntent.getBroadcast(context, 0, intent, 0); } else { pi = PendingIntent.getActivity(context, NOTIFICATION_ID, intent,
static Intent createMarkAsReadIntent(Context context, long deliveryTime) { Intent deleteIntent = new Intent(context, CellBroadcastReceiver.class); deleteIntent.setAction(CellBroadcastReceiver.ACTION_MARK_AS_READ); deleteIntent.putExtra(CellBroadcastReceiver.EXTRA_DELIVERY_TIME, deliveryTime); return deleteIntent;
/** * @hide */ public class NetdService { private static final String TAG = NetdService.class.getSimpleName(); private static final String NETD_SERVICE_NAME = "netd"; private static final int BASE_TIMEOUT_MS = 100; private static final int MAX_TIMEOUT_MS = 1000; /** * It is the caller's responsibility to check for a null return value * and to handle RemoteException errors from invocations on the returned * interface if, for example, netd dies and is restarted. * * Returned instances of INetd should not be cached. * * @return an INetd instance or null. */ public static INetd getInstance() { // NOTE: ServiceManager does no caching for the netd service, // because netd is not one of the defined common services. final INetd netdInstance = INetd.Stub.asInterface( ServiceManager.getService(NETD_SERVICE_NAME)); if (netdInstance == null) { Log.w(TAG, "WARNING: returning null INetd instance."); } return netdInstance; } /** * Blocks until an INetd instance is available. *
if (netdInstance == null) { Log.w(TAG, "WARNING: returning null INetd instance."); } return netdInstance; } /** * Blocks until an INetd instance is available. * * It is the caller's responsibility to handle RemoteException errors * from invocations on the returned interface if, for example, netd * dies after this interface was returned. * * Returned instances of INetd should not be cached. * * @return an INetd instance or null. */ public static INetd get(int maxTimeoutMs) { int timeoutMs = BASE_TIMEOUT_MS; for (int i = 0; i > -1; i++) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } // No netdInstance was received; sleep and retry. final int timeoutMs = (i < (MAX_TIMEOUT_MS / BASE_TIMEOUT_MS)) ? (i * BASE_TIMEOUT_MS) : MAX_TIMEOUT_MS; try { Thread.sleep(timeoutMs); } catch (InterruptedException e) {} } }
public static INetd get() { for (int i = 0; ; i++) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } // No netdInstance was received; sleep and retry. final int timeoutMs = (i < (MAX_TIMEOUT_MS / BASE_TIMEOUT_MS)) ? (i * BASE_TIMEOUT_MS) : MAX_TIMEOUT_MS; try { Thread.sleep(timeoutMs); } catch (InterruptedException e) { // If this occurs we can lose track of some time slept. } if (maxTimeoutMs > 0) maxTimeoutMs -= timeoutMs; }
void run(INetd netd) throws RemoteException; } /** * Blocks until an INetd instance is availabe, and retries until either * the command succeeds or a ServiceSpecificError is thrown. */
void run(INetd netd) throws RemoteException, ServiceSpecificException; } /** * Blocks until an INetd instance is availabe, and retries until either * the command succeeds or a runtime exception is thrown. */
public static void run(NetdCommand cmd) { while (true) { try { cmd.run(get()); return; } catch (RemoteException re) { Log.e(TAG, "error communicated with netd: " + re); } }
public static void run(NetdCommand cmd) { while (true) { try { cmd.run(get()); return; } catch (RemoteException re) { Log.e(TAG, "error communicated with netd: " + re); } }
ResultUnit.BYTE); Stat.StatResult stat = Stat.getStat(mbps); getReportLog().printSummary("write throughput", stat.mAverage, ResultType.HIGHER_BETTER, ResultUnit.MBPS); } @TimeoutReq(minutes = 80) public void testSingleSequentialUpdate() throws Exception { final long fileSize = FileUtil.getFileSizeExceedingMemory(getContext(), BUFFER_SIZE); if (fileSize == 0) { // not enough space, give up return; } final int NUMBER_REPETITION = 3; FileUtil.doSequentialUpdateTest(getContext(), DIR_SEQ_UPDATE, getReportLog(), fileSize, BUFFER_SIZE, NUMBER_REPETITION); } @TimeoutReq(minutes = 30) public void testSingleSequentialRead() throws Exception { final long fileSize = FileUtil.getFileSizeExceedingMemory(getContext(), BUFFER_SIZE); if (fileSize == 0) { // not enough space, give up return; } long start = System.currentTimeMillis(); final File file = FileUtil.createNewFilledFile(getContext(), DIR_SEQ_RD, fileSize); long finish = System.currentTimeMillis();
private void updateSavedNetworkSelectionStatus() { List<WifiConfiguration> savedNetworks = mWifiConfigManager.getSavedNetworks(); if (savedNetworks.size() == 0) { localLog("No saved networks."); return; } StringBuffer sbuf = new StringBuffer("Saved Networks List: \n"); for (WifiConfiguration network : savedNetworks) { /** * Ignore Passpoint networks. Passpoint networks are also considered as "saved" * network, but without being persisted to the storage. They are managed * by {@link PasspointNetworkEvaluator}. */ if (network.isPasspoint()) { continue; } WifiConfiguration.NetworkSelectionStatus status = network.getNetworkSelectionStatus(); // If a configuration is temporarily disabled, re-enable it before trying // to connect to it. mWifiConfigManager.tryEnableNetwork(network.networkId); //TODO(b/30928589): Enable "permanently" disabled networks if we are in DISCONNECTED // state. // Clear the cached candidate, score and seen. mWifiConfigManager.clearNetworkCandidateScanResult(network.networkId);
List<WifiConfiguration> associatedConfigurations = null; WifiConfiguration associatedConfiguration = mWifiConfigManager.getSavedNetworkForScanDetailAndCache(scanDetail); if (associatedConfiguration == null) { continue; } else { associatedConfigurations = new ArrayList<>(Arrays.asList(associatedConfiguration)); } for (WifiConfiguration network : associatedConfigurations) { /** * Ignore Passpoint networks. Passpoint networks are also considered as "saved" * network, but without being persisted to the storage. They are being evaluated * by {@link PasspointNetworkEvaluator}. */ if (network.isPasspoint()) { continue; } WifiConfiguration.NetworkSelectionStatus status = network.getNetworkSelectionStatus(); status.setSeenInLastQualifiedNetworkSelection(true); if (!status.isNetworkEnabled()) { continue; } else if (network.BSSID != null && !network.BSSID.equals("any") && !network.BSSID.equals(scanResult.BSSID)) { // App has specified the only BSSID to connect for this // configuration. So only the matching ScanResult can be a candidate.
"am stack move-top-activity-to-pinned-stack 1 0 0 500 500"; protected static final String LAUNCHING_ACTIVITY = "LaunchingActivity"; private static final String AM_RESIZE_DOCKED_STACK = "am stack resize-docked-stack "; private static final String AM_MOVE_TASK = "am stack movetask "; private static final String AM_SUPPORTS_SPLIT_SCREEN_MULTIWINDOW = "am supports-split-screen-multiwindow"; private static final String INPUT_KEYEVENT_HOME = "input keyevent 3"; /** A reference to the device under test. */ protected ITestDevice mDevice; private HashSet<String> mAvailableFeatures; protected static String getAmStartCmd(final String activityName) { return "am start -n " + getActivityComponentName(activityName); } protected static String getAmStartCmdOverHome(final String activityName) { return "am start --activity-task-on-home -n " + getActivityComponentName(activityName); } static String getActivityComponentName(final String activityName) {
public int startLocalOnlyWifiHotspot(WifiConfiguration cfg) { final Mode current = mMode; if (current != Mode.IDLE) { if (VDBG) { Log.e(TAG, "Attempt to startLocalOnlyWifiHotspot absent corresponding stop."); } return ConnectivityManager.TETHER_ERROR_SERVICE_UNAVAIL; } mMode = Mode.LOCAL_HOTSPOT; return setWifiTethering(cfg, true);
public int startLocalOnlyWifiHotspot(WifiConfiguration cfg) { if (mMode == Mode.LOCAL_HOTSPOT) { if (VDBG) { Log.e(TAG, "Already in mode: " + current.description); } return ConnectivityManager.TETHER_ERROR_SERVICE_UNAVAIL; } mMode = Mode.LOCAL_HOTSPOT; return setWifiTethering(cfg, true);
public void stopLocalOnlyWifiHotspot() { if (mMode != Mode.LOCAL_HOTSPOT) { if (VDBG) { Log.e(TAG, "Local hotspot not running."); } return; } setWifiTethering(null, false);
protected boolean turnOffMasterTetherSettings() { if (!stopIpServices()) { transitionTo(mStopTetheringErrorState); return false; } if (mMode == Mode.TETHERING) { try { mNMService.setIpForwardingEnabled(false); } catch (Exception e) { transitionTo(mSetIpForwardingDisabledErrorState); return false; } } transitionTo(mInitialState); return true;
import java.util.Random; /** * IPv6 tethering is rather different from IPv4 owing to the absence of NAT. * This coordinator is responsible for evaluating the dedicated prefixes * assigned to the device and deciding how to divvy them up among downstream * interfaces. * * @hide */ public class IPv6TetheringCoordinator { private static final String TAG = IPv6TetheringCoordinator.class.getSimpleName(); private static final boolean DBG = false; private static final boolean VDBG = false; private static class Downstream { public final TetherInterfaceStateMachine tism; public final short subnetId; DownstreamState(TetherInterfaceStateMachine tism, short subnetId) { this.tism = tism; this.subnetId = subnetId; } } private final ArrayList<TetherInterfaceStateMachine> mNotifyList; private final LinkedList<DownstreamState> mActiveDownstreams; private short mNextSubnetId; private byte[] mUniqueLocalPrefix; private NetworkState mUpstreamNetworkState; public IPv6TetheringCoordinator(ArrayList<TetherInterfaceStateMachine> notifyList) { mNotifyList = notifyList; mActiveDownstreams = new LinkedList<>();
*/ public class IPv6TetheringCoordinator { private static final String TAG = IPv6TetheringCoordinator.class.getSimpleName(); private static final boolean DBG = false; private static final boolean VDBG = false; private static class DownstreamState { public final TetherInterfaceStateMachine tism; public final short subnetId; DownstreamState(TetherInterfaceStateMachine tism, short subnetId) { this.tism = tism; this.subnetId = subnetId; } } private final ArrayList<TetherInterfaceStateMachine> mNotifyList; private final LinkedList<Downstream> mActiveDownstreams; private short mNextSubnetId; private byte[] mUniqueLocalPrefix; private NetworkState mUpstreamNetworkState; public IPv6TetheringCoordinator(ArrayList<TetherInterfaceStateMachine> notifyList) { mNotifyList = notifyList; mActiveDownstreams = new LinkedList<>(); mNextSubnetId = 0; } public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { // Adding a new downstream appends it to the list. Adding a // downstream a second time without first removing it has no effect.
public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { // Adding a new downstream appends it to the list. Adding a // downstream a second time without first removing it has no effect. mActiveDownstreams.offer(new Downstream(downstream, mNextSubnetId++)); updateIPv6TetheringInterfaces(); }
private static byte[] generateUniqueLocalPrefix() { final byte[] ulp = new byte[6]; // 6 = 48bits / 8bits/byte (new Random()).nextBytes(ulp); final byte[] in6addr = Arrays.copyOf(ulp, NetworkConstants.IPV6_ADDR_LEN); in6addr[0] = (byte) 0xfd; // fc00::/7 and L=1 return in6addr;
ActivityReceiverFilter appEndReceiver = new ActivityReceiverFilter(ACTIVITY_EXIT_ACTION); // The filter for the time event. ActivityReceiverFilter timeReceiver = new ActivityReceiverFilter(ACTIVITY_TIME_TRACK_INFO); // Run the activity. mContext.startActivity(intent, options.toBundle()); // Wait until it finishes and end the reciever then. assertEquals(RESULT_PASS, appEndReceiver.waitForActivity()); appEndReceiver.close(); if (!noHomeScreen()) { // At this time the timerReceiver should not fire, even though the activity has shut // down, because we are back to the home screen. assertEquals(RESULT_TIMEOUT, timeReceiver.waitForActivity()); assertTrue(timeReceiver.mTimeUsed == 0); } else { assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); } // Issuing now another activity will trigger the timing information release. final Intent dummyIntent = new Intent(context, MockApplicationActivity.class); dummyIntent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); final Activity activity = mInstrumentation.startActivitySync(dummyIntent); // Wait until it finishes and end the reciever then.
private CdmaSubscriptionSourceManager mCdmaSSM; public static final String INVALID_MCC = "000"; public static final String DEFAULT_MNC = "00"; private HbpcdUtils mHbpcdUtils = null; /* Used only for debugging purposes. */ private String mRegistrationDeniedReason; private String mCurrentCarrier = null; /* list of LTE EARFCNs (E-UTRA Absolute Radio Frequency Channel Number, * Reference: 3GPP TS 36.104 5.4.3) * inclusive ranges for which the lte rsrp boost is applied */ private ArrayList<Pair<Integer, Integer>> mEarfcnPairListForRsrpBoost = null; private int mLteRsrpBoost = 0; // offset which is reduced from the rsrp threshold // while calculating signal strength level. private final Object mLteRsrpBoostLock = new Object(); // mLteRsrpBoost lock public ServiceStateTracker(GsmCdmaPhone phone, CommandsInterface ci) { mPhone = phone; mCi = ci; mRatRatcheter = new RatRatcheter(mPhone); mVoiceCapable = mPhone.getContext().getResources().getBoolean( com.android.internal.R.bool.config_voice_capable);
/* list of LTE EARFCNs (E-UTRA Absolute Radio Frequency Channel Number, * Reference: 3GPP TS 36.104 5.4.3) * pairs for which the lte rsrp boost is applied */ private ArrayList<Pair<Integer, Integer>> mEarfcnPairListForRsrpBoost = null; private int mLteRsrpBoost = 0; // offset which is reduced from the rsrp threshold // while calculating signal strength level. private final Object mLteRsrpBoostLock = new Object(); private static final int INVALID_LTE_EARFCN = -1; public ServiceStateTracker(GsmCdmaPhone phone, CommandsInterface ci) { mPhone = phone; mCi = ci; mRatRatcheter = new RatRatcheter(mPhone); mVoiceCapable = mPhone.getContext().getResources().getBoolean( com.android.internal.R.bool.config_voice_capable); mUiccController = UiccController.getInstance(); mUiccController.registerForIccChanged(this, EVENT_ICC_CHANGED, null); mCi.setOnSignalStrengthUpdate(this, EVENT_SIGNAL_STRENGTH_UPDATE, null); mCi.registerForCellInfoList(this, EVENT_UNSOL_CELL_INFO_LIST, null); mSubscriptionController = SubscriptionController.getInstance();
&& ServiceState.isCdma(newDataRat))) { mCi.getSignalStrength(obtainMessage(EVENT_GET_SIGNAL_STRENGTH)); } // voice roaming state in done while handling EVENT_POLL_STATE_REGISTRATION_CDMA mNewSS.setDataRoaming(regCodeIsRoaming(regState)); if (DBG) { log("handlPollStateResultMessage: CdmaLteSST setDataRegState=" + dataRegState + " regState=" + regState + " dataRadioTechnology=" + newDataRat); } } updateServiceStateLteEarfcnBoost(mNewSS, getLteEarfcn(dataRegStateResult)); break; } case EVENT_POLL_STATE_OPERATOR: { if (mPhone.isPhoneTypeGsm()) { String opNames[] = (String[]) ar.result; if (opNames != null && opNames.length >= 3) { // FIXME: Giving brandOverride higher precedence, is this desired? String brandOverride = mUiccController.getUiccCard(getPhoneId()) != null ? mUiccController.getUiccCard(getPhoneId()).getOperatorBrandOverride() : null; if (brandOverride != null) {
private void updateLteEarfcnBoost(int lteEarfcn) { synchronized (mLteRsrpBoostLock) { if ((lteEarfcn != -1) && containsEarfcnInEarfcnRange(mEarfcnPairListForRsrpBoost, lteEarfcn)) { serviceState.setLteEarfcnRsrpBoost(mLteRsrpBoost); } else { mNewSS.setLteEarfcnRsrpBoost(0); } }
&& mRingingCall.getState() == ImsPhoneCall.State.IDLE) { mForegroundCall.detach(mPendingMO); removeConnection(mPendingMO); mPendingMO.finalize(); mPendingMO = null; mPhone.initiateSilentRedial(); return; } else { mPendingMO = null; int cause = getDisconnectCauseFromReasonInfo(reasonInfo); ImsPhoneConnection conn = findConnection(imsCall); if(conn != null) { conn.setPreciseDisconnectCause( getPreciseDisconnectCauseFromReasonInfo(reasonInfo)); } processCallStateChange(imsCall, ImsPhoneCall.State.DISCONNECTED, cause); } mMetrics.writeOnImsCallStartFailed(mPhone.getPhoneId(), imsCall.getCallSession(), reasonInfo); }
* onFeatureCapabilityChanged(int, int[], int[])} callbacks, or values received via the * {@link ImsCallProfile#EXTRA_CALL_RAT_TYPE} extra. Util we receive a value via the extras, * we will use the wifi state based on the {@code onFeatureCapabilityChanged}. Once a value * is received via the extras, we will prefer those values going forward. */ private boolean mIsWifiStateFromExtras = false; private int mPreciseDisconnectCause = 0; //***** Event Constants private static final int EVENT_DTMF_DONE = 1; private static final int EVENT_PAUSE_DONE = 2; private static final int EVENT_NEXT_POST_DIAL = 3; private static final int EVENT_WAKE_LOCK_TIMEOUT = 4; private static final int EVENT_DTMF_DELAY_DONE = 5; //***** Constants private static final int PAUSE_DELAY_MILLIS = 3 * 1000; private static final int WAKE_LOCK_TIMEOUT_MILLIS = 60*1000; //***** Inner Classes class MyHandler extends Handler {
/** Not a preempted call */ public static final int CDMA_PREEMPTED = 1007; /** Not an emergency call */ public static final int CDMA_NOT_EMERGENCY = 1008; /** Access Blocked by CDMA network */ public static final int CDMA_ACCESS_BLOCKED = 1009; /** Mapped from ImsReasonInfo */ /* The passed argument is an invalid */ public static final int ILLEGAL_ARGUMENT = 1200; // The operation is invoked in invalid call state public static final int LOCAL_ILLEGAL_STATE = 1201; // IMS service internal error public static final int INTERNAL_ERROR = 1202; // IMS service goes down (service connection is lost) public static final int IMS_SERVICE_DOWN = 1203; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204; // Service unavailable; by power off public static final int POWER_OFF = 1205; // Service unavailable; by low battery public static final int LOW_BATTERY = 1206;
public static final int CDMA_PREEMPTED = 1007; /** Not an emergency call */ public static final int CDMA_NOT_EMERGENCY = 1008; /** Access Blocked by CDMA network */ public static final int CDMA_ACCESS_BLOCKED = 1009; /** Mapped from ImsReasonInfo */ /* The passed argument is an invalid */ public static final int ILLEGAL_ARGUMENT = 1200; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201; // IMS service internal error public static final int LOCAL_INTERNAL_ERROR = 1202; // IMS service goes down (service connection is lost) public static final int IMS_SERVICE_DOWN = 1203; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204; // Service unavailable; by power off public static final int POWER_OFF = 1205; // Service unavailable; by low battery public static final int LOW_BATTERY = 1206; // Service unavailable; by out of service (data service state)
/** Access Blocked by CDMA network */ public static final int CDMA_ACCESS_BLOCKED = 1009; /** Mapped from ImsReasonInfo */ /* The passed argument is an invalid */ public static final int ILLEGAL_ARGUMENT = 1200; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201; // IMS service internal error public static final int INTERNAL_ERROR = 1202; // IMS service goes down (service connection is lost) public static final int LOCAL_IMS_SERVICE_DOWN = 1203; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204; // Service unavailable; by power off public static final int POWER_OFF = 1205; // Service unavailable; by low battery public static final int LOW_BATTERY = 1206; // Service unavailable; by out of service (data service state) public static final int NETWORK_NO_SERVICE = 1207; /* Service unavailable; by no LTE coverage * (VoLTE is not supported even though IMS is registered)
public static final int ILLEGAL_ARGUMENT = 1200; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201; // IMS service internal error public static final int INTERNAL_ERROR = 1202; // IMS service goes down (service connection is lost) public static final int IMS_SERVICE_DOWN = 1203; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204; // Service unavailable; by power off public static final int LOCAL_POWER_OFF = 1205; // Service unavailable; by low battery public static final int LOW_BATTERY = 1206; // Service unavailable; by out of service (data service state) public static final int NETWORK_NO_SERVICE = 1207; /* Service unavailable; by no LTE coverage * (VoLTE is not supported even though IMS is registered) */ public static final int NETWORK_NO_LTE_COVERAGE = 1208; /** Service unavailable; by located in roaming area */ public static final int NETWORK_ROAMING = 1209;
/** Service unavailable; by located in roaming area */ public static final int NETWORK_ROAMING = 1209; /** Service unavailable; by IP changed */ public static final int NETWORK_IP_CHANGED = 1210; /** Service unavailable; other */ public static final int SERVICE_UNAVAILABLE = 1211; /* Service unavailable; IMS connection is lost (IMS is not registered) */ public static final int NOT_REGISTERED = 1212; /** Max call exceeded */ public static final int LOCAL_MAX_CALL_EXCEEDED = 1213; /** Call decline */ public static final int LOCAL_CALL_DECLINE = 1214; /** SRVCC is in progress */ public static final int VCC_ON_PROGRESSING = 1215; /** Resource reservation is failed (QoS precondition) */ public static final int RESOURCE_RESERVATION_FAILED = 1216; /** Retry CS call; VoLTE service can't be provided by the network or remote end * Resolve the extra code(EXTRA_CODE_CALL_RETRY_*) if the below code is set */
public static INetd get(int maxTimeoutMs) { int timeoutMs = BASE_TIMEOUT_MS; while (true) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } if (maxTimeoutMs == 0) break; // No netdInstance was received; sleep and retry. timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); try { Thread.sleep(timeoutMs); } catch (InterruptedException e) { // If this occurs we can lose track of some time slept. } if (maxTimeoutMs > 0) maxTimeoutMs -= timeoutMs; } return null;
public static INetd get(int maxTimeoutMs) { int timeoutMs = BASE_TIMEOUT_MS; while (true) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } if (maxTimeoutMs == 0) break; // No netdInstance was received; sleep and retry. timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); try { Thread.sleep(timeoutMs); } catch (InterruptedException e) { // If this occurs we can lose track of some time slept. } if (maxTimeoutMs > 0) maxTimeoutMs -= timeoutMs; } return null;
public static INetd get(int maxTimeoutMs) { int timeoutMs = BASE_TIMEOUT_MS; while (true) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } if (maxTimeoutMs == 0) break; // No netdInstance was received; sleep and retry. timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); if (maxTimeoutMs > 0) timeoutMs = Math.min(timeoutMs, maxTimeoutMs); try { Thread.sleep(timeoutMs); } catch (InterruptedException e) { // If this occurs we can lose track of some time slept. } if (maxTimeoutMs > 0) maxTimeoutMs -= timeoutMs; } return null;
public static void run(NetdCommand cmd) { while (true) { try { cmd.run(get()); return; } catch (RemoteException re) { Log.e(TAG, "error communicating with netd: " + re); } }
private AuthenticatorHelper mAuthenticatorHelper; private BluetoothAdapter mBtAdapter; private ConnectivityListener mConnectivityListener; private boolean mInputSettingNeeded; private Preference mDeveloperPref; private PreferenceGroup mAccessoriesGroup; private PreferenceGroup mAccountsGroup; private Preference mAddAccessory; private Preference mNetworkPref; private Preference mSoundsPref; private final BroadcastReceiver mBCMReceiver = new BroadcastReceiver() { @Override public void onReceive(Context context, Intent intent) { updateAccessories(); } }; public static MainFragment newInstance() { return new MainFragment(); } @Override public void onCreate(Bundle savedInstanceState) { mAuthenticatorHelper = new AuthenticatorHelper(getContext(), new UserHandle(UserHandle.myUserId()), new AuthenticatorHelper.OnAccountsUpdateListener() { @Override public void onAccountsUpdate(UserHandle userHandle) { updateAccounts(); } }); mBtAdapter = BluetoothAdapter.getDefaultAdapter(); mConnectivityListener = new ConnectivityListener(getContext(), new ConnectivityListener.Listener() { @Override
public void onStart() { super.onStart(); mAuthenticatorHelper.listenToAccountUpdates(); IntentFilter btChangeFilter = new IntentFilter(); btChangeFilter.addAction(BluetoothDevice.ACTION_ACL_CONNECTED); btChangeFilter.addAction(BluetoothDevice.ACTION_ACL_DISCONNECTED); btChangeFilter.addAction(BluetoothAdapter.ACTION_STATE_CHANGED); getContext().registerReceiver(mBCMReceiver, btChangeFilter);
List<X509Certificate> certPathList) throws GeneralSecurityException { if (debug != null) { debug.println("ForwardBuilder.verifyCert(SN: " + Debug.toHexString(cert.getSerialNumber()) + "\n Issuer: " + cert.getIssuerX500Principal() + ")" + "\n Subject: " + cert.getSubjectX500Principal() + ")"); } ForwardState currState = (ForwardState)currentState; // BEGIN Android-removed: Certificate checking // Android doesn't use this mechanism for checking untrusted certificates. // // Don't bother to verify untrusted certificate more. // currState.untrustedChecker.check(cert, Collections.<String>emptySet()); // END Android-removed: Android doesn't use this mechanism for checking untrusted certificates. /* * check for looping - abort a loop if we encounter the same * certificate twice */ if (certPathList != null) { for (X509Certificate cpListCert : certPathList) { if (cert.equals(cpListCert)) { if (debug != null) { debug.println("loop detected!!"); }
} public void testScreenLayout() throws Exception { int expectedScreenLayout = computeScreenLayout(); int expectedSize = expectedScreenLayout & Configuration.SCREENLAYOUT_SIZE_MASK; int expectedLong = expectedScreenLayout & Configuration.SCREENLAYOUT_LONG_MASK; // Check that all four orientations report the same configuration value. for (int i = 0; i < ORIENTATIONS.length; i++) { Activity activity = startOrientationActivity(ORIENTATIONS[i]); if (activity.isInMultiWindowMode()) { // activity.setRequestedOrientation has no effect in multiwindow mode. tearDown(); return; } Configuration mConfig = activity.getResources().getConfiguration(); int actualSize = mConfig.screenLayout & Configuration.SCREENLAYOUT_SIZE_MASK; int actualLong = mConfig.screenLayout & Configuration.SCREENLAYOUT_LONG_MASK; assertEquals("Expected screen size value of " + expectedSize + " but got " + actualSize + " for orientation " + ORIENTATIONS[i], expectedSize, actualSize); assertEquals("Expected screen long value of " + expectedLong + " but got " + actualLong
public void testCompare() { assertTrue(PhoneNumberUtils.compare(null, null)); assertTrue(PhoneNumberUtils.compare("2023458246", "2023458246")); assertFalse(PhoneNumberUtils.compare("2023458246", "6503458246")); assertTrue(PhoneNumberUtils.compare("2023458246", "202-345-8246")); assertTrue(PhoneNumberUtils.compare("2023458246", "+12023458246")); assertTrue(PhoneNumberUtils.compare("2023458246", "+812023458246")); assertTrue(PhoneNumberUtils.compare("2023458246", "+1(202)345-8246"));
public void testFormatNumberToE164() { assertNull(PhoneNumberUtils.formatNumber("invalid#", "US")); assertEquals("+18004664114", PhoneNumberUtils.formatNumberToE164("800-GOOG-114", "US")); assertEquals("+12023458246", PhoneNumberUtils.formatNumberToE164("(202)345-8246", "US")); assertEquals("+812023458246", PhoneNumberUtils.formatNumberToE164("202-345-8246", "JP"));
int connectionState = mStateMachine.getConnectionState(device); if (connectionState != BluetoothProfile.STATE_CONNECTED && connectionState != BluetoothProfile.STATE_CONNECTING) { return false; } mStateMachine.sendMessage(HeadsetStateMachine.DISCONNECT, device); return true; } public List<BluetoothDevice> getConnectedDevices() { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getConnectedDevices(); } private List<BluetoothDevice> getDevicesMatchingConnectionStates(int[] states) { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getDevicesMatchingConnectionStates(states); } public int getConnectionState(BluetoothDevice device) { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getConnectionState(device); } public boolean setPriority(BluetoothDevice device, int priority) { enforceCallingOrSelfPermission(BLUETOOTH_ADMIN_PERM, "Need BLUETOOTH_ADMIN permission"); Settings.Global.putInt(getContentResolver(),
private void processSlcConnected() { if (mPhoneProxy != null) { try { mPhoneProxy.queryPhoneState(); } catch (RemoteException e) { Log.e(TAG, Log.getStackTraceString(new Throwable())); } } else { Log.e(TAG, "Handsfree phone proxy null for query phone state"); }
} return BluetoothProfile.STATE_DISCONNECTED; } else { Log.e(TAG, "Bad currentState: " + currentState); return BluetoothProfile.STATE_DISCONNECTED; } } } List<BluetoothDevice> getConnectedDevices() { List<BluetoothDevice> devices = new ArrayList<BluetoothDevice>(); synchronized (this) { for (int i = 0; i < mConnectedDevicesList.size(); i++) devices.add(mConnectedDevicesList.get(i)); } return devices; } boolean isAudioOn() { return (getCurrentState() == mAudioOn); } boolean isAudioConnected(BluetoothDevice device) { synchronized (this) { /* Additional check for audio state included for the case when PhoneApp queries Bluetooth Audio state, before we receive the close event from the stack for the sco disconnect issued in AudioOn state. This was causing a mismatch in the Incall screen UI. */ if (getCurrentState() == mAudioOn && mCurrentDevice.equals(device)
public void exit() { mWifiConfigStore.enableAllNetworks(); mWifiConfigStore.loadConfiguredNetworks();
public void exit() { mWifiConfigStore.enableAllNetworks(); mWifiConfigStore.loadConfiguredNetworks();
protected boolean hasLog(String str) throws DeviceNotAvailableException { String logs = getDevice().executeAdbCommand("logcat", "-v", "brief", "-d", mService + ":I", "*:S"); return logs.contains(str); } private void clearLogcat() throws DeviceNotAvailableException { getDevice().executeAdbCommand("logcat", "-c"); } protected boolean supportedHardware() throws DeviceNotAvailableException { // Customization by third-party tiles is only a requirement for devices // supporting Quick Settings UI component, according to the CDD: // http://source.android.com/compatibility/7.1/android-7.1-cdd.html#3_13_quick_settings // // As there is no public API to distinguish a device with Quick Settings // from others, the check below, as well as all the tests under // CtsSystemUiHostTestCases relying on the check may have false negatives. String features = getDevice().executeShellCommand("pm list features"); return !features.contains("android.hardware.type.television") && !features.contains("android.hardware.type.watch"); } }
HandlerThread thread = new HandlerThread("BluetoothAdvertiseManager"); thread.start(); mHandler = new Handler(thread.getLooper()); } void cleanup() { logd("cleanup()"); cleanupNative(); mAdvertisers.clear(); sTempRegistrationId = -1; if (mHandler != null) { // Shut down the thread mHandler.removeCallbacksAndMessages(null); Looper looper = mHandler.getLooper(); if (looper != null) { looper.quit(); } mHandler = null; } } class AdvertiserInfo { /* When id is negative, the registration is ongoing. When the registration finishes, id * becomes equal to advertiser_id */ public Integer id; public AdvertisingSetDeathRecipient deathRecipient; public IAdvertisingSetCallback callback; AdvertiserBag(Integer id, AdvertisingSetDeathRecipient deathRecipient, IAdvertisingSetCallback callback) { this.id = id; this.deathRecipient = deathRecipient; this.callback = callback; } } IBinder toBinder(IAdvertisingSetCallback e) { return ((IInterface) e).asBinder(); } class AdvertisingSetDeathRecipient implements IBinder.DeathRecipient {
import android.os.ParcelFileDescriptor; import android.os.Process; import android.os.SystemClock; import android.telecom.PhoneAccount; import android.telecom.PhoneAccountHandle; import android.telecom.TelecomManager; import junit.framework.TestCase; import java.io.BufferedReader; import java.io.FileInputStream; import java.io.InputStream; import java.io.InputStreamReader; import java.nio.charset.StandardCharsets; import java.util.ArrayList; import java.util.Optional; import java.util.concurrent.CountDownLatch; import java.util.concurrent.TimeUnit; import java.util.function.Predicate; public class TestUtils { static final String TAG = "TelecomCTSTests"; static final boolean HAS_TELECOM = Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP; static final long WAIT_FOR_STATE_CHANGE_TIMEOUT_MS = 10000; static final long WAIT_FOR_CALL_ADDED_TIMEOUT_S = 15; static final long WAIT_FOR_STATE_CHANGE_TIMEOUT_CALLBACK = 50; // Non-final to allow modification by tests not in this package (e.g. permission-related // tests in the Telecom2 test package.
// Avoid unnecessary work on spurious updates. if (Objects.equals(mLastIPv6LinkProperties, v6only)) { return; } RaParams params = null; if (v6only != null) { params = new RaParams(); params.mtu = v6only.getMtu(); params.hasDefaultRoute = v6only.hasIPv6DefaultRoute(); for (LinkAddress linkAddr : v6only.getLinkAddresses()) { if (linkAddr.getPrefixLength() != RFC7421_PREFIX_LENGTH) continue; final IpPrefix prefix = new IpPrefix( linkAddr.getAddress(), linkAddr.getPrefixLength()); params.prefixes.add(prefix); final Inet6Address dnsServer = getLocalDnsIpFor(prefix); if (dnsServer != null) { params.dnses.add(dnsServer); } } } // If v6only is null, we pass in null to setRaParams(), which handles // deprecation of any existing RA data. setRaParams(params); mLastIPv6LinkProperties = v6only;
*/ public static final int IPV6_HEADER_LEN = 40; public static final int IPV6_PROTOCOL_OFFSET = 6; public static final int IPV6_SRC_ADDR_OFFSET = 8; public static final int IPV6_DST_ADDR_OFFSET = 24; public static final int IPV6_ADDR_LEN = 16; /** * ICMPv6 constants. * * See also: * - https://tools.ietf.org/html/rfc4443 * - https://tools.ietf.org/html/rfc4861 */ public static final int ICMPV6_HEADER_MIN_LEN = 4; public static final int ICMPV6_ROUTER_SOLICITATION = 133; public static final int ICMPV6_ROUTER_ADVERTISEMENT = 134; public static final int ICMPV6_NEIGHBOR_SOLICITATION = 135; public static final int ICMPV6_NEIGHBOR_ADVERTISEMENT = 136; public static final int ICMPV6_ND_OPTION_MIN_LENGTH = 8;
private boolean startIPv6() { try { enableInterfaceIpv6PrivacyExtensions(); setInterfaceIpv6RaRtInfoMaxPlen(ACCEPT_RA_RT_INFO_MAX_PLEN); mNwService.enableIpv6(mInterfaceName); } catch (RemoteException re) { logError("Unable to change interface settings: %s", re); return false; } return true;
* See the License for the specific language governing permissions and * limitations under the License. */ package com.android.server.connectivity.tethering; import android.net.INetd; import android.net.IpPrefix; import android.net.LinkAddress; import android.net.LinkProperties; import android.net.NetworkCapabilities; import android.net.NetworkState; import android.net.RouteInfo; import android.net.ip.RouterAdvertisementDaemon; import android.net.ip.RouterAdvertisementDaemon.RaParams; import android.net.util.NetdService; import android.os.INetworkManagementService; import android.os.ServiceSpecificException; import android.os.RemoteException; import android.util.Log; import android.util.Slog; import java.net.Inet6Address; import java.net.InetAddress; import java.net.NetworkInterface; import java.net.SocketException; import java.net.UnknownHostException; import java.util.ArrayList; import java.util.HashSet; import java.util.Objects; /** * @hide */ public class IPv6TetheringInterfaceServices { private static final String TAG = IPv6TetheringInterfaceServices.class.getSimpleName();
import android.net.apf.ApfFilter; import android.net.DhcpResults; import android.net.INetd; import android.net.InterfaceConfiguration; import android.net.LinkAddress; import android.net.LinkProperties; import android.net.LinkProperties.ProvisioningChange; import android.net.ProxyInfo; import android.net.RouteInfo; import android.net.StaticIpConfiguration; import android.net.dhcp.DhcpClient; import android.net.metrics.IpConnectivityLog; import android.net.metrics.IpManagerEvent; import android.net.util.MultinetworkPolicyTracker; import android.os.INetworkManagementService; import android.os.Message; import android.os.RemoteException; import android.os.ServiceManager; import android.os.ServiceSpecificException; import android.os.SystemClock; import android.system.OsConstants; import android.text.TextUtils; import android.util.LocalLog; import android.util.Log; import android.util.SparseArray; import com.android.internal.annotations.VisibleForTesting; import com.android.internal.util.IndentingPrintWriter; import com.android.internal.util.IState; import com.android.internal.util.State; import com.android.internal.util.StateMachine; import com.android.server.net.NetlinkTracker; import java.io.FileDescriptor;
protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); final int dialogType = getIntent().getIntExtra(DIALOG_TYPE_KEY, INVALID_PICK); switch (dialogType) { case DATA_PICK: case CALLS_PICK: case SMS_PICK: createDialog(this, dialogType).show(); break; case PREFERRED_PICK: displayPreferredDialog(extras.getInt(PREFERRED_SIM)); break; default: throw new IllegalArgumentException("Invalid dialog type " + dialogType + " sent."); }
{"12345", "12345", "12345"}, {"12345", "67890", "67890"}, {"12345*00000", "12345", "12345*00000"}, {"12345*00000", "67890", "67890"}, {"12345*00000", "12345*00000", "12345*00000"}, {"12345;11111*00000", "12345", "12345"}, {"12345*00000;11111", "12345", "12345*00000"}, {"18412345*00000", "18412345", "18412345*00000"}, {"+8112345*00000", "+8112345", "+8112345*00000"}, {"12345*00000", "12346", "12346"}}; for (String[] testAddress : testAddressMappingSet) { mConnectionUT = new ImsPhoneConnection(mImsPhone, testAddress[0], mImsCT, mForeGroundCall, false); doReturn(testAddress[1]).when(mImsCallProfile) .getCallExtra(eq(ImsCallProfile.EXTRA_OI)); mConnectionUT.updateAddressDisplay(mImsCall); assertEquals(testAddress[2], mConnectionUT.getAddress()); }
* @hide */ public static final int PROPERTY_IS_DOWNGRADED_CONFERENCE = 1<<6; /** * Set by the framework to indicate that the {@link Connection} originated from a self-managed * {@link ConnectionService}. * <p> * See {@link PhoneAccount#CAPABILITY_SELF_MANAGED}. */ public static final int PROPERTY_SELF_MANAGED = 1<<7; /** * Set by the framework to indicate that a connection has an active RTT session associated with * it. * @hide */ @TestApi public static final int PROPERTY_IS_RTT = 1 << 8; //********************************************************************************************** // Next PROPERTY value: 1<<9 //********************************************************************************************** /** * Connection extra key used to store the last forwarded number associated with the current * connection. Used to communicate to the user interface that the connection was forwarded via * the specified number. */ public static final String EXTRA_LAST_FORWARDED_NUMBER = "android.telecom.extra.LAST_FORWARDED_NUMBER"; /**
private static final int STACK_EVENT = 101; private static final int DIALING_OUT_TIMEOUT = 102; private static final int START_VR_TIMEOUT = 103; private static final int CLCC_RSP_TIMEOUT = 104; private static final int CONNECT_TIMEOUT = 201; private static final int DIALING_OUT_TIMEOUT_VALUE = 10000; private static final int START_VR_TIMEOUT_VALUE = 5000; private static final int CLCC_RSP_TIMEOUT_VALUE = 5000; // Max number of HF connections at any time private int max_hf_connections = 1; private static final int NBS_CODEC = 1; private static final int WBS_CODEC = 2; // Keys are AT commands, and values are the company IDs. private static final Map<String, Integer> VENDOR_SPECIFIC_AT_COMMAND_COMPANY_ID; // Hash for storing the Audio Parameters like NREC for connected headsets private HashMap<BluetoothDevice, HashMap> mHeadsetAudioParam = new HashMap<BluetoothDevice, HashMap>(); // Hash for storing the Remotedevice BRSF private HashMap<BluetoothDevice, Integer> mHeadsetBrsf =
import android.preference.PreferenceManager; import android.provider.Telephony; import android.provider.Telephony.CellBroadcasts; import android.telephony.CarrierConfigManager; import android.telephony.cdma.CdmaSmsCbProgramData; import android.util.Log; import com.android.internal.telephony.TelephonyIntents; import com.android.internal.telephony.cdma.sms.SmsEnvelope; public class CellBroadcastReceiver extends BroadcastReceiver { private static final String TAG = "CellBroadcastReceiver"; static final boolean DBG = false; // STOPSHIP: change to false before ship // Key to access the stored reminder interval default value private static final String CURRENT_INTERVAL_DEFAULT = "current_interval_default"; public static final String ACTION_MARK_AS_READ = "com.android.cellbroadcastreceiver.intent.action.MARK_AS_READ"; public static final String EXTRA_DELIVERY_TIME = "com.android.cellbroadcastreceiver.intent.extra.ID"; @Override public void onReceive(Context context, Intent intent) { onReceiveWithPrivilege(context, intent, false); } protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) {
public boolean processMessage(Message message) { logStateAndMessage(message, this); switch (message.what) { case WifiMonitor.WPS_SUCCESS_EVENT: // Ignore intermediate success, wait for full connection break; case WifiMonitor.NETWORK_CONNECTION_EVENT: if (loadNetworksFromSupplicantAfterWps()) { replyToMessage(mSourceMessage, WifiManager.WPS_COMPLETED); } else { replyToMessage(mSourceMessage, WifiManager.WPS_FAILED, WifiManager.ERROR); } mSourceMessage.recycle(); mSourceMessage = null; deferMessage(message); transitionTo(mDisconnectedState); break; case WifiMonitor.WPS_OVERLAP_EVENT: replyToMessage(mSourceMessage, WifiManager.WPS_FAILED, WifiManager.WPS_OVERLAP_ERROR); mSourceMessage.recycle(); mSourceMessage = null; transitionTo(mDisconnectedState); break; case WifiMonitor.WPS_FAIL_EVENT: // Arg1 has the reason for the failure if ((message.arg1 != WifiManager.ERROR) || (message.arg2 != 0)) { replyToMessage(mSourceMessage, WifiManager.WPS_FAILED, message.arg1);
public boolean connect(Call call) { if (mIsConnected) { Log.addEvent(call, LogUtils.Events.INFO, "Already connected, ignoring request."); return true; } if (call.isSelfManaged() && !mInCallServiceInfo.isSelfManagedCallsSupported()) { Log.i(this, "Skipping binding to %s - doesn't support self-mgd calls", mInCallServiceInfo); mIsConnected = false; return CONNECTION_NOT_SUPPORTED; } Intent intent = new Intent(InCallService.SERVICE_INTERFACE); intent.setComponent(mInCallServiceInfo.getComponentName()); if (call != null && !call.isIncoming() && !call.isExternalCall()){ intent.putExtra(TelecomManager.EXTRA_OUTGOING_CALL_EXTRAS, call.getIntentExtras()); intent.putExtra(TelecomManager.EXTRA_PHONE_ACCOUNT_HANDLE, call.getTargetPhoneAccount()); } Log.i(this, "Attempting to bind to InCall %s, with %s", mInCallServiceInfo, intent); mIsConnected = true; if (!mContext.bindServiceAsUser(intent, mServiceConnection, Context.BIND_AUTO_CREATE | Context.BIND_FOREGROUND_SERVICE, UserHandle.CURRENT)) { Log.w(this, "Failed to connect."); mIsConnected = false; }
public CallerInfoAsyncQuery startQuery(int token, Context context, String number, CallerInfoAsyncQuery.OnQueryCompleteListener listener, Object cookie) { Log.i(TelecomSystem.getInstance(), "CallerInfoAsyncQuery.startQuery number=%s cookie=%s", Log.pii(number), cookie); return CallerInfoAsyncQuery.startQuery( token, context, number, listener, cookie);
*/ public class IncomingCallNotifier extends CallsManagerListenerBase { public interface IncomingCallNotifierFactory { IncomingCallNotifier make(Context context, CallsManagerProxy mCallsManagerProxy); } /** * Eliminates strict dependency between this class and CallsManager. */ public interface CallsManagerProxy { boolean hasCallsForOtherPhoneAccount(PhoneAccountHandle phoneAccountHandle); } // Notification for incoming calls. This is interruptive and will show up as a HUN. @VisibleForTesting public static final int NOTIFICATION_INCOMING_CALL = 1; public final Call.ListenerBase mCallListener = new Call.ListenerBase() { @Override public void onCallerInfoChanged(Call call) { if (mIncomingCall != call) { return; } showIncomingCallNotification(mIncomingCall); } }; private final Context mContext; private final NotificationManager mNotificationManager; private final Set<Call> mCalls = new ArraySet<>(); private CallsManagerProxy mCallsManagerProxy; // The current incoming call we are displaying UX for. private Call mIncomingCall; public IncomingCallNotifier(Context context) { mContext = context; mNotificationManager =
} public boolean isConnected() { return sc.isConnected(); } public boolean isBound() { return sc.localAddress() != null; } public boolean isClosed() { return !sc.isOpen(); } public boolean isInputShutdown() { return !sc.isInputOpen(); } public boolean isOutputShutdown() { return !sc.isOutputOpen(); } /** * Android-added: for testing and internal use. */ @Override public FileDescriptor getFileDescriptor$() { return sc.getFD(); } }
kage libcore.java.nio.file.spi; import org.junit.Test; import java.nio.file.Paths; import java.nio.file.spi.FileTypeDetector; import static org.junit.Assert.assertEquals; public class FileTypeDetectorTest { @Test public void test_probeFileType() throws Exception { FileTypeDetector defaultFileTypeDetector = sun.nio.fs.DefaultFileTypeDetector.create(); // The method uses file extensions to deduce mime type, therefore, it doesn't check for // file existence. assertEquals("text/plain", defaultFileTypeDetector.probeContentType(Paths.get("file.txt"))); assertEquals("text/x-java", defaultFileTypeDetector.probeContentType(Paths.get("file.java"))); } }
import java.io.FileOutputStream; import java.io.FilenameFilter; import java.io.IOException; import java.io.PrintWriter; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.List; /** * CarrierConfigLoader binds to privileged carrier apps to fetch carrier config overlays. */ public class CarrierConfigLoader extends ICarrierConfigLoader.Stub { private static final String LOG_TAG = "CarrierConfigLoader"; // Package name for platform carrier config app, bundled with system image. private final String mPlatformCarrierConfigPackage; /** The singleton instance. */ private static CarrierConfigLoader sInstance; // The context for phone app, passed from PhoneGlobals. private Context mContext; // Carrier configs from default app, indexed by phoneID. private PersistableBundle[] mConfigFromDefaultApp; // Carrier configs from privileged carrier config app, indexed by phoneID. private PersistableBundle[] mConfigFromCarrierApp; // Service connection for binding to config app. private CarrierServiceConnection[] mServiceConnection; // Broadcast receiver for Boot intents, register intent filter in construtor.
enforceTetherAccessPermission(); return mTethering.getTetheredIfaces(); } @Override public String[] getTetheringErroredIfaces() { enforceTetherAccessPermission(); return mTethering.getErroredIfaces(); } @Override public String[] getTetheredDhcpRanges() { enforceConnectivityInternalPermission(); return mTethering.getTetheredDhcpRanges(); } // if ro.tether.denied = true we default to no tethering // gservices could set the secure setting to 1 though to enable it on a build where it // had previously been turned off. @Override public boolean isTetheringSupported() { enforceTetherAccessPermission(); int defaultVal = (mSystemProperties.get("ro.tether.denied").equals("true") ? 0 : 1); boolean tetherEnabledInSettings = (Settings.Global.getInt(mContext.getContentResolver(), Settings.Global.TETHER_SUPPORTED, defaultVal) != 0) && !mUserManager.hasUserRestriction(UserManager.DISALLOW_CONFIG_TETHERING); return tetherEnabledInSettings && mUserManager.isAdminUser() && mTethering.hasTetherableConfiguration(); } @Override public void startTethering(int type, ResultReceiver receiver, boolean showProvisioningUi) {
private boolean updateBssidBlacklist(String bssid, boolean enable, int reasonCode) { if (enable) { return mBssidBlacklist.remove(bssid) != null; } status.blacklistedTimeStamp = mClock.getElapsedSinceBootMillis(); status.counter++; if (!status.isBlacklisted) { if (status.counter >= BSSID_BLACKLIST_THRESHOLD || reasonCode == REASON_CODE_AP_UNABLE_TO_HANDLE_NEW_STA) { status.isBlacklisted = true; return true; } } return false; }
when(mClock.getElapsedSinceBootMillis()).thenReturn(SystemClock.elapsedRealtime() + WifiConnectivityManager.BSSID_BLACKLIST_EXPIRE_TIME_MS); mWifiConnectivityManager.forceConnectivityScan(); assertFalse(mWifiConnectivityManager.isBssidDisabled(bssid)); } /** * When WifiConnectivityManager is on and Wifi client mode is enabled, framework * queries firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability. * * Expected behavior: WifiConnectivityManager#setWifiEnabled calls into * WifiConnectivityHelper#getFirmwareRoamingInfo */ @Test public void verifyGetFirmwareRoamingInfoIsCalledWhenEnableWiFiAndWcmOn() { reset(mWifiConnectivityHelper); // WifiConnectivityManager is on by default mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper).getFirmwareRoamingInfo(); } /** * When WifiConnectivityManager is off, verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode. * * Expected behavior: WifiConnectivityManager#setWifiEnabled does not call into * WifiConnectivityHelper#getFirmwareRoamingIinfo
reset(mWifiConnectivityHelper); // WifiConnectivityManager is on by default mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper).getFirmwareRoamingInfo(); } /** * When WifiConnectivityManager is off, verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode. * * Expected behavior: WifiConnectivityManager#setWifiEnabled does not call into * WifiConnectivityHelper#getFirmwareRoamingInfo */ @Test public void verifyGetFirmwareRoamingInfoIsNotCalledWhenEnableWiFiAndWcmOff() { reset(mWifiConnectivityHelper); mWifiConnectivityManager.enable(false); mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper, times(0)).getFirmwareRoamingInfo(); } /* * Firmware supports controlled roaming. * Connect to a network from the DISCONNECTED state. * * Expected behavior: WifiConnectivityManager calls * WifiStateMachine.startConnectToNetwork() with the * expected candidate network ID, and the BSSID value should be * 'any' since firmware controls the roaming. */ @Test
public void useAnyBssidToConnectWhenFirmwareRoamingOnAndConfigHasNoBssidSpecified() { // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY);
public void noFrameworkRoamingIfConnectedAndFirmwareRoamingSupported() { // Mock the currently connected network which has the same networkID and // SSID as the one to be selected. WifiConfiguration currentNetwork = generateWifiConfig( 0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null); when(mWifiConfigManager.getConfiguredNetwork(anyInt())).thenReturn(currentNetwork); // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set WiFi to connected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_CONNECTED); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); verify(mWifiStateMachine, times(0)).startRoamToNetwork( anyInt(), anyObject());
private void refreshBssidBlacklist() { Iterator<BssidBlacklistStatus> iter = mBssidBlacklist.values().iterator(); Long currentTimeStamp = mClock.getElapsedSinceBootMillis(); while (iter.hasNext()) { BssidBlacklistStatus status = iter.next(); if (status.isBlacklisted && ((currentTimeStamp - status.blacklistedTimeStamp) >= BSSID_BLACKLIST_EXPIRE_TIME_MS)) { iter.remove(); updated = true; } } if (updated && mConnectivityHelper.isFirmwareRoamingSupported()) { updateFirmwareBssidBlacklist(); }
// network(same SSID & security type) as the currently connected one. // This might save a disconnection triggered by network switch when // the score of the currently connected BSSID is lower than a network // with a different SSID, but within the currently connected network // there is a BSSID better than the currently connected BSSID. // This is under the assumption that firmware will roam the device // to that better BSSID. score += mSameBssidAward; sbuf.append(" Firmware roaming equivalent BSSID bonus: ") .append(mSameBssidAward).append(","); } } // When firmware roaming is supported, the same BSSID award is already // applied above, skip it. if (!mConnectivityHelper.isFirmwareRoamingSupported()) { // Same BSSID award. if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward) .append(","); } } // Security award.
data[0] = new StructCapUserData(data[0].effective, data[0].permitted, data[0].permitted); data[1] = new StructCapUserData(data[1].effective, data[1].permitted, data[1].permitted); Os.capset(header, data); } for (int i = 0; i < 64; i++) { int dataIndex = OsConstants.CAP_TO_INDEX(i); int capMask = OsConstants.CAP_TO_MASK(i); if ((data[dataIndex].inheritable & capMask) != 0) { try { Os.prctl(OsConstants.PR_CAP_AMBIENT, OsConstants.PR_CAP_AMBIENT_RAISE, i, 0, 0); } catch (ErrnoException ex) { Slog.e(RuntimeInit.TAG, "RuntimeInit: Failed to raise ambient capability " + i, ex); } } } } catch (Exception e) { Slog.e(RuntimeInit.TAG, "RuntimeInit: Failed to preserve capabilities", e); }
* This is supposed to be from Telephony service. * otherwise we think it is from other applications. * @return Returns true if the country code passed in is acceptable. */ public synchronized boolean setCountryCode(String countryCode) { if (DBG) Log.d(TAG, "Receive set country code request: " + countryCode); // Empty country code. if (TextUtils.isEmpty(countryCode)) { if (DBG) Log.d(TAG, "Received empty country code, reset to default country code"); mTelephonyCountryCode = null; } else { mTelephonyCountryCode = countryCode.toUpperCase(); } // If wpa_supplicant is ready we set the country code now, otherwise it will be // set once wpa_supplicant is ready. if (mReady) { updateCountryCode(); } return true; } /** * Method to get the Country Code that was sent to wpa_supplicant. * * @return Returns the local copy of the Country Code that was sent to the driver upon * setReadyForChange(true).
* See the License for the specific language governing permissions and * limitations under the License. */ package android.system; /** * Constants and helper functions for use with {@link Os}. */ public final class OsConstants { private OsConstants() { } /** * Returns the index of the element in the cap_user_data array that this capability is stored * in. * @hide */ public static int CAP_TO_INDEX(int x) { return x >>> 5; } /** * Returns the mask for the given capability. This is relative to the capability's cap_user_data * element, the index of which can be retrieved with CAP_TO_INDEX. * @hide */ public static int CAP_TO_MASK(int x) { return 1 << (x & 31); } /** * Tests whether the given mode is a block device. */ public static boolean S_ISBLK(int mode) { return (mode & S_IFMT) == S_IFBLK; } /**
refreshBssidBlacklist(); if (mStateMachine.isLinkDebouncing() || mStateMachine.isSupplicantTransientState()) { localLog(listenerName + " onResults: No network selection because linkDebouncing is " + mStateMachine.isLinkDebouncing() + " and supplicantTransient is " + mStateMachine.isSupplicantTransientState()); return false; } localLog(listenerName + " onResults: start network selection"); HashSet<String> blacklistedBssids = buildBssidBlacklist(); WifiConfiguration candidate = mNetworkSelector.selectNetwork(scanDetails, buildBssidBlacklist(), mWifiInfo, mStateMachine.isConnected(), mStateMachine.isDisconnected(), mUntrustedConnectionAllowed); mWifiLastResortWatchdog.updateAvailableNetworks( mNetworkSelector.getFilteredScanDetails()); mWifiMetrics.countScanResults(scanDetails); if (candidate != null) { localLog(listenerName + ": WNS candidate-" + candidate.SSID); connectToNetwork(candidate); return true; } else { return false; }
public void useAnyBssidToConnectWhenFirmwareRoamingOnAndConfigHasNoBssidSpecified() { // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY);
private void localLog(String log) { mLocalLog.log(log);
private void updateEverything() { BatteryInfo info = BatteryInfo.getBatteryInfo(getContext(), mBatteryBroadcast, mStats, SystemClock.elapsedRealtime() * 1000); final View view = getView(); if (mShowCellSignal) { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser, mPhoneParser); } else { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser); } ((TextView) view.findViewById(R.id.charge)).setText(info.batteryPercentString); ((TextView) view.findViewById(R.id.estimation)).setText(info.remainingLabel); bindData(mChargingParser, R.string.battery_stats_charging_label, R.id.charging_group); bindData(mScreenOn, R.string.battery_stats_screen_on_label, R.id.screen_on_group); bindData(mGpsParser, R.string.battery_stats_gps_on_label, R.id.gps_group);
SystemClock.elapsedRealtime() * 1000); final View view = getView(); if (mShowCellSignal) { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser, mPhoneParser); } else { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser); } ((TextView) view.findViewById(R.id.charge)).setText(info.batteryPercentString); ((TextView) view.findViewById(R.id.estimation)).setText(info.remainingLabel); bindData(mChargingParser, R.string.battery_stats_charging_label, R.id.charging_group); bindData(mScreenOn, R.string.battery_stats_screen_on_label, R.id.screen_on_group); bindData(mGpsParser, R.string.battery_stats_gps_on_label, R.id.gps_group); bindData(mFlashlightParser, R.string.battery_stats_flashlight_on_label, R.id.flashlight_group);
bindData(mFlashlightParser, R.string.battery_stats_flashlight_on_label, R.id.flashlight_group); bindData(mCameraParser, R.string.battery_stats_camera_on_label, R.id.camera_group); bindData(mWifiParser, R.string.battery_stats_wifi_running_label, R.id.wifi_group); bindData(mCpuParser, R.string.battery_stats_wake_lock_label, R.id.cpu_group); if (mShowCellSignal) { bindData(mPhoneParser, R.string.battery_stats_phone_signal_label, R.id.cell_network_group); } else { view.findViewById(R.id.cell_network_group).setVisibility(View.GONE); }
// Wait until it finishes and end the reciever then. assertEquals(RESULT_PASS, appEndReceiver.waitForActivity()); appEndReceiver.close(); if (!noHomeScreen()) { // At this time the timerReceiver should not fire, even though the activity has shut // down, because we are back to the home screen. assertEquals(RESULT_TIMEOUT, timeReceiver.waitForActivity()); assertTrue(timeReceiver.mTimeUsed == 0); } else { // With platforms that have no home screen, focus is returned to something else that is // considered a completion of the tracked activity flow, and hence time tracking is // triggered. assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); } // Issuing now another activity will trigger the timing information release. final Intent dummyIntent = new Intent(context, MockApplicationActivity.class); dummyIntent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); final Activity activity = mInstrumentation.startActivitySync(dummyIntent); // Wait until it finishes and end the reciever then. assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); timeReceiver.close(); assertTrue(timeReceiver.mTimeUsed != 0); } /** * Verify that the TimeTrackingAPI works properly when switching away from the monitored task. */
* getPhoneId(DEFAULT_SUB_ID) will return the same as getPhoneId(getDefaultSubId()). * * Finally, any getters which perform the mapping between subscriptions, slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID. All other getters * will fail and return the appropriate error value. Ie calling * getSlotIndex(INVALID_SUBSCRIPTION_ID) will return INVALID_SIM_SLOT_INDEX and calling * getSubInfoForSubscriber(INVALID_SUBSCRIPTION_ID) will return null. * */ public class SubscriptionController extends ISub.Stub { static final String LOG_TAG = "SubscriptionController"; static final boolean DBG = true; static final boolean VDBG = false; static final int MAX_LOCAL_LOG_LINES = 500; // TODO: Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog(MAX_LOCAL_LOG_LINES); /** * Copied from android.util.LocalLog with flush() adding flush and line number * TODO: Update LocalLog */ static class ScLocalLog { private LinkedList<String> mLog;
import java.io.PrintWriter; import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.Iterator; import java.util.LinkedList; import java.util.List; import java.util.Map; import java.util.Map.Entry; import java.util.Set; import java.util.concurrent.ConcurrentHashMap; /** * SubscriptionController to provide an inter-process communication to * access Sms in Icc. * * Any setters which take subId, slotIndex or phoneId as a parameter will throw an exception if the * parameter equals the corresponding INVALID_XXX_ID or DEFAULT_XXX_ID. * * All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID. Ie calling * getPhoneId(DEFAULT_SUB_ID) will return the same as getPhoneId(getDefaultSubId()). * * Finally, any getters which perform the mapping between subscriptions, slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID. All other getters * will fail and return the appropriate error value. Ie calling getSlotId(INVALID_SUBSCRIPTION_ID)
* * All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID. Ie calling * getPhoneId(DEFAULT_SUB_ID) will return the same as getPhoneId(getDefaultSubId()). * * Finally, any getters which perform the mapping between subscriptions, slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID. All other getters * will fail and return the appropriate error value. Ie calling getSlotIndex(INVALID_SUBSCRIPTION_ID) * will return INVALID_SLOT_ID and calling getSubInfoForSubscriber(INVALID_SUBSCRIPTION_ID) * will return null. * */ public class SubscriptionController extends ISub.Stub { static final String LOG_TAG = "SubscriptionController"; static final boolean DBG = true; static final boolean VDBG = false; static final int MAX_LOCAL_LOG_LINES = 500; // TODO: Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog(MAX_LOCAL_LOG_LINES); /** * Copied from android.util.LocalLog with flush() adding flush and line number
} } /** * @return the maximum number of subscriptions this device will support at any one time. */ @Override public int getActiveSubInfoCountMax() { // FIXME: This valid now but change to use TelephonyDevController in the future return mTelephonyManager.getSimCount(); } /** * Add a new SubInfoRecord to subinfo database if needed * @param iccId the IccId of the SIM card * @param slotIndex the slot which the SIM is inserted * @return 0 if success, < 0 on error. */ @Override public int addSubInfoRecord(String iccId, int slotId) { if (DBG) logdl("[addSubInfoRecord]+ iccId:" + SubscriptionInfo.givePrintableIccid(iccId) + " slotId:" + slotId); enforceModifyPhoneState("addSubInfoRecord"); // Now that all security checks passes, perform the operation as ourselves. final long identity = Binder.clearCallingIdentity(); try { if (iccId == null) {
public int addSubInfoRecord(String iccId, int slotId) { if (DBG) logdl("[addSubInfoRecord]+ iccId:" + SubscriptionInfo.givePrintableIccid(iccId) + " slotIndex:" + slotIndex); enforceModifyPhoneState("addSubInfoRecord"); // Now that all security checks passes, perform the operation as ourselves. final long identity = Binder.clearCallingIdentity(); try { if (iccId == null) { if (DBG) logdl("[addSubInfoRecord]- null iccId"); return -1; } ContentResolver resolver = mContext.getContentResolver(); Cursor cursor = resolver.query(SubscriptionManager.CONTENT_URI, new String[]{SubscriptionManager.UNIQUE_KEY_SUBSCRIPTION_ID, SubscriptionManager.SIM_SLOT_INDEX, SubscriptionManager.NAME_SOURCE}, SubscriptionManager.ICC_ID + "=?", new String[]{iccId}, null); int color = getUnusedColor(mContext.getOpPackageName()); boolean setDisplayName = false; try { if (cursor == null || !cursor.moveToFirst()) { setDisplayName = true; ContentValues value = new ContentValues();
public int addSubInfoRecord(String iccId, int slotId) { if (DBG) logdl("[addSubInfoRecord]+ iccId:" + SubscriptionInfo.givePrintableIccid(iccId) + " slotIndex:" + slotIndex); enforceModifyPhoneState("addSubInfoRecord"); // Now that all security checks passes, perform the operation as ourselves. final long identity = Binder.clearCallingIdentity(); try { if (iccId == null) { if (DBG) logdl("[addSubInfoRecord]- null iccId"); return -1; } ContentResolver resolver = mContext.getContentResolver(); Cursor cursor = resolver.query(SubscriptionManager.CONTENT_URI, new String[]{SubscriptionManager.UNIQUE_KEY_SUBSCRIPTION_ID, SubscriptionManager.SIM_SLOT_INDEX, SubscriptionManager.NAME_SOURCE}, SubscriptionManager.ICC_ID + "=?", new String[]{iccId}, null); int color = getUnusedColor(mContext.getOpPackageName()); boolean setDisplayName = false; try { if (cursor == null || !cursor.moveToFirst()) { setDisplayName = true; ContentValues value = new ContentValues();
import com.android.internal.telephony.Phone; import com.android.internal.telephony.PhoneConstants; import com.android.internal.telephony.SubscriptionController; import com.android.internal.telephony.TelephonyIntents; import java.io.FileDescriptor; import java.io.PrintWriter; import java.util.concurrent.atomic.AtomicInteger; import java.util.List; // must extend SubscriptionController as some people use it directly within-process public class SubscriptionControllerMock extends SubscriptionController { final AtomicInteger mDefaultDataSubId = new AtomicInteger(INVALID_SUBSCRIPTION_ID); final ITelephonyRegistry.Stub mTelephonyRegistry; final int[][] mSlotIndexToSubId; public static SubscriptionController init(Phone phone) { throw new RuntimeException("not implemented"); } public static SubscriptionController init(Context c, CommandsInterface[] ci) { throw new RuntimeException("not implemented"); } public static SubscriptionController getInstance() { throw new RuntimeException("not implemented"); } public SubscriptionControllerMock(Context c, ITelephonyRegistry.Stub tr, int phoneCount) { super(c); mTelephonyRegistry = tr; mSlotIdxToSubId = new int[phoneCount][];
public SubscriptionInfo getActiveSubscriptionInfoForSimSlotIndex(int slotIndex, String cp){ throw new RuntimeException("not implemented");
private boolean isInvalidSlotId(int slotIndex) { if (slotIndex < 0 || slotIndex >= mSlotIndexToSubId.length) return true; return false;
public int[] getSubId(int slotIndex) { if (isInvalidSlotId(slotIndex)) { return null; } return mSlotIdxToSubId[slotIdx];
public void setSlotSubId(int slotIndex, int subId) { if (isInvalidSlotId(slotIndex)) { throw new RuntimeException("invalid slot specified" + slotIndex); } if (mSlotIdxToSubId[slotIdx][0] != subId) { mSlotIdxToSubId[slotIdx][0] = subId; try { mTelephonyRegistry.notifySubscriptionInfoChanged(); } catch (RemoteException ex) {} }
public SubscriptionInfo getActiveSubscriptionInfoForSimSlotIndex(int slotIndex, String callingPackage) { if (!canReadPhoneState(callingPackage, "getActiveSubscriptionInfoForSimSlotIndex")) { return null; } // Now that all security checks passes, perform the operation as ourselves. final long identity = Binder.clearCallingIdentity(); try { List<SubscriptionInfo> subList = getActiveSubscriptionInfoList( mContext.getOpPackageName()); if (subList != null) { for (SubscriptionInfo si : subList) { if (si.getSimSlotIndex() == slotIdx) { if (DBG) { logd("[getActiveSubscriptionInfoForSimSlotIndex]+ slotIdx=" + slotIdx + " subId=" + si); } return si; } } if (DBG) { logd("[getActiveSubscriptionInfoForSimSlotIndex]+ slotIdx=" + slotIdx + " subId=null"); } } else { if (DBG) { logd("[getActiveSubscriptionInfoForSimSlotIndex]+ subList=null"); } } } finally { Binder.restoreCallingIdentity(identity); }
public int[] getSubId(int slotIndex) { if (VDBG) printStackTrace("[getSubId]+ slotIndex=" + slotIndex); // Map default slotIdx to the current default subId. // TODO: Not used anywhere sp consider deleting as it's somewhat nebulous // as a slot maybe used for multiple different type of "connections" // such as: voice, data and sms. But we're doing the best we can and using // getDefaultSubId which makes a best guess. if (slotIdx == SubscriptionManager.DEFAULT_SIM_SLOT_INDEX) { slotIdx = getSlotId(getDefaultSubId()); if (VDBG) logd("[getSubId] map default slotIdx=" + slotIdx); } // Check that we have a valid SlotIdx if (!SubscriptionManager.isValidSlotId(slotIdx)) { if (DBG) logd("[getSubId]- invalid slotIdx=" + slotIdx); return null; } // Check if we've got any SubscriptionInfo records using slotIdToSubId as a surrogate. int size = sSlotIdxToSubId.size();
private int[] getDummySubIds(int slotIndex) { // FIXME: Remove notion of Dummy SUBSCRIPTION_ID. // I tested this returning null as no one appears to care, // but no connection came up on sprout with two sims. // We need to figure out why and hopefully remove DummySubsIds!!! int numSubs = getActiveSubInfoCountMax(); if (numSubs > 0) { int[] dummyValues = new int[numSubs]; for (int i = 0; i < numSubs; i++) { dummyValues[i] = SubscriptionManager.DUMMY_SUBSCRIPTION_ID_BASE - slotIdx; } if (VDBG) { logd("getDummySubIds: slotIdx=" + slotIdx + " return " + numSubs + " DummySubIds with each subId=" + dummyValues[0]); } return dummyValues; } else { return null; }
pw.println(" defaultDataPhoneId=" + SubscriptionManager .from(mContext).getDefaultDataPhoneId()); pw.println(" defaultVoicePhoneId=" + SubscriptionManager.getDefaultVoicePhoneId()); pw.println(" defaultSmsPhoneId=" + SubscriptionManager .from(mContext).getDefaultSmsPhoneId()); pw.flush(); for (Entry<Integer, Integer> entry : sSlotIndexToSubId.entrySet()) { pw.println(" sSlotIndexToSubId[" + entry.getKey() + "]: subId=" + entry.getValue()); } pw.flush(); pw.println("++++++++++++++++++++++++++++++++"); List<SubscriptionInfo> sirl = getActiveSubscriptionInfoList( mContext.getOpPackageName()); if (sirl != null) { pw.println(" ActiveSubInfoList:"); for (SubscriptionInfo entry : sirl) { pw.println(" " + entry.toString()); } } else { pw.println(" ActiveSubInfoList: is null"); } pw.flush(); pw.println("++++++++++++++++++++++++++++++++"); sirl = getAllSubInfoList(mContext.getOpPackageName()); if (sirl != null) {
import com.android.internal.telephony.Phone; import com.android.internal.telephony.PhoneConstants; import com.android.internal.telephony.SubscriptionController; import com.android.internal.telephony.TelephonyIntents; import java.io.FileDescriptor; import java.io.PrintWriter; import java.util.concurrent.atomic.AtomicInteger; import java.util.List; // must extend SubscriptionController as some people use it directly within-process public class SubscriptionControllerMock extends SubscriptionController { final AtomicInteger mDefaultDataSubId = new AtomicInteger(INVALID_SUBSCRIPTION_ID); final ITelephonyRegistry.Stub mTelephonyRegistry; final int[][] mSlotIndexToSubId; public static SubscriptionController init(Phone phone) { throw new RuntimeException("not implemented"); } public static SubscriptionController init(Context c, CommandsInterface[] ci) { throw new RuntimeException("not implemented"); } public static SubscriptionController getInstance() { throw new RuntimeException("not implemented"); } public SubscriptionControllerMock(Context c, ITelephonyRegistry.Stub tr, int phoneCount) { super(c); mTelephonyRegistry = tr; mSlotIdxToSubId = new int[phoneCount][];
public SubscriptionInfo getActiveSubscriptionInfoForSimSlotIndex(int slotIndex, String cp){ throw new RuntimeException("not implemented");
private boolean isInvalidSlotId(int slotIndex) { if (slotIndex < 0 || slotIndex >= mSlotIndexToSubId.length) return true; return false;
public void setSlotSubId(int slotIndex, int subId) { if (isInvalidSlotId(slotIndex)) { throw new RuntimeException("invalid slot specified" + slotIndex); } if (mSlotIdxToSubId[slotIdx][0] != subId) { mSlotIdxToSubId[slotIdx][0] = subId; try { mTelephonyRegistry.notifySubscriptionInfoChanged(); } catch (RemoteException ex) {} }
private static String getEtwsPrimaryMessage(Context context, int category) { final Resources r = context.getResources(); switch (category) { case ETWS_WARNING_TYPE_EARTHQUAKE: return r.getString(R.string.etws_primary_default_message_earthquake); case ETWS_WARNING_TYPE_TSUNAMI: return r.getString(R.string.etws_primary_default_message_tsunami); case ETWS_WARNING_TYPE_EARTHQUAKE_AND_TSUNAMI: return r.getString(R.string.etws_primary_default_message_earthquake_and_tsunami); case ETWS_WARNING_TYPE_TEST_MESSAGE: return r.getString(R.string.etws_primary_default_message_test); case ETWS_WARNING_TYPE_OTHER_EMERGENCY: return r.getString(R.string.etws_primary_default_message_others); default: return ""; }
* * @param subId The subscription ID * @return true if the network for the subscription is roaming, false otherwise */ public boolean isNetworkRoaming(int subId) { final int phoneId = getPhoneId(subId); if (phoneId < 0) { // What else can we do? return false; } return TelephonyManager.getDefault().isNetworkRoaming(subId); } /** * Returns a constant indicating the state of sim for the slot index. * * @param slotIndex * * {@See TelephonyManager#SIM_STATE_UNKNOWN} * {@See TelephonyManager#SIM_STATE_ABSENT} * {@See TelephonyManager#SIM_STATE_PIN_REQUIRED} * {@See TelephonyManager#SIM_STATE_PUK_REQUIRED} * {@See TelephonyManager#SIM_STATE_NETWORK_LOCKED} * {@See TelephonyManager#SIM_STATE_READY} * {@See TelephonyManager#SIM_STATE_NOT_READY} * {@See TelephonyManager#SIM_STATE_PERM_DISABLED} * {@See TelephonyManager#SIM_STATE_CARD_IO_ERROR} * * {@hide} */
ServiceStateTable.DATA_OPERATOR_NUMERIC, ServiceStateTable.IS_MANUAL_NETWORK_SELECTION, ServiceStateTable.RIL_VOICE_RADIO_TECHNOLOGY, ServiceStateTable.RIL_DATA_RADIO_TECHNOLOGY, ServiceStateTable.CSS_INDICATOR, ServiceStateTable.NETWORK_ID, ServiceStateTable.SYSTEM_ID, ServiceStateTable.CDMA_ROAMING_INDICATOR, ServiceStateTable.CDMA_DEFAULT_ROAMING_INDICATOR, ServiceStateTable.CDMA_ERI_ICON_INDEX, ServiceStateTable.CDMA_ERI_ICON_MODE, ServiceStateTable.IS_EMERGENCY_ONLY, ServiceStateTable.IS_DATA_ROAMING_FROM_REGISTRATION, ServiceStateTable.IS_USING_CARRIER_AGGREGATION, }; @Override public boolean onCreate() { mServiceState = new ServiceState(); mServiceState.setStateOutOfService(); return true; } @Override public Uri insert(Uri uri, ContentValues values) { throw new RuntimeException("Not supported"); } @Override public int delete(Uri uri, String selection, String[] selectionArgs) { throw new RuntimeException("Not supported"); } @Override public int update(Uri uri, ContentValues values, String selection, String[] selectionArgs) { throw new RuntimeException("Not supported"); } @Override public String getType(Uri uri) { if (ServiceStateTable.CONTENT_URI.equals(uri)) {
voice_operator_numeric, data_operator_alpha_long, data_operator_alpha_short, data_operator_numeric, is_manual_network_selection, ril_voice_radio_technology, ril_data_radio_technology, css_indicator, network_id, system_id, cdma_roaming_indicator, cdma_default_roaming_indicator, cdma_eri_icon_index, cdma_eri_icon_mode, is_emergency_only, is_data_roaming_from_registration, is_using_carrier_aggregation, }); }
MESSAGE_FORMAT, MESSAGE_PRIORITY, ETWS_WARNING_TYPE, CMAS_MESSAGE_CLASS, CMAS_CATEGORY, CMAS_RESPONSE_TYPE, CMAS_SEVERITY, CMAS_URGENCY, CMAS_CERTAINTY }; } /** * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri.parse("content://service-state/"); /** * Used to push and receive updates to a field in the ServiceState for a given subId * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId(String field, int subId) {
CMAS_RESPONSE_TYPE, CMAS_SEVERITY, CMAS_URGENCY, CMAS_CERTAINTY }; } /** * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri.parse("content://service-state/"); /** * Used to push and receive updates to a field in the ServiceState for a given subId * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId(String field, int subId) { return CONTENT_URI.buildUpon().appendEncodedPath(String.valueOf(subId)) .appendEncodedPath(field).build(); }
public static Uri getUriForFieldAndSubId(String field, int subId) { return CONTENT_URI.buildUpon().appendEncodedPath(String.valueOf(subId)) .appendEncodedPath(field).build();
+ something.getClass().getName() + " to byte array!"); } } public AdvertiseData buildAdvData(JSONObject params) throws Exception { AdvertiseData.Builder builder = new AdvertiseData.Builder(); Iterator<String> keys = params.keys(); while (keys.hasNext()) { String key = keys.next(); /** Python doesn't have multi map, if advertise data should repeat use * serviceUuid, serviceUuid2, serviceUuid3... . For that use "startsWith" */ if (key.startsWith("manufacturerData")) { JSONArray manuf = params.getJSONArray(key); int manufId = manuf.getInt(0); byte[] data = somethingToByteArray(manuf.get(1)); builder.addManufacturerData(manufId, data); } else if (key.startsWith("serviceData")) { JSONArray serDat = params.getJSONArray(key); ParcelUuid uuid = ParcelUuid.fromString(serDat.getString(0)); byte[] data = somethingToByteArray(serDat.get(1)); builder.addServiceData(uuid, data); } else if (key.startsWith("serviceUuid")) {
+ something.getClass().getName() + " to byte array!"); } } public AdvertiseData buildAdvData(JSONObject params) throws Exception { AdvertiseData.Builder builder = new AdvertiseData.Builder(); Iterator<String> keys = params.keys(); while (keys.hasNext()) { String key = keys.next(); /** Python doesn't have multi map, if advertise data should repeat use * serviceUuid, serviceUuid2, serviceUuid3... . For that use "startsWith" */ if (key.startsWith("manufacturerData")) { JSONArray manuf = params.getJSONArray(key); int manufId = manuf.getInt(0); byte[] data = somethingToByteArray(manuf.get(1)); builder.addManufacturerData(manufId, data); } else if (key.startsWith("serviceData")) { JSONArray serDat = params.getJSONArray(key); ParcelUuid uuid = ParcelUuid.fromString(serDat.getString(0)); byte[] data = somethingToByteArray(serDat.get(1)); builder.addServiceData(uuid, data); } else if (key.startsWith("serviceUuid")) {
public PeriodicAdvertisingParameters buildPeriodicParameters(JSONObject params) throws Exception { PeriodicAdvertisingParameters.Builder builder = new PeriodicAdvertisingParameters.Builder(); Iterator<String> keys = params.keys(); while (keys.hasNext()) { String key = keys.next(); if (key.equals("enable")) { builder.setEnable(params.getBoolean(key)); } else if (key.equals("includeTxPower")) { builder.setIncludeTxPower(params.getBoolean(key)); } else if (key.equals("interval")) { builder.setInterval(params.getInt(key)); } else { throw new IllegalArgumentException( "Unknown PeriodicAdvertisingParameters field " + key); } } return builder.build(); } /** * Starts ble advertising * * @throws Exception */ @Rpc(description = "Starts ble advertisement") public void bleAdvSetStartAdvertisingSet( @RpcParameter(name = "params") JSONObject parametersJson, @RpcParameter(name = "data") JSONObject dataJson, @RpcParameter(name = "scanResponse") JSONObject scanResponseJson, @RpcParameter(name = "periodicParameters") JSONObject periodicParametersJson,
public void useAnyBssidToConnectWhenFirmwareRoamingOnAndConfigHasNoBssidSpecified() { // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY);
private int readHighTagNumber() throws BerDataValueFormatException { // Base-128 big-endian form, where each byte has the highest bit set, except for the last // byte int b; int result = 0; do { if (!mBuf.hasRemaining()) { throw new BerDataValueFormatException("Truncated tag number"); } b = mBuf.get(); result <<= 7; result += b & 0x7f; if (result < 0) { throw new BerDataValueFormatException("Tag number too large"); } result <<= 7; result |= b & 0x7f; } while ((b & 0x80) != 0); return result; } private int readShortFormLength(int firstLengthByte) throws BerDataValueFormatException { return firstLengthByte & 0x7f; } private int readLongFormLength(int firstLengthByte) throws BerDataValueFormatException { // The low 7 bits of the first byte represent the number of bytes (following the first // byte) in which the length is in big-endian base-256 form int byteCount = firstLengthByte & 0x7f;
"Truncated indefinite-length contents: " + bytesRead + " bytes read"); } int b = mBuf.get(); bytesRead++; if (bytesRead < 0) { throw new BerDataValueFormatException("Indefinite-length contents too long"); } if (b == 0) { if (prevZeroByte) { // End of contents reached -- we've read the value and its terminator 0x00 0x00 return bytesRead - 2; } prevZeroByte = true; } else { prevZeroByte = false; } } } }
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.rs.rsov.test; import android.content.Context; import android.renderscript.Allocation; import android.renderscript.Element; import android.renderscript.RenderScript; import android.renderscript.Type; import android.util.Log; public class UT_global_query extends UnitTest { protected UT_global_query(RSoVTestCore rstc, Context ctx) { super(rstc, "global_query", ctx); }
req.channelRequestType = channelRequestType; req.channel = channel; req.ifaceName = interfaceName; req.securityRequired = !((pmk == null || pmk.length == 0) && (passphrase == null || passphrase.length() == 0)); if (req.securityRequired) { req.cipherType = getStrongestCipherSuiteType(capabilities.supportedCipherSuites); if (pmk != null && pmk.length != 0) { convertLcByteToUcByteArray(pmk, req.pmk); } else { convertLcByteToUcByteArray(passphrase.getBytes(), req.passphrase); } } if (passphrase != null && passphrase.length() != 0) { req.cipherType = getStrongestCipherSuiteType(capabilities.supportedCipherSuites); req.securityConfig = NanDataPathSecurityConfig.PASSPHRASE; convertNativeByteArrayToArrayList(passphrase.getBytes(), req.passphrase); } try { WifiStatus status = iface.initiateDataPathRequest(transactionId, req); if (status.code == WifiStatusCode.SUCCESS) { return true; } else { Log.e(TAG, "initiateDataPath: error: " + statusString(status)); return false; } } catch (RemoteException e) { Log.e(TAG, "initiateDataPath: exception: " + e); return false; }
public boolean setWfdEnable(boolean enable) { return mSupplicantP2pIfaceHal.enableWfd(enable); } /** * Set Wifi Display device info. * * @param hex WFD device info as described in section 5.1.2 of WFD technical * specification v1.0.0. * @return true, if operation was successful. */ public boolean setWfdDeviceInfo(String hex) { return mSupplicantP2pIfaceHal.setWfdDeviceInfo(hex); } /** * Initiate a P2P service discovery indefinitely. * Will trigger {@link WifiP2pMonitor#P2P_DEVICE_FOUND_EVENT} on finding devices. * * @return boolean value indicating whether operation was successful. */ public boolean p2pFind() { return p2pFind(0); } /** * Initiate a P2P service discovery with a (optional) timeout. * * @param timeout Max time to be spent is peforming discovery. * Set to 0 to indefinely continue discovery untill and explicit * |stopFind| is sent. * @return boolean value indicating whether operation was successful. */ public boolean p2pFind(int timeout) {
import java.io.IOException; import java.util.Map; import java.util.concurrent.atomic.AtomicReference; public class ToyVpnService extends VpnService implements Handler.Callback, ToyVpnConnection.Listener { private static final String TAG = ToyVpnService.class.getSimpleName(); public static final String ACTION_CONNECT = "com.example.android.toyvpn.START"; public static final String ACTION_DISCONNECT = "com.example.android.toyvpn.STOP"; private Handler mHandler; private SparseArray<Thread> mThreads = new SparseArray<>(); private AtomicInteger mNextConnectionId = new AtomicInteger(1); private AtomicReference<ParcelFileDescriptor> mTunnelInterface = new AtomicReference<>(); private PendingIntent mConfigureIntent; @Override public void onCreate() { // The handler is only used to show messages. if (mHandler == null) { mHandler = new Handler(this); } // Create the intent to "configure" the connection (just start ToyVpnClient). mConfigureIntent = PendingIntent.getActivity(this, 0, new Intent(this, ToyVpnClient.class), PendingIntent.FLAG_UPDATE_CURRENT); } @Override
public int onStartCommand(Intent intent, int flags, int startId) { if (ACTION_DISCONNECT.equals(intent.getAction())) { disconnect(); } else { connect(); }
public boolean handleMessage(Message message) { Toast.makeText(this, message.what, Toast.LENGTH_SHORT).show(); if (message.what != R.string.disconnected) { updateForegroundNotification(message.what); } return true;
} final ParcelFileDescriptor oldInterface = mTunnelInterface.getAndSet(tunInterface); if (oldInterface != null) { try { Log.i(TAG, "Closing interface: " + oldInterface); oldInterface.close(); } catch (IOException e){ Log.e(TAG, "Closing interface failed", e); } } } @Override public synchronized void onDisconnect(int connectionId) { mThreads.remove(connectionId); } @Override public void onRevoke() { disconnect(); } private void connect() { // Become a foreground service. Background services can be VPN services too, but they can // be killed by background check before getting a chance to receive onRevoke(). updateForegroundNotification(R.string.connecting); mHandler.sendEmptyMessage(R.string.connecting); final SharedPreferences prefs = getSharedPreferences(ToyVpnClient.Prefs.NAME, MODE_PRIVATE); final ToyVpnConnection connection; try { // Extract information from the shared preferences. connection = new ToyVpnConnection(this, this, mNextConnectionId, prefs.getString(ToyVpnClient.Prefs.SERVER_ADDRESS, ""),
import org.junit.After; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.ArgumentCaptor; import org.mockito.Mock; import org.mockito.MockitoAnnotations; import static android.Manifest.permission.MODIFY_PHONE_STATE; import static android.Manifest.permission.READ_PHONE_STATE; import static com.android.internal.telephony.ims.ImsResolver.SERVICE_INTERFACE; import static junit.framework.Assert.assertEquals; import static junit.framework.Assert.assertNotNull; import static junit.framework.Assert.assertNull; import static junit.framework.Assert.fail; import static org.mockito.Matchers.anyInt; import static org.mockito.Matchers.anyString; import static org.mockito.Matchers.eq; import static org.mockito.Matchers.nullable; import static org.mockito.Mockito.doThrow; import static org.mockito.Mockito.never; import static org.mockito.Mockito.times; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.when; /** * Unit tests for ImsService */ @RunWith(AndroidJUnit4.class) public class ImsServiceTest { private static final int TEST_SLOT_0 = 0; private static final int TEST_SLOT_1 = 1;
// Mock the HeadsetService when(mockServiceFactory.getHeadsetService()).thenReturn(mockHeadsetService); when(mockHeadsetService.getPriority(device)) .thenReturn(BluetoothProfile.PRIORITY_UNDEFINED); // Mock the A2DP service when(mockServiceFactory.getA2dpService()).thenReturn(mockA2dpService); when(mockA2dpService.getPriority(device)).thenReturn(BluetoothProfile.PRIORITY_UNDEFINED); // Mock the looper when(mockAdapterService.getMainLooper()).thenReturn(mHandlerThread.getLooper()); // Tell the AdapterService that it is a mock (see isMock documentation) when(mockAdapterService.isMock()).thenReturn(true); PhonePolicy phPol = new PhonePolicy(mockAdapterService, mockServiceFactory); // Get the broadcast receiver to inject events. BroadcastReceiver injector = phPol.getBroadcastReceiver(); // Inject an event for UUIDs updated for a remote device with only HFP enabled Intent intent = new Intent(BluetoothDevice.ACTION_UUID); intent.putExtra(BluetoothDevice.EXTRA_DEVICE, device); ParcelUuid[] uuids = new ParcelUuid[2]; uuids[0] = BluetoothUuid.Handsfree; uuids[1] = BluetoothUuid.AudioSink;
import com.android.internal.telephony.MmiCode; import com.android.internal.telephony.Phone; import com.android.internal.telephony.PhoneConstants; import java.util.List; /** * Used to display a dialog from within the Telephony service when running an USSD code */ public class MMIDialogActivity extends Activity { private static final String TAG = MMIDialogActivity.class.getSimpleName(); private Dialog mMMIDialog; private Handler mHandler; private CallManager mCM = PhoneGlobals.getInstance().getCallManager(); private Phone mPhone; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); Intent intent = getIntent(); int subId = intent.getIntExtra(PhoneConstants.SUBSCRIPTION_KEY, SubscriptionManager.DEFAULT_SUBSCRIPTION_ID); mPhone = PhoneGlobals.getPhone(subId); mHandler = new Handler() { @Override public void handleMessage(Message msg) { switch (msg.what) { case PhoneGlobals.MMI_COMPLETE: onMMIComplete((MmiCode) ((AsyncResult) msg.obj).result); break; case PhoneGlobals.MMI_CANCEL: onMMICancel();
// Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY); } /* * Firmware supports controlled roaming. * Connect to a network which has a config specified BSSID. * * Expected behavior: WifiConnectivityManager calls * WifiStateMachine.startConnectToNetwork() with the * expected candidate network ID, and the BSSID value should be * 'any' since firmware controls the roaming. */ @Test public void useAnyBssidToConnectWhenFirmwareRoamingOnAndConfigHasBssidSpecified() { // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set up the candidate configuration such that it has a BSSID specified. WifiConfiguration candidate = generateWifiConfig( 0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null);
anyBoolean(), anyBoolean())).thenReturn(candidate); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY); } /* * Firmware does not support controlled roaming. * Connect to a network which doesn't have a config specified BSSID. * * Expected behavior: WifiConnectivityManager calls * WifiStateMachine.startConnectToNetwork() with the expected candidate network ID, * and the BSSID value should be the candidate scan result specified. */ @Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified() { // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine, atLeastOnce()).startConnectToNetwork( CANDIDATE_NETWORK_ID, CANDIDATE_BSSID); } /*
public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified() { // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork(CANDIDATE_NETWORK_ID, CANDIDATE_BSSID);
*/ @Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified() { // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine, atLeastOnce()).startConnectToNetwork( CANDIDATE_NETWORK_ID, CANDIDATE_BSSID); } /* * Firmware does not support controlled roaming. * Connect to a network which has a config specified BSSID. * * Expected behavior: WifiConnectivityManager calls * WifiStateMachine.startConnectToNetwork() with the expected candidate network ID, * and the BSSID value should be the config specified one. */ @Test public void useConfigSpecifiedBssidToConnectionWhenFirmwareRoamingOff() { // Set up the candidate configuration such that it has a BSSID specified. WifiConfiguration candidate = generateWifiConfig( 0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null); candidate.BSSID = CANDIDATE_BSSID; // config specified ScanResult candidateScanResult = new ScanResult();
candidateScanResult.SSID = CANDIDATE_SSID; candidateScanResult.BSSID = CANDIDATE_BSSID; candidate.getNetworkSelectionStatus().setCandidate(candidateScanResult); when(mWifiNS.selectNetwork(anyObject(), anyObject(), anyObject(), anyBoolean(), anyBoolean(), anyBoolean())).thenReturn(candidate); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork(CANDIDATE_NETWORK_ID, CANDIDATE_BSSID);
} updateAlwaysOnNotification(detailedState); } /** * Chooses whether to force all connections to go though VPN. * * Used to enable/disable legacy VPN lockdown. This uses the same rule-based mechanism as * {@link #setAlwaysOnPackage(String, boolean)}; previous settings from calling that function * will be replaced. * * @param lockdown whether to prevent all traffic outside of a VPN. */ public synchronized void setLockdown(boolean lockdown) { enforceControlPermissionOrInternalCaller(); // Explicitly disable previous settings from always-on app VPN if it was set up, to avoid // getting into a confusing state with both enabled at the same time. if (mAlwaysOn) { setAlwaysOnPackage(null, false); } // Apply the new lockdown rules. setVpnForcedLocked(lockdown); mLockdown = lockdown; } /** * Configures an always-on VPN connection through a specific application. * This connection is automatically granted and persisted after a reboot. *
* * @param lockdown whether to prevent all traffic outside of a VPN. */ public synchronized void setLockdownEnabled(boolean lockdown) { enforceControlPermissionOrInternalCaller(); // Explicitly disable previous settings from always-on app VPN if it was set up, to avoid // getting into a confusing state with both enabled at the same time. if (mAlwaysOn) { setAlwaysOnPackage(null, false); } // Apply the new lockdown rules. setVpnForcedLocked(lockdown); mLockdown = lockdown; // Update app lockdown setting if it changed. Legacy VPN lockdown status is controlled by // LockdownVpnTracker.isEnabled() which keeps track of its own state. if (mAlwaysOn) { saveAlwaysOnPackage(); } } /** * Configures an always-on VPN connection through a specific application. * This connection is automatically granted and persisted after a reboot. * * <p>The designated package should exist and declare a {@link VpnService} in its * manifest guarded by {@link android.Manifest.permission.BIND_VPN_SERVICE}, * otherwise the call will fail. * * @param packageName the package to designate as always-on VPN supplier. * @param lockdown whether to prevent traffic outside of a VPN, for example while connecting.
private void setVpnForcedLocked(boolean enforce) { final List<String> exemptedPackages = isNullOrLegacyVpn(mPackage) ? null : Collections.singletonList(mPackage); setVpnForcedWithExemptionsLocked(enforce, exemptedPackages);
private void setVpnForcedWithExemptionsLocked(boolean enforce, @Nullable List<String> exemptedPackages) { final Set<UidRange> removedRanges = new ArraySet<>(mBlockedUsers); final Set<UidRange> addedRanges; if (enforce) { addedRanges = createUserAndRestrictedProfilesRanges(mUserHandle, /* allowedApplications */ null, /* disallowedApplications */ exemptedPackages); removedRanges.removeAll(addedRanges); addedRanges.removeAll(mBlockedUsers); } setAllowOnlyVpnForUids(false, removedRanges); setAllowOnlyVpnForUids(true, addedRanges);
private void setVpnForcedWithExemptionsLocked(boolean enforce, @Nullable List<String> exemptedPackages) { final Set<UidRange> removedRanges = new ArraySet<>(mBlockedUsers); final Set<UidRange> addedRanges; if (enforce) { addedRanges = createUserAndRestrictedProfilesRanges(mUserHandle, /* allowedApplications */ null, /* disallowedApplications */ exemptedPackages); removedRanges.removeAll(addedRanges); addedRanges.removeAll(mBlockedUsers); } setAllowOnlyVpnForUids(false, removedRanges); setAllowOnlyVpnForUids(true, addedRanges);
* instances representing the type variable. However, all instances * representing a type variable must be equal() to each other. * As a consequence, users of type variables must not rely on the identity * of instances of classes implementing this interface. * * @param <D> the type of generic declaration that declared the * underlying type variable. * * @since 1.5 */ // Android-changed: Removed AnnotatedElement super-class due to excluded support // for runtime type annotations public interface TypeVariable<D extends GenericDeclaration> extends Type { /** * Returns an array of {@code Type} objects representing the * upper bound(s) of this type variable. Note that if no upper bound is * explicitly declared, the upper bound is {@code Object}. * * <p>For each upper bound B: <ul> <li>if B is a parameterized * type or a type variable, it is created, (see {@link * java.lang.reflect.ParameterizedType ParameterizedType} for the
* @param log WifiLog object to assign to the clientHandler */ @VisibleForTesting public void setWifiHandlerLogForTest(WifiLog log) { mClientHandler.setWifiLog(log); } /** * Check if we are ready to start wifi. * * This function is used only at boot time */ public void checkAndStartWifi() { // First check if we will end up restarting WifiService if (mFrameworkFacade.inStorageManagerCryptKeeperBounce()) { Log.d(TAG, "Device still encrypted. Need to restart SystemServer. Do not start wifi."); return; } // Check if wi-fi needs to be enabled boolean wifiEnabled = mSettingsStore.isWifiToggleEnabled(); Slog.i(TAG, "WifiService starting up with Wi-Fi " + (wifiEnabled ? "enabled" : "disabled")); registerForScanModeChange();
public void testWifiDoesNotStartWhenDeviceTriggerResetMainAtBoot() { when(mFrameworkFacade.inStorageManagerCryptKeeperBounce()).thenReturn(true); when(mSettingsStore.isWifiToggleEnabled()).thenReturn(false); mWifiServiceImpl.checkAndStartWifi(); verify(mWifiController, never()).start();
public void testWifiStartsWhenDeviceIsDecryptedAtBootWithWifiDisabled() { when(mFrameworkFacade.inStorageManagerCryptKeeperBounce()).thenReturn(false); when(mSettingsStore.isWifiToggleEnabled()).thenReturn(false); mWifiServiceImpl.checkAndStartWifi(); verify(mWifiController).start(); verify(mWifiController, never()).sendMessage(CMD_WIFI_TOGGLED);
public void testWifiStartsWhenDeviceIsDecryptedAtBootWithWifiEnabled() { when(mFrameworkFacade.inStorageManagerCryptKeeperBounce()).thenReturn(false); when(mSettingsStore.handleWifiToggled(true)).thenReturn(true); when(mSettingsStore.isWifiToggleEnabled()).thenReturn(true); when(mWifiStateMachine.syncGetWifiState()).thenReturn(WIFI_STATE_DISABLED); mWifiServiceImpl.checkAndStartWifi(); verify(mWifiController).start(); verify(mWifiController).sendMessage(CMD_WIFI_TOGGLED);
public static final int SUP_DISCONNECTION_EVENT = BASE + 2; /* Network connection completed */ public static final int NETWORK_CONNECTION_EVENT = BASE + 3; /* Network disconnection completed */ public static final int NETWORK_DISCONNECTION_EVENT = BASE + 4; /* Scan results are available */ public static final int SCAN_RESULTS_EVENT = BASE + 5; /* Scheduled scan results are available */ public static final int SCHED_SCAN_RESULTS_EVENT = BASE + 6; /* Supplicate state changed */ public static final int SUPPLICANT_STATE_CHANGE_EVENT = BASE + 6; /* Password failure and EAP authentication failure */ public static final int AUTHENTICATION_FAILURE_EVENT = BASE + 8; /* WPS success detected */ public static final int WPS_SUCCESS_EVENT = BASE + 9; /* WPS failure detected */ public static final int WPS_FAIL_EVENT = BASE + 10; /* WPS overlap detected */ public static final int WPS_OVERLAP_EVENT = BASE + 11; /* WPS timeout detected */
public void OnPnoNetworkFound() { Log.d(TAG, "Pno scan result event"); mWifiMonitor.broadcastPnoScanResultEvent(mClientInterfaceName);
android.provider.Settings.Global.SETUP_PREPAID_DATA_SERVICE_URL)); if (!isLteOnCdma || missingDataServiceUrl) { prefSet.removePreference(mLteDataServicePref); } else { android.util.Log.d(LOG_TAG, "keep ltePref"); } // Hide enhanced 4G LTE mode settings when either it is not supported by platform or // 'KEY_HIDE_ENHANCED_4G_LTE_BOOL' is true. if (!(ImsManager.isVolteEnabledByPlatform(getActivity()) && ImsManager.isVolteProvisionedOnDevice(getActivity())) || carrierConfig.getBoolean( CarrierConfigManager.KEY_HIDE_ENHANCED_4G_LTE_BOOL)) { Preference pref = prefSet.findPreference(BUTTON_4G_LTE_KEY); if (pref != null) { prefSet.removePreference(pref); } } ActionBar actionBar = getActivity().getActionBar(); if (actionBar != null) { // android.R.id.home will be triggered in onOptionsItemSelected() actionBar.setDisplayHomeAsUpEnabled(true); } // Enable link to CMAS app settings depending on the value in config.xml.
if (!isLteOnCdma || missingDataServiceUrl) { prefSet.removePreference(mLteDataServicePref); } else { android.util.Log.d(LOG_TAG, "keep ltePref"); } // Hide enhanced 4G LTE mode settings when either it is not supported by platform or // 'KEY_HIDE_ENHANCED_4G_LTE_BOOL' is true. if (!(ImsManager.isVolteEnabledByPlatform(getActivity()) && ImsManager.isVolteProvisionedOnDevice(getActivity())) || carrierConfig.getBoolean( CarrierConfigManager.KEY_HIDE_ENHANCED_4G_LTE_BOOL)) { Preference pref = prefSet.findPreference(BUTTON_4G_LTE_KEY); if (pref != null) { prefSet.removePreference(pref); } } ActionBar actionBar = getActivity().getActionBar(); if (actionBar != null) { // android.R.id.home will be triggered in onOptionsItemSelected() actionBar.setDisplayHomeAsUpEnabled(true); } // Enable link to CMAS app settings depending on the value in config.xml. final boolean isCellBroadcastAppLinkEnabled = getActivity().getResources().getBoolean(
assertFalse(nc.hasCapability(NET_CAPABILITY_INTERNET)); } @Test public void testNetworkCapabilitiesForTypeBluetooth() { verifyUnrestrictedNetworkCapabilities( ConnectivityManager.TYPE_BLUETOOTH, TRANSPORT_BLUETOOTH); } @Test public void testNetworkCapabilitiesForTypeEthernet() { verifyUnrestrictedNetworkCapabilities( ConnectivityManager.TYPE_ETHERNET, TRANSPORT_ETHERNET); } @Test public void testNoDoubleCallbackRegistration() throws Exception { ConnectivityManager manager = new ConnectivityManager(mCtx, mService); NetworkRequest request = makeRequest(1); NetworkCallback callback = new ConnectivityManager.NetworkCallback(); ApplicationInfo info = new ApplicationInfo(); info.targetSdkVersion = VERSION_CODES.N_MR1 + 1; when(mCtx.getApplicationInfo()).thenReturn(info); when(mService.requestNetwork(any(), any(), anyInt(), any(), anyInt())).thenReturn(request); Handler handler = new Handler(Looper.getMainLooper()); manager.requestNetwork(request, callback, handler); // Callback is already registered, reregistration should fail. Class<IllegalArgumentException> wantException = IllegalArgumentException.class;
Handler handler = new Handler(Looper.getMainLooper()); manager.requestNetwork(request, callback, handler); // Callback is already registered, reregistration should fail. Class<IllegalArgumentException> wantException = IllegalArgumentException.class; expectThrowable(() -> manager.requestNetwork(request, callback), wantException); manager.unregisterNetworkCallback(callback); // unregistering the callback should make it registrable again. manager.requestNetwork(request, callback); } static Message makeMessage(NetworkRequest req, int messageType) { Bundle bundle = new Bundle(); bundle.putParcelable(NetworkRequest.class.getSimpleName(), req); Message msg = Message.obtain(); msg.what = messageType; msg.setData(bundle); return msg; } static NetworkRequest makeRequest(int requestId) { NetworkRequest request = new NetworkRequest.Builder().clearCapabilities().build(); return new NetworkRequest(request.networkCapabilities, ConnectivityManager.TYPE_NONE, requestId, NetworkRequest.Type.NONE);
if (maxBlacklistSize <= 0) { Log.wtf(TAG, "Invalid max BSSID blacklist size: " + maxBlacklistSize); return; } ArrayList<String> blacklistedBssids = new ArrayList<String>(buildBssidBlacklist()); int blacklistSize = blacklistedBssids.size(); if (blacklistSize > maxBlacklistSize) { Log.wtf(TAG, "Attempt to write " + blacklistSize + " blacklisted BSSIDs, max size is " + maxBlacklistSize); blacklistedBssids = new ArrayList<String>(blacklistedBssids.subList(0, maxBlacklistSize)); localLog("Trim down BSSID blacklist size from " + blacklistSize + " to " + blacklistedBssids.size()); } if (!mConnectivityHelper.setFirmwareRoamingConfiguration(blacklistedBssids, new ArrayList<String>())) { // TODO(b/36488259): SSID whitelist management. localLog("Failed to set firmware roaming configuration."); }
private void start() { mConnectivityHelper.getFirmwareRoamingInfo(); clearBssidBlacklist(); startConnectivityScan(SCAN_IMMEDIATELY);
public void setWifiEnabled(boolean enable) { localLog("Set WiFi " + (enable ? "enabled" : "disabled")); mWifiEnabled = enable;
private void localLog(String log) { mLocalLog.log(log);
sbuf.append(" Same network the current one bonus: ") .append(mSameNetworkAward).append(","); // When firmware roaming is supported, equivalent BSSIDs (the ones under the // same network as the currently connected one) get the same BSSID award. if (mConnectivityHelper.isFirmwareRoamingSupported() && currentBssid != null && !currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Firmware roaming equivalent BSSID bonus: ") .append(mSameBssidAward).append(","); } } // Same BSSID award. if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward) .append(","); } // Security award. if (!WifiConfigurationUtil.isConfigForOpenNetwork(network)) { score += mSecurityAward; sbuf.append(" Secure network bonus: ").append(mSecurityAward).append(","); } // No internet penalty.
if (mConnectivityHelper.isFirmwareRoamingSupported() && currentBssid != null && !currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Firmware roaming equivalent BSSID bonus: ") .append(mSameBssidAward).append(","); } } // Same BSSID award. if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward) .append(","); } // Security award. if (!WifiConfigurationUtil.isConfigForOpenNetwork(network)) { score += mSecurityAward; sbuf.append(" Secure network bonus: ").append(mSecurityAward).append(","); } // No internet penalty. if (network.numNoInternetAccessReports > 0 && !network.validatedInternetAccess) { score -= mNoInternetPenalty; sbuf.append(" No internet penalty: -").append(mNoInternetPenalty).append(","); } sbuf.append(" ## Total score: ").append(score).append("\n"); return score;
if (mConnectivityHelper.isFirmwareRoamingSupported() && currentBssid != null && !currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Firmware roaming equivalent BSSID bonus: ") .append(mSameBssidAward).append(","); } } // Same BSSID award. if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward) .append(","); } // Security award. if (!WifiConfigurationUtil.isConfigForOpenNetwork(network)) { score += mSecurityAward; sbuf.append(" Secure network bonus: ").append(mSecurityAward).append(","); } // No internet penalty. if (network.numNoInternetAccessReports > 0 && !network.validatedInternetAccess) { score -= mNoInternetPenalty; sbuf.append(" No internet penalty: -").append(mNoInternetPenalty).append(","); } sbuf.append(" ## Total score: ").append(score).append("\n"); return score;
public void testCTSSyscallBlocked() { if (CpuFeatures.isArm64Cpu()) { testBlocked(217); // __NR_add_key testBlocked(219); // __NR_keyctl testAllowed(56); // __NR_openat } else if (CpuFeatures.isArmCpu()) { testBlocked(7); testAllowed(8); testBlocked(9); } else if (CpuFeatures.isX86_64Cpu()) { testBlocked(31); testAllowed(32); testBlocked(33); } else if (CpuFeatures.isX86Cpu()) { testBlocked(7); testAllowed(8); testBlocked(9); } else if (CpuFeatures.isMips64Cpu()) { testBlocked(5030); testAllowed(5031); testBlocked(5032); } else if (CpuFeatures.isMipsCpu()) { testBlocked(4032); testAllowed(4033); testBlocked(4034); } else { fail("Unsupported OS"); }
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.security.cts; import android.test.AndroidTestCase; import com.android.compatibility.common.util.CpuFeatures; import junit.framework.TestCase; /** * Verify that the seccomp policy is enforced */ public class SeccompTest extends AndroidTestCase { static { System.loadLibrary("ctssecurity_jni"); } public void testCTSSyscallBlocked() { if (CpuFeatures.isArm64Cpu()) {
mPhone.notifyOtaspChanged(ServiceStateTracker.OTASP_SIM_UNPROVISIONED); // Tear down all metered apns cleanUpAllConnections(true, Phone.REASON_CARRIER_ACTION_DISABLE_METERED_APN); } else { teardownRestrictedMeteredConnections(); setupDataOnConnectableApns(Phone.REASON_DATA_ENABLED); } } } } private void onSimNotReady() { if (DBG) log("onSimNotReady"); cleanUpAllConnections(true, Phone.REASON_SIM_NOT_READY); mAllApnSettings = null; mAutoAttachOnCreationConfig = false; } private void onSetDependencyMet(String apnType, boolean met) { // don't allow users to tweak hipri to work around default dependency not met if (PhoneConstants.APN_TYPE_HIPRI.equals(apnType)) return; ApnContext apnContext = mApnContexts.get(apnType); if (apnContext == null) { loge("onSetDependencyMet: ApnContext not found in onSetDependencyMet(" + apnType + ", " + met + ")");
public void onChange(boolean selfChange) { mUserWantsSuspendOpt.set(mFacade.getIntegerSetting(mContext, Settings.Global.WIFI_SUSPEND_OPTIMIZATIONS_ENABLED, 1) == 1);
mSapProxy = getSapProxy(); } /** * Notify SapServer that this class is ready for shutdown. */ void notifyShutdown() { if (DEBUG) Log.i(TAG, "notifyShutdown()"); // If we are already shutdown, don't bother sending a notification. synchronized (this) { if (mSapProxy != null) sendShutdownMessage(); } } /** * This will reset SapProxy. */ public void shutdown() { if (DEBUG) Log.i(TAG, "shutdown()"); /* On Android you need to close the IOstreams using Socket.shutdown* * The IOstream close must not be used, as it some how decouples the * stream from the socket, and when the socket is closed, the pending * reads never return nor throw and exception. * Hence here we use the shutdown method: */ synchronized (this) { if (mSapProxy != null) { mSapProxy = null; } } }
return null; } WifiConfiguration[] configs = new WifiConfiguration[ssids.length]; for (int index = 0; index < ssids.length; index++) { int networkId = index; for (int k = 0; k < index; k++) { // If two networks have the same SSID and security type, assign them // the same network Id. if (ssids[index].equals(ssids[k]) && (securities[index] == securities[k])) { networkId = k; } } configs[index] = generateWifiConfig(id.intValue(), 0, ssids[index], false, true, null, null, securities[index]); } return configs;
for (int index = 0; index < ssids.length; index++) { int networkId = index; for (int k = 0; k < index; k++) { // If two networks have the same SSID and security type, assign them // the same network Id. if (ssids[index].equals(ssids[k]) && (securities[index] == securities[k])) { networkId = k; } } configs[index] = generateWifiConfig(id.intValue(), 0, ssids[index], false, true, null, null, securities[index]); } return configs;
public class MacroSubstitutionNamingStrategy implements TestCaseNamingStrategy { private static final String MACRO_PATTERN = "\\{[^\\}]{0,50}\\}"; // Pattern that keeps delimiters in split result private static final Pattern MACRO_SPLIT_PATTERN = Pattern.compile(String.format("(?=%s)|(?<=%s)", MACRO_PATTERN, MACRO_PATTERN)); private static final String MACRO_START = "{"; private static final String MACRO_END = "}"; // Android-changed: CTS and AndroidJUnitRunner rely on specific format to test names, changing // them will prevent CTS and AndroidJUnitRunner from working properly; see b/36541809 static final String DEFAULT_TEMPLATE = "{method}[{index}]"; private TestMethod method; public MacroSubstitutionNamingStrategy(TestMethod testMethod) { this.method = testMethod; } @Override public String getTestCaseName(int parametersIndex, Object parameters) { TestCaseName testCaseName = method.getAnnotation(TestCaseName.class); String template = getTemplate(testCaseName); String builtName = buildNameByTemplate(template, parametersIndex, parameters);
import org.mockito.MockitoAnnotations; import org.mockito.stubbing.Answer; import java.net.InetAddress; import java.util.ArrayList; import java.util.Arrays; import java.util.List; import java.util.Random; /** * Unit tests for {@link com.android.server.wifi.WifiVendorHal}. */ public class WifiVendorHalTest { WifiVendorHal mWifiVendorHal; private WifiStatus mWifiStatusSuccess; private WifiStatus mWifiStatusFailure; WifiLog mWifiLog; @Mock private HalDeviceManager mHalDeviceManager; @Mock private TestLooper mLooper; @Mock private WifiVendorHal.HalDeviceManagerStatusListener mHalDeviceManagerStatusCallbacks; @Mock private IWifiApIface mIWifiApIface; @Mock private IWifiChip mIWifiChip; @Mock private IWifiStaIface mIWifiStaIface; @Mock private IWifiRttController mIWifiRttController; private IWifiStaIfaceEventCallback mIWifiStaIfaceEventCallback; private IWifiChipEventCallback mIWifiChipEventCallback; @Mock private WifiNative.VendorHalDeathEventHandler mVendorHalDeathHandler; /** * Identity function to supply a type to its argument, which is a lambda */
break; case CMD_DIAGS_CONNECT_TIMEOUT: mWifiDiagnostics.reportConnectionEvent( (Long) message.obj, BaseWifiDiagnostics.CONNECTION_EVENT_FAILED); break; default: loge("Error! unhandled message" + message); break; } return HANDLED; } } class InitialState extends State { private void cleanup() { // Tearing down the client interfaces below is going to stop our supplicant. mWifiMonitor.stopAllMonitoring(); mDeathRecipient.unlinkToDeath(); mWifiNative.tearDownInterfaces(); mWifiNative.stopHal(); } @Override public void enter() { mWifiStateTracker.updateState(WifiStateTracker.INVALID); cleanup(); } @Override public boolean processMessage(Message message) { logStateAndMessage(message, this); switch (message.what) { case CMD_START_SUPPLICANT: mClientInterface = mWifiNative.setupDriverForClientMode(); if (mClientInterface == null || !mDeathRecipient.linkToDeath(mClientInterface.asBinder())) { setWifiState(WifiManager.WIFI_STATE_UNKNOWN); cleanup(); break; } try {
sendMessage(CMD_DISCONNECT); } break; case WifiManager.CONNECT_NETWORK: /** * The connect message can contain a network id passed as arg1 on message or * or a config passed as obj on message. * For a new network, a config is passed to create and connect. * For an existing network, a network id is passed */ netId = message.arg1; config = (WifiConfiguration) message.obj; mWifiConnectionStatistics.numWifiManagerJoinAttempt++; boolean hasCredentialChanged = false; // New network addition. if (config != null) { result = mWifiConfigManager.addOrUpdateNetwork(config, message.sendingUid); if (!result.isSuccess()) { loge("CONNECT_NETWORK adding/updating config=" + config + " failed"); messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL; replyToMessage(message, WifiManager.CONNECT_NETWORK_FAILED, WifiManager.ERROR); break; } netId = result.getNetworkId(); } if (!connectToUserSelectNetwork(netId, message.sendingUid)) {
/** * The connect message can contain a network id passed as arg1 on message or * or a config passed as obj on message. * For a new network, a config is passed to create and connect. * For an existing network, a network id is passed */ netId = message.arg1; config = (WifiConfiguration) message.obj; mWifiConnectionStatistics.numWifiManagerJoinAttempt++; boolean hasCredentialChanged = false; // New network addition. if (config != null) { result = mWifiConfigManager.addOrUpdateNetwork(config, message.sendingUid); if (!result.isSuccess()) { loge("CONNECT_NETWORK adding/updating config=" + config + " failed"); messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL; replyToMessage(message, WifiManager.CONNECT_NETWORK_FAILED, WifiManager.ERROR); break; } netId = result.getNetworkId(); } if (!connectToUserSelectNetwork(netId, message.sendingUid)) { messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL; replyToMessage(message, WifiManager.CONNECT_NETWORK_FAILED,
newNetwork || WifiConfigurationUtil.hasCredentialChanged( existingInternalConfig, newInternalConfig); // This is needed to inform IpManager about any IP configuration changes. boolean hasIpChanged = newNetwork || WifiConfigurationUtil.hasIpChanged( existingInternalConfig, newInternalConfig); boolean hasProxyChanged = newNetwork || WifiConfigurationUtil.hasProxyChanged( existingInternalConfig, newInternalConfig); // Reset the |hasEverConnected| flag if the credential parameters changed in this update. boolean hasCredentialChanged = newNetwork || WifiConfigurationUtil.hasCredentialChanged( existingInternalConfig, newInternalConfig); if (hasCredentialChanged) { newInternalConfig.getNetworkSelectionStatus().setHasEverConnected(false); } // Add it to our internal map. This will replace any existing network configuration for // updates. mConfiguredNetworks.put(newInternalConfig); if (mDeletedEphemeralSSIDs.remove(config.SSID)) { if (mVerboseLoggingEnabled) { Log.v(TAG, "Removed from ephemeral blacklist: " + config.SSID); } } // Stage the backup of the SettingsProvider package which backs this up. mBackupManagerProxy.notifyDataChanged(); NetworkUpdateResult result = new NetworkUpdateResult(hasIpChanged, hasProxyChanged, hasCredentialChanged); result.setIsNewNetwork(newNetwork);
public ISap getSapProxy() { synchronized (mSapProxyLock) { if (mSapProxy != null) { mSapProxy.linkToDeath(mSapProxyDeathRecipient, mSapProxyCookie.incrementAndGet()); mSapProxy.setCallback(mSapCallback); } else { Log.e(TAG, "getSapProxy: mSapProxy == null"); } } catch (RemoteException | RuntimeException e) { mSapProxy = null; Log.e(TAG, "getSapProxy: exception: " + e); } if (mSapProxy == null) { // if service is not up, treat it like death notification to try to get service again mSapServerMsgHandler.sendMessageDelayed( mSapServerMsgHandler.obtainMessage( SapServer.SAP_PROXY_DEAD, mSapProxyCookie.get()), SapServer.ISAP_GET_SERVICE_DELAY_MILLIS); } return mSapProxy;
" mtu=" + mtu + " status=" + status); if (!address.equals(mDevice.getAddress())) { return; } try { mCallback.onMtuChanged(BluetoothGatt.this, mtu, status); } catch (Exception ex) { Log.w(TAG, "Unhandled exception in callback", ex); } } /** * Callback invoked when the given connection is updated * @hide */ @Override public void onConnectionUpdated(String address, int interval, int latency, int timeout, int status) { if (DBG) Log.d(TAG, "onConnectionUpdated() - Device=" + address + " interval=" + interval + " latency=" + latency + " timeout=" + timeout + " status=" + status); if (!address.equals(mDevice.getAddress())) { return; } try { mCallback.onConnectionUpdated(BluetoothGatt.this, interval, latency, timeout, status); } catch (Exception ex) { Log.w(TAG, "Unhandled exception in callback", ex); } } };
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.server; import static android.Manifest.permission.DUMP; import static android.Manifest.permission.SHUTDOWN; import android.content.Context; import android.net.IIpSecService; import android.net.INetd; import android.os.Binder; import android.os.Handler; import android.os.Process; import android.os.RemoteException; import android.os.ServiceManager; import android.util.Log; import java.io.FileDescriptor; import java.io.PrintWriter;
import java.util.concurrent.CountDownLatch; /** @hide */ public class IpSecService extends IIpSecService.Stub implements Watchdog.Monitor { private static final String TAG = "IpSecService"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_TAG = "NetdConnector"; private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; private INetd mNetdService; private final Thread mThread; private CountDownLatch mConnectedSignal = new CountDownLatch(1); /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; // make sure this is on the same looper as our NativeDaemonConnector for sync purposes mFgHandler = new Handler(FgThread.get().getLooper()); mConnector =
private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_TAG = "NetdConnector"; private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; /** connector object for communicating with netd */ private final NativeDaemonConnector mConnector; private final Handler mFgHandler; private INetd mNetdService; private static final int NETD_FETCH_TIMEOUT = 1000; //ms /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; // make sure this is on the same looper as our NativeDaemonConnector for sync purposes mFgHandler = new Handler(FgThread.get().getLooper()); mConnector = new NativeDaemonConnector( new NetdCallbackReceiver(), socket, 10, NETD_TAG, 160, null /*wakelock*/, FgThread.get().getLooper());
public void systemReady() { if (isNetdAlive()) { Slog.d(TAG, "IpSecService is ready"); } else { prepareNativeDaemon(); }
private void connectNativeNetdService() { // Avoid blocking the system server to do this Thread t = new Thread(
assertEquals(RESULT_PASS, appEndReceiver.waitForActivity()); appEndReceiver.close(); if (!noHomeScreen()) { // At this time the timerReceiver should not fire, even though the activity has shut // down, because we are back to the home screen. Going to the home screen does not // qualify as the user leaving the activity's flow. The time tracking is considered // complete only when the user switches to another activity that is not part of the // tracked flow. assertEquals(RESULT_TIMEOUT, timeReceiver.waitForActivity()); assertTrue(timeReceiver.mTimeUsed == 0); } else { // With platforms that have no home screen, focus is returned to something else that is // considered a completion of the tracked activity flow, and hence time tracking is // triggered. assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); } // Issuing now another activity will trigger the timing information release. final Intent dummyIntent = new Intent(context, MockApplicationActivity.class); dummyIntent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK);
public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { // Adding a new downstream appends it to the list. Adding a // downstream a second time without first removing it has no effect. if (mActiveDownstreams.offer(new Downstream(downstream, mNextSubnetId))) { mNextSubnetId = (short) Math.max(0, mNextSubnetId + 1); // always positive } updateIPv6TetheringInterfaces(); }
// (which extends it). SYSTEM_SERVICE_NAMES.put(android.text.ClipboardManager.class, Context.CLIPBOARD_SERVICE); registerService(Context.CONNECTIVITY_SERVICE, ConnectivityManager.class, new StaticApplicationContextServiceFetcher<ConnectivityManager>() { @Override public ConnectivityManager createService(Context context) { IBinder b = ServiceManager.getService(Context.CONNECTIVITY_SERVICE); IConnectivityManager service = IConnectivityManager.Stub.asInterface(b); return new ConnectivityManager(context, service); }}); registerService(Context.IPSEC_SERVICE, IpSecManager.class, new StaticApplicationContextServiceFetcher<IpSecManager>() { @Override public IpSecManager createService() { IBinder b = ServiceManager.getService(Context.IPSEC_SERVICE); IIpSecService service = IIpSecService .Stub.asInterface(b); return new IpSecManager(context, service); }}); registerService(Context.COUNTRY_DETECTOR, CountryDetector.class, new StaticServiceFetcher<CountryDetector>() { @Override public CountryDetector createService() { IBinder b = ServiceManager.getService(Context.COUNTRY_DETECTOR); return new CountryDetector(ICountryDetector.Stub.asInterface(b)); }}); registerService(Context.DEVICE_POLICY_SERVICE, DevicePolicyManager.class,
public IpSecManager createService(Context context) { IBinder b = ServiceManager.getService(Context.IPSEC_SERVICE); IIpSecService service = IIpSecService.Stub.asInterface(b); return new IpSecManager(service);
import android.os.RemoteException; import android.util.Log; import android.util.Slog; import java.io.FileDescriptor; import java.io.PrintWriter; /** @hide */ public class IpSecService extends IIpSecService.Stub { private static final String TAG = "IpSecService"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; } static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); service.connectNativeNetdService(); return service; } public static IpSecService create(Context context) throws InterruptedException {
import android.util.Slog; import java.io.FileDescriptor; import java.io.PrintWriter; /** @hide */ public class IpSecService extends IIpSecService.Stub { private static final String TAG = "IpSecService"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; } static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); service.connectNativeNetdService(); return service; } public static IpSecService create(Context context) throws InterruptedException { return create(context, NETD_SERVICE_NAME); }
protected Vpn(Looper looper, Context context, INetworkManagementService netService, int userHandle, SystemServices systemServices) { mContext = context; mNetd = netService; mUserHandle = userHandle; mLooper = looper; mSystemServices = systemServices; mPackage = VpnConfig.LEGACY_VPN; mOwnerUID = getAppUid(mPackage, mUserHandle); try { netService.registerObserver(mObserver); } catch (RemoteException e) { Log.wtf(TAG, "Problem registering observer", e); } mNetworkInfo = new NetworkInfo(ConnectivityManager.TYPE_VPN, 0, NETWORKTYPE, ""); // TODO: Copy metered attribute and bandwidths from physical transport, b/16207332 mNetworkCapabilities = new NetworkCapabilities(); mNetworkCapabilities.addTransportType(NetworkCapabilities.TRANSPORT_VPN); mNetworkCapabilities.removeCapability(NetworkCapabilities.NET_CAPABILITY_NOT_VPN);
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.example.android.toyvpn; import android.app.Activity; import android.content.Intent; import android.content.SharedPreferences; import android.net.VpnService; import android.os.Bundle; import android.widget.TextView; public class ToyVpnClient extends Activity { public interface Prefs { String NAME = "connection"; String SERVER_ADDRESS = "server.address"; String SERVER_PORT = "server.port"; String SHARED_SECRET = "shared.secret"; } @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.form); final TextView serverAddress = (TextView) findViewById(R.id.address); final TextView serverPort = (TextView) findViewById(R.id.port); final TextView sharedSecret = (TextView) findViewById(R.id.secret);
* * TODO: really don't do this; a blocking read on another thread is much cleaner. */ private static final long IDLE_INTERVAL_MS = TimeUnit.MILLISECONDS.toMillis(100); /** * Number of periods of length {@IDLE_INTERVAL_MS} to wait before declaring the handshake a * complete and abject failure. * * TODO: use a higher-level protocol; hand-rolling is a fun but pointless exercise. */ private static final int MAX_HANDSHAKE_ATTEMPTS = 50; private final VpnService mService; private final int mConnectionId; private final String mServerName; private final int mServerPort; private final byte[] mSharedSecret; private PendingIntent mConfigureIntent; private OnEstablishListener mOnEstablishListener; public ToyVpnConnection(final VpnService service, final int connectionId, final String serverName, final int serverPort, final byte[] sharedSecret) { mService = service; mConnectionId = connectionId; mServerName = serverName; mServerPort= serverPort; mSharedSecret = sharedSecret; } /**
} catch (Exception e) { Log.e(getTag(), "Connection failed, exiting", e); } } private boolean run(SocketAddress server) throws Exception { ParcelFileDescriptor iface = null; boolean connected = false; // Create a DatagramChannel as the VPN tunnel. try (DatagramChannel tunnel = DatagramChannel.open()) { // Protect the tunnel before connecting to avoid loopback. if (!mService.protect(tunnel.socket())) { throw new IllegalStateException("Cannot protect the tunnel"); } // Connect to the server. tunnel.connect(server); // For simplicity, we use the same thread for both reading and // writing. Here we put the tunnel into non-blocking mode. tunnel.configureBlocking(false); // Authenticate and configure the virtual network interface. iface = handshake(tunnel); // Now we are connected. Set the flag. connected = true; // Packets to be sent are queued in this input stream. FileInputStream in = new FileInputStream(iface.getFileDescriptor());
packet.position(0); tunnel.write(packet); } packet.clear(); // Wait for the parameters within a limited time. for (int i = 0; i < MAX_HANDSHAKE_ATTEMPTS; ++i) { Thread.sleep(IDLE_INTERVAL_MS); // Normally we should not receive random packets. int length = tunnel.read(packet); if (length > 0 && packet.get(0) == 0) { return configure(new String(packet.array(), 1, length - 1, US_ASCII).trim()); } } throw new IllegalStateException("Timed out"); } private ParcelFileDescriptor configure(String parameters) throws Exception { // Configure a builder while parsing the parameters. VpnService.Builder builder = mService.new Builder(); for (String parameter : parameters.split(" ")) { String[] fields = parameter.split(","); try { switch (fields[0].charAt(0)) { case 'm': builder.setMtu(Short.parseShort(fields[1])); break; case 'a': builder.addAddress(fields[1], Integer.parseInt(fields[2]));
packet.position(0); tunnel.write(packet); } packet.clear(); // Wait for the parameters within a limited time. for (int i = 0; i < MAX_HANDSHAKE_ATTEMPTS; ++i) { Thread.sleep(IDLE_INTERVAL_MS); // Normally we should not receive random packets. int length = tunnel.read(packet); if (length > 0 && packet.get(0) == 0) { return configure(new String(packet.array(), 1, length - 1, US_ASCII).trim()); } } throw new IllegalStateException("Timed out"); } private ParcelFileDescriptor configure(String parameters) throws Exception { // Configure a builder while parsing the parameters. VpnService.Builder builder = mService.new Builder(); for (String parameter : parameters.split(" ")) { String[] fields = parameter.split(","); try { switch (fields[0].charAt(0)) { case 'm': builder.setMtu(Short.parseShort(fields[1])); break; case 'a': builder.addAddress(fields[1], Integer.parseInt(fields[2]));
private void setConnectingThread(final Thread thread) { final Thread oldThread = mConnectingThread.getAndSet(thread); if (oldThread != null) { try { oldThread.interrupt(); } catch (SecurityException e) { Log.e(TAG, "Interrupting thread", e); } }
private void setConnection(final Connection connection) { final Connection oldConnection = mConnection.getAndSet(connection); if (oldConnection != null) { try { oldConnection.first.interrupt(); oldConnection.second.close(); } catch (Exception e) { Log.e(TAG, "Interrupting thread", e); } catch (IOException e) { Log.e(TAG, "Closing VPN interface", e); } }
public static int inlineMonomorphic(Main a) { if (a == null) { return 42; } int i = 0; while (i < 100) { i += a.getValue(); } return i; } /// CHECK-START: int Main.inlinePolymorphic(Main) inliner (before) /// CHECK: InvokeVirtual method_name:Main.getValue /// CHECK-START: int Main.inlinePolymorphic(Main) inliner (after) /// CHECK-NOT: InvokeVirtual method_name:Main.getValue /// CHECK-START: int Main.inlineMonomorphic(Main) licm (before) /// CHECK: <<Deopt:l\d+>> Deoptimize /// CHECK: InstanceFieldGet [<<Deopt>>] field_name:Main.value /// CHECK-START: int Main.inlineMonomorphic(Main) licm (after) /// CHECK: <<Deopt:l\d+>> Deoptimize /// CHECK: InstanceFieldGet [<<Deopt>>] field_name:Main.value public static int inlinePolymorphic(Main a) { return a.getValue(); } public int getValue() { return value; }
mNetworkFactory = new WifiNetworkFactory(getHandler().getLooper(), mContext, NETWORKTYPE, mNetworkCapabilitiesFilter); mNetworkFactory.setScoreFilter(60); mNetworkFactory.register(); // We can't filter untrusted network in the capabilities filter because a trusted // network would still satisfy a request that accepts untrusted ones. mUntrustedNetworkFactory = new UntrustedWifiNetworkFactory(getHandler().getLooper(), mContext, NETWORKTYPE_UNTRUSTED, mNetworkCapabilitiesFilter); mUntrustedNetworkFactory.setScoreFilter(Integer.MAX_VALUE); mUntrustedNetworkFactory.register(); } } } /** * WifiStateMachine needs to enable/disable other services when wifi is in client mode. This * method allows WifiStateMachine to get these additional system services. * * At this time, this method is used to setup variables for P2P service and Wifi Aware. */ private void getAdditionalWifiServiceInterfaces() { // First set up Wifi Direct if (mP2pSupported) { IBinder s1 = mFacade.getService(Context.WIFI_P2P_SERVICE); WifiP2pServiceImpl wifiP2pServiceImpl =
* and calls the <code>close</code> method of the underlying output * stream. * * @exception IOException if an I/O error occurs. * @since JCE1.2 */ public void close() throws IOException { if (closed) { return; } closed = true; try { obuffer = cipher.doFinal(); } catch (IllegalBlockSizeException | BadPaddingException e) { obuffer = null; // Android-added: Throw an exception when the underlying cipher does. http://b/36636576 throw new IOException(e); } try { flush(); } catch (IOException ignored) {} out.close(); } }
setAndBroadcastNetworkSetTime(mSavedTime + (currTime - mSavedAtTime)); } } private void revertToNitzTimeZone() { if (Settings.Global.getInt(mCr, Settings.Global.AUTO_TIME_ZONE, 0) == 0) { return; } String tmpLog = "Reverting to NITZ TimeZone: tz=" + mSavedTimeZone; if (DBG) log(tmpLog); mTimeZoneLog.log(tmpLog); if (mSavedTimeZone != null) { setAndBroadcastNetworkSetTimeZone(mSavedTimeZone); } } /** * Post a notification to NotificationManager for restricted state and * rejection cause for cs registration * * @param notifyType is one state of * PS/CS_*_ENABLE/DISABLE/ * CS_REJECT_CAUSE_ENABLED/CS_REJECT_CAUSE_DISABLED */ @VisibleForTesting public void setNotification(int notifyType) { if (DBG) log("setNotification: create notification " + notifyType); // Needed because sprout RIL sends these when they shouldn't? boolean isSetNotification = mPhone.getContext().getResources().getBoolean( com.android.internal.R.bool.config_user_notification_of_restrictied_mobile_access);
private void setNotification(int notifyType) { if (DBG) log("setNotification: create notification " + notifyType); // Needed because sprout RIL sends these when they shouldn't? boolean isSetNotification = mPhone.getContext().getResources().getBoolean( com.android.internal.R.bool.config_user_notification_of_restrictied_mobile_access); if (!isSetNotification) { if (DBG) log("Ignore all the notifications"); return; } Context context = mPhone.getContext(); CarrierConfigManager configManager = (CarrierConfigManager) context.getSystemService(Context.CARRIER_CONFIG_SERVICE); if (configManager != null) { PersistableBundle bundle = configManager.getConfig(); if (bundle != null) { boolean disableVoiceBarringNotification = bundle.getBoolean( CarrierConfigManager.KEY_DISABLE_VOICE_BARRING_NOTIFICATION_BOOL, false); if(disableVoiceBarringNotification && (notifyType == CS_ENABLED || notifyType == CS_NORMAL_ENABLED || notifyType == CS_EMERGENCY_ENABLED)) { if (DBG) log("Voice/emergency call barred notification disabled"); return; } } } CharSequence details = "";
public void prepareForForcedConnection(int netId) { localLog("prepareForForcedConnection: netId=" + netId); clearConnectionAttemptTimeStamps(); clearBssidBlacklist();
long timeStamp = clock.getElapsedSinceBootMillis(); for (int index = 0; index < ssids.length; index++) { ScanDetail scanDetail = new ScanDetail(WifiSsid.createFromAsciiEncoded(ssids[index]), bssids[index], caps[index], levels[index], freqs[index], timeStamp, 0); scanDetailList.add(scanDetail); } return scanDetailList; } /** * Generate an array of {@link android.net.wifi.WifiConfiguration} based on the caller * supplied network SSID and security information. * * @param ssids an array of SSIDs * @param securities an array of the network's security setting * @return the constructed array of {@link android.net.wifi.WifiConfiguration} */ public static WifiConfiguration[] generateWifiConfigurations(String[] ssids, int[] securities) { if (ssids == null || securities == null || ssids.length != securities.length || ssids.length == 0) { return null; } Map<String, Integer> netIdMap = new HashMap<>(); int netId = 0;
MAXIMUM_POOL_SIZE, KEEP_ALIVE_SECONDS, TimeUnit.SECONDS, workQueue); for (int i = 1; i < mPackages.size(); i++) { final AppPrefLoader loader = new AppPrefLoader(); loader.executeOnExecutor(executor, mPackages.valueAt(i)); } } else { removePreference(KEY_APP_LIST); } } else { final Context context = getActivity(); UidDetail uidDetail = new UidDetailProvider(context).getUidDetail(mAppItem.key, true); mIcon = uidDetail.icon; mLabel = uidDetail.label; mPackageName = context.getPackageName(); removePreference(KEY_UNRESTRICTED_DATA); removePreference(KEY_APP_SETTINGS); removePreference(KEY_RESTRICT_BACKGROUND); removePreference(KEY_APP_LIST); }
MAXIMUM_POOL_SIZE, KEEP_ALIVE_SECONDS, TimeUnit.SECONDS, workQueue); for (int i = 1; i < mPackages.size(); i++) { final AppPrefLoader loader = new AppPrefLoader(); loader.executeOnExecutor(executor, mPackages.valueAt(i)); } } else { removePreference(KEY_APP_LIST); } } else { final Context context = getActivity(); UidDetail uidDetail = new UidDetailProvider(context).getUidDetail(mAppItem.key, true); mIcon = uidDetail.icon; mLabel = uidDetail.label; mPackageName = context.getPackageName(); removePreference(KEY_UNRESTRICTED_DATA); removePreference(KEY_APP_SETTINGS); removePreference(KEY_RESTRICT_BACKGROUND); removePreference(KEY_APP_LIST); }
private void setConnectingThread(final Thread thread) { final Thread oldThread = mConnectingThread.getAndSet(thread); if (oldThread != null) { oldThread.interrupt(); }
*/ @HasKeyId @Name("BoostLockedRegionPriorityFeature") @Description("Feature turning on BoostLockedRegionPriorityFeature") public final class BoostLockedRegionPriorityFeature implements Feature { @Nonnull public static final BooleanPropertyId ENABLE = BooleanPropertyId.create( "jack.transformations.boost-locked-region-priority", "Boost priority of threads acquiring certain locks") .addCategory(Private.class) .addDefaultValue(Boolean.FALSE) .addCategory(DumpInLibrary.class); @Nonnull public static final PropertyId<List<String>> BOOST_LOCK_CLASSNAME = PropertyId.create( "jack.transformations.boost-locked-region-priority.classname", "The class signatures where acquiring it as a lock should boost a thread's prioirty", new ClassNameCodec()) .requiredIf(BoostLockedRegionPriorityFeature.ENABLE.getValue().isTrue()) .addCategory(Private.class) .addCategory(DumpInLibrary.class); @Nonnull public static final PropertyId<List<MethodNameValue>> BOOST_LOCK_REQUEST_METHOD = PropertyId.create( "jack.transformations.boost-locked-region-priority.request", "Static methods in the specified classes that can boost a thread's prioirty",
Jack.getSession().getReporter().report(Severity.FATAL, new BadBoostLockedRegionPriorityConfigurationException(prop, e)); Jack.getSession().abortEventually(); return null; } } @Override public void run(@Nonnull JMethod method) { if (method.isNative() || method.isAbstract() || !filter.accept(this.getClass(), method)) { return; } if (lockClass.length == 0) { return; } TransformationRequest tr = new TransformationRequest(method); Visitor visitor = new Visitor(method, tr); visitor.accept(method); tr.commit(); } private class Visitor extends JVisitor { @Nonnull private final JMethod method; @Nonnull private final TransformationRequest tr; public Visitor(@Nonnull JMethod method, @Nonnull TransformationRequest tr) { this.method = method; this.tr = tr; } @Override public void endVisit(@Nonnull JLock jLock) { assert lockClass != null; int lockIndex = -1;
* Two objects of HIDL types are considered equal if: * 1. Both null * 2. Both non-null, and of the same class, and: * 2.1 Both are primitive arrays / enum arrays, elements are equal using == check * 2.2 Both are object arrays, elements are checked recursively * 2.3 Both are Lists, elements are checked recursively * 2.4 (If both are collections other than lists or maps, undefined behavior) * 2.5 lft.equals(rgt) returns true */ public static boolean deepEquals(Object lft, Object rgt) { if (lft == rgt) { return true; } if (lft == null || rgt == null) { return false; } Class<?> lftClazz = lft.getClass(); Class<?> rgtClazz = rgt.getClass(); if (lftClazz != rgtClazz) { return false; } if (lftClazz.isArray()) { Class<?> lftElementType = lftClazz.getComponentType(); if (lftElementType != rgtClazz.getComponentType()) { return false; }
* Two objects of HIDL types are considered equal if: * 1. Both null * 2. Both non-null, and of the same class, and: * 2.1 Both are primitive arrays / enum arrays, elements are equal using == check * 2.2 Both are object arrays, elements are checked recursively * 2.3 Both are Lists, elements are checked recursively * 2.4 (If both are collections other than lists or maps, undefined behavior) * 2.5 lft.equals(rgt) returns true */ public static boolean deepEquals(Object lft, Object rgt) { if (lft == rgt) { return true; } if (lft == null || rgt == null) { return false; } Class<?> lftClazz = lft.getClass(); Class<?> rgtClazz = rgt.getClass(); if (lftClazz != rgtClazz) { return false; } if (lftClazz.isArray()) { Class<?> lftElementType = lftClazz.getComponentType(); if (lftElementType != rgtClazz.getComponentType()) { return false; }
* Two objects of HIDL types are considered equal if: * 1. Both null * 2. Both non-null, and of the same class, and: * 2.1 Both are primitive arrays / enum arrays, elements are equal using == check * 2.2 Both are object arrays, elements are checked recursively * 2.3 Both are Lists, elements are checked recursively * 2.4 (If both are collections other than lists or maps, undefined behavior) * 2.5 lft.equals(rgt) returns true */ public static boolean deepEquals(Object lft, Object rgt) { if (lft == rgt) { return true; } if (lft == null || rgt == null) { return false; } Class<?> lftClazz = lft.getClass(); Class<?> rgtClazz = rgt.getClass(); if (lftClazz != rgtClazz) { return false; } if (lftClazz.isArray()) { Class<?> lftElementType = lftClazz.getComponentType(); if (lftElementType != rgtClazz.getComponentType()) { return false; }
} String invokeWith = null; if ((app.info.flags & ApplicationInfo.FLAG_DEBUGGABLE) != 0) { // Debuggable apps may include a wrapper script with their library directory. String wrapperFileName = app.info.nativeLibraryDir + "/wrap.sh"; StrictMode.ThreadPolicy oldPolicy = StrictMode.allowThreadDiskReads(); try { if (new File(wrapperFileName).exists()) { invokeWith = "/system/bin/logwrapper " + wrapperFileName; } } finally { StrictMode.setThreadPolicy(oldPolicy); } } String requiredAbi = (abiOverride != null) ? abiOverride : app.info.primaryCpuAbi; if (requiredAbi == null) { requiredAbi = Build.SUPPORTED_ABIS[0]; } String instructionSet = null; if (app.info.primaryCpuAbi != null) { instructionSet = VMRuntime.getInstructionSet(app.info.primaryCpuAbi); } app.gids = gids; app.requiredAbi = requiredAbi; app.instructionSet = instructionSet; // Start the process. It will either succeed and return a result containing
loge("setWfcSetting(): ", e); } } } /** * Change persistent WFC enabled setting for slot. */ public void setWfcSettingForSlot(boolean enabled) { int value = enabled ? 1 : 0; android.provider.Settings.Global.putInt(mContext.getContentResolver(), android.provider.Settings.Global.WFC_IMS_ENABLED, value); setWfcSettingInternalForSlot(enabled, getWfcModeForSlot()); } /** * Non-persistently change WFC enabled setting and WFC mode for slot * * @param wfcMode The WFC preference if WFC is enabled */ public void setWfcSettingInternalForSlot(boolean enabled, int wfcMode) { int imsFeatureValue = enabled ? ImsConfig.FeatureValueConstants.ON : ImsConfig.FeatureValueConstants.OFF; // Force IMS to register over LTE when turning off WFC int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig.WfcModeFeatureValueConstants.CELLULAR_PREFERRED; try { ImsConfig config = getConfigInterface(); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI, TelephonyManager.NETWORK_TYPE_IWLAN,
loge("setWfcSetting(): ", e); } } } /** * Change persistent WFC enabled setting for slot. */ public void setWfcSettingForSlot(boolean enabled) { int value = enabled ? 1 : 0; android.provider.Settings.Global.putInt(mContext.getContentResolver(), android.provider.Settings.Global.WFC_IMS_ENABLED, value); setWfcSettingInternalForSlot(enabled, getWfcModeForSlot()); } /** * Non-persistently change WFC enabled setting and WFC mode for slot * * @param wfcMode The WFC preference if WFC is enabled */ public void setWfcSettingInternalForSlot(boolean enabled, int wfcMode) { int imsFeatureValue = enabled ? ImsConfig.FeatureValueConstants.ON : ImsConfig.FeatureValueConstants.OFF; // Force IMS to register over LTE when turning off WFC int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig.WfcModeFeatureValueConstants.CELLULAR_PREFERRED; try { ImsConfig config = getConfigInterface(); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI, TelephonyManager.NETWORK_TYPE_IWLAN,
public void setWfcNonPersistentForSlot(boolean enabled, int wfcMode) { int imsFeatureValue = enabled ? ImsConfig.FeatureValueConstants.ON : ImsConfig.FeatureValueConstants.OFF; // Force IMS to register over LTE when turning off WFC int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig.WfcModeFeatureValueConstants.CELLULAR_PREFERRED; try { ImsConfig config = getConfigInterface(); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI, TelephonyManager.NETWORK_TYPE_IWLAN, imsFeatureValue, mImsConfigListener); if (enabled) { log("setWfcSettingForSlot() : turnOnIms"); turnOnIms(); } else if (isTurnOffImsAllowedByPlatformForSlot() && (!isVolteEnabledByPlatformForSlot() || !isEnhanced4gLteModeSettingEnabledByUserForSlot())) { log("setWfcSettingForSlot() : imsServiceAllowTurnOff -> turnOffIms"); turnOffIms(); } setWfcModeInternalForSlot(imsWfcModeFeatureValue); } catch (ImsException e) { loge("setWfcSettingForSlot(): ", e); }
* <h3>Developer Guides</h3> * <p>For more information about using Bluetooth, read the * <a href="{@docRoot}guide/topics/connectivity/bluetooth.html">Bluetooth</a> developer guide.</p> * </div> * * {@see BluetoothServerSocket} * {@see java.io.InputStream} * {@see java.io.OutputStream} */ public final class BluetoothSocket implements Closeable { private static final String TAG = "BluetoothSocket"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final boolean VDBG = Log.isLoggable(TAG, Log.VERBOSE); /** @hide */ public static final int MAX_RFCOMM_CHANNEL = 30; /*package*/ static final int MAX_L2CAP_PACKAGE_SIZE = 0xFFFF; /** RFCOMM socket */ public static final int TYPE_RFCOMM = 1; /** SCO socket */ public static final int TYPE_SCO = 2; /** L2CAP socket */ public static final int TYPE_L2CAP = 3; /*package*/ static final int EBADFD = 77; /*package*/ static final int EADDRINUSE = 98;
public NetworkCapabilities setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier != null && Long.bitCount(mTransportTypes) != 1) { throw new IllegalStateException("Must have a single transport specified to use " + "setNetworkSpecifier"); } if (networkSpecifier != null && !(networkSpecifier instanceof Parcelable)) { throw new IllegalArgumentException("Network specifier must be parcelable"); } mNetworkSpecifier = networkSpecifier; return this;
public boolean equals(Object o) { return o instanceof MatchAllNetworkSpecifier;
public NetworkCapabilities setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier != null && Long.bitCount(mTransportTypes) != 1) { throw new IllegalStateException("Must have a single transport specified to use " + "setNetworkSpecifier"); } mNetworkSpecifier = networkSpecifier; return this;
private boolean satisfiedBySpecifier(NetworkCapabilities nc) { return mNetworkSpecifier == null || mNetworkSpecifier.satisfiedBy(nc.mNetworkSpecifier) || nc.mNetworkSpecifier instanceof MatchAllNetworkSpecifier;
(mLinkUpBandwidthKbps * 11) + (mLinkDownBandwidthKbps * 13) + Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); if (mNetworkSpecifier != null && !NetworkSpecifier.isWhitelistedNetworkSpecifier( mNetworkSpecifier)) { throw new IllegalStateException("Invalid network specifier"); } dest.writeParcelable((Parcelable) mNetworkSpecifier, flags); dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); netCap.mNetworkSpecifier = in.readParcelable(null); netCap.mSignalStrength = in.readInt(); return netCap; } @Override
(mLinkUpBandwidthKbps * 11) + (mLinkDownBandwidthKbps * 13) + Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); if (mNetworkSpecifier != null && !NetworkSpecifier.isWhitelistedNetworkSpecifier( mNetworkSpecifier)) { throw new IllegalStateException("Invalid network specifier"); } dest.writeParcelable((Parcelable) mNetworkSpecifier, flags); dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); netCap.mNetworkSpecifier = in.readParcelable(null); netCap.mSignalStrength = in.readInt(); return netCap; } @Override
public StringNetworkSpecifier(String specifier) { Preconditions.checkStringNotEmpty(specifier); this.specifier = specifier;
public boolean satisfiedBy(NetworkSpecifier other) { return equals(other);
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net; import android.os.Parcel; import android.os.Parcelable; import android.text.TextUtils; import java.util.Objects; /** @hide */ public final class StringNetworkSpecifier extends NetworkSpecifier implements Parcelable { public final String specifier; public StringNetworkSpecifier(String specifier) { if (TextUtils.isEmpty(specifier)) { throw new IllegalArgumentException("Network specifier must not be empty"); }
public boolean satisfiedBy(NetworkSpecifier other) { if (other == null) return false; if (!(other instanceof StringNetworkSpecifier)) return false; return specifier.equals(((StringNetworkSpecifier) other).specifier);
private IpSecService(Context context) { mContext = context;
/** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; } static IpSecService create(Context context) throws InterruptedException { final IpSecService service = new IpSecService(context); service.connectNativeNetdService(); return service; } public static IpSecService create(Context context) throws InterruptedException { return create(context, NETD_SERVICE_NAME); } public void systemReady() { if (isNetdAlive()) { Slog.d(TAG, "IpSecService is ready"); } else { Slog.wtf(TAG, "IpSecService not ready: failed to connect to NetD Native Service!"); } } private void connectNativeNetdService() { // Avoid blocking the system server to do this Thread t =
/** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; } static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); service.connectNativeNetdService(); return service; } public void systemReady() { if (isNetdAlive()) { Slog.d(TAG, "IpSecService is ready"); } else { Slog.wtf(TAG, "IpSecService not ready: failed to connect to NetD Native Service!"); } } private void connectNativeNetdService() { // Avoid blocking the system server to do this Thread t = new Thread( new Runnable() { @Override public void run() { synchronized (mLock) { NetdService.get(NETD_FETCH_TIMEOUT); } }
} void unlinkDeathRecipient() { if (mBinder != null) { mBinder.unlinkToDeath(this, 0); } } protected void releaseResources() {} protected void nullifyRecord() {} public void binderDied() { Log.w(TAG, "IpSecService.SpiRecord binderDied(" + mBinder + ")"); } } private final SparseArray<SpiRecord> mSpiRecords = new SparseArray<>(); private final SparseArray<TransformRecord> mTransformRecords = new SparseArray<>(); /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context) { mContext = context; } static IpSecService create(Context context) throws InterruptedException { final IpSecService service = new IpSecService(context); service.connectNativeNetdService(); return service; } public void systemReady() { if (isNetdAlive()) { Slog.d(TAG, "IpSecService is ready"); } else {
} catch (RemoteException e) { throw e.rethrowFromSystemServer(); } synchronized (mSpiRecords) { mSpiRecords.put( resourceId, new SpiRecord(resourceId, direction, localAddress, remoteAddress, spi, binder)); } Bundle retBundle = new Bundle(3); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_STATUS, IpSecManager.Status.OK); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_RESOURCE_ID, resourceId); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_SPI, spi); return retBundle;
public Bundle createTransportModeTransform(IpSecConfig c, IBinder binder) { // TODO: Basic input validation here since it's coming over the Binder int resourceId = mNextTransformId.getAndIncrement(); for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { IpSecAlgorithm auth = c.getAuthentication(direction); IpSecAlgorithm crypt = c.getEncryption(direction); try { int result = getNetdInstance().ipSecAddSecurityAssociation( resourceId, c.getMode(), direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", (c.getNetwork() != null) ? c.getNetwork().getNetworkHandle() : 0, c.getSpi(direction), (auth != null) ? auth.getName() : "", (auth != null) ? auth.getKey() : null, (auth != null) ? auth.getTruncationLengthBits() : 0, (crypt != null) ? crypt.getName() : "",
public Bundle createTransportModeTransform(IpSecConfig c, IBinder binder) { int resourceId = mNextTransformId.getAndIncrement(); for (int direction : DIRECTIONS) { IpSecAlgorithm auth = c.getAuthentication(direction); IpSecAlgorithm crypt = c.getEncryption(direction); try { int result = getNetdInstance().ipSecAddSecurityAssociation( resourceId, c.getMode(), direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", (c.getNetwork() != null) ? c.getNetwork().getNetworkHandle() : 0, c.getSpi(direction), (auth != null) ? auth.getName() : "", (auth != null) ? auth.getKey() : null, (auth != null) ? auth.getTruncationLengthBits() : 0,
(auth != null) ? auth.getKey() : null, (auth != null) ? auth.getTruncationLengthBits() : 0, (crypt != null) ? crypt.getName() : "", (crypt != null) ? crypt.getKey() : null, (crypt != null) ? crypt.getTruncationLengthBits() : 0, c.getEncapType(), c.getEncapLocalPort(), c.getEncapRemotePort()); if (result != c.getSpi(direction)) { Bundle retBundle = new Bundle(2); retBundle.putInt( IpSecTransform.KEY_STATUS, IpSecManager.Status.SPI_UNAVAILABLE); retBundle.putInt( IpSecTransform.KEY_RESOURCE_ID, IpSecTransform.INVALID_RESOURCE_ID); return retBundle; } } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } synchronized (mTransformRecords) { mTransformRecords.put(resourceId, new TransformRecord(c, resourceId, binder)); }
(crypt != null) ? crypt.getKey() : null, (crypt != null) ? crypt.getTruncationLengthBits() : 0, c.getEncapType(), c.getEncapLocalPort(), c.getEncapRemotePort()); if (result != c.getSpi(direction)) { Bundle retBundle = new Bundle(2); retBundle.putInt( IpSecTransform.KEY_STATUS, IpSecManager.Status.SPI_UNAVAILABLE); retBundle.putInt( IpSecTransform.KEY_RESOURCE_ID, IpSecTransform.INVALID_RESOURCE_ID); return retBundle; } } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } synchronized (mTransformRecords) { mTransformRecords.put(resourceId, new TransformRecord(c, resourceId, binder)); } Bundle retBundle = new Bundle(2); retBundle.putInt(IpSecTransform.KEY_STATUS, IpSecManager.Status.OK); retBundle.putInt(IpSecTransform.KEY_RESOURCE_ID, resourceId); return retBundle;
public void deleteTransportModeTransform(int resourceId) { TransformRecord record; synchronized (mTransformRecords) { TransformRecord record; // We want to non-destructively get so that we can check credentials before removing this record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // remove from the DB because releasing might fail, but it won't ever succeed later mTransformRecords.remove(resourceId); record.releaseResources(); record.nullifyRecord(); }
record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional record.releaseResources(); record.nullifyRecord(); }
public void applyTransportModeTransform(ParcelFileDescriptor socket, int resourceId) { synchronized (mTransformRecords) { // FIXME: this code should be factored out into a security check + getter info = mTransformRecords.get(resourceId); if (info == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not active"); } if (info.pid != getCallingPid() || info.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may apply it!"); } IpSecConfig c = info.getConfig(); try { for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { getNetdInstance().ipSecApplyTransportModeTransform( socket.getFileDescriptor(), resourceId, direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "",
import static org.mockito.Mockito.atLeastOnce; import static org.mockito.Mockito.mock; import static org.mockito.Mockito.validateMockitoUsage; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.when; import android.content.Context; import android.net.wifi.WifiScanner.BssidInfo; import android.os.Handler; import android.os.Message; import android.os.test.TestLooper; import android.test.suitebuilder.annotation.SmallTest; import com.android.internal.util.test.BidirectionalAsyncChannelServer; import org.junit.After; import org.junit.Before; import org.mockito.Mock; import org.mockito.MockitoAnnotations; /** * Unit tests for {@link android.net.wifi.WifiScanner}. */ @SmallTest public class WifiScannerTest { @Mock private Context mContext; @Mock private IWifiScanner mService; private WifiScanner mWifiScanner; private TestLooper mLooper; private Handler mHandler; /** * Setup before tests. */ @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); mLooper = new TestLooper(); mHandler = mock(Handler.class);
mImsRegistered = (responseArray[0] == 1) ? true : false; } break; //GSM case EVENT_RADIO_AVAILABLE: //this is unnecessary //setPowerStateToDesired(); break; case EVENT_SIM_READY: // Reset the mPreviousSubId so we treat a SIM power bounce // as a first boot. See b/19194287 mOnSubscriptionsChangedListener.mPreviousSubId.set(-1); pollState(); // Signal strength polling stops when radio is off queueNextSignalStrengthPoll(); break; case EVENT_RADIO_STATE_CHANGED: case EVENT_PHONE_TYPE_SWITCHED: if(!mPhone.isPhoneTypeGsm() && mCi.getRadioState() == CommandsInterface.RadioState.RADIO_ON) { handleCdmaSubscriptionSource(mCdmaSSM.getCdmaSubscriptionSource()); // Signal strength polling stops when radio is off. queueNextSignalStrengthPoll(); } // This will do nothing in the 'radio not available' case setPowerStateToDesired(); // These events are modem triggered, so pollState() needs to be forced modemTriggeredPollState(); break;
* Reference: 3GPP TS 36.104 5.4.3) inclusive ranges on which lte_rsrp_boost_int * will be applied. Format of the String array is expected to be {"erafcn1_start-earfcn1_end", * "earfcn2_start-earfcn2_end" ... } * @hide */ public static final String KEY_BOOSTED_LTE_EARFCNS_STRING_ARRAY = "boosted_lte_earfcns_string_array"; /** The default value for every variable. */ private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true);
* perform operations that pertain to network connectivity at an abstract * level, use {@link android.net.ConnectivityManager}. */ public class WifiManager { private static final String TAG = "WifiManager"; // Supplicant error codes: /** * The error code if there was a problem authenticating. */ public static final int ERROR_AUTHENTICATING = 1; // Supplicant Authentication Failure reason codes: /** * The reason code if there is no error during authentication. * It could also imply that there no authentication in progress, * this reason code also serves as a reset value. * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0; // Supplicant Authentication Failure reason codes: /** * The reason code if there was a timeout authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; // Supplicant Authentication Failure reason codes: /** * The reason code if there was a wrong password while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; // Supplicant Authentication Failure reason codes: /**
*/ public class WifiManager { private static final String TAG = "WifiManager"; // Supplicant error codes: /** * The error code if there was a problem authenticating. */ public static final int ERROR_AUTHENTICATING = 1; // Supplicant Authentication Failure reason codes: /** * Default reason code for error during authentication. * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0; /** * The reason code if there was a timeout authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; // Supplicant Authentication Failure reason codes: /** * The reason code if there was a wrong password while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; // Supplicant Authentication Failure reason codes: /** * The reason code if there was EAP failure while * authenticating. * @hide */
*/ public static final int ERROR_AUTHENTICATING = 1; // Supplicant Authentication Failure reason codes: /** * Default reason code for error during authentication. * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0; // Supplicant Authentication Failure reason codes: /** * The reason code if there was a timeout authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; /** * The reason code if there was a wrong password while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; // Supplicant Authentication Failure reason codes: /** * The reason code if there was EAP failure while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3; /** * Broadcast intent action indicating whether Wi-Fi scanning is allowed currently * @hide */
// Supplicant Authentication Failure reason codes: /** * The reason code if there was a timeout authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; // Supplicant Authentication Failure reason codes: /** * The reason code if there was a wrong password while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; /** * The reason code if there was EAP failure while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3; /** * Broadcast intent action indicating whether Wi-Fi scanning is allowed currently * @hide */ public static final String WIFI_SCAN_AVAILABLE = "wifi_scan_available"; /** * Extra int indicating scan availability, WIFI_STATE_ENABLED and WIFI_STATE_DISABLED * @hide */ public static final String EXTRA_SCAN_AVAILABLE = "scan_enabled"; /**
(mLinkUpBandwidthKbps * 11) + (mLinkDownBandwidthKbps * 13) + Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); if (mNetworkSpecifier != null && !NetworkSpecifier.isWhitelistedNetworkSpecifier( mNetworkSpecifier)) { throw new IllegalStateException("Invalid network specifier"); } dest.writeParcelable((Parcelable) mNetworkSpecifier, flags); dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); netCap.mNetworkSpecifier = in.readParcelable(null); netCap.mSignalStrength = in.readInt(); return netCap; } @Override
* distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net; /** * Describes specific properties of a network for use in a {@link NetworkRequest}. * * Applications cannot instantiate this class by themselves, but can obtain instances of this * class via other APIs. * * @hide */ public abstract class NetworkSpecifier { /** * Returns true if a request with this {@link NetworkSpecifier} is satisfied by a network * with the given NetworkSpecifier. */ public abstract boolean satisfiedBy(NetworkSpecifier other); }
// STATE_DIALING, put it on hold before answering the call. if (foregroundCall != null && foregroundCall != call && (foregroundCall.isActive() || foregroundCall.getState() == CallState.DIALING || foregroundCall.getState() == CallState.PULLING)) { if (!foregroundCall.getTargetPhoneAccount().equals( call.getTargetPhoneAccount()) && ((call.isSelfManaged() != foregroundCall.isSelfManaged()) || call.isSelfManaged())) { // The foreground call is from another connection service, and either: // 1. FG call's managed state doesn't match that of the incoming call. // E.g. Incoming is self-managed and FG is managed, or incoming is managed // and foreground is self-managed. // 2. The incoming call is self-managed. // E.g. The incoming call is Log.i(this, "Answering call from %s CS; disconnecting calls from %s CS.", foregroundCall.isSelfManaged() ? "selfMg" : "mg",
@Mock private Call mVideoCall; @Mock private Call mRingingCall; private IncomingCallNotifier mIncomingCallNotifier; private NotificationManager mNotificationManager; public void setUp() throws Exception { super.setUp(); mContext = mComponentContextFixture.getTestDouble().getApplicationContext(); ApplicationInfo info = new ApplicationInfo(); info.targetSdkVersion = Build.VERSION_CODES.N_MR1; doReturn(info).when(mContext).getApplicationInfo(); doReturn(null).when(mContext).getTheme(); mNotificationManager = (NotificationManager) mContext.getSystemService( Context.NOTIFICATION_SERVICE); mIncomingCallNotifier = new IncomingCallNotifier(mContext); mIncomingCallNotifier.setCallsManagerProxy(mCallsManagerProxy); when(mAudioCall.getVideoState()).thenReturn(VideoProfile.STATE_AUDIO_ONLY); when(mAudioCall.getTargetPhoneAccountLabel()).thenReturn("Bar"); when(mVideoCall.getVideoState()).thenReturn(VideoProfile.STATE_BIDIRECTIONAL); when(mVideoCall.getTargetPhoneAccountLabel()).thenReturn("Bar"); when(mRingingCall.isSelfManaged()).thenReturn(true); when(mRingingCall.isIncoming()).thenReturn(true);
@Mock WifiTrafficPoller mWifiTrafficPoller; @Mock WifiStateMachine mWifiStateMachine; @Mock HandlerThread mHandlerThread; TestLooper mLooper; @Mock AsyncChannel mAsyncChannel; @Mock Resources mResources; @Mock FrameworkFacade mFrameworkFacade; @Mock WifiLockManager mLockManager; @Mock WifiMulticastLockManager mWifiMulticastLockManager; @Mock WifiLastResortWatchdog mWifiLastResortWatchdog; @Mock WifiBackupRestore mWifiBackupRestore; @Mock WifiMetrics mWifiMetrics; @Spy FakeWifiLog mLog; @Mock WifiPermissionsUtil mWifiPermissionsUtil; @Mock WifiSettingsStore mSettingsStore; @Mock ContentResolver mContentResolver; PowerManager mPowerManager; private class WifiAsyncChannelTester { private static final String TAG = "WifiAsyncChannelTester"; public static final int CHANNEL_STATE_FAILURE = -1; public static final int CHANNEL_STATE_DISCONNECTED = 0; public static final int CHANNEL_STATE_HALF_CONNECTED = 1; public static final int CHANNEL_STATE_FULLY_CONNECTED = 2; private int mState = CHANNEL_STATE_DISCONNECTED; private WifiAsyncChannel mChannel; private WifiLog mAsyncTestLog;
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License */ package benchmarks.regression; import com.google.caliper.Param; public class StringReplaceAllBenchmark { // NOTE: These estimates of MOVEABLE / NON_MOVEABLE are based on a knowledge of // ART implementation details. They make a difference here because JNI calls related // to strings took different paths depending on whether the String in question was // moveable or not. enum StringLengths { EMPTY(""),
} /** * Creates a new advertising set. If operation succeed, device will start advertising. This * method returns immediately, the operation status is delivered through * {@code callback.onAdvertisingSetStarted()}. * <p> * @param parameters advertising set parameters. * @param advertiseData Advertisement data to be broadcasted. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength}. If the * advertisement is connectable, three bytes will be added for flags. * @param scanResponse Scan response associated with the advertisement data. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength} * @param periodicData Periodic advertising data. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength} * @param timeoutMillis Advertising time limit. May not exceed 180000 * @param callback Callback for advertising set. * @param handler thread upon which the callbacks will be invoked. */ public void startAdvertisingSet(AdvertisingSetParameters parameters, AdvertiseData advertiseData, AdvertiseData scanResponse, PeriodicAdvertisingParameters periodicParameters,
} /** * Creates a new advertising set. If operation succeed, device will start advertising. This * method returns immediately, the operation status is delivered through * {@code callback.onAdvertisingSetStarted()}. * <p> * @param parameters advertising set parameters. * @param advertiseData Advertisement data to be broadcasted. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength}. If the * advertisement is connectable, three bytes will be added for flags. * @param scanResponse Scan response associated with the advertisement data. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength} * @param periodicData Periodic advertising data. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength} * @param timeoutMillis Advertising time limit. May not exceed 180000 * @param callback Callback for advertising set. * @param handler thread upon which the callbacks will be invoked. */ public void startAdvertisingSet(AdvertisingSetParameters parameters, AdvertiseData advertiseData, AdvertiseData scanResponse, PeriodicAdvertisingParameters periodicParameters,
* by the system. */ public static final String ACTION_SUBINFO_RECORD_UPDATED = "android.intent.action.ACTION_SUBINFO_RECORD_UPDATED"; /** * Broadcast Action: The default subscription has changed. This has the following * extra values:</p> * <ul> * <li><em>subscription</em> - A int, the current default subscription.</li> * </ul> * @deprecated Use {@link SubscriptionManager.ACTION_DEFAULT_SUBSCRIPTION_CHANGED} */ @Deprecated public static final String ACTION_DEFAULT_SUBSCRIPTION_CHANGED = SubscriptionManager.ACTION_DEFAULT_SUBSCRIPTION_CHANGED; /** * Broadcast Action: The default data subscription has changed. This has the following * extra values:</p> * <ul> * <li><em>subscription</em> - A int, the current data default subscription.</li> * </ul> */ public static final String ACTION_DEFAULT_DATA_SUBSCRIPTION_CHANGED = "android.intent.action.ACTION_DEFAULT_DATA_SUBSCRIPTION_CHANGED"; /** * Broadcast Action: The default voice subscription has changed. This has the following
* </ul> */ public static final String ACTION_DEFAULT_VOICE_SUBSCRIPTION_CHANGED = "android.intent.action.ACTION_DEFAULT_VOICE_SUBSCRIPTION_CHANGED"; /** * Broadcast Action: The default sms subscription has changed. This has the following * extra values:</p> * <ul> * <li><em>subscription</em> - A int, the current sms default subscription.</li> * </ul> * @deprecated Use {@link SubscriptionManager.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED} */ @Deprecated public static final String ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED = SubscriptionManager.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED; /* * Broadcast Action: An attempt to set phone radio type and access technology has changed. * This has the following extra values: * <ul> * <li><em>phones radio access family </em> - A RadioAccessFamily * array, contain phone ID and new radio access family for each phone.</li> * </ul> * * <p class="note"> * Requires the READ_PHONE_STATE permission.
} public void testChangeFontScaleNoRelaunch() throws Exception { // Should receive onConfigurationChanged() and no relaunch testChangeFontScale(NO_RELAUNCH_ACTIVITY_NAME, false); } private void testRotation( String activityName, int rotationStep, int numRelaunch, int numConfigChange) throws Exception { executeShellCommand(getAmStartCmd(activityName)); final String[] waitForActivitiesVisible = new String[] {activityName}; mAmWmState.computeState(mDevice, waitForActivitiesVisible); final int initialRotation = 4 - rotationStep; setDeviceRotation(initialRotation); mAmWmState.computeState(mDevice, waitForActivitiesVisible); final int actualStackId = mAmWmState.getAmState().getTaskByActivityName( activityName).mStackId; final int displayId = mAmWmState.getAmState().getStackById(actualStackId).mDisplayId; final int newDeviceRotation = getDeviceRotation(displayId); if (newDeviceRotation == INVALID_DEVICE_ROTATION) { CLog.logAndDisplay(LogLevel.WARN, "Got an invalid device rotation value. " + "Continuing the test despite of that, but it is likely to fail.");
Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); if (mNetworkSpecifier != null && !NetworkSpecifier.isWhitelistedNetworkSpecifier( mNetworkSpecifier)) { throw new IllegalArgumentException("Invalid network specifier"); } dest.writeParcelable((Parcelable) mNetworkSpecifier, flags); dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); try { netCap.mNetworkSpecifier = in.readParcelable(null);
new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); try { netCap.mNetworkSpecifier = in.readParcelable(null); } catch (Exception e) { Log.e(TAG, "Exception: e=" + e); netCap.mNetworkSpecifier = null; } netCap.mSignalStrength = in.readInt(); return netCap; } @Override public NetworkCapabilities[] newArray(int size) { return new NetworkCapabilities[size]; } }; @Override public String toString() { int[] types = getTransportTypes(); String transports = (types.length > 0) ? " Transports: " + transportNamesOf(types) : ""; types = getCapabilities(); String capabilities = (types.length > 0 ? " Capabilities: " : "");
*/ @Override public void onPullExternalCall() { if ((getConnectionProperties() & Connection.PROPERTY_IS_EXTERNAL_CALL) != Connection.PROPERTY_IS_EXTERNAL_CALL) { Log.w(this, "onPullExternalCall - cannot pull non-external call"); return; } if (mOriginalConnection != null) { mOriginalConnection.pullExternalCall(); } } @Override public void onStartRtt(RttTextStream textStream) { if (isImsConnection()) { ImsPhone imsPhone = (ImsPhone) getPhone(); imsPhone.sendRttModifyRequest(textStream); } else { Log.w(this, "onStartRtt - not in IMS, so RTT cannot be enabled."); } } @Override public void onStopRtt() { // This is not supported by carriers/vendor yet. No-op for now. } @Override public void handleRttUpgradeResponse(RttTextStream textStream) { Phone phone = getPhone(); if (!(phone instanceof ImsPhone)) {
if (phone instanceof ImsPhone) { ImsPhone imsPhone = (ImsPhone) phone; imsPhone.sendRttModifyRequest(textStream); } else { Log.w(this, "onStartRtt - not in IMS, so RTT cannot be enabled."); } } @Override public void onStopRtt() { // This is not supported by carriers/vendor yet. No-op for now. } @Override public void handleRttUpgradeResponse(RttTextStream textStream) { if (!isImsConnection()) { Log.w(this, "handleRttUpgradeResponse - not in IMS, so RTT cannot be enabled."); return; } ImsPhone imsPhone = (ImsPhone) phone; imsPhone.sendRttModifyResponse(textStream); } public void performHold() { Log.v(this, "performHold"); // TODO: Can dialing calls be put on hold as well since they take up the // foreground call slot? if (Call.State.ACTIVE == mConnectionState) { Log.v(this, "Holding active call"); try {
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net.wifi.aware; import android.net.NetworkSpecifier; import android.os.Parcel; import android.os.Parcelable; import java.util.Arrays; import java.util.Objects; /** * Network specifier object used to request a Wi-Fi Aware network. Apps do not create these objects * directly but obtain them using * {@link WifiAwareSession#createNetworkSpecifierOpen(int, byte[])} or
public boolean satisfiedBy(NetworkSpecifier other) { // MatchAllNetworkSpecifier is taken care in NetworkCapabilities#satisfiedBySpecifier. return equals(other);
public static List<String> getTimeZoneIdsWithUniqueOffsets(String country) { synchronized(sLastUniqueLockObj) { if ((country != null) && country.equals(sLastUniqueCountry)) { if (DBG) { Log.d(TAG, "getTimeZonesWithUniqueOffsets(" + country + "): return cached version"); } return sLastUniqueZoneOffsets; } } Collection<TimeZone> zones = getTimeZones(country); ArrayList<TimeZone> uniqueTimeZones = new ArrayList<>(); for (TimeZone zone : zones) { // See if we already have this offset, // Using slow but space efficient and these are small. boolean found = false; for (int i = 0; i < uniqueTimeZones.size(); i++) { if (uniqueTimeZones.get(i).getRawOffset() == zone.getRawOffset()) { found = true; break; } } if (!found) { if (DBG) { Log.d(TAG, "getTimeZonesWithUniqueOffsets: add unique offset=" +
private static String getCounterLabel(int counterIndex) { switch (counterIndex) { case ON_POST_DIAL_WAIT: return "onPostDialWait"; case ON_CALL_EVENT: return "onCallEvent"; case ON_PULL_EXTERNAL_CALL: return "onPullExternalCall"; case ON_EXTRAS_CHANGED: return "onExtrasChanged"; case ON_START_RTT: return "onStartRtt"; case ON_RTT_REQUEST_RESPONSE: return "onRttRequestResponse"; case ON_STOP_RTT: return "onStopRtt"; default: return "Callback"; }
mKeepaliveCallback, mConfig.getLocalAddress(), mConfig.getEncapLocalPort(), mConfig.getRemoteAddress()); try { // FIXME: this is still a horrible way to fudge the synchronous callback mKeepaliveSyncLock.wait(2000); } catch (InterruptedException e) { } } if (mKeepaliveStatus != ConnectivityManager.PacketKeepalive.SUCCESS) { throw new UnsupportedOperationException("Packet Keepalive cannot be started"); } } /* Package */ int getResourceId() { return mResourceId; } /* Package */ void stopKeepalive() { if (mKeepalive == null) { return; } mKeepalive.stop(); synchronized (mKeepaliveSyncLock) { if (mKeepaliveStatus == ConnectivityManager.PacketKeepalive.SUCCESS) { try { mKeepaliveSyncLock.wait(2000); } catch (InterruptedException e) { } } } } /** * Builder object to facilitate the creation of IpSecTransform objects. *
protected void releaseResources() { try { getNetdInstance() .ipSecDeleteSecurityAssociation( mResourceId, mDirection, mLocalAddress, mRemoteAddress, mSpi); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { Log.e(TAG, "Failed to delete SPI reservation with ID: " + mResourceId); }
INetd getNetdInstance() { final INetd netd = NetdService.getInstance(); if (netd == null) { throw new RemoteException("Failed to Get Netd Instance"); } return netd;
} return netd; } boolean isNetdAlive() { synchronized (mLock) { final INetd netd = getNetdInstance(); if (netd == null) { return false; } try { return netd.isAlive(); } catch (RemoteException re) { return false; } } } @Override /** Get a new SPI and maintain the reservation in the system server */ public Bundle reserveSecurityParameterIndex( int direction, String remoteAddress, int requestedSpi, IBinder binder) throws RemoteException { int resourceId = mNextResourceId.getAndIncrement(); int spi = IpSecManager.INVALID_SECURITY_PARAMETER_INDEX; String localAddress = ""; Bundle retBundle = new Bundle(3); try { spi = getNetdInstance() .ipSecAllocateSpi( resourceId, direction, localAddress, remoteAddress, requestedSpi); Log.d(TAG, "Allocated SPI " + spi); retBundle.putInt(KEY_STATUS, IpSecManager.Status.OK); retBundle.putInt(KEY_RESOURCE_ID, resourceId); retBundle.putInt(KEY_SPI, spi);
* Create a transport mode transform, which represent two security associations (one in each * direction) in the kernel. The transform will be cached by the system server and must be freed * when no longer needed. It is possible to free one, deleting the SA from underneath sockets * that are using it, which will result in all of those sockets becoming unable to send or * receive data. */ @Override public Bundle createTransportModeTransform(IpSecConfig c, IBinder binder) throws RemoteException { // TODO: Basic input validation here since it's coming over the Binder int resourceId = mNextResourceId.getAndIncrement(); for (int direction : DIRECTIONS) { IpSecAlgorithm auth = c.getAuthentication(direction); IpSecAlgorithm crypt = c.getEncryption(direction); try { int result = getNetdInstance() .ipSecAddSecurityAssociation( resourceId, c.getMode(), direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "",
* system server. If this is called on an inactive (or non-existent) transform, it will not * return an error. It's safe to de-allocate transforms that may have already been deleted for * other reasons. */ @Override public void deleteTransportModeTransform(int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord record; // We want to non-destructively get so that we can check credentials before removing // this from the records. record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional record.releaseResources(); mTransformRecords.remove(resourceId);
*/ @Override public void deleteTransportModeTransform(int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord record; // We want to non-destructively get so that we can check credentials before removing this record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != Binder.getCallingPid() || record.uid != Binder.getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional record.releaseResources(); mTransformRecords.remove(resourceId); record.nullifyRecord(); } } /** * Apply an active transport mode transform to a socket, which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override
if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // TODO: if releaseResources() throws RemoteException, we can try again to clean up on // binder death. Need to make sure that path is actually functional. record.releaseResources(); mTransformRecords.remove(resourceId); record.nullifyRecord(); } } /** * Apply an active transport mode transform to a socket, which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override public void applyTransportModeTransform(ParcelFileDescriptor socket, int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord info; // FIXME: this code should be factored out into a security check + getter info = mTransformRecords.get(resourceId);
// TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional record.releaseResources(); mTransformRecords.remove(resourceId); record.nullifyRecord(); } } /** * Apply an active transport mode transform to a socket, which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override public void applyTransportModeTransform(ParcelFileDescriptor socket, int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord info; // FIXME: this code should be factored out into a security check + getter info = mTransformRecords.get(resourceId); if (info == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not active"); } // TODO: make this a function. if (info.pid != getCallingPid() || info.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may apply it!"); }
} } } /** * Remove a transport mode transform from a socket, applying the default (empty) policy. This * will ensure that NO IPsec policy is applied to the socket (would be the equivalent of * applying a policy that performs no IPsec). Today the resourceId parameter is passed but not * used: reserved for future improved input validation. */ @Override public void removeTransportModeTransform(ParcelFileDescriptor socket, int resourceId) throws RemoteException { try { getNetdInstance().ipSecRemoveTransportModeTransform(socket.getFileDescriptor()); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } } @Override protected void dump(FileDescriptor fd, PrintWriter pw, String[] args) { mContext.enforceCallingOrSelfPermission(DUMP, TAG); pw.println("IpSecService Log:"); pw.println("NetdNativeService Connection: " + (isNetdAlive() ? "alive" : "dead")); pw.println(); } }
// and a remote IP address int spi; // Encryption Algorithm IpSecAlgorithm encryption; // Authentication Algorithm IpSecAlgorithm authentication; } Flow[] flow = new Flow[] {new Flow(), new Flow()}; // For tunnel mode IPv4 UDP Encapsulation // IpSecTransform#ENCAP_ESP_*, such as ENCAP_ESP_OVER_UDP_IKE int encapType; int encapLocalPort; int encapRemotePort; // An interval, in seconds between the NattKeepalive packets int nattKeepaliveInterval; // Transport or Tunnel public int getMode() { return mode; } public InetAddress getLocalAddress() { return localAddress; } public int getSpi(int direction) { return flow[direction].spi; } public InetAddress getRemoteAddress() { return remoteAddress; } public IpSecAlgorithm getEncryption(int direction) { return flow[direction].encryption; } public IpSecAlgorithm getAuthentication(int direction) {
out.writeParcelable(flow[IpSecTransform.DIRECTION_OUT].encryption, flags); out.writeParcelable(flow[IpSecTransform.DIRECTION_OUT].authentication, flags); out.writeInt(encapType); out.writeInt(encapLocalPort); out.writeInt(encapRemotePort); } // Package Private: Used by the IpSecTransform.Builder; // there should be no public constructor for this object IpSecConfig() {} private static InetAddress readInetAddressFromParcel(Parcel in) { String addrString = in.readString(); if (addrString == null) { return null; } try { return InetAddress.getByName(addrString); } catch (UnknownHostException e) { Log.wtf(TAG, "Invalid IpAddress " + addrString); return null; } } private IpSecConfig(Parcel in) { properties = in.readLong(); localAddress = readInetAddressFromParcel(in); remoteAddress = readInetAddressFromParcel(in);
* You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net; import static android.net.IpSecManager.INVALID_RESOURCE_ID; import static android.net.IpSecManager.KEY_STATUS; import static android.net.IpSecManager.KEY_RESOURCE_ID; import android.annotation.IntDef; import android.annotation.NonNull; import android.annotation.SystemApi; import android.content.Context; import android.os.Binder; import android.os.Bundle; import android.os.IBinder; import android.os.RemoteException; import android.os.ServiceManager; import android.util.Log; import com.android.internal.util.Preconditions; import dalvik.system.CloseGuard; import java.io.IOException; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.net.InetAddress; /** * This class represents an IpSecTransform, which encapsulates both properties and state of IPsec. *
private IpSecTransform(Context context, IpSecConfig config) { mContext = context; mConfig = config; mResourceId = INVALID_RESOURCE_ID; } private IIpSecService getIpSecService() { IBinder b = ServiceManager.getService(IPSEC_SERVICE); if (b == null) { throw new RemoteException("Failed to connect to IpSecService") .rethrowAsRuntimeException(); } return IIpSecService.Stub.asInterface(b); } private void checkResultStatus(int status) throws IOException, IpSecManager.ResourceUnavailableException, IpSecManager.SpiUnavailableException { switch (status) { case IpSecManager.Status.OK: return; case IpSecManager.Status.RESOURCE_UNAVAILABLE: throw new IpSecManager.ResourceUnavailableException( "Failed to allocate a new IpSecTransform"); case IpSecManager.Status.SPI_UNAVAILABLE: Log.wtf(TAG, "Attempting to use an SPI that was somehow not reserved"); // Fall through default:
mConfig = config; mResourceId = INVALID_RESOURCE_ID; } private IIpSecService getIpSecService() { IBinder b = ServiceManager.getService(IPSEC_SERVICE); if (b == null) { throw new RemoteException("Failed to connect to IpSecService") .rethrowAsRuntimeException(); } return IIpSecService.Stub.asInterface(b); } /** @hide */ public static final String KEY_STATUS = "status"; /** @hide */ public static final String KEY_RESOURCE_ID = "resourceId"; private void checkResultStatusAndThrow(int status) throws IOException, IpSecManager.ResourceUnavailableException, IpSecManager.SpiUnavailableException { switch (status) { case IpSecManager.Status.OK: return; case IpSecManager.Status.RESOURCE_UNAVAILABLE: throw new IpSecManager.ResourceUnavailableException( "Failed to allocate a new IpSecTransform"); case IpSecManager.Status.SPI_UNAVAILABLE: Log.wtf(TAG, "Attempting to use an SPI that was somehow not reserved"); // Fall through default: throw new IllegalStateException(
} private IIpSecService getIpSecService() { IBinder b = ServiceManager.getService(IPSEC_SERVICE); if (b == null) { throw new RemoteException("Failed to connect to IpSecService") .rethrowAsRuntimeException(); } return IIpSecService.Stub.asInterface(b); } /** @hide */ public static final String KEY_STATUS = "status"; /** @hide */ public static final String KEY_RESOURCE_ID = "resourceId"; private void checkResultStatusAndThrow(int status) throws IOException, IpSecManager.ResourceUnavailableException, IpSecManager.SpiUnavailableException { switch (status) { case IpSecManager.Status.OK: return; case IpSecManager.Status.RESOURCE_UNAVAILABLE: throw new IpSecManager.ResourceUnavailableException( "Failed to allocate a new IpSecTransform"); case IpSecManager.Status.SPI_UNAVAILABLE: Log.wtf(TAG, "Attempting to use an SPI that was somehow not reserved"); // Fall through default: throw new IllegalStateException( "Failed to Create a Transform with status code " + status); } } private IpSecTransform activate()
private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_SERVICE_NAME = "netd"; private static final int[] DIRECTIONS = new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}; /** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms private AtomicInteger mNextResourceId = new AtomicInteger(0x00FADED0); private abstract class ManagedResource implements IBinder.DeathRecipient { final int pid; final int uid; private IBinder mBinder; ManagedResource(IBinder binder) { super(); mBinder = binder; pid = getCallingPid(); uid = getCallingUid(); try { mBinder.linkToDeath(this, 0); } catch (RemoteException e) { binderDied(); } } /** * When this record is no longer needed for managing system resources this function should * unlink all references held by the record to allow efficient garbage collection. */
/** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms private AtomicInteger mNextTransformId = new AtomicInteger(0xFADED000); private abstract class ManagedResource implements IBinder.DeathRecipient { final int pid; final int uid; private IBinder mBinder; ManagedResource(IBinder binder) { super(); mBinder = binder; pid = Binder.getCallingPid(); uid = Binder.getCallingUid(); try { mBinder.linkToDeath(this, 0); } catch (RemoteException e) { binderDied(); } } /** * When this record is no longer needed for managing system resources this function should * unlink all references held by the record to allow efficient garbage collection. */ public final void release() { //Release all the underlying system resources first releaseResources(); if (mBinder != null) { mBinder.unlinkToDeath(this, 0); } mBinder = null;
protected void releaseResources() { for (int direction : DIRECTIONS) { try { getNetdInstance() .ipSecDeleteSecurityAssociation( mResourceId, direction, (mConfig.getLocalAddress() != null) ? mConfig.getLocalAddress().getHostAddress() : "", (mConfig.getRemoteAddress() != null) ? mConfig.getRemoteAddress().getHostAddress() : "", mConfig.getSpi(direction)); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } }
mResourceId, direction, (mConfig.getLocalAddress() != null) ? mConfig.getLocalAddress().getHostAddress() : "", (mConfig.getRemoteAddress() != null) ? mConfig.getRemoteAddress().getHostAddress() : "", mConfig.getSpi(direction)); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { Log.e(TAG, "Failed to delete SA with ID: " + mResourceId); } }
retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_RESOURCE_ID, resourceId); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_SPI, spi); synchronized (mSpiRecords) { mSpiRecords.put( resourceId, new SpiRecord( resourceId, direction, localAddress, remoteAddress, spi, binder)); } } catch (ServiceSpecificException e) { // TODO: Add appropriate checks when other ServiceSpecificException types are supported retBundle.putInt(KEY_STATUS, IpSecManager.Status.SPI_UNAVAILABLE); retBundle.putInt(KEY_RESOURCE_ID, resourceId); retBundle.putInt(KEY_SPI, spi); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } return retBundle;
public void deleteTransportModeTransform(int resourceId) { synchronized (mTransformRecords) { TransformRecord record; // We want to non-destructively get so that we can check credentials before removing // this from the records. record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // remove from the DB because releasing might fail, but it won't ever succeed later mTransformRecords.remove(resourceId); record.releaseResources(); record.nullifyRecord(); }
record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional record.releaseResources(); record.nullifyRecord(); }
info = mTransformRecords.get(resourceId); if (info == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not active"); } if (info.pid != getCallingPid() || info.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may apply it!"); } IpSecConfig c = info.getConfig(); try { for (int direction : DIRECTIONS) { getNetdInstance() .ipSecApplyTransportModeTransform( socket.getFileDescriptor(), resourceId, direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", c.getSpi(direction)); } } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception
* <h3>Developer Guides</h3> * <p>For more information about using Bluetooth, read the * <a href="{@docRoot}guide/topics/connectivity/bluetooth.html">Bluetooth</a> developer guide.</p> * </div> * * {@see BluetoothServerSocket} * {@see java.io.InputStream} * {@see java.io.OutputStream} */ public final class BluetoothSocket implements Closeable { private static final String TAG = "BluetoothSocket"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final boolean VDBG = Log.isLoggable(TAG, Log.VERBOSE); /** @hide */ public static final int MAX_RFCOMM_CHANNEL = 30; /*package*/ static final int MAX_L2CAP_PACKAGE_SIZE = 0xFFFF; /** RFCOMM socket */ public static final int TYPE_RFCOMM = 1; /** SCO socket */ public static final int TYPE_SCO = 2; /** L2CAP socket */ public static final int TYPE_L2CAP = 3; /*package*/ static final int EBADFD = 77; /*package*/ static final int EADDRINUSE = 98;
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net.cts; import android.content.Context; import android.net.ConnectivityManager; import android.net.IpSecAlgorithm; import android.net.IpSecManager; import android.net.IpSecTransform; import android.net.Network; import android.test.AndroidTestCase; import java.io.IOException; import java.net.DatagramPacket; import java.net.DatagramSocket; import java.net.InetAddress; import java.net.UnknownHostException;
public void testAllocSpi() throws Exception { for (InetAddress addr : GOOGLE_DNS_LIST) { IpSecManager.SecurityParameterIndex randomSpi = null, droidSpi = null; try { randomSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_OUT, addr, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); assertTrue(randomSpi.getSpi() != IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); droidSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue(droidSpi.getSpi() == DROID_SPI); } catch (IpSecManager.ResourceUnavailableException | IpSecManager.SpiUnavailableException ru) { assertTrue(false); } // This *should* throw an SpiUnavailableException try { mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue(false); // we expect an exception in the above call } catch (IpSecManager.ResourceUnavailableException ru) { assertTrue(false); } catch (IpSecManager.SpiUnavailableException sp) { } randomSpi.close(); droidSpi.close(); }
try { randomSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_OUT, addr, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); assertTrue(randomSpi.getSpi() != IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); droidSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue(droidSpi.getSpi() == DROID_SPI); } catch (IpSecManager.ResourceUnavailableException | IpSecManager.SpiUnavailableException ru) { assertTrue(false); } try { mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue(false); // we expect an exception in the above call } catch (IpSecManager.ResourceUnavailableException ru) { assertTrue(false); } catch (IpSecManager.SpiUnavailableException sp) { } randomSpi.close(); droidSpi.close(); }
public void testCreateTransform() { try { IpSecManager.SecurityParameterIndex inSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, local, outSpi.getSpi()); IpSecManager.SecurityParameterIndex inSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, remote, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); IpSecTransform firstTransform = new IpSecTransform.Builder(mContext) .setSpi(IpSecTransform.DIRECTION_OUT, outSpi) .setEncryption( IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm( IpSecAlgorithm.ALGO_CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication( IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm( IpSecAlgorithm.ALGO_AUTH_HMAC_SHA256, AUTH_KEY, AUTH_KEY.length * 8)) .setSpi(IpSecTransform.DIRECTION_IN, inSpi) .setEncryption( IpSecTransform.DIRECTION_IN, new IpSecAlgorithm( IpSecAlgorithm.ALGO_CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication(
TimeZone biasMatch = null; for (int i = 0; i < candidates.size(); i++) { TimeZone match = candidates.get(i); if (!offsetMatchesAtTime(match, offsetSeconds, isDst, whenMillis)) { continue; } if (firstMatch == null) { firstMatch = match; if (bias == null) { // Terminate early if there is no bias. break; } } if (match.getID().equals(bias.getID())) { return match; } } TimeZone toReturn; if (biasMatch != null) { toReturn = biasMatch; } else if (firstMatch != null) { toReturn = firstMatch; } else { return null; } return toReturn;
import java.nio.file.Path; import java.nio.file.SimpleFileVisitor; import java.nio.file.attribute.BasicFileAttributes; import java.util.Arrays; import java.util.HashMap; import java.util.HashSet; import java.util.List; import java.util.Map; import java.util.Set; import java.util.stream.Collectors; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertNull; import static org.junit.Assert.fail; public class TimeZoneFinderTest { private static final int HOUR_MILLIS = 60 * 60 * 1000; // Zones used in the tests. NEW_YORK_TZ and LONDON_TZ chosen because they never overlap but both // have DST. private static final TimeZone NEW_YORK_TZ = TimeZone.getTimeZone("America/New_York"); private static final TimeZone LONDON_TZ = TimeZone.getTimeZone("Europe/London"); // A zone that matches LONDON_TZ for WHEN_NO_DST. It does not have DST so differs for WHEN_DST.
} @Test public void xmlParsing_emptyFile() throws Exception { checkThrowsParserException(""); } @Test public void xmlParsing_unexpectedRootElement() throws Exception { checkThrowsParserException("<foo></foo>\n"); } @Test public void xmlParsing_missingCountryZones() throws Exception { checkThrowsParserException("<timezones></timezones>\n"); } @Test public void xmlParsing_noCountriesOk() throws Exception { validate("<timezones>\n" + " <countryzones>\n" + " </countryzones>\n" + "</timezones>\n"); } @Test public void xmlParsing_unexpectedElementsIgnored() throws Exception { String unexpectedElement = "<unexpected-element>\n<a /></unexpected-element>\n"; TimeZoneFinder finder = parse("<timezones>\n" + " " + unexpectedElement + " <countryzones>\n" + " <country code=\"gb\">\n" + " <id>Europe/London</id>\n" + " </country>\n" + " </countryzones>\n" + "</timezones>\n");
checkThrowsParserException("<foo></foo>\n"); } @Test public void xmlParsing_missingCountryZones() throws Exception { checkThrowsParserException("<timezones></timezones>\n"); } @Test public void xmlParsing_noCountriesOk() throws Exception { parse("<timezones>\n" + " <countryzones>\n" + " </countryzones>\n" + "</timezones>\n"); } @Test public void xmlParsing_unexpectedElementsIgnored() throws Exception { String unexpectedElement = "<unexpected-element>\n<a /></unexpected-element>\n"; TimeZoneFinder finder = validate("<timezones>\n" + " " + unexpectedElement + " <countryzones>\n" + " <country code=\"gb\">\n" + " <id>Europe/London</id>\n" + " </country>\n" + " </countryzones>\n" + "</timezones>\n"); assertZonesEqual(zones("Europe/London"), finder.lookupTimeZonesByCountry("gb")); finder = parse("<timezones>\n" + " <countryzones>\n" + " " + unexpectedElement
mHandler.sendMessageDelayed(msg1, 1000); } } break; case MSG_INCOMING_CONNECTION_RETRY: if (mBatchs.size() == 0) { Log.i(TAG, "Start Obex Server"); createServerSession(mPendingConnection); mIncomingRetries = 0; mPendingConnection = null; } else { if (mIncomingRetries == 20) { Log.w(TAG, "Retried 20 seconds, reject connection"); try { mPendingConnection.close(); } catch (IOException e) { Log.e(TAG, "close tranport error"); } mIncomingRetries = 0; mPendingConnection = null; } else { Log.i(TAG, "OPP busy! Retry after 1 second"); mIncomingRetries = mIncomingRetries + 1; Message msg2 = Message.obtain(mHandler); msg2.what = MSG_INCOMING_CONNECTION_RETRY; mHandler.sendMessageDelayed(msg2, 1000); } } break; }
protected void releaseResources() { for (int direction : DIRECTIONS) { try { getNetdInstance() .ipSecDeleteSecurityAssociation( mResourceId, direction, (mConfig.getLocalAddress() != null) ? mConfig.getLocalAddress().getHostAddress() : "", (mConfig.getRemoteAddress() != null) ? mConfig.getRemoteAddress().getHostAddress() : "", mConfig.getSpi(direction)); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } }
protected void setUp() throws Exception { super.setUp(); mCM = (ConnectivityManager) getContext().getSystemService(Context.CONNECTIVITY_SERVICE); mISM = (IpSecManager) getContext().getSystemService(Context.IPSEC_SERVICE); } /* * Allocate a random SPI * Allocate a specific SPI using previous randomly created SPI value * Realloc the same SPI that was specifically created (expect SpiUnavailable) * Close SPIs */ public void testAllocSpi() throws Exception { for (InetAddress addr : GOOGLE_DNS_LIST) { IpSecManager.SecurityParameterIndex randomSpi = null, droidSpi = null; randomSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_OUT, addr, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); assertTrue(randomSpi.getSpi() != IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); droidSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue( "Failed to allocate specified SPI, " + DROID_SPI, droidSpi.getSpi() == DROID_SPI); try {
// This is a success case because we expect a dupe SPI to throw } randomSpi.close(); droidSpi.close(); } } /* * Alloc outbound SPI * Alloc inbound SPI * Create transport mode transform * open socket * apply transform to socket * send data on socket * release transform * send data (expect exception) */ public void testCreateTransform() throws Exception { InetAddress local = InetAddress.getLoopbackAddress(); IpSecManager.SecurityParameterIndex outSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_OUT, local, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); IpSecManager.SecurityParameterIndex inSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, local, outSpi.getSpi()); IpSecTransform transform = new IpSecTransform.Builder(mContext) .setSpi(IpSecTransform.DIRECTION_OUT, outSpi) .setEncryption( IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm(IpSecAlgorithm.CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication( IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm( IpSecAlgorithm.AUTH_HMAC_SHA256,
if (length == 1) { return symbol.charAt(0); } if (length > 1) { char first = symbol.charAt(0); char second = symbol.charAt(1); if (first == '\u200E' || first == '\u200F' || first == '\u061C') { return second; } if (length == 2 && (second == '\u200E' || second == '\u200F' || second == '\u061C')) { return first; } } return fallback;
public NetworkCapabilities setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier != null && Long.bitCount(mTransportTypes) != 1) { throw new IllegalStateException("Must have a single transport specified to use " + "setNetworkSpecifier"); } mNetworkSpecifier = networkSpecifier; return this;
* it should document their particulars. For example, Bluetooth may use some sort of * device id while WiFi could used ssid and/or bssid. Cellular may use carrier spn. * * @param networkSpecifier An {@code String} of opaque format used to specify the bearer * specific network specifier where the bearer has a choice of * networks. */ public Builder setNetworkSpecifier(String networkSpecifier) { return setNetworkSpecifierObject(TextUtils.isEmpty(networkSpecifier) ? null : new StringNetworkSpecifier(networkSpecifier)); } /** * Sets the optional bearer specific network specifier. * This has no meaning if a single transport is also not specified, so calling * this without a single transport set will generate an exception, as will * subsequently adding or removing transports after this is set. * </p> * * @param networkSpecifier A concrete, parcelable framework class that extends * NetworkSpecifier. * * @hide */ public Builder setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier instanceof MatchAllNetworkSpecifier) {
} /** * Sets the optional bearer specific network specifier. * This has no meaning if a single transport is also not specified, so calling * this without a single transport set will generate an exception, as will * subsequently adding or removing transports after this is set. * </p> * * @param networkSpecifier A concrete, parcelable framework class that extends * NetworkSpecifier. * * @hide */ public Builder setNetworkSpecifierObject(NetworkSpecifier networkSpecifier) { if (networkSpecifier instanceof MatchAllNetworkSpecifier) { throw new IllegalArgumentException( "NetworkRequests must not use MatchAllNetworkSpecifier"); } mNetworkCapabilities.setNetworkSpecifier(networkSpecifier); return this; } /** * Sets the signal strength. This is a signed integer, with higher values indicating a * stronger signal. The exact units are bearer-dependent. For example, Wi-Fi uses the same * RSSI units reported by WifiManager. * <p> * Note that when used to register a network callback, this specifies the minimum acceptable
* distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net; /** * Describes specific properties of a network for use in a {@link NetworkRequest}. * * Applications cannot instantiate this class by themselves, but can obtain instances of * subclasses of this class via other APIs. * * @hide */ public abstract class NetworkSpecifier { /** * Validate that the input NetworkSpecifier is one of the whitelisted types. * * @hide */ public static boolean isWhitelistedNetworkSpecifier(NetworkSpecifier ns) { return ns instanceof MatchAllNetworkSpecifier || ns instanceof StringNetworkSpecifier; } /** * @hide */ public NetworkSpecifier() {} /** * Returns true if a request with this {@link NetworkSpecifier} is satisfied by a network * with the given NetworkSpecifier. * * @hide */
/** * Describes specific properties of a network for use in a {@link NetworkRequest}. * * Applications cannot instantiate this class by themselves, but can obtain instances of this * class via other APIs. * * @hide */ public abstract class NetworkSpecifier { /** * Validate that the input NetworkSpecifier is one of the whitelisted types. * * @hide */ public NetworkSpecifier() {} /** * Returns true if a request with this {@link NetworkSpecifier} is satisfied by a network * with the given NetworkSpecifier. * * @hide */ public abstract boolean satisfiedBy(NetworkSpecifier other); }
|| wiFiEnabledState == WifiManager.WIFI_STATE_DISABLED) { if (startConsentUi(packageName, Binder.getCallingUid(), WifiManager.ACTION_REQUEST_ENABLE)) { return true; } } } else if (wiFiEnabledState == WifiManager.WIFI_STATE_ENABLING || wiFiEnabledState == WifiManager.WIFI_STATE_ENABLED) { if (startConsentUi(packageName, Binder.getCallingUid(), WifiManager.ACTION_REQUEST_DISABLE)) { return true; } } } mWifiController.sendMessage(CMD_WIFI_TOGGLED); return true; } /** * see {@link WifiManager#getWifiState()} * @return One of {@link WifiManager#WIFI_STATE_DISABLED}, * {@link WifiManager#WIFI_STATE_DISABLING}, * {@link WifiManager#WIFI_STATE_ENABLED}, * {@link WifiManager#WIFI_STATE_ENABLING}, * {@link WifiManager#WIFI_STATE_UNKNOWN} */ @Override public int getWifiEnabledState() { enforceAccessPermission(); mLog.trace("getWifiEnabledState uid=%").c(Binder.getCallingUid()).flush();
* the grouping separator, and so on) needed by <code>DecimalFormat</code> * to format numbers. <code>DecimalFormat</code> creates for itself an instance of * <code>DecimalFormatSymbols</code> from its locale data. If you need to change any * of these symbols, you can get the <code>DecimalFormatSymbols</code> object from * your <code>DecimalFormat</code> and modify it. * * @see java.util.Locale * @see DecimalFormat * @author Mark Davis * @author Alan Liu */ public class DecimalFormatSymbols implements Cloneable, Serializable { // Android-changed: Removed reference to DecimalFormatSymbolsProvider but suggested // getInstance() be used instead in case Android supports it in future. /** * Create a DecimalFormatSymbols object for the default * {@link java.util.Locale.Category#FORMAT FORMAT} locale. * It is recommended that the {@link #getInstance(Locale) getInstance} method is used * instead. * <p>This is equivalent to calling * {@link #DecimalFormatSymbols(Locale)
public void testBluetoothDirWrite() { try { File file = new File("/data/misc/bluetooth/test.file"); assertTrue("File not created", file.createNewFile()); file.delete(); } catch (IOException e) { fail("Exception creating file /data/misc/bluetooth/test.file: " + e); }
assertEquals( TimeZoneDistroInstaller.INSTALL_SUCCESS, installer.stageInstallWithErrorCode(stagedDistro.getBytes())); assertInstallDistroStaged(stagedDistro); TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder(NEWER_RULES_VERSION, 1) .setTzLookupXml(null) .buildUnvalidated(); assertEquals( TimeZoneDistroInstaller.INSTALL_FAIL_BAD_DISTRO_STRUCTURE, installer.stageInstallWithErrorCode(incompleteDistro.getBytes())); assertInstallDistroStaged(stagedDistro); assertNoInstalledDistro(); } /** Tests that a distro with a bad tzlookup file will not update the content. */ public void testStageInstallWithErrorCode_badTzLookupFile() throws Exception { TimeZoneDistro stagedDistro = createValidTimeZoneDistro(NEW_RULES_VERSION, 1); assertEquals( TimeZoneDistroInstaller.INSTALL_SUCCESS, installer.stageInstallWithErrorCode(stagedDistro.getBytes())); assertInstallDistroStaged(stagedDistro); TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder(NEWER_RULES_VERSION, 1) .setTzLookupXml("<foo />") .buildUnvalidated(); assertEquals( TimeZoneDistroInstaller.INSTALL_FAIL_VALIDATION_ERROR, installer.stageInstallWithErrorCode(incompleteDistro.getBytes())); assertInstallDistroStaged(stagedDistro);
/** * Attempts to strip RTL, LTR and Arabic letter markers from {@code symbol}. * If the string contains a single non-marker character (and any number of marker characters), * then that character is returned, otherwise {@code fallback} is returned. * * @hide */ // VisibleForTesting public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length == 1) { char c = symbol.charAt(0); if (c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000') { return c; } } else if (length > 1) { char nonMarker = 0; for (char c : symbol.toCharArray()) {
/** * Attempts to strip RTL, LTR and Arabic letter markers from {@code symbol}. * If the string contains a single non-marker character (and any number of marker characters), * then that character is returned, otherwise {@code fallback} is returned. * * @hide */ // VisibleForTesting public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length == 1) { char c = symbol.charAt(0); if (c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000') { return c; } } else if (length > 1) { char nonMarker = 0; for (char c : symbol.toCharArray()) {
public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length == 1) { char c = symbol.charAt(0); if (c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000') { return c; } } else if (length > 1) { char nonMarker = 0; for (int i = 0; i < length; i++) { char c = symbol.charAt(i); if (c == '\u200E' || c == '\u200F' || c == '\u061C') { continue; } if (nonMarker != 0 || c == '\u0000') { // more than one non-marker character or U+0000 in the input string. return fallback; } nonMarker = c; } if (nonMarker != 0) { return nonMarker; } } return fallback;
public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length >= 1) { boolean sawNonMarker = false; char nonMarker = 0; for (int i = 0; i < length; i++) { final char c = symbol.charAt(i); if (c == '\u200E' || c == '\u200F' || c == '\u061C') { continue; } if (sawNonMarker) { // More than one non-marker character. return fallback; } sawNonMarker = true; nonMarker = c; } if (sawNonMarker) { return nonMarker; } } return fallback;
private final StateMachine mTetherMasterSM; private final OffloadController mOffloadController; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor; private volatile TetheringConfiguration mConfig; private String mCurrentUpstreamIface; private Notification.Builder mTetheredNotificationBuilder; private int mLastNotificationId; public enum Mode { IDLE("idle"), TETHERING("tethering"), LOCAL_HOTSPOT("local_only_hotspot"); public final String description; Mode(String description) { this.description = description; } } private boolean mRndisEnabled; // track the RNDIS function enabled state private boolean mUsbTetherRequested; // true if USB tethering should be started // when RNDIS is enabled // True iff WiFi tethering should be started when soft AP is ready. private boolean mWifiTetherRequested; public Tethering(Context context, INetworkManagementService nmService, INetworkStatsService statsService, INetworkPolicyManager policyManager, Looper looper, MockableSystemProperties systemProperties) { mContext = context; mNMService = nmService; mStatsService = statsService; mPolicyManager = policyManager; mLooper = looper; mSystemProperties = systemProperties;
return ConnectivityManager.TETHER_ERROR_UNKNOWN_IFACE; } // Ignore the error status of the interface. If the interface is available, // the errors are referring to past tethering attempts anyway. if (tetherState.lastState != IControlsTethering.STATE_AVAILABLE) { Log.e(TAG, "Tried to Tether an unavailable iface: " + iface + ", ignoring"); return ConnectivityManager.TETHER_ERROR_UNAVAIL_IFACE; } tetherState.mStateMachine.sendMessage(TetherInterfaceStateMachine.CMD_TETHER_REQUESTED); return ConnectivityManager.TETHER_ERROR_NO_ERROR; }
private final StateMachine mTetherMasterSM; private final OffloadController mOffloadController; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor; private volatile TetheringConfiguration mConfig; private String mCurrentUpstreamIface; private Notification.Builder mTetheredNotificationBuilder; private int mLastNotificationId; public enum Mode { IDLE("idle"), TETHERING("tethering"), LOCAL_HOTSPOT("local_only_hotspot"); public final String description; Mode(String description) { this.description = description; } } private boolean mRndisEnabled; // track the RNDIS function enabled state private boolean mUsbTetherRequested; // true if USB tethering should be started // when RNDIS is enabled // True iff WiFi tethering should be started when soft AP is ready. private boolean mWifiTetherRequested; public Tethering(Context context, INetworkManagementService nmService, INetworkStatsService statsService, INetworkPolicyManager policyManager, Looper looper, MockableSystemProperties systemProperties) { mContext = context; mNMService = nmService; mStatsService = statsService; mPolicyManager = policyManager; mLooper = looper; mSystemProperties = systemProperties;
public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { // Adding a new downstream appends it to the list. Adding a // downstream a second time without first removing it has no effect. mActiveDownstreams.offer(downstream); updateIPv6TetheringInterfaces(); }
// Make a local copy, so we can modify it. final RaParams deprecated = new RaParams(deprecatedParams); // Remove any ULA DNS servers. removeULAs(deprecated.dnses); // Process newly deprecated information. mDeprecatedInfoTracker.putPrefixes(deprecated.prefixes); mDeprecatedInfoTracker.putDnses(deprecated.dnses); } // Make a local copy, so we can modify it. final RaParams params = (newParams != null) ? new RaParams(newParams) : null; if (params != null) { // Remove any ULA DNS servers. removeULAs(params.dnses); // Process information that is no longer deprecated. mDeprecatedInfoTracker.removePrefixes(newParams.prefixes); mDeprecatedInfoTracker.removeDnses(newParams.dnses); } mRaParams = params; assembleRaLocked(); } maybeNotifyMulticastTransmitter();
when(mResources.getStringArray( com.android.internal.R.array.config_mobile_hotspot_provision_app)) .thenReturn(new String[] {"malformedApp"}); assertTrue(!mTethering.isTetherProvisioningRequired()); } private void sendWifiApStateChanged(int state) { final Intent intent = new Intent(WifiManager.WIFI_AP_STATE_CHANGED_ACTION); intent.putExtra(WifiManager.EXTRA_WIFI_AP_STATE, state); mServiceContext.sendStickyBroadcastAsUser(intent, UserHandle.ALL); } @Test public void workingLocalOnlyHotspot() throws Exception { when(mConnectivityManager.isTetheringSupported()).thenReturn(true); when(mWifiManager.setWifiApEnabled(any(WifiConfiguration.class), anyBoolean())) .thenReturn(true); // Emulate externally-visible WifiManager effects, causing the // per-interface state machine starts up, and telling us that hotspot // mode is to be started. mTethering.interfaceStatusChanged(mTestIfname, true); sendWifiApStateChanged(WifiManager.WIFI_AP_STATE_ENABLED); mLooper.dispatchAll(); verify(mNMService, times(1)).listInterfaces(); verify(mNMService, times(1)).getInterfaceConfig(mTestIfname);
intent.putExtra(WifiManager.EXTRA_WIFI_AP_STATE, state); mServiceContext.sendStickyBroadcastAsUser(intent, UserHandle.ALL); } @Test public void workingWifiHotspot() throws Exception { when(mConnectivityManager.isTetheringSupported()).thenReturn(true); when(mWifiManager.setWifiApEnabled(any(WifiConfiguration.class), anyBoolean())) .thenReturn(true); // Emulate externally-visible WifiManager effects, causing the // per-interface state machine to start up, and telling us that // hotspot mode is to be started. mTethering.interfaceStatusChanged(mTestIfname, true); sendWifiApStateChanged(WifiManager.WIFI_AP_STATE_ENABLED); mLooper.dispatchAll(); verify(mNMService, times(1)).listInterfaces(); verify(mNMService, times(1)).getInterfaceConfig(mTestIfname); verify(mNMService, times(1)) .setInterfaceConfig(eq(mTestIfname), any(InterfaceConfiguration.class)); verify(mNMService, times(1)).tetherInterface(mTestIfname); verify(mNMService, times(1)).setIpForwardingEnabled(true); verify(mNMService, times(1)).startTethering(any(String[].class)); verifyNoMoreInteractions(mNMService);
private void combineSpecifiers(NetworkCapabilities nc) { if (mNetworkSpecifier != null && !mNetworkSpecifier.equals(nc.mNetworkSpecifier)) { throw new IllegalStateException("Can't combine two networkSpecifiers"); } setNetworkSpecifier(nc.getNetworkSpecifier());
private void combineSpecifiers(NetworkCapabilities nc) { if (mNetworkSpecifier != null && !mNetworkSpecifier.equals(nc.getNetworkSpecifier())) { throw new IllegalStateException("Can't combine two networkSpecifiers"); } setNetworkSpecifier(nc.mNetworkSpecifier);
public NetworkRequest pendingRequestForNetwork(NetworkCapabilities networkCapabilities, PendingIntent operation) { checkNotNull(operation, "PendingIntent cannot be null."); networkCapabilities = new NetworkCapabilities(networkCapabilities); enforceNetworkRequestPermissions(networkCapabilities); enforceMeteredApnPolicy(networkCapabilities); ensureRequestableCapabilities(networkCapabilities); MatchAllNetworkSpecifier.checkNotMatchAllNetworkSpecifier( networkCapabilities.getNetworkSpecifier()); NetworkRequest networkRequest = new NetworkRequest(networkCapabilities, TYPE_NONE, nextNetworkRequestId(), NetworkRequest.Type.REQUEST); NetworkRequestInfo nri = new NetworkRequestInfo(networkRequest, operation); if (DBG) log("pendingRequest for " + nri); mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_REQUEST_WITH_INTENT, nri)); return networkRequest;
NetworkCapabilities nc = new NetworkCapabilities(networkCapabilities); if (!ConnectivityManager.checkChangePermission(mContext)) { // Apps without the CHANGE_NETWORK_STATE permission can't use background networks, so // make all their listens include NET_CAPABILITY_FOREGROUND. That way, they will get // onLost and onAvailable callbacks when networks move in and out of the background. // There is no need to do this for requests because an app without CHANGE_NETWORK_STATE // can't request networks. nc.addCapability(NET_CAPABILITY_FOREGROUND); } MatchAllNetworkSpecifier.checkNotMatchAllNetworkSpecifier( networkCapabilities.getNetworkSpecifier()); NetworkRequest networkRequest = new NetworkRequest(nc, TYPE_NONE, nextNetworkRequestId(), NetworkRequest.Type.LISTEN); NetworkRequestInfo nri = new NetworkRequestInfo(messenger, networkRequest, binder); if (VDBG) log("listenForNetwork for " + nri); mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_LISTENER, nri)); return networkRequest;
public void pendingListenForNetwork(NetworkCapabilities networkCapabilities, PendingIntent operation) { checkNotNull(operation, "PendingIntent cannot be null."); if (!hasWifiNetworkListenPermission(networkCapabilities)) { enforceAccessPermission(); } MatchAllNetworkSpecifier.checkNotMatchAllNetworkSpecifier( networkCapabilities.getNetworkSpecifier()); NetworkRequest networkRequest = new NetworkRequest( new NetworkCapabilities(networkCapabilities), TYPE_NONE, nextNetworkRequestId(), NetworkRequest.Type.LISTEN); NetworkRequestInfo nri = new NetworkRequestInfo(networkRequest, operation); if (VDBG) log("pendingListenForNetwork for " + nri); mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_LISTENER, nri));
public void setNetworkSpecifier(NetworkSpecifier networkSpecifier) { mNetworkCapabilities.setNetworkSpecifier(networkSpecifier); mNetworkAgent.sendNetworkCapabilities(mNetworkCapabilities);
public void testNetworkSpecifier() { NetworkRequest rEmpty1 = newWifiRequestBuilder().build(); NetworkRequest rEmpty2 = newWifiRequestBuilder().setNetworkSpecifier((String) null).build(); NetworkRequest rEmpty3 = newWifiRequestBuilder().setNetworkSpecifier("").build(); NetworkRequest rEmpty4 = newWifiRequestBuilder().setNetworkSpecifier( (NetworkSpecifier) null).build(); NetworkRequest rFoo = newWifiRequestBuilder().setNetworkSpecifier("foo").build(); NetworkRequest rBar = newWifiRequestBuilder().setNetworkSpecifier( new StringNetworkSpecifier("bar")).build(); TestNetworkCallback cEmpty1 = new TestNetworkCallback(); TestNetworkCallback cEmpty2 = new TestNetworkCallback(); TestNetworkCallback cEmpty3 = new TestNetworkCallback(); TestNetworkCallback cEmpty4 = new TestNetworkCallback(); TestNetworkCallback cFoo = new TestNetworkCallback(); TestNetworkCallback cBar = new TestNetworkCallback(); TestNetworkCallback[] emptyCallbacks = new TestNetworkCallback[] { cEmpty1, cEmpty2, cEmpty3 }; mCm.registerNetworkCallback(rEmpty1, cEmpty1); mCm.registerNetworkCallback(rEmpty2, cEmpty2); mCm.registerNetworkCallback(rEmpty3, cEmpty3);
mCm.registerNetworkCallback(rEmpty3, cEmpty3); mCm.registerNetworkCallback(rEmpty4, cEmpty4); mCm.registerNetworkCallback(rFoo, cFoo); mCm.registerNetworkCallback(rBar, cBar); mWiFiNetworkAgent = new MockNetworkAgent(TRANSPORT_WIFI); mWiFiNetworkAgent.connect(false); cEmpty1.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty2.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty3.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty4.expectAvailableCallbacks(mWiFiNetworkAgent); assertNoCallbacks(cFoo, cBar); mWiFiNetworkAgent.setNetworkSpecifier(new StringNetworkSpecifier("foo")); cFoo.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c: emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } cFoo.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); cFoo.assertNoCallback(); mWiFiNetworkAgent.setNetworkSpecifier("bar"); cFoo.expectCallback(CallbackState.LOST, mWiFiNetworkAgent); cBar.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c: emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); }
cEmpty2.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty3.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty4.expectAvailableCallbacks(mWiFiNetworkAgent); assertNoCallbacks(cFoo, cBar); mWiFiNetworkAgent.setNetworkSpecifier("foo"); cFoo.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c: emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } cFoo.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); cFoo.assertNoCallback(); mWiFiNetworkAgent.setNetworkSpecifier(new StringNetworkSpecifier("bar")); cFoo.expectCallback(CallbackState.LOST, mWiFiNetworkAgent); cBar.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c: emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } cBar.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); cBar.assertNoCallback(); mWiFiNetworkAgent.setNetworkSpecifier(null); cBar.expectCallback(CallbackState.LOST, mWiFiNetworkAgent); for (TestNetworkCallback c: emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } assertNoCallbacks(cEmpty1, cEmpty2, cEmpty3, cFoo, cBar);
}; class ParcelableSpecifier extends NonParcelableSpecifier implements Parcelable { @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel p, int flags) {} } NetworkRequest.Builder builder; builder = new NetworkRequest.Builder().addTransportType(TRANSPORT_ETHERNET); try { builder.setNetworkSpecifier(new NonParcelableSpecifier()); Parcel parcelW = Parcel.obtain(); builder.build().writeToParcel(parcelW, 0); fail("Parceling a non-parcelable specifier did not throw an exception"); } catch (Exception e) { // expected }
private int phoneIdForRequest(NetworkRequest netRequest) { NetworkSpecifier specifier = netRequest.networkCapabilities.getNetworkSpecifier(); int subId; if (specifier == null) { subId = mDefaultDataSubscription; } else if (specifier instanceof StringNetworkSpecifier) { try { subId = Integer.parseInt(((StringNetworkSpecifier) specifier).specifier); } catch (NumberFormatException e) { Rlog.e(LOG_TAG, "NumberFormatException on " + ((StringNetworkSpecifier) specifier).specifier); subId = INVALID_SUBSCRIPTION_ID; } } else { subId = INVALID_SUBSCRIPTION_ID; } int phoneId = INVALID_PHONE_INDEX; if (subId == INVALID_SUBSCRIPTION_ID) return phoneId; for (int i = 0 ; i < mNumPhones; i++) { if (mPhoneSubscriptions[i] == subId) { phoneId = i; break; } } return phoneId;
* You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net; /** * Describes specific properties of a network for use in a {@link NetworkRequest}. * * Applications cannot instantiate this class by themselves, but can obtain instances of * subclasses of this class via other APIs. */ public abstract class NetworkSpecifier { public NetworkSpecifier() {} /** * Returns true if a request with this {@link NetworkSpecifier} is satisfied by a network * with the given NetworkSpecifier. * * @hide */ public abstract boolean satisfiedBy(NetworkSpecifier other); }
public void resize(int newSize) { Preconditions.checkArgumentNonnegative(newSize); if (newSize <= mValues.length) { Arrays.fill(mValues, newSize, mValues.length, 0); } else { ensureCapacity(newSize - mSize); }
public void resize(int newSize) { int oldSize = mSize; mSize = newSize; ensureCapacity(mSize); if (newSize < oldSize) { Arrays.fill(mValues, newSize, oldSize, 0); } mSize = newSize;
public void resize(int newSize) { // TODO throw on negative Size int oldSize = mSize; mSize = newSize; ensureCapacity(mSize); if (newSize < oldSize) { Arrays.fill(mValues, newSize, oldSize, 0); } mSize = newSize;
public void resize(int newSize) { // TODO throw on negative Size int oldSize = mSize; mSize = newSize; ensureCapacity(mSize); if (newSize < oldSize) { Arrays.fill(mValues, newSize, oldSize, 0); } mSize = newSize;
// changes network state. http://b/29964605 enforceMeteredApnPolicy(networkCapabilities); } ensureRequestableCapabilities(networkCapabilities); if (timeoutMs < 0) { throw new IllegalArgumentException("Bad timeout specified"); } if (networkCapabilities.getNetworkSpecifier() instanceof MatchAllNetworkSpecifier) { throw new IllegalArgumentException("NetworkRequest with MatchAllNetworkSpecifier"); } NetworkRequest networkRequest = new NetworkRequest(networkCapabilities, legacyType, nextNetworkRequestId(), type); NetworkRequestInfo nri = new NetworkRequestInfo(messenger, networkRequest, binder); if (DBG) log("requestNetwork for " + nri); mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_REQUEST, nri)); if (timeoutMs > 0) { mHandler.sendMessageDelayed(mHandler.obtainMessage(EVENT_TIMEOUT_NETWORK_REQUEST, nri), timeoutMs); } return networkRequest;
public static void main(String[] args) { // Set up minint32, maxint32 and some others. int[] xi = new int[8]; xi[0] = 0x80000000; xi[1] = 0x7fffffff; xi[2] = 0x80000001; xi[3] = -13; xi[4] = -1; xi[5] = 0; xi[6] = 1; xi[7] = 999; doitInt(xi); expectEquals32(0x80000000, xi[0]); expectEquals32(0x7fffffff, xi[1]); expectEquals32(999, xi[2]); expectEquals32(13, xi[3]); expectEquals32(1, xi[4]); expectEquals32(0, xi[5]); expectEquals32(1, xi[6]); expectEquals32(999, xi[7]); // Set up minint64, maxint64 and some others. long[] xl = new long[8]; xl[0] = 0x8000000000000000L; xl[1] = 0x7fffffffffffffffL; xl[2] = -999; xl[3] = -13; xl[4] = -1; xl[5] = 0;
try { provider.isSameFile(null, filesSetup.getDataFilePath()); fail(); } catch (NullPointerException expected) {} try { provider.isSameFile(filesSetup.getDataFilePath(), null); fail(); } catch (NullPointerException expected) {} } @Test public void test_getFileStore() throws IOException { try { provider.getFileStore(filesSetup.getDataFilePath()); fail(); } catch (SecurityException expected) { } } try { provider.getFileStore(null); fail(); } catch(SecurityException expected) { } } @Test public void test_isHidden() throws IOException { assertFalse(provider.isHidden(filesSetup.getDataFilePath())); // Files can't be hidden using the "dos" view, which is unsupported since it relies // on a custom xattr, which may or may not be available on all FSs. // // Note that this weirdly asymmetric : setting the hidden attribute uses xattrs to
} else { return false; } } @Rpc(description = "request a network") public String connectivityRequestNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "Request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); networkRequest.networkCapabilities.setNetworkSpecifier(WifiAwareManagerFacade.getNetworkSpecifier(j)); } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId;
mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities .getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); networkRequest.networkCapabilities.setNetworkSpecifier(WifiAwareManagerFacade.getNetworkSpecifier(j)); } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "Stop listening for connectivity changes") public void connectivityStopTrackingConnectivityStateChange() { if (mTrackingConnectivityStateChange) { mTrackingConnectivityStateChange = false; mContext.unregisterReceiver(mConnectivityReceiver); } }
String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); networkRequest.networkCapabilities.setNetworkSpecifier( WifiAwareManagerFacade.getNetworkSpecifier(j)); } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "Stop listening for connectivity changes") public void connectivityStopTrackingConnectivityStateChange() { if (mTrackingConnectivityStateChange) { mTrackingConnectivityStateChange = false; mContext.unregisterReceiver(mConnectivityReceiver); } }
return key; } @Rpc(description = "request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); networkRequest.networkCapabilities.setNetworkSpecifier( WifiAwareManagerFacade.getNetworkSpecifier(j)); } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "Stop listening for connectivity changes") public void connectivityStopTrackingConnectivityStateChange() { if (mTrackingConnectivityStateChange) { mTrackingConnectivityStateChange = false; mContext.unregisterReceiver(mConnectivityReceiver); } } @Rpc(description = "Get the extra information about the network state provided by lower network layers.")
public Uri insert(Uri uri, ContentValues values) { if (uri.isPathPrefixMatch(CONTENT_URI)) { // Parse the subId int subId = 0; try { subId = Integer.parseInt(uri.getLastPathSegment()); } catch (NumberFormatException e) { Log.d(TAG, "insert: no subId provided in uri"); throw e; } Log.d(TAG, "subId=" + subId); // create the new service state ServiceState newSS = new ServiceState(); newSS.setVoiceRegState(values.getAsInteger(VOICE_REG_STATE)); newSS.setDataRegState(values.getAsInteger(DATA_REG_STATE)); newSS.setVoiceOperatorName(values.getAsString(VOICE_OPERATOR_ALPHA_LONG), values.getAsString(VOICE_OPERATOR_ALPHA_SHORT), values.getAsString(VOICE_OPERATOR_NUMERIC)); newSS.setDataOperatorName(values.getAsString(DATA_OPERATOR_ALPHA_LONG), values.getAsString(DATA_OPERATOR_ALPHA_SHORT), values.getAsString(DATA_OPERATOR_NUMERIC)); newSS.setIsManualSelection(values.getAsBoolean(IS_MANUAL_NETWORK_SELECTION));
private static byte getRandomNonZeroByte() { final byte random = (byte) (new Random()).nextInt(); // Don't pick the subnet-router anycast address, since that might be // in use on the upstream already. return (random != 0) ? random : 0x1;
public boolean processMessage(Message message) { maybeLogMessage(this, message.what); boolean retValue = true; switch (message.what) { case CMD_TETHER_REQUESTED: final Mode mode = (Mode) message.obj; Log.e(TAG, "CMD_TETHER_REQUESTED with mode " + mode + " when already operating in mode " + mMode); break; case CMD_TETHER_UNREQUESTED: transitionTo(mInitialState); if (DBG) Log.d(TAG, "Untethered (unrequested)" + mIfaceName); break; case CMD_INTERFACE_DOWN: transitionTo(mUnavailableState); if (DBG) Log.d(TAG, "Untethered (ifdown)" + mIfaceName); break; case CMD_TETHER_CONNECTION_CHANGED: if (mMode != Mode.TETHERING) { // Upstream changes are not of interest in our current mode. break; } String newUpstreamIfaceName = (String)(message.obj);
a.resize(15); a.set(14, 30); verify(new int[]{1, 2, 0, 0, 0, 20, 10, 0, 0, 0, 0, 0, 0, 0, 30}, a); int[] backingArray = new int[]{1, 2, 3, 4}; a = IntArray.wrap(backingArray); a.set(0, 10); assertEquals(10, backingArray[0]); backingArray[1] = 20; backingArray[2] = 30; verify(backingArray, a); assertEquals(2, a.indexOf(30)); a.resize(2); assertEquals(0, backingArray[2]); assertEquals(0, backingArray[3]); a.add(50); verify(new int[]{10, 20, 30, 4, 50}, a);
a.resize(15); a.set(14, 30); verify(new long[]{1, 2, 0, 0, 0, 20, 10, 0, 0, 0, 0, 0, 0, 0, 30}, a); long[] backingArray = new long[]{1, 2, 3, 4}; a = LongArray.wrap(backingArray); a.set(0, 10); assertEquals(10, backingArray[0]); backingArray[1] = 20; backingArray[2] = 30; verify(backingArray, a); assertEquals(2, a.indexOf(30)); a.resize(2); assertEquals(0, backingArray[2]); assertEquals(0, backingArray[3]); a.add(50); verify(new long[]{10, 20, 30, 4, 50}, a);
* @throws ResourceUnavailableException indicating that too many SPIs are currently allocated * for this user * @throws SpiUnavailableException indicating that a particular SPI cannot be reserved */ public SecurityParameterIndex reserveSecurityParameterIndex( int direction, InetAddress remoteAddress) throws ResourceUnavailableException { try { return new SecurityParameterIndex( mService, direction, remoteAddress, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); } catch (SpiUnavailableException unlikely) { throw new ResourceUnavailableException("No SPIs available"); } } /** * Reserve an SPI for traffic bound towards the specified remote address. * * <p>If successful, this SPI is guaranteed available until released by a call to {@link * SecurityParameterIndex#close()}. * * @param direction {@link IpSecTransform#DIRECTION_IN} or {@link IpSecTransform#DIRECTION_OUT} * @param remoteAddress address of the remote. SPIs must be unique for each remoteAddress.
* @throws ResourceUnavailableException indicating that too many SPIs are currently allocated * for this user * @throws SpiUnavailableException indicating that a particular SPI cannot be reserved */ public SecurityParameterIndex reserveSecurityParameterIndex( int direction, InetAddress remoteAddress) throws ResourceUnavailableException { try { return new SecurityParameterIndex( mService, direction, remoteAddress, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); } catch (SpiUnavailableException unlikely) { throw new ResourceUnavailableException("No SPIs available"); } } /** * Reserve an SPI for traffic bound towards the specified remote address. * * <p>If successful, this SPI is guaranteed available until released by a call to {@link * SecurityParameterIndex#close()}. * * @param direction {@link IpSecTransform#DIRECTION_IN} or {@link IpSecTransform#DIRECTION_OUT} * @param remoteAddress address of the remote. SPIs must be unique for each remoteAddress.
} } if (hostName != null) { hostAddr = InetAddress.getByName(hostName); serverSocket = new ServerSocket(port, 0, hostAddr); } else { serverSocket = new ServerSocket(port); } // use as workaround for unspecified behaviour of isAnyLocalAddress() InetAddress iAddress = null; if (hostName != null) { iAddress = serverSocket.getInetAddress(); } else { iAddress = InetAddress.getLocalHost(); } address = iAddress.getHostName() + ":" + serverSocket.getLocalPort(); return address; } /** * Stops listening for connection on current address. */ @Override public void stopListening() throws IOException { if (serverSocket != null) { serverSocket.close(); } } /** * Accepts transport connection for currently listened address and performs handshaking * for specified timeout. * * @param acceptTimeout timeout for accepting in milliseconds * @param handshakeTimeout timeout for handshaking in milliseconds */ @Override
expectEquals( 8070450532247928832L, geoLongMulLastValue(2147483647L)); expectEquals( 0L, geoLongMulLastValue(-2147483648L)); expectEquals( 8070450532247928832L, geoLongMulLastValue(9223372036854775807L)); expectEquals( 0L, geoLongMulLastValue(-9223372036854775808L)); float[] a = new float[16]; narrowingSubscript(a); for (int i = 0; i < 16; i++) { expectEquals(2.0f, a[i]); } int[] xx = new int[2]; int[] yy = new int[469]; reduc(xx, yy); expectEquals(-469, xx[0]); expectEquals(-938, xx[1]); for (int i = 0; i < 469; i++) { expectEquals(2, yy[i]); } System.out.println("passed");
mSentSinceLastRecv = 0; putRecoveryAction(RecoveryAction.GET_DATA_CALL_LIST); } else { if (VDBG_STALL) log("updateDataStallInfo: NONE"); } } private boolean isPhoneStateIdle() { for (int i = 0; i < TelephonyManager.getDefault().getPhoneCount(); i++ ) { Phone phone = PhoneFactory.getPhone(i); if (phone != null && phone.getState() != PhoneConstants.State.IDLE) { log("isPhoneStateIdle false: Voice call active on phone " + i); return false; } } return true; } private void onDataStallAlarm(int tag) { if (mDataStallAlarmTag != tag) { if (DBG) { log("onDataStallAlarm: ignore, tag=" + tag + " expecting " + mDataStallAlarmTag); } return; } updateDataStallInfo(); int hangWatchdogTrigger = Settings.Global.getInt(mResolver, Settings.Global.PDP_WATCHDOG_TRIGGER_PACKET_COUNT, NUMBER_SENT_PACKETS_OF_HANG); boolean suspectedStall = DATA_STALL_NOT_SUSPECTED;
chosenIface = iface; break; } } } if (chosenIface == null) { Log.e(TAG, "could not find iface of type " + interfaceType); return; } final int result; switch (requestedState) { case IControlsTethering.STATE_UNAVAILABLE: case IControlsTethering.STATE_AVAILABLE: result = untether(chosenIface); break; case IControlsTethering.STATE_TETHERED: case IControlsTethering.STATE_LOCAL_HOTSPOT: result = tether(chosenIface, requestedState); break; default: Log.wtf(TAG, "Unknown interface state: " + requestedState); return; } if (result != ConnectivityManager.TETHER_ERROR_NO_ERROR) { Log.e(TAG, "unable start or stop tethering on iface " + chosenIface); return; }
// by sending CMD_CLEAR_ERROR if (error == ConnectivityManager.TETHER_ERROR_MASTER_ERROR) { mTetherMasterSM.sendMessage(TetherMasterSM.CMD_CLEAR_ERROR, who); } switch (state) { case IControlsTethering.STATE_UNAVAILABLE: case IControlsTethering.STATE_AVAILABLE: mUpstreamWantingIfaces.remove(iface); mTetherMasterSM.sendMessage(TetherMasterSM.CMD_TETHER_MODE_UNREQUESTED, who); break; case IControlsTethering.STATE_TETHERED: case IControlsTethering.STATE_LOCAL_HOTSPOT: mUpstreamWantingIfaces.remove(iface); mTetherMasterSM.sendMessage(TetherMasterSM.CMD_TETHER_MODE_REQUESTED, who); break; } sendTetherStateChangedBroadcast();
case CMD_START_TETHERING_ERROR: case CMD_STOP_TETHERING_ERROR: case CMD_SET_DNS_FORWARDERS_ERROR: mLastError = ConnectivityManager.TETHER_ERROR_MASTER_ERROR; transitionTo(mInitialState); break; default: return false; } return true; } } class LocalHotspotState extends State { @Override public void enter() { if (DBG) Log.d(TAG, "Local hotspot " + mIfaceName); setInterfaceState(IControlsTethering.STATE_LOCAL_HOTSPOT); } @Override public boolean processMessage(Message message) { maybeLogMessage(this, message.what); switch (message.what) { case CMD_TETHER_REQUESTED: Log.e(TAG, "CMD_TETHER_REQUESTED while in local hotspot mode."); break; case CMD_TETHER_CONNECTION_CHANGED: // Ignored in local hotspot state. break; default: return false; } return true; } } class TetheredState extends State { @Override public void enter() { if (DBG) Log.d(TAG, "Tethered " + mIfaceName);
private final Object mPublicSync; private final Context mContext; private final ArrayMap<String, TetherState> mTetherStates; private final BroadcastReceiver mStateReceiver; private final INetworkManagementService mNMService; private final INetworkStatsService mStatsService; private final INetworkPolicyManager mPolicyManager; private final Looper mLooper; private final MockableSystemProperties mSystemProperties; private final StateMachine mTetherMasterSM; private final OffloadController mOffloadController; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor; private final HashSet<TetherInterfaceStateMachine> mForwardedDownstreams; private volatile TetheringConfiguration mConfig; private String mCurrentUpstreamIface; private Notification.Builder mTetheredNotificationBuilder; private int mLastNotificationId; private boolean mRndisEnabled; // track the RNDIS function enabled state private boolean mUsbTetherRequested; // true if USB tethering should be started // when RNDIS is enabled // True iff WiFi tethering should be started when soft AP is ready. private boolean mWifiTetherRequested; public Tethering(Context context, INetworkManagementService nmService, INetworkStatsService statsService, INetworkPolicyManager policyManager, Looper looper, MockableSystemProperties systemProperties) {
if (error == ConnectivityManager.TETHER_ERROR_MASTER_ERROR) { mTetherMasterSM.sendMessage(TetherMasterSM.CMD_CLEAR_ERROR, who); } int which; switch (state) { case IControlsTethering.STATE_UNAVAILABLE: case IControlsTethering.STATE_AVAILABLE: which = TetherMasterSM.EVENT_IFACE_SERVING_STATE_INACTIVE; break; case IControlsTethering.STATE_TETHERED: case IControlsTethering.STATE_LOCAL_HOTSPOT: which = TetherMasterSM.EVENT_IFACE_SERVING_STATE_ACTIVE; break; default: Log.wtf(TAG, "Unknown interface state: " + state); return; } mTetherMasterSM.sendMessage(which, state, 0, who); sendTetherStateChangedBroadcast();
capabilities |= PhoneAccount.CAPABILITY_VIDEO_CALLING_RELIES_ON_PRESENCE; } if (mIsVideoCapable && isCarrierEmergencyVideoCallsAllowed()) { capabilities |= PhoneAccount.CAPABILITY_EMERGENCY_VIDEO_CALLING; } mIsVideoPauseSupported = isCarrierVideoPauseSupported(); Bundle phoneAccountExtras = new Bundle(); if (isCarrierInstantLetteringSupported()) { capabilities |= PhoneAccount.CAPABILITY_CALL_SUBJECT; phoneAccountExtras = getPhoneAccountExtras(phoneAccountExtras); } phoneAccountExtras.putInt(PhoneAccount.EXTRA_SORT_ORDER, slotId); mIsMergeCallSupported = isCarrierMergeCallSupported(); mIsMergeImsCallSupported = isCarrierMergeImsCallSupported(); mIsVideoConferencingSupported = isCarrierVideoConferencingSupported(); mIsMergeOfWifiCallsAllowedWhenVoWifiOff = isCarrierMergeOfWifiCallsAllowedWhenVoWifiOff(); if (isEmergency && mContext.getResources().getBoolean( R.bool.config_emergency_account_emergency_calls_only)) { capabilities |= PhoneAccount.CAPABILITY_EMERGENCY_CALLS_ONLY; } if (icon == null) { // TODO: Switch to using Icon.createWithResource() once that supports tinting. Resources res = mContext.getResources(); Drawable drawable = res.getDrawable(DEFAULT_SIM_ICON, null);
for (Map.Entry<Class<? extends UnitTest>, Integer> entry : allUnitTests.entrySet()) { int testApiVersion = entry.getValue(); // Only add test if test API version is not greater than build API version. if (testApiVersion <= thisApiVersion) { validUnitTests.add(entry.getKey()); } } return validUnitTests; } @Parameter(0) public UnitTest mTest; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); UnitTest test = mTestClass.getDeclaredConstructor(Context.class).newInstance(ctx); test.runTest(); Assert.assertTrue(test.getSuccess()); } }
private static void allocateReachableObjects(ArrayList<MockClass> reachableObjs) { for (int i = 0; i < reachableObjNum; i++) { reachableObjs.add(new MockClass(true)); }
private static void allocateUnreachableObjects() { for (int i = 0; i < unreachableObjNum; i++) { new MockClass(false); }
private static void allocateUnreachableObjects() { for (int i = 0; i < unreachableObjNum; i++) { new MockClass(false); }
} if (!mBinaryTestProfilingLibraryPath.isEmpty()) { jsonObject.put(BINARY_TEST_PROFILING_LIBRARY_PATH, new JSONArray(mBinaryTestProfilingLibraryPath)); CLog.i("Added %s to the Json object", BINARY_TEST_PROFILING_LIBRARY_PATH); } if (mBinaryTestDisableFramework) { jsonObject.put(BINARY_TEST_DISABLE_FRAMEWORK, mBinaryTestDisableFramework); CLog.i("Added %s to the Json object", BINARY_TEST_DISABLE_FRAMEWORK); } if (mBinaryTestStopNativeServers) { jsonObject.put(BINARY_TEST_STOP_NATIVE_SERVERS, mBinaryTestStopNativeServers); CLog.i("Added %s to the Json object", BINARY_TEST_STOP_NATIVE_SERVERS); } if (!mHalHidlReplayTestTracePaths.isEmpty()) { jsonObject.put(HAL_HIDL_REPLAY_TEST_TRACE_PATHS, new JSONArray(mHalHidlReplayTestTracePaths));
import android.util.Log; import java.util.Arrays; import java.util.Objects; /** * Network specifier object used to request a Wi-Fi Aware network. Apps do not create these objects * directly but obtain them using * {@link WifiAwareSession#createNetworkSpecifierOpen(int, byte[])} or * {@link DiscoverySession#createNetworkSpecifierOpen(PeerHandle)} or their secure (Passphrase) * versions. * * @hide */ public final class WifiAwareNetworkSpecifier extends NetworkSpecifier implements Parcelable { /** * TYPE: in band, specific peer: role, client_id, session_id, peer_id, pmk/passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB = 0; /** * TYPE: in band, any peer: role, client_id, session_id, pmk/passphrase optional * [only permitted for RESPONDER] * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB_ANY_PEER = 1; /** * TYPE: out-of-band: role, client_id, peer_mac, pmk/passphrase optional
mMediaInterface.folderItemsRsp(bdaddr, AvrcpConstants.RSP_INV_RANGE, null); return; } result_items = checkIndexOutofBounds(bdaddr, items, startItem, endItem); /* check for index out of bound errors */ if (result_items == null) { Log.w(TAG, "result_items is null."); mMediaInterface.folderItemsRsp(bdaddr, AvrcpConstants.RSP_INV_RANGE, null); return; } FolderItemsData folderDataNative = new FolderItemsData(result_items.size()); /* variables to accumulate attrs */ ArrayList<String> attrArray = new ArrayList<String>(); ArrayList<Integer> attrId = new ArrayList<Integer>(); for (int itemIndex = 0; itemIndex < result_items.size(); itemIndex++) { // get the queue id long qid = result_items.get(itemIndex).getQueueId(); byte[] uid = ByteBuffer.allocate(AvrcpConstants.UID_SIZE).putLong(qid).array(); // get the array of uid from 2d to array 1D array for (int idx = 0; idx < AvrcpConstants.UID_SIZE; idx++) {
String value = null; int attribId = isAllAttribRequested ? (idx + 1) : folderItemsReqObj.mAttrIDs[idx]; if (attribId >= AvrcpConstants.ATTRID_TITLE && attribId <= AvrcpConstants.ATTRID_PLAY_TIME) { value = getAttrValue(attribId, result_items, itemIndex); if (value != null) { attrArray.add(value); attrId.add(attribId); attrCnt++; } } else { Log.w(TAG, "invalid attribute id is requested: " + attribId); } } /* add num attr actually received from media player for a particular item */ folderDataNative.mAttributesNum[itemIndex] = attrCnt; } } /* copy filtered attr ids and attr values to response parameters */ if (folderItemsReqObj.mNumAttr != AvrcpConstants.NUM_ATTR_NONE) { folderDataNative.mAttrIds = new int[attrId.size()]; for (int attrIndex = 0; attrIndex < attrId.size(); attrIndex++) folderDataNative.mAttrIds[attrIndex] = attrId.get(attrIndex);
if (oldLp != null && newLp.isIdenticalDnses(oldLp)) { return; // no updating necessary } Collection<InetAddress> dnses = newLp.getDnsServers(); if (DBG) log("Setting DNS servers for network " + netId + " to " + dnses); try { mNetd.setDnsConfigurationForNetwork( netId, NetworkUtils.makeStrings(dnses), newLp.getDomains()); } catch (Exception e) { loge("Exception in setDnsConfigurationForNetwork: " + e); } final NetworkAgentInfo defaultNai = getDefaultNetwork(); if (defaultNai != null && defaultNai.network.netId == netId) { setDefaultDnsSystemProperties(dnses); } flushVmDnsCache();
/** * The URL used for fallback HTTP captive portal detection when previous HTTP * and HTTPS captive portal detection attemps did not return a conclusive answer. * * @hide */ public static final String CAPTIVE_PORTAL_FALLBACK_URL = "captive_portal_fallback_url"; /** * A "|" separated list of URLs used for captive portal detection in addition to the * fallback HTTP url associated with the CAPTIVE_PORTAL_FALLBACK_URL settings. * * @hide */ public static final String CAPTIVE_PORTAL_OTHER_FALLBACK_URLS = "captive_portal_other_fallback_urls"; /** * Whether to use HTTPS for network validation. This is enabled by default and the setting * needs to be set to 0 to disable it. This setting is a misnomer because captive portals * don't actually use HTTPS, but it's consistent with the other settings. * * @hide */ public static final String CAPTIVE_PORTAL_USE_HTTPS = "captive_portal_use_https"; /**
private URL[] makeCaptivePortalFallbackUrls(Context context) { String firstUrl = getSetting(context, Settings.Global.CAPTIVE_PORTAL_FALLBACK_URL, DEFAULT_FALLBACK_URL); String joinedUrls = firstUrl + "," + getSetting(context, Settings.Global.CAPTIVE_PORTAL_OTHER_FALLBACK_URLS, DEFAULT_OTHER_FALLBACK_URLS); List<URL> urls = new ArrayList<>(); for (String s : joinedUrls.split(",")) { URL u = makeURL(s); if (u == null) { continue; } urls.add(u); } if (urls.isEmpty()) { Log.e(TAG, String.format("could not create any url from %s", joinedUrls)); } return urls.toArray(new URL[urls.size()]);
* Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA. * * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA * or visit www.oracle.com if you need additional information or have any * questions. */ package java.util; import java.util.function.Consumer; import java.util.function.Function; import java.util.function.Predicate; import java.util.function.Supplier; // Android-changed: removed ValueBased paragraph. /** * A container object which may or may not contain a non-null value. * If a value is present, {@code isPresent()} will return {@code true} and * {@code get()} will return the value. * * <p>Additional methods that depend on the presence or absence of a contained * value are provided, such as {@link #orElse(java.lang.Object) orElse()} * (return a default value if value not present) and * {@link #ifPresent(java.util.function.Consumer) ifPresent()} (execute a block
* supported on this device. * * @param secondaryPhy Secondary advertising physical channel, can only be * one of {@link BluetoothDevice#PHY_LE_1M}, * {@link BluetoothDevice#PHY_LE_2M} or * {@link BluetoothDevice#PHY_LE_CODED}. * @throws IllegalArgumentException If the secondaryPhy is invalid. */ public Builder setSecondaryPhy(int secondaryPhy) { if (secondaryPhy != BluetoothDevice.PHY_LE_1M && secondaryPhy != BluetoothDevice.PHY_LE_2M && secondaryPhy != BluetoothDevice.PHY_LE_CODED) { throw new IllegalArgumentException("bad secondaryPhy " + secondaryPhy); } this.secondaryPhy = secondaryPhy; return this; } /** * Set advertising interval. * * @param interval Bluetooth LE Advertising interval, in 0.625ms unit. Valid * range is from 160 (100ms) to 16777215 (10,485.759375 s). * Recommended values are: * {@link AdvertisingSetParameters#INTERVAL_LOW}, * {@link AdvertisingSetParameters#INTERVAL_MEDIUM}, or
public String getDisplayName(boolean daylightTime, int style, Locale locale) { // BEGIN Android-changed: implement using android.icu.text.TimeZoneNames TimeZoneNames.NameType nameType; switch (style) { case SHORT: nameType = daylightTime ? TimeZoneNames.NameType.SHORT_DAYLIGHT : TimeZoneNames.NameType.SHORT_STANDARD; break; case LONG: nameType = daylightTime ? TimeZoneNames.NameType.LONG_DAYLIGHT : TimeZoneNames.NameType.LONG_STANDARD; break; default: throw new IllegalArgumentException("Illegal style: " + style); } long now = System.currentTimeMillis(); String canonicalID = android.icu.util.TimeZone.getCanonicalID(getID()); if (canonicalID != null) { TimeZoneNames names = TimeZoneNames.getInstance(locale); String displayName = names.getDisplayName(canonicalID, nameType, now); if (displayName != null) { return displayName; } } // We get here if this is a custom timezone or ICU doesn't have name data for the specific // style and locale. int offsetMillis = getRawOffset();
// Android-changed: implement using android.icu.text.TimeZoneNames TimeZoneNames.NameType nameType; switch (style) { case SHORT: nameType = daylightTime ? TimeZoneNames.NameType.SHORT_DAYLIGHT : TimeZoneNames.NameType.SHORT_STANDARD; break; case LONG: nameType = daylightTime ? TimeZoneNames.NameType.LONG_DAYLIGHT : TimeZoneNames.NameType.LONG_STANDARD; break; default: throw new IllegalArgumentException("Illegal style: " + style); } String canonicalID = android.icu.util.TimeZone.getCanonicalID(getID()); if (canonicalID != null) { TimeZoneNames names = TimeZoneNames.getInstance(locale); String displayName = names.getDisplayName(canonicalID, nameType, now); if (displayName != null) { return displayName; } } // We get here if this is a custom timezone or ICU doesn't have name data for the specific // style and locale. int offsetMillis = getRawOffset(); if (daylightTime) { offsetMillis += getDSTSavings(); }
boolean isRingerAudible = isVolumeOverZero && shouldRingForContact && isRingtonePresent; // Acquire audio focus under any of the following conditions: // 1. Should ring for contact and there's an HFP device attached // 2. Volume is over zero, we should ring for the contact, and there's a audible ringtone // present. boolean shouldAcquireAudioFocus = isRingerAudible || (isHfpDeviceAttached && shouldRingForContact) || isSelfManaged; // Don't do call waiting operations or vibration unless these are false. boolean isTheaterModeOn = mSystemSettingsUtil.isTheaterModeOn(mContext); boolean letDialerHandleRinging = mInCallController.doesConnectedDialerSupportRinging(); boolean endEarly = isTheaterModeOn || letDialerHandleRinging; if (endEarly) { if (letDialerHandleRinging) { Log.addEvent(foregroundCall, LogUtils.Events.SKIP_RINGING); } return shouldAcquireAudioFocus;
Log.addEvent(foregroundCall, LogUtils.Events.START_RINGER); // Because we wait until a contact info query to complete before processing a // call (for the purposes of direct-to-voicemail), the information about custom // ringtones should be available by the time this code executes. We can safely // request the custom ringtone from the call and expect it to be current. mRingtonePlayer.play(mRingtoneFactory, foregroundCall); } else { Log.i(this, "startRinging: skipping because ringer would not be audible. " + "isVolumeOverZero=%s, shouldRingForContact=%s, isRingtonePresent=%s", isVolumeOverZero, shouldRingForContact, isRingtonePresent); } if (shouldVibrate(mContext, foregroundCall) && !mIsVibrating && shouldRingForContact) { mVibratingCall = foregroundCall; mVibrator.vibrate(VIBRATION_PATTERN, VIBRATION_PATTERN_REPEAT, VIBRATION_ATTRIBUTES); mIsVibrating = true; } else if (mIsVibrating) { Log.addEvent(foregroundCall, LogUtils.Events.SKIP_VIBRATION, "already vibrating"); } return shouldAcquireAudioFocus;
private URL nextFallbackUrl() { if (mCaptivePortalFallbackUrls.length == 0) { return null; } int idx = Math.abs(mNextFallbackUrlIndex) % mCaptivePortalFallbackUrls.length; mNextFallbackUrlIndex += new Random().nextInt(); // randomely change url without memory. return mCaptivePortalFallbackUrls[idx];
when(mFakeCallsManager.hasOngoingCalls()).thenReturn(true); assertTrue(mTSIBinder.isInCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testNotIsInCall() throws Exception { when(mFakeCallsManager.hasOngoingCalls()).thenReturn(false); assertFalse(mTSIBinder.isInCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testIsInCallFail() throws Exception { doThrow(new SecurityException()).when(mContext).enforceCallingOrSelfPermission( anyString(), any()); try { mTSIBinder.isInCall("blah"); fail(); } catch (SecurityException e) { // desired result } verify(mFakeCallsManager, never()).hasOngoingCalls(); } @SmallTest public void testIsInManagedCall() throws Exception { when(mFakeCallsManager.hasOngoingManagedCalls()).thenReturn(true); assertTrue(mTSIBinder.isInManagedCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testNotIsInManagedCall() throws Exception { when(mFakeCallsManager.hasOngoingManagedCalls()).thenReturn(false); assertFalse(mTSIBinder.isInManagedCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest
assertTrue(mTSIBinder.isInManagedCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testNotIsInManagedCall() throws Exception { when(mFakeCallsManager.hasOngoingManagedCalls()).thenReturn(false); assertFalse(mTSIBinder.isInManagedCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testIsInManagedCallFail() throws Exception { doThrow(new SecurityException()).when(mContext).enforceCallingOrSelfPermission( anyString(), any()); try { mTSIBinder.isInManagedCall("blah"); fail(); } catch (SecurityException e) { // desired result } verify(mFakeCallsManager, never()).hasOngoingCalls(); } /** * Register phone accounts for the supplied PhoneAccountHandles to make them * visible to all users (via the isVisibleToCaller method in TelecomServiceImpl. * @param handles the handles for which phone accounts should be created for. */ private void makeAccountsVisibleToAllUsers(PhoneAccountHandle... handles) { for (PhoneAccountHandle ph : handles) { when(mFakePhoneAccountRegistrar.getPhoneAccountUnchecked(eq(ph))).thenReturn(
for (int i = 0; i <= 255; ++i) { s.setTrafficClass(i); // b/30909505 // Linux does not set ECN bits for IP_TOS, but sets for IPV6_TCLASS. We should // accept either output. int actual = s.getTrafficClass(); assertTrue(i == actual || // IPV6_TCLASS (actual == (i & ~INET_ECN_MASK)); // IP_TOS: ECN bits should be 0 } } } public void testReadAfterClose() throws Exception { MockServer server = new MockServer(); server.enqueue(new byte[]{5, 3}, 0); Socket socket = new Socket("localhost", server.port); InputStream in = socket.getInputStream(); assertEquals(5, in.read()); assertEquals(3, in.read()); assertEquals(-1, in.read()); assertEquals(-1, in.read()); socket.close(); in.close(); /* * Rather astonishingly, read() doesn't throw even though the stream is
} } } } private void connectToAddress(InetAddress address, int port, int timeout) throws IOException { if (address.isAnyLocalAddress()) { doConnect(InetAddress.getLocalHost(), port, timeout); } else { doConnect(address, port, timeout); } } public void setOption(int opt, Object val) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } // Android-removed: Logic dealing with value type moved to socketSetOption. /* boolean on = true; switch (opt) { // check type safety b4 going native. These should never * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). // case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) throw new SocketException("Bad parameter for option"); if (val instanceof Boolean) { // true only if disabling - enabling should be Integer on = false; } break; case SO_TIMEOUT:
if (address.isAnyLocalAddress()) { doConnect(InetAddress.getLocalHost(), port, timeout); } else { doConnect(address, port, timeout); } } public void setOption(int opt, Object val) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } // Android-removed: alternative implementation /* boolean on = true; switch (opt) { /* check type safety b4 going native. These should never * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). // case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) throw new SocketException("Bad parameter for option"); if (val instanceof Boolean) { // true only if disabling - enabling should be Integer on = false; } break; case SO_TIMEOUT: if (val == null || (!(val instanceof Integer))) throw new SocketException("Bad parameter for SO_TIMEOUT");
} else { doConnect(address, port, timeout); } } public void setOption(int opt, Object val) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } // Android-removed: alternative implementation /* boolean on = true; switch (opt) { // check type safety b4 going native. These should never * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). * case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) throw new SocketException("Bad parameter for option"); if (val instanceof Boolean) { // true only if disabling - enabling should be Integer on = false; } break; case SO_TIMEOUT: if (val == null || (!(val instanceof Integer))) throw new SocketException("Bad parameter for SO_TIMEOUT"); int tmp = ((Integer) val).intValue(); if (tmp < 0) throw new IllegalArgumentException("timeout < 0");
} // Android-removed: alternative implementation /* boolean on = true; switch (opt) { // check type safety b4 going native. These should never * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). // case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) throw new SocketException("Bad parameter for option"); if (val instanceof Boolean) { /* true only if disabling - enabling should be Integer * on = false; } break; case SO_TIMEOUT: if (val == null || (!(val instanceof Integer))) throw new SocketException("Bad parameter for SO_TIMEOUT"); int tmp = ((Integer) val).intValue(); if (tmp < 0) throw new IllegalArgumentException("timeout < 0"); timeout = tmp; break; case IP_TOS: if (val == null || !(val instanceof Integer)) { throw new SocketException("bad argument for IP_TOS"); }
break; default: throw new SocketException("unrecognized TCP option: " + opt); } socketSetOption(opt, on, val); */ if (opt == SO_TIMEOUT) { timeout = (Integer) val; } socketSetOption(opt, val); } public Object getOption(int opt) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } if (opt == SO_TIMEOUT) { return new Integer(timeout); } // Android-removed: Logic dealing with value type moved to socketGetOption. /* int ret = 0; // * The native socketGetOption() knows about 3 options. * The 32 bit value it returns will be interpreted according * to what we're asking. A return of -1 means it understands * the option but its turned off. It will raise a SocketException * if "opt" isn't one it understands. // switch (opt) { case TCP_NODELAY: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_OOBINLINE:
throw new SocketException("unrecognized TCP option: " + opt); } socketSetOption(opt, on, val); */ if (opt == SO_TIMEOUT) { timeout = (Integer) val; } socketSetOption(opt, val); } public Object getOption(int opt) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } if (opt == SO_TIMEOUT) { return new Integer(timeout); } // Android-removed: alternative implementation /* int ret = 0; /* * The native socketGetOption() knows about 3 options. * The 32 bit value it returns will be interpreted according * to what we're asking. A return of -1 means it understands * the option but its turned off. It will raise a SocketException * if "opt" isn't one it understands. // switch (opt) { case TCP_NODELAY: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_OOBINLINE:
} if (opt == SO_TIMEOUT) { return new Integer(timeout); } // Android-removed: alternative implementation /* int ret = 0; // * The native socketGetOption() knows about 3 options. * The 32 bit value it returns will be interpreted according * to what we're asking. A return of -1 means it understands * the option but its turned off. It will raise a SocketException * if "opt" isn't one it understands. * switch (opt) { case TCP_NODELAY: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_OOBINLINE: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_LINGER: ret = socketGetOption(opt, null); return (ret == -1) ? Boolean.FALSE: (Object)(new Integer(ret)); case SO_REUSEADDR: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_BINDADDR: InetAddressContainer in = new InetAddressContainer();
} abstract void socketCreate(boolean isServer) throws IOException; abstract void socketConnect(InetAddress address, int port, int timeout) throws IOException; abstract void socketBind(InetAddress address, int port) throws IOException; abstract void socketListen(int count) throws IOException; abstract void socketAccept(SocketImpl s) throws IOException; abstract int socketAvailable() throws IOException; abstract void socketClose0(boolean useDeferredClose) throws IOException; abstract void socketShutdown(int howto) throws IOException; // Android-changed: Method signature changed, socket{Get,Set}Option work directly with Object // values. abstract void socketSetOption(int cmd, Object value) throws SocketException; abstract Object socketGetOption(int opt) throws SocketException; abstract void socketSendUrgentData(int data) throws IOException; public final static int SHUT_RD = 0; public final static int SHUT_WR = 1; }
public static void main(String[] args) { System.out.println(test());
* @see #checkAccess() * @see #getThreadGroup() * @see #MAX_PRIORITY * @see #MIN_PRIORITY * @see ThreadGroup#getMaxPriority() */ public final void setPriority(int newPriority) { ThreadGroup g; checkAccess(); if (newPriority > MAX_PRIORITY || newPriority < MIN_PRIORITY) { // Android-changed: Improve exception message when the new priority // is out of bounds. throw new IllegalArgumentException("Priority out of range: " + newPriority); } if((g = getThreadGroup()) != null) { if (newPriority > g.getMaxPriority()) { newPriority = g.getMaxPriority(); } synchronized(this) { this.priority = newPriority; if (isAlive()) { nativeSetPriority(newPriority); } } } } /** * Returns this thread's priority. * * @return this thread's priority. * @see #setPriority */ public final int getPriority() { return priority; } /**
private static void DisableReporting() { if (doDisableReporting == null) { return; } try { DoDisableReporting.invoke(null); } catch (Exception e) { throw new Error("Unable to disable reporting!"); }
private static void ensureTestWatcherInitialized() { try { // Make sure the TestWatcher class can be found from the Object <init> function. addToBootClassLoader(LISTENER_LOCATION); // Load TestWatcher from the bootclassloader and make sure it is initialized. Class<?> testwatcher_class = Class.forName("art.test.TestWatcher", true, null); doEnableReporting = testwatcher_class.getDeclaredMethod("EnableReporting"); doDisableReporting = testwatcher_class.getDeclaredMethod("DisableReporting"); } catch (Exception e) { throw new Error("Exception while making testwatcher", e); }
/// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecAdd loop:<<Loop>> outer_loop:none // /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345*array1[j]; } } /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecSub loop:<<Loop>> outer_loop:none //
/// CHECK-DAG: VecAdd loop:<<Loop>> outer_loop:none // /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } } /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecSub loop:<<Loop>> outer_loop:none // /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (after)
// /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } } /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecSub loop:<<Loop>> outer_loop:none // /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none
handleRadioProxyExceptionForRR(rr, "setSimCardPower", e); } } } @Override public void setCarrierInfoForImsiEncryption(PublicKey publicKey, String keyIdentifier, Message result) { IRadio radioProxy = getRadioProxy(result); if (radioProxy != null) { android.hardware.radio.V1_1.IRadio radioProxy11 = android.hardware.radio.V1_1.IRadio.castFrom(radioProxy); if (radioProxy11 == null) { if (result != null) { AsyncResult.forMessage(result, null, CommandException.fromRilErrno(REQUEST_NOT_SUPPORTED)); result.sendToTarget(); } } else { RILRequest rr = obtainRequest(RIL_REQUEST_SET_CARRIER_INFO_IMSI_ENCRYPTION, result, mRILDefaultWorkSource); if (RILJ_LOGD) riljLog(rr.serialString() + "> " + requestToString(rr.mRequest)); try { radioProxy11.setCarrierInfoForImsiEncryption( rr.mSerial, publicKeyToArrayList(publicKey), keyIdentifier); } catch (RemoteException | RuntimeException e) { handleRadioProxyExceptionForRR(rr, "setCarrierInfoForImsiEncryption", e); } } } } @Override
if (DBG) { log("reportNetworkConnectivity(" + nai.network.netId + ", " + hasConnectivity + ") by " + uid); } synchronized (nai) { // Validating a network that has not yet connected could result in a call to // rematchNetworkAndRequests() which is not meant to work on such networks. if (!nai.everConnected) return; if (isNetworkWithLinkPropertiesBlocked(nai.linkProperties, uid, false)) return; nai.networkMonitor.sendMessage(NetworkMonitor.CMD_FORCE_REEVALUATION, uid); } LinkProperties lp = getLinkProperties(nai); if (isNetworkWithLinkPropertiesBlocked(lp, uid, false)) { return; } nai.networkMonitor.sendMessage(NetworkMonitor.CMD_FORCE_REEVALUATION, uid);
if (items == null) { Log.i(TAG, "null queue from " + mediaController.getPackageName() + ", constructing current-item list"); MediaMetadata metadata = mediaController.getMetadata(); // Because we are database-unaware, we can just number the item here whatever we want // because they have to re-poll it every time. MediaSession.QueueItem current = getCurrentQueueItem(mediaController, 1); items = new ArrayList<MediaSession.QueueItem>(); items.add(current); } mNowPlayingList = items; return items; } /* Constructs a queue item representing the current playing metadata from an * active controller with queue id |qid|. */ private MediaSession.QueueItem getCurrentQueueItem(MediaController controller, long qid) { MediaMetadata metadata = controller.getMetadata(); if (metadata == null) { Log.w(TAG, "Controller has no metadata!? Making an empty one"); metadata = (new MediaMetadata.Builder()).build(); } MediaDescription.Builder bob = new MediaDescription.Builder();
if (mediaController == null) { Log.e(TAG, "mediaController = null, sending no available players response"); mMediaInterface.getItemAttrRsp(bdaddr, AvrcpConstants.RSP_NO_AVBL_PLAY, null); return; } // We don't have the cached list, fetch it from Media Controller items = mediaController.getQueue(); if (items == null) { // We may be presenting a queue with only 1 item (the current one) int count = mediaController.getMetadata() != null ? 1 : 0; mMediaInterface.getTotalNumOfItemsRsp(bdaddr, AvrcpConstants.RSP_NO_ERROR, 0, count); } // Cache the response for later mNowPlayingList = items; mMediaInterface.getTotalNumOfItemsRsp(bdaddr, AvrcpConstants.RSP_NO_ERROR, 0, items.size());
if ((length == 10 || length == 26 || length == 58) && password.matches("[0-9A-Fa-f]*")) { wifiConfiguration.wepKeys[0] = password; } else if (length == 5 || length == 13 || length == 16) { wifiConfiguration.wepKeys[0] = '"' + password + '"'; } } else { if (wifiSecurity == WifiSecurity.PSK && password.length() < FormPageDisplayer.PSK_MIN_LENGTH) { return; } if (password.matches("[0-9A-Fa-f]{64}")) { wifiConfiguration.preSharedKey = password; } else { wifiConfiguration.preSharedKey = '"' + password + '"'; } }
private void getNumSlots(APDU apdu) { p1p2Unused(apdu); //dataUnused(apdu); // TODO(ascull): how to handle the cases of APDU properly? prepareToSend(apdu, (short) 4); final byte buffer[] = apdu.getBuffer(); Util.setShort(buffer, (short) 0, (short) 0); Util.setShort(buffer, (short) 2, mSlots.getNumSlots()); apdu.sendBytes((short) 0, (byte) 4);
@Override public void onPullExternalCall() { if ((getConnectionProperties() & Connection.PROPERTY_IS_EXTERNAL_CALL) != Connection.PROPERTY_IS_EXTERNAL_CALL) { Log.w(this, "onPullExternalCall - cannot pull non-external call"); return; } if (mOriginalConnection != null) { mOriginalConnection.pullExternalCall(); } } @Override public void onStartRtt(RttTextStream textStream) { if (isImsConnection()) { ImsPhoneConnection originalConnection = (ImsPhoneConnection) mOriginalConnection; originalConnection.sendRttModifyRequest(textStream); } else { Log.w(this, "onStartRtt - not in IMS, so RTT cannot be enabled."); } } @Override public void onStopRtt() { // This is not supported by carriers/vendor yet. No-op for now. } @Override public void handleRttUpgradeResponse(RttTextStream textStream) { if (!isImsConnection()) { Log.w(this, "handleRttUpgradeResponse - not in IMS, so RTT cannot be enabled."); return; } ImsPhone imsPhone = (ImsPhone) getPhone();
private Attribute sourceDebugExtension(DirectClassFile cf, int offset, int length, ParseObserver observer) { ByteArray bytes = cf.getBytes().slice(offset, offset + length); CstString smapString = new CstString(bytes); Attribute result = new AttSourceDebugExtension(smapString); if (observer != null) { String decoded = smapString.getString(); observer.parsed(bytes, offset, length, "sourceDebugExtension: " + decoded); } return result;
import com.android.dx.rop.cst.CstMethodRef; import com.android.dx.rop.cst.CstNat; import com.android.dx.rop.cst.CstType; import com.android.dx.rop.type.StdTypeList; import com.android.dx.rop.type.Type; import com.android.dx.rop.type.TypeList; import com.android.dx.util.Warning; import java.util.ArrayList; /** * Utility methods that translate various classfile attributes * into forms suitable for use in creating {@code dex} files. */ /*package*/ class AttributeTranslator { /** * This class is uninstantiable. */ private AttributeTranslator() { // This space intentionally left blank. } /** * Gets the list of thrown exceptions for a given method. * * @param method {@code non-null;} the method in question * @return {@code non-null;} the list of thrown exceptions */ public static TypeList getExceptions(Method method) { AttributeList attribs = method.getAttributes(); AttExceptions exceptions = (AttExceptions) attribs.findFirst(AttExceptions.ATTRIBUTE_NAME); if (exceptions == null) {
public static long $opt$noinline$mulNeg(long left, long right) { if (doThrow) throw new Error(); return - (left * right); } /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecAdd loop:<<Loop>> outer_loop:none /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } }
private static void throttle(byte[] bArray, short bOff, short failureCount) { short highWord = 0; short lowWord = 0; final short thirtySecondsInMilliseconds = 0x7530; // = 1000 * 30 if (failureCount == 0) { // 0s } else if (failureCount > 0 && failureCount <= 10) { if (failureCount % 5 == 0) { // 30s lowWord = thritySecondsInMilliseconds; } else { // 0s } } else if (failureCount < 30) { // 30s lowWord = thritySecondsInMilliseconds; } else if (failureCount < 140) { // 30 * (2^((x - 30)/10)) final short shift = (short) ((short) (failureCount - 30) / 10); highWord = (short) (thritySecondsInMilliseconds >> (16 - shift)); lowWord = (short) (thritySecondsInMilliseconds << shift); } else { // 1 day in ms = 1000 * 60 * 60 * 24 = 0x526 5C00 highWord = 0x0526;
IpSecTransform.DIRECTION_IN, new IpSecAlgorithm(IpSecAlgorithm.CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication( IpSecTransform.DIRECTION_IN, new IpSecAlgorithm( IpSecAlgorithm.AUTH_HMAC_SHA256, AUTH_KEY, CRYPT_KEY.length * 8)) .buildTransportModeTransform(local); // Hack to ensure the socket doesn't block indefinitely on failure DatagramSocket localSocket = new DatagramSocket(8888); localSocket.setSoTimeout(500); mISM.applyTransportModeTransform(udpSocket, transform); byte[] data = new String("Best test data ever!").getBytes("UTF-8"); byte[] in = new byte[data.length]; Os.sendto(udpSocket, data, 0, data.length, 0, local, 8888); Os.read(udpSocket, in, 0, in.length); assertTrue("Encapsulated data did not match.", Arrays.equals(data, in)); mISM.removeTransportModeTransform(udpSocket, transform); Os.close(udpSocket); transform.close(); } }
if (mEnableTerminal != null) { updateSwitchPreference(mEnableTerminal, context.getPackageManager().getApplicationEnabledSetting(TERMINAL_APP_PACKAGE) == PackageManager.COMPONENT_ENABLED_STATE_ENABLED); } updateSwitchPreference(mBugreportInPower, Settings.Secure.getInt(cr, Settings.Global.BUGREPORT_IN_POWER_MENU, 0) != 0); updateSwitchPreference(mKeepScreenOn, Settings.Global.getInt(cr, Settings.Global.STAY_ON_WHILE_PLUGGED_IN, 0) != 0); updateSwitchPreference(mBtHciSnoopLog, SystemProperties.getBoolean( BLUETOOTH_BTSNOOP_ENABLE_PROPERTY, false)); updateSwitchPreference(mDebugViewAttributes, Settings.Global.getInt(cr, Settings.Global.DEBUG_VIEW_ATTRIBUTES, 0) != 0); updateSwitchPreference(mForceAllowOnExternal, Settings.Global.getInt(cr, Settings.Global.FORCE_ALLOW_ON_EXTERNAL, 0) != 0); updateHdcpValues(); updatePasswordSummary(); updateDebuggerOptions(); updateMockLocation(); updateStrictModeVisualOptions(); updatePointerLocationOptions(); updateShowTouchesOptions(); updateFlingerOptions(); updateHardwareUiOptions(); updateMsaaOptions(); updateTrackFrameTimeOptions(); updateShowNonRectClipOptions(); updateShowHwScreenUpdatesOptions(); updateShowHwLayersUpdatesOptions(); updateDebugHwOverdrawOptions();
// Check that this is a valid device address (i.e. not broadcast). if ((val[0] & 0x01) != 0) { // Invalid since this is a broadcast address. errorLog("Invalid device address=" + Utils.getAddressStringFromByte(val) + ". Ignore this address."); break; } mAddress = val; String address = Utils.getAddressStringFromByte(mAddress); debugLog("Address is:" + address); intent = new Intent(BluetoothAdapter.ACTION_BD_ADDR_CHANGED); intent.putExtra(BluetoothAdapter.EXTRA_BD_ADDR, address); intent.addFlags(Intent.FLAG_RECEIVER_REGISTERED_ONLY_BEFORE_BOOT); mService.sendBroadcastAsUser( intent, UserHandle.ALL, mService.BLUETOOTH_PERM); break; case AbstractionLayer.BT_PROPERTY_CLASS_OF_DEVICE: mBluetoothClass = Utils.byteArrayToInt(val, 0); debugLog("BT Class:" + mBluetoothClass); break; case AbstractionLayer.BT_PROPERTY_ADAPTER_SCAN_MODE: int mode = Utils.byteArrayToInt(val, 0);
* This extra represents the previous connection state. */ public static final String EXTRA_PREVIOUS_CONNECTION_STATE = "android.bluetooth.adapter.extra.PREVIOUS_CONNECTION_STATE"; /** * Broadcast Action: The Bluetooth adapter state has changed in LE only mode. * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Broadcast Action: The notifys Bluetooth BD (mac) address * updated event. * * @hide */ public static final String ACTION_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BD_ADDR_CHANGED"; /** * Extra used by {@link #ACTION_BT_BD_ADDR_CHANGED} * * This extra represents the BD Address. * * @hide */ public static final String EXTRA_BT_BD_ADDR = "android.bluetooth.adapter.extra.BT_BD_ADDR"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be
/** * Broadcast Action: The Bluetooth adapter state has changed in LE only mode. * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Broadcast Action: The notifys Bluetooth BD (mac) address * updated event. * * @hide */ public static final String ACTION_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BD_ADDR_CHANGED"; /** * Extra used by {@link #ACTION_BT_BD_ADDR_CHANGED} * * This extra represents the BD Address. * * @hide */ public static final String EXTRA_BT_BD_ADDR = "android.bluetooth.adapter.extra.BT_BD_ADDR"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON. This denotes GATT connection
*/ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Broadcast Action: The notifys Bluetooth BD (mac) address * updated event. * * @hide */ public static final String ACTION_BT_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"; /** * Extra used by {@link #ACTION_BT_BD_ADDR_CHANGED} * * This extra represents the BD Address. * * @hide */ public static final String EXTRA_BD_ADDR = "android.bluetooth.adapter.extra.BD_ADDR"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON. This denotes GATT connection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of {@link BluetoothDevice#ACTION_ACL_CONNECTED} which
/** * Broadcast Action: The notifys Bluetooth BD (mac) address * updated event. * * @hide */ public static final String ACTION_BT_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"; /** * Extra used by {@link #ACTION_BT_BD_ADDR_CHANGED} * * This extra represents the BD Address. * * @hide */ public static final String EXTRA_BD_ADDR = "android.bluetooth.adapter.extra.BD_ADDR"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON. This denotes GATT connection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of {@link BluetoothDevice#ACTION_ACL_CONNECTED} which * works in Bluetooth state STATE_ON * @hide */ public static final String ACTION_BLE_ACL_CONNECTED =
String newName = intent.getStringExtra(BluetoothAdapter.EXTRA_LOCAL_NAME); if (DBG) Slog.d(TAG, "Bluetooth Adapter name changed to " + newName); if (newName != null) { storeNameAndAddress(newName, null); } } else if (BluetoothAdapter.ACTION_BT_BD_ADDR_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BT_BD_ADDR); if (newAddress != null) { if (DBG) Slog.d(TAG, "Bluetooth Adapter MAC Address changed to " + newAddress); storeNameAndAddress(null, newAddress); } else { if (DBG) Slog.e(TAG, "No Bluetooth Adapter BD Address parameter found"); } }
if (newName != null) { storeNameAndAddress(newName, null); } } else if (BluetoothAdapter.ACTION_BT_BD_ADDR_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BT_BD_ADDR); if (newAddress != null) { if (DBG) Slog.d(TAG, "Bluetooth Adapter BD Address changed to " + newAddress); storeNameAndAddress(null, newAddress); } else { if (DBG) Slog.e(TAG, "No Bluetooth Adapter MAC Address parameter found"); } }
public void testAospServiceContexts() throws Exception { /* obtain service_contexts file from running device */ deviceSvcFile = File.createTempFile("service_contexts", ".tmp"); deviceSvcFile.deleteOnExit(); mDevice.pullFile("/service_contexts", deviceSvcFile); /* retrieve the AOSP service_contexts file from jar */ aospSvcFile = copyResourceToTempFile("/general_service_contexts"); /* retrieve NMR1 AOSP service_contexts file from jar */ if (!isFileStartsWith(aospSvcFile, deviceSvcFile)) { aospSvcFile = copyResourceToTempFile("/ab3857191_service_contexts"); assertFileStartsWith(aospSvcFile, deviceSvcFile); } } /** * Tests that the file_contexts.bin file on the device is valid. * * @throws Exception */ @CddTest(requirement="9.7") public void testValidFileContexts() throws Exception { /* retrieve the checkfc executable from jar */ checkFc = copyResourceToTempFile("/checkfc"); checkFc.setExecutable(true); /* obtain file_contexts.bin file from running device */
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package art; import java.util.Base64; public class Test985 { static class Transform { private void Start() { System.out.println("hello - private"); } private void Finish() { System.out.println("goodbye - private"); } public void sayHi(Runnable r) { System.out.println("Pre Start private method call"); Start();
byte result = Consts.READ_WRONG_KEY; if (Util.arrayCompare( keyBuffer, keyOffset, mKey, (short) 0, Consts.SLOT_KEY_BYTES) == 0) { return Consts.READ_SUCCESS; } JCSystem.beginTransaction(); if (result == Consts.READ_WRONG_KEY) { if (mFailureCount != 0x7fff) { mFailureCount += 1; } if (throttle(sRemainingBackoff, (short) 0, mFailureCount)) { //mBackoffTimer.startTimer( // sRemainingBackoff, (short) 0, DSTimer.DST_POWEROFFMODE_FALLBACK); } Util.arrayCopyNonAtomic( sRemainingBackoff, (short) 0, outBuffer, outOffset, (byte) 4); return Consts.SW_WRONG_KEY; } JCSystem.commitTransaction(); return result;
/// CHECK-NOT: InstanceFieldSet /// CHECK-NOT: ConstructorFence /// CHECK-NOT: InstanceFieldGet // Make sure the constructor fence gets eliminated when the allocation is eliminated. static double calcCircleArea(double radius) { return new Circle(radius).getArea(); } /// CHECK-START: double Main.calcEllipseArea(double, double) load_store_elimination (before) /// CHECK: NewInstance /// CHECK: InstanceFieldSet /// CHECK: InstanceFieldSet /// CHECK: ConstructorFence /// CHECK: InstanceFieldGet /// CHECK: InstanceFieldGet /// CHECK-START: double Main.calcEllipseArea(double, double) load_store_elimination (after) /// CHECK-NOT: NewInstance /// CHECK-NOT: InstanceFieldSet /// CHECK-NOT: ConstructorFence /// CHECK-NOT: InstanceFieldGet // Multiple constructor fences can accumulate through inheritance, make sure // they are all eliminated when the allocation is eliminated. static double calcEllipseArea(double vertex, double covertex) {
static double calcEllipseArea(double vertex, double covertex) { return new Ellipse(vertex, covertex).getArea(); } /// CHECK-START: double Main.calcCircleAreaOrCircumference(double, boolean) load_store_elimination (before) /// CHECK: NewInstance /// CHECK: InstanceFieldSet /// CHECK: ConstructorFence /// CHECK: InstanceFieldGet /// CHECK-START: double Main.calcCircleAreaOrCircumference(double, boolean) load_store_elimination (after) /// CHECK: NewInstance /// CHECK-NOT: ConstructorFence // // The object allocation will not be eliminated by LSE because of aliased stores. // However the object is still a singleton, so it never escapes the current thread. // There should not be a constructor fence here after LSE. static double calcCircleAreaOrCircumference(double radius, boolean area_or_circumference) { CalcCircleAreaOrCircumference calc = new CalcCircleAreaOrCircumference( area_or_circumference ? CalcCircleAreaOrCircumference.TYPE_AREA : CalcCircleAreaOrCircumference.TYPE_CIRCUMFERENCE); if (area_or_circumference) { // Area
/// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecAdd loop:<<Loop>> outer_loop:none // /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-NOT: VecMull /// CHECK-NOT: VecAdd public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } } /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except * in compliance with the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software distributed under the License * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express * or implied. See the License for the specific language governing permissions and limitations under * the License. */ package com.android.rs.test; import android.content.Context; import android.renderscript.Allocation; import android.renderscript.Element; import android.renderscript.RenderScript; import android.renderscript.RSIllegalArgumentException; import android.renderscript.ScriptIntrinsicBlur; import android.renderscript.Type; import android.util.Log; public class UT_blur_validation extends UnitTest { private static final int ARRAY_SIZE = 256; private static final String TAG = "ScriptIntrinsicBlur validation";
output2D.destroy(); scriptBlur.destroy(); pRS.destroy(); passTest(); return; } Log.e(TAG, "setting 1d output does not trigger exception"); pRS.finish(); input1D.destroy(); input2D.destroy(); output1D.destroy(); output2D.destroy(); scriptBlur.destroy(); pRS.destroy(); failTest(); return; } Log.e(TAG, "setting 1d input does not trigger exception"); cleanup(); failTest();
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package art; import java.lang.reflect.Method; import java.util.HashMap; public class Test986 { static { // NB This is called before any setup is done so we don't need to worry about getting bind // events. Main.bindAgentJNIForClass(Test986.class); } private static final HashMap<Method, String> SymbolMap = new HashMap<>();
ProcessBuilder pb1 = new ProcessBuilder(checkFc.getAbsolutePath(), "-c", aospFcFile.getAbsolutePath(), deviceFcFile.getAbsolutePath()); pb1.redirectOutput(ProcessBuilder.Redirect.PIPE); pb1.redirectErrorStream(true); Process p1 = pb1.start(); p1.waitFor(); BufferedReader result1 = new BufferedReader(new InputStreamReader(p1.getInputStream())); String line1 = result1.readLine(); assertTrue("The file_contexts.bin file did not include the AOSP entries:\n" + line + "\n", line.equals("equal") || line.equals("subset")); } } /** * Tests that the property_contexts file on the device contains * the standard AOSP entries. * * @throws Exception */ @CddTest(requirement="9.7") public void testAospPropertyContexts() throws Exception { /* obtain property_contexts file from running device */ devicePcFile = File.createTempFile("property_contexts", ".tmp"); devicePcFile.deleteOnExit();
BufferedWriter writer = new BufferedWriter(new FileWriter(sourceList.getAbsolutePath())); for (String f : files) { writer.write(f); writer.write('\n'); } writer.close(); commandLine.add('@' + sourceList.getAbsolutePath()); } @Override @Nonnull public AndroidToolchain setAndroidMinApiLevel(@Nonnull String minApiLevel) throws Exception { this.minApiLevel = minApiLevel; return this; } protected abstract boolean isDesugarEnabled(); }
public void run() { RenderScript pRS = RenderScript.create(mCtx); final int width = 100; final int height = 100; input1D = Allocation.createSized(RS, Element.U8(RS), width * height, Allocation.USAGE_SCRIPT); final Allocation output1D = Allocation.createTyped(pRS, input1D.getType()); Type.Builder typeBuilder = new Type.Builder(pRS, Element.U8(pRS)); typeBuilder.setX(width); typeBuilder.setY(height); Type ty = typeBuilder.create(); final Allocation input2D = Allocation.createTyped(pRS, ty); final Allocation output2D = Allocation.createTyped(pRS, ty); ScriptIntrinsicBlur scriptBlur = ScriptIntrinsicBlur.create(pRS, Element.U8(pRS)); scriptBlur.setRadius(25f); boolean failed = false; try { scriptBlur.setInput(input1D); } catch (RSIllegalArgumentException e) { scriptBlur.setInput(input2D); try { scriptBlur.forEach(output1D); } catch (RSIllegalArgumentException e1) { scriptBlur.forEach(output2D);
* the License. */ package com.android.rs.test_compat; import android.content.Context; import android.content.res.Resources; import android.support.v8.renderscript.Allocation; import android.support.v8.renderscript.Element; import android.support.v8.renderscript.RenderScript; import android.support.v8.renderscript.RSIllegalArgumentException; import android.support.v8.renderscript.ScriptIntrinsicBlur; import android.support.v8.renderscript.Type; import android.util.Log; public class UT_blur_validation extends UnitTest { private static final String TAG = "ScriptIntrinsicBlur validation"; protected UT_blur_validation(RSTestCore rstc, Resources res, Context ctx) { super(rstc, TAG, ctx); } public void run() { RenderScript pRS = RenderScript.create(mCtx); final int width = 100; final int height = 100; Allocation input1D = Allocation.createSized(pRS, Element.U8(pRS), width * height, Allocation.USAGE_SCRIPT); final Allocation output1D = Allocation.createTyped(pRS, input1D.getType());
public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action.equals(BluetoothDevice.ACTION_BOND_STATE_CHANGED)) { int bondState = intent.getIntExtra(BluetoothDevice.EXTRA_BOND_STATE, BluetoothDevice.ERROR); if ((bondState != BluetoothDevice.BOND_NONE) && (bondState != BluetoothDevice.BOND_BONDED)) { return; } } else if (action.equals(ACTION_DISMISS_PAIRING)) { Log.d(TAG, "Notification cancel " + mDevice.getAddress() + " (" + mDevice.getName() + ")"); } else { int bondState = intent.getIntExtra(BluetoothDevice.EXTRA_BOND_STATE, BluetoothDevice.ERROR); Log.d(TAG, "Dismiss pairing for " + mDevice.getAddress() + " (" + mDevice.getName() + "), BondState: " + bondState); } stopForeground(true); stopSelf();
public void sendUssd(String ussdMessage) throws ImsException { logi("sendUssd :: ussdMessage=" + ussdMessage); synchronized(mLockObj) { if (mSession == null) { loge("sendUssd :: "); throw new ImsException("No call session", ImsReasonInfo.CODE_LOCAL_CALL_TERMINATED); } mSession.sendUssd(ussdMessage); } } /** * Sends a user-requested RTT upgrade request. */ public void sendRttModifyRequest() { logi("sendRttModifyRequest"); synchronized(mLockObj) { if (mSession == null) { loge("sendRttModifyRequest::no session"); } if (mCallProfile.mMediaProfile.isRttCall()) { logi("sendRttModifyRequest::Already RTT call, ignoring."); return; } // Make a copy of the current ImsCallProfile and modify it to enable RTT Parcel p = Parcel.obtain();
public static List<String> getTimeZoneIdsWithUniqueOffsets(String country) { synchronized(sLastUniqueLockObj) { if ((country != null) && country.equals(sLastUniqueCountry)) { if (DBG) { Log.d(TAG, "getTimeZonesWithUniqueOffsets(" + country + "): return cached version"); } return sLastUniqueZoneOffsets; } } Collection<TimeZone> zones = getTimeZones(country); ArrayList<TimeZone> uniqueTimeZones = new ArrayList<>(); for (TimeZone zone : zones) { // See if we already have this offset, // Using slow but space efficient and these are small. boolean found = false; for (int i = 0; i < uniqueTimeZones.size(); i++) { if (uniqueTimeZones.get(i).getRawOffset() == zone.getRawOffset()) { found = true; break; } } if (!found) { if (DBG) { Log.d(TAG, "getTimeZonesWithUniqueOffsets: add unique offset=" +
return mgr.isVolteProvisioned(); } } return true; } /** * Indicates whether VoLTE is provisioned on this slot. */ public boolean isVolteProvisionedOnDeviceForSlot() { if (getBooleanCarrierConfigForSlot( CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) { return isVolteProvisioned(); } return true; } /** * Indicates whether VoWifi is provisioned on device. * * When CarrierConfig KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL is true, and VoLTE is not * provisioned on device, this method returns false. * * @deprecated Does not support MSIM devices. Please use * {@link #isWfcProvisionedOnDeviceForSlot()} instead. */ public static boolean isWfcProvisionedOnDevice(Context context) { if (getBooleanCarrierConfig(context, CarrierConfigManager.KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL)) { if (!isVolteProvisionedOnDevice(context)) { return false; } } if (getBooleanCarrierConfig(context, CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) {
return false; } } if (getBooleanCarrierConfig(context, CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) { ImsManager mgr = ImsManager.getInstance(context, SubscriptionManager.getDefaultVoicePhoneId()); if (mgr != null) { return mgr.isWfcProvisioned(); } } return true; } /** * Indicates whether VoWifi is provisioned on slot. * * When CarrierConfig KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL is true, and VoLTE is not * provisioned on device, this method returns false. */ public boolean isWfcProvisionedOnDeviceForSlot() { if (getBooleanCarrierConfigForSlot( CarrierConfigManager.KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL)) { if (!isVolteProvisionedOnDeviceForSlot()) { return false; } } if (getBooleanCarrierConfigForSlot( CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) { return isWfcProvisioned(); } return true; } /** * Indicates whether VT is provisioned on device * * @deprecated Does not support MSIM devices. Please use
private void sendTetherStateChangedBroadcast() { if (!getConnectivityManager().isTetheringSupported()) return; ArrayList<String> availableList = new ArrayList<String>(); ArrayList<String> activeList = new ArrayList<String>(); ArrayList<String> erroredList = new ArrayList<String>(); boolean wifiTethered = false; boolean usbTethered = false; boolean bluetoothTethered = false; final TetheringConfiguration cfg = mConfig; synchronized (mPublicSync) { for (int i = 0; i < mTetherStates.size(); i++) { TetherState tetherState = mTetherStates.valueAt(i); String iface = mTetherStates.keyAt(i); if (tetherState.lastError != ConnectivityManager.TETHER_ERROR_NO_ERROR) { erroredList.add(iface); } else if (tetherState.lastState == IControlsTethering.STATE_AVAILABLE) { availableList.add(iface); } else if (tetherState.lastState == IControlsTethering.STATE_LOCAL_HOTSPOT) { hotspotList.add(iface);
import android.telephony.CarrierConfigManager; import android.os.Message; import android.os.Messenger; import com.android.internal.util.AsyncChannel; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.MockitoAnnotations; import org.mockito.ArgumentCaptor; import java.util.List; @RunWith(AndroidJUnit4.class) @SmallTest public class NsdManagerTest { @Mock Context mContext; @Mock INsdManager mService; MockServiceHandler mServiceHandler; long mTimeoutMs = 100; // non-final so that tests can adjust the value. @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); mServiceHandler = spy(MockServiceHandler.make(mContext)); when(mService.getMessenger()).thenReturn(new Messenger(mServiceHandler)); } @Test public void testResolveService() { NsdManager manager = makeManager(); NsdServiceInfo request = new NsdServiceInfo("a name", "a type"); NsdServiceInfo reply = new NsdServiceInfo("resolved name", "resolved type"); NsdManager.ResolveListener listener = mock(NsdManager.ResolveListener.class); manager.resolveService(request, listener);
public void testResolveService() { NsdManager manager = makeManager(); NsdServiceInfo request = new NsdServiceInfo("a_name", "a_type"); NsdServiceInfo reply = new NsdServiceInfo("resolved_name", "resolved_type"); NsdManager.ResolveListener listener = mock(NsdManager.ResolveListener.class); manager.resolveService(request, listener); int key1 = verifyRequest(NsdManager.RESOLVE_SERVICE); int err = 33; sendResponse(NsdManager.RESOLVE_SERVICE_FAILED, err, key1, null); verify(listener, timeout(mTimeoutMs).times(1)).onResolveFailed(request, err); manager.resolveService(request, listener); int key2 = verifyRequest(NsdManager.RESOLVE_SERVICE); sendResponse(NsdManager.RESOLVE_SERVICE_SUCCEEDED, 0, key2, reply); verify(listener, timeout(mTimeoutMs).times(1)).onServiceResolved(reply);
public static MockServiceHandler create(Context context) { HandlerThread t = new HandlerThread("mock-service-handler"); t.start(); return new MockServiceHandler(t.getLooper(), context);
mConnected.countDown(); return; case AsyncChannel.CMD_CHANNEL_DISCONNECTED: Log.e(TAG, "Channel lost"); return; default: break; } final NsdServiceInfo ns = getNsdService(key); final Object listener = getListener(key); if (listener == null) { // Another message associated with that key notified the listener first. // This is expected for replies and timeouts to resolveService(). return; } if (DBG) { Log.d(TAG, "received " + nameOf(what) + " for key " + key + ", service " + ns); } switch (what) { case DISCOVER_SERVICES_STARTED: String s = getNsdServiceInfoType((NsdServiceInfo) message.obj); ((DiscoveryListener) listener).onDiscoveryStarted(s); break; case DISCOVER_SERVICES_FAILED: removeListener(key); ((DiscoveryListener) listener).onStartDiscoveryFailed(getNsdServiceInfoType(ns), message.arg1); break; case SERVICE_FOUND:
* * This extra represents the previous connection state. */ public static final String EXTRA_PREVIOUS_CONNECTION_STATE = "android.bluetooth.adapter.extra.PREVIOUS_CONNECTION_STATE"; /** * Broadcast Action: The Bluetooth adapter state has changed in LE only mode. * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Intent used to broadcast the change in the Bluetooth address * of the local Bluetooth adapter. * <p>Always contains the extra field {@link * #EXTRA_BLUETOOTH_ADDRESS} containing the MAC address. * * Note: only system level processes are allowed to send this * defined broadcast. * * @hide */ public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = "android.bluetooth.adapter.action.BLUETOOTH_ADDRESS_CHANGED"; /** * Used as a String extra field in {@link * #ACTION_BLUETOOTH_ADDRESS_CHANGED} intent to store the local * Bluetooth MAC address. *
"android.bluetooth.adapter.extra.PREVIOUS_CONNECTION_STATE"; /** * Broadcast Action: The Bluetooth adapter state has changed in LE only mode. * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter. * <p>Always contains the extra field {@link * #EXTRA_BLUETOOTH_ADDRESS} containing the Bluetooth address. * * Note: only system level processes are allowed to send this * defined broadcast. * * @hide */ public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = "android.bluetooth.adapter.action.BLUETOOTH_ADDRESS_CHANGED"; /** * Used as a String extra field in {@link * #ACTION_BLUETOOTH_ADDRESS_CHANGED} intent to store the local * Bluetooth MAC address. * * @hide */ public static final String EXTRA_BLUETOOTH_ADDRESS = "android.bluetooth.adapter.extra.BLUETOOTH_ADDRESS";
* <p>Always contains the extra field {@link * #EXTRA_BLUETOOTH_ADDRESS} containing the MAC address. * * Note: only system level processes are allowed to send this * defined broadcast. * * @hide */ public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = "android.bluetooth.adapter.action.BLUETOOTH_ADDRESS_CHANGED"; /** * Used as a String extra field in {@link * #ACTION_BLUETOOTH_ADDRESS_CHANGED} intent to store the local * Bluetooth address. * * @hide */ public static final String EXTRA_BLUETOOTH_ADDRESS = "android.bluetooth.adapter.extra.BLUETOOTH_ADDRESS"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON. This denotes GATT connection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of {@link BluetoothDevice#ACTION_ACL_CONNECTED} which
String newName = intent.getStringExtra(BluetoothAdapter.EXTRA_LOCAL_NAME); if (DBG) Slog.d(TAG, "Bluetooth Adapter name changed to " + newName); if (newName != null) { storeNameAndAddress(newName, null); } } else if (BluetoothAdapter.ACTION_BLUETOOTH_ADDRESS_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BLUETOOTH_ADDRESS); if (newAddress != null) { if (DBG) Slog.d(TAG, "Bluetooth Adapter address changed to " + newAddress); storeNameAndAddress(null, newAddress); } else { if (DBG) Slog.e(TAG, "No Bluetooth Adapter MAC Address parameter found"); } }
if (newName != null) { storeNameAndAddress(newName, null); } } else if (BluetoothAdapter.ACTION_BLUETOOTH_ADDRESS_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BLUETOOTH_ADDRESS); if (newAddress != null) { if (DBG) Slog.d(TAG, "Bluetooth Adapter MAC Address changed to " + newAddress); storeNameAndAddress(null, newAddress); } else { if (DBG) Slog.e(TAG, "No Bluetooth Adapter address parameter found"); } }
mErrorRecoveryRetryCounter = 0; mContentResolver = context.getContentResolver(); // Observe BLE scan only mode settings change. registerForBleScanModeChange(); mCallbacks = new RemoteCallbackList<IBluetoothManagerCallback>(); mStateChangeCallbacks = new RemoteCallbackList<IBluetoothStateChangeCallback>(); IntentFilter filter = new IntentFilter(BluetoothAdapter.ACTION_LOCAL_NAME_CHANGED); filter.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter); filter = new IntentFilter(BluetoothAdapter.ACTION_BLUETOOTH_ADDRESS_CHANGED); filter.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter); loadStoredNameAndAddress(); if (isBluetoothPersistedStateOn()) { if (DBG) Slog.d(TAG, "Startup: Bluetooth persisted state is ON."); mEnableExternal = true; } String airplaneModeRadios = Settings.Global.getString(mContentResolver, Settings.Global.AIRPLANE_MODE_RADIOS); if (airplaneModeRadios == null || airplaneModeRadios.contains(Settings.Global.RADIO_BLUETOOTH)) { mContentResolver.registerContentObserver( Settings.Global.getUriFor(Settings.Global.AIRPLANE_MODE_ON), true, mAirplaneModeObserver); }
"android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter. * <p>Always contains the extra field {@link #EXTRA_BD_ADDR} * containing the MAC address. * * Note: only system level processes are allowed to send this * defined broadcast * * @hide */ public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = "android.bluetooth.adapter.action.BLUETOOTH_ADDRESS_CHANGED"; /** * Used as a String extra field in {@link * #ACTION_BD_ADDR_CHANGED} intent to store the local Bluetooth * MAC address. * * @hide */ public static final String EXTRA_BD_ADDR = "android.bluetooth.adapter.extra.BD_ADDR"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON. This denotes GATT connection
Log.d(TAG, "Notification cancel " + mDevice.getAddress() + " (" + mDevice.getName() + ")"); mDevice.cancelPairingUserInput(); } else { int bondState = intent.getIntExtra(BluetoothDevice.EXTRA_BOND_STATE, BluetoothDevice.ERROR); Log.d(TAG, "Dismiss pairing for " + mDevice.getAddress() + " (" + mDevice.getName() + "), BondState: " + bondState); } stopForeground(true); stopSelf(); } }; @Override public void onCreate() { } @Override public int onStartCommand(Intent intent, int flags, int startId) { if (intent == null) { Log.e(TAG, "Can't start: null intent!"); stopSelf(); return START_NOT_STICKY; } Resources res = getResources(); Notification.Builder builder = new Notification.Builder(this) .setSmallIcon(android.R.drawable.stat_sys_data_bluetooth) .setTicker(res.getString(R.string.bluetooth_notif_ticker)); PendingIntent pairIntent = PendingIntent.getActivity(this, 0,
} /** * This method can assume EXTENDED_YEAR has been set. * @param millis milliseconds of the date fields (local midnight millis) * @param millisInDay milliseconds of the time fields; may be out * or range. * @return total zone offset (raw + DST) for the given moment * @deprecated This method suffers from a potential integer overflow and may be removed or * changed in a future release. See <a href="http://bugs.icu-project.org/trac/ticket/11632"> * ICU ticket #11632</a> for details. */ protected int computeZoneOffset(long millis, int millisInDay) { int[] offsets = new int[2]; long wall = millis + millisInDay; if (zone instanceof BasicTimeZone) { int duplicatedTimeOpt = (repeatedWallTime == WALLTIME_FIRST) ? BasicTimeZone.LOCAL_FORMER : BasicTimeZone.LOCAL_LATTER; int nonExistingTimeOpt = (skippedWallTime == WALLTIME_FIRST) ? BasicTimeZone.LOCAL_LATTER : BasicTimeZone.LOCAL_FORMER;
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ public class Main { public static void main(String[] args) { System.loadLibrary(args[0]); testGetFieldId(TestClass.class, "intField", "I"); testGetFieldId(TestClass.class, "intField", "int"); testGetFieldId(TestClass.class, "intField", "Lint;"); testGetFieldId(TestClass.class, "stringField", "I");
* <tr><td>Android 7.0 (Nougat)</td> * <td><a href="http://site.icu-project.org/download/56">ICU 56.1</a></td> * <td><a href="http://cldr.unicode.org/index/downloads/cldr-28">CLDR 28</a></td> * <td><a href="http://www.unicode.org/versions/Unicode8.0.0/">Unicode 8.0</a></td></tr> * <tr><td>Android O</td> * <td><a href="http://site.icu-project.org/download/58">ICU 58.2</a></td> * <td><a href="http://cldr.unicode.org/index/downloads/cldr-30">CLDR 30.0.3</a></td> * <td><a href="http://www.unicode.org/versions/Unicode9.0.0/">Unicode 9.0</a></td></tr> * </table> * * <a name="default_locale"></a><h4>Be wary of the default locale</h3> * <p>Note that there are many convenience methods that automatically use the default locale, but
// Disable native bind notify for now to avoid infinite loops. setNativeBindNotify(false); String transSym = SymbolMap.getOrDefault(method, nativeSym); System.out.println(method + " = " + nativeSym + " -> " + transSym); setNativeBindNotify(true); return transSym; } public static void doTest() throws Exception { Method say_hi_method = Transform.class.getDeclaredMethod("sayHi"); // Test we will bind fine if we make no changes. Transform.sayHi2(); // Test we can get in the middle of autobind setNativeTransform(say_hi_method, "NoReallySayGoodbye"); Transform.sayHi(); // Test we can get in between manual bind. setNativeTransform(say_hi_method, "Java_art_Test986_00024Transform_sayHi2"); rebindTransformClass(); Transform.sayHi(); // Test we can get rid of transform removeNativeTransform(say_hi_method); rebindTransformClass(); Transform.sayHi(); Main.bindAgentJNIForClass(Main.class); Main.bindAgentJNIForClass(Test986.class); } // Functions called from native code.
// Test we can get in the middle of autobind setNativeTransform(say_hi_method, "NoReallySayGoodbye"); Transform.sayHi(); // Test we can get in between manual bind. setNativeTransform(say_hi_method, "Java_art_Test986_00024Transform_sayHi2"); rebindTransformClass(); Transform.sayHi(); // Test we can get rid of transform removeNativeTransform(say_hi_method); rebindTransformClass(); Transform.sayHi(); } // Functions called from native code. public static void doSayHi() { System.out.println("Hello"); } public static void doSayHi2() { System.out.println("Hello - 2"); } public static void doSayBye() { System.out.println("Bye"); } private static native void setNativeBindNotify(boolean enable); private static native void setupNativeBindNotify(); private static void rebindTransformClass() { rebindTransformClass(Transform.class); } private static native void rebindTransformClass(Class<?> trans); }
private void ensureValidNetworkSpecifier(NetworkCapabilities nc) { if (nc == null) { return; }
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net.cts; import static com.android.server.NetworkManagementSocketTagger.resetKernelUidStats; import java.net.ServerSocket; import android.net.TrafficStats; import android.os.Process; import android.test.AndroidTestCase; import android.util.Log; import android.net.LocalSocket; import java.io.File; import java.io.BufferedReader; import java.io.FileNotFoundException; import java.io.FileReader; import java.io.FileWriter;
String line; Pattern ctrlDataPattern = Pattern.compile(PATTERN); while((line = qtaguidReader.readLine()) != null) { Matcher refCountMatcher = ctrlDataPattern.matcher(line); if(refCountMatcher.matches()) { if (refCountMatcher.group(TAG_INDEX).contains(Long.toHexString(fullTag)) && refCountMatcher.group(UID_INDEX).contains(Integer.toString(uid))) { refcnt_res = Integer.parseInt(refCountMatcher.group(REFCNT_INDEX)); Log.d(TAG, "result refcnt:" + refcnt_res); break; } } } } return refcnt_res;
if (refCountMatcher.group(TAG_INDEX).contains(Long.toHexString(fullTag)) && refCountMatcher.group(UID_INDEX).contains(Integer.toString(uid))) { refcnt_res = Integer.parseInt(refCountMatcher.group(REFCNT_INDEX)); Log.d(TAG, "result refcnt:" + refcnt_res); break; } } } qtaguidReader.close(); } catch (FileNotFoundException e) { fail("Not able to access qtaguid/ctrl: "+e); } catch (IOException e) { fail("file read error"); } qtaguidReader.close(); return refcnt_res;
public boolean imsIsEnhanced4gLteModeSettingEnabledByPlatform() { return mImsManager.isVolteEnabledByPlatformForSlot();
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.internal.util; import android.annotation.Nullable; import libcore.util.Objects; import java.nio.ByteBuffer; import java.util.Arrays; import java.util.UUID; /** * A utility class for handling unsigned integers and unsigned arithmetics, as well as syntactic * sugar methods for ByteBuffer. Useful for networking and packet manipulations. * {@hide} */ public final class BitUtils { private BitUtils() {} public static boolean maskedEquals(long a, long b, long mask) { return (a & mask) == (b & mask); } public static boolean maskedEquals(byte a, byte b, byte mask) { return (a & mask) == (b & mask); } public static boolean maskedEquals(byte[] a, byte[] b, @Nullable byte[] mask) { if (a == null || b == null) return a == b;
} try { // Verification of TestClass.test() used to crash when processing // the final abstract (erroneous) class. Class<?> tc = Class.forName("TestClass"); Method test = tc.getDeclaredMethod("test"); test.invoke(null); System.out.println("UNREACHABLE!"); } catch (InvocationTargetException ite) { if (ite.getCause() instanceof InstantiationError) { System.out.println( ite.getCause().getClass().getName() + ": " + ite.getCause().getMessage()); } else { ite.printStackTrace(System.out); } } catch (Throwable t) { t.printStackTrace(System.out); }
} return findPreviousZoneTransitionTime(tz, upperOffset, mid, lower); } /** * Compute the milliseconds in the day from the fields. This is a * value from 0 to 23:59:59.999 inclusive, unless fields are out of * range, in which case it can be an arbitrary value. This value * reflects local zone wall time. * @deprecated This method suffers from a potential integer overflow and may be removed in a * future release. Overriding this method in subclasses will not have the desired effect. * See ICU ticket #11632. */ protected int computeMillisInDay() { // Do the time portion of the conversion. int millisInDay = 0; // Find the best set of fields specifying the time of day. There // are only two possibilities here; the HOUR_OF_DAY or the // AM_PM and the HOUR. int hourOfDayStamp = stamp[HOUR_OF_DAY]; int hourStamp = Math.max(stamp[HOUR], stamp[AM_PM]);
} return findPreviousZoneTransitionTime(tz, upperOffset, mid, lower); } /** * Compute the milliseconds in the day from the fields. This is a * value from 0 to 23:59:59.999 inclusive, unless fields are out of * range, in which case it can be an arbitrary value. This value * reflects local zone wall time. * @deprecated This method suffers from a potential integer overflow and may be removed in a * future release. Overriding this method in subclasses will not have the desired effect. * See ICU ticket #11632. */ protected int computeMillisInDay() { // Do the time portion of the conversion. int millisInDay = 0; // Find the best set of fields specifying the time of day. There // are only two possibilities here; the HOUR_OF_DAY or the // AM_PM and the HOUR. int hourOfDayStamp = stamp[HOUR_OF_DAY]; int hourStamp = Math.max(stamp[HOUR], stamp[AM_PM]);
* empty String if no provider was explicitly specified. */ private String verifiedProvider; /** * If verifiedPublicKey is not null, result of the verification using * verifiedPublicKey and verifiedProvider. If true, verification was * successful, if false, it failed. */ private boolean verificationResult; /** * Default constructor. */ public X509CertImpl() { } /** * Unmarshals a certificate from its encoded form, parsing the * encoded bytes. This form of constructor is used by agents which * need to examine and use certificate contents. That is, this is * one of the more commonly used constructors. Note that the buffer * must include only a certificate, and no "garbage" may be left at * the end. If you need to ignore data at the end of a certificate, * use another constructor. * * @param certData the encoded bytes, with no trailing padding.
* * @param certData the encoded bytes, with no trailing padding. * @exception CertificateException on parsing and initialization errors. */ public X509CertImpl(byte[] certData) throws CertificateException { try { parse(new DerValue(certData)); } catch (IOException e) { signedCert = null; throw new CertificateException("Unable to initialize, " + e, e); } } // END Android-added: Needed To retain original encoded form in PKCS7. // BEGIN Android-removed: unused code /* /** * unmarshals an X.509 certificate from an input stream. If the * certificate is RFC1421 hex-encoded, then it must begin with * the line X509Factory.BEGIN_CERT and end with the line * X509Factory.END_CERT. * * @param in an input stream holding at least one certificate that may * be either DER-encoded or RFC1421 hex-encoded version of the * DER-encoded certificate. * @exception CertificateException on parsing and initialization errors. *
public void onRestoreInstanceState(Bundle savedInstanceState) { if (savedInstanceState != null) { super.onRestoreInstanceState(savedInstanceState); DialogState dialogState = mDialogState.valueOf(savedInstanceState.getString(DIALOG_STATE)); String msg = savedInstanceState.getString(DIALOG_MSG_STRING); updateDialog(dialogState, msg); if (dialogState == DialogState.WPS_START) { startWps(); } }
import java.util.Arrays; import java.nio.ByteBuffer; import javax.obex.ServerRequestHandler; import javax.obex.ResponseCodes; import javax.obex.ApplicationParameter; import javax.obex.Operation; import javax.obex.HeaderSet; public class BluetoothPbapObexServer extends ServerRequestHandler { private static final String TAG = "BluetoothPbapObexServer"; private static final boolean D = BluetoothPbapService.DEBUG; private static final boolean V = BluetoothPbapService.VERBOSE; private static final int UUID_LENGTH = 16; public static final long INVALID_VALUE_PARAMETER = -1; // The length of suffix of vcard name - ".vcf" is 5 private static final int VCARD_NAME_SUFFIX_LENGTH = 5; // 128 bit UUID for PBAP private static final byte[] PBAP_TARGET = new byte[] { 0x79, 0x61, 0x35, (byte)0xf0, (byte)0xf0, (byte)0xc5, 0x11, (byte)0xd8, 0x09, 0x66, 0x08, 0x00, 0x20, 0x0c, (byte)0x9a, 0x66 };
pushResult = ResponseCodes.OBEX_HTTP_INTERNAL_ERROR; } if (!closeStream(outputStream, op)) { pushResult = ResponseCodes.OBEX_HTTP_INTERNAL_ERROR; } return pushResult; } private final int handleAppParaForResponse( AppParamValue appParamValue, int size, HeaderSet reply, Operation op, String name) { byte[] misnum = new byte[1]; ApplicationParameter ap = new ApplicationParameter(); boolean needSendCallHistoryVersionCounters = false; if (isNameMatchTarget(name, MCH) || isNameMatchTarget(name, ICH) || isNameMatchTarget(name, OCH) || isNameMatchTarget(name, CCH)) needSendCallHistoryVersionCounters = checkPbapFeatureSupport(folderVersionCounterbitMask); boolean needSendPhonebookVersionCounters = false; if (isNameMatchTarget(name, PB)) needSendPhonebookVersionCounters = checkPbapFeatureSupport(folderVersionCounterbitMask); // In such case, PCE only want the number of index. // So response not contain any Body header. if (mNeedPhonebookSize) {
boolean status = sdpManager.removeSdpRecord(mSdpHandle); Log.d(TAG, "RemoveSDPrecord returns " + status); mSdpHandle = -1; } mSdpHandle = SdpManager.getDefaultManager().createPbapPseRecord( "OBEX Phonebook Access Server", mServerSockets.getRfcommChannel(), mServerSockets.getL2capPsm(), SDP_PBAP_SERVER_VERSION, SDP_PBAP_SUPPORTED_REPOSITORIES, SDP_PBAP_SUPPORTED_FEATURES); /* Here we might have changed crucial data, hence reset DB identifier */ updateDbIdentifier(); if (DEBUG) Log.d(TAG, "PBAP server with handle:" + mSdpHandle); }
intent.putExtra(BluetoothDevice.EXTRA_PACKAGE_NAME, getPackageName()); mIsWaitingAuthorization = true; sendOrderedBroadcast(intent, BLUETOOTH_ADMIN_PERM); if (VERBOSE) Log.v(TAG, "waiting for authorization for connection from: " + sRemoteDeviceName); // In case car kit time out and try to use HFP for // phonebook // access, while UI still there waiting for user to // confirm mSessionStatusHandler.sendMessageDelayed( mSessionStatusHandler.obtainMessage(USER_TIMEOUT), USER_CONFIRM_TIMEOUT_VALUE); /* We will continue the process when we receive * BluetoothDevice.ACTION_CONNECTION_ACCESS_REPLY from Settings app. */ } return true;
+ startPointId; } String selection; if (typeSelection == null) { selection = recordSelection; } else { selection = "(" + typeSelection + ") AND (" + recordSelection + ")"; } if (V) Log.v(TAG, "Call log query selection is: " + selection); return composeCallLogsAndSendSelectedVCards(op, selection, vcardType21, needSendBody, pbSize, null, ignorefilter, filter, vcardselector, vcardselectorop, vcardselect); } final int composeAndSendPhonebookVcards(Operation op, final int startPoint, final int endPoint, final boolean vcardType21, String ownerVCard, int needSendBody, int pbSize, boolean ignorefilter, byte[] filter, byte[] vcardselector, String vcardselectorop, boolean vcardselect) { if (startPoint < 1 || startPoint > endPoint) { Log.e(TAG, "internal error: startPoint or endPoint is not correct."); return ResponseCodes.OBEX_HTTP_INTERNAL_ERROR; }
public String onValueReceived( String rawValue, int type, String label, boolean isPrimary) { /* 'p' and 'w' are the standard characters for pause and wait * (see RFC 3601) so use those when exporting phone numbers via vCard.*/ String numberWithControlSequence = rawValue.replace(PhoneNumberUtils.PAUSE, 'p') .replace(PhoneNumberUtils.WAIT, 'w'); return numberWithControlSequence;
public String onValueReceived( String rawValue, int type, String label, boolean isPrimary) { /* 'p' and 'w' are the standard characters for pause and wait * (see RFC 3601) so use those when exporting phone numbers via vCard.*/ String numberWithControlSequence = rawValue.replace(PhoneNumberUtils.PAUSE, 'p') .replace(PhoneNumberUtils.WAIT, 'w'); return numberWithControlSequence;
private boolean checkprop(String vcard, String prop) { String lines[] = vcard.split(SEPARATOR); boolean isPresent = false; for (String line : lines) { if (!Character.isWhitespace(line.charAt(0)) && !line.startsWith("=")) { String currentProp = line.split("[;:]")[0]; if (prop.equals(currentProp)) { Log.d(TAG, "bit.prop.equals current prop :" + prop); isPresent = true; return isPresent; } } } return isPresent;
private boolean CheckVcardSelector(String vcard, String vcardselectorop) { boolean selectedIn = true; for (PropertyMask bit : PropertyMask.values()) { if (checkbit(bit.pos, selector)) { Log.d(TAG, "checking for prop :" + bit.prop); if (vcardselectorop.equals("0")) { if (checkprop(vcard, bit.prop)) { Log.e(TAG, "bit.prop.equals current prop :" + bit.prop); selectedIn = true; break; } else { selectedIn = false; } } else if (vcardselectorop.equals("1")) { if (!checkprop(vcard, bit.prop)) { Log.e(TAG, "bit.prop.notequals current prop" + bit.prop); selectedIn = false; return selectedIn; } else { selectedIn = true; } } } } return selectedIn;
private boolean CheckVcardSelector(String vcard, String vcardselectorop) { boolean selectedIn = true; for (PropertyMask bit : PropertyMask.values()) { if (checkbit(bit.pos, selector)) { Log.e(TAG, "checking for prop :" + bit.prop); if (vcardselectorop.equals("0")) { if (checkprop(vcard, bit.prop)) { Log.d(TAG, "bit.prop.equals current prop :" + bit.prop); selectedIn = true; break; } else { selectedIn = false; } } else if (vcardselectorop.equals("1")) { if (!checkprop(vcard, bit.prop)) { Log.e(TAG, "bit.prop.notequals current prop" + bit.prop); selectedIn = false; return selectedIn; } else { selectedIn = true; } } } } return selectedIn;
boolean status = sdpManager.removeSdpRecord(mSdpHandle); Log.d(TAG, "RemoveSDPrecord returns " + status); mSdpHandle = -1; } mSdpHandle = SdpManager.getDefaultManager().createPbapPseRecord( "OBEX Phonebook Access Server", mServerSockets.getRfcommChannel(), mServerSockets.getL2capPsm(), SDP_PBAP_SERVER_VERSION, SDP_PBAP_SUPPORTED_REPOSITORIES, SDP_PBAP_SUPPORTED_FEATURES); // fetch Pbap Params to check if significant change has happened to Database BluetoothPbapUtils.fetchPbapParams(mContext); if (DEBUG) Log.d(TAG, "PBAP server with handle:" + mSdpHandle); }
private boolean initialize() { Log.d(TAG, "Start initialize()"); mPMCStatusLogger = new PMCStatusLogger(TAG + ".log", TAG); // Check if any Bluetooth devices are connected ArrayList<BluetoothDevice> results = new ArrayList<BluetoothDevice>(); Set<BluetoothDevice> bondedDevices = mBluetoothAdapter.getBondedDevices(); if (bondedDevices == null) { Log.e(TAG, "Bonded devices list is null"); return false; } for (BluetoothDevice bd : bondedDevices) { if (bd.isConnected()) { results.add(bd); } } if (results.isEmpty()) { Log.e(TAG, "No device is connected"); return false; } Log.d(TAG, "Finish initialize()"); return true;
private boolean initialize() { Log.d(TAG, "Start initialize()"); mPMCStatusLogger = new PMCStatusLogger(TAG + ".log", TAG); // Check if any BT devices are connected ArrayList<BluetoothDevice> results = new ArrayList<BluetoothDevice>(); Set<BluetoothDevice> bondedDevices = mBluetoothAdapter.getBondedDevices(); if (bondedDevices == null) return false; for (BluetoothDevice bd : bondedDevices) { if (bd.isConnected()) { results.add(bd); } } if (results.isEmpty()) { Log.e(TAG, "No device is connected"); return false; } Log.d(TAG, "Finish initialize()"); return true;
boolean bt_off_mute = false; Bundle extras = intent.getExtras(); if (extras == null) { Log.e(TAG, "No parameters specified"); return; } // Always initialize() if (!initialize()) { mPMCStatusLogger.logStatus("initialize() Failed"); return; } // Check if it is baseline BT is on but not stream if (extras.containsKey("BT_ON_NotPlay")) { Log.v(TAG, "NotPlay is specified for baseline case that only Bluetooth is on"); // Do nothing further mPMCStatusLogger.logStatus("READY"); mPMCStatusLogger.logStatus("SUCCEED"); return; } if (!extras.containsKey("PlayTime")) { Log.e(TAG, "No Play Time specified"); return; } tmpStr = extras.getString("PlayTime"); Log.d(TAG, "Play Time = " + tmpStr); playTime = Integer.valueOf(tmpStr); if (!extras.containsKey("MusicURL")) { Log.e(TAG, "No Music URL specified"); return; }
Log.e(TAG, "No Play Time specified"); return; } tmpStr = extras.getString("PlayTime"); Log.d(TAG, "Play Time = " + tmpStr); playTime = Integer.valueOf(tmpStr); if (!extras.containsKey("MusicURL")) { Log.e(TAG, "No Music URL specified"); return; } musicUrl = extras.getString("MusicURL"); Log.d(TAG, "Music URL = " + musicUrl); // playTime and musicUrl are necessary if (playTime == 0 || musicUrl.isEmpty() || musicUrl == null) { Log.d(TAG, "Invalid paramters"); return; } // Check if it is the baseline for BT off but streaming with speakers muted if (extras.containsKey("BT_OFF_Mute")) { Log.v(TAG, "Mute is specified for BT off baseline case"); bt_off_mute = true; } else { if (!extras.containsKey("CodecType")) { Log.e(TAG, "No Codec Type specified"); return; }
public void testClientsCanConnect() { NsdService service = makeService(); NsdManager client1 = connectClient(service); NsdManager client2 = connectClient(service); // TODO: disconnect client1 // TODO: disconnect client2
} public MockPrintStream(OutputStream os) { super(os); } @Override public void clearError() { super.clearError(); } @Override public void setError() { super.setError(); } } /** * {@link java.io.PrintStream#PrintStream(String)} */ public void test_Constructor_Ljava_lang_String() throws IOException { PrintStream os = new PrintStream(testFilePath); os.print(UNICODE_STRING); os.close(); assertFileContents(UNICODE_STRING.getBytes(Charset.defaultCharset()), testFile); } /** * {@link java.io.PrintStream#PrintStream(String, String)} */ public void test_Constructor_Ljava_lang_String_Ljava_lang_String() throws Exception { // Test that a bogus charset is mentioned in the exception try { new PrintStream(testFilePath, "Bogus"); fail("Exception expected"); } catch (UnsupportedEncodingException e) { assertNotNull(e.getMessage()); } { PrintStream os = new PrintStream(testFilePath, "utf-8"); os.print(UNICODE_STRING); os.close();
public void test_ConstructorLjava_io_OutputStreamZLjava_lang_String() throws Exception { try { new PrintStream(new ByteArrayOutputStream(), false, "%Illegal_name!"); fail("Expected UnsupportedEncodingException"); } catch (UnsupportedEncodingException e) { // expected } { ByteArrayOutputStream bos = new ByteArrayOutputStream(); PrintStream printStream = new PrintStream(bos, true /* autoFlush */, "utf-8"); printStream.print(UNICODE_STRING); printStream.close(); assertByteArraysEqual(UNICODE_STRING.getBytes(StandardCharsets.UTF_8), bos.toByteArray()); } { ByteArrayOutputStream bos = new ByteArrayOutputStream(); PrintStream printStream = new PrintStream(bos, true, "utf-16"); printStream.print(UNICODE_STRING); printStream.close(); assertByteArraysEqual(UNICODE_STRING.getBytes(StandardCharsets.UTF_16), bos.toByteArray()); }
confirmConfiguration(); return; } // Thread-unsafe access to mApfFilter but just used for debugging. final ApfFilter apfFilter = mApfFilter; final ProvisioningConfiguration provisioningConfig = mConfiguration; IndentingPrintWriter pw = new IndentingPrintWriter(writer, " "); pw.println(mTag + " APF dump:"); pw.increaseIndent(); if (apfFilter != null) { apfFilter.dump(pw); } else { pw.print("No active ApfFilter"); pw.println((provisioningConfig != null) ? "; provisioned capabilities: " + provisioningConfig.mApfCapabilities : ""); } pw.decreaseIndent(); pw.println(); pw.println(mTag + " current ProvisioningConfiguration:"); pw.increaseIndent(); pw.println((provisioningConfig != null) ? provisioningConfig : "N/A"); pw.decreaseIndent(); pw.println(); pw.println(mTag + " StateMachine dump:"); pw.increaseIndent(); mLocalLog.readOnlyLocalLog().dump(fd, pw, args); pw.decreaseIndent(); pw.println();
return; } // Thread-unsafe access to mApfFilter but just used for debugging. final ApfFilter apfFilter = mApfFilter; final ProvisioningConfiguration provisioningConfig = mConfiguration; IndentingPrintWriter pw = new IndentingPrintWriter(writer, " "); pw.println(mTag + " APF dump:"); pw.increaseIndent(); if (apfFilter != null) { apfFilter.dump(pw); } else { pw.print("No active ApfFilter"); pw.println((provisioningConfig != null) ? "; provisioned capabilities: " + provisioningConfig.mApfCapabilities : ""); } pw.decreaseIndent(); pw.println(); pw.println(mTag + " current ProvisioningConfiguration:"); pw.increaseIndent(); pw.println((provisioningConfig != null) ? provisioningConfig : "N/A"); pw.decreaseIndent(); pw.println(); pw.println(mTag + " StateMachine dump:"); pw.increaseIndent(); mLocalLog.readOnlyLocalLog().dump(fd, pw, args); pw.decreaseIndent(); pw.println();
pw.increaseIndent(); if (apfFilter != null) { apfFilter.dump(pw); } else { if (provisioningConfig != null) { pw.println("No active ApfFilter; provisioned capabilities: " + provisioningConfig.mApfCapabilities); } else { pw.println("N/A -- no ProvisioningConfiguration available"); } } pw.decreaseIndent(); pw.println(); pw.println(mTag + " current ProvisioningConfiguration:"); pw.increaseIndent(); pw.println(Objects.toString(provisioningConfig, "N/A")); pw.decreaseIndent(); pw.println(); pw.println(mTag + " StateMachine dump:"); pw.increaseIndent(); mLocalLog.readOnlyLocalLog().dump(fd, pw, args); pw.decreaseIndent(); pw.println(); pw.println(mTag + " connectivity packet log:"); pw.println(); pw.println("Debug with python and scapy via:"); pw.println("shell$ python"); pw.println(">>> from scapy import all as scapy");
private int putListener(Object listener, NsdServiceInfo s) { checkListener(listener); final int key; synchronized (mMapLock) { int valueIndex = mListenerMap.indexOfValue(listener); checkArgument(valueIndex == -1, "listener already in use"); key = nextListenerKey(); mListenerMap.put(key, listener); mServiceMap.put(key, s); } return key;
public void onOwnAddressRead(AdvertisingSet advertisingSet, int addressType, String address) { Log.d("onOwnAddressRead" + mEventType + " " + setIndex); Bundle results = new Bundle(); results.putInt("setId", setIndex); results.putInt("addressType", addressType); results.putString("address", address); mEventFacade.postEvent(mEventType + setIndex + "onOwnAddressRead", results);
public void run() { ClassLoader classLoader = null; if (System.getProperty("java.vendor").contains("Android")) { classLoader = getClassLoaderInitializedWithDexFile(); } else { classLoader = getClassLoaderInitializedWithClassFile(); } Class<?> klass = null; try { klass = classLoader.loadClass(classWithSourceDebugExtension); } catch (ClassNotFoundException e) { logWriter.println("--> Debuggee: Could not find class " + classWithSourceDebugExtension); } synchronizer.sendMessage(JPDADebuggeeSynchronizer.SGNL_READY); logWriter.println("--> Debuggee: SourceDebugExtensionDebuggee..."); synchronizer.receiveMessage(JPDADebuggeeSynchronizer.SGNL_CONTINUE);
import android.media.MediaDescription; import android.media.MediaMetadata; import android.media.AudioManager; import android.media.session.MediaSessionManager; import android.os.Bundle; import android.os.Looper; import android.test.AndroidTestCase; import android.util.Log; import java.nio.ByteBuffer; import java.util.List; import java.util.Arrays; import java.util.ArrayList; import static org.mockito.Mockito.isA; import static org.mockito.Mockito.anyInt; import static org.mockito.Mockito.mock; import static org.mockito.Mockito.when; public class AvrcpTest extends AndroidTestCase { public void testCanStart() { if (Looper.myLooper() == null) Looper.prepare(); } public void testCanBuild() { Avrcp a = Avrcp.make(getContext()); } public void testFailedBrowseStart() { Context mockContext = mock(Context.class); AudioManager mockAudioManager = mock(AudioManager.class); PackageManager mockPackageManager = mock(PackageManager.class); when(mockAudioManager.getStreamMaxVolume(AudioManager.STREAM_MUSIC)).thenReturn(100); when(mockContext.getSystemService(Context.AUDIO_SERVICE)).thenReturn(mockAudioManager);
protected void setWifiConfigurationPassword( WifiConfiguration wifiConfiguration, WifiSecurity wifiSecurity, String password) { if (wifiSecurity == WifiSecurity.WEP) { int length = password.length(); // WEP-40, WEP-104, and 256-bit WEP (WEP-232?) if ((length == 10 || length == 26 || length == 32 || length == 58) && password.matches("[0-9A-Fa-f]*")) { wifiConfiguration.wepKeys[0] = password; } else if (length == 5 || length == 13 || length == 16) { wifiConfiguration.wepKeys[0] = '"' + password + '"'; } } else { if (wifiSecurity == WifiSecurity.PSK && password.length() < FormPageDisplayer.PSK_MIN_LENGTH) { return; } if (password.matches("[0-9A-Fa-f]{64}")) { wifiConfiguration.preSharedKey = password; } else { wifiConfiguration.preSharedKey = '"' + password + '"'; } }
protected void setWifiConfigurationPassword( WifiConfiguration wifiConfiguration, WifiSecurity wifiSecurity, String password) { if (wifiSecurity == WifiSecurity.WEP) { int length = password.length(); // WEP-40, WEP-104, and 256-bit WEP (WEP-232?) if ((length == 10 || length == 26 || length == 58) && password.matches("[0-9A-Fa-f]*")) { wifiConfiguration.wepKeys[0] = password; } else if (length == 5 || length == 13 || length == 16 || length == 29) { wifiConfiguration.wepKeys[0] = '"' + password + '"'; } } else { if (wifiSecurity == WifiSecurity.PSK && password.length() < FormPageDisplayer.PSK_MIN_LENGTH) { return; } if (password.matches("[0-9A-Fa-f]{64}")) { wifiConfiguration.preSharedKey = password; } else { wifiConfiguration.preSharedKey = '"' + password + '"'; } }
0x8888888877777777L)); assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar2(0x7FFFFFFFFFFFFFFFL, 5L, 7L)); assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar2(2L, 5L, 7L)); assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar3(2L, 5L, 7L)); assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar4(0L, 5L, 7L)); assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar4(0xFFFFFFFF00000000L, 5L, 7L)); long[] expected_1 = {5L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L}; assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar6(0L, 5L, 7L)); assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar6(2L, 5L, 7L)); assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar6(-9000L, 5L, 7L));
protected SuggestionCursor getCurrentSuggestions() { if (mSearchActivityView.getSuggestions() == null) { return null; } return suggestions.getResult();
// Make sure that core apps are optimized according to their own "reason". // If the core apps are not preopted in the B OTA, and REASON_AB_OTA is not speed // (by default is speed-profile) they will be interepreted/JITed. This in itself is // not a problem as we will end up doing profile guided compilation. However, some // core apps may be loaded by system server which doesn't JIT and we need to make // sure we are not interpreting all their code in that process. int compilationReason = p.coreApp ? PackageManagerService.REASON_CORE_APP : PackageManagerService.REASON_AB_OTA; mDexoptCommands.addAll(generatePackageDexopts(p, compilationReason)); } for (PackageParser.Package p : others) { // We assume here that there are no core apps left. if (p.coreApp) { throw new IllegalStateException("Found a core app that's not important"); } mDexoptCommands.addAll( generatePackageDexopts(p, PackageManagerService.REASON_FIRST_BOOT)); } completeSize = mDexoptCommands.size();
classLoader = getClassLoaderInitializedWithDexFile(); } else { classLoader = getClassLoaderInitializedWithClassFile(); } Class<?> klass = null; try { klass = classLoader.loadClass(classWithSourceDebugExtension); } catch (ClassNotFoundException e) { logWriter.println("--> Debuggee: Could not find class " + classWithSourceDebugExtension); } // Create an instance of classWithSourceDebugExtension so the // SourceDebugExtension metadata can be reported back to the debugger. Object o = null; if (klass != null) { try { o = klass.getConstructor().newInstance(); } catch (Exception e) { logWriter.println("--> Debuggee: Failed to instantiate " + classWithSourceDebugExtension + ": " + e); } } synchronizer.sendMessage(JPDADebuggeeSynchronizer.SGNL_READY); logWriter.println("--> Debuggee: SourceDebugExtensionDebuggee..."); synchronizer.receiveMessage(JPDADebuggeeSynchronizer.SGNL_CONTINUE);
/** * The MBMS middleware should send this when a download of single file has completed or * failed. Mandatory extras are * {@link #EXTRA_RESULT} * {@link #EXTRA_INFO} * {@link #EXTRA_REQUEST} * {@link #EXTRA_TEMP_LIST} * {@link #EXTRA_FINAL_URI} * * TODO: future systemapi */ public static final String ACTION_DOWNLOAD_RESULT_INTERNAL = "android.telephony.mbms.action.DOWNLOAD_RESULT_INTERNAL"; /** * The MBMS middleware should send this when it wishes to request {@code content://} URIs to * serve as temp files for downloads or when it wishes to resume paused downloads. Mandatory * extras are * {@link #EXTRA_REQUEST} * * Optional extras are * {@link #EXTRA_FD_COUNT} (0 if not present) * {@link #EXTRA_PAUSED_LIST} (empty if not present) * * TODO: future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST =
* * Optional extras are * {@link #EXTRA_FD_COUNT} (0 if not present) * {@link #EXTRA_PAUSED_LIST} (empty if not present) * * TODO: future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST = "android.telephony.mbms.ACTION_FILE_DESCRIPTOR_REQUEST"; /** * The MBMS middleware should send this when it wishes to clean up temp files in the app's * filesystem. Mandatory extras are: * {@link #EXTRA_TEMP_FILES_IN_USE} * * TODO: future systemapi */ public static final String ACTION_CLEANUP = "android.telephony.mbms.ACTION_CLEANUP"; /** * Integer extra indicating the result code of the download. * TODO: put in link to error list * TODO: future systemapi (here and and all extras) */ public static final String EXTRA_RESULT = "android.telephony.mbms.EXTRA_RESULT"; /** * Extra containing the {@link android.telephony.mbms.FileInfo} for which the download result
* * TODO: future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST = "android.telephony.mbms.ACTION_FILE_DESCRIPTOR_REQUEST"; /** * The MBMS middleware should send this when it wishes to signal that there may be orphaned * files in the app's filesystem. Mandatory extras are * {@link #EXTRA_TEMP_FILES_IN_USE} * * TODO: future systemapi */ public static final String ACTION_CLEANUP = "android.telephony.mbms.action.CLEANUP"; /** * Integer extra indicating the result code of the download. * TODO: put in link to error list * TODO: future systemapi (here and and all extras) */ public static final String EXTRA_RESULT = "android.telephony.mbms.EXTRA_RESULT"; /** * Extra containing the {@link android.telephony.mbms.FileInfo} for which the download result * is for. Must not be null. */ public static final String EXTRA_INFO = "android.telephony.mbms.EXTRA_INFO"; /**
* files in the app's filesystem. Mandatory extras are * {@link #EXTRA_TEMP_FILES_IN_USE} * * TODO: future systemapi */ public static final String ACTION_CLEANUP = "android.telephony.mbms.ACTION_CLEANUP"; /** * Integer extra indicating the result code of the download. * TODO: put in link to error list * TODO: future systemapi (here and and all extras) */ public static final String EXTRA_RESULT = "android.telephony.mbms.extra.RESULT"; /** * Extra containing the {@link android.telephony.mbms.FileInfo} for which the download result * is for. Must not be null. */ public static final String EXTRA_INFO = "android.telephony.mbms.EXTRA_INFO"; /** * Extra containing the {@link DownloadRequest} for which the download result or file * descriptor request is for. Must not be null. */ public static final String EXTRA_REQUEST = "android.telephony.mbms.EXTRA_REQUEST"; /**
* decoded downloaded file resides. Must not be null. */ public static final String EXTRA_FINAL_URI = "android.telephony.mbms.EXTRA_FINAL_URI"; /** * Extra containing an integer indicating the number of temp files requested. */ public static final String EXTRA_FD_COUNT = "android.telephony.mbms.EXTRA_FD_COUNT"; /** * Extra containing a list of {@link Uri}s that the middleware is requesting write access to. */ public static final String EXTRA_PAUSED_LIST = "android.telephony.mbms.extra.PAUSED_LIST"; /** * Extra containing a list of {@link android.telephony.mbms.UriPathPair}s, used in the * response to {@link #ACTION_FILE_DESCRIPTOR_REQUEST}. These are temp files that are meant * to be used for new file downloads. */ public static final String EXTRA_FREE_URI_LIST = "android.telephony.mbms.EXTRA_FREE_URI_LIST"; /** * Extra containing a list of {@link android.telephony.mbms.UriPathPair}s, used in the
* decoded downloaded file resides. Must not be null. */ public static final String EXTRA_FINAL_URI = "android.telephony.mbms.EXTRA_FINAL_URI"; /** * Extra containing an integer indicating the number of temp files requested. */ public static final String EXTRA_FD_COUNT = "android.telephony.mbms.EXTRA_FD_COUNT"; /** * Extra containing a list of {@link Uri}s that the middleware is requesting write access to. */ public static final String EXTRA_PAUSED_LIST = "android.telephony.mbms.extra.PAUSED_LIST"; /** * Extra containing a list of {@link android.telephony.mbms.UriPathPair}s, used in the * response to {@link #ACTION_FILE_DESCRIPTOR_REQUEST}. These are temp files that are meant * to be used for new file downloads. */ public static final String EXTRA_FREE_URI_LIST = "android.telephony.mbms.EXTRA_FREE_URI_LIST"; /** * Extra containing a list of {@link android.telephony.mbms.UriPathPair}s, used in the
* still using. */ public static final String EXTRA_TEMP_FILES_IN_USE = "android.telephony.mbms.EXTRA_TEMP_FILES_IN_USE"; public static final int RESULT_SUCCESSFUL = 1; public static final int RESULT_CANCELLED = 2; public static final int RESULT_EXPIRED = 3; // TODO - more results! private final Context mContext; private int mSubId = INVALID_SUBSCRIPTION_ID; private IMbmsDownloadService mService; private final IMbmsDownloadManagerCallback mCallback; private final String mDownloadAppName; public MbmsDownloadManager(Context context, IMbmsDownloadManagerListener callback, String downloadAppName, int subId) { mContext = context; mCallback = callback; mDownloadAppName = downloadAppName; mSubId = subId; } /** * Create a new MbmsDownloadManager using the system default data subscription ID. * * Note that this call will bind a remote service and that may take a bit. This * may throw an Illegal ArgumentException or RemoteException. * * @hide */
private MbmsDownloadManager(Context context, IMbmsDownloadManagerCallback callback, String downloadAppName, int subId) { mContext = context; mCallback = callback; mDownloadAppName = downloadAppName; mSubId = subId;
private MbmsStreamingManager(Context context, IMbmsStreamingManagerCallback listener, String streamingAppName, int subscriptionId) { mContext = context; mAppName = streamingAppName; mCallbackToApp = listener; mSubId = subId;
private MbmsStreamingManager(Context context, IMbmsStreamingManagerCallback listener, String streamingAppName, int subscriptionId) { mContext = context; mAppName = streamingAppName; mCallbackToApp = listener; mSubId = subId;
mBrightnessMode != brightnessMode) { if (DEBUG) Slog.v(TAG, "setLight #" + mId + ": color=#" + Integer.toHexString(color) + ": brightnessMode=" + brightnessMode); mLastColor = mColor; mColor = color; mMode = mode; mOnMS = onMS; mOffMS = offMS; mBrightnessMode = brightnessMode; Trace.traceBegin(Trace.TRACE_TAG_POWER, "setLight(" + mId + ", 0x" + Integer.toHexString(color) + ")"); try { setLight_native(mNativePointer, mId, color, mode, onMS, offMS, brightnessMode); } finally { Trace.traceEnd(Trace.TRACE_TAG_POWER); } }
public static boolean contactsLoaded = false; private static HashMap<String, ArrayList<String>> email = new HashMap<String, ArrayList<String>>(); private static HashMap<String, ArrayList<String>> phone = new HashMap<String, ArrayList<String>>(); private static HashMap<String, ArrayList<String>> address = new HashMap<String, ArrayList<String>>(); private static HashMap<String, String> name = new HashMap<String, String>(); private static HashSet<String> ContactSet = new HashSet<String>(); private static final String TYPE_NAME = "name"; private static final String TYPE_PHONE = "phone"; private static final String TYPE_EMAIL = "email"; private static final String TYPE_ADDRESS = "address"; public static boolean hasFilter(byte[] filter) { return filter != null && filter.length > 0; } public static boolean isNameAndNumberOnly(byte[] filter) { // For vcard 2.0: VERSION,N,TEL is mandatory // For vcard 3.0, VERSION,N,FN,TEL is mandatory // So we only need to make sure that no other fields except optionally // NICKNAME is set // Check that an explicit filter is not set. If not, this means // return everything if (!hasFilter(filter)) {
} public NetworkStats readNetworkStatsDetail(int limitUid, String[] limitIfaces, int limitTag, NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // For 464xlat traffic, xt_qtaguid sees every IPv4 packet twice, once as a native IPv4 // packet on the stacked interface, and once as translated to an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat // packets needs to be subtracted for the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust =
NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat // packet needs to be subtracted from the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L);
NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat // packet needs to be subtracted from the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L);
readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat // packet needs to be subtracted from the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) {
readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat // packet needs to be subtracted from the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) {
for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) { adjust.rxBytes -= (entry.rxBytes + entry.rxPackets * IPV4V6_HEADER_DELTA); adjust.txBytes -= (entry.txBytes + entry.txPackets * IPV4V6_HEADER_DELTA); adjust.rxPackets -= entry.rxPackets; adjust.txPackets -= entry.txPackets; } } stats.combineValues(adjust); } } // For 464xlat traffic, xt_qtaguid only counts the bytes of the inner IPv4 packet sent on // the stacked interface with prefix "v4-" and drops the IPv6 header size after unwrapping. // To account correctly for on-the-wire traffic, adds the 20 additional bytes difference // for all packets (http://b/12249687, http:/b/33681750). for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry);
adjust.rxPackets -= entry.rxPackets; adjust.txPackets -= entry.txPackets; // TODO: does Entry#operations need to be adjusted too ? } } stats.combineValues(adjust); } } // For 464xlat traffic, xt_qtaguid only counts the bytes of the inner IPv4 packet sent on // the stacked interface with prefix "v4-" and drops the IPv6 header size after unwrapping. // To account correctly for on-the-wire traffic, add the 20 additional bytes difference // for all packets (http://b/12249687, http:/b/33681750). for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry); if (entry.iface != null && entry.iface.startsWith(CLATD_INTERFACE_PREFIX)) { entry.rxBytes = entry.rxPackets * IPV4V6_HEADER_DELTA; entry.txBytes = entry.txPackets * IPV4V6_HEADER_DELTA; entry.rxPackets = 0; entry.txPackets = 0; stats.combineValues(entry); } } return stats; }
private static final String CLATD_INTEFACE_PREFIX = "v4-"; /** Path to {@code /proc/net/xt_qtaguid/iface_stat_all}. */ private final File mStatsXtIfaceAll; /** Path to {@code /proc/net/xt_qtaguid/iface_stat_fmt}. */ private final File mStatsXtIfaceFmt; /** Path to {@code /proc/net/xt_qtaguid/stats}. */ private final File mStatsXtUid; // TODO: to improve testability and avoid global state, do no use a static variable. @GuardedBy("sStackedIfaces") private static final ArrayMap<String, String> sStackedIfaces = new ArrayMap<>(); public static void noteStackedIface(String stackedIface, String baseIface) { synchronized (sStackedIfaces) { if (baseIface != null) { sStackedIfaces.put(stackedIface, baseIface); } else { sStackedIfaces.remove(stackedIface); } } } public NetworkStatsFactory() { this(new File("/proc/")); } @VisibleForTesting public NetworkStatsFactory(File procRoot) {
// from root UID on the base interface. NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) { adjust.rxBytes -= (entry.rxBytes + entry.rxPackets * IPV4V6_HEADER_DELTA); adjust.txBytes -= (entry.txBytes + entry.txPackets * IPV4V6_HEADER_DELTA); adjust.rxPackets -= entry.rxPackets; } } stats.combineValues(adjust); } } // Double sigh, all rx traffic on clat needs to be tweaked to // account for the dropped IPv6 header size post-unwrap. for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry); if (entry.iface != null && entry.iface.startsWith(CLATD_INTEFACE_PREFIX)) { // Delta between IPv4 header (20b) and IPv6 header (40b) entry.rxBytes = entry.rxPackets * 20;
private void sendNsdStateChangeBroadcast(boolean isEnabled) { final Intent intent = new Intent(NsdManager.ACTION_NSD_STATE_CHANGED); intent.addFlags(Intent.FLAG_RECEIVER_REGISTERED_ONLY_BEFORE_BOOT); int nsdState = isEnabled ? NsdManager.NSD_STATE_ENABLED : NsdManager.NSD_STATE_DISABLED; intent.putExtra(NsdManager.EXTRA_NSD_STATE, nsdState); mContext.sendStickyBroadcastAsUser(intent, UserHandle.ALL);
for (String conscryptAlg : conscryptAlgs) { Provider.Service service = getService(bc, conscryptAlg); if (service != null) { bcClasses.add(service.getClassName()); } } assertTrue(bcClasses.size() > 0); // Sanity check // 3. Determine which IDs in BC point to that set of classes Set<String> shouldBeOverriddenBcIds = new HashSet<>(); for (Object keyObject : bc.keySet()) { String key = (String) keyObject; if (key.contains(" ")) { continue; } if (key.startsWith("Alg.Alias.")) { key = key.substring("Alg.Alias.".length()); } Provider.Service service = getService(bc, key); if (bcClasses.contains(service.getClassName())) { shouldBeOverriddenBcIds.add(key); } } // 4. Check each of those IDs to ensure that it's present in Conscrypt Set<String> nonOverriddenIds = new TreeSet<>(); for (String shouldBeOverridenBcId : shouldBeOverriddenBcIds) {
* * This terminates at unescaped AVA separators ("+") or RDN * separators (",", ";"), and removes cosmetic whitespace at the end of * values. */ AVA(Reader in, Map<String, String> keywordMap) throws IOException { this(in, DEFAULT, keywordMap); } /** * Parse an AVA string formatted according to format. */ AVA(Reader in, int format) throws IOException { this(in, format, Collections.<String, String>emptyMap()); } /** * Parse an AVA string formatted according to format. * * @param in Reader containing AVA String * @param format parsing format * @param keywordMap a Map where a keyword String maps to a corresponding * OID String. Each AVA keyword will be mapped to the corresponding OID. * If an entry does not exist, it will fallback to the builtin
return s; } catch (IOException e) { // should not occur throw new RuntimeException("AVA error: " + e, e); } } private static DerValue parseHexString (Reader in, int format) throws IOException { int c; ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte b = 0; int cNdx = 0; while (true) { c = in.read(); if (isTerminator(c, format)) { break; } // BEGIN Android-added: AVA: Support DerValue hex strings that contain ' ' or '\n' if (c == ' ' || c == '\n') { do { if (c != ' ' && c != '\n') { throw new IOException("AVA parse, invalid hex " + "digit: "+ (char)c); } c = in.read(); } while (!isTerminator(c, format)); break; } int cVal = hexDigits.indexOf(Character.toUpperCase((char)c)); if (cVal == -1) { throw new IOException("AVA parse, invalid hex " +
while (true) { c = in.read(); if (isTerminator(c, format)) { break; } // Android-changed: Skip trailing whitespace. if (c == ' ' || c == '\n') { do { if (c != ' ' && c != '\n') { throw new IOException("AVA parse, invalid hex " + "digit: "+ (char)c); } c = in.read(); } while (!isTerminator(c, format)); break; } // END Android-added: AVA: Support DerValue hex strings that contain ' ' or '\n' int cVal = hexDigits.indexOf(Character.toUpperCase((char)c)); if (cVal == -1) { throw new IOException("AVA parse, invalid hex " + "digit: "+ (char)c); } if ((cNdx % 2) == 1) { b = (byte)((b * 16) + (byte)(cVal)); baos.write(b); } else { b = (byte)(cVal); } cNdx++; } // throw exception if no hex digits
temp.append(hexString); embeddedHex.clear(); } do { c = in.read(); } while ((c == '\n') || (c == ' ')); if (c != -1) { throw new IOException("AVA had characters other than " + "whitespace after terminating quote"); } // encode as PrintableString unless value contains // non-PrintableString chars if (this.oid.equals((Object)PKCS9Attribute.EMAIL_ADDRESS_OID) || (this.oid.equals((Object)X500Name.DOMAIN_COMPONENT_OID) && PRESERVE_OLD_DC_ENCODING == false)) { // EmailAddress and DomainComponent must be IA5String return new DerValue(DerValue.tag_IA5String, temp.toString()); } else if (isPrintableString) { return new DerValue(temp.toString()); } else { return new DerValue(DerValue.tag_UTF8String, temp.toString()); } } private DerValue parseString
* This class is not a general repository for OIDs, or for such string names. * Note that the mappings between algorithm IDs and algorithm names is * not one-to-one. * * * @author David Brownell * @author Amit Kapoor * @author Hemma Prafullchandra */ public class AlgorithmId implements Serializable, DerEncoder { /** use serialVersionUID from JDK 1.1. for interoperability */ private static final long serialVersionUID = 7205873507486557157L; /** * The object identitifer being used for this algorithm. */ private ObjectIdentifier algid; // The (parsed) parameters private AlgorithmParameters algParams; private boolean constructedFromDer = true; /** * Parameters for this algorithm. These are stored in unparsed * DER-encoded form; subclasses can be made to automaticaly parse
} catch (NoSuchAlgorithmException e) { // BEGIN Android-changed // It was searching for the EC parameters in an internal provider in the deleted package // sun.security.ec before setting them to null. Since EC is in the OpenSSL provider, // there's no need for such fallback. Setting it to null directly. /* * This algorithm parameter type is not supported, so we cannot * parse the parameters. */ algParams = null; return; // END Android-changed } // Decode (parse) the parameters algParams.init(params.toByteArray()); } /** * Marshal a DER-encoded "AlgorithmID" sequence on the DER stream. */ public final void encode(DerOutputStream out) throws IOException { derEncode(out); } /** * DER encode this object onto an output stream. * Implements the <code>DerEncoder</code> interface. * * @param out * the output stream on which to write the DER encoding. * * @exception IOException on encoding error.
private static final String OCSPNOCHECK = ROOT + "." + OCSPNoCheckExtension.NAME; private static final int NetscapeCertType_data[] = { 2, 16, 840, 1, 113730, 1, 1 }; /** Map ObjectIdentifier(oid) -> OIDInfo(info) */ private final static Map<ObjectIdentifier,OIDInfo> oidMap; /** Map String(friendly name) -> OIDInfo(info) */ private final static Map<String,OIDInfo> nameMap; // BEGIN Android-changed: Specify Class objects rather for oidMap rather than String // literals + reflection. static { oidMap = new HashMap<ObjectIdentifier,OIDInfo>(); nameMap = new HashMap<String,OIDInfo>(); addInternal(SUB_KEY_IDENTIFIER, PKIXExtensions.SubjectKey_Id, SubjectKeyIdentifierExtension.class); addInternal(KEY_USAGE, PKIXExtensions.KeyUsage_Id, KeyUsageExtension.class); addInternal(PRIVATE_KEY_USAGE, PKIXExtensions.PrivateKeyUsage_Id, PrivateKeyUsageExtension.class); addInternal(SUB_ALT_NAME, PKIXExtensions.SubjectAlternativeName_Id, SubjectAlternativeNameExtension.class); addInternal(ISSUER_ALT_NAME, PKIXExtensions.IssuerAlternativeName_Id, IssuerAlternativeNameExtension.class); addInternal(BASIC_CONSTRAINTS, PKIXExtensions.BasicConstraints_Id,
SubjectInfoAccessExtension.class); addInternal(AUTH_INFO_ACCESS, PKIXExtensions.AuthInfoAccess_Id, AuthorityInfoAccessExtension.class); addInternal(ISSUING_DIST_POINT, PKIXExtensions.IssuingDistributionPoint_Id, IssuingDistributionPointExtension.class); addInternal(DELTA_CRL_INDICATOR, PKIXExtensions.DeltaCRLIndicator_Id, DeltaCRLIndicatorExtension.class); addInternal(FRESHEST_CRL, PKIXExtensions.FreshestCRL_Id, FreshestCRLExtension.class); addInternal(OCSPNOCHECK, PKIXExtensions.OCSPNoCheck_Id, OCSPNoCheckExtension.class); } /** * Add attributes to the table. For internal use in the static * initializer. */ private static void addInternal(String name, ObjectIdentifier oid, Class clazz) { OIDInfo info = new OIDInfo(name, oid, clazz); oidMap.put(oid, info); nameMap.put(name, info); } /** * Inner class encapsulating the mapping info and Class loading. */ private static class OIDInfo { final ObjectIdentifier oid; final String name; private volatile Class<?> clazz; OIDInfo(String name, ObjectIdentifier oid, Class<?> clazz) {
private AVAComparator() { // empty } static Comparator<AVA> getInstance() { return INSTANCE; } /** * AVA's containing a standard keyword are ordered alphabetically, * followed by AVA's containing an OID keyword, ordered numerically */ public int compare(AVA a1, AVA a2) { boolean a1Has2253 = a1.hasRFC2253Keyword(); boolean a2Has2253 = a2.hasRFC2253Keyword(); // BEGIN Android-changed: Keep sort order of RDN from Android M if (a1Has2253) { if (a2Has2253) { return a1.toRFC2253CanonicalString().compareTo (a2.toRFC2253CanonicalString()); } else { return -1; } } else { if (a2Has2253) { return 1; } else { int[] a1Oid = a1.getObjectIdentifier().toIntArray(); int[] a2Oid = a2.getObjectIdentifier().toIntArray(); int pos = 0; int len = (a1Oid.length > a2Oid.length) ? a2Oid.length :
* distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.nfc; import android.content.BroadcastReceiver; import android.content.Context; import android.content.Intent; import android.content.pm.PackageManager; /** * Boot completed receiver. used to disable the application if the device doesn't * support NFC when device boots. * */ public class NfcBootCompletedReceiver extends BroadcastReceiver { @Override public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action == null) { return; } if (action.equals(Intent.ACTION_BOOT_COMPLETED)) { PackageManager pm = context.getPackageManager(); if (!pm.hasSystemFeature(PackageManager.FEATURE_NFC)) { pm.setApplicationEnabledSetting(context.getPackageName(), PackageManager.COMPONENT_ENABLED_STATE_DISABLED, 0); } } } }
public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action == null) { return; } if (Intent.ACTION_BOOT_COMPLETED.equals(action)) { PackageManager pm = context.getPackageManager(); if (!pm.hasSystemFeature(PackageManager.FEATURE_NFC)) { pm.setApplicationEnabledSetting(context.getPackageName(), PackageManager.COMPONENT_ENABLED_STATE_DISABLED, 0); } }
public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action == null) { return; } if (action.equals(Intent.ACTION_BOOT_COMPLETED)) { PackageManager pm = context.getPackageManager(); if (!pm.hasSystemFeature(PackageManager.FEATURE_NFC_ANY)) { pm.setApplicationEnabledSetting(context.getPackageName(), PackageManager.COMPONENT_ENABLED_STATE_DISABLED, 0); } }
NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // Sigh, xt_qtaguid ends up double-counting tx traffic going through // clatd interfaces, so we need to subtract it here. final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) {
*/ public static native String getOsVersion(); /** * @return hardware id extracted from uname() native call */ public static native String getHardwareId(); /** * @return kernel version extracted from uname() native call */ public static native String getKernelVersion(); /** * @return sysprop ro.boot.avb_version */ public static native String getBootAvbVersion(); /** * @return libavb version in bootloader. Format is {@code x.y}. */ public static native String getBootVbmetaAvbVersion(); }
private void setLightLocked(int color, int mode, int onMS, int offMS, int brightnessMode) { if (shouldBeInLowPersistenceMode()) { brightnessMode = BRIGHTNESS_MODE_LOW_PERSISTENCE; } else if (brightnessMode == BRIGHTNESS_MODE_LOW_PERSISTENCE) { brightnessMode = mLastBrightnessMode; } if (!mInitialized || color != mColor || mode != mMode || onMS != mOnMS || offMS != mOffMS || mBrightnessMode != brightnessMode) { if (DEBUG) Slog.v(TAG, "setLight #" + mId + ": color=#" + Integer.toHexString(color) + ": brightnessMode=" + brightnessMode); mInitialized = true; mLastColor = mColor; mColor = color; mMode = mode; mOnMS = onMS; mOffMS = offMS; mBrightnessMode = brightnessMode; Trace.traceBegin(Trace.TRACE_TAG_POWER, "setLight(" + mId + ", 0x" + Integer.toHexString(color) + ")"); try {
private int putListener(Object listener, NsdServiceInfo s) { checkListener(listener); final int key; synchronized (mMapLock) { int valueIndex = mListenerMap.indexOfValue(listener); checkArgument(valueIndex == -1, "listener already in use"); key = nextListenerKey(); mListenerMap.put(key, listener); mServiceMap.put(key, s); } return key;
public int initialize(IMbmsStreamingManagerCallback listener, String appName, int subId) { String appKey = appName + subId; if (!mAppCallbacks.containsKey(appKey)) { mAppCallbacks.put(appKey, listener); } else { return MbmsInitializationException.ERROR_ALREADY_INITIALIZED; }
@Override public boolean isTrue() throws UiObjectNotFoundException { return device.findObject( new UiSelector().resourceId(Res.GOOGLE_PLAY_INPUT_RES)).exists(); } }); if (inputTextFieldExists) { UiObject inputTextField = device.findObject( new UiSelector().resourceId(Res.GOOGLE_PLAY_INPUT_RES)); inputTextField.clearTextField(); inputTextField.setText(application); device.pressEnter(); } } /** * Selects an application listed in the Play Store. */ public static void selectFromGooglePlay(Instrumentation instrumentation, String appDescription) throws Exception { final UiDevice device = UiDevice.getInstance(instrumentation); final String playStore = "Play Store"; final String application = appDescription; boolean isListed = new Wait().until(new Wait.ExpectedCondition() { @Override public boolean isTrue() throws UiObjectNotFoundException { return device.findObject(new UiSelector() .description(application)).exists(); } }); if (isListed) { device.findObject(new UiSelector() .description(application)).clickAndWaitForNewWindow();
public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. * * Filters out any tests with API version greater than current API version. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { int thisApiVersion = android.os.Build.VERSION.SDK_INT; int minApiVersion = 21; if (thisApiVersion < minApiVersion) { Log.w(TAG, String.format("API version is less than %d, no tests running", minApiVersion)); } Context ctx = InstrumentationRegistry.getTargetContext(); List<UnitTest> validUnitTests = new ArrayList<>(); for (Class<? extends UnitTest> testClass : RSTests.getTestClassesForCurrentAPIVersion()) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); validUnitTests.add(test); } checkDuplicateNames(validUnitTests); return validUnitTests; } /** * Throws RuntimeException if any tests have the same name. */ private static void checkDuplicateNames(List<UnitTest> tests) {
* To run the test, please use command * * adb shell am instrument -w com.android.rs.testforward/android.support.test.runner.AndroidJUnitRunner */ @RunWith(Parameterized.class) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); List<UnitTest> validUnitTests = new ArrayList<>(); Iterable<Class<? extends UnitTest>> testClasses = RSUtils.getProperSubclasses(UnitTest.class); List<UnitTest> ret = new ArrayList<>(); for (Class<? extends UnitTest> testClass : unitTestClasses) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); ret.add(test); } return ret; } @Parameter(0) public UnitTest mTest; @Test @MediumTest public void testRSUnitTest() throws Exception { String thisDeviceName = android.os.Build.DEVICE; int thisApiVersion = android.os.Build.VERSION.SDK_INT;
*/ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); Iterable<Class<? extends UnitTest>> unitTestClasses = RSUtils.getProperSubclasses(UnitTest.class); List<UnitTest> ret = new ArrayList<>(); for (Class<? extends UnitTest> testClass : unitTestClasses) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); ret.add(test); } UnitTest.checkDuplicateNames(validUnitTests); return validUnitTests; } @Parameter(0) public UnitTest mTest; @Test @MediumTest public void testRSUnitTest() throws Exception { String thisDeviceName = android.os.Build.DEVICE; int thisApiVersion = android.os.Build.VERSION.SDK_INT; Log.i(TAG, String.format("RenderScript forward compatibility testing (%s) " + "on device %s, API version %d", mTest.toString(), thisDeviceName, thisApiVersion)); mTest.runTest(); switch (mTest.getResult()) { case UT_NOT_STARTED: case UT_RUNNING:
import java.util.ArrayList; import java.util.HashSet; import java.util.List; import java.util.Set; /** * RSTestBackward, functional test for platform RenderScript APIs. * To run the test, please use command * * adb shell am instrument -w com.android.rs.testbackward/android.support.test.runner.AndroidJUnitRunner */ @RunWith(Parameterized.class) public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. * * Filters out any tests with API version greater than current API version. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { int thisApiVersion = android.os.Build.VERSION.SDK_INT; if (thisApiVersion < 19) { Log.w(TAG, "API version is less than 19, no tests running"); } Context ctx = InstrumentationRegistry.getTargetContext(); ArrayList<UnitTest> validUnitTests = new ArrayList<>();
public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. * * Filters out any tests with API version greater than current API version. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { int thisApiVersion = android.os.Build.VERSION.SDK_INT; if (thisApiVersion < 21) { Log.w(TAG, "API version is less than 21, no tests running"); } Context ctx = InstrumentationRegistry.getTargetContext(); ArrayList<UnitTest> validUnitTests = new ArrayList<>(); for (Class<? extends UnitTest> testClass : RSTests.getTestClassesForCurrentAPIVersion()) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); validUnitTests.add(test); } checkDuplicateNames(validUnitTests); return validUnitTests; } /** * Throws RuntimeException if any tests have the same name. */ private static void checkDuplicateNames(List<UnitTest> tests) {
} Context ctx = InstrumentationRegistry.getTargetContext(); ArrayList<UnitTest> validUnitTests = new ArrayList<>(); for (Class<? extends UnitTest> testClass : RSTests.getTestClassesForCurrentAPIVersion()) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); validUnitTests.add(test); } checkDuplicateNames(validUnitTests); return validUnitTests; } /** * Throws RuntimeException if any tests have the same name. */ private static void checkDuplicateNames(List<UnitTest> tests) { Set<String> names = new HashSet<>(); for (UnitTest test : tests) { String name = test.toString(); if (names.contains(name)) { throw new RuntimeException("duplicate name: " + name); } names.add(name); } } @Parameter(0) public UnitTest mTest; @Test @MediumTest public void testRSUnitTest() throws Exception { String thisDeviceName = android.os.Build.DEVICE; int thisApiVersion = android.os.Build.VERSION.SDK_INT;
import com.android.rs.unittest.*; import java.util.ArrayList; /** * This class is auto-generated by frameworks/rs/tests/java_api/RSUnitTests/RSUnitTests.py. * To change unit tests version, please run the Python script above. */ public class RSTests { public static Iterable<Class<? extends UnitTest>> getTestClassesForCurrentAPIVersion() { int thisApiVersion = android.os.Build.VERSION.SDK_INT; ArrayList<Class<? extends UnitTest>> validClasses = new ArrayList<>(); if (thisApiVersion >= 19) { validClasses.add(UT_alloc.class); validClasses.add(UT_array_alloc.class); validClasses.add(UT_array_init.class); validClasses.add(UT_atomic.class); validClasses.add(UT_bitfield.class); validClasses.add(UT_bug_char.class); validClasses.add(UT_check_dims.class); validClasses.add(UT_clamp.class); validClasses.add(UT_clamp_relaxed.class); validClasses.add(UT_constant.class); validClasses.add(UT_convert.class); validClasses.add(UT_convert_relaxed.class); validClasses.add(UT_copy_test.class); validClasses.add(UT_element.class);
import android.content.Context; import android.support.test.InstrumentationRegistry; import android.support.test.filters.MediumTest; import android.util.Log; import org.junit.Assert; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameter; import org.junit.runners.Parameterized.Parameters; /** * RSTestForward, functional test for platform RenderScript APIs. * To run the test, please use command * * adb shell am instrument -w com.android.rs.testforward/android.support.test.runner.AndroidJUnitRunner */ @RunWith(Parameterized.class) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { return RSUtils.getProperSubclasses(UnitTest.class); } @Parameter(0) public Class<? extends UnitTest> mTestClass; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext();
import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameter; import org.junit.runners.Parameterized.Parameters; /** * RSTestForward, functional test for platform RenderScript APIs. * To run the test, please use command * * adb shell am instrument -w com.android.rs.testforward/android.support.test.runner.AndroidJUnitRunner * */ @RunWith(Parameterized.class) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { return RSUtils.getProperSubclasses(UnitTest.class); } @Parameter(0) public Class<? extends UnitTest> mTestClass; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); UnitTest test = mTestClass.getDeclaredConstructor(Context.class).newInstance(ctx); test.runTest(); switch (test.getResult()) { case UT_NOT_STARTED: case UT_RUNNING:
return RSUtils.getProperSubclasses(UnitTest.class); } @Parameter(0) public Class<? extends UnitTest> mTestClass; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); UnitTest test = mTestClass.getDeclaredConstructor(Context.class).newInstance(ctx); test.runTest(); switch (test.getResult()) { case UT_NOT_STARTED: case UT_RUNNING: Log.w(TAG, "unexpected unit test result: " + test.getResult().toString()); break; } Assert.assertTrue(mTest.getSuccess()); } }
* Copyright (C) 2017 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.rs.testforward; import com.android.rs.unittest.UnitTest; import android.content.Context; import android.support.test.InstrumentationRegistry; import dalvik.system.DexFile; import java.io.IOException; import java.util.ArrayList; import java.util.Enumeration; public class RSUtils { /** Returns a list of all proper subclasses of the input class */
MetricsLogger.histogram(context, "ota_stashed_in_MiBs", bytesStashedInMiB); } if (temperatureStart != -1) { MetricsLogger.histogram(context, "ota_temperature_start", temperatureStart); } if (temperatureEnd != -1) { MetricsLogger.histogram(context, "ota_temperature_end", temperatureEnd); } if (temperatureMax != -1) { MetricsLogger.histogram(context, "ota_temperature_max", temperatureMax); } if (errorCode != -1) { MetricsLogger.histogram(context, "ota_non_ab_error_code", errorCode); } if (causeCode != -1) { MetricsLogger.histogram(context, "ota_blockbased_cause_code", timeTotal); } } catch (IOException e) { Log.e(TAG, "Failed to read lines in last_install", e); }
} else if (line.startsWith("source_build")) { sourceVersion = scaled; } else if (line.startsWith("bytes_written")) { bytesWrittenInMiB = (bytesWrittenInMiB == -1) ? scaled : bytesWrittenInMiB + scaled; } else if (line.startsWith("bytes_stashed")) { bytesStashedInMiB = (bytesStashedInMiB == -1) ? scaled : bytesStashedInMiB + scaled; } else if (line.startsWith("temperatureStart")) { temperatureStart = scaled; } else if (line.startsWith("temperature_end")) { temperatureEnd = scaled; } else if (line.startsWith("temperatureMax")) { temperatureMax = scaled; } else if (line.startsWith("error")) { errorCode = scaled; } else if (line.startsWith("cause")) { causeCode = scaled; } } // Don't report data to tron if corresponding entry isn't found in last_install. if (timeTotal != -1) {
void sendTrackChangeWithId(int trackChangedNT, MediaController mediaController) { if (DEBUG) Log.d(TAG, "sendTrackChangeWithId"); byte[] track; try { String mediaId = mediaController.getMetadata().getDescription().getMediaId(); long qid = MediaSession.QueueItem.UNKNOWN_ID; List<MediaSession.QueueItem> items = mNowPlayingList; /* traverse now playing list for current playing item */ for (QueueItem item : items) { if (item.getDescription().getMediaId().equals(mediaId)) { qid = item.getQueueId(); if (DEBUG) Log.d(TAG, "sendTrackChangeWithId: Found matching qid= " + qid); break; } } /* for any item associated with NowPlaying, uid is queueId */ track = ByteBuffer.allocate(AvrcpConstants.UID_SIZE).putLong(qid).array(); } catch (NullPointerException e) { Log.w(TAG, "NullPointerException getting uid, sending no track selected");
} else if (!isPlayerAlreadyAddressed(selectedId)) { // register new Media Controller Callback and update the current Ids if (!updateCurrentController(selectedId, mCurrBrowsePlayerID)) { status = AvrcpConstants.RSP_INTERNAL_ERR; Log.e(TAG, "register for new Address player failed: " + mCurrAddrPlayerID); } } if (DEBUG) Log.d(TAG, "setAddressedPlayer for selectedId: " + selectedId + " , status: " + status); // Sending address player response to remote setAddressedPlayerRspNative(bdaddr, status);
mUnbinding = false; mEnable = false; mState = BluetoothAdapter.STATE_OFF; mQuietEnableExternal = false; mEnableExternal = false; mAddress = null; mName = null; mErrorRecoveryRetryCounter = 0; mContentResolver = context.getContentResolver(); // Observe BLE scan only mode settings change. registerForBleScanModeChange(); mCallbacks = new RemoteCallbackList<IBluetoothManagerCallback>(); mStateChangeCallbacks = new RemoteCallbackList<IBluetoothStateChangeCallback>(); IntentFilter filter = new IntentFilter(BluetoothAdapter.ACTION_LOCAL_NAME_CHANGED); filter.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter); filter = new IntentFilter(BluetoothAdapter.ACTION_BLUETOOTH_ADDRESS_CHANGED); filter.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter); filter = new IntentFilter(Intent.ACTION_SETTING_RESTORED); mContext.registerReceiver(mReceiver, filter); loadStoredNameAndAddress(); if (isBluetoothPersistedStateOn()) { if (DBG) Slog.d(TAG, "Startup: Bluetooth persisted state is ON."); mEnableExternal = true; } String airplaneModeRadios = Settings.Global.getString(mContentResolver, Settings.Global.AIRPLANE_MODE_RADIOS); if (airplaneModeRadios == null ||
protected int adjustDexoptNeeded(int dexoptNeeded) { if (dexoptNeeded == DexFile.NO_DEXOPT_NEEDED) { // Ensure compilation by pretending a compiler filter change on the // apk/odex location (the reason for the '-'. A positive value means // the 'oat' location). return -DexFile.DEX2OAT_FOR_FILTER; } return dexoptNeeded;
private static final int CRASH_LOG_MAX_SIZE = 100; private static final String REASON_AIRPLANE_MODE = "airplane mode"; private static final String REASON_RESTARTED = "automatic restart"; private static final String REASON_START_CRASH = "turn-on crash"; private static final String REASON_SYSTEM_BOOT = "system boot"; private static final String REASON_UNEXPECTED = "unexpected crash"; private static final String REASON_USER_SWITCH = "user switch"; private static final int TIMEOUT_BIND_MS = 3000; //Maximum msec to wait for a bind //Maximum msec to wait for service restart private static final int SERVICE_RESTART_TIME_MS = 200; //Maximum msec to wait for restart due to error private static final int ERROR_RESTART_TIME_MS = 3000; //Maximum msec to delay MESSAGE_USER_SWITCHED private static final int USER_SWITCHED_TIME_MS = 200; // Delay for the addProxy function in msec private static final int ADD_PROXY_DELAY_MS = 100;
/// CHECK-DAG: <<Add:d\d+>> VecAdd [<<Load>>,<<Repl>>] /// CHECK-NOT: IntermediateAddress /// CHECK-DAG: VecStore [<<Array>>,<<Address1>>,<<Add>>] /// CHECK-START-ARM64: void Main.checkIntCase(int[]) disassembly (after) /// CHECK: IntermediateAddressIndex /// CHECK-NEXT: add w{{[0-9]+}}, w{{[0-9]+}}, w{{[0-9]+}}, lsl #2 public static void checkIntCase(int[] a) { for (int i = 0; i < 128; i++) { a[i] += 5; } } /// CHECK-START-ARM64: void Main.checkByteCase(byte[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: <<Array:l\d+>> ParameterValue /// CHECK-DAG: <<Const5:i\d+>> IntConstant 5 /// CHECK-DAG: <<Repl:d\d+>> VecReplicateScalar [<<Const5>>] // -------------- Loop /// CHECK-DAG: <<Index:i\d+>> Phi
/// CHECK-DAG: <<Add:d\d+>> VecAdd [<<Load>>,<<Repl>>] /// CHECK-NOT: IntermediateAddress /// CHECK-DAG: VecStore [<<Array>>,<<Address1>>,<<Add>>] /// CHECK-START-ARM64: void Main.checkByteCase(byte[]) disassembly (after) /// CHECK: IntermediateAddressIndex /// CHECK-NEXT: add w{{[0-9]+}}, w{{[0-9]+}}, #0x{{[0-9a-fA-F]+}} /// CHECK: VecLoad /// CHECK-NEXT: ldr q{{[0-9]+}}, [x{{[0-9]+}}, x{{[0-9]+}}] /// CHECK: VecStore /// CHECK-NEXT: str q{{[0-9]+}}, [x{{[0-9]+}}, x{{[0-9]+}}] public static void checkByteCase(byte[] a) { for (int i = 0; i < 128; i++) { a[i] += 5; } }
/// CHECK: <<Add:d\d+>> VecAdd [<<Load>>,<<Repl>>] /// CHECK-NOT: IntermediateAddress /// CHECK: VecStore [<<Array>>,<<Address1>>,<<Add>>] /// CHECK-START-ARM64: void Main.checkIntCase(int[]) disassembly (after) /// CHECK: IntermediateAddressIndex /// CHECK-NEXT: add w{{[0-9]+}}, w{{[0-9]+}}, w{{[0-9]+}}, lsl #2 public static void checkIntCase(int[] a) { for (int i = 0; i < 128; i++) { a[i] += 5; } } /// CHECK-START-ARM64: void Main.checkByteCase(byte[]) instruction_simplifier_arm64 (before) /// CHECK: <<Array:l\d+>> ParameterValue /// CHECK: <<Const5:i\d+>> IntConstant 5 /// CHECK: <<Repl:d\d+>> VecReplicateScalar [<<Const5>>] // -------------- Loop /// CHECK: <<Index:i\d+>> Phi /// CHECK: If
public static void checkInt2Float(int[] a, float[] b) { for (int i = 0; i < 128; i++) { b[i] = (float) a[i]; }
public static void checkInt2Float(int[] a, float[] b) { for (int i = 0; i < 128; i++) { b[i] = (float) a[i]; }
public static int calcArraySum(int[] a, byte[] b, float[] c) { int sum = 0; for (int i = 0; i < 128; i++) { sum += a[i] + b[i] + (int) c[i]; } return sum;
* Agreement between Taligent and Sun. This technology is protected * by multiple US and International patents. * * This notice and attribution to Taligent may not be removed. * Taligent is a registered trademark of Taligent, Inc. * */ package java.awt.font; import java.io.InvalidObjectException; import java.text.AttributedCharacterIterator.Attribute; import java.util.Map; import java.util.HashMap; // Android-removed: List of classes for use with attribute keys; Android doesn't have those. // Android-removed: "Summary of attributes" section. Android doesn't have the referenced classes. /** * The <code>TextAttribute</code> class defines attribute keys and * attribute values used for text rendering. * <p> * <code>TextAttribute</code> instances are used as attribute keys to * identify attributes in classes handling text attributes. Other * constants defined in this class can be used as attribute values. * <p> * For each text attribute, the documentation provides: * <UL> * <LI>the type of its value, * <LI>the relevant predefined constants, if any
if (instance != null) { return instance; } else { throw new InvalidObjectException("unknown attribute name"); } } // Serialization compatibility with Java 2 platform v1.2. // 1.2 will throw an InvalidObjectException if ever asked to // deserialize INPUT_METHOD_UNDERLINE. // This shouldn't happen in real life. static final long serialVersionUID = 7744112784117861702L; // // For use with Font. // // Android-removed: Don't link to java.awt.Font class, it doesn't exist on Android. /** * Attribute key for the font name. Values are instances of * <b><code>String</code></b>. The default value is * <code>"Default"</code>, which causes the platform default font * family to be used. * * <p> The <code>Font</code> class defines constants for the logical * font names. * * <p>This defines the value passed as <code>name</code> to the * <code>Font</code> constructor. Both logical and physical
* and the rendering system might not render text at these sizes. * Negative sizes are illegal and result in the default size. * * <p>Note that the appearance and metrics of a 12pt font with a * 2x transform might be different than that of a 24 point font * with no transform. */ public static final TextAttribute SIZE = new TextAttribute("size"); // Android-removed: References to classes that don't exist on Android. // These classes were AffineTransform, Font, and TransformAttribute. /** * Attribute key for the transform of a font. Values are * instances of <b><code>TransformAttribute</code></b>. The * default value is <code>TransformAttribute.IDENTITY</code>. * * <p>The primary intent is to support scaling and skewing, though * other effects are possible.</p> * * <p>Some transforms will cause the baseline to be rotated and/or * shifted. The text and the baseline are transformed together so * that the text follows the new baseline. For example, with text
* and descent can never become negative, however. */ public static final TextAttribute SUPERSCRIPT = new TextAttribute("superscript"); /** * Standard superscript. * @see #SUPERSCRIPT */ public static final Integer SUPERSCRIPT_SUPER = Integer.valueOf(1); /** * Standard subscript. * @see #SUPERSCRIPT */ public static final Integer SUPERSCRIPT_SUB = Integer.valueOf(-1); // Android-removed: Don't link to java.awt.Font class, it doesn't exist on Android. /** * Attribute key used to provide the font to use to render text. * * The default * value is null, indicating that normal resolution of a * <code>Font</code> from attributes should be performed. * * <p><code>TextLayout</code> and * <code>AttributedCharacterIterator</code> work in terms of * <code>Maps</code> of <code>TextAttributes</code>. Normally, * all the attributes are examined and used to select and * configure a <code>Font</code> instance. If a <code>FONT</code>
* default value for <code>JUSTIFICATION</code>. * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_FULL = Float.valueOf(1.0f); /** * Do not allow the line to be justified. * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_NONE = Float.valueOf(0.0f); // // For use by input method. // // Android-removed: References to java.awt.im.InputMethodHighlight (doesn't exist on Android). /** * Attribute key for input method highlight styles. * * The default value is <code>null</code>, * which means that input method styles should not be applied * before rendering. * * @see java.text.Annotation */ public static final TextAttribute INPUT_METHOD_HIGHLIGHT = new TextAttribute("input method highlight"); /** * Attribute key for input method underlines. Values * are instances of <b><code>Integer</code></b>. The default * value is <code>-1</code>, which means no underline. *
mHandler.removeMessages(MESSAGE_RESTART_BLUETOOTH_SERVICE); if (mEnable && mBluetooth != null) { waitForOnOff(true, false); mEnable = false; handleDisable(); waitForOnOff(false, false); } else { mEnable = false; handleDisable(); } break; case MESSAGE_RESTORE_ON_SETTING: try { if ((msg.arg1 == RESTORE_SETTING_TO_OFF) && mEnable) { if (DBG) Slog.d(TAG, "Restore Bluetooth state to disabled"); disable(REASON_RESTORE_USER_SETTING, true); } else if ((msg.arg1 == RESTORE_SETTING_TO_ON) && !mEnable) { if (DBG) Slog.d(TAG, "Restore to enable Bluetooth"); enable(REASON_RESTORE_USER_SETTING); } } catch (RemoteException e) { Slog.e(TAG,"Unable to change Bluetooth On setting",e); } break; case MESSAGE_REGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_ADAPTER:
} else { mEnable = false; handleDisable(); } break; case MESSAGE_RESTORE_ON_SETTING: try { if ((msg.arg1 == RESTORE_SETTING_TO_OFF) && mEnable) { if (DBG) Slog.d(TAG, "Restore to disable Bluetooth"); disable(REASON_RESTORE_USER_SETTING, true); } else if ((msg.arg1 == RESTORE_SETTING_TO_ON) && !mEnable) { if (DBG) Slog.d(TAG, "Restore Bluetooth state to enabled"); enable(REASON_RESTORE_USER_SETTING); } } catch (RemoteException e) { Slog.e(TAG,"Unable to change Bluetooth On setting",e); } break; case MESSAGE_REGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.unregister(callback); break; } case MESSAGE_REGISTER_STATE_CHANGE_CALLBACK: {
private static final int MESSAGE_BLUETOOTH_STATE_CHANGE = 60; private static final int MESSAGE_TIMEOUT_BIND = 100; private static final int MESSAGE_TIMEOUT_UNBIND = 101; private static final int MESSAGE_GET_NAME_AND_ADDRESS = 200; private static final int MESSAGE_USER_SWITCHED = 300; private static final int MESSAGE_USER_UNLOCKED = 301; private static final int MESSAGE_ADD_PROXY_DELAYED = 400; private static final int MESSAGE_BIND_PROFILE_SERVICE = 401; private static final int MESSAGE_RESTORE_USER_SETTING = 500; private static final int RESTORE_SETTING_TO_ON = 1; private static final int RESTORE_SETTING_TO_OFF = 0; private static final int MAX_SAVE_RETRIES = 3; private static final int MAX_ERROR_RESTART_RETRIES = 6; // Bluetooth persisted setting is off private static final int BLUETOOTH_OFF=0; // Bluetooth persisted setting is on // and Airplane mode won't affect Bluetooth state at start up private static final int BLUETOOTH_ON_BLUETOOTH=1; // Bluetooth persisted setting is on
Intent.EXTRA_SETTING_NEW_VALUE); if (DBG) Slog.d(TAG, "ACTION_SETTING_RESTORED with BLUETOOTH_ON, prevValue=" + prevValue + ", newValue=" + newValue); if ((newValue != null) && (prevValue != null) && !prevValue.equals(newValue)) { Message msg = mHandler.obtainMessage(MESSAGE_RESTORE_USER_SETTING, newValue.equals("0") ? RESTORE_SETTING_TO_OFF : RESTORE_SETTING_TO_ON, 0); mHandler.sendMessage(msg); } } }
if ((msg.arg1 == RESTORE_SETTING_TO_OFF) && mEnable) { if (DBG) Slog.d(TAG, "Restore Bluetooth state to disabled"); disable(REASON_RESTORE_USER_SETTING, true); } else if ((msg.arg1 == RESTORE_SETTING_TO_ON) && !mEnable) { if (DBG) Slog.d(TAG, "Restore Bluetooth state to enabled"); enable(REASON_RESTORE_USER_SETTING); } } catch (RemoteException e) { Slog.e(TAG,"Unable to change Bluetooth On setting", e); } break; case MESSAGE_REGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.unregister(callback); break; } case MESSAGE_REGISTER_STATE_CHANGE_CALLBACK: { IBluetoothStateChangeCallback callback = (IBluetoothStateChangeCallback) msg.obj; mStateChangeCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_STATE_CHANGE_CALLBACK: {
* @hide */ public class ServiceInfo implements Parcelable { // arbitrary limit on the number of locale -> name pairs we support final static int MAP_LIMIT = 50; /** * User displayable names listed by language. Unmodifiable. */ final Map<Locale, String> names; /** * The class name for this service - used to catagorize and filter */ final String className; /** * The language for this service content */ final Locale locale; /** * The carrier's identifier for the service. */ final String serviceId; /** * The start time indicating when this service will be available. */ final Date sessionStartTime; /** * The end time indicating when this sesion stops being available. */ final Date sessionEndTime; public ServiceInfo(Map<Locale, String> newNames, String newClassName, Locale newLocale, String newServiceId, Date start, Date end) {
/** * Initialize streaming service for this app and subId, registering the listener. * * @param listener The callback to use to communicate with the app. * @param appName The package name of the calling app. * @param subscriptionId The subscription ID to use. * @return {@link MbmsException#ERROR_ALREADY_INITIALIZED} or {@link MbmsException#SUCCESS}. */ @Override public int initialize(IMbmsStreamingManagerCallback listener, String appName, int subscriptionId) throws RemoteException { return 0; } /** * Registers serviceClasses of interest with the appName/subId key. * Starts async fetching data on streaming services of matching classes to be reported * later via {@link IMbmsStreamingManagerCallback#streamingServicesUpdated(List)} * * Note that subsequent calls with the same appName and subId will replace * the service class list. * * @param appName The package name of the calling app. * @param subscriptionId The subscription id for eMBMS
/** * Initialize streaming service for this app and subId, registering the listener. * * @param listener The callback to use to communicate with the app. * @param appName The package name of the calling app. * @param subscriptionId The subscription ID to use. * @return {@link MbmsException#ERROR_ALREADY_INITIALIZED} or {@link MbmsException#SUCCESS}. */ @Override public int initialize(IMbmsStreamingManagerCallback listener, String appName, int subscriptionId) throws RemoteException { return 0; } /** * Registers serviceClasses of interest with the appName/subId key. * Starts async fetching data on streaming services of matching classes to be reported * later via {@link IMbmsStreamingManagerCallback#streamingServicesUpdated(List)} * * Note that subsequent calls with the same appName and subId will replace * the service class list. * * @param appName The package name of the calling app. * @param subscriptionId The subscription id for eMBMS
*/ @Override public int initialize(IMbmsStreamingManagerCallback listener, String appName, int subscriptionId) throws RemoteException { return 0; } /** * Registers serviceClasses of interest with the appName/subId key. * Starts async fetching data on streaming services of matching classes to be reported * later via {@link IMbmsStreamingManagerCallback#streamingServicesUpdated(List)} * * Note that subsequent calls with the same uid, appName and subId will replace * the service class list. * * @param appName The package name of the calling app. * @param subscriptionId The subscription id for eMBMS * @param serviceClasses The service classes that the app wishes to get info on. The strings * may contain arbitrary data as negotiated between the app and the * carrier. */ @Override public int getStreamingServices(String appName, int subscriptionId, List<String> serviceClasses) throws MbmsException { return 0; } @Override public StreamingService startStreaming(String appName, int subId,
security.checkWrite(name); } } */ if (name == null) { // Android-changed: different exception message in ctor when file == null. // throw new NullPointerException(); throw new NullPointerException("file == null"); } if (file.isInvalid()) { throw new FileNotFoundException("Invalid file path"); } this.path = name; this.mode = imode; // BEGIN Android-changed: Use IoBridge.open() instead of open. fd = IoBridge.open(name, imode); if (syncMetadata) { try { fd.sync(); } catch (IOException e) { // Ignored } } guard.open("close"); // END Android-changed: Use IoBridge.open() instead of open. } /** * Returns the opaque file descriptor object associated with this * stream. * * @return the file descriptor object associated with this stream. * @exception IOException if an I/O error occurs. * @see java.io.FileDescriptor */
if (VDBG) Log.d(TAG, "Tether Mode requested by " + who); handleInterfaceServingStateActive(message.arg1, who); who.sendMessage(TetherInterfaceStateMachine.CMD_TETHER_CONNECTION_CHANGED, mCurrentUpstreamIface); // If there has been a change and an upstream is now // desired, kick off the selection process. final boolean previousUpstreamWanted = updateUpstreamWanted(); if (!previousUpstreamWanted && mUpstreamWanted) { chooseUpstreamType(true); } break; } case CMD_TETHER_MODE_UNREQUESTED: { TetherInterfaceStateMachine who = (TetherInterfaceStateMachine)message.obj; if (VDBG) Log.d(TAG, "Tether Mode unrequested by " + who); handleInterfaceServingStateInactive(who); if (mNotifyList.isEmpty()) { turnOffMasterTetherSettings(); // transitions appropriately } else { if (DBG) { Log.d(TAG, "TetherModeAlive still has " + mNotifyList.size() + " live requests:"); for (TetherInterfaceStateMachine o : mNotifyList) {
// /// CHECK-START: int Main.getSum21() instruction_simplifier$after_bce (after) /// CHECK-DAG: <<Int:i\d+>> IntConstant 21 loop:none /// CHECK-DAG: Return [<<Int>>] loop:none private static int getSum21() { int k = 0; int sum = 0; for (int i = 0; i < 6; i++) { k++; sum += k; } return sum; } // Ensure double induction does not "overshoot" the subscript range. private static int getIncr2(int[] arr) { for (int i = 0; i < 12; ) { arr[i++] = 30; arr[i++] = 29; } int sum = 0; for (int i = 0; i < 12; i++) { sum += arr[i]; } return sum; } // TODO: handle as closed/empty eventually? static int mainIndexReturnedN(int n) { int i; for (i = 0; i < n; i++); return i; }
// To account correctly for on-the-wire traffic, add the 20 additional bytes difference // for all packets (http://b/12249687, http:/b/33681750). for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry); if (entry.iface == null || !entry.iface.startsWith(CLATD_INTERFACE_PREFIX)) { continue; } entry.rxBytes = entry.rxPackets * IPV4V6_HEADER_DELTA; entry.txBytes = entry.txPackets * IPV4V6_HEADER_DELTA; entry.rxPackets = 0; entry.txPackets = 0; stats.combineValues(entry); } return stats; } private NetworkStats readNetworkStatsDetailInternal(int limitUid, String[] limitIfaces, int limitTag, NetworkStats lastStats) throws IOException { if (USE_NATIVE_PARSING) { final NetworkStats stats; if (lastStats != null) { stats = lastStats; stats.setElapsedRealtime(SystemClock.elapsedRealtime()); } else {
// base interface. For correct stats accounting on the base interface, every 464xlat // packets needs to be subtracted for the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); if (!stackedIface.startsWith(CLATD_INTERFACE_PREFIX)) { continue; } NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) { adjust.rxBytes -= (entry.rxBytes + entry.rxPackets * IPV4V6_HEADER_DELTA); adjust.txBytes -= (entry.txBytes + entry.txPackets * IPV4V6_HEADER_DELTA); adjust.rxPackets -= entry.rxPackets; adjust.txPackets -= entry.txPackets;
assertStatsEntry(stats, "lo", 0, SET_DEFAULT, 0x0, 1288L, 1288L); NetworkStatsFactory.noteStackedIface("v4-wlan0", null); } public void testDoubleClatAccounting100MBDownload() throws Exception { // Downloading 100mb from an ipv4 only destination in a foreground activity long appRxBytesBefore = 328684029L; long appRxBytesAfter = 439237478L; assertEquals("App traffic should be ~100MB", 110553449, appRxBytesAfter - appRxBytesBefore); long rootRxBytesBefore = 1394011L; long rootRxBytesAfter = 1398634L; assertEquals("Root traffic should be ~0", 4623, rootRxBytesAfter - rootRxBytesBefore); NetworkStatsFactory.noteStackedIface("v4-wlan0", "wlan0"); NetworkStats stats; // Stats snapshot before the download stats = parseDetailedStats(R.raw.xt_qtaguid_with_clat_100mb_download_before); assertStatsEntry(stats, "v4-wlan0", 10106, SET_FOREGROUND, 0x0, appRxBytesBefore, 5199872L); assertStatsEntry(stats, "wlan0", 0, SET_DEFAULT, 0x0, rootRxBytesBefore, 647888L);
} public void testDoubleClatAccounting100MBDownload() throws Exception { // Downloading 100mb from an ipv4 only destination in a foreground activity long appRxBytesBefore = 328684029L; long appRxBytesAfter = 439237478L; assertEquals("App traffix should be ~100MB", 110553449, appRxBytesAfter - appRxBytesBefore); long rootRxBytesBefore = 1394011L; long rootRxBytesAfter = 1398634L; assertEquals("UID 0 traffic should be ~0", 4623, rootRxBytesAfter - rootRxBytesBefore); NetworkStatsFactory.noteStackedIface("v4-wlan0", "wlan0"); NetworkStats stats; // Stats snapshot before the download stats = parseDetailedStats(R.raw.xt_qtaguid_with_clat_100mb_download_before); assertStatsEntry(stats, "v4-wlan0", 10106, SET_FOREGROUND, 0x0, appRxBytesBefore, 5199872L); assertStatsEntry(stats, "wlan0", 0, SET_DEFAULT, 0x0, rootRxBytesBefore, 647888L); // Stats snapshot after the download stats = parseDetailedStats(R.raw.xt_qtaguid_with_clat_100mb_download_after);
public void onConnected() { Log.d(TAG, "BrowsablePlayerListBuilder: " + mCurrentPlayer.packageName + " OK"); mCurrentBrowser.disconnect(); mCurrentBrowser = null; mBrowsePlayerInfoList.add(mCurrentPlayer); MediaPlayerInfo info = getMediaPlayerInfo(mCurrentPlayer.packageName); MediaController controller = (info == null) ? null : info.getMediaController(); // Refresh the media player entry so it notices we can browse if (controller != null) { addMediaPlayerController(controller.getWrappedInstance()); } else { addMediaPlayerPackage(mCurrentPlayer.packageName); } mPlayersChanged = true; connectNextPlayer();
} shr32(); for (int i = 0; i < 128; i++) { expectEquals(0x3fffffff, a[i], "shr32"); } shr33(); for (int i = 0; i < 128; i++) { expectEquals(0x1fffffff, a[i], "shr33"); } shrMinus254(); for (int i = 0; i < 128; i++) { expectEquals(0x07ffffff, a[i], "shrMinus254"); } // Bit-wise not operator. not(); for (int i = 0; i < 128; i++) { expectEquals(0xf8000000, a[i], "not"); } // Done. System.out.println("passed");
} shr64(); for (int i = 0; i < 128; i++) { expectEquals(0x3fffffffffffffffL, a[i], "shr64"); } shr65(); for (int i = 0; i < 128; i++) { expectEquals(0x1fffffffffffffffL, a[i], "shr65"); } shrMinus254(); for (int i = 0; i < 128; i++) { expectEquals(0x07ffffffffffffffL, a[i], "shrMinus254"); } // Bit-wise not operator. not(); for (int i = 0; i < 128; i++) { expectEquals(0xf800000000000000L, a[i], "not"); } // Done. System.out.println("passed");
*/ @SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION) public static final String ACTION_REPORT = "android.bluetooth.input.profile.action.REPORT"; /** * @hide */ @SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION) public static final String ACTION_VIRTUAL_UNPLUG_STATUS = "android.bluetooth.input.profile.action.VIRTUAL_UNPLUG_STATUS"; /** * @hide */ @SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION) public static final String ACTION_IDLE_TIME_CHANGED = "android.bluetooth.input.profile.action.IDLE_TIME_CHANGED"; /** * Return codes for the connect and disconnect Bluez / Dbus calls. * @hide */ public static final int INPUT_DISCONNECT_FAILED_NOT_CONNECTED = 5000; /** * @hide */ public static final int INPUT_CONNECT_FAILED_ALREADY_CONNECTED = 5001; /** * @hide */ public static final int INPUT_CONNECT_FAILED_ATTEMPT_FAILED = 5002; /** * @hide */ public static final int INPUT_OPERATION_GENERIC_FAILURE = 5003; /** * @hide */
/** * @hide */ public static final String EXTRA_REPORT = "android.bluetooth.BluetoothInputDevice.extra.REPORT"; /** * @hide */ public static final String EXTRA_STATUS = "android.bluetooth.BluetoothInputDevice.extra.STATUS"; /** * @hide */ public static final String EXTRA_VIRTUAL_UNPLUG_STATUS = "android.bluetooth.BluetoothInputDevice.extra.VIRTUAL_UNPLUG_STATUS"; /** * @hide */ public static final String EXTRA_IDLE_TIME = "android.bluetooth.BluetoothInputDevice.extra.IDLE_TIME"; private Context mContext; private ServiceListener mServiceListener; private BluetoothAdapter mAdapter; private IBluetoothInputDevice mService; final private IBluetoothStateChangeCallback mBluetoothStateChangeCallback = new IBluetoothStateChangeCallback.Stub() { public void onBluetoothStateChange(boolean up) { if (DBG) Log.d(TAG, "onBluetoothStateChange: up=" + up); if (!up) { if (VDBG) Log.d(TAG,"Unbinding service..."); synchronized (mConnection) { try { mService = null; mContext.unbindService(mConnection);
*/ public boolean getEmergencyCallbackMode(int subId) { try { ITelephony telephony = getITelephony(); if (telephony == null) { return false; } return telephony.getEmergencyCallbackMode(subId); } catch (RemoteException e) { Log.e(TAG, "Error calling ITelephony#getEmergencyCallbackMode", e); } return false; } /** * Get the most recently available signal strength information. * * Get the most recent SignalStrength information reported by the modem. Due * to power saving this information may not always be current. * @return the most recent cached signal strength info from the modem * @hide */ @Nullable public SignalStrength getSignalStrength() { try { ITelephony service = getITelephony(); if (service != null) { return service.getSignalStrength(getSubId(), getOpPackageName()); } } catch (RemoteException e) {
* class. The testcase checks that no any unexpected ERROR is returned and that * the JSR45 metadata matches the expected value. */ public void testSourceDebugExtension001() { doTest("testSourceDebugExtension001", "Lorg/apache/harmony/jpda/tests/jdwp/Events/SourceDebugExtensionMockClass;", JDWPConstants.Error.NONE); } /** * This testcase exercises ReferenceType.SourceDebugExtension command. * * The class queried is a primitive type which on ART does not * have an associated DEX cache. */ public void testSourceDebugExtension002() { doTest("testSourceDebugExtension001", "I", JDWPConstants.Error.ABSENT_INFORMATION); } /** * This testcase exercises ReferenceType.SourceDebugExtension command. * * The class queried is a primitive array which on ART does not * have a DEX cache installed. */ public void testSourceDebugExtension003() { doTest("testSourceDebugExtension003", "[I", JDWPConstants.Error.ABSENT_INFORMATION); } /** * This testcase exercises ReferenceType.SourceDebugExtension command. *
* the server name from the certificate mismatch. */ defaultHostnameVerifier = (HostnameVerifier) Class.forName("com.android.okhttp.internal.tls.OkHostnameVerifier") .getField("INSTANCE").get(null); originalDefaultHostnameVerifierClass = defaultHostnameVerifier.getClass(); } catch (Exception e) { throw new AssertionError("Failed to obtain okhttp HostnameVerifier", e); } } } /** * The <code>hostnameVerifier</code> for this object. */ protected HostnameVerifier hostnameVerifier; // END Android-changed: Use lazily-created OkHttp hostname verifier /** * Sets the default <code>HostnameVerifier</code> inherited by a * new instance of this class. * <P> * If this method is not called, the default * <code>HostnameVerifier</code> assumes the connection should not * be permitted. * * @param v the default host name verifier * @throws IllegalArgumentException if the <code>HostnameVerifier</code> * parameter is null. * @throws SecurityException if a security manager exists and its * <code>checkPermission</code> method does not allow
// missing server, so no trusted time available return false; } // We can't do this at initialization time: ConnectivityService might not be running yet. synchronized (this) { if (mCM == null) { mCM = (ConnectivityManager) sContext.getSystemService(Context.CONNECTIVITY_SERVICE); } } final NetworkInfo ni = mCM == null ? null : mCM.getActiveNetworkInfo(); if (ni == null || !ni.isConnected()) { if (LOGD) Log.d(TAG, "forceRefresh: no connectivity"); return false; } if (LOGD) Log.d(TAG, "forceRefresh() from cache miss"); final SntpClient client = new SntpClient(); if (client.requestTime(mServer, (int) mTimeout)) { mHasCache = true; mCachedNtpTime = client.getNtpTime(); mCachedNtpElapsedRealtime = client.getNtpTimeReference(); mCachedNtpCertainty = client.getRoundTripTime() / 2; return true; } else { return false; }
private void onPollNetworkTime(int event) { // If Automatic time is not set, don't bother. final NetworkInfo netInfo = mConnManager == null ? null : mConnManager.getActiveNetworkInfo(); if (!isAutomaticTimeRequested() || (netInfo != null && !netInfo.isConnected())) return; mWakeLock.acquire(); try { onPollNetworkTimeUnderWakeLock(event); } finally { mWakeLock.release(); }
private void onPollNetworkTime(int event) { // If Automatic time is not set, don't bother. final NetworkInfo netInfo = mConnManager == null ? null : mConnManager.getActiveNetworkInfo(); if (!isAutomaticTimeRequested() || (netInfo != null && !netInfo.isConnected())) return; mWakeLock.acquire(); try { onPollNetworkTimeUnderWakeLock(event); } finally { mWakeLock.release(); }
* * You should have received a copy of the GNU General Public License version * 2 along with this work; if not, write to the Free Software Foundation, * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA. * * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA * or visit www.oracle.com if you need additional information or have any * questions. */ package javax.security.auth; // Android-changed: We don't implement this permission system on Android. /** * Legacy security code; do not use. */ public final class AuthPermission extends java.security.BasicPermission { public AuthPermission(String name) { super(""); } public AuthPermission(String name, String actions) { super("", ""); } }
public NetworkTimeUpdateService(Context context) { mContext = context; mTime = NtpTrustedTime.getInstance(context); mAlarmManager = (AlarmManager) mContext.getSystemService(Context.ALARM_SERVICE); mCM = (ConnectivityManager) mContext.getSystemService(Context.CONNECTIVITY_SERVICE); Intent pollIntent = new Intent(ACTION_POLL, null); mPendingPollIntent = PendingIntent.getBroadcast(mContext, POLL_REQUEST, pollIntent, 0); mPollingIntervalMs = mContext.getResources().getInteger( com.android.internal.R.integer.config_ntpPollingInterval); mPollingIntervalShorterMs = mContext.getResources().getInteger( com.android.internal.R.integer.config_ntpPollingIntervalShorter); mTryAgainTimesMax = mContext.getResources().getInteger( com.android.internal.R.integer.config_ntpRetry); mTimeErrorThresholdMs = mContext.getResources().getInteger( com.android.internal.R.integer.config_ntpThreshold); mWakeLock = ((PowerManager) context.getSystemService(Context.POWER_SERVICE)).newWakeLock( PowerManager.PARTIAL_WAKE_LOCK, TAG);
} } }; /** Handler to do the network accesses on */ private class MyHandler extends Handler { public MyHandler(Looper l) { super(l); } @Override public void handleMessage(Message msg) { switch (msg.what) { case EVENT_AUTO_TIME_CHANGED: case EVENT_POLL_NETWORK_TIME: case EVENT_NETWORK_CHANGED: onPollNetworkTime(msg.what); break; } } } private class NetworkTimeUpdateCallback extends ConnectivityManager.NetworkCallback { @Override public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { if (networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED)){ mNetworkValidated = true; }else { mNetworkValidated = false; } } } /** Observer to watch for changes to the AUTO_TIME setting */ private static class SettingsObserver extends ContentObserver { private int mMsg; private Handler mHandler; SettingsObserver(Handler handler, int msg) { super(handler); mHandler = handler; mMsg = msg; } void observe(Context context) {
} } }; /** Handler to do the network accesses on */ private class MyHandler extends Handler { public MyHandler(Looper l) { super(l); } @Override public void handleMessage(Message msg) { switch (msg.what) { case EVENT_AUTO_TIME_CHANGED: case EVENT_POLL_NETWORK_TIME: case EVENT_NETWORK_CHANGED: onPollNetworkTime(msg.what); break; } } } private class NetworkTimeUpdateCallback extends ConnectivityManager.NetworkCallback { @Override public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { if (networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED)){ mNetworkValidated = true; }else { mNetworkValidated = false; } } } /** Observer to watch for changes to the AUTO_TIME setting */ private static class SettingsObserver extends ContentObserver { private int mMsg; private Handler mHandler; SettingsObserver(Handler handler, int msg) { super(handler); mHandler = handler; mMsg = msg; } void observe(Context context) {
public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { if (networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED)){ mNetworkValidated = true; }else { mNetworkValidated = false; } } @Override public void onLost(Network network) { mNetworkValidated = false; }
private void onPollNetworkTime(int event) { // If Automatic time is not set, don't bother. final NetworkInfo netInfo = mConnManager == null ? null : mConnManager.getActiveNetworkInfo(); if (!isAutomaticTimeRequested() || netInfo == null || !netInfo.isConnected()) return; mWakeLock.acquire(); try { onPollNetworkTimeUnderWakeLock(event); } finally { mWakeLock.release(); }
return; case INS_GET_LOCK: /* getLock(lockId, sendMetadata) */ resp = sendLockData(apdu, p1, p2); if (resp != 0) { sendResponseCode(apdu, resp); } return; case INS_SET_LOCK: /* setlock(index, val) { data } */ if (p1 >= (byte)locks.length) { sendResponseCode(apdu, (short)0x0100); return; } // useMetadata argument byte is required. if (numBytes != 1) { sendResponseCode(apdu, (short)0x0200); return; } resp = locks[p1].setWithMetadata(p2, metadata, (short) 0, metadataLength); // "Consume" the metadata. metadataLength = (short)0; sendResponseCode(apdu, resp); return; case INS_SET_PRODUCTION: /* setProduction(p1) */ if (globalState.setProduction(enable) == true) { resp = 0x0000; } else { resp = 0x0001; } sendResponseCode(apdu, resp); return; /* carrierLockTest() { testVector } */
import android.widget.TextView; import java.io.IOException; import java.net.HttpURLConnection; import java.net.MalformedURLException; import java.net.URL; import java.lang.InterruptedException; import java.lang.reflect.Field; import java.lang.reflect.Method; import java.util.Random; public class CaptivePortalLoginActivity extends Activity { private static final String TAG = CaptivePortalLoginActivity.class.getSimpleName(); private static final boolean DBG = true; private static final int SOCKET_TIMEOUT_MS = 10000; private enum Result { DISMISSED, UNWANTED, WANTED_AS_IS }; private URL mUrl; private String mUserAgent; private Network mNetwork; private CaptivePortal mCaptivePortal; private NetworkCallback mNetworkCallback; private ConnectivityManager mCm; private boolean mLaunchBrowser = false; private MyWebViewClient mWebViewClient; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); mCm = ConnectivityManager.from(this);
private void testForCaptivePortal() { // TODO: reuse NetworkMonitor facilities for consistent captive portal detection. new Thread(new Runnable() { public void run() { // Give time for captive portal to open. try { Thread.sleep(1000); } catch (InterruptedException e) { } HttpURLConnection urlConnection = null; int httpResponseCode = 500; try { urlConnection = (HttpURLConnection) mNetwork.openConnection(mUrl); urlConnection.setInstanceFollowRedirects(false); urlConnection.setConnectTimeout(SOCKET_TIMEOUT_MS); urlConnection.setReadTimeout(SOCKET_TIMEOUT_MS); urlConnection.setUseCaches(false); if (mUserAgent != null) { urlConnection.setRequestProperty("User-Agent", mUserAgent); } // cannot read request header after connection String requestHeader = urlConnection.getRequestProperties().toString(); urlConnection.getInputStream(); httpResponseCode = urlConnection.getResponseCode(); if (DBG) { Log.d(TAG, "probe at " + mUrl +
public void systemRunning() { registerForTelephonyIntents(); registerForAlarms(); HandlerThread thread = new HandlerThread(TAG); thread.start(); mHandler = new MyHandler(thread.getLooper()); mNetworkTimeUpdateCallback = new NetworkTimeUpdateCallback(); mCM.registerDefaultNetworkCallback(mNetworkTimeUpdateCallback, mHandler); mSettingsObserver = new SettingsObserver(mHandler, EVENT_AUTO_TIME_CHANGED); mSettingsObserver.observe(mContext);
public void onCapabilitiesChanged(Network network, NetworkCapabilities netCap) { mNetworkValidated = netCap.hasCapability( NetworkCapabilities.NET_CAPABILITY_VALIDATED);
public void onCapabilitiesChanged(Network network, NetworkCapabilities netCap) { mNetworkValidated = netCap.hasCapability( NetworkCapabilities.NET_CAPABILITY_VALIDATED);
public void onCapabilitiesChanged(Network network, NetworkCapabilities netCap) { mNetworkValidated = netCap.hasCapability( NetworkCapabilities.NET_CAPABILITY_VALIDATED);
/// CHECK-DAG: <<Get2:b\d+>> ArrayGet loop:<<Loop>> outer_loop:none /// CHECK-DAG: <<Max:i\d+>> InvokeStaticOrDirect [<<Get1>>,<<Get2>>] intrinsic:MathMaxIntInt loop:<<Loop>> outer_loop:none /// CHECK-DAG: <<Cnv:b\d+>> TypeConversion [<<Max>>] loop:<<Loop>> outer_loop:none /// CHECK-DAG: ArraySet [{{l\d+}},<<Phi>>,<<Cnv>>] loop:<<Loop>> outer_loop:none // // TODO: narrow type vectorization. /// CHECK-START: void Main.doitMax(byte[], byte[], byte[]) loop_optimization (after) /// CHECK-NOT: VecMax private static void doitMax(byte[] x, byte[] y, byte[] z) { int min = Math.min(x.length, Math.min(y.length, z.length)); for (int i = 0; i < min; i++) { x[i] = (byte) Math.max(y[i], z[i]); } } public static void main(String[] args) { // Initialize cross-values for the interesting values. int total = 256 * 256; byte[] x = new byte[total];
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.telephony; import android.content.ComponentName; import android.content.Context; import android.content.Intent; import android.content.ServiceConnection; import android.content.pm.PackageManager; import android.content.pm.ResolveInfo; import android.os.DeadObjectException; import android.os.IBinder; import android.os.RemoteException; import android.telephony.mbms.MbmsException; import android.telephony.mbms.StreamingService; import android.telephony.mbms.StreamingServiceInfo; import android.telephony.mbms.vendor.IMbmsStreamingService; import android.util.Log; import java.util.LinkedList; import java.util.List; import java.util.concurrent.CountDownLatch; import java.util.concurrent.TimeUnit; import static android.telephony.SubscriptionManager.INVALID_SUBSCRIPTION_ID; /** @hide */ public class MbmsStreamingManager { private interface ServiceListener { void onServiceConnected(); void onServiceDisconnected(); } private static final String LOG_TAG = "MbmsStreamingManager";
* limitations under the License. */ package android.os; /** * Mimics the real Android class when running tests on host. This class is needed by the code * generated by Desugar to choose the runtime strategy of try-with-resource based on the android * runtime version. Set it to 17 to force to use the mimic desugaring strategy. */ public class Build { public static class VERSION { public static final int SDK_INT = 17; } }
* limitations under the License. */ package android.os; /** * Mimics the real Android class when running tests on host. This class is needed by the code * generated by Desugar to choose the runtime strategy of try-with-resource based on the android * runtime version. Set it to 17 to force to use the mimic desugaring strategy. */ public class Build { public static class VERSION { public static final int SDK_INT = 17; } }
import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.Random; import java.util.concurrent.CountDownLatch; import java.util.concurrent.Semaphore; import java.util.concurrent.TimeUnit; import static java.nio.charset.StandardCharsets.UTF_8; /** * Tests URLConnections for ftp:// URLs. */ public class FtpURLConnectionTest extends TestCase { private static final String FILE_PATH = "test/file/for/FtpURLConnectionTest.txt"; private static final String SERVER_HOSTNAME = "localhost"; private static final String USER_HOME_DIR = "/home/user"; private FakeFtpServer fakeFtpServer; private UnixFakeFileSystem fileSystem; @Override public void setUp() throws Exception { super.setUp(); fakeFtpServer = new FakeFtpServer(); fakeFtpServer.setServerControlPort(0 /* allocate port number automatically */); fakeFtpServer.addUserAccount(new UserAccount(USER, PASSWORD, USER_HOME_DIR)); fileSystem = new UnixFakeFileSystem(); fakeFtpServer.setFileSystem(fileSystem);
int total = interesting.length * interesting.length; short[] x = new short[total]; short[] y = new short[total]; short[] z = new short[total]; int k = 0; for (int i = 0; i < interesting.length; i++) { for (int j = 0; j < interesting.length; j++) { x[k] = 0; y[k] = interesting[i]; z[k] = interesting[j]; k++; } } // And test. doitMin(x, y, z); for (int i = 0; i < total; i++) { short expected = (short) Math.min(y[i], z[i]); expectEquals(expected, x[i]); } doitMax(x, y, z); for (int i = 0; i < total; i++) { short expected = (short) Math.max(y[i], z[i]); expectEquals(expected, x[i]); } System.out.println("passed");
private void recordAndEmit(Category category, String msg) { final String entry = logLine(category, msg); mLocalLog.log(entry); if (ERROR.equals(category)) { Log.e(mTag, entry); } else { Log.d(mTag, entry); }
import android.content.Context; import android.content.ContextWrapper; import android.content.res.Resources; import android.support.test.filters.SmallTest; import android.support.test.runner.AndroidJUnit4; import android.telephony.TelephonyManager; import com.android.internal.util.test.BroadcastInterceptingContext; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.MockitoAnnotations; @RunWith(AndroidJUnit4.class) @SmallTest public class TetheringConfigurationTest { @Mock private Context mContext; @Mock private TelephonyManager mTelephonyManager; @Mock private Resources mResources; private Context mMockContext; private boolean mWithTelephonyManager; private class MockContext extends BroadcastInterceptingContext { MockContext(Context base) { super(base); } @Override public Resources getResources() { return mResources; } @Override public Object getSystemService(String name) { if (Context.TELEPHONY_SERVICE.equals(name)) { return mWithTelephonyManager ? mTelephonyManager : null; } return super.getSystemService(name); } }
import android.telephony.TelephonyManager; import com.android.internal.util.test.BroadcastInterceptingContext; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.MockitoAnnotations; @RunWith(AndroidJUnit4.class) @SmallTest public class TetheringConfigurationTest { private static final String[] PROVISIONING_APP_NAME = {"some", "app"}; @Mock private Context mContext; @Mock private TelephonyManager mTelephonyManager; @Mock private Resources mResources; private Context mMockContext; private boolean mHasTelephonyManager; private class MockContext extends BroadcastInterceptingContext { MockContext(Context base) { super(base); } @Override public Resources getResources() { return mResources; } @Override public Object getSystemService(String name) { if (Context.TELEPHONY_SERVICE.equals(name)) { return mWithTelephonyManager ? mTelephonyManager : null; } return super.getSystemService(name); } } @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this);
* is only meant for debugging and is not guaranteed to be stable across * releases and/or devices. * * @hide */ public static native String getDexFileStatus(String fileName, String instructionSet) throws FileNotFoundException; /** * Returns the paths of the optimized files generated for {@code fileName}. * If no optimized code exists the method returns null. * @hide */ public static native String[] getDexFileOutputPath(String fileName, String instructionSet) throws FileNotFoundException; /** * Returns whether the given filter is a valid filter. * * @hide */ public native static boolean isValidCompilerFilter(String filter); /** * Returns whether the given filter is based on profiles. * * @hide */ public native static boolean isProfileGuidedCompilerFilter(String filter); /** * Returns the version of the compiler filter that is not based on profiles.
* releases and/or devices. * * @hide */ public static native String getDexFileStatus(String fileName, String instructionSet) throws FileNotFoundException; /** * Returns the full file path of the optimized dex file {@code fileName}. The returned string * is the full file name including path of optimized dex file, if it exists. * @hide */ public static native String[] getDexFileOutputPaths(String fileName, String instructionSet) throws FileNotFoundException; /** * Returns whether the given filter is a valid filter. * * @hide */ public native static boolean isValidCompilerFilter(String filter); /** * Returns whether the given filter is based on profiles. * * @hide */ public native static boolean isProfileGuidedCompilerFilter(String filter); /** * Returns the version of the compiler filter that is not based on profiles. * If the input is not a valid filter, or the filter is already not based on
// determine the ABI from either ApplicationInfo or Build String arch = "arm"; if (cameraInfo.primaryCpuAbi != null && VMRuntime.is64BitAbi(cameraInfo.primaryCpuAbi)) { arch = arch + "64"; } else { if (VMRuntime.is64BitAbi(Build.SUPPORTED_ABIS[0])) { arch = arch + "64"; } } // get the path to the odex or oat file String baseCodePath = cameraInfo.getBaseCodePath(); String[] optimizedCode = null; try { files = DexFile.getDexFileOutputPaths(baseCodePath, arch); } catch (IOException ioe) {} if (optimizedCode == null) { return true; } //not pinning the oat/odex is not a fatal error for (int i = 0; i < optimizedCode.length; i++) { pf = pinFile(optimizedCode[i], 0, 0, MAX_CAMERA_PIN_SIZE); if (pf != null) { mPinnedCameraFiles.add(pf); if (DEBUG) { Slog.i(TAG, "Pinned " + pf.mFilename); } }
String baseCodePath = cameraInfo.getBaseCodePath(); String[] optimizedCode = null; try { optimizedCode = DexFile.getDexFileOutputPath(baseCodePath, arch); } catch (IOException ioe) {} if (optimizedCode == null) { return true; } //not pinning the oat/odex is not a fatal error for (String file : files) { pf = pinFile(file, 0, 0, MAX_CAMERA_PIN_SIZE); if (pf != null) { mPinnedCameraFiles.add(pf); if (DEBUG) { Slog.i(TAG, "Pinned " + pf.mFilename); } } } return true;
String baseCodePath = cameraInfo.getBaseCodePath(); String[] optimizedCode = null; try { optimizedCode = DexFile.getDexFileOutputPath(baseCodePath, arch); } catch (IOException ioe) {} if (optimizedCode == null) { return true; } //not pinning the oat/odex is not a fatal error for (String file : files) { pf = pinFile(file, 0, 0, MAX_CAMERA_PIN_SIZE); if (pf != null) { mPinnedCameraFiles.add(pf); if (DEBUG) { Slog.i(TAG, "Pinned " + pf.mFilename); } } } return true;
packageIntentFilter.addAction(Intent.ACTION_PACKAGE_REMOVED); packageIntentFilter.addAction(Intent.ACTION_PACKAGE_ADDED); packageIntentFilter.addDataScheme("package"); context.registerReceiverAsUser(mReceiver, UserHandle.ALL, packageIntentFilter, null, null); IntentFilter bootIntentFilter = new IntentFilter(Intent.ACTION_BOOT_COMPLETED); context.registerReceiverAsUser(mReceiver, UserHandle.ALL, bootIntentFilter, null, null); IntentFilter userRemovedFilter = new IntentFilter(Intent.ACTION_USER_REMOVED); context.registerReceiver(mReceiver, userRemovedFilter); Uri defaultDialerSetting = Settings.Secure.getUriFor(Settings.Secure.DIALER_DEFAULT_APPLICATION); context.getContentResolver() .registerContentObserver(defaultDialerSetting, false, mDefaultDialerObserver, UserHandle.USER_ALL);
public IPv6TetheringCoordinator(ArrayList<TetherInterfaceStateMachine> notifyList) { mNotifyList = notifyList; mActiveDownstreams = new LinkedList<>(); mUniqueLocalPrefix = generateUniqueLocalPrefix(); mNextSubnetId = 0;
public void e(String msg) { Log.e(mTag, record(Category.ERROR, msg));
} public void dump(FileDescriptor fd, PrintWriter writer, String[] args) { mLocalLog.readOnlyLocalLog().dump(fd, writer, args); } public void error(Exception e) { recordAndEmit(Category.ERROR, e.toString()); } public void error(String msg) { recordAndEmit(Category.ERROR, msg); } public void event(String msg) { record(Category.EVENT, msg); } public void log(String msg) { record(Category.NONE, msg); } public void mark(String msg) { record(Category.MARK, msg); } private void record(Category category, String msg) { mLocalLog.log(logLine(category, msg)); } private void recordAndEmit(Category category, String msg) { final String entry = logLine(category, msg); mLocalLog.log(entry); if (Category.ERROR.equals(category)) { Log.e(mTag, entry); } else { Log.d(mTag, entry); } }
phoneAccountHandle = extras.getParcelable( TelecomManager.EXTRA_PHONE_ACCOUNT_HANDLE); } boolean isSelfManaged = phoneAccountHandle != null && isSelfManagedConnectionService(phoneAccountHandle); if (isSelfManaged) { mContext.enforceCallingOrSelfPermission(Manifest.permission.MANAGE_OWN_CALLS, "Self-managed ConnectionServices require MANAGE_OWN_CALLS permission."); if (!callingPackage.equals( phoneAccountHandle.getComponentName().getPackageName()) && !canCallPhone(callingPackage, "CALL_PHONE permission required to place calls.")) { // The caller is not allowed to place calls, so we want to ensure that it // can only place calls through itself. throw new SecurityException("Self-managed ConnectionServices can only " + "place calls through their own ConnectionService."); } } else if (!canCallPhone(callingPackage, "placeCall")) { throw new SecurityException("Package " + callingPackage + " is not allowed to place phone calls"); } // Note: we can still get here for the default/system dialer, even if the Phone
private String logLine(Category category, String msg) { final StringJoiner sj = new StringJoiner(" "); if (!isRootLogInstance()) sj.add("[" + mComponent + "]"); if (category != Category.NONE) sj.add(category.toString()); return sj.add(msg).toString();
* is used for accessing the key store and trust store for TLS * certificates. * * @param target The base URL for the server to be accessed. * @param conf The configuration for certificates and credentials. * @param mapper The object mapper. * @param loader The resource loader. */ public GatewayClient(String target, ClientConfig conf, ObjectMapper mapper, ResourceLoader loader) { super(target, conf, mapper, loader); } /** * Verify connectivity between the local gateway server and the remote * federation server. * * @param peerId The ID of the peer Acumos. * @return Information about the peer. */ public MLPPeer ping(String peerId) { return handleResponse(PEER_PFX + FederationClient.PING_URI, new ParameterizedTypeReference<JsonResponse<MLPPeer>>(){}, peerId); } /** * Ask the peer about its peers. * * @param peerId The ID of the peer Acumos. * @return The list of the peer's peers. */ public List<MLPPeer> getPeers(String peerId) {
} /** * Ask the peer about its peers. * * @param peerId The ID of the peer Acumos. * @return The list of the peer's peers. */ public List<MLPPeer> getPeers(String peerId) { return handleResponse(PEER_PFX + FederationClient.PEERS_URI, new ParameterizedTypeReference<JsonResponse<List<MLPPeer>>>(){}, peerId); } /** * Ask the remote federation server to * add the local server to its list of peers. * * @param peerId The ID of the peer Acumos. * @return Information about the peer. */ public MLPPeer register(String peerId) { return handleResponse(PEER_PFX + FederationClient.REGISTER_URI, HttpMethod.POST, new ParameterizedTypeReference<JsonResponse<MLPPeer>>(){}, peerId); } /** * Ask the peer for a list of catalogs. * * @param peerId The ID of the peer Acumos. * @return The list of catalogs (enhanced with their sizes), the peer is willing to share. */ public List<MLPCatalog> getCatalogs(String peerId) {
* * Configuration classes are also Conponents so they are subject to Component scanning. */ @SpringBootApplication @EnableAutoConfiguration(exclude = { DataSourceAutoConfiguration.class, DataSourceTransactionManagerAutoConfiguration.class, HibernateJpaAutoConfiguration.class }) @EnableConfigurationProperties @ComponentScan(basePackages = "org.acumos.federation", useDefaultFilters = false, includeFilters = @ComponentScan.Filter(type=FilterType.ASSIGNABLE_TYPE, classes={org.acumos.federation.gateway.config.GatewayConfiguration.class, org.acumos.federation.gateway.config.AdapterConfiguration.class})) public class Application { private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); private final static EELFLoggerDelegate logger = EELFLoggerDelegate.getLogger(Application.class); /** * We should be able to swap the LocalConfiguration in the case of adapters. */ public static void main(String[] args) throws Exception { SpringApplicationBuilder gatewayBuilder = new SpringApplicationBuilder(Application.class) .bannerMode(Banner.Mode.OFF) .web(false); gatewayBuilder.child(FederationConfiguration.class) .bannerMode(Banner.Mode.OFF) .web(true) .run(args); gatewayBuilder.child(LocalConfiguration.class)
public MLPSolution createSolution(MLPSolution solution) { return clients.getCDSClient().createSolution(solution);
import com.github.dockerjava.api.DockerClient; import com.github.dockerjava.core.DefaultDockerClientConfig; import com.github.dockerjava.core.DockerClientBuilder; import org.acumos.cds.client.ICommonDataServiceRestClient; import org.acumos.cds.client.CommonDataServiceRestClientImpl; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.ClientBase; import org.acumos.federation.client.FederationClient; /** * Defines all beans used to access outside services. * * By mocking this bean, all external access can be stubbed out. */ public class Clients { @Autowired private FederationConfig federation; @Autowired private ServiceConfig cdmsConfig; @Autowired private NexusConfig nexusConfig; @Autowired private DockerConfig dockerConfig; private ICommonDataServiceRestClient cdsClient; private NexusClient nexusClient; private DockerClient dockerClient; public FederationClient getFederationClient(String url) { return new FederationClient(url, federation); } public synchronized ICommonDataServiceRestClient getCDSClient() { if (cdsClient == null) { String url = cdmsConfig.getUrl(); ClientConfig cc = new ClientConfig(); cc.setCreds(cdmsConfig);
public InputStream getArtifactContent(MLPArtifact artifact); /** * Set the URI for an artifact. * * @param solutionId The ID of the solution. * @param artifact The artifact to set the URI on. */ public void setArtifactUri(String solutionId, MLPArtifact artifact); /** * Put the content of an artifact. * * @param artifact The artifact to put. * @param tag The image tag in the input data. * @param is The data to put. Implementations must close the input stream. */ public void putArtifactContent(MLPArtifact artifact, String tag, InputStream is); /** * Get the body of a document. * * @param document The document to retrieve. * @return An InputStream for reading the document's content. */ public InputStream getDocumentContent(MLPDocument document); /** * Set the URI for an document. * * @param solutionId The ID of the solution. * @param document The document to set the URI on. */
*/ public InputStream getDocumentContent(MLPDocument document); /** * Set the URI for an document. * * @param solutionId The ID of the solution. * @param document The document to set the URI on. */ public void setDocumentUri(String solutionId, MLPDocument document); /** * Put the content of a document. * * @param document The document to put. * @param is The data to put. Implementations must close the input stream. */ public void putDocumentContent(MLPDocument document, InputStream is); }
import org.acumos.cds.domain.MLPSolutionRevision; import org.acumos.cds.domain.MLPArtifact; import org.acumos.cds.domain.MLPDocument; import org.acumos.federation.client.ClientBase; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.data.Artifact; import org.acumos.federation.client.data.Document; import org.acumos.federation.client.data.JsonResponse; import org.acumos.federation.client.data.SolutionRevision; /** * Controller bean for the external (public) API. */ @Controller @CrossOrigin public class FederationController { private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private FederationConfig federation; @Autowired private WebSecurityConfigurerAdapter security; @Autowired private PeerService peerService; @Autowired private CatalogService catalogService; @Autowired private ContentService contentService; private UriTemplateHandler originBuilder; private String makeOrigin(String uri, Object... params) { if (originBuilder == null) {
import org.acumos.cds.domain.MLPDocument; import org.acumos.federation.client.ClientBase; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.data.Artifact; import org.acumos.federation.client.data.Document; import org.acumos.federation.client.data.JsonResponse; import org.acumos.federation.client.data.SolutionRevision; /** * Controller bean for the external (public) API. */ @Controller @CrossOrigin public class FederationController { private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private FederationConfig federation; @Autowired private WebSecurityConfigurerAdapter security; @Autowired private PeerService peerService; @Autowired private CatalogService catalogService; @Autowired private ContentService contentService; private UriTemplateHandler originBuilder; private String makeOrigin(String uri, Object... params) { if (originBuilder == null) { originBuilder = ClientBase.buildRestTemplate("https://" + ((Security)security).getSelf().getSubjectName() + ":" + federation.getServer().getPort(), new ClientConfig(), null, null).getUriTemplateHandler(); }
public JsonResponse<Void> badRequestError(HttpServletRequest request, HttpServletResponse response, BadRequestException badRequest) { log.warn("Rejecting invalid request {}: {} {} {}", request.getRequestURI(), badRequest.getMessage(), badRequest.getCode(), badRequest); JsonResponse<Void> ret = new JsonResponse<>(); ret.setError(badRequest.getMessage()); response.setStatus(badRequest.getCode()); return ret;
import org.acumos.cds.domain.MLPCatalog; import org.acumos.cds.domain.MLPSolution; import org.acumos.cds.domain.MLPPeer; import org.acumos.cds.domain.MLPPeerSubscription; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.GatewayClient; import org.acumos.federation.client.data.JsonResponse; /** * Controller bean for the internal (gateway) API. */ @Controller @CrossOrigin @Secured(Security.ROLE_INTERNAL) @RequestMapping(GatewayClient.PEER_PFX) public class GatewayController { private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private Clients clients; @Autowired private PeerService peerService; @Autowired private PeerGateway peerGateway; @ApiOperation(value = "Invoked by local Acumos to get a list of catalogs available from a peer Acumos instance .", response = MLPCatalog.class, responseContainer = "List") @RequestMapping(value = FederationClient.CATALOGS_URI, method = RequestMethod.GET, produces = MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseBody public JsonResponse<List<MLPCatalog>> getCatalogs( HttpServletResponse response, @PathVariable("peerId") String peerId) {
import org.springframework.security.config.http.SessionCreationPolicy; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.userdetails.User; import org.acumos.cds.domain.MLPPeer; import org.acumos.federation.client.config.TlsConfig; import org.acumos.federation.client.FederationClient; /** * Service bean implementing authentication and peer identification services * on requests to the Federation Gateway. */ @Configuration @EnableWebSecurity public class Security extends WebSecurityConfigurerAdapter { private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); /** * The role indicating a peer is allowed to register. */ public static final String ROLE_REGISTER = "ROLE_REGISTRATION"; /** * The role indicating a peer is allowed to cancel their registration. */ public static final String ROLE_UNREGISTER = "ROLE_UNREGISTRATION"; /** * The role indicating a peer has normal access to the gateway. */ public static final String ROLE_PEER = "ROLE_PEER"; /** * The role indicating a peer has trusted access to the gateway. */
if (alias == null) { Enumeration<String> aliases = ks.aliases(); while (aliases.hasMoreElements()) { alias = aliases.nextElement(); if (ks.entryInstanceOf(alias, KeyStore.PrivateKeyEntry.class)) { break; } } } myself = peerService.getSelf(getLdapNameField(new LdapName(((X509Certificate)ks.getCertificate(alias)).getSubjectX500Principal().getName()), "CN")); } } catch (Exception e) { myself = new MLPPeer(); myself.setStatusCode(PSC_UNKNOWN); log.error("Cannot determine 'self' peer", e); }
logger.debug("JWTAuthorizationFilter() begin"); this.secretKey = secretKey; this.userService = new UserService(cdsClient); logger.debug("JWTAuthorizationFilter() end"); } /** * Method is called internally and should not be accessible directly using class instance. * */ @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException { logger.debug("doFilterInternal() begin"); HttpServletRequest httpRequest = request; String authToken = null; authToken = httpRequest.getHeader(AUTHORIZATION_HEADER_KEY); logger.debug("AUTHORIZATION_HEADER_KEY : " + authToken); if (authToken == null) { authToken = httpRequest.getHeader(JWT_TOKEN_HEADER_KEY); logger.debug("JWT_TOKEN_HEADER_KEY : " + authToken); } if (authToken == null) { authToken = request.getParameter(JWT_TOKEN_HEADER_KEY); logger.debug("JWT_TOKEN_HEADER_KEY : " + authToken); } if (authToken != null) {
logger.debug("JWT_TOKEN_HEADER_KEY : " + authToken); } if (authToken != null) { authToken = authToken.replace(TOKEN_PASS_KEY, ""); logger.debug("TOKEN_PASS_KEY : " + authToken); JWTTokenVO jwtTokenVO = JwtTokenUtil.getUserToken(authToken, secretKey); if (jwtTokenVO != null && !(SecurityContextHolder.getContext().getAuthentication() instanceof AnonymousAuthenticationToken) && validateToken(jwtTokenVO, secretKey)) { //validate token MLPUser mlpUser = userService.findUserByUsername(jwtTokenVO.getUserName()); //TODO : Need to implement role base authority UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken( new AuthenticatedUser(mlpUser), authToken, new ArrayList<>()); authentication.setDetails(new WebAuthenticationDetailsSource() .buildDetails(httpRequest)); SecurityContextHolder.getContext().setAuthentication(authentication); } } } chain.doFilter(request, response); logger.debug("doFilterInternal() End"); } private boolean validateToken(JWTTokenVO jwtTokenVO, String secretKey) { logger.debug("validateToken() Begin");
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.federation.client; import java.util.List; import org.acumos.cds.domain.MLPCatalog; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.config.TlsConfig; import org.acumos.federation.client.data.Catalog; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.GatewayClient; /** * Demonstrates use of the Federation (public "E5" interface) and * Gateway (private internal interface) clients. */ public class ClientDemo { private static final String peerApiUrl = "https://public.otheracumos.org:9084"; private static final String internalApiUrl = "https://federation-service:9011"; private static final String keystore = "keystore.jks"; private static final String keystorepass = "keystore_pass"; private static final String firstpeerid = "12345678-1234-1234-1234-1234567890ab"; private static final String secondpeerid = "cafebebe-cafe-bebe-cafe-bebecafebebe"; public static void main(String[] args) throws Exception { ClientConfig cconf = new ClientConfig();
private static final String keystorepass = "keystore_pass"; private static final String firstpeerid = "12345678-1234-1234-1234-1234567890ab"; private static final String secondpeerid = "cafebebe-cafe-bebe-cafe-bebecafebebe"; public static void main(String[] args) throws Exception { ClientConfig cconf = new ClientConfig(); cconf.setSsl(new TlsConfig()); cconf.getSsl().setKeyStore(keystore); cconf.getSsl().setKeyStorePassword(keystorepass); FederationClient fedclient = new FederationClient(peerApiUrl, cconf); System.out.println("Checking connectivity to remote acumos using public E5 interface"); System.out.println("Response from remote acumos is " + fedclient.ping()); System.out.println("Listing remote acumos catalogs using public E5 interface"); for (MLPCatalog mcat: fedclient.getCatalogs()) { System.out.println("Catalog " + mcat.getName() + " has " + ((Catalog)mcat).getSize() + " models"); } GatewayClient gwclient = new GatewayClient(internalApiUrl, cconf); System.out.println("Fetching first peer's catalogs from inside Acumos using private interface"); for (MLPCatalog mcat: gwclient.getCatalogs(firstpeerid)) {
import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(value = "/") public class PipeLineServiceController { private static final String PIPELINE_INPROGRESS = "IP"; private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired @Qualifier("InputValidationServiceImpl") private InputValidationService inputValidationService; @Autowired @Qualifier("PipeLineValidationServiceImpl") private PipeLineValidationService pipeLineValidationService; @Autowired @Qualifier("PipeLineServiceImpl") private PipeLineService pipeLineService; @Autowired private PipeLineCacheService pipelineCacheService; /** * Creates new independent Pipeline for a user. * @param authenticatedUserId
} else { logger.debug("Skipping flow creation...flow " + pipelineName + " already exists for user " + acumosLoginId + " in NiFi Registry."); // THROW AN EXCEPTION TO MLWB-UI - REQUESTED PIPELINE NAME ALREADY EXISTS BOTH IN NIFI IN AND REGISTRY throw new DuplicatePipeLineException("Request PipeLine Name : " + pipelineName + " already Exists in Both NiFi Server and NiFi Registry"); } logger.debug("NiFi createPipeline() end"); return flowURL; } /** * This method will check if the NiFi POD is running or not * @param acumosLoginId * Accepts acumosLoginId as parameter * @return * boolean as true/false */ public boolean checkifNifiPodRunning(String acumosLoginId) { boolean nifiPodRunning = false; logger.debug("checkifNifiPodRunning() begin"); nifiPodRunning = createNiFi.checkifNifiPodRunning(acumosLoginId); logger.debug("checkifNifiPodRunning() End"); return nifiPodRunning; } public String createNiFiInstance(String acumosLoginId) { logger.debug("createNiFiInstance() Begin"); String nifiURL = null; // Call the Kubernetes API to create a NiFi Instance try { nifiURL = createNiFi.createNiFiInstanceForUser(acumosLoginId);
throw new DuplicatePipeLineException("Request PipeLine Name : " + pipelineName + " already Exists in Both NiFi Server and NiFi Registry"); } logger.debug("NiFi createPipeline() end"); return flowURL; } public boolean checkifNifiPodRunning(String acumosLoginId) { boolean nifiPodRunning = false; logger.debug("checkifNifiPodRunning() begin"); nifiPodRunning = createNiFi.checkifNifiPodRunning(acumosLoginId); logger.debug("checkifNifiPodRunning() End"); return nifiPodRunning; } /** * This method will create the Instance of NiFi * @param acumosLoginId * Accepts acumosLoginId as parameter * @return * NiFi URL */ public String createNiFiInstance(String acumosLoginId) { logger.debug("createNiFiInstance() Begin"); String nifiURL = null; // Call the Kubernetes API to create a NiFi Instance try { nifiURL = createNiFi.createNiFiInstanceForUser(acumosLoginId); } catch (NiFiInstanceCreationException e) { logger.error("Exception occured while creating NiFi Instance for User",e); throw new NiFiInstanceCreationException("Exception occured while creating NiFi Instance for User "); } logger.debug("createNiFiInstance() End"); return nifiURL; }
*/ package org.acumos.workbench.pipelineservice.service; import java.lang.invoke.MethodHandles; import org.acumos.workbench.common.vo.Pipeline; import org.acumos.workbench.pipelineservice.exception.DuplicateRequestException; import org.acumos.workbench.pipelineservice.util.MLWBRequestCache; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; @Service public class PipeLineCacheService { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private MLWBRequestCache requestCache; /** * This method will put the create request * @param requestId * Accepts the requestId as parameter * @param pipeline * Accepts the pipeline as parameter */ public void putCreateRequest(String requestId, Pipeline pipeline) { logger.debug("putCreateRequest() Begin "); Boolean exist = requestCache.checkIfCreateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addCreateRequest(requestId, pipeline); } logger.debug("putCreateRequest() End"); } public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); }
private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private MLWBRequestCache requestCache; public void putCreateRequest(String requestId, Pipeline pipeline) { logger.debug("putCreateRequest() Begin "); Boolean exist = requestCache.checkIfCreateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addCreateRequest(requestId, pipeline); } logger.debug("putCreateRequest() End"); } /** * This method will remove the create request * @param requestId * Accepts the requestId as parameter * @param pipeline * Accepts the pipeline as parameter */ public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); }
public void putCreateRequest(String requestId, Pipeline pipeline) { logger.debug("putCreateRequest() Begin "); Boolean exist = requestCache.checkIfCreateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addCreateRequest(requestId, pipeline); } logger.debug("putCreateRequest() End"); } public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } /** * This method will put update request * @param requestId * Accepts the requestId as parameter * @param pipeline * Accepts the pipeline as parameter */ public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); } public void removeUpdateRequest(String requestId, Pipeline pipeline) { requestCache.removeUpdateRequest(requestId); }
} public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); } /** * This method will remove update request * @param requestId * Accepts the requestId as parameter * @param pipeline * Accepts the pipeline as parameter */ public void removeUpdateRequest(String requestId, Pipeline pipeline) { requestCache.removeUpdateRequest(requestId); } public void putDeleteRequest(String requestId, String pipelineId) { logger.debug("putDeleteRequest() Begin "); Boolean exist = requestCache.checkIfDeleteRequestExists(requestId, pipelineId); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addDeleteRequest(requestId, pipelineId); } logger.debug("putDeleteRequest() End "); }
} public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); } public void removeUpdateRequest(String requestId, Pipeline pipeline) { requestCache.removeUpdateRequest(requestId); } /** * This method will put delete request * @param requestId * Accepts the requestId as parameter * @param pipelineId * Accepts the pipelineId as parameter * */ public void putDeleteRequest(String requestId, String pipelineId) { logger.debug("putDeleteRequest() Begin "); Boolean exist = requestCache.checkIfDeleteRequestExists(requestId, pipelineId); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addDeleteRequest(requestId, pipelineId); } logger.debug("putDeleteRequest() End "); } public void removeDeleteRequest(String requestId, String pipelineId) { requestCache.removeDeleteRequest(requestId); }
@ApplicationScope @Component public class MLWBRequestCache implements Serializable { private static final long serialVersionUID = -4688732173089705360L; private Map<String, Pipeline> createRequests; // Key is Request Id and value is pipeline input private Map<String, Pipeline> updateRequests; // Key is Request Id and value is pipeline input private Map<String, String> deleteRequests; // Key is Request Id and value is pipeline Id private Map<String, String> archiveRequests; // Key is Request Id and value is pipeline Id /** * Constructor */ public MLWBRequestCache() { createRequests = new HashMap<String, Pipeline>(); updateRequests = new HashMap<String, Pipeline>(); deleteRequests = new HashMap<String, String>(); archiveRequests = new HashMap<String, String>(); } public void addCreateRequest(String key, Pipeline value) { createRequests.put(key, value); } public void removeCreateRequest(String key) { createRequests.remove(key); } public Pipeline getCreateRequestByKey(String key) { if(createRequests.containsKey(key)) { return createRequests.get(key);
private Map<String, String> deleteRequests; // Key is Request Id and value is pipeline Id private Map<String, String> archiveRequests; // Key is Request Id and value is pipeline Id public MLWBRequestCache() { createRequests = new HashMap<String, Pipeline>(); updateRequests = new HashMap<String, Pipeline>(); deleteRequests = new HashMap<String, String>(); archiveRequests = new HashMap<String, String>(); } /** * This method will Add Create Request * @param key * Accepts key as parameter * @param value * Accepts value as parameter */ public void addCreateRequest(String key, Pipeline value) { createRequests.put(key, value); } public void removeCreateRequest(String key) { createRequests.remove(key); } public Pipeline getCreateRequestByKey(String key) { if(createRequests.containsKey(key)) { return createRequests.get(key); } return null; } /** * Check if request with given requestId or Pipeline already exists in the cache. * @param key * request Id * @param value * Pipeline * @return boolean
List<Nodes> nodesList = new ArrayList<Nodes>(); nodesList.add(node); cdump.setNodes(nodesList); String nodeId = "123"; String userId = "123"; //try { when(props.getPackagepath()).thenReturn("org/acumos/vo/"); when(props.getClassName()).thenReturn("DataVO"); Resource resource1 = resourceLoader.getResource(PROTOBUF_TEMPLATE_NAME) ; when(resourceLoader.getResource("classpath:Protobuf_Template.txt")).thenReturn(resource1); gdmServiceImpl.createDeployGDM(cdump, nodeId, userId); } catch (ServiceException e) { e.printStackTrace(); }
* you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ /** * */ package org.acumos.designstudio.test; import static org.junit.Assert.*; import java.lang.invoke.MethodHandles; import java.util.ArrayList; import java.util.List; import java.util.Properties; import org.acumos.designstudio.ce.util.ConfigurationProperties; import org.acumos.designstudio.ce.vo.DSSolution; import org.acumos.designstudio.ce.vo.MatchingModel; import org.acumos.designstudio.ce.vo.SuccessErrorMessage; import org.acumos.designstudio.ce.vo.blueprint.BPCollatorMap; import org.acumos.designstudio.ce.vo.blueprint.BPDataBrokerMap;
import com.google.common.collect.Lists; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.ApiKey; import springfox.documentation.service.AuthorizationScope; import springfox.documentation.service.Contact; import springfox.documentation.service.SecurityReference; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spi.service.contexts.SecurityContext; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; @Configuration @EnableSwagger2 public class SwaggerConfiguration { @Bean public Docket swaggerSpringfoxDocket() { Docket docket = new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .forCodeGeneration(true) .genericModelSubstitutes(ResponseEntity.class) .ignoredParameterTypes(Pageable.class) .ignoredParameterTypes(java.sql.Date.class) .directModelSubstitute(java.time.LocalDate.class, java.sql.Date.class) .directModelSubstitute(java.time.ZonedDateTime.class, Date.class) .directModelSubstitute(java.time.LocalDateTime.class, Date.class) .securityContexts(Lists.newArrayList(securityContext()))
} // Secure the endpoints with HTTP Basic authentication @Override protected void configure(HttpSecurity http) throws Exception { http .csrf().disable() .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() .antMatchers("/swagger-ui.html").permitAll() .anyRequest().authenticated() .and() .addFilterBefore(jwtAuthorizationFilterBean(), UsernamePasswordAuthenticationFilter.class); } @Bean public JWTAuthorizationFilter jwtAuthorizationFilterBean() throws Exception { JWTAuthorizationFilter jwtAuthorizationFilter = new JWTAuthorizationFilter(authenticationManagerBean(), conf.getJwtSecretKey(), cdsClient); return jwtAuthorizationFilter; } }
* * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.workbench.modelservice.service; import org.acumos.workbench.common.vo.Model; public interface ModelValidationService { /** * To Validate the Input for * * @param authenticatedUserId the authenticated User Id * @param model the model */ public void validateInputData(String authenticatedUserId, Model model); }
* http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.workbench.modelservice.service; import org.acumos.workbench.common.vo.Model; public interface ModelValidationService { /** * To Validate the Input Data * * @param authenticatedUserId * @param model */ public void validateInputData(String authenticatedUserId, Model model); }
* ===============LICENSE_START======================================================= * Acumos * =================================================================================== * Copyright (C) 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. * =================================================================================== * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.designstudio.toscagenerator.test; import java.io.File; import java.io.IOException; import java.lang.invoke.MethodHandles; import java.time.Instant; import java.util.ArrayList; import java.util.List; import org.acumos.cds.domain.MLPSolutionRevision; import org.acumos.designstudio.toscagenerator.ToscaGeneratorClient;
import org.junit.Rule; import org.junit.Test; import org.mockito.MockitoAnnotations; import org.mockito.junit.MockitoJUnit; import org.mockito.junit.MockitoRule; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class ToscaGeneratorClientTest { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Rule public MockitoRule mockitoRule = MockitoJUnit.rule(); @Before public void setUp() { MockitoAnnotations.initMocks(this); } @Test() public void ToscaClientTest(){
mlpRev.setModified(Instant.now()); mlpRev.setOnboarded(Instant.now()); mlpRev.setPublisher("techmdev"); mlpRev.setRevisionId("123"); mlpRev.setSolutionId("123"); mlpRev.setUserId("123"); mlpRev.setVerifiedLicense("Yes"); mlpRev.setVerifiedVulnerability("Yes"); mlpRev.setVersion("1"); List<MLPSolutionRevision> listMLPSolRev = new ArrayList<>(); listMLPSolRev.add(mlpRev); try { client.generateTOSCA("123", "123", "1", "123", protoFile, tagFile); } catch (AcumosException e) { logger.error("AcumosException occured while generating the TOSCA File"); }
* ===============LICENSE_START======================================================= * Acumos * =================================================================================== * Copyright (C) 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. * =================================================================================== * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.csvdatabroker.vo; import static org.junit.Assert.assertTrue; import org.junit.Test; public class CSVdatabrokerVOTest { @Test public void csvdatabrokerVOTest() { DataBrokerMap dataBrokerMap = new DataBrokerMap(); dataBrokerMap.setScript("test");
* ===============LICENSE_START======================================================= * Acumos * =================================================================================== * Copyright (C) 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. * =================================================================================== * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.sqldatabroker.vo; import static org.junit.Assert.assertTrue; import java.util.ArrayList; import java.util.List; import org.acumos.sqldatabroker.exceptionhandler.ServiceException; import org.junit.Test; public class DataBrokerMapVOTest { @Test
* ===============LICENSE_START======================================================= * Acumos * =================================================================================== * Copyright (C) 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. * =================================================================================== * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.csvdatabroker.vo; import static org.junit.Assert.assertTrue; import org.junit.Test; public class CSVdatabrokerVOTest { @Test public void csvdatabrokerVOTest() { DataBrokerMap dataBrokerMap = new DataBrokerMap(); dataBrokerMap.setScript("test");
@RestController @RequestMapping(value = "/") public class ModelServiceController { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired @Qualifier("InputValidationServiceImpl") private InputValidationService inputValidationService; @Autowired @Qualifier("ModelValidationServiceImpl") private ModelValidationService modelValidationService; @Autowired @Qualifier("ModelServiceImpl") private ModelService modelService; @ApiOperation(value = "List out all the Models that belongs to user") @RequestMapping(value = "/users/{authenticatedUserId}/models/", method = RequestMethod.GET) public ResponseEntity<?> listModels(HttpServletRequest request,@ApiParam(value="Acumos User login Id",required = true)@PathVariable("authenticatedUserId") String authenticatedUserId){ logger.debug("listModels() Begin"); String authToken = getAuthJWTToken(request); //1. Check the Authenticated User Id is present or not inputValidationService.isValuePresent(ModelServiceConstants.MODEL_AUTHENTICATED_USER_ID, authenticatedUserId);
import org.acumos.workbench.common.vo.Version; import org.acumos.workbench.modelservice.exceptionhandling.ModelNotFoundException; import org.acumos.workbench.modelservice.util.ConfigurationProperties; import org.acumos.workbench.modelservice.util.ModelServiceProperties; import org.acumos.workbench.modelservice.util.ModelServiceUtil; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.slf4j.MDC; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Service; import org.springframework.web.client.RestClientResponseException; @Service("ModelServiceImpl") public class ModelServiceImpl implements ModelService { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private CommonDataServiceRestClientImpl cdsClient; @Autowired private ModelServiceProperties props; @Autowired private ConfigurationProperties confprops; @Autowired private ProjectServiceRestClientImpl psClient; @Override public List<Model> getModels(String authenticatedUserId, String projectId) { logger.debug("getModels() Begin"); List<Model> modelList = new ArrayList<Model>(); MLPUser mlpUser = getUserDetails(authenticatedUserId);
Model model = getModelWithErrorStatus(ex); return new ResponseEntity<Model>(model, HttpStatus.NOT_FOUND); } /** * To handle AssociationExistsException and returns appropriate response to UI. * @param ex * the exception thrown by the service method * @param request * the WebRequest * @return ResponseEntitiy<Model> * returns Model with ServiceStatus indicating error */ @ExceptionHandler(AssociationException.class) public final ResponseEntity<?> handleAssociationExistsException(AssociationException ex, WebRequest request) { Model model = getModelWithErrorStatus(ex); return new ResponseEntity<Model>(model, HttpStatus.NOT_FOUND); } /** * To handle AssociationNotFoundException and returns appropriate response to UI. * @param ex * the exception thrown by the service method * @param request * the WebRequest * @return ResponseEntitiy<Model> * returns Model with ServiceStatus indicating error */ @ExceptionHandler(ProjectModelAssociationNotFoundException.class)
* * @param fieldName * The name of the filed to be shown in the error message. * @param value * The value to be validated * @throws ValueNotFoundException * throws ValueNotFoundException in case value is null or empty. */ public void isValuePresent(String fieldName, String value) throws ValueNotFoundException; /** * To validate the input Json value of Model * @param model * the model object with input values * @throws InvalidInputJSONException * throws InvalidInputJSONException in case of error in the input JSON */ public void validateModelInputJson(Model model) throws InvalidInputJSONException; }
* ===============LICENSE_END========================================================= */ package org.acumos.workbench.modelservice.util; public class ModelServiceConstants { public static final String MODEL_AUTHENTICATED_USER_ID = "AuthenticatedUserId"; public static final String DELETED = "DELETED"; public static final String MODEL_IS_ACTIVE = "Model is Active"; public static final String CATALOGNAMES = "CATALOG_NAMES"; public static final String UNARCHIVE = "UA"; public static final String ARCHIVE = "A"; public static final String PROJECTID = "projectId"; public static final String ASSOCIATIONID = "ASSOCIATION_ID"; public static final String MODELTYPECODE = "MODEL_TYPE_CODE"; public static final String MODELPUBLISHSTATUS = "MODEL_PUBLISH_STATUS"; }
private List<String> getConnectedPortInputMsgNames(List<ProtobufServiceOperation> operations) { List<String> inputMessageNames = null; for (ProtobufServiceOperation o : operations) { // TODO : Current logic returns the first operation's input msg name, but need to update the logic to return the connected port input message name inputMessageNames = o.getInputMessageNames(); } return inputMessageNames;
// 1. Get the list of SolutionRevision for the solutionId. mlpSolutionRevisionList = getSolutionRevisionsList(solutionId); // 2. Match the version with the SolutionRevision and get the // solutionRevisionId. if (null != mlpSolutionRevisionList && !mlpSolutionRevisionList.isEmpty()) { solutionRevisionId = mlpSolutionRevisionList.stream().filter(mlp -> mlp.getVersion().equals(version)) .findFirst().get().getRevisionId(); logger.debug(EELFLoggerDelegator.debugLogger," SolutionRevisonId for Version : " + solutionRevisionId); } else { result = String.format(error, "501", "Failed to fetch the Solution Revision List"); } } catch (Exception e) { logger.error(EELFLoggerDelegator.errorLogger, "Error : Exception in fetchJsonTOSCA() : Failed to fetch the Solution Revision List", e); result = String.format(error, "501", "Failed to fetch the Solution Revision List for the version {} ", version); } if (null != solutionRevisionId) {
// add protobuf file addProtobufFile(protobufJarEntryName, tempJar); // add DavaVO.class file List<String> dataVOEntryList = addDataVOClasses(DataVOClassEntryName, tempJar); JarEntry entry = null; // Open the original jar jar = new JarFile(jarFile); // Loop through the jar entries and add them to the temp jar, // skipping the entry that was added to the temp jar already. for (Enumeration entries = jar.entries(); entries.hasMoreElements();) { // Get the next entry. // Read the entry and write it to the temp jar. // If the entry has not been added already, add it. if (!entry.getName().equals(fieldMappingJarEntryName) && !dataVOEntryList.contains(entry.getName())) { // Get an input stream for the entry. InputStream entryStream = jar.getInputStream(entry); // Read the entry and write it to the temp jar. tempJar.putNextEntry(entry); while ((bytesRead = entryStream.read(buffer)) != -1) {
curPartIdx++; if (curPartIdx <= endPartIdx) { boolean suitablePartFound = false; for (int i = curPartIdx; i <= endPartIdx; i++) { // Prune partition because no element in it can satisfy the occurrence threshold. if (partitionCursors[i] == null || partitionCursors[i].size() < occurrenceThreshold) { continue; } suitablePartFound = true; curPartIdx = i; break; } // If no partition is availble to explore, we stop here. if (!suitablePartFound) { isFinishedSearch = true; invListMerger.close(); finalSearchResult.finalizeWrite(); return true; } // Temp : // System.out.println("\nMerging the cursor for the partition " + curPartIdx + " start " // + partitions.getMinValidPartitionIndex() + " end " + endPartIdx // + " - PartitionedTOccurrenceSearcher::continueSearch()"); //
isSingleInvertedList = true; needToReadNewPart = true; } else { singleInvListCursor = null; isSingleInvertedList = false; needToReadNewPart = invListMerger.merge(partitionCursors[curPartIdx], occurrenceThreshold, numPrefixLists, finalSearchResult); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); } // Finished processing one partition if (needToReadNewPart && isFinalPartIdx) { invListMerger.close(); finalSearchResult.finalizeWrite(); isFinishedSearch = true; // Temp : // System.out.println("Final partition " + curPartIdx + " Search done"); return true; } } else { isFinishedSearch = true; } return false; } public void setNumTokensBoundsInSearchKeys(short numTokensLowerBound, short numTokensUpperBound) {
needToReadNewPart = true; } else { singleInvListCursor = null; isSingleInvertedList = false; needToReadNewPart = invListMerger.merge(partitionCursors[curPartIdx], occurrenceThreshold, numPrefixLists, finalSearchResult); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); } // Finished processing one partition if (needToReadNewPart && isFinalPartIdx) { invListMerger.close(); finalSearchResult.finalizeWrite(); isFinishedSearch = true; // Temp : // System.out.println("Final partition " + curPartIdx + " Search done"); return true; } } else { isFinishedSearch = true; } return false; } public void setNumTokensBoundsInSearchKeys(short numTokensLowerBound, short numTokensUpperBound) {
searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); // Temp : // System.out.println("PartitionedTOccurrenceSearcher::continueSearch() - " + needToReadNewPart // + " tupleCount " + searchResultFta.getTupleCount()); // } // Finished processing one partition if (needToReadNewPart && isFinalPartIdx) { invListMerger.close(); finalSearchResult.finalizeWrite(); isFinishedSearch = true; return true; } } else { isFinishedSearch = true; } return false; } public void setNumTokensBoundsInSearchKeys(short numTokensLowerBound, short numTokensUpperBound) { ShortPointable.setShort(lowerBoundTuple.getFieldData(0), lowerBoundTuple.getFieldStart(0), numTokensLowerBound); ShortPointable.setShort(upperBoundTuple.getFieldData(0), upperBoundTuple.getFieldStart(0), numTokensUpperBound); } public ITupleReference getPrefixSearchKey() { return searchKey; } public ITupleReference getFullLowSearchKey() { return fullLowSearchKey;
singleInvListCursor.prepareLoadPages(); singleInvListCursor.loadPages(); isSingleInvertedList = true; isFinishedSearch = true; } else { finalSearchResult.reset(); isFinishedSearch = invListMerger.merge(invListCursors, occurrenceThreshold, numPrefixLists, finalSearchResult); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); } if (isFinishedSearch) { invListMerger.close(); finalSearchResult.finalizeWrite(); } // Some or all output was generated by the merger. Let the result cursor fetch the output. resultCursor.open(null, searchPred); } /** * Continues a search process if it was paused because the output buffer (one frame) of the final result was full. * This method should not be called for a single inverted list case since there cannot be multiple inverted list * cursors for a single keyword.
* false otherwise. * @throws HyracksDataException */ @Override public boolean continueSearch() throws HyracksDataException { if (isFinishedSearch) { return true; } isFinishedSearch = invListMerger.continueMerge(); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); if (isFinishedSearch) { invListMerger.close(); finalSearchResult.finalizeWrite(); } return isFinishedSearch; } }
* Otherwise, it performs an insert. * * @param tuple * Tuple to be deleted. * @throws HyracksDataException * If the BufferCache throws while un/pinning or un/latching. * @throws IndexException * If there is no matching tuple in the index. * */ public void upsert(ITupleReference tuple) throws HyracksDataException; /** * Creates a cursor appropriate for passing into search(). * * @throws HyracksDataException * */ public IIndexCursor createSearchCursor(boolean exclusive) throws HyracksDataException; /** * Open the given cursor for an index search using the given predicate as * search condition. * * @param icursor * Cursor over the index entries satisfying searchPred. * @param searchPred * Search condition. * @throws HyracksDataException * If the BufferCache throws while un/pinning or un/latching. * @throws IndexException */ public void search(IIndexCursor cursor, ISearchPredicate searchPred) throws HyracksDataException; }
public boolean append(byte[] bytes, int offset, int length) { if (tupleDataEndOffset + length + TUPLE_COUNT_SIZE <= frameSize) { System.arraycopy(bytes, offset, buffer.array(), tupleDataEndOffset, length); tupleDataEndOffset += length; return true; } return false;
invListTuple = invListCursor.getTuple(); if (!newSearchResult.append(invListTuple, 1)) { // For a final result, needs to pause when a frame becomes full to let the caller // consume the frame. SearchResult.append() should only return false for this case. return false; } invListTidx++; if (invListCursor.hasNext()) { invListCursor.next(); } } // append remaining elements from previous result set while (resultTidx < prevResultFrameTupleCount) { resultTuple.reset(prevCurrentBuffer.array(), resultFrameTupleAcc.getTupleStartOffset(resultTidx)); count = getCount(resultTuple); if (!newSearchResult.append(resultTuple, count)) { // For a final result, needs to pause when a frame becomes full to let the caller // consume the frame. SearchResult.append() should only return false for this case. return false; } resultTidx++; checkPrevResultAndFetchNextFrame(prevSearchResult); } return finishMergingOneList(isFinalList, prevSearchResult, newSearchResult); }
} private static final Map<Integer, ReplicationRequestType> TYPES = new HashMap<>(); static { Stream.of(ReplicationRequestType.values()).forEach(type -> TYPES.put(type.ordinal(), type)); } public static ByteBuffer readRequest(SocketChannel socketChannel, ByteBuffer dataBuffer) throws IOException { //read request size NetworkingUtil.readBytes(socketChannel, dataBuffer, Integer.BYTES); final int requestSize = dataBuffer.getInt(); if (dataBuffer.capacity() < requestSize) { dataBuffer = ByteBuffer.allocate(requestSize); } //read request NetworkingUtil.readBytes(socketChannel, buf, requestSize); return dataBuffer; } public static ReplicationRequestType getRequestType(SocketChannel socketChannel, ByteBuffer byteBuffer) throws IOException { //read replication request type NetworkingUtil.readBytes(socketChannel, byteBuffer, REPLICATION_REQUEST_TYPE_SIZE); return TYPES.get(byteBuffer.getInt()); } private static ByteBuffer getGoodbyeBuffer() { ByteBuffer bb = ByteBuffer.allocate(REPLICATION_REQUEST_TYPE_SIZE); bb.putInt(ReplicationRequestType.GOODBYE.ordinal()); bb.flip(); return bb; }
public static int getTxnIdFromLogAckMessage(String msg) { return Integer.parseInt(msg.substring(msg.indexOf(LOG_REPLICATION_ACK) + 1));
ITupleReference highSearchKey = null; partSearcher.setNumTokensBoundsInSearchKeys(numTokensLowerBound, numTokensUpperBound); if (numTokensLowerBound < 0) { ctx.getBtreePred().setLowKeyComparator(ctx.getPrefixSearchCmp()); lowSearchKey = partSearcher.getPrefixSearchKey(); } else { ctx.getBtreePred().setLowKeyComparator(ctx.getSearchCmp()); lowSearchKey = partSearcher.getFullLowSearchKey(); } if (numTokensUpperBound < 0) { ctx.btreePred.setHighKeyComparator(ctx.prefixSearchCmp); highSearchKey = partSearcher.getPrefixSearchKey(); } else { ctx.getBtreePred().setHighKeyComparator(ctx.getSearchCmp()); highSearchKey = partSearcher.getFullHighSearchKey(); } ctx.getBtreePred().setLowKey(lowSearchKey, true); ctx.getBtreePred().setHighKey(highSearchKey, true); ctx.getBtreeAccessor().search(ctx.getBtreeCursor(), ctx.getBtreePred()); boolean tokenExists = false; try { while (ctx.getBtreeCursor().hasNext()) { ctx.getBtreeCursor().next(); ITupleReference btreeTuple = ctx.getBtreeCursor().getTuple();
} protected void createAndOpenFile() throws HyracksDataException { if (isInMemoryOpMode) { // In-memory mode should not generate a file. return; } if (searchResultWriter == null) { FileReference file = ctx.getJobletContext().createManagedWorkspaceFile(FILE_PREFIX); searchResultWriter = new RunFileWriter(file, ctx.getIoManager()); searchResultWriter.open(); isFileOpened = true; } } // Deallocates the I/O buffer (one frame). This should be the last oepration. protected void deallocateIOBuffer() throws HyracksDataException { if (ioBufferFrame != null) { // Temp : // System.out.println( // "InvertedIndexSearchResult::deallocateIOBuffer() buffer - " + ObjectUtils.identityToString(ioBuffer)); bufferManager.releaseFrame(ioBuffer); buffers.clear(); ioBufferFrame = null; ioBuffer = null; } } /**
foundIn = i; return true; } } if (i == 0 && includeMutableComponent) { // unlatch/unpin btreeCursors[i].reset(); searchCallback.reconcile(predicate.getLowKey()); reconciled = true; // retraverse btreeAccessors[0].search(btreeCursors[i], predicate); if (btreeCursors[i].hasNext()) { btreeCursors[i].next(); if (((ILSMTreeTupleReference) btreeCursors[i].getTuple()).isAntimatter()) { searchCallback.cancel(predicate.getLowKey()); rangeCursors[i].close(); return false; } else { frameTuple = btreeCursors[i].getTuple(); foundTuple = true; searchCallback.complete(predicate.getLowKey()); foundIn = i; return true; } } else { searchCallback.cancel(predicate.getLowKey()); btreeCursors[i].close(); } } else { frameTuple = btreeCursors[i].getTuple(); searchCallback.reconcile(frameTuple); searchCallback.complete(frameTuple); foundTuple = true; foundIn = i;
protected void appendToLogTail(ILogRecord logRecord) { syncAppendToLogTail(logRecord); if (waitForFlush(logRecord) && !logRecord.isFlushed()) { synchronized (logRecord) { while (!logRecord.isFlushed()) { try { logRecord.wait(); } catch (InterruptedException e) { // NOSONAR ensure txn survive at this stage // ignore interrupt } } }); }
* "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.common.replication; import java.util.HashMap; import java.util.Map; public class ReplicationStrategyFactory { private static final Map<String, Class<? extends IReplicationStrategy>> BUILT_IN_REPLICATION_STRATEGY = new HashMap<>(); static { BUILT_IN_REPLICATION_STRATEGY.put("none", NoReplicationStrategy.class); BUILT_IN_REPLICATION_STRATEGY.put("all", AllDatasetsReplicationStrategy.class); BUILT_IN_REPLICATION_STRATEGY.put("metadata", MetadataOnlyReplicationStrategy.class); } private ReplicationStrategyFactory() { throw new AssertionError(); } public static IReplicationStrategy create(String name) { String strategyName = name.toLowerCase(); if (!BUILT_IN_REPLICATION_STRATEGY.containsKey(strategyName)) { throw new IllegalStateException("Couldn't find strategy with name: " + name); } Class<? extends IReplicationStrategy> clazz = BUILT_IN_REPLICATION_STRATEGY.get(strategyName); try {
setNumActiveIOOps(getNumActiveIOOps() + 1); } public synchronized void undeclareActiveIOOperation() { setNumActiveIOOps(getNumActiveIOOps() - 1); //notify threads waiting on this dataset info notifyAll(); } public synchronized Set<ILSMIndex> getDatasetIndexes() { Set<ILSMIndex> datasetIndexes = new HashSet<>(); for (IndexInfo iInfo : getIndexes().values()) { if (iInfo.isOpen()) { datasetIndexes.add(iInfo.getIndex()); } } return indexSet; } @Override public int compareTo(DatasetInfo i) { // sort by (isOpen, referenceCount, lastAccess) ascending, where true < false // // Example sort order: // ------------------- // (F, 0, 70) <-- largest // (F, 0, 60) // (T, 10, 80) // (T, 10, 70) // (T, 9, 90) // (T, 0, 100) <-- smallest if (isOpen() && !i.isOpen()) { return -1;
ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetLifecycle> openDatasets = new ArrayList<>(datasetLifecycles.values()); for (DatasetLifecycle dslc : openDatasets) { closeDataset(dslc.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) { if (dsr.getDatasetID() >= getFirstAvilableUserDatasetID()) { closeDataset(dsr.getDatasetInfo()); } } } @Override public synchronized void stop(boolean dumpState, OutputStream outputStream) throws IOException { if (stopped) { return; } if (dumpState) { dumpState(outputStream); } closeAllDatasets(); datasetLifecycles.clear();
synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetLifecycle> openDatasets = new ArrayList<>(datasetLifecycles.values()); for (DatasetLifecycle dslc : openDatasets) { closeDataset(dslc.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) { if (dsr.getDatasetID() >= getFirstAvilableUserDatasetID()) { closeDataset(dsr.getDatasetInfo()); } } } @Override public synchronized void stop(boolean dumpState, OutputStream outputStream) throws IOException { if (stopped) { return; } if (dumpState) { dumpState(outputStream); } closeAllDatasets(); datasetLifecycles.clear(); stopped = true; } @Override
protected void cleanupForAbort() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers .entrySet()) { AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); }
protected void cleanupForAbort() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers .entrySet()) { AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); }
protected void cleanupForAbort() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers .entrySet()) { AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); }
protected void cleanupForAbort() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers .entrySet()) { AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); }
protected void cleanupForAbort() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers .entrySet()) { AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); }
return primaryKeyVars; } /** * Returns the search key expression which feeds a secondary-index search. If we are optimizing a selection query * then this method returns the a ConstantExpression from the first constant value in the optimizable function * expression. * If we are optimizing a join, then this method returns the VariableReferenceExpression that should feed the * secondary index probe. * * @throws AlgebricksException */ public static Triple<ILogicalExpression, ILogicalExpression, Boolean> createSearchKeyExpr(Index index, IOptimizableFuncExpr optFuncExpr, IAType indexedFieldType, OptimizableOperatorSubTree probeSubTree) throws AlgebricksException { if (probeSubTree == null) { // We are optimizing a selection query. Search key is a constant. // Type Checking and type promotion is done here if (optFuncExpr.getNumConstantExpr() == 0) { //We are looking at a selection case, but using two variables //This means that the second variable comes from a nonPure function call //TODO: Right now we miss on type promotion for nonpure functions
if (dsInfo.isDurable()) { synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null, logManager.getNodeId(), indexes.size()); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { //notification will come from LogBuffer class (notifyFlushTerminator) logRecord.wait(); } catch (InterruptedException e) { Thread.currentThread().interrupt(); throw HyracksDataException.create(e); } } } for (ILSMIndex index : indexes) { //update resource lsn AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) {
synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null, logManager.getNodeId(), indexes.size()); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { //notification will come from LogBuffer class (notifyFlushTerminator) logRecord.wait(); } catch (InterruptedException e) { Thread.currentThread().interrupt(); throw HyracksDataException.create(e); } } } for (ILSMIndex index : indexes) { //update resource lsn AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) { // TODO: This is not efficient since we flush the indexes sequentially.
try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { closeIndex(iInfo); } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) { closeDataset(dsr.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) {
try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { closeIndex(iInfo); } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) { closeDataset(dsr.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) {
// we will force all jobs to spill their cached entities to disk. // This could happen only when we have many jobs with small // number of records and none of them have job commit. freeJobsCachedEntities(txnId); } jobId2WinnerEntitiesMap.put(txnId, jobEntityWinners); } else { jobEntityWinners = jobId2WinnerEntitiesMap.get(txnId); } jobEntityWinners.add(logRecord); } private synchronized void startRecoveryRedoPhase(Set<Integer> partitions, ILogReader logReader, long lowWaterMarkLSN, Set<Long> winnerTxnSet) throws IOException, ACIDException { int redoCount = 0; long txnId = 0; long resourceId; long maxDiskLastLsn; long lsn = -1; ILSMIndex index = null; LocalResource localResource = null; DatasetLocalResource localResourceMetadata = null; boolean foundWinner = false; JobEntityCommits jobEntityWinners = null; IAppRuntimeContextProvider appRuntimeContext = txnSubsystem.getAsterixAppRuntimeContextProvider(); IDatasetLifecycleManager datasetLifecycleManager = appRuntimeContext.getDatasetLifecycleManager();
private void doWriteLogRecord(ByteBuffer buffer) { buffer.put(logSource); buffer.put(logType); buffer.putLong(txnId); switch (logType) { case LogType.ENTITY_COMMIT: writeEntityResource(buffer); writeEntityValue(buffer); break; case LogType.UPDATE: writeEntityInfo(buffer); buffer.putLong(resourceId); buffer.putInt(logSize); buffer.putInt(newValueFieldCount); buffer.put(newOp); buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); if (oldValueSize > 0) { buffer.putInt(oldValueSize); buffer.putInt(oldValueFieldCount); writeTuple(buffer, oldValue, oldValueSize); } break; case LogType.FILTER: writeEntityInfoNoPK(buffer); buffer.putLong(resourceId); buffer.putInt(logSize); buffer.putInt(newValueFieldCount); buffer.put(newOp); buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); break; case LogType.FLUSH: buffer.putInt(datasetId); break; case LogType.MARKER: buffer.putInt(datasetId); buffer.putInt(resourcePartition); callback.before(buffer); buffer.putInt(logSize);
private void writeEntityValue(ByteBuffer buffer) { buffer.putInt(PKHashValue); if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } buffer.putInt(PKValueSize); writePKValue(buffer);
private void writeEntityValue(ByteBuffer buffer) { buffer.putInt(PKHashValue); if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } buffer.putInt(PKValueSize); writePKValue(buffer);
private void writeEntityResource(ByteBuffer buffer) { buffer.putInt(resourcePartition); buffer.putInt(datasetId);
txnId = buffer.getLong(); switch (logType) { case LogType.FLUSH: if (buffer.remaining() < ILogRecord.DS_LEN) { return RecordReadStatus.TRUNCATED; } datasetId = buffer.getInt(); resourceId = 0l; // fall throuh case LogType.WAIT: computeAndSetLogSize(); break; case LogType.JOB_COMMIT: case LogType.ABORT: datasetId = -1; PKHashValue = -1; computeAndSetLogSize(); break; case LogType.ENTITY_COMMIT: if (readEntityResource(buffer) && readEntityValue(buffer)) { computeAndSetLogSize(); } else { return RecordReadStatus.TRUNCATED; } break; case LogType.UPDATE: if (readEntityInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.FILTER: if (readEntityNoPKInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) {
if (readEntityInfo(buffer)) { computeAndSetLogSize(); } else { return RecordReadStatus.TRUNCATED; } break; case LogType.UPDATE: if (readEntityInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.FILTER: if (readEntityResource(buffer)) { return readUpdateInfo(buffer); } break; case LogType.MARKER: if (buffer.remaining() < DS_LEN + RS_PARTITION_LEN + PRVLSN_LEN + LOGRCD_SZ_LEN) { return RecordReadStatus.TRUNCATED; } datasetId = buffer.getInt(); resourcePartition = buffer.getInt(); prevMarkerLSN = buffer.getLong(); logSize = buffer.getInt(); int lenRemaining = logSize - MARKER_BASE_LOG_SIZE;
computeAndSetLogSize(); } else { return RecordReadStatus.TRUNCATED; } break; case LogType.UPDATE: if (readEntityInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.FILTER: if (readEntityResource(buffer)) { return readUpdateInfo(buffer); } break; case LogType.MARKER: if (buffer.remaining() < DS_LEN + RS_PARTITION_LEN + PRVLSN_LEN + LOGRCD_SZ_LEN) { return RecordReadStatus.TRUNCATED; } datasetId = buffer.getInt(); resourcePartition = buffer.getInt(); prevMarkerLSN = buffer.getLong(); logSize = buffer.getInt(); int lenRemaining = logSize - MARKER_BASE_LOG_SIZE; if (buffer.remaining() < lenRemaining) {
private boolean readEntityInfo(ByteBuffer buffer) { //attempt to read in the resourcePartition, dsid, PK hash and PK length if (buffer.remaining() < ENTITY_VALUE_HEADER_LEN) { return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); PKHashValue = buffer.getInt(); PKValueSize = buffer.getInt(); // attempt to read in the PK if (buffer.remaining() < PKValueSize) { return false; } if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } PKValue = readPKValue(buffer); return true;
private boolean readEntityInfo(ByteBuffer buffer) { //attempt to read in the resourcePartition, dsid, PK hash and PK length if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) { return false; } PKHashValue = buffer.getInt(); PKValueSize = buffer.getInt(); // attempt to read in the PK if (buffer.remaining() < PKValueSize) { return false; } if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } PKValue = readPKValue(buffer); return true;
private boolean readEntityResource(ByteBuffer buffer) { //attempt to read in the resourcePartition and dsid if (buffer.remaining() < ENTITY_RESOURCE_HEADER_LEN) { return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); return true;
private boolean readEntityResource(ByteBuffer buffer) { //attempt to read in the resourcePartition and dsid if (buffer.remaining() < ENTITY_RESOURCE_HEADER_LEN) { return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); return true;
private boolean readEntityResource(ByteBuffer buffer) { //attempt to read in the resourcePartition and dsid if (buffer.remaining() < ENTITY_RESOURCE_HEADER_LEN) { return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); return true;
if (isDeleteOperation(tuple, numOfPrimaryKeys)) { // Only delete if it is a delete and not upsert abstractModCallback.setOp(Operation.DELETE); lsmAccessor.forceDelete(tuple); recordWasDeleted = true; } else { abstractModCallback.setOp(Operation.UPSERT); lsmAccessor.forceUpsert(tuple); recordWasInserted = true; } if (isFiltered && prevTuple != null) { // need to update the filter of the new component with the previous value lsmAccessor.updateFilter(prevTuple); } writeOutput(index, recordWasInserted, recordWasDeleted); } catch (Exception e) { throw HyracksDataException.create(e); } } @Override public void start() throws HyracksDataException { lsmAccessor.getCtx().setOperation(IndexOperation.UPSERT); } @Override public void finish() throws HyracksDataException { lsmAccessor.getCtx().setOperation(IndexOperation.UPSERT); } }; } // we have the permutation which has [pk locations, record location, optional:filter-location] // the index -> we don't need anymore data?
* * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.common.ophelpers; public enum IndexOperation { CREATE, INSERT, DELETE, UPDATE, UPSERT, FILTER_MOD, SEARCH, FILTER_MOD, DISKORDERSCAN, PHYSICALDELETE, NOOP, MERGE, FULL_MERGE, FLUSH, REPLICATE, DISK_COMPONENT_SCAN, DELETE_MEMORY_COMPONENT, DELETE_DISK_COMPONENTS }
ctx.setOperation(IndexOperation.UPSERT); lsmHarness.forceUpdateMeta(ctx, key, value); } @Override public ITreeIndexCursor createSearchCursor(boolean exclusive) { return cursorFactory.create(ctx); } @Override public void updateFilter(ITupleReference tuple) throws HyracksDataException { ctx.setOperation(IndexOperation.UPSERT); lsmHarness.updateFilter(ctx, tuple); } public void batchOperate(FrameTupleAccessor accessor, FrameTupleReference tuple, IFrameTupleProcessor processor, IFrameOperationCallback frameOpCallback) throws HyracksDataException { lsmHarness.batchOperate(ctx, accessor, tuple, processor, frameOpCallback); } @Override public void scanDiskComponents(IIndexCursor cursor) throws HyracksDataException { ctx.setOperation(IndexOperation.DISK_COMPONENT_SCAN); lsmHarness.scanDiskComponents(ctx, cursor); } @Override public String toString() { return getClass().getSimpleName() + ':' + lsmHarness.toString(); } @Override
} @Override public void found(ITupleReference before, ITupleReference after) throws HyracksDataException { if (isFoundNull) { Assert.assertEquals(null, before); } else { Assert.assertEquals(0, cmp.compare(AbstractModificationOperationCallbackTest.this.tuple, before)); } Assert.assertEquals(0, cmp.compare(AbstractModificationOperationCallbackTest.this.tuple, after)); } } }
// Do nothing. } @Override public void before(ITupleReference tuple) { // Do nothing. } @Override public void found(ITupleReference before, ITupleReference after) { // Do nothing. } @Override public void cancel(ITupleReference tuple) { // Do nothing. } @Override public void complete(ITupleReference tuple) throws HyracksDataException { // Do nothing. } }
public void after(ITupleReference tuple) { //Nothing to do there, not testing filters
IOptimizationContext context, Quadruple<Boolean, Boolean, Boolean, Boolean> indexOnlyPlanInfo) throws AlgebricksException { // index-only plan possible? boolean isIndexOnlyPlan = false; // secondary key field usage after the select (join) operators // This boolean is mainly used for R-Tree case since R-Tree index generates an MBR // and we can restore original point or rectangle from this MBR if an index is built on point or rectangle. boolean secondaryKeyFieldUsedAfterSelectOrJoinOp; // Whether a post verification (especially for R-Tree case) is required after the secondary index search // (e.g., the shape of the given query is not a point or rectangle. // Then, we may need to apply the select again using the real polygon, not MBR of it to get the true // result, not a super-set of it.) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); // Does the given index can cover all search predicates? boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getFourth();
// (e.g., the shape of the given query is not a point or rectangle. // Then, we may need to apply the select again using the real polygon, not MBR of it to get the true // result, not a super-set of it.) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); // Does the given index can cover all search predicates? boolean doesSIdxSearchCoverAllPredicates; // matched function expressions List<IOptimizableFuncExpr> matchedFuncExprs = analysisCtx.getMatchedFuncExprs(); // If no-index-only option is given, we stop here to honor that request. boolean noIndexOnlyPlanOption = getNoIndexOnlyOption(context); if (noIndexOnlyPlanOption) { indexOnlyPlanInfo.setFirst(isIndexOnlyPlan); return; } // logical variables that select (join) operator is using List<LogicalVariable> usedVarsInSelJoinOp = new ArrayList<>(); List<LogicalVariable> usedVarsInSelJoinOpTemp = new ArrayList<>(); // live variables that select (join) operator can access
|| funcExpr.getFunctionIdentifier() == BuiltinFunctions.FULLTEXT_CONTAINS_WO_OPTION) { boolean matches = AccessMethodUtils.analyzeFuncExprArgsForOneConstAndVarAndUpdateAnalysisCtx(funcExpr, analysisCtx, context, typeEnvironment); if (!matches) { matches = AccessMethodUtils.analyzeFuncExprArgsForTwoVarsAndUpdateAnalysisCtx(funcExpr, analysisCtx); } return matches; } return analyzeGetItemFuncExpr(funcExpr, assignsAndUnnests, analysisCtx); } public boolean analyzeGetItemFuncExpr(AbstractFunctionCallExpression funcExpr, List<AbstractLogicalOperator> assignsAndUnnests, AccessMethodAnalysisContext analysisCtx) throws AlgebricksException { if (funcExpr.getFunctionIdentifier() != BuiltinFunctions.GET_ITEM) { return false; } ILogicalExpression arg1 = funcExpr.getArguments().get(0).getValue(); ILogicalExpression arg2 = funcExpr.getArguments().get(1).getValue(); // The second arg is the item index to be accessed. It must be a constant. if (arg2.getExpressionTag() != LogicalExpressionTag.CONSTANT) { return false; } // The first arg must be a variable or a function expr.
// (E.g. There are index-nested-loop-joins in the plan.) private List<Mutable<ILogicalOperator>> ixJoinOuterAdditionalDataSourceRefs = null; private List<DataSourceType> ixJoinOuterAdditionalDataSourceTypes = null; private List<Dataset> ixJoinOuterAdditionalDatasets = null; private List<ARecordType> ixJoinOuterAdditionalRecordTypes = null; /** * Identifies the root of the subtree and initializes the data-source, assign, and unnest information. */ public boolean initFromSubTree(Mutable<ILogicalOperator> subTreeOpRef) throws AlgebricksException { reset(); rootRef = subTreeOpRef; root = subTreeOpRef.getValue(); boolean passedSource = false; boolean result = false; Mutable<ILogicalOperator> searchOpRef = subTreeOpRef; // Examine the op's children to match the expected patterns. AbstractLogicalOperator subTreeOp = (AbstractLogicalOperator) searchOpRef.getValue(); MetadataProvider metadataProvider = (MetadataProvider) context.getMetadataProvider(); do { // Skips the limit operator. if (subTreeOp.getOperatorTag() == LogicalOperatorTag.LIMIT) {
// object creation: should be relatively low btreeCursors = new ITreeIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; bloomFilters = new BloomFilter[numBTrees]; } includeMutableComponent = false; for (int i = 0; i < numBTrees; i++) { ILSMComponent component = operationalComponents.get(i); BTree btree = (BTree) component.getIndex(); if (component.getType() == LSMComponentType.MEMORY) { includeMutableComponent = true; bloomFilters[i] = null; } else { bloomFilters[i] = ((LSMBTreeWithBloomFilterDiskComponent) component).getBloomFilter(); } if (btreeAccessors[i] == null) { btreeAccessors[i] = btree.createAccessor(NoOpIndexAccessParameters.INSTANCE); btreeCursors[i] = btreeAccessors[i].createPointCursor(false); } else { // re-use btreeAccessors[i].reset(btree, NoOpOperationCallback.INSTANCE, NoOpOperationCallback.INSTANCE); btreeCursors[i].close(); } } nextHasBeenCalled = false; foundTuple = false; } @Override public void next() throws HyracksDataException { nextHasBeenCalled = true;
// object creation: should be relatively low btreeCursors = new ITreeIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; bloomFilters = new BloomFilter[numBTrees]; } includeMutableComponent = false; for (int i = 0; i < numBTrees; i++) { ILSMComponent component = operationalComponents.get(i); BTree btree = (BTree) component.getIndex(); if (component.getType() == LSMComponentType.MEMORY) { includeMutableComponent = true; bloomFilters[i] = null; } else { bloomFilters[i] = ((LSMBTreeWithBloomFilterDiskComponent) component).getBloomFilter(); } if (btreeAccessors[i] == null) { btreeAccessors[i] = btree.createAccessor(NoOpIndexAccessParameters.INSTANCE); btreeCursors[i] = btreeAccessors[i].createPointCursor(false); } else { // re-use btreeAccessors[i].reset(btree, NoOpOperationCallback.INSTANCE, NoOpOperationCallback.INSTANCE); btreeCursors[i].close(); } } nextHasBeenCalled = false; foundTuple = false; } @Override public void next() throws HyracksDataException { nextHasBeenCalled = true;
public int compare(ReferenceEntry tp1, ReferenceEntry tp2) { int[] tPointers1 = tp1.getTPointers(); int[] tPointers2 = tp2.getTPointers(); int cmp = NormalizedKeyUtils.compareNormalizeKeys(tPointers1, 0, tPointers2, 0, normalizedKeyLength); if (cmp != 0 || normalizedKeyDecisive) { return cmp; } IFrameTupleAccessor fta1 = tp1.getAccessor(); IFrameTupleAccessor fta2 = tp2.getAccessor(); byte[] b1 = fta1.getBuffer().array(); byte[] b2 = fta2.getBuffer().array(); for (int f = 0; f < sortFields.length; ++f) { int c; try { c = comparators[f].compare(b1, tPointers1[2 * f + normalizedKeyLength], tPointers1[2 * f + normalizedKeyLength + 1], b2, tPointers2[2 * f + normalizedKeyLength], tPointers2[2 * f + normalizedKeyLength + 1]); if (c != 0) { return c; } } catch (HyracksDataException e) {
flushAndWaitForIO(dsInfo, iInfo); } } } private void closeDataset(DatasetInfo dsInfo) throws HyracksDataException { // First wait for any ongoing IO operations synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { throw HyracksDataException.create(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values());
if (op2.getOperatorTag() == LogicalOperatorTag.DATASOURCESCAN) { DataSourceScanOperator scan = (DataSourceScanOperator) op2; int n = scan.getVariables().size(); LogicalVariable scanRecordVar = scan.getVariables().get(n - 1); IDataSource<DataSourceId> dataSource = (IDataSource<DataSourceId>) scan.getDataSource(); byte dsType = ((DataSource) dataSource).getDatasourceType(); if (dsType != DataSource.Type.INTERNAL_DATASET && dsType != DataSource.Type.EXTERNAL_DATASET) { return false; } DataSourceId asid = dataSource.getId(); MetadataProvider mp = (MetadataProvider) context.getMetadataProvider(); Dataset dataset = mp.findDataset(asid.getDataverseName(), asid.getDatasourceName()); if (dataset == null) { throw new AlgebricksException("Dataset " + asid.getDatasourceName() + " not found."); } if (dataset.getDatasetType() != DatasetType.INTERNAL) { setAsFinal(access, context, finalAnnot); return false; } String tName = dataset.getItemTypeName();
buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); if (oldValueSize > 0) { buffer.putInt(oldValueSize); buffer.putInt(oldValueFieldCount); writeTuple(buffer, oldValue, oldValueSize); } break; case LogType.FILTER: writeEntityResource(buffer); buffer.putLong(resourceId); buffer.putInt(logSize); buffer.putInt(newValueFieldCount); buffer.put(newOp); buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); break; case LogType.FLUSH: buffer.putInt(datasetId); break; case LogType.MARKER: buffer.putInt(datasetId); buffer.putInt(resourcePartition); callback.before(buffer); buffer.putInt(logSize); buffer.put(marker); break; default: // Do nothing }
* software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.common.api; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.hyracks.storage.common.IModificationOperationCallback; public interface IExtendedModificationOperationCallback extends IModificationOperationCallback { /** * Called after the action taken in found, to take action on a tuple that is not part of the index * itself but is part of an ancillary structure that is updated alongside the index. An example would * be a simple statistic on the index that records the minimum and maximum values. * * @param after The tuple to feed to the ancilliary structure * @throws HyracksDataException */ void after(ITupleReference after) throws HyracksDataException; }
public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { return createAccessor(createOpContext((IExtendedModificationOperationCallback) iap.getModificationCallback(), iap.getSearchOperationCallback()));
public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { return createAccessor(createOpContext((IExtendedModificationOperationCallback) iap.getModificationCallback(), iap.getSearchOperationCallback()));
if (minTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); minTupleBytes = new byte[numBytes]; opCallback.after(tuple); logged = true; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); minTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, minTuple); if (c < 0) { if (!logged) { opCallback.after(tuple); logged = true; } int numBytes = tupleWriter.bytesRequired(tuple); if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple);
if (minTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); minTupleBytes = new byte[numBytes]; opCallback.after(tuple); logged = true; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); minTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, minTuple); if (c < 0) { if (!logged) { opCallback.after(tuple); logged = true; } int numBytes = tupleWriter.bytesRequired(tuple); if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple);
if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if (!logged) { opCallback.after(tuple); logged = true; } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if(!logged) { opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) {
minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if(!logged) { opCallback.after(tuple); } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if(!logged) { opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) { maxTupleBytes = new byte[numBytes];
int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if(!logged) { opCallback.after(tuple); logged = true; } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if (!logged) { opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) { maxTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); } else { tupleWriter.writeTuple(tuple, maxTupleBytes, 0); } ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } } } @Override public ITupleReference getMinTuple() { return minTuple; } @Override
return new LSMInvertedIndexAccessor(getHarness(), createOpContext((IExtendedModificationOperationCallback) (iap.getModificationCallback()), iap.getSearchOperationCallback())); } @Override protected LSMInvertedIndexOpContext createOpContext(IExtendedModificationOperationCallback modificationCallback, ISearchOperationCallback searchCallback) throws HyracksDataException { return new LSMInvertedIndexOpContext(this, memoryComponents, modificationCallback, searchCallback, invertedIndexFieldsForNonBulkLoadOps, filterFieldsForNonBulkLoadOps, getFilterCmpFactories(), tracer); } @Override public ITypeTraits[] getInvListTypeTraits() { return invListTypeTraits; } @Override public IBinaryComparatorFactory[] getInvListCmpFactories() { return invListCmpFactories; } @Override public ITypeTraits[] getTokenTypeTraits() { return tokenTypeTraits; } @Override public IBinaryComparatorFactory[] getTokenCmpFactories() { return tokenCmpFactories; }
public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { LSMRTreeOpContext opCtx = createOpContext(((IExtendedModificationOperationCallback) iap.getModificationCallback()), iap.getSearchOperationCallback()); return new LSMTreeIndexAccessor(getHarness(), opCtx, cursorFactory);
public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { LSMRTreeOpContext opCtx = createOpContext(((IExtendedModificationOperationCallback) iap.getModificationCallback()), iap.getSearchOperationCallback()); return new LSMTreeIndexAccessor(getHarness(), opCtx, cursorFactory);
public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { LSMRTreeOpContext opCtx = createOpContext((IExtendedModificationOperationCallback) iap.getModificationCallback(), iap.getSearchOperationCallback()); return new LSMTreeIndexAccessor(getHarness(), opCtx, cursorFactory);
// may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker. flushAndWaitForIO(dsInfo, iInfo); } } } private void closeDataset(DatasetInfo dsInfo) throws HyracksDataException { // First wait for any ongoing IO operations synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsr, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException {
// may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker. flushAndWaitForIO(dsInfo, iInfo); } } } private void closeDataset(DatasetInfo dsInfo) throws HyracksDataException { // First wait for any ongoing IO operations synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsr, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException {
} catch (HyracksDataException e) { datasetLifecycleManager.close(localResource.getPath()); throw e; } //#. set resourceId and maxDiskLastLSN to the map resourceId2MaxLSNMap.put(resourceId, maxDiskLastLsn); } else { maxDiskLastLsn = resourceId2MaxLSNMap.get(resourceId); } } } break; case LogType.JOB_COMMIT: case LogType.ENTITY_COMMIT: case LogType.ABORT: case LogType.FLUSH: case LogType.WAIT: case LogType.MARKER: //do nothing break; default: throw new ACIDException("Unsupported LogType: " + logRecord.getLogType()); } logRecord = logReader.next(); } LOGGER.info("Logs REDO phase completed. Redo logs count: " + redoCount); } finally {
int numBytes = tupleWriter.bytesRequired(tuple); minTupleBytes = new byte[numBytes]; opCallback.after(tuple); logged = true; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); minTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, minTuple); if (c < 0) { opCallback.after(tuple); logged = true; int numBytes = tupleWriter.bytesRequired(tuple); if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple);
minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if (!logged) { opCallback.after(tuple); } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if (!logged) { opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) { maxTupleBytes = new byte[numBytes];
return pin(dpid, newPage, null); } @Override public ICachedPage pin(long dpid, boolean newPage, ILargePageHelper helper) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; }
return pin(dpid, newPage, null); } @Override public ICachedPage pin(long dpid, boolean newPage, ILargePageHelper helper) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; }
return pin(dpid, newPage, null); } @Override public ICachedPage pin(long dpid, boolean newPage, ILargePageHelper helper) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; }
return null; } }); } for(int i=0;i<bufferCacheNumPages;i++){ synchronized (readers[i]){ while(readers[i].getValue() == null){ readers[i].wait(); } } } final long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start < duration){ for(int i=0;i<bufferCacheNumPages;i++){ readers[i].getValue().interrupt(); } Thread.sleep(25); // NOSONAR Sleep so some reads are successful } try { for (int i = 0; i < bufferCacheNumPages; i++) { futures[i].get(); } } finally { bufferCache.deleteFile(fileId); bufferCache.close(); } } @Test public void simpleOpenPinCloseTest() throws HyracksException { TestStorageManagerComponentHolder.init(PAGE_SIZE, NUM_PAGES, MAX_OPEN_FILES); IBufferCache bufferCache = TestStorageManagerComponentHolder.getBufferCache(ctx.getJobletContext().getServiceContext()); IIOManager ioManager = TestStorageManagerComponentHolder.getIOManager(); String fileName = getFileName(); FileReference file = ioManager.resolve(fileName);
this.btreePred = (RangePredicate) searchPred; btreeAccessor.search(btreeCursor, btreePred); openInvListRangeSearchCursor(); } @Override public boolean hasNext() throws HyracksDataException { // No more results possible if (!isInvListCursorOpen) { return false; } if (invListRangeSearchCursor.hasNext()) { return true; } // The current inverted-list-range-search cursor is exhausted. invListRangeSearchCursor.close(); isInvListCursorOpen = false; openInvListRangeSearchCursor(); return isInvListCursorOpen; } @Override public void next() throws HyracksDataException { invListRangeSearchCursor.next(); if (concatTuple.hasMaxTuples()) { concatTuple.removeLastTuple(); } concatTuple.addTuple(invListRangeSearchCursor.getTuple()); } @Override public void destroy() throws HyracksDataException { if (isInvListCursorOpen) { invListRangeSearchCursor.unloadPages(); invListRangeSearchCursor.destroy(); isInvListCursorOpen = false; } btreeCursor.destroy(); } @Override
// Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } pageReplacementStrategy.notifyCachePageAccess(cPage); if(DEBUG){ pinnedPageOwner.put((CachedPage) cPage, Thread.currentThread().getStackTrace()); } cPage.setLargePageHelper(helper);
// Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } pageReplacementStrategy.notifyCachePageAccess(cPage); if(DEBUG){ pinnedPageOwner.put((CachedPage) cPage, Thread.currentThread().getStackTrace()); } cPage.setLargePageHelper(helper);
// Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } pageReplacementStrategy.notifyCachePageAccess(cPage); if(DEBUG){ pinnedPageOwner.put((CachedPage) cPage, Thread.currentThread().getStackTrace()); } cPage.setLargePageHelper(helper);
pageReplacementStrategy.notifyCachePageAccess(cPage); return cPage; } cPage = cPage.next; } } finally { bucket.bucketLock.unlock(); } return cPage; } @Override public ICachedPage pin(long dpid, boolean newPage) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally { confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage); cPage.valid = true; } } } else {
pageReplacementStrategy.notifyCachePageAccess(cPage); return cPage; } cPage = cPage.next; } } finally { bucket.bucketLock.unlock(); } return cPage; } @Override public ICachedPage pin(long dpid, boolean newPage) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally { confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage); cPage.valid = true; } } } else {
* "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.common; import java.io.File; import java.text.SimpleDateFormat; import java.util.ArrayList; import java.util.Date; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Random; import org.apache.commons.lang3.mutable.Mutable; import org.apache.commons.lang3.mutable.MutableObject; import org.apache.hyracks.api.context.IHyracksTaskContext; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.api.exceptions.HyracksException; import org.apache.hyracks.api.io.FileReference; import org.apache.hyracks.api.io.IIOManager; import org.apache.hyracks.storage.common.buffercache.CachedPage; import org.apache.hyracks.storage.common.buffercache.IBufferCache; import org.apache.hyracks.storage.common.buffercache.ICachedPage; import org.apache.hyracks.storage.common.file.BufferedFileHandle;
} this.writer = writer; } @Override public void setInputRecordDescriptor(int index, RecordDescriptor recordDescriptor) { // input is not accessed } @Override public void open() throws HyracksDataException { if (idx == 0) { writer.open(); } } @Override public void nextFrame(ByteBuffer buffer) throws HyracksDataException { writer.nextFrame(buffer); } @Override public void fail() throws HyracksDataException { boolean failed = failedShared.getValue(); failedShared.setValue(Boolean.TRUE); if (!failed) { writer.fail(); } } @Override public void close() throws HyracksDataException { if (idx == 0) { writer.close(); } } } }
int n = subplans.size(); AlgebricksPipeline[] result = new AlgebricksPipeline[n]; for (int i = 0; i < n; i++) { List<AlgebricksPipeline> subplanOps = subplans.get(i); if (subplanOps.size() != 1) { throw new AlgebricksException("Attempting to construct a nested plan with " + subplanOps.size() + " operator descriptors. Currently, nested plans can only consist in linear pipelines of " + "Asterix micro operators."); } result[i] = subplanOps.get(0); } return result; } protected List<List<AlgebricksPipeline>> compileSubplansImpl(IOperatorSchema outerPlanSchema, AbstractOperatorWithNestedPlans npOp, IOperatorSchema opSchema, JobGenContext context) throws AlgebricksException { List<List<AlgebricksPipeline>> subplans = new ArrayList<>(npOp.getNestedPlans().size()); PlanCompiler pc = new PlanCompiler(context); for (ILogicalPlan p : npOp.getNestedPlans()) { subplans.add(buildPipelineWithProjection(p, outerPlanSchema, npOp, opSchema, pc)); } return subplans; }
context.getTypeEnvironment(op.getInputs().get(0).getValue()), inputSchemas[0], context); IMissingWriterFactory[] missingWriterFactories = new IMissingWriterFactory[np.get(0).getOutputWidth()]; for (int i = 0; i < missingWriterFactories.length; i++) { missingWriterFactories[i] = context.getMissingWriterFactory(); } RecordDescriptor recDesc = JobGenHelper.mkRecordDescriptor(context.getTypeEnvironment(op), opSchema, context); SubplanRuntimeFactory runtime = new SubplanRuntimeFactory(np, missingWriterFactories, inputRecordDesc, recDesc, null); builder.contributeMicroOperator(subplan, runtime, recDesc); ILogicalOperator src = op.getInputs().get(0).getValue(); builder.contributeGraphEdge(src, 0, op, 0); } @Override public boolean expensiveThanMaterialization() { return true; } }
public void setInputRecordDescriptor(int index, RecordDescriptor recordDescriptor) { // input is not accessed
return useConnectorPolicyForScheduling; } public void setUseConnectorPolicyForScheduling(boolean useConnectorPolicyForScheduling) { this.useConnectorPolicyForScheduling = useConnectorPolicyForScheduling; } public void setRequiredClusterCapacity(IClusterCapacity capacity) { this.requiredClusterCapacity = capacity; } public IClusterCapacity getRequiredClusterCapacity() { return requiredClusterCapacity; } public void setMetaOps(List<? extends IOperatorDescriptor> metaOps) { this.metaOps = metaOps; } public List<IOperatorDescriptor> getMetaOps() { return metaOps; } private <K, V> void insertIntoIndexedMap(Map<K, List<V>> map, K key, int index, V value) { List<V> vList = map.computeIfAbsent(key, k -> new ArrayList<>()); extend(vList, index); vList.set(index, value); } @Override public String toString() { StringBuilder buffer = new StringBuilder(); opMap.forEach((key, value) -> { buffer.append(key.getId()).append(" : ").append(value.toString()).append("\n");
* * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.ipc.impl; import org.apache.hyracks.ipc.api.IIPCEventListener; public class NoOpIPCEventListener implements IIPCEventListener { public static final IIPCEventListener INSTANCE = new NoOpIPCEventListener(); private NoOpIPCEventListener() { } }
return new BloomFilterBuilder(numElements, numHashes, numBitsPerElement); } public class BloomFilterBuilder implements IIndexBulkLoader { private final long[] hashes = BloomFilter.createHashArray(); private final long numElements; private final int numHashes; private final long numBits; private final int numPages; private final IFIFOPageQueue queue; private final ICachedPage[] pages; private ICachedPage metaDataPage = null; public BloomFilterBuilder(long estimatedNumElemenets, int numHashes, int numBitsPerElement) throws HyracksDataException { if (!isActivated) { throw HyracksDataException.create(ErrorCode.CANNOT_CREATE_BLOOM_FILTER_BUILDER_FOR_INACTIVE_FILTER); } queue = bufferCache.createFIFOQueue(); this.numElements = numElements; this.numHashes = numHashes; numBits = this.numElements * numBitsPerElement; long tmp = (long) Math.ceil(numBits / (double) numBitsPerPage); if (tmp > Integer.MAX_VALUE) { throw HyracksDataException.create(ErrorCode.CANNOT_CREATE_BLOOM_FILTER_WITH_NUMBER_OF_PAGES, tmp); } numPages = (int) tmp; pages = new ICachedPage[numPages];
import org.apache.hyracks.tests.util.NoOpOperatorDescriptor; import org.junit.Assert; import org.junit.Test; public class JobFailureTest extends AbstractMultiNCIntegrationTest { @Test public void failureOnCreatePushRuntime() throws Exception { JobId jobId = null; for (int i = 0; i < 20; i++) { JobSpecification spec = new JobSpecification(); JobId runJobId = runTest(spec, new ExceptionOnCreatePushRuntimeOperatorDescriptor(spec, 0, 1, new int[] { 4 }, true)); if (i == 0) { jobId = runJobId; // passes. read from job archive waitForCompletion(jobId, ExceptionOnCreatePushRuntimeOperatorDescriptor.ERROR_MESSAGE); } } // passes. read from job history waitForCompletion(jobId, ExceptionOnCreatePushRuntimeOperatorDescriptor.ERROR_MESSAGE); for (int i = 0; i < 300; i++) { JobSpecification spec = new JobSpecification(); runTest(spec, new ExceptionOnCreatePushRuntimeOperatorDescriptor(spec, 0, 1, new int[] { 4 }, true)); } // passes. history has been cleared
* software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.api.http.server; import java.util.Map; import java.util.UUID; import java.util.concurrent.ConcurrentMap; import java.util.concurrent.TimeUnit; import java.util.concurrent.TimeoutException; import java.util.function.Function; import org.apache.asterix.algebra.base.ILangExtension; import org.apache.asterix.app.message.CancelQueryRequest; import org.apache.asterix.app.message.ExecuteStatementRequestMessage; import org.apache.asterix.app.message.ExecuteStatementResponseMessage; import org.apache.asterix.app.result.ResultReader; import org.apache.asterix.common.api.Duration; import org.apache.asterix.common.api.IApplicationContext; import org.apache.asterix.common.config.GlobalConfig; import org.apache.asterix.common.exceptions.ErrorCode; import org.apache.asterix.common.exceptions.ExceptionUtils; import org.apache.asterix.common.exceptions.RuntimeDataException; import org.apache.asterix.common.messaging.api.INCMessageBroker;
channel.abort(); } finally { channel.close(); resultState.readClose(); // if resultState has been exhausted, delete the result partition if (resultState.isExhausted()) { datasetPartitionManager.removePartition(resultState.getResultSetPartitionId().getJobId(), resultState.getResultSetPartitionId().getResultSetId(), resultState.getResultSetPartitionId().getPartition()); } } } catch (HyracksDataException e) { LOGGER.error("unexpected failure in partition reader", e); } if (LOGGER.isDebugEnabled()) { LOGGER.debug("result reading successful(" + resultState.getResultSetPartitionId() + ")"); }
* specific language governing permissions and limitations * under the License. */ package org.apache.asterix.translator; import java.util.Map; import org.apache.asterix.translator.IStatementExecutor.Stats; import org.apache.hyracks.api.dataset.IHyracksDataset; public interface IRequestParameters { /** * @return A Hyracks dataset client object that is used to read the results. */ IHyracksDataset getHyracksDataset(); /** * Gets the required result properties of the request. * * @return the result properties */ ResultProperties getResultProperties(); /** * @return a reference to write the stats of executed queries */ Stats getStats(); /** * @return a reference to write the metadata of executed queries */ IStatementExecutor.ResultMetadata getOutMetadata(); /** * @return the client context id for the query */ String getClientContextId(); /** * @return Optional request parameters. Otherwise null. */ Map<String, String> getOptionalParameters(); }
* "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.common.api; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.hyracks.storage.common.IIndexCursor; public interface ILSMIndexCursor extends IIndexCursor { /** * @return the min tuple of the corresponding component's filter */ ITupleReference getFilterMinTuple(); /** * * @return the max tuple of the current index's filter */ ITupleReference getFilterMaxTuple(); }
* * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.common.api; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.hyracks.storage.common.IIndexCursor; public interface ILSMIndexCursor extends IIndexCursor { /** * @return the min tuple of the current index's filter */ ITupleReference getFilterMinTuple(); /** * * @return the max tuple of the current index's filter */ ITupleReference getFilterMaxTuple(); }
AbstractLogicalOperator op2 = (AbstractLogicalOperator) opRef2.getValue(); // If it's not an indexed field, it is pushed so that scan can be // rewritten into index search. if (op2.getOperatorTag() == LogicalOperatorTag.PROJECT || context.checkAndAddToAlreadyCompared(access, op2) && !(op2.getOperatorTag() == LogicalOperatorTag.SELECT && isAccessToIndexedField(access, context))) { return false; } Object annotation = op2.getAnnotations().get("isMovable"); if (annotation != null && !((Boolean) annotation)) { return false; } if (tryingToPushThroughSelectionWithSameDataSource(access, op2)) { return false; } if (testAndModifyRedundantOp(access, op2)) { propagateFieldAccessRec(opRef2, context, finalAnnot); return true; } List<LogicalVariable> usedInAccess = new LinkedList<>(); VariableUtilities.getUsedVariables(access, usedInAccess); List<LogicalVariable> produced2 = new LinkedList<>(); if (op2.getOperatorTag() == LogicalOperatorTag.GROUP) { VariableUtilities.getLiveVariables(op2, produced2);
import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalOperator; import org.apache.hyracks.algebricks.core.algebra.base.LogicalVariable; import org.apache.hyracks.algebricks.core.algebra.properties.VariablePropagationPolicy; import org.apache.hyracks.algebricks.core.algebra.visitors.ILogicalExpressionReferenceTransform; public abstract class AbstractBinaryJoinOperator extends AbstractLogicalOperator { protected final Mutable<ILogicalExpression> condition; protected JoinKind joinKind; public enum JoinKind { INNER, LEFT_OUTER } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition) { this.joinKind = joinKind; this.condition = condition; this.phaseToInput = new HashMap<>(); phaseToInput.put(0,1); phaseToInput.put(1,0); } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition, Mutable<ILogicalOperator> input1, Mutable<ILogicalOperator> input2) { this(joinKind, condition);
import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalOperator; import org.apache.hyracks.algebricks.core.algebra.base.LogicalVariable; import org.apache.hyracks.algebricks.core.algebra.properties.VariablePropagationPolicy; import org.apache.hyracks.algebricks.core.algebra.visitors.ILogicalExpressionReferenceTransform; public abstract class AbstractBinaryJoinOperator extends AbstractLogicalOperator { protected final Mutable<ILogicalExpression> condition; protected JoinKind joinKind; public enum JoinKind { INNER, LEFT_OUTER } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition) { this.joinKind = joinKind; this.condition = condition; this.phaseToInput = new HashMap<>(); phaseToInput.put(0,1); phaseToInput.put(1,0); } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition, Mutable<ILogicalOperator> input1, Mutable<ILogicalOperator> input2) { this(joinKind, condition); inputs.add(input1); inputs.add(input2); }
if (connection != null) { inp.put("input", connection.getLeft().getLeft().getOperatorId().toString()); } } } if (pleObject.size() > 0) { pcObject.set("location", pleObject); } if (pcObject.size() > 0) { op.set("partition-constraints", pcObject); } } jopArray.add(op); }); jjob.set("operators", jopArray); ArrayNode jcArray = om.createArrayNode(); connMap.forEach((key, value) -> { ObjectNode conn = om.createObjectNode(); Pair<Pair<IOperatorDescriptor, Integer>, Pair<IOperatorDescriptor, Integer>> connection = connectorOpMap.get(key); if (connection != null) { conn.put("in-operator-id", connection.getLeft().getLeft().getOperatorId().toString()); conn.put("in-operator-port", connection.getLeft().getRight().intValue());
} } return false; } /** * Executes the passed interruptible, retrying if the operation fails due to {@link ClosedByInterruptException}. * Once the interruptible completes, the current thread will be re-interrupted, if the original operation was * interrupted. */ public static void doIoUninterruptibly(ThrowingIOInterruptible interruptible) throws IOException { boolean interrupted = false; try { while (true) { try { interruptible.run(); break; } catch (ClosedByInterruptException | InterruptedException e) { LOGGER.error("IO operation Interrupted. Retrying..", e); interrupted = true; Thread.interrupted(); } } } finally { if (interrupted) { Thread.currentThread().interrupt(); } } } @FunctionalInterface public interface Interruptible { void run() throws InterruptedException; } @FunctionalInterface public interface ThrowingInterruptible { void run() throws Exception; // NOSONAR } @FunctionalInterface public interface ThrowingIOInterruptible { void run() throws IOException; } }
} catch (ClosedByInterruptException e) { LOGGER.error("IO operation Interrupted. Retrying..", e); interrupted = true; Thread.interrupted(); } } } finally { if (interrupted) { Thread.currentThread().interrupt(); } } } @FunctionalInterface public interface Interruptible { void run() throws InterruptedException; } @FunctionalInterface public interface ThrowingInterruptible { void run() throws Exception; // NOSONAR } @FunctionalInterface public interface ThrowingIOInterruptible { void run() throws IOException, InterruptedException; } }
if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Substitute node joining : " + serviceContext.getNodeId()); } updateOnNodeJoin(); } appContext.initialize(initialRun); MessagingProperties messagingProperties = ((IPropertiesProvider) appContext).getMessagingProperties(); messageBroker = new NCMessageBroker(controllerService, messagingProperties); serviceContext.setMessageBroker(messageBroker); MessagingChannelInterfaceFactory interfaceFactory = new MessagingChannelInterfaceFactory((NCMessageBroker) messageBroker, messagingProperties); this.ncServiceCtx.setMessagingChannelInterfaceFactory(interfaceFactory); boolean replicationEnabled = ClusterProperties.INSTANCE.isReplicationEnabled(); boolean autoFailover = ClusterProperties.INSTANCE.isAutoFailoverEnabled(); if (initialRun) { LOGGER.info("System is being initialized. (first run)"); } else { IRecoveryManager recoveryMgr = appContext.getTransactionSubsystem().getRecoveryManager(); systemState = recoveryMgr.getSystemState(); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("System is in a state: " + systemState); } //do not attempt to perform remote recovery if this is a virtual NC if (autoFailover && !virtualNC) {
if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Substitute node joining : " + serviceContext.getNodeId()); } updateOnNodeJoin(); } appContext.initialize(initialRun); MessagingProperties messagingProperties = ((IPropertiesProvider) appContext).getMessagingProperties(); messageBroker = new NCMessageBroker(controllerService, messagingProperties); serviceContext.setMessageBroker(messageBroker); MessagingChannelInterfaceFactory interfaceFactory = new MessagingChannelInterfaceFactory((NCMessageBroker) messageBroker, messagingProperties); this.ncServiceCtx.setMessagingChannelInterfaceFactory(interfaceFactory); boolean replicationEnabled = ClusterProperties.INSTANCE.isReplicationEnabled(); boolean autoFailover = ClusterProperties.INSTANCE.isAutoFailoverEnabled(); if (initialRun) { LOGGER.info("System is being initialized. (first run)"); } else { IRecoveryManager recoveryMgr = appContext.getTransactionSubsystem().getRecoveryManager(); systemState = recoveryMgr.getSystemState(); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("System is in a state: " + systemState); } //do not attempt to perform remote recovery if this is a virtual NC if (autoFailover && !virtualNC) {
int n = subplans.size(); AlgebricksPipeline[] result = new AlgebricksPipeline[n]; for (int i = 0; i < n; i++) { List<AlgebricksPipeline> subplanOps = subplans.get(i); if (subplanOps.size() != 1) { throw new AlgebricksException("Attempting to construct a nested plan with " + subplanOps.size() + " operator descriptors. Currently, nested plans can only consist in linear pipelines of " + "micro operators."); } result[i] = subplanOps.get(0); } return result; } protected List<List<AlgebricksPipeline>> compileSubplansImpl(IOperatorSchema outerPlanSchema, AbstractOperatorWithNestedPlans npOp, IOperatorSchema opSchema, JobGenContext context) throws AlgebricksException { List<List<AlgebricksPipeline>> subplans = new ArrayList<>(npOp.getNestedPlans().size()); PlanCompiler pc = new PlanCompiler(context); for (ILogicalPlan p : npOp.getNestedPlans()) { subplans.add(buildPipelineWithProjection(p, outerPlanSchema, npOp, opSchema, pc)); } return subplans; }
opSchema.addAllVariables(topOpInSubplanScm); Map<OperatorDescriptorId, IOperatorDescriptor> opMap = nestedJob.getOperatorMap(); List<? extends IOperatorDescriptor> metaOps = nestedJob.getMetaOps(); if (opMap.size() != metaOps.size()) { for (IOperatorDescriptor opd : opMap.values()) { if (!(opd instanceof AlgebricksMetaOperatorDescriptor)) { throw new AlgebricksException( "Can only generate jobs for pipelinable nested plans, not for " + opd .getClass().getName()); } } throw new IllegalStateException(); } List<AlgebricksPipeline> result = new ArrayList<>(metaOps.size()); for (IOperatorDescriptor opd : metaOps) { AlgebricksMetaOperatorDescriptor amod = (AlgebricksMetaOperatorDescriptor) opd; result.add(amod.getPipeline()); } return result; } }
Map<OperatorDescriptorId, IOperatorDescriptor> opMap = nestedJob.getOperatorMap(); List<? extends IOperatorDescriptor> metaOps = nestedJob.getMetaOps(); if (opMap.size() != metaOps.size()) { for (IOperatorDescriptor opd : opMap.values()) { if (!(opd instanceof AlgebricksMetaOperatorDescriptor)) { throw new AlgebricksException( "Can only generate Hyracks jobs for pipelinable Asterix nested plans, not for " + opd .getClass().getName()); } } throw new IllegalStateException("Unexpected nested plan"); } List<AlgebricksPipeline> result = new ArrayList<>(metaOps.size()); for (IOperatorDescriptor opd : metaOps) { AlgebricksMetaOperatorDescriptor amod = (AlgebricksMetaOperatorDescriptor) opd; result.add(amod.getPipeline()); } return result; } }
return true; } @Override public void contributeRuntimeOperator(IHyracksJobBuilder builder, JobGenContext context, ILogicalOperator op, IOperatorSchema opSchema, IOperatorSchema[] inputSchemas, IOperatorSchema outerPlanSchema) throws AlgebricksException { RecordDescriptor recordDescriptor = JobGenHelper.mkRecordDescriptor(context.getTypeEnvironment(op), opSchema, context); List<Mutable<ILogicalOperator>> inputs = op.getInputs(); int nInputs = inputs.size(); MicroUnionAllRuntimeFactory runtime = new MicroUnionAllRuntimeFactory(nInputs); builder.contributeMicroOperator(op, runtime, recordDescriptor); super.contributeRuntimeOperator(builder, context, op, opSchema, inputSchemas, outerPlanSchema); } }
RecordDescriptor pipelineLastRecordDescriptor = pipeline.getRecordDescriptors()[pipeline.getRecordDescriptors().length - 1]; RecordDescriptor outputRecordDescriptor; IFrameWriter outputWriter; if (i == 0) { // primary pipeline outputWriter = new TupleOuterProduct(pipelineLastRecordDescriptor, missingWriters); outputRecordDescriptor = SubplanRuntimeFactory.this.outputRecordDesc; } else { // secondary pipeline IPushRuntime outputPushRuntime = linkSecondaryPipeline(pipeline, pipelineAssemblers, i); if (outputPushRuntime == null) { throw new IllegalStateException("Invalid pipeline"); } outputPushRuntime.setInputRecordDescriptor(0, pipelineLastRecordDescriptor); outputWriter = outputPushRuntime; outputRecordDescriptor = pipelineLastRecordDescriptor; } PipelineAssembler pa = new PipelineAssembler(pipeline, 1, 1, inputRecordDesc, outputRecordDescriptor); startOfPipelines[i] = (NestedTupleSourceRuntime) pa.assemblePipeline(outputWriter, ctx); pipelineAssemblers[i] = pa; } } IPushRuntime linkSecondaryPipeline(AlgebricksPipeline pipeline, PipelineAssembler[] pipelineAssemblers, int pipelineAssemblersCount) { IPushRuntimeFactory[] outputRuntimeFactories = pipeline.getOutputRuntimeFactories();
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if (n > 0xff) { n >>>= 8; log |= 8; } if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if (n > 0xf) { n >>>= 4; log |= 4; } if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if (n > 3) { n >>>= 2; log |= 2; } return log+(n>>>1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log + (n >>> 1);
public Ini toIni(boolean includeDefaults) { Ini ini = new Ini(); (includeDefaults ? configurationMap : definedMap).forEach((option, value) -> { if (value != null) { ini.add(option.section().sectionName(), option.ini(), option.type().serializeToIni(value)); } }); nodeSpecificMap.forEach((key, nodeValueMap) -> { String section = Section.NC.sectionName() + "/" + key; synchronized (nodeValueMap) { for (Map.Entry<IOption, Object> entry : nodeValueMap.entrySet()) { if (entry.getValue() != null) { final IOption option = entry.getKey(); ini.add(section, option.ini(), option.type().serializeToIni(entry.getValue())); } } } }); extensionOptions.forEach((extension, options) -> { options.forEach(option -> ini .add(extension, option.getKey(), option.getValue())); }); return ini;
public void sendApplicationMessageToCC(byte[] data, DeploymentId deploymentId, String nodeId) throws Exception; public void registerResultPartitionLocation(JobId jobId, ResultSetId rsId, boolean orderedResult, boolean emptyResult, int partition, int nPartitions, NetworkAddress networkAddress) throws Exception; public void reportResultPartitionWriteCompletion(JobId jobId, ResultSetId rsId, int partition) throws Exception; public void reportResultPartitionFailure(JobId jobId, ResultSetId rsId, int partition, HyracksDataException cause) throws Exception; public void getNodeControllerInfos() throws Exception; public void notifyThreadDump(String nodeId, String threadDumpJSON) throws Exception; }
List<TaskAttemptDescriptor> taskDescriptors, Map<ConnectorDescriptorId, IConnectorPolicy> connectorPolicies, Set<JobFlag> flags, Map<String, byte[]> contextRuntTimeVarMap) throws Exception; public void abortTasks(JobId jobId, List<TaskAttemptId> tasks) throws Exception; public void cleanUpJoblet(JobId jobId, JobStatus status) throws Exception; public void reportPartitionAvailability(PartitionId pid, NetworkAddress networkAddress) throws Exception; public void deployBinary(DeploymentId deploymentId, List<URL> url) throws Exception; public void undeployBinary(DeploymentId deploymentId) throws Exception; public void dumpState(String stateDumpId) throws Exception; public void shutdown(boolean terminateNCService) throws Exception; public void sendApplicationMessageToNC(byte[] data, DeploymentId deploymentId, String nodeId) throws Exception; public void takeThreadDump(String requestId) throws Exception; }
throws HyracksDataException { this.ctx = ctx; this.treeIndexHelper = indexHelperFactory.create(ctx.getJobletContext().getServiceContext(), partition); this.searchCallbackFactory = searchCallbackFactory; } @Override public void initialize() throws HyracksDataException { treeIndexHelper.open(); try { try { writer.open(); FrameTupleAppender appender = new FrameTupleAppender(new VSizeFrame(ctx)); scan(appender); appender.write(writer, true); } catch (Throwable th) { writer.fail(); } catch (Throwable failFailure) {// NOSONAR: Must maintain all stacks failure = ExceptionUtils.suppress(failure, failFailure); } } finally { try { writer.close(); } } catch (Throwable th) { throw HyracksDataException.create(th); } } private void scan(FrameTupleAppender appender) throws IOException { ITreeIndex treeIndex = (ITreeIndex) treeIndexHelper.getIndexInstance(); LocalResource resource = treeIndexHelper.getResource(); ISearchOperationCallback searchCallback = searchCallbackFactory.createSearchOperationCallback(resource.getId(), ctx, null); IIndexAccessParameters iap = new IndexAccessParameters(NoOpOperationCallback.INSTANCE, searchCallback); ITreeIndexAccessor indexAccessor = (ITreeIndexAccessor) treeIndex.createAccessor(iap); try {
this.searchCallbackFactory = searchCallbackFactory; } @Override public void initialize() throws HyracksDataException { treeIndexHelper.open(); try { try { writer.open(); FrameTupleAppender appender = new FrameTupleAppender(new VSizeFrame(ctx)); scan(appender); appender.write(writer, true); } catch (Throwable th) { writer.fail(); throw HyracksDataException.create(th); } finally { writer.close(); } } } private void scan(FrameTupleAppender appender) throws IOException { ITreeIndex treeIndex = (ITreeIndex) treeIndexHelper.getIndexInstance(); LocalResource resource = treeIndexHelper.getResource(); ISearchOperationCallback searchCallback = searchCallbackFactory.createSearchOperationCallback(resource.getId(), ctx, null); IIndexAccessParameters iap = new IndexAccessParameters(NoOpOperationCallback.INSTANCE, searchCallback); ITreeIndexAccessor indexAccessor = (ITreeIndexAccessor) treeIndex.createAccessor(iap); try { doScan(treeIndex, indexAccessor, appender); } finally { indexAccessor.destroy(); } }
for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { filterTuples.add(mergeOp.getMergingComponents().get(i).getLSMComponentFilter().getMinTuple()); filterTuples.add(mergeOp.getMergingComponents().get(i).getLSMComponentFilter().getMaxTuple()); } getFilterManager().updateFilter(mergedComponent.getLSMComponentFilter(), filterTuples); getFilterManager().writeFilter(mergedComponent.getLSMComponentFilter(), mergedComponent.getMetadataHolder()); } componentBulkLoader.end(); return mergedComponent; } @Override public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { return new LSMRTreeAccessor(getHarness(), createOpContext(iap.getModificationCallback(), iap.getSearchOperationCallback()), buddyBTreeFields); } // This function is modified for R-Trees without antimatter tuples to allow buddy B-Tree to have only primary keys @Override public void modify(IIndexOperationContext ictx, ITupleReference tuple) throws HyracksDataException { LSMRTreeOpContext ctx = (LSMRTreeOpContext) ictx; if (ctx.getOperation() == IndexOperation.PHYSICALDELETE) {
public void resetNonIndexFieldsTuple(ITupleReference newValue) { tupleWithNonIndexFields.reset(newValue); } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; HyracksDataException failure = null; try { accessor.destroy(); } catch (HyracksDataException e) { failure = e; } finally { try { if (cursor != null) { cursor.destroy(); } } catch (Exception e) { throw HyracksDataException.suppress(failure, e); } } if (failure != null) { throw HyracksDataException.create(failure); } } }
public void resetNonIndexFieldsTuple(ITupleReference newValue) { tupleWithNonIndexFields.reset(newValue); } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; HyracksDataException failure = null; try { accessor.destroy(); } catch (HyracksDataException e) { failure = e; } finally { try { if (cursor != null) { cursor.destroy(); } } catch (Exception e) { throw HyracksDataException.suppress(failure, e); } } if (failure != null) { throw HyracksDataException.create(failure); } } }
builder.addField(diskTuple.getFieldData(i), diskTuple.getFieldStart(i), diskTuple.getFieldLength(i)); } } @Override public ITupleReference doGetTuple() { return outputTuple; } @Override public void doDestroy() throws HyracksDataException { Throwable failure = null; if (lsmHarness != null) { if (rangeCursors != null) { for (int i = 0; i < rangeCursors.length; i++) { try { rangeCursors[i].destroy(); } catch (Throwable th) { // NOSONAR. Must destroy all cursors failure = ExceptionUtils.suppress(failure, th); } } rangeCursors = null; } try { lsmHarness.endScanDiskComponents(opCtx); } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } } foundNext = false; if (failure != null) { throw HyracksDataException.create(failure); } } @Override protected void setPriorityQueueComparator() { if (pqCmp == null || cmp != pqCmp.getMultiComparator()) { pqCmp = new PriorityQueueScanComparator(cmp); } }
} @Override public void doDestroy() throws HyracksDataException { Throwable failure = null; if (lsmHarness != null) { if (rangeCursors != null) { for (int i = 0; i < rangeCursors.length; i++) { try { rangeCursors[i].destroy(); } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } } rangeCursors = null; } try { lsmHarness.endScanDiskComponents(opCtx); } catch (Throwable th) { // NOSONAR. Don't lose the root cause failure = ExceptionUtils.suppress(failure, th); } } foundNext = false; if (failure != null) { throw HyracksDataException.create(failure); } } @Override protected void setPriorityQueueComparator() { if (pqCmp == null || cmp != pqCmp.getMultiComparator()) { pqCmp = new PriorityQueueScanComparator(cmp); } } private class PriorityQueueScanComparator extends PriorityQueueComparator { public PriorityQueueScanComparator(MultiComparator cmp) { super(cmp); } @Override
* software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.lsm.common.util; import org.apache.hyracks.storage.am.common.api.IIndexOperationContext; import org.apache.hyracks.storage.common.IIndexAccessor; import org.apache.hyracks.storage.common.IIndexCursor; public class DestroyUtils { private DestroyUtils() { } public static <T extends IIndexOperationContext> Throwable destroy(T[] contexts) { Throwable failure = null; for (int i = 0; i < contexts.length; i++) { if (contexts[i] != null) { try { contexts[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexAccessor> Throwable destroy(T[] accessors) { Throwable failure = null;
package org.apache.hyracks.storage.am.lsm.common.util; import org.apache.hyracks.storage.am.common.api.IIndexOperationContext; import org.apache.hyracks.storage.common.IIndexAccessor; import org.apache.hyracks.storage.common.IIndexCursor; public class DestroyUtils { public static <T extends IIndexOperationContext> Throwable destroy(T[] contexts) { Throwable failure = null; for (int i = 0; i < contexts.length; i++) { if (contexts[i] != null) { try { contexts[i].destroy(); } catch (Throwable th) { // NOSONAR must destroy all if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexAccessor> Throwable destroy(T[] accessors) { Throwable failure = null; for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { try { accessors[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th;
} catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexAccessor> Throwable destroy(T[] accessors) { Throwable failure = null; for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { try { accessors[i].destroy(); } catch (Throwable th) { // NOSONAR must destroy all if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexCursor> Throwable destroy(T[] cursors) { Throwable failure = null; for (int i = 0; i < cursors.length; i++) { if (cursors[i] != null) { try { cursors[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else {
} catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexCursor> Throwable destroy(T[] cursors) { Throwable failure = null; for (int i = 0; i < cursors.length; i++) { if (cursors[i] != null) { try { cursors[i].destroy(); } catch (Throwable th) { // NOSONAR must destroy all if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } }
boolean abort = true; try { try { ISearchPredicate rtreeSearchPred = new SearchPredicate(null, null); ILSMIndexOperationContext opCtx = ((LSMRTreeSortedCursor) cursor).getOpCtx(); search(opCtx, cursor, rtreeSearchPred); try { mergedComponent = createDiskComponent(componentFactory, mergeOp.getTarget(), mergeOp.getBTreeTarget(), mergeOp.getBloomFilterTarget(), true); // In case we must keep the deleted-keys BTrees, then they must be merged // *before* merging the r-trees so that // lsmHarness.endSearch() is called once when the r-trees have been merged. if (mergeOp.getMergingComponents().get(mergeOp.getMergingComponents().size() - 1) != diskComponents .get(diskComponents.size() - 1)) { // Keep the deleted tuples since the oldest disk component is not included in the merge operation long numElements = 0L; for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { numElements += ((LSMRTreeDiskComponent) mergeOp.getMergingComponents().get(i))
// In case we must keep the deleted-keys BTrees, then they must be merged *before* merging the r-trees so that // lsmHarness.endSearch() is called once when the r-trees have been merged. if (mergeOp.getMergingComponents().get(mergeOp.getMergingComponents().size() - 1) != diskComponents .get(diskComponents.size() - 1)) { // Keep the deleted tuples since the oldest disk component // is not included in the merge operation long numElements = 0L; for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { numElements += ((LSMRTreeDiskComponent) mergeOp.getMergingComponents().get(i)) .getBloomFilter().getNumElements(); } componentBulkLoader = mergedComponent.createBulkLoader(1.0f, false, numElements, false, false, false); LSMRTreeDeletedKeysBTreeMergeCursor btreeCursor = new LSMRTreeDeletedKeysBTreeMergeCursor(opCtx); try { search(opCtx, btreeCursor, rtreeSearchPred); try { while (btreeCursor.hasNext()) {
} doOpen(initialState, searchPred); state = State.OPENED; if (STORE_TRACES) { openCallStack = new Throwable().getStackTrace(); } } protected void doOpen(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { // Do nothing } @Override public final boolean hasNext() throws HyracksDataException { if (ENFORCE_NEXT_HAS_NEXT && state != State.OPENED) { throw new IllegalStateException("Cannot call hasNext() on a cursor in the state " + state); } return doHasNext(); } protected boolean doHasNext() throws HyracksDataException { return false; } @Override public final void next() throws HyracksDataException { if (ENFORCE_NEXT_HAS_NEXT) { if (state != State.OPENED) { throw new IllegalStateException("Cannot call next() on a cursor in the state " + state); } } doNext(); } protected void doNext() throws HyracksDataException { // Do nothing } @Override
if (state != State.OPENED) { throw new IllegalStateException("Cannot call hasNext() on a cursor in the state " + state); } } return doHasNext(); } protected boolean doHasNext() throws HyracksDataException { return false; } @Override public final void next() throws HyracksDataException { if (ENFORCE_NEXT_HAS_NEXT && state != State.OPENED) { throw new IllegalStateException("Cannot call next() on a cursor in the state " + state); } doNext(); } protected void doNext() throws HyracksDataException { // Do nothing } @Override public final void destroy() throws HyracksDataException { if (ENFORCE_OPEN_CLOSE_DESTROY) { if (state == State.DESTROYED) { LOGGER.log(Level.WARN, "multiple cursor.destroy() call in " + Arrays.toString(new Throwable().getStackTrace())); return; } else if (state != State.CLOSED) { if (STORE_TRACES && openCallStack != null) {
private ByteBuffer buffer; private volatile long dpid; private int multiplier; private VirtualPage next; public VirtualPage(ByteBuffer buffer, int pageSize) { this.buffer = buffer; this.pageSize = pageSize; latch = new ReentrantReadWriteLock(true); dpid = -1; next = null;
public void acquireReadLatch() { latch.readLock().lock();
LOGGER.info("Disk-Order Scan:"); } ITreeIndexAccessor treeIndexAccessor = (ITreeIndexAccessor) indexAccessor; TreeIndexDiskOrderScanCursor diskOrderCursor = (TreeIndexDiskOrderScanCursor) treeIndexAccessor.createDiskOrderScanCursor(); try { treeIndexAccessor.diskOrderScan(diskOrderCursor); try { while (diskOrderCursor.hasNext()) { diskOrderCursor.next(); ITupleReference frameTuple = diskOrderCursor.getTuple(); String rec = TupleUtils.printTuple(frameTuple, fieldSerdes); LOGGER.info(rec); } } finally { diskOrderCursor.close(); } } finally { diskOrderCursor.destroy(); } } catch (UnsupportedOperationException e) { // Ignore exception because some indexes, e.g. the LSMRTree, don't // support disk-order scan. if (LOGGER.isInfoEnabled()) { LOGGER.info("Ignoring disk-order scan since it's not supported."); } } catch (ClassCastException e) { // Ignore exception because IIndexAccessor sometimes isn't // an ITreeIndexAccessor, e.g., for the LSMRTree.
Class<?> c = Class.forName(className); ncAppEntryPoint = (INCApplicationEntryPoint) c.newInstance(); String[] args = ncConfig.appArgs == null ? new String[0] : ncConfig.appArgs.toArray(new String[ncConfig.appArgs.size()]); ncAppEntryPoint.start(appCtx, args); } executor = Executors.newCachedThreadPool(appCtx.getThreadFactory()); } @Override public synchronized void stop() throws Exception { if (!shuttedDown) { LOGGER.log(Level.INFO, "Stopping NodeControllerService"); executor.shutdownNow(); if (!executor.awaitTermination(10, TimeUnit.SECONDS)) { LOGGER.log(Level.SEVERE, "Some jobs failed to exit, continuing shutdown abnormally"); } partitionManager.close(); datasetPartitionManager.close(); netManager.stop(); datasetNetworkManager.stop(); if (messagingNetManager != null) { messagingNetManager.stop(); } queue.stop(); if (ncAppEntryPoint != null) { ncAppEntryPoint.stop(); } /** * Stop heartbeat after NC has stopped to avoid false node failure detection
CCNCFunctions.NodeRegistrationResult nrrf = (CCNCFunctions.NodeRegistrationResult) fn; setNodeRegistrationResult(nrrf.getNodeParameters(), nrrf.getException()); return; case GET_NODE_CONTROLLERS_INFO_RESPONSE: CCNCFunctions.GetNodeControllersInfoResponseFunction gncirf = (CCNCFunctions.GetNodeControllersInfoResponseFunction) fn; setNodeControllersInfo(gncirf.getNodeControllerInfos()); return; case DEPLOY_BINARY: CCNCFunctions.DeployBinaryFunction dbf = (CCNCFunctions.DeployBinaryFunction) fn; queue.schedule(new DeployBinaryWork(NodeControllerService.this, dbf.getDeploymentId(), dbf.getBinaryURLs())); return; } case UNDEPLOY_BINARY: CCNCFunctions.UnDeployBinaryFunction ndbf = (CCNCFunctions.UnDeployBinaryFunction) fn; queue.schedule(new UnDeployBinaryWork(NodeControllerService.this, ndbf.getDeploymentId())); return; case STATE_DUMP_REQUEST: final CCNCFunctions.StateDumpRequestFunction dsrf = (StateDumpRequestFunction) fn; queue.schedule(new StateDumpWork(NodeControllerService.this, dsrf.getStateDumpId())); return; case SHUTDOWN_REQUEST: final CCNCFunctions.ShutdownRequestFunction sdrf = (CCNCFunctions.ShutdownRequestFunction) fn;
*/ package org.apache.hyracks.api.job; import java.io.DataInput; import java.io.DataOutput; import java.io.IOException; import java.io.Serializable; import org.apache.hyracks.api.control.CcId; import org.apache.hyracks.api.exceptions.ErrorCode; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.api.io.IWritable; public final class JobId implements IWritable, Serializable, Comparable { private static final int CC_BITS = Short.SIZE; private static final int ID_BITS = Long.SIZE - CC_BITS; static final long MAX_ID = (1L << ID_BITS) - 1; public static final JobId INVALID = null; private static final long serialVersionUID = 1L; private long id; private transient CcId ccId; public static JobId create(DataInput dis) throws IOException { JobId jobId = new JobId(); jobId.readFields(dis); return jobId; } private JobId() { } public JobId(long id) { this.id = id; } public long getId() {
import java.io.DataOutput; import java.io.IOException; import java.io.Serializable; import org.apache.hyracks.api.control.CcId; import org.apache.hyracks.api.exceptions.ErrorCode; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.api.io.IWritable; public final class JobId implements IWritable, Serializable, Comparable { private static final int CC_BITS = Short.SIZE; private static final int ID_BITS = Long.SIZE - CC_BITS; static final long MAX_ID = (1L << ID_BITS) - 1; public static final JobId INVALID = null; private static final long serialVersionUID = 1L; private long id; private transient CcId ccId; public static JobId create(DataInput dis) throws IOException { JobId jobId = new JobId(); jobId.readFields(dis); return jobId; } private JobId() { } public JobId(long id) { this.id = id; } public long getId() { return id; } public CcId getCcId() {
ncAppEntryPoint.stop(); /* * Stop heartbeat after NC has stopped to avoid false node failure detection * on CC if an NC takes a long time to stop. */ heartbeatTask.cancel(); LOGGER.log(Level.INFO, "Stopped NodeControllerService"); shuttedDown = true; } } public String getId() { return id; } public ServerContext getServerContext() { return serverCtx; } public Map<JobId, Joblet> getJobletMap() { return jobletMap; } public NetworkManager getNetworkManager() { return netManager; } public DatasetNetworkManager getDatasetNetworkManager() { return datasetNetworkManager; } public PartitionManager getPartitionManager() { return partitionManager; } public IClusterController getClusterController() { return ccs; } public NodeParameters getNodeParameters() { return nodeParameters; } public ExecutorService getExecutorService() { return executor; } public NCConfig getConfiguration() {
currentRecordChannel = new DatasetNetworkInputChannel(netManager, getSocketAddress(record), jobId, resultSetId, currentRecord, NUM_READ_BUFFERS); currentRecordMonitor = getMonitor(currentRecord); currentRecordChannel.registerMonitor(currentRecordMonitor); currentRecordChannel.open(datasetClientCtx); } private boolean isFirstRead() { return currentRecord == -1; } private boolean isLastRecord() { return knownRecords != null && currentRecord == knownRecords.length - 1; } private static class DatasetInputChannelMonitor implements IInputChannelMonitor { private int availableFrames; private boolean eos; private boolean failed; DatasetInputChannelMonitor() { eos = false; failed = false; } @Override public synchronized void notifyFailure(IInputChannel channel) { failed = true; notifyAll(); } @Override public synchronized void notifyDataAvailability(IInputChannel channel, int nFrames) { availableFrames += nFrames; notifyAll(); } @Override public synchronized void notifyEndOfStream(IInputChannel channel) { eos = true; notifyAll(); } synchronized boolean failed() { return failed; }
private static final boolean[] UNIQUE_META_FIELDS = null; private static final int[] KEY_INDEXES = { 0 }; private static final int[] KEY_INDICATORS = { Index.RECORD_INDICATOR }; private static final List<Integer> KEY_INDICATORS_LIST = Arrays.asList(new Integer[] { Index.RECORD_INDICATOR }); private static final int TOTAL_NUM_OF_RECORDS = 10000; private static final int RECORDS_PER_COMPONENT = 1000; private static final int DATASET_ID = 101; private static final int PARTITION_ID = 0; private static final String DATAVERSE_NAME = "TestDV"; private static final String DATASET_NAME = "TestDS"; private static final String DATA_TYPE_NAME = "DUMMY"; private static final String NODE_GROUP_NAME = "DEFAULT"; private static final Predicate<ILSMComponent> memoryComponentsPredicate = c -> c instanceof ILSMMemoryComponent; private static final StorageComponentProvider storageManager = new StorageComponentProvider(); private static TestNodeController nc; private static TestLsmBtree lsmBtree; private static NCAppRuntimeContext ncAppCtx; private static IDatasetLifecycleManager dsLifecycleMgr; private static Dataset dataset;
/** * @return the operation callback */ ILSMIOOperationCallback getCallback(); /** * @return the index id */ String getIndexIdentifier(); /** * @return the operation type */ LSMIOOperationType getIOOpertionType(); @Override Boolean call() throws HyracksDataException; /** * @return The target of the io operation */ FileReference getTarget(); /** * @return the accessor of the operation */ ILSMIndexAccessor getAccessor(); /** * @return the component files produced by this operation */ LSMComponentFileReferences getComponentFiles(); }
private boolean isDiskComponentScan; public LSMBTreeCursorInitialState(ITreeIndexFrameFactory leafFrameFactory, MultiComparator cmp, MultiComparator bloomFilterCmp, ILSMHarness lsmHarness, ISearchPredicate predicate, ISearchOperationCallback searchCallback, List<ILSMComponent> operationalComponents) { this.leafFrameFactory = leafFrameFactory; this.cmp = cmp; this.bloomFilterCmp = bloomFilterCmp; this.lsmHarness = lsmHarness; this.searchCallback = searchCallback; this.predicate = predicate; this.operationalComponents = operationalComponents;
btreeCursors[i] = btreeAccessors[i].createPointCursor(false); } else { // re-use btreeAccessors[i].reset(btree, NoOpOperationCallback.INSTANCE, NoOpOperationCallback.INSTANCE); btreeCursors[i].reset(); } } nextHasBeenCalled = false; foundTuple = false; } @Override public void next() throws HyracksDataException { nextHasBeenCalled = true; } @Override public void doDestroy() throws HyracksDataException { if (btreeCursors != null) { for (int i = 0; i < numBTrees; ++i) { if (btreeCursors[i] != null) { btreeCursors[i].destroy(); } } } nextHasBeenCalled = false; foundTuple = false; } @Override public ITupleReference getTuple() { return frameTuple; } @Override public ITupleReference getFilterMinTuple() { ILSMComponentFilter filter = getFilter(); return filter == null ? null : filter.getMinTuple(); } @Override public ITupleReference getFilterMaxTuple() { ILSMComponentFilter filter = getFilter(); return filter == null ? null : filter.getMaxTuple(); }
private final LSMBTreeRangeSearchCursor rangeCursor; private ITreeIndexCursor currentCursor; public LSMBTreeSearchCursor(ILSMIndexOperationContext opCtx) { pointCursor = new LSMBTreePointSearchCursor(opCtx); rangeCursor = new LSMBTreeRangeSearchCursor(opCtx); } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMBTreeCursorInitialState lsmInitialState = (LSMBTreeCursorInitialState) initialState; RangePredicate btreePred = (RangePredicate) searchPred; currentCursor = lsmInitialState.isDiskComponentScan() ? scanCursor : btreePred.isPointPredicate(lsmInitialState.getOriginalKeyComparator()) ? pointCursor : rangeCursor; currentCursor.open(lsmInitialState, searchPred); } @Override public boolean hasNext() throws HyracksDataException { return currentCursor.hasNext(); } @Override public void next() throws HyracksDataException { currentCursor.next(); } @Override public void close() throws HyracksDataException { if (currentCursor != null) { currentCursor.close(); } currentCursor = null; } @Override public void reset() throws HyracksDataException { if (currentCursor != null) { currentCursor.reset(); } currentCursor = null;
// (E.g. There are index-nested-loop-joins in the plan.) private List<Mutable<ILogicalOperator>> ixJoinOuterAdditionalDataSourceRefs = null; private List<DataSourceType> ixJoinOuterAdditionalDataSourceTypes = null; private List<Dataset> ixJoinOuterAdditionalDatasets = null; private List<ARecordType> ixJoinOuterAdditionalRecordTypes = null; /** * Identifies the root of the subtree and initializes the data-source, assign, and unnest information. */ public boolean initFromSubTree(Mutable<ILogicalOperator> subTreeOpRef) throws AlgebricksException { reset(); rootRef = subTreeOpRef; root = subTreeOpRef.getValue(); boolean passedSource = false; boolean result = false; Mutable<ILogicalOperator> searchOpRef = subTreeOpRef; // Examine the op's children to match the expected patterns. AbstractLogicalOperator subTreeOp = (AbstractLogicalOperator) searchOpRef.getValue(); do { // Skips select operator. if (subTreeOp.getOperatorTag() == LogicalOperatorTag.SELECT) { searchOpRef = subTreeOp.getInputs().get(0);
} } /** * Computes and returns the byte array for an integer value. */ public static byte[] computeByteArrayForIntValue(int value) throws AlgebricksException { ArrayBackedValueStorage castBuffer = new ArrayBackedValueStorage(); try { AInt32 val = new AInt32(value); SerializerDeserializerUtil.serializeTag(val, castBuffer.getDataOutput()); AInt32SerializerDeserializer.INSTANCE.serialize(val, castBuffer.getDataOutput()); } catch (HyracksDataException e) { throw CompilationException.create(ErrorCode.CANNOT_SERIALIZE_A_VALUE, e); } return castBuffer.getByteArray(); } }
private ITreeIndexAccessor[] btreeAccessors; private RTreeSearchCursor[] mutableRTreeCursors; private ITreeIndexCursor[] btreeCursors; private RangePredicate btreeRangePredicate; private boolean foundNext; private ITupleReference frameTuple; private int[] comparatorFields; private MultiComparator btreeCmp; private int currentCursor; private SearchPredicate rtreeSearchPredicate; private int numMutableComponents; private boolean open; protected ISearchOperationCallback searchCallback; private boolean resultOfsearchCallBackProceed = false; public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx) { this(opCtx, false); } public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx, boolean returnDeletedTuples) { super(opCtx, returnDeletedTuples); currentCursor = 0; } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = (LSMRTreeCursorInitialState) initialState; cmp = lsmInitialState.getHilbertCmp(); btreeCmp = lsmInitialState.getBTreeCmp(); lsmHarness = lsmInitialState.getLSMHarness();
private RTreeSearchCursor[] mutableRTreeCursors; private ITreeIndexCursor[] btreeCursors; private RangePredicate btreeRangePredicate; private boolean foundNext; private ITupleReference frameTuple; private int[] comparatorFields; private MultiComparator btreeCmp; private int currentCursor; private SearchPredicate rtreeSearchPredicate; private int numMutableComponents; private boolean open; protected ISearchOperationCallback searchCallback; private boolean resultOfsearchCallBackProceed = false; public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx) { this(opCtx, false); } public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx, boolean returnDeletedTuples) { super(opCtx, returnDeletedTuples); currentCursor = 0; } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = (LSMRTreeCursorInitialState) initialState; cmp = lsmInitialState.getHilbertCmp(); btreeCmp = lsmInitialState.getBTreeCmp(); lsmHarness = lsmInitialState.getLSMHarness();
private RTreeSearchCursor[] mutableRTreeCursors; private ITreeIndexCursor[] btreeCursors; private RangePredicate btreeRangePredicate; private boolean foundNext; private ITupleReference frameTuple; private int[] comparatorFields; private MultiComparator btreeCmp; private int currentCursor; private SearchPredicate rtreeSearchPredicate; private int numMutableComponents; private boolean open; protected ISearchOperationCallback searchCallback; private boolean resultOfsearchCallBackProceed = false; public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx) { this(opCtx, false); } public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx, boolean returnDeletedTuples) { super(opCtx, returnDeletedTuples); currentCursor = 0; } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = (LSMRTreeCursorInitialState) initialState; cmp = lsmInitialState.getHilbertCmp(); btreeCmp = lsmInitialState.getBTreeCmp(); lsmHarness = lsmInitialState.getLSMHarness();
public interface INcApplicationContext extends IApplicationContext { IIOManager getIoManager(); Executor getThreadExecutor(); ITransactionSubsystem getTransactionSubsystem(); void preStop() throws Exception; boolean isShuttingdown(); ILSMIOOperationScheduler getLSMIOScheduler(); ILSMMergePolicyFactory getMetadataMergePolicyFactory(); IBufferCache getBufferCache(); ILocalResourceRepository getLocalResourceRepository(); IDatasetLifecycleManager getDatasetLifecycleManager(); IDatasetMemoryManager getDatasetMemoryManager(); IResourceIdFactory getResourceIdFactory(); ILSMOperationTracker getPrimaryOperationTracker(int datasetID, int partition); void initialize(boolean initialRun) throws IOException, ACIDException, AlgebricksException; void setShuttingdown(boolean b); void deinitialize() throws HyracksDataException; double getBloomFilterFalsePositiveRate(); Object getActiveManager(); IReplicationManager getReplicationManager(); IReplicationChannel getReplicationChannel(); /** * Exports the metadata node to the metadata RMI port. * * @throws RemoteException */ void exportMetadataNodeStub() throws RemoteException; /** * Initializes the metadata node and bootstraps the metadata. * * @param newUniverse * @throws Exception */
idGenerator.refresh(); if (dsInfo.isDurable()) { synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { //notification will come from LogBuffer class (notifyFlushTerminator) logRecord.wait(); } catch (InterruptedException e) { Thread.currentThread().interrupt(); throw HyracksDataException.create(e); } } } for (ILSMIndex index : indexes) { //update resource lsn AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) { // TODO: This is not efficient since we flush the indexes sequentially.
idGenerator.refresh(); if (dsInfo.isDurable()) { synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { //notification will come from LogBuffer class (notifyFlushTerminator) logRecord.wait(); } catch (InterruptedException e) { Thread.currentThread().interrupt(); throw HyracksDataException.create(e); } } } for (ILSMIndex index : indexes) { //update resource lsn AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) { // TODO: This is not efficient since we flush the indexes sequentially.
this.setMemoryAllocated(false); } @Override public void touch() { super.touch(); setLastAccess(System.currentTimeMillis()); } @Override public void untouch() { super.untouch(); setLastAccess(System.currentTimeMillis()); } public synchronized void declareActiveIOOperation() { numActiveIOOps++; } public synchronized void undeclareActiveIOOperation() { numActiveIOOps--; //notify threads waiting on this dataset info notifyAll(); } public synchronized Set<ILSMIndex> getDatasetPartitionOpenIndexes(int partition) { Set<ILSMIndex> indexSet = new HashSet<>(); Set<IndexInfo> partitionIndexInfos = this.partitionIndexes.get(partition); if (partitionIndexInfos != null) { for (IndexInfo iInfo : partitionIndexInfos) { if (iInfo.isOpen()) { indexSet.add(iInfo.getIndex()); } } } return indexSet; } @Override public int compareTo(DatasetInfo i) { // sort by (isOpen, referenceCount, lastAccess) ascending, where true < false // // Example sort order: // -------------------
public String toString() { return "JID[" + (id >>> ID_BITS) + ":" + getIdOnly() + "]";
import java.util.Map; import java.util.Set; import org.apache.hyracks.api.application.ICCServiceContext; import org.apache.hyracks.api.application.IClusterLifecycleListener; import org.apache.hyracks.api.config.IApplicationConfig; import org.apache.hyracks.api.config.IOption; import org.apache.hyracks.api.context.ICCContext; import org.apache.hyracks.api.exceptions.HyracksException; import org.apache.hyracks.api.job.IJobLifecycleListener; import org.apache.hyracks.api.job.JobId; import org.apache.hyracks.api.job.JobSpecification; import org.apache.hyracks.api.job.JobStatus; import org.apache.hyracks.api.service.IControllerService; import org.apache.hyracks.control.cc.ClusterControllerService; import org.apache.hyracks.control.common.application.ServiceContext; import org.apache.hyracks.control.common.context.ServerContext; import org.apache.hyracks.control.common.utils.HyracksThreadFactory; import org.apache.hyracks.control.common.work.IResultCallback; public class CCServiceContext extends ServiceContext implements ICCServiceContext { private final ICCContext ccContext; protected final Set<String> initPendingNodeIds; protected final Set<String> deinitPendingNodeIds; protected IResultCallback<Object> initializationCallback; protected IResultCallback<Object> deinitializationCallback;
indexOnlyPlanInfo.setFirst(false); return; } // index-only plan possible? boolean isIndexOnlyPlan = false; // secondary key field usage after the select (join) operators // This boolean is mainly used for R-Tree case since R-Tree index generates an MBR // and we can restore original point or rectangle from this MBR if an index is built on point or rectangle. boolean secondaryKeyFieldUsedAfterSelectOrJoinOp; // Whether a post verification (especially for R-Tree case) is required after the secondary index search // (e.g., the shape of the given query is not a point or rectangle. // Then, we may need to apply the select again using the real polygon, not MBR of it to get the true // result, not a super-set of it.) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); // Does the given index can cover all search predicates? boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getFourth(); // matched function expressions
// (e.g., the shape of the given query is not a point or rectangle. // Then, we may need to apply the select again using the real polygon, not MBR of it to get the true // result, not a super-set of it.) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); // Does the given index can cover all search predicates? boolean doesSIdxSearchCoverAllPredicates; // matched function expressions List<IOptimizableFuncExpr> matchedFuncExprs = analysisCtx.getMatchedFuncExprs(); // logical variables that select (join) operator is using List<LogicalVariable> usedVarsInSelJoinOp = new ArrayList<>(); List<LogicalVariable> usedVarsInSelJoinOpTemp = new ArrayList<>(); // live variables that select (join) operator can access List<LogicalVariable> liveVarsAfterSelJoinOp = new ArrayList<>(); // PK, record variable List<LogicalVariable> dataScanPKRecordVars; List<LogicalVariable> dataScanPKVars = new ArrayList<>(); List<LogicalVariable> dataScanRecordVars = new ArrayList<>();
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) { return new IScalarEvaluatorFactory() { private static final long serialVersionUID = 1L; @Override @SuppressWarnings("unchecked") public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException { return new IScalarEvaluator() { private class AbstractSTSingleGeometryEvaluator implements IScalarEvaluator { private final AMutableInt32 intRes = new AMutableInt32(0); @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { resultStorage.reset(); eval0.evaluate(tuple, argPtr0); try { byte[] bytes0 = argPtr0.getByteArray(); int offset0 = argPtr0.getStartOffset(); int len0 = argPtr0.getLength(); ATypeTag tag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes0[offset0]); if (tag != ATypeTag.GEOMETRY) {
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) { return new IScalarEvaluatorFactory() { private static final long serialVersionUID = 1L; @Override public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException { return new IScalarEvaluator() { private class STGeomFromWKBEvaulator implements IScalarEvaluator { @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { eval.evaluate(tuple, inputArg); byte[] data = inputArg.getByteArray(); int offset = inputArg.getStartOffset(); int len = inputArg.getLength(); if (data[offset] != ATypeTag.SERIALIZED_BINARY_TYPE_TAG) { throw new TypeMismatchException(BuiltinFunctions.ST_GEOM_FROM_WKB, 0, data[offset], ATypeTag.SERIALIZED_BINARY_TYPE_TAG); } try { out.writeByte(ATypeTag.SERIALIZED_GEOMETRY_TYPE_TAG);
public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) { return new IScalarEvaluatorFactory() { private static final long serialVersionUID = 1L; @Override public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException { return new STPolygonizeEvaluator(args, ctx); } }; } @Override @SuppressWarnings("unchecked") public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { eval.evaluate(tuple, inputArg); byte[] bytes = inputArg.getByteArray(); int offset = inputArg.getStartOffset(); int len = inputArg.getLength(); AOrderedListType type = new AOrderedListType(BuiltinType.AGEOMETRY, null); byte typeTag = inputArg.getByteArray()[inputArg.getStartOffset()]; ISerializerDeserializer serde; if (typeTag == ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG) { serde = new AOrderedListSerializerDeserializer(type);
public int hashCode() { return Objects.hash(first, second, third, fourth);
public boolean equals(Object o) { if (!(o instanceof Quadruple<?, ?, ?, ?>)) { return false; } Quadruple<?, ?, ?, ?> quadruple = (Quadruple<?, ?, ?, ?>) o; return Objects.equals(first, quadruple.first) && Objects.equals(second, quadruple.second) && Objects.equals(third, quadruple.third) && Objects.equals(fourth, quadruple.fourth);
public boolean hasNext() { return currentElementIx < numElements;
* KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.common; import java.util.Arrays; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.logging.log4j.Level; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; public abstract class EnforcedIndexCursor implements IIndexCursor { enum State { CLOSED, OPENED, DESTROYED } private static final boolean STORE_TRACES = false; private static final boolean ENFORCE_NEXT_HAS_NEXT = true; private static final boolean ENFORCE_OPEN_CLOSE_DESTROY = true; private static final Logger LOGGER = LogManager.getLogger(); private State state = State.CLOSED; private StackTraceElement[] openCallStack; private StackTraceElement[] destroyCallStack; @Override public final void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { if (ENFORCE_OPEN_CLOSE_DESTROY && state != State.CLOSED) {
private static final long serialVersionUID = 1L; private static final int METADATA_DATASET_ID = MetadataPrimaryIndexes.PROPERTIES_METADATA.getDatasetId(); // shared between core and extension private IDatasetLifecycleManager datasetLifecycleManager; private ITransactionSubsystem transactionSubsystem; private int metadataStoragePartition; // core only private transient MetadataTupleTranslatorProvider tupleTranslatorProvider; // extension only private Map<ExtensionMetadataDatasetId, ExtensionMetadataDataset<?>> extensionDatasets; public static final MetadataNode INSTANCE = new MetadataNode(); private MetadataNode() { super(); } public void initialize(INcApplicationContext runtimeContext, MetadataTupleTranslatorProvider tupleTranslatorProvider, List<IMetadataExtension> metadataExtensions) { this.tupleTranslatorProvider = tupleTranslatorProvider; this.transactionSubsystem = runtimeContext.getTransactionSubsystem(); this.datasetLifecycleManager = runtimeContext.getDatasetLifecycleManager(); this.metadataStoragePartition = ((IPropertiesProvider) runtimeContext).getMetadataProperties() .getMetadataPartition().getPartitionId(); if (metadataExtensions != null) { extensionDatasets = new HashMap<>(); for (IMetadataExtension metadataExtension : metadataExtensions) { for (ExtensionMetadataDataset<?> extensionIndex : metadataExtension.getExtensionIndexes()) {
import java.util.concurrent.atomic.AtomicLong; import java.util.function.Supplier; import org.apache.asterix.common.transactions.ILongBlockFactory; import org.apache.asterix.common.transactions.ITxnIdFactory; import org.apache.asterix.common.transactions.TxnId; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; /** * Represents a factory to generate unique transaction IDs. */ class CcTxnIdFactory implements ITxnIdFactory { private static final int TXN_BLOCK_SIZE = 1024; private static final Logger LOGGER = LogManager.getLogger(); private final Supplier<ILongBlockFactory> blockFactorySupplier; private volatile Block block = new Block(0, 0); public CcTxnIdFactory(Supplier<ILongBlockFactory> blockFactorySupplier) { this.blockFactorySupplier = blockFactorySupplier; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { // retry
private static int TXN_BLOCK_SIZE = 10; private static final Logger LOGGER = LogManager.getLogger(); private final Supplier<ILongBlockFactory> blockFactorySupplier; private volatile Block block = new Block(0, 0); public CcTxnIdFactory(Supplier<ILongBlockFactory> blockFactorySupplier) { this.blockFactorySupplier = blockFactorySupplier; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { // retry LOGGER.info("block exhausted; obtaining new block from supplier"); block = new Block(blockFactorySupplier.get().getBlock(TXN_BLOCK_SIZE), TXN_BLOCK_SIZE); } } } @Override public void ensureMinimumId(long id) throws AlgebricksException { blockFactorySupplier.get().ensureMinimum(id); } static class Block { private static final BlockExhaustedException BLOCK_EXHAUSTED_EXCEPTION = new BlockExhaustedException(); private final AtomicLong id; private final long start; private final long endExclusive; private Block(long start, long blockSize) { this.id = new AtomicLong(start); this.start = start;
} @Override public ActiveManager getActiveManager() { return activeManager; } @Override public ReplicationProperties getReplicationProperties() { return replicationProperties; } @Override public IReplicationChannel getReplicationChannel() { return replicationChannel; } @Override public IReplicationManager getReplicationManager() { return replicationManager; } @Override public ILibraryManager getLibraryManager() { return libraryManager; } @Override public void initializeMetadata(boolean newUniverse) throws Exception { IAsterixStateProxy proxy; if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Bootstrapping metadata"); } MetadataNode.INSTANCE.initialize(this, ncExtensionManager.getMetadataTupleTranslatorProvider(), ncExtensionManager.getMetadataExtensions()); //noinspection unchecked ConcurrentHashMap<CcId, IAsterixStateProxy> proxyMap = ((ConcurrentHashMap<CcId, IAsterixStateProxy>) getServiceContext().getDistributedState()); if (proxyMap == null) { throw new IllegalStateException("Metadata node cannot access distributed state"); } // This is a special case, we just give the metadataNode directly. // This way we can delay the registration of the metadataNode until // it is completely initialized.
return replicationManager; } @Override public ILibraryManager getLibraryManager() { return libraryManager; } @Override public void initializeMetadata(boolean newUniverse) throws Exception { Collection<IAsterixStateProxy> proxies; LOGGER.info("Bootstrapping metadata"); MetadataNode.INSTANCE.initialize(this, ncExtensionManager.getMetadataTupleTranslatorProvider(), ncExtensionManager.getMetadataExtensions()); proxy = (IAsterixStateProxy) getServiceContext().getDistributedState(); if (proxy == null) { throw new IllegalStateException("Metadata node cannot access distributed state"); } // This is a special case, we just give the metadataNode directly. // This way we can delay the registration of the metadataNode until // it is completely initialized. MetadataManager.initialize(proxyMap.values(), MetadataNode.INSTANCE); MetadataBootstrap.startUniverse(getServiceContext(), newUniverse); MetadataBootstrap.startDDLRecovery(); ncExtensionManager.initializeMetadata(getServiceContext()); LOGGER.info("Metadata node bound"); } @Override public synchronized void exportMetadataNodeStub() throws RemoteException {
} } catch (InterruptedException e) { Thread.currentThread().interrupt(); throw HyracksDataException.create(e); } catch (RemoteException e) { throw new RuntimeDataException(ErrorCode.REMOTE_EXCEPTION_WHEN_CALLING_METADATA_NODE, e); } super.init(); } } private static class NCMetadataManagerImpl extends MetadataManager { public NCMetadataManagerImpl(Collection<IAsterixStateProxy> proxies, IMetadataNode metadataNode) { super(proxies, metadataNode); } @Override public MetadataTransactionContext beginTransaction() throws RemoteException { TxnId txnId = new TxnId(metadataNode.reserveTxnIdBlock(1)); metadataNode.beginTransaction(txnId); return new MetadataTransactionContext(txnId); } } }
import java.util.concurrent.atomic.AtomicLong; import java.util.function.Supplier; import org.apache.asterix.common.transactions.ILongBlockFactory; import org.apache.asterix.common.transactions.ITxnIdFactory; import org.apache.asterix.common.transactions.TxnId; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; /** * Represents a factory to generate unique transaction IDs. */ class CcTxnIdFactory implements ITxnIdFactory { private static final int TXN_BLOCK_SIZE = 1024; private static final Logger LOGGER = LogManager.getLogger(); private final Supplier<ILongBlockFactory> blockFactorySupplier; private volatile Block block = new Block(0, 0); public CcTxnIdFactory(Supplier<ILongBlockFactory> blockFactorySupplier) { this.blockFactorySupplier = blockFactorySupplier; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { // retry
} @Override public synchronized void stop() throws Exception { if (!shuttedDown) { LOGGER.log(Level.INFO, "Stopping NodeControllerService"); executor.shutdownNow(); if (!executor.awaitTermination(10, TimeUnit.SECONDS)) { LOGGER.log(Level.SEVERE, "Some jobs failed to exit, continuing with abnormal shutdown"); } partitionManager.close(); datasetPartitionManager.close(); netManager.stop(); datasetNetworkManager.stop(); queue.stop(); if (ncAppEntryPoint != null) { ncAppEntryPoint.stop(); } workQueue.stop(); ncAppEntryPoint.stop(); /* * Stop heartbeat after NC has stopped to avoid false node failure detection * on CC if an NC takes a long time to stop. */ heartbeatTask.cancel(); LOGGER.log(Level.INFO, "Stopped NodeControllerService"); shuttedDown = true; } } public String getId() { return id; } public ServerContext getServerContext() { return serverCtx; } public Map<JobId, Joblet> getJobletMap() { return jobletMap; }
} @Override public synchronized void stop() throws Exception { if (!shuttedDown) { LOGGER.log(Level.INFO, "Stopping NodeControllerService"); executor.shutdownNow(); if (!executor.awaitTermination(10, TimeUnit.SECONDS)) { LOGGER.log(Level.SEVERE, "Some jobs failed to exit, continuing with abnormal shutdown"); } partitionManager.close(); datasetPartitionManager.close(); netManager.stop(); datasetNetworkManager.stop(); if (messagingNetManager != null) { messagingNetManager.stop(); } /** * Stop heartbeat after NC has stopped to avoid false node failure detection * on CC if an NC takes a long time to stop. */ heartbeatTask.cancel(); LOGGER.log(Level.INFO, "Stopped NodeControllerService"); shuttedDown = true; } } public String getId() { return id; } public ServerContext getServerContext() { return serverCtx; } public Map<JobId, Joblet> getJobletMap() { return jobletMap; }
// Scan diskInvertedIndexes ignoring the memoryInvertedIndex. // Create an inverted index instance. ILSMDiskComponent component = createDiskComponent(componentFactory, mergeOp.getTarget(), mergeOp.getDeletedKeysBTreeTarget(), mergeOp.getBloomFilterTarget(), true); ILSMDiskComponentBulkLoader componentBulkLoader; // In case we must keep the deleted-keys BTrees, then they must be merged *before* merging the inverted // indexes so that lsmHarness.endSearch() is called once when the inverted indexes have been merged. if (mergeOp.getMergingComponents().get(mergeOp.getMergingComponents().size() - 1) != diskComponents .get(diskComponents.size() - 1)) { // Keep the deleted tuples since the oldest disk component is not included in the merge operation LSMInvertedIndexDeletedKeysBTreeMergeCursor btreeCursor = new LSMInvertedIndexDeletedKeysBTreeMergeCursor(opCtx); try { long numElements = 0L; for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { numElements += ((LSMInvertedIndexDiskComponent) mergeOp.getMergingComponents().get(i))
private boolean isOpen; public Info() { referenceCount = 0; isOpen = false;
public void untouch() { long tid = Thread.currentThread().getId(); List<StackTraceElement[]> caller = callers.get(tid); if (caller == null || caller.isEmpty()) { throw new RuntimeException("Untouch of an untouched resource by thread: " + tid); } caller.remove(caller.size() - 1); --referenceCount; if (referenceCount < 0) { throw new IllegalStateException("Unreferencing an unreferenced object"); }
public void touch() { long tid = Thread.currentThread().getId(); if (callers.containsKey(tid)) { LOGGER.log(Level.WARN, "\"Double touch of a resource by thread:" + tid + ". Previous call was from: " + Arrays.toString(callers.get(tid)) + ". This call is from: " + Arrays.toString(new Throwable().getStackTrace())); throw new RuntimeException("Double touch of a resource by thread: " + tid); } threads.add(new Throwable().getStackTrace()); ++referenceCount;
* KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.api.dataflow; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IDestroyable { /** * Destroy the object and releases any system resources associated * with it. If the object is already destroyed then invoking this * method has no effect. * All other calls after this method is invoked is undefined * * @throws HyracksDataException */ void destroy() throws HyracksDataException; }
dest.add(context.newVar()); } } /** * Gets the primary key variables from the unnest-map or left-outer-unnest-map operator * that does a secondary index lookup. * The order: SK, PK, [Optional: the result of a TryLock on PK] */ public static List<LogicalVariable> getKeyVarsFromSecondaryUnnestMap(Dataset dataset, ARecordType recordType, ARecordType metaRecordType, ILogicalOperator unnestMapOp, Index index, secondaryUnnestMapOutputVarType keyVarType) throws AlgebricksException { int numPrimaryKeys; int numSecondaryKeys = KeyFieldTypeUtil.getNumSecondaryKeys(index, recordType, metaRecordType); if (dataset.getDatasetType() == DatasetType.EXTERNAL) { numPrimaryKeys = IndexingConstants .getRIDSize(((ExternalDatasetDetails) dataset.getDatasetDetails()).getProperties()); } else { numPrimaryKeys = dataset.getPrimaryKeys().size(); } List<LogicalVariable> keyVars = new ArrayList<>(); List<LogicalVariable> sourceVars = ((AbstractUnnestMapOperator) unnestMapOp).getVariables(); // Assumption: the primary keys are located after the secondary key.
numPrimaryKeys = IndexingConstants .getRIDSize(((ExternalDatasetDetails) dataset.getDatasetDetails()).getProperties()); } else { numPrimaryKeys = dataset.getPrimaryKeys().size(); } List<LogicalVariable> keyVars = new ArrayList<>(); List<LogicalVariable> sourceVars = ((AbstractUnnestMapOperator) unnestMapOp).getVariables(); // Assumption: the primary keys are located after the secondary key. int start; int stop; // If a secondary-index search didn't generate SKs, set it to zero. // Currently, only an inverted-index search doesn't generate any SKs. boolean isNgramOrKeywordIndex = isInvertedIndex(index); if (isNgramOrKeywordIndex) { numSecondaryKeys = 0; } // Fetches keys: type 0 - PK, type 1 - SK, type 2 - the result of instantTryLock() on PK switch (keyType) { case 0: // Fetches primary keys - the second position start = numSecondaryKeys; stop = numSecondaryKeys + numPrimaryKeys; break; case 1: // Fetches secondary keys - the first position start = 0; stop = numSecondaryKeys; break; case 2: // Fetches conditional splitter - the last position
switch (keyType) { case 0: // Fetches primary keys - the second position start = numSecondaryKeys; stop = numSecondaryKeys + numPrimaryKeys; break; case 1: // Fetches secondary keys - the first position start = 0; stop = numSecondaryKeys; break; case 2: // Fetches conditional splitter - the last position start = numSecondaryKeys + numPrimaryKeys; stop = start + 1; break; default: return Collections.emptyList(); } for (int i = start; i < stop; i++) { keyVars.add(sourceVars.get(i)); } return keyVars; } public static List<LogicalVariable> getPrimaryKeyVarsFromSecondaryUnnestMap(Dataset dataset, ILogicalOperator unnestMapOp) { int numPrimaryKeys; if (dataset.getDatasetType() == DatasetType.EXTERNAL) { numPrimaryKeys = IndexingConstants .getRIDSize(((ExternalDatasetDetails) dataset.getDatasetDetails()).getProperties()); } else { numPrimaryKeys = dataset.getPrimaryKeys().size(); } List<LogicalVariable> primaryKeyVars = new ArrayList<>();
// If the constant type and target type does not match, we may need to do a type conversion. if (constantValueTag != indexedFieldTypeTag && constantValue != null) { // To check whether the constant is REAL values, and target field is an INT type field. // In this case, we need to change the search parameter. Refer to the caller section for the detail. realTypeConvertedToIntegerType = isRealTypeConvertedToIntegerType(constantValueTag, indexedFieldTypeTag); if (realTypeConvertedToIntegerType && !index.isEnforced() && !index.isOverridingKeyFieldTypes()) { // For the index on a closed-type field, // if a DOUBLE or FLOAT constant is converted to an INT type value, // we need to check a corner case where two real values are located // between an INT value. For example, the following query, // // for $emp in dataset empDataset // where $emp.age > double("2.3") and $emp.age < double("3.3") // return $emp.id; //
mathFunctionTypeForNumericTypeCasting); break; case EQ: // equality case - both CEIL and FLOOR need to be applied. replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.FLOOR); replacedConstantValueForEQCase = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.CEIL); break; default: break; } } else if (!realTypeConvertedToIntegerType) { // Type conversion only case: (e.g., INT -> BIGINT) replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.NONE); } } // No type-casting at all if (replacedConstantValue == null) { return new Triple<>(constantAtRuntimeExpression, null, false); } // A type-casting happened, but not EQ case if (replacedConstantValueForEQCase == null) {
replacedConstantValueForEQCase = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.CEIL); break; default: break; } } // Type conversion only case: (e.g., INT -> BIGINT) if (mathFunctionTypeForNumericTypeCasting == TypeCastingMathFunctionType.NONE) { replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.NONE); } } // No type-casting at all if (replacedConstantValue == null) { return new Triple<>(constantAtRuntimeExpression, null, false); } // A type-casting happened, but not EQ case if (replacedConstantValueForEQCase == null) { return new Triple<>(new ConstantExpression(replacedConstantValue), null, realTypeConvertedToIntegerType); } // A type-casting happened and it's an EQ case. return new Triple<>(new ConstantExpression(replacedConstantValue), new ConstantExpression(replacedConstantValueForEQCase), realTypeConvertedToIntegerType); }
private final String nodeId; private final List<INCLifecycleTask> tasks; public RegistrationTasksResponseMessage(String nodeId, List<INCLifecycleTask> tasks) { this.nodeId = nodeId; this.tasks = tasks; } @Override public void handle(INcApplicationContext appCtx) throws HyracksDataException, InterruptedException { INCMessageBroker broker = (INCMessageBroker) appCtx.getServiceContext().getMessageBroker(); IControllerService cs = appCtx.getServiceContext().getControllerService(); boolean success = true; try { Throwable exception = null; try { Throwable exception = null; try { for (INCLifecycleTask task : tasks) { if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Starting startup task: " + task); } task.perform(getCcId(), cs); if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Completed startup task: " + task); } } } catch (Throwable e) { //NOSONAR all startup failures should be reported to CC LOGGER.log(Level.ERROR, "Failed during startup task", e);
class CachingTxnIdFactory implements ITxnIdFactory { private static final Logger LOGGER = LogManager.getLogger(); private final INcApplicationContext appCtx; private volatile Block block = new Block(0, 0); public CachingTxnIdFactory(INcApplicationContext appCtx) { this.appCtx = appCtx; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { // retry LOGGER.info("block exhausted; obtaining new block from supplier"); TxnIdBlockRequest.Block newBlock; try { newBlock = TxnIdBlockRequestMessage.send(appCtx); } catch (HyracksDataException e) { throw new AlgebricksException(e); } block = new Block(newBlock.getStartingId(), newBlock.getBlockSize()); } } } @Override public void ensureMinimumId(long id) throws AlgebricksException { throw new UnsupportedOperationException(); } @Override public long getIdBlock(int blockSize) { throw new UnsupportedOperationException(); } @Override
((ClusterControllerService) appCtx.getServiceContext().getControllerService()).getJobIdFactory() .setMaxJobId(maxJobId); } public static void send(CcId ccId, NodeControllerService ncs) throws HyracksDataException { INcApplicationContext appContext = (INcApplicationContext) ncs.getApplicationContext(); long maxResourceId = Math.max(appContext.getLocalResourceRepository().maxId(), MetadataIndexImmutableProperties.FIRST_AVAILABLE_USER_DATASET_ID); long maxTxnId = appContext.getMaxTxnId(); long maxJobId = ncs.getMaxJobId(ccId); ReportLocalCountersMessage countersMessage = new ReportLocalCountersMessage(ncs.getId(), maxResourceId, maxTxnId, maxJobId); try { ((INCMessageBroker) ncs.getContext().getMessageBroker()).sendMessageToCC(ccId, countersMessage); } catch (Exception e) { LOGGER.log(Level.ERROR, "Unable to report local counters", e); throw HyracksDataException.create(e); } } @Override public String toString() { return ReportLocalCountersMessage.class.getSimpleName(); } }
public static Throwable close(ITupleForwarder tupleForwarder, Throwable root) { if (tupleForwarder != null) { try { tupleForwarder.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable ignore) { // NOSONAR Logging exception will be ignored // NOSONAR ignore } root = ExceptionUtils.suppress(root, th); } } return root;
public static Throwable close(ITupleForwarder tupleForwarder, Throwable root) { if (tupleForwarder != null) { try { tupleForwarder.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable ignore) { // NOSONAR Logging exception will be ignored // NOSONAR ignore } root = ExceptionUtils.suppress(root, th); } } return root;
* * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.api.dataflow; import org.apache.hyracks.api.exceptions.HyracksDataException; @FunctionalInterface public interface IDestroyable { /** * Destroy the object and releases any system resources associated * with it. If the object is already destroyed then invoking this * method has no effect. * All other calls after this method is invoked is undefined * * @throws HyracksDataException */ void destroy() throws HyracksDataException; }
* KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.api.dataflow; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IDestroyable { /** * Destroy the object and releases any system resources associated * with it. If the object is already destroyed then invoking this * method has no effect. * The behavior of other calls after this method is invoked is undefined * * @throws HyracksDataException */ void destroy() throws HyracksDataException; }
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root;
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root;
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable loggingFailure) { // Do nothing } } } return root;
public static Throwable close(List<IIndexDataflowHelper> indexHelpers, Throwable root) { for (int i = 0; i < indexHelpers.size(); i++) { root = close(indexHelpers.get(i), root); } return root;
reusablePred.setHighKeyComparator(predicate.getHighKeyComparator()); includeMutableComponent = false; int numBTrees = operationalComponents.size(); if (rangeCursors == null) { // object creation: should be relatively low rangeCursors = new IIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; } else if (rangeCursors.length != numBTrees) { // should destroy first Throwable failure = ExceptionUtils.suppress(DestroyUtils.destroy(btreeAccessors), DestroyUtils.destroy(rangeCursors)); HyracksDataException.throwIfNotNull(failure); rangeCursors = new IIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; } for (int i = 0; i < numBTrees; i++) { ILSMComponent component = operationalComponents.get(i); BTree btree; if (component.getType() == LSMComponentType.MEMORY) { includeMutableComponent = true; } btree = (BTree) component.getIndex(); if (btreeAccessors[i] == null) { btreeAccessors[i] = btree.createAccessor(NoOpIndexAccessParameters.INSTANCE); rangeCursors[i] = btreeAccessors[i].createSearchCursor(false);
try { indexHelper.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } } try { // will definitely be called regardless of exceptions writer.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } if (closeException != null) { throw HyracksDataException.create(closeException); } } @Override public void doFail() throws HyracksDataException { failed = true; writer.fail(); } }
indexHelper.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } } try { // will definitely be called regardless of exceptions writer.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } if (closeException != null) { throw HyracksDataException.create(closeException); } } @Override public void doFail() throws HyracksDataException { failed = true; writer.fail(); } }
} } try { indexHelper.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } } try { // will definitely be called regardless of exceptions writer.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } if (closeException != null) { throw HyracksDataException.create(closeException); } } @Override public void doFail() throws HyracksDataException { failed = true; writer.fail(); } }
.getLongValue()); file.setLastModefiedTime(new Date( ((ADateTime) externalFileRecord.getValueByPos(FilesIndexDescription.EXTERNAL_FILE_MOD_DATE_FIELD_INDEX)) .getChrononTime())); } public void close() throws HyracksDataException { Throwable failure = ResourceReleaseUtils.close(fileIndexSearchCursor, null); failure = DestroyUtils.destroy(fileIndexSearchCursor, failure); failure = DestroyUtils.destroy(fileIndexAccessor, failure); failure = ResourceReleaseUtils.close(indexDataflowHelper, failure); HyracksDataException.throwIfNotNull(failure); } }
public static Throwable close(ITupleForwarder tupleForwarder, Throwable root) { if (tupleForwarder != null) { try { tupleForwarder.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable ignore) { // NOSONAR Logging exception will be ignored // NOSONAR ignore } root = ExceptionUtils.suppress(root, th); } } return root;
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root;
try { rangeCursors[i].destroy(); } catch (Throwable th) { // NOSONAR. Must destroy all cursors failure = ExceptionUtils.suppress(failure, th); } } rangeCursors = null; } try { lsmHarness.endScanDiskComponents(opCtx); } catch (Throwable th) { // NOSONAR. Don't lose the root cause failure = ExceptionUtils.suppress(failure, th); } } foundNext = false; HyracksDataException.throwIfNotNull(failure); } @Override protected void setPriorityQueueComparator() { if (pqCmp == null || cmp != pqCmp.getMultiComparator()) { pqCmp = new PriorityQueueScanComparator(cmp); } } private class PriorityQueueScanComparator extends PriorityQueueComparator { public PriorityQueueScanComparator(MultiComparator cmp) { super(cmp); } @Override public int compare(PriorityQueueElement elementA, PriorityQueueElement elementB) { int result; try { result = cmp.compare(elementA.getTuple(), elementB.getTuple()); if (result != 0) { return result; }
*/ package org.apache.asterix.test.base; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; import org.junit.rules.TestWatcher; import org.junit.runner.Description; /* * Traces method entry/exit to System.out (or supplied PrintStream). To use, add the following to your test class: * * @Rule * public TestRule watcher = new TestMethodTracer(); * * @Rule * public TestRule watcher = new TestMethodTracer(Level.INFO); * </code> */ public class TestMethodTracer extends TestWatcher { private static final Logger LOGGER = LogManager.getLogger(); @Override protected void starting(Description description) { LOGGER.info("### {} START", description.getMethodName()); } @Override protected void failed(Throwable e, Description description) { LOGGER.info("### {} FAILED ({})", description.getMethodName(), e.getClass().getName()); } @Override protected void succeeded(Description description) { LOGGER.info("### {} SUCCEEDED", description.getMethodName()); } }
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } } } return root;
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } } } return root;
public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } } } return root;
} public LSMBTreePointSearchCursor getInsertSearchCursor() { return insertSearchCursor; } public BTreeRangeSearchCursor getMemCursor() { return memCursor; } public LSMBTreeCursorInitialState getSearchInitialState() { return searchInitialState; } public MultiComparator getCmp() { return cmp; } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; Throwable failure = DestroyUtils.destroy(null, mutableBTreeAccessors); failure = DestroyUtils.destroy(failure, mutableBTreeOpCtxs); failure = DestroyUtils.destroy(failure, insertSearchCursor, memCursor); if (failure != null) { throw HyracksDataException.create(failure); } } }
public BTreeRangeSearchCursor getMemCursor() { return memCursor; } public LSMBTreeCursorInitialState getSearchInitialState() { return searchInitialState; } public MultiComparator getCmp() { return cmp; } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; Throwable failure = DestroyUtils.destroy(null, mutableBTreeAccessors); failure = DestroyUtils.destroy(failure, mutableBTreeOpCtxs); failure = DestroyUtils.destroy(failure, insertSearchCursor, memCursor); if (failure != null) { throw HyracksDataException.create(failure); } } }
return memCursor; } public LSMBTreeCursorInitialState getSearchInitialState() { return searchInitialState; } public MultiComparator getCmp() { return cmp; } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; Throwable failure = DestroyUtils.destroy(null, mutableBTreeAccessors); failure = DestroyUtils.destroy(failure, mutableBTreeOpCtxs); failure = DestroyUtils.destroy(failure, insertSearchCursor, memCursor); if (failure != null) { throw HyracksDataException.create(failure); } } }
} Function f = new Function(dataverse, getExternalFunctionFullName(libraryName, function.getName().trim()), args.size(), args, function.getReturnType().trim(), function.getDefinition().trim(), library.getLanguage().trim(), function.getFunctionType().trim(), null); MetadataManager.INSTANCE.addFunction(mdTxnCtx, f); if (LOGGER.isInfoEnabled()) { LOGGER.info("Installed function: " + functionFullName); } } } if (LOGGER.isInfoEnabled()) { LOGGER.info("Installed functions in library :" + libraryName); } // Add adapters if (library.getLibraryAdapters() != null) { for (LibraryAdapter adapter : library.getLibraryAdapters().getLibraryAdapter()) { String adapterFactoryClass = adapter.getFactoryClass().trim(); String adapterName = getExternalFunctionFullName(libraryName, adapter.getName().trim()); AdapterIdentifier aid = new AdapterIdentifier(dataverse, adapterName); DatasourceAdapter dsa =
* specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.api; import org.apache.asterix.external.library.java.JTypeTag; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IFunctionHelper { public IJObject getArgument(int index); public IJObject getResultObject(); public void setResult(IJObject result) throws HyracksDataException; public boolean isValidResult(); public IJObject getObject(JTypeTag jtypeTag) throws HyracksDataException; public void reset(); public String getParamsString(); }
import org.apache.hyracks.data.std.api.IDataOutputProvider; import org.apache.hyracks.data.std.api.IValueReference; public class JavaFunctionHelper implements IFunctionHelper { private final IExternalFunctionInfo finfo; private final IDataOutputProvider outputProvider; private final IJObject[] arguments; private IJObject resultHolder; private final IObjectPool<IJObject, IAType> objectPool = new ListObjectPool<>(JTypeObjectFactory.INSTANCE); private final JObjectPointableVisitor pointableVisitor; private final PointableAllocator pointableAllocator; private final Map<Integer, TypeInfo> poolTypeInfo; private final String paramsString; private boolean isValidResult = false; public JavaFunctionHelper(IExternalFunctionInfo finfo, IDataOutputProvider outputProvider, String parameters) throws HyracksDataException { this.finfo = finfo; this.outputProvider = outputProvider; this.pointableVisitor = new JObjectPointableVisitor(); this.pointableAllocator = new PointableAllocator(); this.arguments = new IJObject[finfo.getArgumentList().size()]; int index = 0; for (IAType param : finfo.getArgumentList()) { this.arguments[index++] = objectPool.allocate(param); } this.resultHolder = objectPool.allocate(finfo.getReturnType());
try { while (true) { pageCleanerPolicy.notifyCleanCycleStart(this); int curPage = 0; while (true) { synchronized (cachedPages) { if (curPage >= cachedPages.size()) { break; } CachedPage cPage = (CachedPage) cachedPages.get(curPage); if (cPage != null) { cleanPage(cPage, false); } } curPage++; } if (shutdownStart) { break; } pageCleanerPolicy.notifyCleanCycleFinish(this); } curPage++; } } } @Override public void close() { closed = true; fifoWriter.destroyQueue(); synchronized (cleanerThread) { cleanerThread.shutdownStart = true; cleanerThread.notifyAll(); while (!cleanerThread.shutdownComplete) { try { cleanerThread.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } synchronized (fileInfoMap) { try {
synchronized (cachedPages) { if (curPage >= cachedPages.size()) { break; } CachedPage cPage = (CachedPage) cachedPages.get(curPage); if (cPage != null) { cleanPage(cPage, false); } } curPage++; } if (shutdownStart) { break; } pageCleanerPolicy.notifyCleanCycleFinish(this); } } catch (Exception e) { e.printStackTrace(); } finally { shutdownComplete = true; notifyAll(); } if (!shutdownStart) { pageCleanerPolicy.notifyCleanCycleFinish(threadLock); } } } @Override public void close() { closed = true; fifoWriter.destroyQueue(); synchronized (cleanerThread) { cleanerThread.shutdownStart = true; cleanerThread.notifyAll(); while (!cleanerThread.shutdownComplete) { try { cleanerThread.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } synchronized (fileInfoMap) { try { for (Map.Entry<Integer, BufferedFileHandle> entry : fileInfoMap.entrySet()) {
public void close() { closed = true; fifoWriter.destroyQueue(); try { synchronized (cleanerThread.threadLock) { cleanerThread.shutdownStart = true; cleanerThread.threadLock.notifyAll(); while (!cleanerThread.shutdownComplete) { cleanerThread.threadLock.wait(); } } } synchronized (fileInfoMap) { try { for (Map.Entry<Integer, BufferedFileHandle> entry : fileInfoMap.entrySet()) { boolean fileHasBeenDeleted = entry.getValue().fileHasBeenDeleted(); sweepAndFlush(entry.getKey(), !fileHasBeenDeleted); if (!fileHasBeenDeleted) { ioManager.close(entry.getValue().getFileHandle()); } } } catch (HyracksDataException e) { e.printStackTrace(); } fileInfoMap.clear(); }
CachedPage cPage = bucket.cachedPage; bucket.cachedPage = bucket.cachedPage.next; cPage.next = null; } } } finally { bucket.bucketLock.unlock(); } } } private boolean invalidateIfFileIdMatch(int fileId, CachedPage cPage, boolean flushDirtyPages) throws HyracksDataException { if (BufferedFileHandle.getFileId(cPage.dpid) == fileId) { int pinCount; if (cPage.dirty.get()) { if (flushDirtyPages) { write(cPage); } cPage.dirty.set(false); pinCount = cPage.pinCount.decrementAndGet(); } else { pinCount = cPage.pinCount.get(); } if (pinCount > 0) { throw new IllegalStateException("Page " + BufferedFileHandle.getFileId(cPage.dpid) + ":" + BufferedFileHandle.getPageId(cPage.dpid) + " is pinned and file is being closed. Pincount is: " + pinCount + " Page is confiscated: " + cPage.confiscated); } cPage.invalidate(); return true; }
isFinishedSearch = true; invListMerger.close(); finalSearchResult.finalizeWrite(); return true; } return false; } // Finished one partition for the both cases #1 and #2. So, moves to the next partition. curPartIdx++; if (curPartIdx <= endPartIdx) { boolean suitablePartFound = false; for (int i = curPartIdx; i <= endPartIdx; i++) { // Prune partition because no element in it can satisfy the occurrence threshold. if (partitionCursors[i] == null) { continue; } suitablePartFound = true; curPartIdx = i; break; } // If no partition is availble to explore, we stop here. if (!suitablePartFound) { isFinishedSearch = true; invListMerger.close(); finalSearchResult.finalizeWrite(); return true; } // Merge inverted lists of current partition. numPrefixLists = searchModifier.getNumPrefixLists(occurrenceThreshold, partitionCursors[curPartIdx].size()); invListMerger.reset(); finalSearchResult.resetBuffer();
this.argTypes = argTypes; this.failOnArgTypeMismatch = failOnArgTypeMismatch; } @Override public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException { final IScalarEvaluator[] argEvals = new IScalarEvaluator[args.length]; final IPointable[] argPtrs = new IPointable[args.length]; for (int i = 0; i < args.length; i++) { argEvals[i] = args[i].createScalarEvaluator(ctx); argPtrs[i] = new VoidPointable(); } return new IScalarEvaluator() { private static final int TABLE_FRAME_SIZE = 32768; private static final int TABLE_SIZE = 100; final ARecordVisitablePointable openRecordPointable = new ARecordVisitablePointable(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE); final ARecordVisitablePointable[] argVisitablePointables; final BitSet castRequired; final ACastVisitor castVisitor; final Triple<IVisitablePointable, IAType, Boolean> castVisitorArg; final RecordBuilder outRecordBuilder = new RecordBuilder(); final BinaryEntry keyEntry = new BinaryEntry(); final BinaryEntry valEntry = new BinaryEntry(); final BinaryHashMap fieldMap =
final BitSet castRequired; final ACastVisitor castVisitor; final Triple<IVisitablePointable, IAType, Boolean> castVisitorArg; final RecordBuilder outRecordBuilder = new RecordBuilder(); final BinaryEntry keyEntry = new BinaryEntry(); final BinaryEntry valEntry = new BinaryEntry(); final BinaryHashMap fieldMap = new BinaryHashMap(TABLE_SIZE, TABLE_FRAME_SIZE, outRecordBuilder.getFieldNameHashFunction(), outRecordBuilder.getFieldNameHashFunction(), outRecordBuilder.getFieldNameComparator()); argPointables = new IPointable[args.length]; argRecordPointables = new ARecordVisitablePointable[args.length]; openRecordPointable = new ARecordVisitablePointable(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE); int argCount = argEvals.length; ARecordVisitablePointable[] vp = new ARecordVisitablePointable[argCount]; BitSet cr = new BitSet(); ACastVisitor cv = null; Triple<IVisitablePointable, IAType, Boolean> ca = null; for (int i = 0; i < argCount; i++) { ARecordType argType = argTypes[i]; if (argType != null) { vp[i] = new ARecordVisitablePointable(argType); if (hasDerivedType(argType.getFieldTypes())) {
import org.apache.hyracks.algebricks.core.algebra.operators.logical.visitors.VariableUtilities; import org.apache.hyracks.algebricks.core.algebra.plan.ALogicalPlanImpl; import org.apache.hyracks.algebricks.core.algebra.util.OperatorPropertiesUtil; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.storage.am.lsm.invertedindex.tokenizers.DelimitedUTF8StringBinaryTokenizer; /** * Static helper functions for rewriting plans using indexes. */ public class AccessMethodUtils { // Output variable type from a secondary unnest-map enum SecondaryUnnestMapOutputVarType { PRIMARY_KEY, SECONDARY_KEY, CONDITIONAL_SPLIT_VAR } public static void appendPrimaryIndexTypes(Dataset dataset, IAType itemType, IAType metaItemType, List<Object> target) throws AlgebricksException { ARecordType recordType = (ARecordType) itemType; ARecordType metaRecordType = (ARecordType) metaItemType; target.addAll(KeyFieldTypeUtil.getPartitoningKeyTypes(dataset, recordType, metaRecordType)); // Adds data record type. target.add(itemType); // Adds meta record type if any. if (dataset.hasMetaPart()) { target.add(metaItemType); } }
switch (keyVarType) { case PRIMARY_KEY: // Fetches primary keys - the second position start = numSecondaryKeys; stop = numSecondaryKeys + numPrimaryKeys; break; case SECONDARY_KEY: // Fetches secondary keys - the first position start = 0; stop = numSecondaryKeys; break; case CONDITIONAL_SPLIT_VAR: // Sanity check - the given unnest map should generate this variable. if (!abstractUnnestMapOp.getGenerateCallBackProceedResultVar()) { throw CompilationException.create(ErrorCode.CANNOT_GET_CONDITIONAL_SPLIT_KEY_VARIABLE); } // Fetches conditional splitter - the last position start = numSecondaryKeys + numPrimaryKeys; stop = start + 1; break; default: return Collections.emptyList(); } for (int i = start; i < stop; i++) { keyVars.add(sourceVars.get(i)); } return keyVars; } public static List<LogicalVariable> getPrimaryKeyVarsFromPrimaryUnnestMap(Dataset dataset, ILogicalOperator unnestMapOp) { int numPrimaryKeys = dataset.getPrimaryKeys().size();
case UPDATE: case WRITE: case WRITE_RESULT: case INDEX_INSERT_DELETE_UPSERT: case INSERT_DELETE_UPSERT: case INTERSECT: return getOperatorRequiredMemory(operator, frameSize); case LEFT_OUTER_UNNEST_MAP: case UNNEST_MAP: // Since an inverted-index search requires certain amount of memory, needs to calculate // the memory size differently if the given index-search is an inverted-index search. long unnestMapMemorySize = frameSize; if (isInvertedIndexSearch((AbstractUnnestMapOperator) operator)) { unnestMapMemorySize += textSearchMemorySize; } return getOperatorRequiredMemory(operator, unnestMapMemorySize); case EXCHANGE: return getExchangeRequiredMemory((ExchangeOperator) operator); case GROUP: return getOperatorRequiredMemory(operator, groupByMemorySize); case ORDER: return getOperatorRequiredMemory(operator, sortMemorySize); case INNERJOIN: case LEFTOUTERJOIN: return getOperatorRequiredMemory(operator, joinMemorySize); default: throw new IllegalStateException("Unrecognized operator: " + operator.getOperatorTag()); }
public static Throwable destroy(Throwable root, IDestroyable... destroyables) { for (IDestroyable destroyable : destroyables) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable loggingFailure) { // NOSONAR // Do nothing } root = ExceptionUtils.suppress(root, th); // NOSONAR } } } return root;
public static Throwable close(IFrameWriter writer, Throwable root) { if (writer != null) { try { writer.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // NOSONAR // Do nothing } root = ExceptionUtils.suppress(root, th); // NOSONAR } } return root;
*/ String[] getPaths(); /** * @return the context associated with this IServlet */ ConcurrentMap<String, Object> ctx(); /** * handle the IServletRequest writing the response in the passed IServletResponse * * @param request * @param response */ void handle(IServletRequest request, IServletResponse response); /** * @return the handler for channel close events */ default IChannelClosedHandler getChannelCloseHandler(HttpServer server) { return server.getChannelCloseHandler(); } }
Collection<Task> tasks = joblet.getTaskMap().values(); for (Task task : tasks) { task.abort(); allTasks.add(task); } final JobId jobId = joblet.getJobId(); if (dpm != null) { dpm.abortReader(jobId); dpm.sweep(jobId); } ncs.getWorkQueue().schedule(new CleanupJobletWork(ncs, jobId, JobStatus.FAILURE)); }); ncs.getWorkQueue().schedule(new EnsureAllCcTasksCompleted(ncs, ccId, abortedTasks)); } }
import java.io.DataOutput; import java.io.IOException; import java.util.LinkedHashMap; import java.util.Map; public final class JRecord implements IJObject { private ARecordType recordType; private IJObject[] fields; private Map<String, IJObject> openFields; RecordBuilder recordBuilder = new RecordBuilder(); ArrayBackedValueStorage fieldName = new ArrayBackedValueStorage(); ArrayBackedValueStorage fieldValue = new ArrayBackedValueStorage(); AMutableString nameString = new AMutableString(""); public JRecord(ARecordType recordType, IJObject[] fields) { this.recordType = recordType; this.fields = fields; this.openFields = new LinkedHashMap<>(); } public JRecord(ARecordType recordType, IJObject[] fields, LinkedHashMap<String, IJObject> openFields) { this(recordType, fields); this.openFields = openFields; } public void addField(String fieldName, IJObject fieldValue) throws HyracksDataException { int pos = getFieldPosByName(fieldName); if (pos >= 0) {
public JRecord(ARecordType recordType, IJObject[] fields, Map<String, IJObject> openFields) { this(recordType, fields); this.openFields = openFields;
return new ARecord(mergedRecordType, mergedFields); } @Override public void reset() throws HyracksDataException { if (openFields != null && !openFields.isEmpty()) { openFields.clear(); } if (fields != null) { for (IJObject field : fields) { if (field != null) { field.reset(); } } } } public void reset(IJObject[] fields, Map<String, IJObject> openFields) throws HyracksDataException { this.reset(); this.fields = fields; this.openFields = openFields; } }
* * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { private JBuiltinType(){ // no op } public static final JBuiltinType JBOOLEAN = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() {
* software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { private JBuiltinType(){ // no op } public static final JBuiltinType JBOOLEAN = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } };
* software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { private JBuiltinType(){ // no op } public static final JBuiltinType JBOOLEAN = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } };
* software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { private JBuiltinType(){ // no op } public static final JBuiltinType JBOOLEAN = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } };
* specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JBYTE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override
* specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JBYTE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override
* specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static final JBuiltinType JBYTE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override
import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCIRCLE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() {
import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCIRCLE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() {
import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JCIRCLE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() {
public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDATE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } };
public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDATE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } };
public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static final JBuiltinType JDATE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } };
} }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDATETIME = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } };
} }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDATETIME = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } };
} }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static final JBuiltinType JDATETIME = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } };
} }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDOUBLE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } };
} }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDOUBLE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } };
} }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static final JBuiltinType JDOUBLE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } };
} }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDURATION = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } };
} }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDURATION = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } };
} }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static final JBuiltinType JDURATION = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } };
} }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFLOAT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } };
} }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFLOAT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } };
} }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static final JBuiltinType JFLOAT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } };
} }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static final JBuiltinType JINT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } };
} }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static final JBuiltinType JINT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } };
} }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static final JBuiltinType JINT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } };
} }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static final JBuiltinType JINTERVAL = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } };
} }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static final JBuiltinType JINTERVAL = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } };
} }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static final JBuiltinType JINTERVAL = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } };
} }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static final JBuiltinType JLINE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } };
} }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static final JBuiltinType JLINE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } };
} }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static final JBuiltinType JLINE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } };
} }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static final JBuiltinType JLONG = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } };
} }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static final JBuiltinType JLONG = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } };
} }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static final JBuiltinType JLONG = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } };
} }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMISSING = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } };
} }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMISSING = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } };
} }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static final JBuiltinType JMISSING = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } };
} }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static final JBuiltinType JNULL = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } };
} }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static final JBuiltinType JNULL = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } };
} }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static final JBuiltinType JNULL = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } };
} }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static final JBuiltinType JPOINT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } };
} }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static final JBuiltinType JPOINT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } };
} }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static final JBuiltinType JPOINT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } };
} }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPOINT3D = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } };
} }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPOINT3D = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } };
} }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static final JBuiltinType JPOINT3D = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } };
} }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPOLYGON = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } };
} }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPOLYGON = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } };
} }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static final JBuiltinType JPOLYGON = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } };
} }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static final JBuiltinType JRECTANGLE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static final JBuiltinType JRECTANGLE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static final JBuiltinType JRECTANGLE = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static final JBuiltinType JSHORT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static final JBuiltinType JSHORT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static final JBuiltinType JSHORT = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JSTRING = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JSTRING = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static final JBuiltinType JSTRING = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static final JBuiltinType JTIME = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static final JBuiltinType JTIME = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
} }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static final JBuiltinType JTIME = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; }
((AMutableCircle) (value)).setValue((APoint) center.getIAObject(), radius); } @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.CIRCLE.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } ACircleSerializerDeserializer.INSTANCE.serialize((AMutableCircle) value, dataOutput); } @Override public void reset() { ((AMutableCircle) value).setValue(null, 0); } }
public JDate(int chrononTimeInDays) { super(new AMutableDate(chrononTimeInDays)); } public void setValue(int chrononTimeInDays) { ((AMutableDate) value).setValue(chrononTimeInDays); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.DATE.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } ADateSerializerDeserializer.INSTANCE.serialize((AMutableDate) value, dataOutput); } @Override public void reset() { ((AMutableDate) value).setValue(0); } @Override public IAType getIAType() { return BuiltinType.ADATE; } }
public JDateTime(long chrononTime) { super(new AMutableDateTime(chrononTime)); } public void setValue(long chrononTime) { ((AMutableDateTime) value).setValue(chrononTime); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.DATETIME.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } ADateTimeSerializerDeserializer.INSTANCE.serialize((AMutableDateTime) value, dataOutput); } @Override public void reset() { ((AMutableDateTime) value).setValue(0); } @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }
super(new AMutableDuration(months, milliseconds)); } public void setValue(int months, long milliseconds) { ((AMutableDuration) value).setValue(months, milliseconds); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.DURATION.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } ADurationSerializerDeserializer.INSTANCE.serialize((AMutableDuration) value, dataOutput); } @Override public void reset() { ((AMutableDuration) value).setValue(0, 0); } @Override public IAType getIAType() { return BuiltinType.ADURATION; } }
} public long getIntervalEnd() { return ((AMutableInterval) value).getIntervalEnd(); } public short getIntervalType() { return ((AMutableInterval) value).getIntervalType(); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.INTERVAL.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } AIntervalSerializerDeserializer.INSTANCE.serialize((AMutableInterval) value, dataOutput); } @Override public void reset() throws HyracksDataException { ((AMutableInterval) value).setValue(0L, 0L, (byte) 0); } @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }
} public void setValue(APoint p1, APoint p2) { ((AMutableLine) value).setValue(p1, p2); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.LINE.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } ALineSerializerDeserializer.INSTANCE.serialize((AMutableLine) value, dataOutput); } @Override public void reset() { ((AMutableLine) value).setValue(null, null); } @Override public IAType getIAType() { return BuiltinType.ALINE; } }
public void reset() { // no op for NULL
public double getYValue() { return ((AMutablePoint3D) value).getY(); } public double getZValue() { return ((AMutablePoint3D) value).getZ(); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.POINT3D.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } APoint3DSerializerDeserializer.INSTANCE.serialize((AMutablePoint3D) value, dataOutput); } @Override public void reset() { ((AMutablePoint3D) value).setValue(0, 0, 0); } @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }
builder.appendString(String.valueOf(i)); break; } case BIGINT: { long l = AInt64SerializerDeserializer.getLong(serString, startOffset); builder.appendString(String.valueOf(l)); break; } case DOUBLE: { double d = ADoubleSerializerDeserializer.getDouble(serString, startOffset); if (Double.isNaN(d)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (d == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (d == Double.NEGATIVE_INFINITY) { // NOSONAR builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) {
break; } case BIGINT: { long l = AInt64SerializerDeserializer.getLong(serString, startOffset); builder.appendString(String.valueOf(l)); break; } case DOUBLE: { double d = ADoubleSerializerDeserializer.getDouble(serString, startOffset); if (Double.isNaN(d)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (d == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (d == Double.NEGATIVE_INFINITY) { // NOSONAR builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) {
} else if (d == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Float.NEGATIVE_INFINITY) { // NOSONAR builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; } case BOOLEAN: { boolean b = ABooleanSerializerDeserializer.getBoolean(serString, startOffset); builder.appendString(String.valueOf(b)); break; } // NotYetImplemented case CIRCLE: case DATE: case DATETIME: case LINE: case TIME: case DURATION: case YEARMONTHDURATION: case DAYTIMEDURATION: case INTERVAL: case ARRAY: case POINT:
builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Float.NEGATIVE_INFINITY) { // NOSONAR builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; } case BOOLEAN: { boolean b = ABooleanSerializerDeserializer.getBoolean(serString, startOffset); builder.appendString(String.valueOf(b)); break; } // NotYetImplemented case CIRCLE: case DATE: case DATETIME: case LINE: case TIME: case DURATION: case YEARMONTHDURATION: case DAYTIMEDURATION: case INTERVAL: case ARRAY: case POINT: case POINT3D: case RECTANGLE: case POLYGON:
builder.appendString(String.valueOf(i)); break; } case BIGINT: { long l = AInt64SerializerDeserializer.getLong(serString, startOffset); builder.appendString(String.valueOf(l)); break; } case DOUBLE: { double d = ADoubleSerializerDeserializer.getDouble(serString, startOffset); if (Double.isNaN(d)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (d == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (d == Double.NEGATIVE_INFINITY) { // NOSONAR builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) {
} else if (d == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Float.NEGATIVE_INFINITY) { // NOSONAR builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; } case BOOLEAN: { boolean b = ABooleanSerializerDeserializer.getBoolean(serString, startOffset); builder.appendString(String.valueOf(b)); break; } // NotYetImplemented case CIRCLE: case DATE: case DATETIME: case LINE: case TIME: case DURATION: case YEARMONTHDURATION: case DAYTIMEDURATION: case INTERVAL: case ARRAY: case POINT:
completeOperation(index, opType, searchCallback, modificationCallback); } } @Override public synchronized void completeOperation(ILSMIndex index, LSMOperationType opType, ISearchOperationCallback searchCallback, IModificationOperationCallback modificationCallback) throws HyracksDataException { if (opType == LSMOperationType.MODIFICATION || opType == LSMOperationType.FORCE_MODIFICATION) { decrementNumActiveOperations(modificationCallback); flushIfNeeded(); } else if (opType == LSMOperationType.FLUSH || opType == LSMOperationType.MERGE || opType == LSMOperationType.REPLICATE) { dsInfo.undeclareActiveIOOperation(); } } public synchronized void flushIfNeeded() throws HyracksDataException { if (numActiveOperations.get() == 0) { flushIfRequested(); } } public void flushIfRequested() throws HyracksDataException { // If we need a flush, and this is the last completing operation, then schedule the flush,
public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // NOSONAR: Ignore catching Throwable // NOSONAR ignore logging failure } root = ExceptionUtils.suppress(root, th); } } return root;
public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // NOSONAR: Ignore catching Throwable // NOSONAR ignore logging failure } root = ExceptionUtils.suppress(root, th); } } return root;
public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, th); // NOSONAR } } return root;
} public void write(IFileHandle fHandle, long offset, ByteBuffer data) throws HyracksDataException { if (state != State.INITIAL) { throw new IllegalStateException("Can't request a read operation through a " + state + " request"); } state = State.WRITE_REQUESTED; this.fHandle = fHandle; this.offset = offset; this.data = data; queue(); } private void queue() throws HyracksDataException { try { submittedRequests.put(this); } catch (InterruptedException e) { // NOSONAR: The call below will re-interrupt throw HyracksDataException.create(e); } } @Override public void await() throws InterruptedException { synchronized (this) { while (state != State.OPERATION_FAILED && state != State.OPERATION_SUCCEEDED) { wait(); } } } synchronized void handle() { try { if (state == State.READ_REQUESTED) { read = ioManager.doSyncRead(fHandle, offset, data); } else if (state == State.WRITE_REQUESTED) { if (data != null) { // single buffer
read = ioManager.doSyncRead(fHandle, offset, data); } else if (state == State.WRITE_REQUESTED) { if (data != null) { // single buffer write = ioManager.doSyncWrite(fHandle, offset, data); } else { // multiple buffers writes = ioManager.doSyncWrite(fHandle, offset, dataArray); } } else { throw new IllegalStateException("IO Request with state = " + state); } state = State.OPERATION_SUCCEEDED; } catch (Throwable th) { // NOSONAR: This method must never throw anything state = State.OPERATION_FAILED; failure = HyracksDataException.create(th); } notifyAll(); } public State getState() { return state; } void recycle() { reset(); freeRequests.offer(this); } public int getRead() { return read; } public int getWrite() { return write; } public long getWrites() { return writes; } @Override public void run() throws InterruptedException { await(); } public HyracksDataException getFailure() { return failure;
public void run() { Thread.currentThread().setName(getClass().getSimpleName() + "-" + num); while (true) { // NOSONAR: Suppress 1 continue and 1 break IoRequest next; try { next = queue.take(); } catch (InterruptedException e) { LOGGER.log(Level.WARN, "Ignoring interrupt. IO threads should never be interrupted."); continue; } if (next == POISON_PILL) { LOGGER.log(Level.INFO, "Exiting"); InvokeUtil.doUninterruptibly(() -> queue.put(POISON_PILL)); if (Thread.interrupted()) { LOGGER.log(Level.ERROR, "Ignoring interrupt. IO threads should never be interrupted."); } break; } next.handle(); }
public void run() { Thread.currentThread().setName(getClass().getSimpleName() + "-" + num); while (true) { IoRequest next; try { next = queue.take(); } catch (InterruptedException e) { // NOSONAR: This is not supposed to be ever interrupted LOGGER.log(Level.WARN, "Ignoring interrupt. IO threads should never be interrupted."); continue; } if (next == POISON_PILL) { LOGGER.log(Level.INFO, "Exiting"); InvokeUtil.doUninterruptibly(() -> queue.put(POISON_PILL)); if (Thread.interrupted()) { LOGGER.log(Level.ERROR, "Ignoring interrupt. IO threads should never be interrupted."); } break; } next.handle(); }
public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { // NOSONAR Will be suppressed try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root;
public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // NOSONAR: Ignore catching Throwable // NOSONAR ignore logging failure } root = ExceptionUtils.suppress(root, th); } } return root;
executor.execute(req); return req; } @Override public void close(IFileHandle fHandle) throws HyracksDataException { try { ((FileHandle) fHandle).close(); } catch (IOException e) { throw new HyracksDataException(e); } } public synchronized FileReference createWorkspaceFile(String prefix) throws HyracksDataException { IODeviceHandle dev = workAreaIODevices.get(workAreaDeviceIndex); workAreaDeviceIndex = (workAreaDeviceIndex + 1) % workAreaIODevices.size(); String waPath = dev.getWorkAreaPath(); File waf; try { waf = File.createTempFile(prefix, WORKSPACE_FILE_SUFFIX, new File(dev.getMount(), waPath)); } catch (IOException e) { throw new HyracksDataException(e); } return dev.createFileReference(waPath + File.separator + waf.getName()); } private abstract class AsyncRequest implements IIOFuture, Runnable { protected final FileHandle fHandle; protected final long offset; protected final ByteBuffer data; private boolean complete; private HyracksDataException exception; private int result;
public void run() { Thread.currentThread().setName(getClass().getSimpleName() + "-" + num); while (true) { IoRequest next; try { next = queue.take(); } catch (InterruptedException e) { // NOSONAR: This is not supposed to be ever interrupted LOGGER.log(Level.WARN, "Ignoring interrupt. IO threads should never be interrupted."); continue; } if (next == POISON_PILL) { LOGGER.log(Level.INFO, "Exiting"); InvokeUtil.doUninterruptibly(() -> queue.put(POISON_PILL)); if (Thread.interrupted()) { LOGGER.log(Level.ERROR, "Ignoring interrupt. IO threads should never be interrupted."); } break; } next.handle(); }
boolean finishConnect = false; try { finishConnect = channel.finishConnect(); } catch (IOException e) { key.cancel(); synchronized (connectionListener) { connectionListener.connectionFailure((InetSocketAddress) key.attachment(), e); } } if (finishConnect) { createConnection(key, channel); } } } } } catch (Exception e) { LOGGER.error("Error in TCPEndpoint {}", localAddress, e); } }
TestHelper.deleteExistingInstanceFiles(); String configPath = System.getProperty("user.dir") + File.separator + "src" + File.separator + "test" + File.separator + "resources" + File.separator + "cc.conf"; nc = new TestNodeController(configPath, false); nc.init(); ncAppCtx = nc.getAppRuntimeContext(); dsLifecycleMgr = ncAppCtx.getDatasetLifecycleManager(); } @AfterClass public static void tearDown() throws Exception { nc.deInit(); TestHelper.deleteExistingInstanceFiles(); } @Before public void createIndex() throws Exception { PrimaryIndexInfo primaryIndexInfo = StorageTestUtils.createPrimaryIndex(nc, PARTITION); IndexDataflowHelperFactory iHelperFactory = new IndexDataflowHelperFactory(nc.getStorageManager(), primaryIndexInfo.getFileSplitProvider()); JobId jobId = nc.newJobId(); ctx = nc.createTestContext(jobId, PARTITION, false); indexDataflowHelper = iHelperFactory.create(ctx.getJobletContext().getServiceContext(), PARTITION); indexDataflowHelper.open(); lsmBtree = (TestLsmBtree) indexDataflowHelper.getIndexInstance();
public void testFlushMetadataOnlyComponent() { try { // allow all operations StorageTestUtils.allowAllOps(lsmBtree); // ensure no disk component and memory component is empty Assert.assertEquals(0, lsmBtree.getDiskComponents().size()); Assert.assertFalse(lsmBtree.isMemoryComponentsAllocated()); MutableArrayValueReference key = new MutableArrayValueReference("FlushMetadataOnlyTestKey".getBytes()); MutableArrayValueReference value = new MutableArrayValueReference("FlushMetadataOnlyTestValue".getBytes()); indexDataflowHelper.open(); ILSMIndexAccessor accessor = lsmBtree.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.updateMeta(key, value); Assert.assertTrue(lsmBtree.isMemoryComponentsAllocated()); Assert.assertTrue(lsmBtree.getCurrentMemoryComponent().isModified()); indexDataflowHelper.close(); // flush synchronously StorageTestUtils.flush(dsLifecycleMgr, lsmBtree, false); // assert one disk component Assert.assertEquals(1, lsmBtree.getDiskComponents().size()); VoidPointable pointable = VoidPointable.FACTORY.createPointable(); ComponentUtils.get(lsmBtree, key, pointable); Assert.assertTrue(DataUtils.equals(pointable, value)); // ensure that we can search this component
public static boolean equals(IValueReference first, IValueReference second) { // NOSONAR if (first.getLength() != second.getLength()) { return false; } return equalsInRange(first.getByteArray(), first.getStartOffset(), second.getByteArray(), second.getStartOffset(), first.getLength());
private static TestLsmBtree lsmBtree; private static NCAppRuntimeContext ncAppCtx; private static IDatasetLifecycleManager dsLifecycleMgr; private static IHyracksTaskContext ctx; private static IIndexDataflowHelper indexDataflowHelper; private static final int PARTITION = 0; @BeforeClass public static void setUp() throws Exception { TestHelper.deleteExistingInstanceFiles(); String configPath = Paths.get(System.getProperty("user.dir"), "src", "test", "resources", "cc.conf").toString(); nc = new TestNodeController(configPath, false); nc.init(); ncAppCtx = nc.getAppRuntimeContext(); dsLifecycleMgr = ncAppCtx.getDatasetLifecycleManager(); } @AfterClass public static void tearDown() throws Exception { System.out.println("TearDown"); nc.deInit(); TestHelper.deleteExistingInstanceFiles(); } @Before public void createIndex() throws Exception { PrimaryIndexInfo primaryIndexInfo = StorageTestUtils.createPrimaryIndex(nc, PARTITION); IndexDataflowHelperFactory iHelperFactory =
ncSection = ccini.add(sectionName); } if (ncConfig.getString(NCConfig.Option.CLUSTER_ADDRESS) == null) { ncSection.put(NCConfig.Option.CLUSTER_ADDRESS.ini(), ccs.getCCConfig().getClusterPublicAddress()); ncSection.put(NCConfig.Option.CLUSTER_PORT.ini(), String.valueOf(ccs.getCCConfig().getClusterPublicPort())); } // if not already configured, set GC max pause time millis to not exceed 1/2 the total max heartbeat miss period... String ncJvmArgs = ncConfig.getString(NCConfig.Option.JVM_ARGS); if (ncJvmArgs == null || !ncJvmArgs.contains(JVM_ARG_MAX_GCPAUSE_MILLIS)) { String gcMaxPauseArg = JVM_ARG_MAX_GCPAUSE_MILLIS + getGcMaxPauseMillis(); ncSection.put(NCConfig.Option.JVM_ARGS.ini(), ncJvmArgs == null ? gcMaxPauseArg : ncJvmArgs + " " + gcMaxPauseArg); } // Finally insert *this* NC's name into localnc section - this is a fixed // entry point so that NCs can determine where all their config is.
ncSection.put(NCConfig.Option.CLUSTER_PORT.ini(), String.valueOf(ccs.getCCConfig().getClusterPublicPort())); } // if not already configured, set GC max pause time millis to not exceed 1/2 the total max heartbeat miss period... String ncJvmArgs = ncConfig.getString(NCConfig.Option.JVM_ARGS); if (ncJvmArgs == null || !ncJvmArgs.contains(JVM_ARG_MAX_GCPAUSE_MILLIS)) { String gcMaxPauseArg = JVM_ARG_MAX_GCPAUSE_MILLIS + getGcMaxPauseMillis(); ncSection.put(NCConfig.Option.JVM_ARGS.ini(), ncJvmArgs == null ? gcMaxPauseArg : ncJvmArgs + " " + gcMaxPauseArg); } // Finally insert *this* NC's name into localnc section - this is a fixed // entry point so that NCs can determine where all their config is. ccini.put(Section.LOCALNC.sectionName(), NCConfig.Option.NODE_ID.ini(), ncId); ccini.store(iniString); if (LOGGER.isDebugEnabled()) { LOGGER.debug("Returning Ini file:\n" + iniString.toString()); } return iniString.toString();
public List<String> getFunctionParameters(String dataverseName, String fullFunctionName) { return externalFunctionParameters.getOrDefault(dataverseName + "." + fullFunctionName, Collections.emptyList());
String functionReturnType = function.getReturnType().trim(); String functionDefinition = function.getDefinition().trim(); String functionLanguage = library.getLanguage().trim(); String functionType = function.getFunctionType().trim(); List<String> args = new ArrayList<>(); for (String arg : fargs) { args.add(arg); } FunctionSignature signature = new FunctionSignature(dataverse, functionFullName, args.size()); Function f = new Function(signature, args, functionReturnType, functionDefinition, functionLanguage, functionType, null); MetadataManager.INSTANCE.addFunction(mdTxnCtx, f); if (LOGGER.isInfoEnabled()) { LOGGER.info("Installed function: " + functionFullName); } } } if (LOGGER.isInfoEnabled()) { LOGGER.info("Installed functions in library :" + libraryName); } // Add adapters if (library.getLibraryAdapters() != null) { for (LibraryAdapter adapter : library.getLibraryAdapters().getLibraryAdapter()) {
configManager.set(nodeId, NCConfig.Option.NCSERVICE_PORT, NCConfig.NCSERVICE_PORT_DISABLED); final INCApplication ncApplication = createNCApplication(); ConfigManager ncConfigManager; if (confFile == null) { ncConfigManager = new ConfigManager(); } else { ncConfigManager = new ConfigManager(new String[] { "-config-file", confFile }); } ncApplication.registerConfig(ncConfigManager); opts.forEach(opt -> ncConfigManager.set(nodeId, opt.getLeft(), opt.getRight())); nodeControllers.add( new NodeControllerService(fixupIODevices(createNCConfig(nodeId, ncConfigManager)), ncApplication)); } opts.stream().forEach(opt -> configManager.set(opt.getLeft(), opt.getRight())); cc.start(); // Starts ncs. nodeNames = ccConfig.getConfigManager().getNodeNames(); List<Thread> startupThreads = new ArrayList<>(); for (NodeControllerService nc : nodeControllers) { Thread ncStartThread = new Thread("IntegrationUtil-" + nc.getId()) { @Override public void run() { try { nc.start();
throws Exception { flushPartition(dslLifecycleMgr, lsmBtree, DATASET, async); } public static void flushPartition(IDatasetLifecycleManager dslLifecycleMgr, TestLsmBtree lsmBtree, Dataset dataset, boolean async) throws Exception { waitForOperations(lsmBtree); PrimaryIndexOperationTracker opTracker = (PrimaryIndexOperationTracker) lsmBtree.getOperationTracker(); opTracker.setFlushOnExit(true); opTracker.flushIfNeeded(); long maxWaitTime = 60000L; // 1min // wait for log record is flushed, i.e., the flush is scheduled long before = System.nanoTime(); while (opTracker.isFlushLogCreated()) { Thread.sleep(5); // NOSONAR: Test code with a timeout if (System.currentTimeMillis() - before > maxWaitTime) { throw new IllegalStateException( (System.currentTimeMillis() - before) + "ms passed without scheduling the flush operation"); } } if (!async) { DatasetInfo dsInfo = dslLifecycleMgr.getDatasetInfo(dataset.getDatasetId()); dsInfo.waitForIO(); } }
throws Exception { flushPartition(dslLifecycleMgr, lsmBtree, DATASET, async); } public static void flushPartition(IDatasetLifecycleManager dslLifecycleMgr, TestLsmBtree lsmBtree, Dataset dataset, boolean async) throws Exception { waitForOperations(lsmBtree); PrimaryIndexOperationTracker opTracker = (PrimaryIndexOperationTracker) lsmBtree.getOperationTracker(); opTracker.setFlushOnExit(true); opTracker.flushIfNeeded(); long maxWaitTime = 60000L; // 1min // wait for log record is flushed, i.e., the flush is scheduled long before = System.nanoTime(); while (opTracker.isFlushLogCreated()) { Thread.sleep(5); // NOSONAR: Test code with a timeout if (System.currentTimeMillis() - before > maxWaitTime) { throw new IllegalStateException( (System.currentTimeMillis() - before) + "ms passed without scheduling the flush operation"); } } if (!async) { DatasetInfo dsInfo = dslLifecycleMgr.getDatasetInfo(dataset.getDatasetId()); dsInfo.waitForIO(); } }
* harness callback simply. */ public class StubIOOperationCallback implements ILSMIOOperationCallback { private ILSMIndexOperationContext opCtx = null; @Override public void beforeOperation(ILSMIndexOperationContext opCtx) throws HyracksDataException { // Not interested in this } @Override public void afterOperation(ILSMIndexOperationContext opCtx) throws HyracksDataException { this.opCtx = opCtx; } @Override public synchronized void afterFinalize(LSMOperationType opType, ILSMDiskComponent newComponent) throws HyracksDataException { } public List<ILSMDiskComponent> getLastOldComponents() { return opCtx.getComponentsToBeMerged(); } public ILSMDiskComponent getLastNewComponent() { return opCtx.getNewComponent(); } @Override public void recycled(ILSMMemoryComponent component, boolean componentSwitched) { // Not interested in this } @Override public void allocated(ILSMMemoryComponent component) { // Not interested in this } }
* harness callback simply. */ public class StubIOOperationCallback implements ILSMIOOperationCallback { private ILSMIndexOperationContext opCtx = null; @Override public void beforeOperation(ILSMIndexOperationContext opCtx) throws HyracksDataException { // Not interested in this } @Override public void afterOperation(ILSMIndexOperationContext opCtx) throws HyracksDataException { this.opCtx = opCtx; } @Override public void afterFinalize(ILSMIndexOperationContext opCtx) throws HyracksDataException { } public List<ILSMDiskComponent> getLastOldComponents() { return opCtx.getComponentsToBeMerged(); } public ILSMDiskComponent getLastNewComponent() { return opCtx.getNewComponent(); } @Override public void recycled(ILSMMemoryComponent component, boolean componentSwitched) { // Not interested in this } @Override public void allocated(ILSMMemoryComponent component) { // Not interested in this } }
protected LSMRTreeOpContext createOpContext(IIndexAccessParameters iap) { return new LSMRTreeOpContext(this, memoryComponents, rtreeLeafFrameFactory, rtreeInteriorFrameFactory, btreeLeafFrameFactory, (IExtendedModificationOperationCallback) iap.getModificationCallback(), iap.getSearchOperationCallback(), getTreeFields(), getFilterFields(), getHarness(), comparatorFields, linearizerArray, getFilterCmpFactories(), tracer);
* * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.api; import java.io.DataOutput; import org.apache.asterix.om.base.IAObject; import org.apache.asterix.om.types.IAType; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IJObject { IAType getIAType(); IAObject getIAObject(); void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException; void reset() throws HyracksDataException; }
super(); this.listType = new AOrderedListType(listItemType, null); } @Override public IAType getIAType() { return listType; } @Override public IAObject getIAObject() { AMutableOrderedList v = new AMutableOrderedList(listType); for (IJObject jObj : jObjects) { v.add(jObj.getIAObject()); } return v; } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { IAsterixListBuilder listBuilder = new OrderedListBuilder(); listBuilder.reset(listType); ArrayBackedValueStorage fieldValue = new ArrayBackedValueStorage(); for (IJObject jObject : jObjects) { fieldValue.reset(); jObject.serialize(fieldValue.getDataOutput(), true); listBuilder.addItem(fieldValue); } listBuilder.write(dataOutput, writeTypeTag); } @Override public void reset() { jObjects.clear(); } }
* specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base; import org.apache.asterix.dataflow.data.nontagged.serde.ABooleanSerializerDeserializer; import org.apache.asterix.om.base.ABoolean; import org.apache.asterix.om.base.IAObject; import org.apache.asterix.om.types.ATypeTag; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; import org.apache.hyracks.api.exceptions.HyracksDataException; import java.io.DataOutput; public final class JBoolean extends JObject { private boolean aBoolean; public JBoolean(boolean value) { this.value = value; } public void setValue(boolean value) { this.value = value; } public boolean getValue() { return value; } @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } @Override public IAObject getIAObject() { return value ? ABoolean.TRUE : ABoolean.FALSE; } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { serializeTypeTag(writeTypeTag, dataOutput, ATypeTag.BOOLEAN);
public ARectangle getValue() { return (AMutableRectangle) value;
public String getInitParameters() { return initParameters;
adapterRuntimeManager = new AdapterRuntimeManager(ctx, feedId, adapter, writer, partition); ActiveRuntimeId runtimeId = new ActiveRuntimeId(feedId, FeedRuntimeType.INTAKE.toString(), partition); ingestionRuntime = new IngestionRuntime(feedId, runtimeId, adapterRuntimeManager, ctx); feedManager.registerRuntime(ingestionRuntime); writer.open(); open = true; TaskUtils.putInSharedMap(HyracksConstants.KEY_MESSAGE, new VSizeFrame(ctx), ctx); adapterRuntimeManager.start(); synchronized (adapterRuntimeManager) { while (!adapterRuntimeManager.isDone()) { adapterRuntimeManager.wait(); } } if (adapterRuntimeManager.isFailed()) { throw new HyracksDataException("Unable to ingest data"); } } catch (Throwable ie) { /* * An Interrupted Exception is thrown if the Intake job cannot progress further due to failure of another node involved in the Hyracks job. * As the Intake job involves only the intake operator, the exception is indicative of a failure at the sibling intake operator location. * The surviving intake partitions must continue to live and receive data from the external source. */
public static void exit(int status) { if (exitThread.isAlive()) { LOGGER.warn("ignoring duplicate request to exit with status " + status + "; already exiting with status " + exitThread.status + "..."); }
import org.apache.logging.log4j.Level; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; /** * Shutdown hook that invokes {@link NodeControllerService#stop() stop} method. * This shutdown hook must have a failsafe mechanism to halt the process in case the shutdown * operation is hanging for any reason */ public class NCShutdownHook extends Thread { private static final Logger LOGGER = LogManager.getLogger(); private final NodeControllerService nodeControllerService; NCShutdownHook(NodeControllerService nodeControllerService) { super("ShutdownHook-" + nodeControllerService.getId()); this.nodeControllerService = nodeControllerService; } @Override public void run() { try { try { LOGGER.info("Shutdown hook called"); } catch (Throwable th) {//NOSONAR } LOGGER.log(Level.INFO, () -> "Thread dump at shutdown: " + ThreadDumpUtil.takeDumpString()); nodeControllerService.stop();
protected void cleanup() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers .entrySet()) { int pendingOps = partitionPendingOps.get(e.getKey()).intValue(); for (int i = 0; i < pendingOps; i++) { try { e.getValue().first.completeOperation(null, LSMOperationType.MODIFICATION, null, e.getValue().second); } catch (HyracksDataException ex) { throw new ACIDException(ex); } }); }
if (interrupted) { Thread.currentThread().interrupt(); } } } /** * Runs the supplied {@code action} until {@code stopCondition} is met or timeout. */ public static void runWithTimeout(ThrowingAction action, BooleanSupplier stopCondition, long timeout, TimeUnit unit) throws Exception { long remainingTime = unit.toNanos(timeout); final long startTime = System.nanoTime(); while (!stopCondition.getAsBoolean()) { if (remainingTime <= 0) { throw new TimeoutException("Stop condition was not met after " + unit.toSeconds(timeout) + " seconds."); } action.run(); remainingTime -= System.nanoTime() - startTime; } } }
throws HyracksDataException { // start+1 and len-1 due to type tag ignore (only interested in String value) return comparator.compare(a.getByteArray(), a.getStartOffset() + 1, a.getLength() - 1, b.getByteArray(), b.getStartOffset() + 1, b.getLength() - 1); } public static boolean isEqual(IValueReference a, IValueReference b, IBinaryComparator comparator) throws HyracksDataException { return compareStringBinValues(a, b, comparator) == 0; } public static boolean byteArrayEqual(IValueReference valueRef1, IValueReference valueRef2) { return byteArrayEqual(valueRef1, valueRef2, 3); } public static boolean byteArrayEqual(IValueReference valueRef1, IValueReference valueRef2, int dataOffset) { if (valueRef1 == null || valueRef2 == null) { return false; } if (valueRef1 == valueRef2) { return true; } int length1 = valueRef1.getLength(); int length2 = valueRef2.getLength(); if (length1 != length2) { return false; }
utf8Writer = new UTF8StringWriter(); } public static IBinaryComparator createStringBinaryComparator() { return PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY).createBinaryComparator(); } public static int compareStringBinValues(IValueReference a, IValueReference b, IBinaryComparator comparitor) throws HyracksDataException { // start+1 and len-1 due to type tag ignore (only interested in String value) return comparator.compare(a.getByteArray(), a.getStartOffset() + 1, a.getLength() - 1, b.getByteArray(), b.getStartOffset() + 1, b.getLength() - 1); } public static boolean isEqual(IValueReference a, IValueReference b, IBinaryComparator comparitor) throws HyracksDataException { return (compareStringBinValues(a, b, comparitor) == 0); } public static boolean byteArrayEqual(IValueReference valueRef1, IValueReference valueRef2) { return byteArrayEqual(valueRef1, valueRef2, 3); } public static boolean byteArrayEqual(IValueReference valueRef1, IValueReference valueRef2, int dataOffset) { if (valueRef1 == null || valueRef2 == null) {
} IndexCursorUtils.open(btreeAccessors, btreeCursors, btreeRangePredicate); try { for (int i = 0; i < numberOfTrees; i++) { if (btreeCursors[i].hasNext()) { btreeCursors[i].next(); } else { depletedBtreeCursors[i] = true; } } } catch (Throwable th) { // NOSONAR Must catch all failures to close before throwing for (int i = 0; i < numberOfTrees; i++) { IndexCursorUtils.close(btreeCursors[i], th); } throw HyracksDataException.create(th); } } }
public static Throwable close(IIndexCursor cursor, Throwable root) { if (cursor != null) { try { cursor.close(); } catch (Throwable th) { // NOSONAR Will be suppressed try { LOGGER.log(Level.WARN, "Failure closing a cursor", th); } catch (Throwable loggingFailure) { // NOSONAR: Ignore catching Throwable // NOSONAR ignore logging failure } root = ExceptionUtils.suppress(root, th); // NOSONAR: Using the same variable is not bad in this context } } return root;
throws HyracksDataException { int opened = 0; try { for (int i = 0; i < cursors.length; i++) { if (accessors.get(i) != null) { accessors.get(i).search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { IndexCursorUtils.close(cursors[j], th); } throw HyracksDataException.create(th); } } public static void open(IIndexAccessor[] accessors, IIndexCursor[] cursors, ISearchPredicate pred) throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { th = IndexCursorUtils.close(cursors[j], th);
throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { IndexCursorUtils.close(cursors[j], th); } throw HyracksDataException.create(th); } } public static Throwable close(IIndexCursor[] cursors, Throwable th) { for (int j = 0; j < cursors.length; j++) { th = IndexCursorUtils.close(cursors[j], th); } return th; } }
public static Throwable close(IIndexCursor[] cursors, Throwable th) { for (int j = 0; j < cursors.length; j++) { th = IndexCursorUtils.close(cursors[j], th); // NOSONAR: Using the same variable is cleaner in this context } return th;
ILSMOperationTracker getOperationTracker(); ILSMIOOperationScheduler getIOScheduler(); ILSMIOOperationCallback getIOOperationCallback(); /** * components with lower indexes are newer than components with higher index */ List<ILSMDiskComponent> getDiskComponents(); boolean isPrimaryIndex(); void modify(IIndexOperationContext ictx, ITupleReference tuple) throws HyracksDataException; /** * If this method returns successfully, then the cursor has been opened, and need to be closed * Otherwise, it has not been opened * * @param ictx * @param cursor * @param pred * @throws HyracksDataException */ void search(ILSMIndexOperationContext ictx, IIndexCursor cursor, ISearchPredicate pred) throws HyracksDataException; public void scanDiskComponents(ILSMIndexOperationContext ctx, IIndexCursor cursor) throws HyracksDataException; void scheduleFlush(ILSMIndexOperationContext ctx, ILSMIOOperationCallback callback) throws HyracksDataException; ILSMDiskComponent flush(ILSMIOOperation operation) throws HyracksDataException; void scheduleMerge(ILSMIndexOperationContext ctx, ILSMIOOperationCallback callback) throws HyracksDataException; ILSMDiskComponent merge(ILSMIOOperation operation) throws HyracksDataException;
public static Throwable close(IIndexCursor cursor, Throwable root) { if (cursor != null) { try { cursor.close(); } catch (Throwable th) { // NOSONAR Will be suppressed try { LOGGER.log(Level.WARN, "Failure closing a cursor", th); } catch (Throwable loggingFailure) { // NOSONAR: Ignore catching Throwable // NOSONAR ignore logging failure } root = ExceptionUtils.suppress(root, th); } } return root;
IOperatorNodePushable operatorNodePushable = operatorNodePushables.get(activityIdInputIndex.getLeft()); return operatorNodePushable.getInputFrameWriter(activityIdInputIndex.getRight()); } @Override public String getDisplayName() { return "Super Activity " + parent.getActivityMap().values().toString(); } @FunctionalInterface interface OperatorNodePushableAction { void run(IOperatorNodePushable op) throws HyracksDataException; } @SuppressWarnings("unchecked") private void runInParallel(OperatorNodePushableAction action) throws HyracksDataException { List<Future<Void>> tasks = new ArrayList<>(operatorNodePushablesBFSOrder.size()); Queue<Throwable> failures = new ArrayBlockingQueue<>(operatorNodePushablesBFSOrder.size()); final Semaphore startSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); final Semaphore completeSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); int completed = 0; Throwable root = null; try { for (int i = 0; i < operatorNodePushablesBFSOrder.size(); i++) { final int current = i; tasks[i] = ctx.getExecutorService().submit(() -> { startSemaphore.release(); try {
} @FunctionalInterface interface OperatorNodePushableAction { void run(IOperatorNodePushable op) throws HyracksDataException; } @SuppressWarnings("unchecked") private void runInParallel(OperatorNodePushableAction action) throws HyracksDataException { Future<Void>[] tasks = new Future[operatorNodePushablesBFSOrder.size()]; Throwable[] failures = new Throwable[operatorNodePushablesBFSOrder.size()]; final Semaphore startSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); final Semaphore completeSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); Throwable root = null; try { for (int i = 0; i < operatorNodePushablesBFSOrder.size(); i++) { final int current = i; tasks[i] = ctx.getExecutorService().submit(() -> { startSemaphore.release(); try { action.run(operatorNodePushablesBFSOrder.get(current)); } catch (Throwable th) { // NOSONAR: Must catch all causes of failure failures[current] = th; throw th; } finally { completeSemaphore.release(); } return null; }); }
final Semaphore completeSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); int completed = 0; Throwable root = null; try { for (int i = 0; i < operatorNodePushablesBFSOrder.size(); i++) { final int current = i; tasks[i] = ctx.getExecutorService().submit(() -> { startSemaphore.release(); try { action.run(operatorNodePushablesBFSOrder.get(current)); } catch (Throwable th) { // NOSONAR: Must catch all causes of failure failures.offer(th); throw th; } finally { completeSemaphore.release(); } return null; }); } for (Future<Void> task : tasks) { task.get(); completed++; } } catch (ExecutionException e) { root = e.getCause(); completed++; } catch (Throwable e) { // NOSONAR: Must catch all causes of failure root = e; } if (root != null) { cancelTasks(tasks, startSemaphore, completeSemaphore);
*/ Checkpoint getLatest() throws ACIDException; /** * Performs a sharp checkpoint. * * @throws HyracksDataException */ void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void unlockLSN(long lsn); void completed(TxnId id); }
/** * Performs a sharp checkpoint. * * @throws HyracksDataException */ void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void unlockLSN(long lsn); void completed(TxnId id); }
DataflowUtils.addTupleToFrame(tupleAppender, tuple, insertOp); lowWaterMarkLSN = recoveryManager.getMinFirstLSN(); currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN); } } /* * At this point, the low-water mark is not in the initialLowWaterMarkFileId, so * a checkpoint should delete it. We will also start a second * job to ensure that the checkpointing coexists peacefully * with other concurrent readers of the log that request * deletions to be witheld */ JobId jobId2 = nc.newJobId(); IHyracksTaskContext ctx2 = nc.createTestContext(jobId2, 0, false); nc.getTransactionManager().beginTransaction(nc.getTxnJobId(ctx2), new TransactionOptions(ITransactionManager.AtomicityLevel.ENTITY_LEVEL)); // Prepare insert operation LSMInsertDeleteOperatorNodePushable insertOp2 = nc.getInsertPipeline(ctx2, dataset, KEY_TYPES, RECORD_TYPE, META_TYPE, null, KEY_INDEXES, KEY_INDICATOR_LIST, storageManager, null).getLeft(); insertOp2.open(); VSizeFrame frame2 = new VSizeFrame(ctx2);
RECORD_TYPE, META_TYPE, null, KEY_INDEXES, KEY_INDICATOR_LIST, storageManager, null).getLeft(); insertOp2.open(); VSizeFrame frame2 = new VSizeFrame(ctx2); FrameTupleAppender tupleAppender2 = new FrameTupleAppender(frame2); for (int i = 0; i < 4; i++) { long lastCkpoint = recoveryManager.getMinFirstLSN(); long lastFileId = logManager.getLogFileId(lastCkpoint); checkpointManager.tryCheckpoint(lowWaterMarkLSN); // Validate initialLowWaterMarkFileId was deleted for (Long fileId : logManager.getLogFileIds()) { Assert.assertNotEquals(initialLowWaterMarkFileId, fileId.longValue()); } while (currentLowWaterMarkLogFileId == lastFileId) { ITupleReference tuple = tupleGenerator.next(); DataflowUtils.addTupleToFrame(tupleAppender2, tuple, insertOp2); lowWaterMarkLSN = recoveryManager.getMinFirstLSN(); currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN); } }
/** * Performs a sharp checkpoint. * * @throws HyracksDataException */ void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void unlockLSN(long lsn); void completed(TxnId id); }
private void touchLogFile(long fileId) { synchronized (txnLogFileId2ReaderCount) { if (txnLogFileId2ReaderCount.containsKey(fileId)) { txnLogFileId2ReaderCount.put(fileId, txnLogFileId2ReaderCount.get(fileId) + 1); } else { txnLogFileId2ReaderCount.put(fileId, 1); } } fileChannel.close();
public void run() { while (!Thread.currentThread().isInterrupted()) { try { logRecord = flushLogsQ.take(); appendToLogTail(logRecord); } catch (ACIDException e) { e.printStackTrace(); } catch (InterruptedException e) { //ignore } }
if (!checkpointDir.exists()) { if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Checkpoint directory " + checkpointDirPath + " didn't exist. Creating one"); } checkpointDir.mkdirs(); } lsnThreshold = checkpointProperties.getLsnThreshold(); pollFrequency = checkpointProperties.getPollFrequency(); // We must keep at least the latest checkpoint historyToKeep = checkpointProperties.getHistoryToKeep() == 0 ? 1 : checkpointProperties.getHistoryToKeep(); securedLSNs = new HashMap<>();
if (checkpointSucceeded) { ILogManager logManager = txnSubsystem.getLogManager(); synchronized (logManager) { for (Long l : lockedLSNs.keySet()) { if (minFirstLSN > l) { return minFirstLSN; } } logManager.deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } } return minFirstLSN; } @Override public void lockLSN(long lsn) { synchronized (txnSubsystem.getRecoveryManager()) { if (!lockedLSNs.containsKey(lsn)) { lockedLSNs.put(lsn, 1); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) + 1); } } } @Override public void unlockLSN(long lsn) { synchronized (txnSubsystem.getLogManager()) { if (!lockedLSNs.containsKey(lsn)) { return; } else { if (lockedLSNs.get(lsn) == 1) { lockedLSNs.remove(lsn); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) - 1); } } } } }
} } return minFirstLSN; } @Override public void lockLSN(long lsn) { synchronized (txnSubsystem.getLogManager()) { if (!lockedLSNs.containsKey(lsn)) { lockedLSNs.put(lsn, 1); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) + 1); } } } @Override public void unlockLSN(long lsn) { synchronized (txnSubsystem.getLogManager()) { if (!lockedLSNs.containsKey(lsn)) { throw new IllegalStateException("Unlock on nonexisting LSN"); } else { if (lockedLSNs.get(lsn) == 1) { lockedLSNs.remove(lsn); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) - 1); } } } } }
final IVisitablePointable vp1 = pa.allocateRecordValue(inRecType1); final IPointable argPtr0 = new VoidPointable(); final IPointable argPtr1 = new VoidPointable(); final IScalarEvaluator eval0 = args[0].createScalarEvaluator(ctx); final IScalarEvaluator eval1 = args[1].createScalarEvaluator(ctx); final List<RecordBuilder> rbStack = new ArrayList<>(); final ArrayBackedValueStorage tabvs = new ArrayBackedValueStorage(); final IBinaryComparator stringBinaryComparator = PointableHelper.createStringBinaryComparator(); return new IScalarEvaluator() { private final RuntimeRecordTypeInfo runtimeRecordTypeInfo = new RuntimeRecordTypeInfo(); private final DeepEqualAssessor deepEqualAssesor = new DeepEqualAssessor(); private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private DataOutput out = resultStorage.getDataOutput(); @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { resultStorage.reset(); eval0.evaluate(tuple, argPtr0); eval1.evaluate(tuple, argPtr1); vp0.set(argPtr0); vp1.set(argPtr1);
public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException { final PointableAllocator pa = new PointableAllocator(); final IVisitablePointable vp0 = pa.allocateRecordValue(inputRecType); final IVisitablePointable vp1 = pa.allocateListValue(inputListType); final IPointable inputArg0 = new VoidPointable(); final IPointable inputArg1 = new VoidPointable(); final IScalarEvaluator eval0 = inputRecordEvalFactory.createScalarEvaluator(ctx); final IScalarEvaluator eval1 = removeFieldPathsFactory.createScalarEvaluator(ctx); final IBinaryComparator stringBinaryComparator = PointableHelper.createStringBinaryComparator(); return new IScalarEvaluator() { private final RuntimeRecordTypeInfo runtimeRecordTypeInfo = new RuntimeRecordTypeInfo(); private final List<RecordBuilder> rbStack = new ArrayList<>(); private final ArrayBackedValueStorage tabvs = new ArrayBackedValueStorage(); private final Deque<IVisitablePointable> recordPath = new ArrayDeque<>(); private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private DataOutput out = resultStorage.getDataOutput(); @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { resultStorage.reset();
} IndexCursorUtils.open(btreeAccessors, btreeCursors, btreeRangePredicate); try { for (int i = 0; i < numberOfTrees; i++) { if (btreeCursors[i].hasNext()) { btreeCursors[i].next(); } else { depletedBtreeCursors[i] = true; } } } catch (Throwable th) { // NOSONAR Must catch all failures to close before throwing for (int i = 0; i < numberOfTrees; i++) { IndexCursorUtils.close(btreeCursors[i], th); } throw HyracksDataException.create(th); } } }
throws HyracksDataException { int opened = 0; try { for (int i = 0; i < cursors.length; i++) { if (accessors.get(i) != null) { accessors.get(i).search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { IndexCursorUtils.close(cursors[j], th); } throw HyracksDataException.create(th); } } public static void open(IIndexAccessor[] accessors, IIndexCursor[] cursors, ISearchPredicate pred) throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { th = IndexCursorUtils.close(cursors[j], th);
throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { IndexCursorUtils.close(cursors[j], th); } throw HyracksDataException.create(th); } } public static Throwable close(IIndexCursor[] cursors, Throwable th) { for (int j = 0; j < cursors.length; j++) { th = IndexCursorUtils.close(cursors[j], th); } return th; } }
initializationTasks.add(ctx.getExecutorService().submit(new Callable<Void>() { @Override public Void call() throws Exception { opAction.runAction(op, opIndex); return null; } })); } // Waits until all parallel actions to finish. for (Future<Void> initializationTask : initializationTasks) { initializationTask.get(); } } catch (Throwable th) { for (Future<Void> initializationTask : initializationTasks) { initializationTask.cancel(true); } } finally { completeSemaphore.acquireUninterruptibly(); } } }
public LogRecord next() { if (buffer.position() == endOffset) { return null; } RecordReadStatus status = logRecord.readLogRecord(buffer); //underflow is not expected because we are at the very tail of the current log buffer if (status != RecordReadStatus.OK) { logReadFailure(status); throw new IllegalStateException("Unexpected log read status: " + status); } return logRecord;
IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); } capture(minFirstLSN, false); if (checkpointSucceeded) { txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; } private synchronized long getMinSecuredLSN() { return securedLSNs.isEmpty() ? Collections.min(securedLSNs.values()) : -1; } @Override public synchronized void secure(TxnId id) throws HyracksDataException { securedLSNs.put(id, txnSubsystem.getRecoveryManager().getMinFirstLSN()); } @Override public synchronized void completed(TxnId id) { securedLSNs.remove(id); } }
Checkpoint getLatest() throws ACIDException; /** * Performs a sharp checkpoint. * * @throws HyracksDataException */ void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void secure(TxnId id) throws HyracksDataException; /** * Notifies this {@link ICheckpointManager} that the transaction identified by {@code id} completed. * * @param id */ void completed(TxnId id); }
*/ public abstract class AbstractCheckpointManager implements ICheckpointManager { private static final Logger LOGGER = LogManager.getLogger(); private static final String CHECKPOINT_FILENAME_PREFIX = "checkpoint_"; public static final long SHARP_CHECKPOINT_LSN = -1; private static final FilenameFilter filter = (File dir, String name) -> name.startsWith(CHECKPOINT_FILENAME_PREFIX); private final File checkpointDir; private final int historyToKeep; private final int lsnThreshold; private final int pollFrequency; protected final ITransactionSubsystem txnSubsystem; private CheckpointThread checkpointer; public AbstractCheckpointManager(ITransactionSubsystem txnSubsystem, CheckpointProperties checkpointProperties) { this.txnSubsystem = txnSubsystem; String checkpointDirPath = checkpointProperties.getCheckpointDirPath(); if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Checkpoint directory = " + checkpointDirPath); } if (!checkpointDirPath.endsWith(File.separator)) { checkpointDirPath += File.separator; } checkpointDir = new File(checkpointDirPath); // Create the checkpoint directory if missing if (!checkpointDir.exists()) {
final long minFirstLSN = txnSubsystem.getRecoveryManager().getMinFirstLSN(); boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN; if (!checkpointSucceeded) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); } capture(minFirstLSN, false); if (checkpointSucceeded) { txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; } @Override public synchronized void secure(TxnId id) throws HyracksDataException { securedLSNs.put(id, txnSubsystem.getRecoveryManager().getMinFirstLSN()); } @Override public synchronized void completed(TxnId id) throws IllegalStateException { if (securedLSNs.containsKey(id)) { securedLSNs.remove(id); } else { throw new IllegalStateException(
} } @Override public void abortTransaction(TxnId txnId) throws ACIDException { final ITransactionContext txnCtx = getTransactionContext(txnId); try { if (txnCtx.isWriteTxn()) { LogRecord logRecord = new LogRecord(); TransactionUtil.formJobTerminateLogRecord(txnCtx, logRecord, false); txnSubsystem.getLogManager().log(logRecord); txnSubsystem.getCheckpointManager().secure(txnId); txnSubsystem.getRecoveryManager().rollbackTransaction(txnCtx); txnCtx.setTxnState(ITransactionManager.ABORTED); } } catch (HyracksDataException e) { String msg = "Could not complete rollback! System is in an inconsistent state"; if (LOGGER.isErrorEnabled()) { LOGGER.log(Level.ERROR, msg, e); } throw new ACIDException(msg, e); } finally { txnCtx.complete(); txnSubsystem.getLockManager().releaseLocks(txnCtx); txnCtxRepository.remove(txnCtx.getTxnId()); txnSubsystem.getCheckpointManager().completed(txnId); } } @Override public long getMaxTxnId() { return maxTxnId.get(); } @Override public void start() {
*/ public abstract class AbstractCheckpointManager implements ICheckpointManager { private static final Logger LOGGER = LogManager.getLogger(); private static final String CHECKPOINT_FILENAME_PREFIX = "checkpoint_"; public static final long SHARP_CHECKPOINT_LSN = -1; private static final FilenameFilter filter = (File dir, String name) -> name.startsWith(CHECKPOINT_FILENAME_PREFIX); private final File checkpointDir; private final int historyToKeep; private final int lsnThreshold; private final int pollFrequency; protected Map<TxnId, Long> securedLSNs; protected final ITransactionSubsystem txnSubsystem; private CheckpointThread checkpointer; public AbstractCheckpointManager(ITransactionSubsystem txnSubsystem, CheckpointProperties checkpointProperties) { this.txnSubsystem = txnSubsystem; String checkpointDirPath = checkpointProperties.getCheckpointDirPath(); if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Checkpoint directory = " + checkpointDirPath); } if (!checkpointDirPath.endsWith(File.separator)) { checkpointDirPath += File.separator; } checkpointDir = new File(checkpointDirPath); // Create the checkpoint directory if missing if (!checkpointDir.exists()) {
for (DatasetResourceReference indexRef : partitionResources) { long remoteIndexMaxLSN = idxCheckpointMgrProvider.get(indexRef).getLowWatermark(); minRemoteLSN = Math.min(minRemoteLSN, remoteIndexMaxLSN); } } return minRemoteLSN; } @Override public synchronized void replayReplicaPartitionLogs(Set<Integer> partitions, boolean flush) throws HyracksDataException { //replay logs > minLSN that belong to these partitions final TxnId randomDummyTxnId = new TxnId(ThreadLocalRandom.current().nextInt(Integer.MIN_VALUE, -1)); try { checkpointManager.secure(recoveryTxnId); long minLSN = getPartitionsMinLSN(partitions); long readableSmallestLSN = logMgr.getReadableSmallestLSN(); if (minLSN < readableSmallestLSN) { minLSN = readableSmallestLSN; } replayPartitionsLogs(partitions, logMgr.getLogReader(true), minLSN); if (flush) { appCtx.getDatasetLifecycleManager().flushAllDatasets(); } } catch (IOException | ACIDException e) { throw HyracksDataException.create(e); } finally { checkpointManager.completed(randomDummyTxnId); } } @Override
void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; /** * Secures the current low-water mark until the transaction identified by {@code id} completes. * * @param id * @throws HyracksDataException */ void secure(TxnId id) throws HyracksDataException; /** * Notifies this {@link ICheckpointManager} that the transaction identified by {@code id} completed. * * @param id */ void completed(TxnId id); }
* @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; /** * Secures the current low-water mark until the transaction identified by {@code id} completes. * * @param id * @throws HyracksDataException */ void secure(TxnId id) throws HyracksDataException; /** * Notifies this {@link ICheckpointManager} that the transaction identified by {@code id} completed. * * @param id */ void completed(TxnId id); }
* KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.transaction.management.service.recovery; import java.io.BufferedWriter; import java.io.File; import java.io.FilenameFilter; import java.io.IOException; import java.io.OutputStream; import java.nio.channels.ClosedByInterruptException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.List; import java.util.Map; import org.apache.asterix.common.exceptions.ACIDException; import org.apache.asterix.common.transactions.Checkpoint; import org.apache.asterix.common.transactions.CheckpointProperties; import org.apache.asterix.common.transactions.ICheckpointManager; import org.apache.asterix.common.transactions.ILogManager; import org.apache.asterix.common.transactions.ITransactionManager; import org.apache.asterix.common.transactions.ITransactionSubsystem; import org.apache.asterix.common.transactions.TxnId; import org.apache.asterix.common.utils.StorageConstants; import org.apache.hyracks.api.exceptions.HyracksDataException;
* log files that end with LSN < {@code checkpointTargetLSN} are deleted. */ @Override public synchronized long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException { LOGGER.info("Attemping soft checkpoint..."); final long minFirstLSN = txnSubsystem.getRecoveryManager().getMinFirstLSN(); final long minSecuredLSN = getMinSecuredLSN(); if (minSecuredLSN != NO_SECURED_LSN && minFirstLSN >= getMinSecuredLSN()) { return minSecuredLSN; } boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN; if (!checkpointSucceeded) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); } capture(minFirstLSN, false); if (checkpointSucceeded) { txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; } private synchronized long getMinSecuredLSN() {
IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); } capture(minFirstLSN, false); if (checkpointSucceeded) { txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; } private synchronized long getMinSecuredLSN() { return securedLSNs.isEmpty() ? NO_SECURED_LSN : Collections.min(securedLSNs.values()); } @Override public synchronized void secure(TxnId id) throws HyracksDataException { securedLSNs.put(id, txnSubsystem.getRecoveryManager().getMinFirstLSN()); } @Override public synchronized void completed(TxnId id) { securedLSNs.remove(id); } }
public void run() { Thread ct = Thread.currentThread(); String threadName = ct.getName(); ct.setName(displayName + ":" + taskAttemptId + ":" + 0); // Calls synchronized addPendingThread(..) to make sure that in the abort() method, // the thread is not escaped from interruption. if (!addPendingThread(ct)) { exceptions.add(new InterruptedException("Task " + getTaskAttemptId() + " was aborted!")); ExceptionUtils.setNodeIds(exceptions, ncs.getId()); ncs.getWorkQueue().schedule(new NotifyTaskFailureWork(ncs, this, exceptions)); return; } try { ct.setName(displayName + ":" + taskAttemptId + ":" + 0); try { operator.initialize(); if (collectors.length > 0) { final Semaphore sem = new Semaphore(collectors.length - 1); for (int i = 1; i < collectors.length; ++i) { final IPartitionCollector collector = collectors[i]; final IFrameWriter writer = operator.getInputFrameWriter(i); sem.acquire(); final int cIdx = i; executorService.execute(new Runnable() { @Override
int tzCount = tzIds.length; TIMEZONE_IDS = new byte[tzCount][]; TIMEZONE_OFFSETS = new int[tzCount]; for (int i = 0; i < tzCount; i++) { TIMEZONE_IDS[i] = encode(tzIds[i]); } Arrays.sort(TIMEZONE_IDS, byteArrayComparator); for (int i = 0; i < tzCount; i++) { TIMEZONE_OFFSETS[i] = TimeZone.getTimeZone(new String(TIMEZONE_IDS[i], ENCODING)).getRawOffset(); } } private static final DateTimeFormatUtils INSTANCE = new DateTimeFormatUtils(); public static DateTimeFormatUtils getInstance() { return INSTANCE; } private DateTimeFormatUtils() { } private int parseFormatField(byte[] format, int formatStart, int formatLength, int formatPointer, char formatChar, int maxAllowedFormatCharCopied) { int formatCharCopies = 0; formatPointer++; formatCharCopies++;
&& data[dataStart + timezoneEndField] <= 'Z') || data[dataStart + timezoneEndField] == '/' || data[dataStart + timezoneEndField] == '_')) { timezoneEndField++; } int searchIdx = binaryTimezoneIDSearch(data, dataStart + dataStringPointer, timezoneEndField - dataStringPointer); if (searchIdx >= 0) { timezone = TIMEZONE_OFFSETS[searchIdx]; } else { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException("Unexpected timezone string: " + new String( data, dataStart + dataStringPointer, dataStart + timezoneEndField, ENCODING)); } else { return false; } } dataStringPointer = timezoneEndField; } timezoneExists = true; break; case AMPM: if (dataStringPointer + 1 < dataLength) { if (hour > 12 || hour <= 0) { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException( "Hour " + hour + " cannot be a time for AM/PM.");
} else { return false; } } if (byteArrayEqualToString(data, dataStart + dataStringPointer, 2, AM_BYTEARRAY)) { // do nothing } else if (byteArrayEqualToString(data, dataStart + dataStringPointer, 2, PM_BYTEARRAY)) { hour += 12; if (hour == 24) { hour = 0; } } else { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException("Unexpected string for AM/PM marker " + new String(data, dataStart + dataStringPointer, dataStart + dataStringPointer + 2, ENCODING)); } else { return false; } } dataStringPointer += 2; } else { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException("Cannot find valid AM/PM marker."); } else { return false; } } break; case SKIPPER: // just skip all continuous character and numbers
public long getWrites() { try { List<String> rows = getInfo(); long writes = extractRow(rows, 5); long cancelledWrites = extractRow(rows, 6); return writes - cancelledWrites; } catch (Exception e) { LOGGER.log(failureCount++ > 0 ? Level.DEBUG : Level.WARN, "Failure getting writes", e); return IOCounterDefault.IO_COUNTER_UNAVAILABLE; }
"Input stream given to OnDiskInvertedIndex bulk load is not sorted."); } } // Remember last tuple by creating a copy. // TODO: This portion can be optimized by only copying the token when it changes, and using the last appended inverted-list element as a reference. lastTupleBuilder.reset(); for (int i = 0; i < tuple.getFieldCount(); i++) { lastTupleBuilder.addField(tuple.getFieldData(i), tuple.getFieldStart(i), tuple.getFieldLength(i)); } lastTuple.reset(lastTupleBuilder.getFieldEndOffsets(), lastTupleBuilder.getByteArray()); } @Override public void end() throws HyracksDataException { // The last tuple builder is empty if add() was never called. if (lastTupleBuilder.getSize() != 0) { createAndInsertBTreeTuple(); } btreeBulkloader.end(); if (currentPage != null) { queue.put(currentPage); } invListsMaxPageId = currentPageId; bufferCache.finishQueue(); } @Override public void abort() throws HyracksDataException { if (btreeBulkloader != null) { btreeBulkloader.abort(); } } } @Override
lastTupleBuilder.reset(); for (int i = 0; i < tuple.getFieldCount(); i++) { lastTupleBuilder.addField(tuple.getFieldData(i), tuple.getFieldStart(i), tuple.getFieldLength(i)); } } @Override public void end() throws HyracksDataException { // The last tuple builder is empty if add() was never called. if (lastTupleBuilder.getSize() != 0) { createAndInsertBTreeTuple(); } btreeBulkloader.end(); if (currentPage != null) { queue.put(currentPage); } invListsMaxPageId = currentPageId; bufferCache.finishQueue(); } @Override public void abort() throws HyracksDataException { if (btreeBulkloader != null) { btreeBulkloader.abort(); } } } @Override public IBufferCache getBufferCache() { return bufferCache; } public int getInvListsFileId() { return fileId; } public int getInvListsMaxPageId() { return invListsMaxPageId; } @Override public IBinaryComparatorFactory[] getInvListCmpFactories() {
} public class OnDiskInvertedIndexAccessor implements IInvertedIndexAccessor { private final OnDiskInvertedIndex index; private final IInvertedIndexSearcher searcher; private final IIndexOperationContext opCtx = new OnDiskInvertedIndexOpContext(btree); public OnDiskInvertedIndexAccessor(OnDiskInvertedIndex index) throws HyracksDataException { this.index = index; this.searcher = new TOccurrenceSearcher(ctx, index); } // Let subclasses initialize. protected OnDiskInvertedIndexAccessor(OnDiskInvertedIndex index, IInvertedIndexSearcher searcher) { this.index = index; this.searcher = searcher; } @Override public IIndexCursor createSearchCursor(boolean exclusive) throws HyracksDataException { if (searcher == null) { searcher = new TOccurrenceSearcher(index, ctx); } return new OnDiskInvertedIndexSearchCursor(searcher); } @Override public void search(IIndexCursor cursor, ISearchPredicate searchPred) throws HyracksDataException { searcher.search((OnDiskInvertedIndexSearchCursor) cursor, (InvertedIndexSearchPredicate) searchPred, opCtx); } @Override public IInvertedListCursor createInvertedListCursor() { return index.createInvertedListCursor(); } @Override public void openInvertedListCursor(IInvertedListCursor listCursor, ITupleReference searchKey) throws HyracksDataException {
public void setKeyTuple(ITupleReference key) { newToken = this.keyTuple == null; this.keyTuple = key;
for (int i = 0; i < end; i++) { if (bloomFilters[i] != null && !bloomFilters[i].contains(keysOnlyTuple, hashes)) { continue; } deletedKeysBTreeAccessors.get(i).search(deletedKeysBTreeCursors[i], keySearchPred); try { if (deletedKeysBTreeCursors[i].hasNext()) { return true; } } finally { deletedKeysBTreeCursors[i].close(); } } return false; } @Override public void doClose() throws HyracksDataException { try { super.doClose(); } finally { if (deletedKeysBTreeCursors != null) { for (int i = 0; i < deletedKeysBTreeCursors.length; i++) { deletedKeysBTreeCursors[i].close(); } } } ======= if (deletedKeysBTreeCursors != null) { for (int i = 0; i < deletedKeysBTreeCursors.length; i++) { deletedKeysBTreeCursors[i].close(); } } super.doClose(); >>>>>>> initial commit } @Override public void doDestroy() throws HyracksDataException {
IIndex invIndex = testCtx.getIndex(); if (LOGGER.isInfoEnabled()) { LOGGER.info("Validating index: " + invIndex); } // Validate index and compare against expected index. invIndex.validate(); if (invIndexType == InvertedIndexType.INMEMORY || invIndexType == InvertedIndexType.ONDISK) { // This comparison method exercises different features of these types of inverted indexes. LSMInvertedIndexTestUtils.compareActualAndExpectedIndexes(testCtx); } LSMInvertedIndexTestUtils.compareActualAndExpectedIndexesRangeSearch(testCtx); if (invIndexType == InvertedIndexType.LSM || invIndexType == InvertedIndexType.PARTITIONED_LSM) { LSMInvertedIndex lsmIndex = (LSMInvertedIndex) invIndex; if (!lsmIndex.isMemoryComponentsAllocated() || lsmIndex.isCurrentMutableComponentEmpty()) { LSMInvertedIndexTestUtils.compareActualAndExpectedIndexesMergeSearch(testCtx); } } } /** * Runs a workload of queries using different search modifiers, and verifies the correctness of the results. */ protected void runTinySearchWorkload(LSMInvertedIndexTestContext testCtx, TupleGenerator tupleGen) throws IOException { for (IInvertedIndexSearchModifier searchModifier : TEST_SEARCH_MODIFIERS) {
* @throws AlgebricksException */ public boolean isSubFieldNullable(List<String> subFieldName) throws AlgebricksException { IAType subRecordType = getFieldType(subFieldName.get(0)); boolean nullable = false; for (int i = 1; i < subFieldName.size(); i++) { if (subRecordType == null) { // open field is nullable return true; } if (subRecordType.getTypeTag().equals(ATypeTag.UNION)) { if (NonTaggedFormatUtil.isOptional(subRecordType)) { return true; } subRecordType = ((AUnionType) subRecordType).getActualType(); if (subRecordType.getTypeTag() != ATypeTag.OBJECT) { throw new AsterixException( "Field accessor is not defined for values of type " + subRecordType.getTypeTag()); } } subRecordType = ((ARecordType) subRecordType).getFieldType(subFieldName.get(i)); } return nullable || subRecordType == null || NonTaggedFormatUtil.isOptional(subRecordType); } /**
boolean changed = changeRec(expr, arg); if (!checkArgs(expr) || !expr.isFunctional()) { return new Pair<>(changed, expr); } // Skip Constant Folding for the record-related functions. if (FUNC_ID_SET_THAT_SHOULD_NOT_BE_APPLIED.contains(expr.getFunctionIdentifier())) { return new Pair<>(false, null); } try { // Current List SerDe assumes a strongly typed list, so we do not constant fold the list constructors // if they are not strongly typed if (expr.getFunctionIdentifier().equals(BuiltinFunctions.UNORDERED_LIST_CONSTRUCTOR) || expr.getFunctionIdentifier().equals(BuiltinFunctions.ORDERED_LIST_CONSTRUCTOR)) { AbstractCollectionType listType = (AbstractCollectionType) TypeCastUtils.getRequiredType(expr); if (listType != null && (listType.getItemType().getTypeTag() == ATypeTag.ANY || listType.getItemType() instanceof AbstractCollectionType)) { //case1: listType == null, could be a nested list inside a list<ANY> //case2: itemType = ANY //case3: itemType = a nested list
IScalarEvaluator eval = fact.createScalarEvaluator(null); eval.evaluate(null, p); Object t = _emptyTypeEnv.getType(expr); @SuppressWarnings("rawtypes") ISerializerDeserializer serde = jobGenCtx.getSerializerDeserializerProvider().getSerializerDeserializer(t); bbis.setByteBuffer(ByteBuffer.wrap(p.getByteArray(), p.getStartOffset(), p.getLength()), 0); IAObject o = (IAObject) serde.deserialize(dis); return new Pair<>(true, new ConstantExpression(new AsterixConstantValue(o))); } catch (HyracksDataException | AlgebricksException e) { if (AlgebricksConfig.ALGEBRICKS_LOGGER.isDebugEnabled()) { AlgebricksConfig.ALGEBRICKS_LOGGER.debug("Exception caught at constant folding: " + e, e); } return new Pair<>(false, null); } } @Override public Pair<Boolean, ILogicalExpression> visitAggregateFunctionCallExpression( AggregateFunctionCallExpression expr, Void arg) throws AlgebricksException { boolean changed = changeRec(expr, arg); return new Pair<>(changed, expr); } @Override public Pair<Boolean, ILogicalExpression> visitStatefulFunctionCallExpression( StatefulFunctionCallExpression expr, Void arg) throws AlgebricksException { boolean changed = changeRec(expr, arg); return new Pair<>(changed, expr); } @Override
empty-tuple-source -- |UNPARTITIONED| assign [$$29] <- [TRUE] -- |UNPARTITIONED| assign [$$26] <- [TRUE] -- |UNPARTITIONED| data-scan []<-[$$20, $$21, $$2] <- tpch:LineItems -- |UNPARTITIONED| empty-tuple-source -- |UNPARTITIONED| */ public class InlineSubplanInputForNestedTupleSourceRule implements IAlgebraicRewriteRule { @Override public boolean rewritePre(Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException { if (hasRun) { return false; } if (context.checkIfInDontApplySet(this, opRef.getValue())) { return false; } Pair<Boolean, LinkedHashMap<LogicalVariable, LogicalVariable>> result = rewriteSubplanOperator(opRef, context); return result.first; } private Pair<Boolean, LinkedHashMap<LogicalVariable, LogicalVariable>> rewriteSubplanOperator( Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException { AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue(); // Recursively traverses input operators as if the current operator before rewriting the current operator. Pair<Boolean, LinkedHashMap<LogicalVariable, LogicalVariable>> changedAndVarMap = traverseNonSubplanOperator(op, context);
translator.addVariableToMetaScope(new VarIdentifier("$$RIGHT_" + i), rightInputVarCopy); for (int j = 0; j < rightInputPKs.size(); j++) { rightInputVarCopy = copyVisitor.varCopy(rightInputPKs.get(j)); translator.addVariableToMetaScope(new VarIdentifier("$$RIGHTPK_" + i + "_" + j), rightInputVarCopy); } copyVisitor.updatePrimaryKeys(context); copyVisitor.reset(); } AQLPlusParser parser = new AQLPlusParser(new StringReader(aqlPlus)); parser.initScope(); parser.setVarCounter(counter); List<Clause> clauses; try { clauses = parser.Clauses(); } catch (ParseException e) { throw new AlgebricksException(e); } // Step 4. The essential substitution with translator. ILogicalPlan plan; try { plan = translator.translate(clauses); } catch (AsterixException e) { throw new AlgebricksException(e); } context.setVarCounter(counter.get());
} while (triggerCount == previousTriggerCount); return triggerCount; } /** * Test time-based invalidation in CatalogdTableInvalidator. */ @Test public void testCatalogdTableInvalidator() throws CatalogException, InterruptedException { Reference<Boolean> tblWasRemoved = new Reference<>(); Reference<Boolean> dbWasAdded = new Reference<>(); String dbName = "functional"; String tblName = "alltypes"; catalog_.invalidateTable(new TTableName(dbName, tblName), tblWasRemoved, dbWasAdded); MockTicker ticker = new MockTicker(); CatalogdTableInvalidator.TIME_SOURCE = ticker; catalog_.setCatalogdTableInvalidator( new CatalogdTableInvalidator(catalog_, /*unusedTableTtlSec=*/ 2, /*invalidateTablesOnMemoryPressure=*/false, /*oldGenFullThreshold=*/ 0.6, /*gcInvalidationFraction=*/0.1)); Assert.assertFalse(catalog_.getDb(dbName).getTable(tblName).isLoaded()); Table table = catalog_.getOrLoadTable(dbName, tblName); Assert.assertTrue(table.isLoaded()); Assert.assertEquals(ticker.now_, table.getLastUsedTime()); long previousTriggerCount = catalog_.getCatalogdTableInvalidator().triggerCount_.get();
profile_ = new TRuntimeProfileNode("Frontend", /*num_children=*/ 0, /*counters=*/new ArrayList<>(), /*metadata=*/-1L, // TODO(todd) what is this used for? why is it required? /*indent=*/false, /*info_strings=*/new HashMap<>(), /*info_strings_display_order*/new ArrayList<>(), /*child_counters_map=*/ImmutableMap.of(ROOT_COUNTER_NAME, new HashSet<>())); } /** * Create a new profile, setting it as the current thread-local profile for the * length of the current scope. This is meant to be used in a try-with-resources * statement. */ public static Scope createNewWithScope() { return new Scope(new FrontendProfile()); } /** * Get the profile attached to the current thread, throw IllegalStateException if there * is none. */ @Nonnull public static FrontendProfile getCurrent() { FrontendProfile prof = THREAD_LOCAL.get(); Preconditions.checkState(prof != null, "no profile in scope"); return prof; } /**
private boolean shouldEvictFromFullHeapAfterGc() { if (!invalidateTableOnMemoryPressure_) return false; long gcCount = oldGenGcBean_.getCollectionCount(); if (gcCount > lastObservedGcCount_) { lastObservedGcCount_ = gcCount; GcInfo lastGcInfo = oldGenGcBean_.getLastGcInfo(); if (lastGcInfo == null) { LOG.warn("gcBean.getLastGcInfo() returned null. Table invalidation based on " + "memory pressure was skipped."); return false; } MemoryUsage tenuredGenUsage = lastGcInfo.getMemoryUsageAfterGc().get(oldGcGenName_); return tenuredGenUsage.getMax() * oldGenFullThreshold_ < tenuredGenUsage.getUsed(); } return false;
long gcCount = oldGenGcBean_.getCollectionCount(); if (gcCount > lastObservedGcCount_) { lastObservedGcCount_ = gcCount; GcInfo lastGcInfo = oldGenGcBean_.getLastGcInfo(); if (lastGcInfo == null) { LOG.warn("gcBean.getLastGcInfo() returns null. Will continue without " + "invalidating tables based on memory pressure this time."); return false; } MemoryUsage tenuredGenUsage = lastGcInfo.getMemoryUsageAfterGc().get(oldGcGenName_); Preconditions.checkState(tenuredGenUsage != null); return tenuredGenUsage.getMax() * oldGenFullThreshold_ < tenuredGenUsage.getUsed(); } return false;
if (removedDb == null) { // Nothing was removed from the catalogd's cache. resp.result.setVersion(catalog_.getCatalogVersion()); return; } // Make sure the cache directives, if any, of the underlying tables are removed for (String tableName: removedDb.getAllTableNames()) { uncacheTable(removedDb.getTable(tableName)); } removedObject = removedDb.toTCatalogObject(); } updateOwnerPrivileges(db.getName(), /* tableName */ null, params.server_name, db.getMetaStoreDb().getOwnerName(), db.getMetaStoreDb().getOwnerType(), /* newOwner */ null, /* newOwnerType */ null, resp); Preconditions.checkNotNull(removedObject); resp.result.setVersion(removedObject.getCatalog_version()); resp.result.addToRemoved_catalog_objects(removedObject); addSummary(resp, "Database has been dropped."); } /** * Drops all the Kudu tables of database 'db' from the Kudu storage engine. Retrieves * the Kudu table name of each table in 'db' from HMS. Throws an ImpalaException if
table = catalog_.removeTable(params.getTable_name().db_name, params.getTable_name().table_name); if (table == null) { // Nothing was removed from the catalogd's cache. resp.result.setVersion(catalog_.getCatalogVersion()); return; } resp.result.setVersion(table.getCatalogVersion()); uncacheTable(table); } if (table.getMetaStoreTable() != null) { updateDatabasePrivileges(table.getDb().getName(), table.getName(), params.server_name, table.getMetaStoreTable().getOwner(), table.getMetaStoreTable().getOwnerType(), /* newOwner */ null, /* newOwnerType */ null, resp); } removedObject.setType(TCatalogObjectType.TABLE); removedObject.setTable(new TTable()); removedObject.getTable().setTbl_name(tableName.getTbl()); removedObject.getTable().setDb_name(tableName.getDb()); removedObject.setCatalog_version(resp.result.getVersion()); resp.result.addToRemoved_catalog_objects(removedObject); } /**
// list of the revoked privileges that contain the grant option. The rolePrivileges // parameter will contain a list of new privileges without the grant option that are // granted. If this is simply a revoke of a privilege without grant options, the // api will still return revoked privileges, but the rolePrivileges will be empty // since there will be no newly granted privileges. rolePrivileges = Lists.newArrayList(); removedGrantOptPrivileges = catalog_.getSentryProxy() .revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), rolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); } Preconditions.checkNotNull(rolePrivileges); List<TCatalogObject> updatedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: rolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); }
} resp.result.setVersion(role.getCatalogVersion()); } /** * Grants or revokes one or more privileges to/from a Sentry role on behalf of the * requestingUser. */ private void grantRevokeRolePrivilege(User requestingUser, TGrantRevokePrivParams grantRevokePrivParams, TDdlExecResponse resp) throws ImpalaException { Preconditions.checkNotNull(requestingUser); verifySentryServiceEnabled(); String roleName = grantRevokePrivParams.getRole_name(); List<TPrivilege> privileges = grantRevokePrivParams.getPrivileges(); List<PrincipalPrivilege> addedRolePrivileges = null; List<PrincipalPrivilege> removedGrantOptPrivileges = Lists.newArrayList(); if (grantRevokePrivParams.isIs_grant()) { rolePrivileges = catalog_.getSentryProxy().grantRolePrivileges(requestingUser, roleName, privileges); addSummary(resp, "Privilege(s) have been granted."); } else { // If this is a revoke of a privilege that contains the grant option, the privileges // with the grant option will be revoked and new privileges without the grant option
} if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog. if (grantRevokePrivParams.isIs_grant()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setVersion( updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version()); } } else if (privileges.get(0).isHas_grant_opt()) { if (!updatedPrivs.isEmpty() && !removedPrivs.isEmpty()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion( updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version() > removedPrivs.get(removedPrivs.size() - 1).getCatalog_version() ? updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version() : removedPrivs.get(removedPrivs.size() - 1).getCatalog_version()); } else { resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion(
private static final String ERROR_MSG_BAD_COLUMN_VALUE = "Raw value '" + ROW_BAD_COLUMN_VALUE + "' couldn't be parsed to type Type: int8 for column 'byteFld'"; private static final String POLICY_REJECT = "REJECT"; private static final String POLICY_WARN = "WARN"; private static final String POLICY_IGNORE = "IGNORE"; @Rule public ExpectedException thrown = ExpectedException.none(); @Test public void testMissingColumnThrowsExceptionDefaultConfig() throws Exception { Context additionalContext = new Context(); additionalContext.put(PATTERN_PROP, TEST_REGEXP_MISSING_COLUMN); testThrowsException(additionalContext, ERROR_MSG_MISSING_COLUMN, ROW_MISSING_COLUMN); } @Test public void testMissingColumnThrowsExceptionDeprecated() throws Exception { Context additionalContext = new Context(); additionalContext.put(PATTERN_PROP, TEST_REGEXP_MISSING_COLUMN); additionalContext.put(SKIP_MISSING_COLUMN_PROP, String.valueOf(false)); testThrowsException(additionalContext, ERROR_MSG_MISSING_COLUMN, ROW_MISSING_COLUMN); } @Test public void testMissingColumnThrowsException() throws Exception { Context additionalContext = new Context();
* The phases of aggregate computation are as follows. Also see AggregateInfo. * - Only a non-distinct class: * - Example: SELECT max(a) FROM... * - 1-phase aggregation * - One distinct class, and optionally a non-distinct class: * - Example: SELECT count(distinct a)[, max(b)] FROM... * - coalesced into a single AggregateInfo to preserve the pre-IMPALA-110 behavior * - 2-phase aggregation, 1st phase groups by GROUP BY plus DISTINCT exprs, 2nd phase * groups by GROUP BY * - the non-distinct class is carried along the two phases, aggregated in 1st phase and * merged in 2nd phase * - Multiple distinct classes, and optionally a non-distinct class * - Example: SELECT count(distinct a), count(distinct b)[, max(c)] FROM... * - 2-phase aggregation followed by a transposition aggregation * - aggregation nodes update and maintain the state of all aggregation classes at once
*/ final private Thread daemonThread_; /** * The threshold above which the old gen is considered almost full. */ final private double oldGenFullThreshold_; /** * The ratio of tables to invalidate when the old gen is almost full. */ final private double gcInvalidationFraction_; /** * The number of times the daemon thread wakes up and scans the tables for invalidation. * It's useful for tests to ensure that a scan happened. */ @VisibleForTesting AtomicLong scanCount_ = new AtomicLong(); private GarbageCollectorMXBean oldGenGcBean_; /** * The name of the old gen memory pool. */ private String oldGcGenName_; /** * The value of oldGenGcBean_.getCollectionCount() when the last memory-based * invalidation was executed. */ private long lastObservedGcCount_; private boolean stopped_ = false; /** * Last time an time-based invalidation is executed in nanoseconds. */ private long lastInvalidationTime_;
private boolean shouldEvictFromFullHeapAfterGc() { if (!invalidateTableOnMemoryPressure_) return false; long gcCount = oldGenGcBean_.getCollectionCount(); if (gcCount > lastObservedGcCount_) { lastObservedGcCount_ = gcCount; GcInfo lastGcInfo = oldGenGcBean_.getLastGcInfo(); if (lastGcInfo == null) { LOG.warn("gcBean.getLastGcInfo() returned null. Table invalidation based on " + "memory pressure was skipped."); return false; } MemoryUsage tenuredGenUsage = lastGcInfo.getMemoryUsageAfterGc().get(oldGcGenName_); return tenuredGenUsage.getMax() * oldGenFullThreshold_ < tenuredGenUsage.getUsed(); } return false;
* If a user with the same name already exists it will be overwritten. */ public User addUser(String userName) { Principal user = addPrincipal(userName, Sets.<String>newHashSet(), TPrincipalType.USER); Preconditions.checkState(user instanceof User); return (User) user; } /** * Add a user to the catalog if it doesn't exist. This is necessary so privileges * can be added for a user. example: owner privileges. */ public org.apache.impala.catalog.User addUserIfNotExists(String owner) { versionLock_.writeLock().lock(); try { org.apache.impala.catalog.User user = getAuthPolicy().getUser(owner); if (user == null) { user = addUser(owner); } return user; } finally { versionLock_.writeLock().unlock(); } } private Principal addPrincipal(String principalName, Set<String> grantGroups, TPrincipalType type) { versionLock_.writeLock().lock(); try { Principal principal = Principal.newInstance(principalName, type, grantGroups);
PrincipalPrivilege privilege = owner.getPrivilege(filter.getPrivilege_name()); if (privilege != null) { PrincipalPrivilege removedPrivilege = catalog_.getAuthPolicy() .removePrivilege(privilege); removedPrivilege.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege .toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } } /** * This is a helper method to take care of catalog related updates when removing * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER);
} else { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error adding privilege: ", e); } } /** * Create a new HMS Partition. */ private static Partition createHmsPartition(List<TPartitionKeyValue> partitionSpec, org.apache.hadoop.hive.metastore.api.Table msTbl, TableName tableName, String location) { List<String> values = Lists.newArrayList(); // Need to add in the values in the same order they are defined in the table. for (FieldSchema fs: msTbl.getPartitionKeys()) { for (TPartitionKeyValue kv: partitionSpec) {
Map<String, Set<TSentryPrivilege>> allUsersPrivileges = sentryPolicyService_.listAllUsersPrivileges(processUser_); for (Map.Entry<String, Set<TSentryPrivilege>> userPrivilegesEntry: allUsersPrivileges.entrySet()) { String userName = userPrivilegesEntry.getKey(); // This user exists and should not be removed so remove it from the // usersToRemove set. usersToRemove.remove(userName); Reference<Boolean> existingUser = new Reference<>(); org.apache.impala.catalog.User user = catalog_.addUserIfNotExists(userName, existingUser); if (existingUser.getRef() && resetVersions_) { user.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } refreshPrivilegesInCatalog(user, allUsersPrivileges); } return usersToRemove; } /** * Updates the privileges for a given principal in the catalog since the last Sentry * sync update. */ private void refreshPrivilegesInCatalog(Principal principal, Map<String, Set<TSentryPrivilege>> allPrincipalPrivileges) throws CatalogException { // Assume all privileges should be removed. Privileges that still exist are // deleted from this set and we are left with the set of privileges that need // to be removed.
TableName tableName = table.getTableName(); PrivilegeRequestBuilder builder = new PrivilegeRequestBuilder() .onTable(tableName.getDb(), tableName.getTbl()) .allOf(priv); if (requireGrantOption) { builder.grantOption(); } registerPrivReq(builder.toRequest()); } /** * Returns the server name if authorization is enabled. Returns null when authorization * is not enabled. */ public String getServerName() { return getAuthzConfig().isEnabled() ? getAuthzConfig().getServerName() : null; } }
} } Preconditions.checkNotNull(newDb); // TODO(todd): if client is a 'v2' impalad, only send back invalidation resp.result.addToUpdated_catalog_objects(newDb.toTCatalogObject()); } updateOwnerPrivileges(newDb.getName(), /* tableName */ null, params.server_name, /* oldOwner */ null, /* oldOwnerType */ null, newDb.getMetaStoreDb().getOwnerName(), newDb.getMetaStoreDb().getOwnerType(), resp); resp.result.setVersion(newDb.getCatalogVersion()); } /** * Update the owner privileges for an object. * If object ownership is enabled in Sentry, we need to update the owner privilege * in the catalog so that any subsequent statements that rely on that privilege, or * the absence, will function correctly without waiting for the next refresh. * If oldOwner is not null, the privilege will be removed. If newOwner is not null, * the privilege will be added. * The catalog will correctly reflect the owner in HMS, however because the owner
String serverName, String oldOwner, PrincipalType oldOwnerType, String newOwner, PrincipalType newOwnerType, TDdlExecResponse resp) { if (catalog_.getSentryProxy() == null || !catalog_.getSentryProxy() .isObjectOwnershipEnabled()) return; Preconditions.checkNotNull(serverName); TPrivilege filter; if (tableName == null) { filter = createDatabaseOwnerPrivilegeFilter(databaseName, serverName); } else { filter = createTableOwnerPrivilegeFilter(databaseName, tableName, serverName); } if(oldOwner != null && !oldOwner.isEmpty()) { removePrivilegeFromCatalog(oldOwner, oldOwnerType, filter, resp); } if(newOwner != null && newOwner.length() > 0) { addPrivilegeToCatalog(newOwner, newOwnerType, filter, resp); } } private void createFunction(TCreateFunctionParams params, TDdlExecResponse resp) throws ImpalaException { Function fn = Function.fromThrift(params.getFn()); if (LOG.isTraceEnabled()) { LOG.trace(String.format("Adding %s: %s", fn.getClass().getSimpleName(), fn.signatureString())); }
PrincipalType newOwnerType, TDdlExecResponse resp) { if (catalog_.getSentryProxy() == null || !catalog_.getSentryProxy() .isObjectOwnershipEnabled()) return; Preconditions.checkNotNull(serverName); TPrivilege filter; if (tableName == null) { filter = createDatabaseOwnerPrivilegeFilter(databaseName, serverName); } else { filter = createTableOwnerPrivilegeFilter(databaseName, tableName, serverName); } if(oldOwner != null && !oldOwner.isEmpty()) { removePrivilegeFromCatalog(oldOwner, oldOwnerType, filter, resp); } if(newOwner != null && newOwner.length() > 0) { addPrivilegeToCatalog(newOwner, newOwnerType, filter, resp); } } private void createFunction(TCreateFunctionParams params, TDdlExecResponse resp) throws ImpalaException { Function fn = Function.fromThrift(params.getFn()); if (LOG.isTraceEnabled()) { LOG.trace(String.format("Adding %s: %s", fn.getClass().getSimpleName(), fn.signatureString())); } boolean isPersistentJavaFn =
TPrivilege filter, TDdlExecResponse response) { try { Principal owner = catalog_.getAuthPolicy().getPrincipal(ownerString, ownerType == PrincipalType.ROLE ? TPrincipalType.ROLE : TPrincipalType.USER); if (owner != null) { PrincipalPrivilege privilege = owner.getPrivilege(filter.getPrivilege_name()); if (privilege != null) { PrincipalPrivilege removedPrivilege = catalog_.getAuthPolicy() .removePrivilege(privilege); removedPrivilege.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege .toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } } /** * This is a helper method to take care of catalog related updates when removing * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege;
PrincipalPrivilege privilege = owner.getPrivilege(filter.getPrivilege_name()); if (privilege != null) { PrincipalPrivilege removedPrivilege = catalog_.getAuthPolicy() .removePrivilege(privilege); removedPrivilege.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege .toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } finally { catalog_.getLock().writeLock().unlock(); } } /** * This is a helper method to take care of catalog related updates when removing * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; Reference<Boolean> existingUser = new Reference<>(); if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId());
} } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } } /** * This is a helper method to take care of catalog related updates when removing * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); } else { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } if (!existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); }
* a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; Reference<Boolean> existingUser = new Reference<>(); if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); if (!existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } } else { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } if (!existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error adding privilege: ", e); } }
if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); } else { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error adding privilege: ", e); } } /** * Create a new HMS Partition. */ private static Partition createHmsPartition(List<TPartitionKeyValue> partitionSpec, org.apache.hadoop.hive.metastore.api.Table msTbl, TableName tableName, String location) {
} /** * Grants or revokes one or more privileges to/from a Sentry role on behalf of the * requestingUser. */ private void grantRevokeRolePrivilege(User requestingUser, TGrantRevokePrivParams grantRevokePrivParams, TDdlExecResponse resp) throws ImpalaException { Preconditions.checkNotNull(requestingUser); verifySentryServiceEnabled(); String roleName = grantRevokePrivParams.getRole_name(); List<TPrivilege> privileges = grantRevokePrivParams.getPrivileges(); List<PrincipalPrivilege> addedRolePrivileges = null; List<PrincipalPrivilege> removedGrantOptPrivileges = Lists.newArrayListWithExpectedSize(privileges.size()); if (grantRevokePrivParams.isIs_grant()) { addedRolePrivileges = catalog_.getSentryProxy().grantRolePrivileges(requestingUser, roleName, privileges); addSummary(resp, "Privilege(s) have been granted."); } else { // If this is a revoke of a privilege that contains the grant option, the privileges // with the grant option will be revoked and new privileges without the grant option // will be added. The privilege in the catalog cannot simply be updated since the
// list of the revoked privileges that contain the grant option. The // addedRolePrivileges parameter will contain a list of new privileges without the // grant option that are granted. If this is simply a revoke of a privilege without // grant options, the api will still return revoked privileges, but the // addedRolePrivileges will be empty since there will be no newly granted // privileges. addedRolePrivileges = Lists.newArrayListWithExpectedSize(privileges.size()); removedGrantOptPrivileges = catalog_.getSentryProxy() .revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), addedRolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); } Preconditions.checkNotNull(addedRolePrivileges); List<TCatalogObject> updatedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: addedRolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); }
// grant options, the api will still return revoked privileges, but the // addedRolePrivileges will be empty since there will be no newly granted // privileges. addedRolePrivileges = Lists.newArrayList(); removedGrantOptPrivileges = catalog_.getSentryProxy() .revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), addedRolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); } Preconditions.checkNotNull(addedRolePrivileges); List<TCatalogObject> updatedPrivs = Lists.newArrayListWithExpectedSize(addedRolePrivileges.size()); for (PrincipalPrivilege rolePriv: addedRolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); } if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog.
// privileges. addedRolePrivileges = Lists.newArrayList(); removedGrantOptPrivileges = catalog_.getSentryProxy() .revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), addedRolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); } Preconditions.checkNotNull(addedRolePrivileges); List<TCatalogObject> updatedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: addedRolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = Lists.newArrayListWithExpectedSize(removedGrantOptPrivileges.size()); for (PrincipalPrivilege rolePriv: removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); } if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog. if (grantRevokePrivParams.isIs_grant()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setVersion(
} if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog. if (grantRevokePrivParams.isIs_grant()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setVersion( updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version()); } } else if (privileges.get(0).isHas_grant_opt()) { if (!updatedPrivs.isEmpty() && !removedPrivs.isEmpty()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion( getLastItemVersion(updatedPrivs) > getLastItemVersion(removedPrivs) ? getLastItemVersion(updatedPrivs) : getLastItemVersion(removedPrivs)); } else { resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion( removedPrivs.get(removedPrivs.size() - 1).getCatalog_version()); } } } /** * Returns the version from the last item in the list. This assumes that the items
} /** * Throws a CatalogException if the Sentry Service is not enabled. */ private void verifySentryServiceEnabled() throws CatalogException { if (catalog_.getSentryProxy() == null) { throw new CatalogException("Sentry Service is not enabled on the " + "CatalogServer."); } } /** * Checks if with grant is enabled for object ownership in Sentry. */ private boolean isObjectOwnershipGrantEnabled() { return catalog_.getSentryProxy() == null ? false : catalog_.getSentryProxy().isObjectOwnershipGrantEnabled(); } /** * Alters partitions in batches of size 'MAX_PARTITION_UPDATES_PER_RPC'. This * reduces the time spent in a single update and helps avoid metastore client * timeouts. */ private void bulkAlterPartitions(String dbName, String tableName, List<HdfsPartition> modifiedParts) throws ImpalaException { List<org.apache.hadoop.hive.metastore.api.Partition> hmsPartitions = Lists.newArrayList(); for (HdfsPartition p: modifiedParts) {
*/ private void verifySentryServiceEnabled() throws CatalogException { if (catalog_.getSentryProxy() == null) { throw new CatalogException("Sentry Service is not enabled on the " + "CatalogServer."); } } /** * Checks if with grant is enabled for object ownership in Sentry. */ private boolean isObjectOwnershipGrantEnabled() { return catalog_.getSentryProxy() == null ? false : catalog_.getSentryProxy().isObjectOwnershipGrantEnabled(); } /** * Alters partitions in batches of size 'MAX_PARTITION_UPDATES_PER_RPC'. This * reduces the time spent in a single update and helps avoid metastore client * timeouts. */ private void bulkAlterPartitions(String dbName, String tableName, List<HdfsPartition> modifiedParts) throws ImpalaException { List<org.apache.hadoop.hive.metastore.api.Partition> hmsPartitions = Lists.newArrayList(); for (HdfsPartition p: modifiedParts) { org.apache.hadoop.hive.metastore.api.Partition msPart = p.toHmsPartition();
originalOwnerName = msDb.getOwnerName(); originalOwnerType = msDb.getOwnerType(); msDb.setOwnerName(params.owner_name); msDb.setOwnerType(PrincipalType.valueOf(params.owner_type.name())); try { applyAlterDatabase(db); } catch (ImpalaRuntimeException e) { msDb.setOwnerName(originalOwnerName); msDb.setOwnerType(originalOwnerType); throw e; } } addDbToCatalogUpdate(db, response.result); addSummary(response, "Updated database."); } private void addDbToCatalogUpdate(Db db, TCatalogUpdateResult result) { Preconditions.checkNotNull(db); // Updating the new catalog version and setting it to the DB catalog version while // holding the catalog version lock for an atomic operation. Most DB operations are // short-lived. It is unnecessary to have a fine-grained DB lock.
} throw new InternalException(String.format("Error making '%s' RPC to " + "Sentry Service: ", type == TPrincipalType.ROLE ? "listAllRolesPrivileges" : "listAllUsersPrivileges"), e); } finally { client.close(); } } /** * Returns the configuration value for the specified key. Will return an empty string * if no value is set. */ public String getConfigValue(String key) throws ImpalaException { try (SentryServiceClient client = new SentryServiceClient()) { return client.get().getConfigValue(key, ""); } catch (SentryUserException e) { throw new InternalException("Error making 'getConfigValue' RPC to Sentry Service: ", e); } finally { client.close(); } } /** * Utility function that converts a TSentryPrivilege to an Impala TPrivilege object. */ public static TPrivilege sentryPrivilegeToTPrivilege(TSentryPrivilege sentryPriv, Principal principal) { TPrivilege privilege = new TPrivilege(); privilege.setServer_name(sentryPriv.getServerName());
public SentryProxy(SentryConfig sentryConfig, CatalogServiceCatalog catalog, String kerberosPrincipal) throws ImpalaException { Preconditions.checkNotNull(catalog); Preconditions.checkNotNull(sentryConfig); catalog_ = catalog; if (Strings.isNullOrEmpty(kerberosPrincipal)) { processUser_ = new User(System.getProperty("user.name")); } else { processUser_ = new User(kerberosPrincipal); } sentryPolicyService_ = new SentryPolicyService(sentryConfig); // For some tests, we create a config but may not have a config file. if (sentryConfig.getConfigFile() != null && !sentryConfig.getConfigFile().isEmpty()) { objectOwnershipConfigValue_ = sentryPolicyService_ .getConfigValue(ServiceConstants.ServerConfig .SENTRY_DB_POLICY_STORE_OWNER_AS_PRIVILEGE); } else { objectOwnershipConfigValue_ = SentryOwnerPrivilegeType.NONE.toString(); } policyReader_.scheduleAtFixedRate(new PolicyReader(false), 0, BackendConfig.INSTANCE.getSentryCatalogPollingFrequency(), TimeUnit.SECONDS); } /** * Refreshes the authorization policy metadata by querying the Sentry Policy Service.
Preconditions.checkNotNull(catalog); Preconditions.checkNotNull(sentryConfig); catalog_ = catalog; if (Strings.isNullOrEmpty(kerberosPrincipal)) { processUser_ = new User(System.getProperty("user.name")); } else { processUser_ = new User(kerberosPrincipal); } sentryPolicyService_ = new SentryPolicyService(sentryConfig); // For some tests, we create a config but may not have a config file. if (sentryConfig.getConfigFile() != null && !sentryConfig.getConfigFile().isEmpty()) { objectOwnershipConfigValue_ = sentryPolicyService_ .getConfigValue(ServiceConstants.ServerConfig .SENTRY_DB_POLICY_STORE_OWNER_AS_PRIVILEGE); } else { objectOwnershipConfigValue_ = SentryOwnerPrivilegeType.NONE.toString(); } policyReader_.scheduleAtFixedRate(new PolicyReader(false), 0, BackendConfig.INSTANCE.getSentryCatalogPollingFrequency(), TimeUnit.SECONDS); } /** * Refreshes the authorization policy metadata by querying the Sentry Policy Service. * There is currently no way to get a snapshot of the policy from the Sentry Service,
// software distributed under the License is distributed on an // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.util; import javax.annotation.concurrent.NotThreadSafe; import java.nio.charset.StandardCharsets; import com.sangupta.murmur.Murmur2; import org.apache.yetus.audience.InterfaceAudience; import org.apache.yetus.audience.InterfaceStability; @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(int nBits, byte[] bitmap, int nHashes, HashFunction hashFunction) { this.nBits = nBits; this.bitmap = bitmap; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2);
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.util; import javax.annotation.concurrent.NotThreadSafe; import java.nio.charset.StandardCharsets; import com.sangupta.murmur.Murmur2; import org.apache.yetus.audience.InterfaceAudience; import org.apache.yetus.audience.InterfaceStability; @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(int nBits, byte[] bitmap, int nHashes, HashFunction hashFunction) { this.nBits = nBits; this.bitmap = bitmap; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); }
public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate, HashFunction hashFunction) { int nBytes = optimalNumOfBytes(expectedCount, fpRate); int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, expectedCount); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction);
public void put(boolean data) { byteBuffer[0] = (byte)(data ? 1 : 0); updateBitset(byteBuffer, 1);
private void updateBitset(byte[] byteBuffer, int length) { assert (byteBuffer.length >= length); long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp = tmp + h2; }
private void updateBitmap(byte[] byteBuffer, int length) { long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = tmp % nBits; bitSet.set((int)bitPos); tmp += h2; }
} } } private void updateBitmap(byte[] byteBuffer, int length) { long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp = tmp + h2; } } @InterfaceAudience.LimitedPrivate("Test") public boolean mayContain(byte[] data) { return checkIfContains(data); } // This is for test. public boolean mayContain(boolean data) { byte[] byteBuffer = new byte[1]; if (data) { byteBuffer[0] = 1; } else { byteBuffer[0] = 0; } return checkIfContains(byteBuffer); } // This is for test. public boolean mayContain(byte data) { byte[] byteBuffer = new byte[1]; byteBuffer[0] = data; return checkIfContains(byteBuffer);
private boolean checkIfContains(byte[] bytes) { long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; int remHashes = nHashes; while (remHashes != 0) { long bitPos = tmp % nBits; if (!bitSet.get((int)bitPos)) { return false; } tmp = tmp + h2; remHashes--; } return true;
private boolean checkIfContains(byte[] bytes) { long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; int remHashes = nHashes; while (remHashes != 0) { long bitpos = pickBit(tmp, nBits); if (!bitmapTest(bitmap, bitpos)) { return false; } tmp += h2; remHashes--; } return true;
long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; int remHashes = nHashes; while (remHashes != 0) { long bitpos = pickBit(tmp, nBits); if (!bitmapTest(bitmap, bitpos)) { return false; } tmp = tmp + h2; remHashes--; } return true; } private static double kNaturalLog2 = 0.69314; private static int optimalNumOfBytes(int expectedCount, double fpRate) { if (fpRate == 0) { fpRate = Double.MIN_VALUE; } return (int) (-expectedCount * Math.log(fpRate) / (Math.log(2) * Math.log(2) * 8)); } private static int optimalExpectedCount(int nBytes, double fpRate) { int nBits = nBytes * 8; return (int) (Math.ceil(nBits * kNaturalLog2 * kNaturalLog2 / Math.log(fpRate))); }
private static int computeOptimalHashCount(int nBits, int elems) { int nHashes = (int)(nBits * kNaturalLog2 / elems); if (nHashes < 1) nHashes = 1; return nHashes;
// software distributed under the License is distributed on an // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.client; import static org.junit.Assert.assertTrue; import java.util.Random; import org.apache.kudu.util.BloomFilter; import org.junit.Test; public class TestBloomFilter { private int nBytes = 32 * 1024; private long kRandomSeed = System.currentTimeMillis(); private int nKeys = 2000; private double fpRate = 0.01; @Test public void testIntGenBFBySizeAndFPRate() { final BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); // Put integers into bloomfilter by random Random rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { bf.put(rand.nextInt()); } // Reset the rand and check existence of the keys. rand = new Random(kRandomSeed);
public void testFloat() { final BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); // Put floats into bloomfilter by random Random rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { bf.put(rand.nextFloat()); } // Reset the rand and check existence of the keys. rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { assertTrue(bf.mayContain(rand.nextFloat())); }
import java.util.List; import org.apache.impala.authorization.PrivilegeRequestBuilder; import org.apache.impala.common.AnalysisException; import org.apache.impala.common.InternalException; import org.apache.impala.common.Pair; import org.apache.impala.thrift.TAdminRequest; import org.apache.impala.thrift.TAdminRequestType; import org.apache.impala.thrift.TNetworkAddress; import org.apache.impala.thrift.TShutdownParams; import com.google.common.base.Joiner; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** * Represents an administrative function call, e.g. ": shutdown('hostname:123')". * * This "admin statement" framework provides a way to expand the set of supported admin * statements without modifying the SQL grammar. For now, the only supported function is * shutdown(), so the logic in here is not generic. */ public class AdminFnStmt extends StatementBase { // Name of the function. Validated during analysis. private final String fnName_; // Arguments to the function. Always non-null. private final List<Expr> params_; // Parameters for the shutdown() command.
* not used since it accesses multiple catalog entities in order to compute a snapshot * of catalog metadata. * * Operations that CREATE/DROP catalog objects such as tables and databases employ the * following locking protocol: * 1. Acquire the metastoreDdlLock_ * 2. Update the Hive Metastore * 3. Increment and get a new catalog version * 4. Update the catalog * 5. Make Sentry cache changes if ownership is enabled. * 6. Release the metastoreDdlLock_ * * It is imperative that other operations that need to hold both the catalog lock and * table locks at the same time follow the same locking protocol and acquire these * locks in that particular order. Also, operations that modify table metadata * (e.g. alter table statements) should not acquire the metastoreDdlLock_. * * TODO: Refactor the CatalogOpExecutor and CatalogServiceCatalog classes and consolidate * the locking protocol into a single class. * * TODO: Improve catalog's consistency guarantees by using a hierarchical locking scheme.
filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); if (existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } } else if (ownerType == PrincipalType.ROLE) { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } else { throw new CatalogException("Unexpected PrincipalType: " + ownerType.name()); } response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error adding privilege: ", e); } } /** * Create a new HMS Partition. */ private static Partition createHmsPartition(List<TPartitionKeyValue> partitionSpec, org.apache.hadoop.hive.metastore.api.Table msTbl, TableName tableName, String location) {
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.util; import javax.annotation.concurrent.NotThreadSafe; import java.nio.charset.StandardCharsets; import java.util.BitSet; import com.sangupta.murmur.Murmur2; import org.apache.yetus.audience.InterfaceAudience; import org.apache.yetus.audience.InterfaceStability; /** * An space-efficient filter which offers an approximate containment check. * * <p>It can be used to filter all the records which are wanted, but doesn't guarantee to filter out * all the records which are <i>not</i> wanted. * * <p>Please check this <a * href="https://en.wikipedia.org/wiki/Bloom_filter">wiki</a> for more details. * * <p>The {@code BloomFilter} here is a scanning filter and used to shrink the amount of records
/** * An space-efficient filter and offers an approximate containment check. * * <p>It can be used to filter all the records which are wanted, but doesn't guarantee to filter out * all the records which are <i>not</i> wanted. * * <p>Please check this <a * href="https://en.wikipedia.org/wiki/Bloom_filter">wiki</a> for more details. * * <p>The {@code BloomFilter} here is a scanning filter and used to constrain the number of records * returned from TServer. It provides different types of {@code put} methods. When you {@code put} a * record into {@code BloomFilter}, it means you are expecting TServer to return records have * the same value in a scan. * * <p>Here is an example for use: * <pre> * {@code * BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); * bf.put(1); * bf.put(3); * bf.put(4);
* the same value in a scan. * * <p>Here is an example for use: * <pre> * {@code * BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); * bf.put(1); * bf.put(3); * bf.put(4); * byte[] bitSet = bf.getBitSet(); * byte[] nHashes = bf.getNHashes(); * String hashFunctionName = bf.getHashFunctionName(); * // TODO: implement the interface for serializing and sending * // (bitSet, nHashes, hashFunctionName) to TServer. * } * </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { if (bitSet.size() < 8) {
* </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { Preconditions.checkArgument(bitSet.size() > 8, "Number of bits in " + "bitset should be at least 8, but found %s.", bitSet.size()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** * Generate bloom filter, Murmur2 is used for hashing by default. * @param nBytes size of Bloom filter * @param fpRate false positive rate */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); }
* </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { Preconditions.checkArgument(bitSet.size() > 8, "Number of bits in " + "bitset should be at least 8, but found %s.", bitSet.size()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** * Generate bloom filter, Murmur2 is used for hashing by default. * @param nBytes size of Bloom filter * @param fpRate false positive rate */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); }
if (bitSet.size() < 8) { throw new IllegalArgumentException("Number of bits in bitset should be at least 8, but found " + bitSet.length()); } this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** * Generate bloom filter, default hashing is {@code Murmur2} and false positive rate is 0.01. * @param nBytes size of bloom filter in bytes */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate, HashFunction hashFunction) { int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, optimalExpectedCount(nBytes, fpRate)); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); } /**
} public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate, HashFunction hashFunction) { int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, optimalExpectedCount(nBytes, fpRate)); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); } /** * Generate bloom filter, default hashing is {@code Murmur2} and false positive rate is 0.01. * @param expectedCount The expected number of elements, targeted by this bloom filter. * It is used to size the bloom filter. * @param fpRate false positive rate */ public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate) { return ByCountAndFPRate(expectedCount, fpRate, HashFunctions.MURMUR2); } public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate, HashFunction hashFunction) { int nBytes = optimalNumOfBytes(expectedCount, fpRate); int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, expectedCount); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); }
* @param fpRate false positive rate */ public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate) { return ByCountAndFPRate(expectedCount, fpRate, HashFunctions.MURMUR2); } public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate, HashFunction hashFunction) { int nBytes = optimalNumOfBytes(expectedCount, fpRate); int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, expectedCount); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); } /** * Update bloom filter with a {@code byte[]}. */ public void put(byte[] data) { updateBitset(data, data.length); } public void put(boolean data) { byteBuffer[0] = (byte)(data ? 1 : 0); updateBitset(byteBuffer, 1); } public void put(byte data) { byteBuffer[0] = data; updateBitset(byteBuffer, 1); } public void put(short data) { byteBuffer[0] = (byte) (data >>> 0); byteBuffer[1] = (byte) (data >>> 8); updateBitset(byteBuffer, 2); }
updateBitset(byteBuffer, 8); } public void put(float data) { put(Float.floatToIntBits(data)); } public void put(double data) { put(Double.doubleToLongBits(data)); } public void put(String data) { put(data.getBytes(StandardCharsets.UTF_8)); } public byte[] getBitSet() { return bitSet.toByteArray(); } public int getNHashes() { return nHashes; } /** * Get the name of hashing used when updating or checking containment. */ public String getHashFunctionName() { return hashFunction.toString(); } // Mark it `private` and user can only use the `HashFunction` specified in the // enumeration below. Thus user cannot send TServer a self defined `HashFunction`, // which might not be identified by TServer. private interface HashFunction { long hash(byte[] data, int length, long seed); } public enum HashFunctions implements HashFunction { // Currently only Murmur2 is provided as an option for hashing. // We can consider to provide some other options like Murmur3, CityHash in the future.
// Currently only Murmur2 is provided as an option for hashing. // We can consider to provide some other options like Murmur3, CityHash in the future. MURMUR2() { @Override public long hash(byte[] data, int length, long seed) { return Murmur2.hash(data, length, seed); } @Override public String toString() { return "Murmur2"; } } } private void updateBitset(byte[] byteBuffer, int length) { Preconditions.checkArgument(byteBuffer.length >= length); long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = tmp % nBits; bitSet.set((int)bitPos); tmp += h2; } } @InterfaceAudience.LimitedPrivate("Test") public boolean mayContain(byte[] data) { return checkIfContains(data); }
TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onDatabase("functional", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onTable("functional", "alltypes", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes")) .error(accessError(true, "functional.alltypes"), onServer(true, allExcept( TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onDatabase(true, "functional", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onTable(true, "functional", "alltypes", allExcept( TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))); } } finally { authzCatalog_.removeRole("foo_owner"); } // Alter table rename. authorize("alter table functional.alltypes rename to functional_parquet.new_table") .ok(onServer(TPrivilegeLevel.ALL)) .ok(onServer(TPrivilegeLevel.OWNER)) .ok(onDatabase("functional", TPrivilegeLevel.ALL), onDatabase("functional_parquet", TPrivilegeLevel.CREATE))
owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege .toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } finally { catalog_.getLock().writeLock().unlock(); } } /** * This is a helper method to take care of catalog related updates when adding * a privilege. This will also add a user to the catalog if it doesn't exist. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; if (ownerType == PrincipalType.USER) { Reference<Boolean> existingUser = new Reference<>(); owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); if (!existingUser.getRef()) {
owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege .toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } finally { catalog_.getLock().writeLock().unlock(); } } /** * This is a helper method to take care of catalog related updates when adding * a privilege. This will also add a user to the catalog if it doesn't exist. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; if (ownerType == PrincipalType.USER) { Reference<Boolean> existingUser = new Reference<>(); owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); if (!existingUser.getRef()) {
* } * </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private static final double DEFAULT_FP_RATE = 0.01; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { Preconditions.checkArgument(bitSet.size() >= 8, "Number of bits in " + "bitset should be at least 8, but found %s.", bitSet.size()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** * Generate bloom filter, default hashing is {@code Murmur2} and false positive rate is 0.01. * @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize(int nBytes) { return BySizeAndFPRate(nBytes, DEFAULT_FP_RATE); }
"bitset should be at least 8, but found %s.", bitSet.size()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** * Generate bloom filter, default hashing is {@code Murmur2} and false positive rate is 0.01. * @param nBytes size of bloom filter in bytes */ public static BloomFilter bySize(int nBytes) { return bySizeAndFPRate(nBytes, DEFAULT_FP_RATE); } /** * Generate bloom filter, default hashing is {@code Murmur2}. * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been {@code put} into the {@code BloomFilter}. */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } /**
* @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize(int nBytes) { return BySizeAndFPRate(nBytes, DEFAULT_FP_RATE); } /** * Generate bloom filter, default hashing is {@code Murmur2}. * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been {@code put} into the {@code BloomFilter}. */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } /** * Generate bloom filter. * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been {@code put} into the {@code BloomFilter}. * @param hashFunction hashing used when updating or checking containment, user should pick * the hashing function from {@code HashFunctions}
TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onDatabase("functional", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onTable("functional", "alltypes", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes")) .error(accessError(true, "functional.alltypes"), onServer(true, allExcept( TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onDatabase(true, "functional", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) .error(accessError(true, "functional.alltypes"), onTable(true, "functional", "alltypes", allExcept( TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))); } } finally { authzCatalog_.removeRole("foo_owner"); } boolean exceptionThrown = false; try { parseAndAnalyze("alter table functional.alltypes set owner role foo_owner", analysisContext_ , frontend_); } catch (AnalysisException e) { exceptionThrown = true; assertEquals("Role 'foo_owner' does not exist.", e.getLocalizedMessage()); }
private final long MISSING_TBL_LOAD_WAIT_TIMEOUT_MS = 2 * 60 * 1000; // Max time to wait for a catalog update notification. private final long MAX_CATALOG_UPDATE_WAIT_TIME_MS = 2 * 1000; //TODO: Make the reload interval configurable. private static final int AUTHORIZATION_POLICY_RELOAD_INTERVAL_SECS = 5 * 60; private ImpaladCatalog impaladCatalog_; private final AuthorizationConfig authzConfig_; private final AtomicReference<AuthorizationChecker> authzChecker_; private final ScheduledExecutorService policyReader_ = Executors.newScheduledThreadPool(1); public Frontend(AuthorizationConfig authorizationConfig, String defaultKuduMasterHosts) { this(authorizationConfig, new ImpaladCatalog(defaultKuduMasterHosts)); } /** * C'tor used by tests to pass in a custom ImpaladCatalog. */ public Frontend(AuthorizationConfig authorizationConfig, ImpaladCatalog catalog) { authzConfig_ = authorizationConfig; impaladCatalog_ = catalog; defaultKuduMasterHosts_ = catalog.getDefaultKuduMasterHosts(); authzChecker_ = new AtomicReference<AuthorizationChecker>( new AuthorizationChecker(authzConfig_, impaladCatalog_.getAuthPolicy()));
public String getHostname() { return hostname;
/** * Kills the TS listening on the provided port. Doesn't do anything if the TS was already killed. * @param port port on which the tablet server is listening on * @throws InterruptedException */ public void killTabletServerOnPort(int port) throws InterruptedException { Process ts = tserverProcesses.remove(port); if (ts == null) { // The TS is already dead, good. return; } } /** * Kills all tablet servers. * @throws InterruptedException */ public void killTabletServers() throws InterruptedException { for (Process tserver : tserverProcesses.values()) { destroyAndWaitForProcess(tserver); } tserverProcesses.clear(); } /** * Restarts any tablet servers which were previously killed. */ public void restartDeadTabletServers() throws Exception { for (int port : tserverPorts) { if (tserverProcesses.containsKey(port)) continue; restartDeadTabletServerOnPort(port); } }
private static String findBinaryDir() { // First check the system property, which is our standard override. String kuduHomeProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduHomeProp != null) { LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduHomeProp); return kuduHomeProp; } // Next, check the environment variable. String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } // Last, use the kudu that is available on the path. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) {
String kuduHomeProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduHomeProp != null) { LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduHomeProp); return kuduHomeProp; } // Next, check the environment variable. String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } // Last, use the kudu that is available on the path. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader);
return kuduHomeProp; } // Next, check the environment variable. String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } // Last, if the `kudu` binary is found on the PATH using `which kudu`, // use its parent directory. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) {
String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } // Last, use the kudu that is available on the path. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8); try { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) { throw new RuntimeException("Error while locating kudu binary", ex); } throw new RuntimeException("Could not locate the kudu binary directory. " + "Set the system variable " + KUDU_BIN_DIR_PROP + ", environment variable " + KUDU_HOME_VAR +
public class AlterViewStmt extends CreateOrAlterViewStmtBase { public AlterViewStmt( TableName tableName, List<ColumnDef> columnDefs, QueryStmt viewDefStmt) { super(false, tableName, columnDefs, null, viewDefStmt); } @Override public void analyze(Analyzer analyzer) throws AnalysisException { // Enforce Hive column labels for view compatibility. analyzer.setUseHiveColLabels(true); viewDefStmt_.analyze(analyzer); Preconditions.checkState(tableName_ != null && !tableName_.isEmpty()); dbName_ = analyzer.getTargetDbName(tableName_); owner_ = analyzer.getUserShortName(); // Set the servername here if authorization is enabled because analyzer_ is not // available in the toThrift() method. serverName_ = analyzer.getServerName(); FeTable table = analyzer.getTable(tableName_, Privilege.ALTER); Preconditions.checkNotNull(table); if (!(table instanceof FeView)) {
try { miniCluster.waitFor(); } catch (InterruptedException e) { LOG.warn("Minicluster process did not exit, destroying"); miniCluster.destroy(); } } } /** * Returns a master server identified by an address. * * @param address unique address identifying the server * @return the DaemonInfo of the server * @throws RuntimeException if the server is not found */ private DaemonInfo getMasterServer(HostAndPort hp) throws RuntimeException { DaemonInfo d = masterServers.get(hp); if (d == null) { throw new RuntimeException(String.format("Master server %s not found", address)); } return d; } /** * Returns a tablet server identified by an address. * * @param address unique address identifying the server * @return the DaemonInfo of the server * @throws RuntimeException if the server is not found */ private DaemonInfo getTabletServer(HostAndPort address) throws RuntimeException { DaemonInfo d = tabletServers.get(address);
import static org.junit.Assert.assertArrayEquals; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; import java.net.InetAddress; import java.net.InetSocketAddress; import java.util.Arrays; import java.util.List; import org.apache.kudu.client.HostAndPort; import org.junit.Test; /** * Test for {@link NetUtil}. */ public class TestNetUtil { /** * Tests parsing strings into {@link HostAndPort} objects with and without specifying * the port in the string. */ @Test public void testParseString() { String aStringWithPort = "1.2.3.4:1234"; HostAndPort hostAndPortForAStringWithPort = NetUtil.parseString(aStringWithPort, 0); assertEquals(hostAndPortForAStringWithPort.getHost(), "1.2.3.4"); assertEquals(hostAndPortForAStringWithPort.getPort(), 1234); String aStringWithoutPort = "1.2.3.4"; HostAndPort hostAndPortForAStringWithoutPort = NetUtil.parseString(aStringWithoutPort, 12345);
private static String findBinaryDir() { // If kuduBinDir system property is set, use that. String kuduBinDirProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduBinDirProp != null) { LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduHomeProp); return kuduHomeProp; } // If the `kudu` binary is found on the PATH using `which kudu`, use its parent directory. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try(Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) {
private PrivilegedExecutor privilegedExecutor; public KuduSink() { this(null); } @InterfaceAudience.LimitedPrivate("Test") @InterfaceAudience.Private public KuduSink(KuduClient kuduClient) { this.client = kuduClient; } @Override public synchronized void start() { Preconditions.checkState(table == null && session == null, "Please call stop before calling start on an old instance."); // Client is not null only inside tests. if (client == null) { // Creating client with FlumeAuthenticator. client = privilegedExecutor.execute( new PrivilegedAction<KuduClient>() { @Override public KuduClient run() { return new KuduClient.KuduClientBuilder(masterAddresses).build(); } } ); } session = client.newSession(); session.setFlushMode(SessionConfiguration.FlushMode.MANUAL_FLUSH); session.setTimeoutMillis(timeoutMillis); session.setIgnoreAllDuplicateRows(ignoreDuplicateRows); session.setMutationBufferSpace(batchSize); try { table = client.openTable(tableName); } catch (Exception ex) { sinkCounter.incrementConnectionFailedCount();
TABLE_NAME); batchSize = context.getInteger(BATCH_SIZE, DEFAULT_BATCH_SIZE); timeoutMillis = context.getLong(TIMEOUT_MILLIS, DEFAULT_TIMEOUT_MILLIS); ignoreDuplicateRows = context.getBoolean(IGNORE_DUPLICATE_ROWS, DEFAULT_IGNORE_DUPLICATE_ROWS); String operationProducerType = context.getString(PRODUCER); String kerberosPrincipal = context.getString(KERBEROS_PRINCIPAL); String kerberosKeytab = context.getString(KERBEROS_KEYTAB); String proxyUser = context.getString(PROXY_USER); privilegedExecutor = FlumeAuthenticationUtil.getAuthenticator( kerberosPrincipal, kerberosKeytab).proxyAs(proxyUser); // Check for operations producer, if null set default operations producer type. if (operationProducerType == null || operationProducerType.isEmpty()) { operationProducerType = DEFAULT_KUDU_OPERATION_PRODUCER; logger.warn("No Kudu operations producer provided, using default"); } Context producerContext = new Context(); producerContext.putAll(context.getSubProperties( KuduSinkConfigurationConstants.PRODUCER_PREFIX)); try { Class<? extends KuduOperationsProducer> clazz = (Class<? extends KuduOperationsProducer>) Class.forName(operationProducerType); operationsProducer = clazz.getDeclaredConstructor().newInstance();
.nullable(true).build()); columns.add(new ColumnSchema.ColumnSchemaBuilder("stringField", Type.STRING).build()); columns.add(new ColumnSchema.ColumnSchemaBuilder("decimalField", Type.DECIMAL) .typeAttributes(DecimalUtil.typeAttributes(9, 1)).build()); CreateTableOptions createOptions = new CreateTableOptions().setRangePartitionColumns(ImmutableList.of("key")) .setNumReplicas(1); return createTable(tableName, new Schema(columns), createOptions); } private List<Event> generateEvents(int eventCount, SchemaLocation schemaLocation) throws Exception { List<Event> events = new ArrayList<>(); for (int i = 0; i < eventCount; i++) { AvroKuduOperationsProducerTestRecord record = new AvroKuduOperationsProducerTestRecord(); record.setKey(10 * i); record.setLongField(2L * i); record.setDoubleField(2.71828 * i); record.setNullableField(i % 2 == 0 ? null : "taco"); record.setStringField(String.format("hello %d", i)); record.setDecimalField(BigDecimal.valueOf(i, 1));
return sink; } static KuduSink createSecureSink(String tableName, String masterAddresses, String clusterRoot) { Context context = new Context(); context.put(KERBEROS_KEYTAB, clusterRoot + "/krb5kdc/test-user.keytab"); context.put(KERBEROS_PRINCIPAL, "test-user@KRBTEST.COM"); return createSink(tableName, null, context, masterAddresses); } static void processEventsCreatingSink( KuduClient syncClient, Context context, String tableName, List<Event> events ) throws EventDeliveryException { KuduSink sink = createSink(syncClient, tableName, context); sink.start(); processEvents(sink, events); } static void processEvents(KuduSink sink, List<Event> events) throws EventDeliveryException { Channel channel = sink.getChannel(); Transaction tx = channel.getTransaction(); tx.begin(); for (Event e : events) { channel.put(e); } tx.commit(); tx.close(); Status status = sink.process(); if (events.isEmpty()) { assertSame("incorrect status for empty channel", status, Status.BACKOFF); } else {
import org.slf4j.LoggerFactory; import org.apache.kudu.ColumnSchema; import org.apache.kudu.Schema; import org.apache.kudu.Type; import org.apache.kudu.client.BaseKuduTest; import org.apache.kudu.client.CreateTableOptions; import org.apache.kudu.client.KuduTable; import org.apache.kudu.client.MiniKuduCluster.MiniKuduClusterBuilder; public class SecureKuduSinkTest extends BaseKuduTest { private static final Logger LOG = LoggerFactory.getLogger(SecureKuduSinkTest.class); private static final int TICKET_LIFETIME_SECONDS = 10; private static final int RENEWABLE_LIFETIME_SECONDS = 30; @Before public void clearTicketCacheProperty() { // Let Flume authenticate System.clearProperty(KUDU_TICKETCACHE_PROPERTY); } @Override protected MiniKuduClusterBuilder getMiniClusterBuilder() { return super.getMiniClusterBuilder() .kdcTicketLifetime(TICKET_LIFETIME + "s") .kdcRenewLifetime(RENEWABLE_LIFETIME + "s") .enableKerberos(); } @Test public void testEventsWithShortTickets() throws Exception { LOG.info("Creating new table..."); ArrayList<ColumnSchema> columns = new ArrayList<>(1);
public PartitionRefImpl(TPartialPartitionInfo p) { this.info_ = Preconditions.checkNotNull(p);
public PartitionRefImpl(TPartialPartitionInfo p) { this.info_ = Preconditions.checkNotNull(p);
private boolean tryConvertKuduPredicate(Analyzer analyzer, org.apache.kudu.client.KuduTable table, Expr expr) { if (!(expr instanceof BinaryPredicate)) return false; BinaryPredicate predicate = (BinaryPredicate) expr; // TODO KUDU-931 look into handling implicit/explicit casts on the SlotRef. predicate = KuduScanNode.normalizeSlotRefComparison(predicate, analyzer); if (predicate == null) return false; ComparisonOp op = getKuduOperator(predicate.getOp()); if (op == null) return false; SlotRef ref = (SlotRef) predicate.getChild(0); LiteralExpr literal = (LiteralExpr) predicate.getChild(1); // Cannot push prediates with null literal values (KUDU-1595). if (literal instanceof NullLiteral) return false; String colName = ref.getDesc().getColumn().getName(); ColumnSchema column = table.getSchema().getColumn(colName); KuduPredicate kuduPredicate = null; switch (literal.getType().getPrimitiveType()) { case BOOLEAN: { kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((BoolLiteral)literal).getValue()); break; } case TINYINT:
if (!(expr instanceof BinaryPredicate)) return false; BinaryPredicate predicate = (BinaryPredicate) expr; // TODO KUDU-931 look into handling implicit/explicit casts on the SlotRef. predicate = normalizeSlotRefComparison(predicate, analyzer); if (predicate == null) return false; ComparisonOp op = getKuduOperator(((BinaryPredicate)predicate).getOp()); if (op == null) return false; SlotRef ref = (SlotRef) predicate.getChild(0); LiteralExpr literal = (LiteralExpr) predicate.getChild(1); // Cannot push prediates with null literal values (KUDU-1595). if (literal instanceof NullLiteral) return false; String colName = ref.getDesc().getColumn().getName(); ColumnSchema column = table.getSchema().getColumn(colName); KuduPredicate kuduPredicate = null; switch (literal.getType().getPrimitiveType()) { case BOOLEAN: { kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((BoolLiteral)literal).getValue()); break; } case TINYINT: case SMALLINT: case INT: { kuduPredicate = KuduPredicate.newComparisonPredicate(column, op,
// Compute the per-instance number of concurrent partitions, taking the number // of nodes and the data partition of the fragment executing this sink into account. long numConcurrentPartitionsPerInstance = fragment_.getPerInstanceNdv(queryOptions.getMt_dop(), partitionKeyExprs_); if (numConcurrentPartitionsPerInstance == -1) { numConcurrentPartitionsPerInstance = DEFAULT_NUM_PARTITIONS; } FeFsTable table = (FeFsTable) targetTable_; // TODO: Estimate the memory requirements more accurately by partition type. Set<HdfsFileFormat> formats = table.getFileFormats(); long perPartitionMemReq = getPerPartitionMemReq(formats); long perInstanceMemEstimate; // The estimate is based purely on the per-partition mem req if the input cardinality_ // or the avg row size is unknown. if (inputNode.getCardinality() == -1 || inputNode.getAvgRowSize() == -1) { perInstanceMemEstimate = numConcurrentPartitionsPerInstance * perPartitionMemReq;
FunctionCallExpr mergeAggInputFn) { super(); fnName_ = fnName; params_ = params; mergeAggInputFn_ = mergeAggInputFn == null ? null : (FunctionCallExpr)mergeAggInputFn.clone(); if (params.exprs() != null) children_ = Lists.newArrayList(params_.exprs()); } /** * Returns an Expr that evaluates the function call <fnName>(<params>). The returned * Expr is not necessarily a FunctionCallExpr (example: DECODE()) */ public static Expr createExpr(FunctionName fnName, FunctionParams params) throws AnalysisException { FunctionCallExpr functionCallExpr = new FunctionCallExpr(fnName, params); if (fnName.getFnNamePath().size() == 1 && fnName.getFnNamePath().get(0).equalsIgnoreCase("decode") || fnName.getFnNamePath().size() == 2 && fnName.getFnNamePath().get(0).equalsIgnoreCase(Catalog.BUILTINS_DB) && fnName.getFnNamePath().get(1).equalsIgnoreCase("decode")) { return new CaseExpr(functionCallExpr); } return functionCallExpr; }
public static FunctionCallExpr createMergeAggCall( FunctionCallExpr agg, List<Expr> params) { Preconditions.checkState(agg.isAnalyzed()); Preconditions.checkState(agg.isAggregateFunction()); FunctionCallExpr result = new FunctionCallExpr( agg.fnName_, new FunctionParams(false, params), mergeAggInputFn); // Inherit the function object from 'agg'. result.fn_ = agg.fn_; result.type_ = agg.type_; // Set an explicit label based on the input agg. if (agg.isMergeAggFn()) { result.label_ = agg.label_; } else { // fn(input) becomes fn:merge(input). result.label_ = agg.toSql().replaceFirst(agg.fnName_.toString(), agg.fnName_.toString() + ":merge"); } Preconditions.checkState(!result.type_.isWildcardDecimal()); return result;
public static FunctionCallExpr createMergeAggCall( FunctionCallExpr agg, List<Expr> params) { Preconditions.checkState(agg.isAnalyzed()); Preconditions.checkState(agg.isAggregateFunction()); FunctionCallExpr result = new FunctionCallExpr( agg.fnName_, new FunctionParams(false, params), mergeAggInputFn); // Inherit the function object from 'agg'. result.fn_ = agg.fn_; result.type_ = agg.type_; // Set an explicit label based on the input agg. if (agg.isMergeAggFn()) { result.label_ = agg.label_; } else { // fn(input) becomes fn:merge(input). result.label_ = agg.toSql().replaceFirst(agg.fnName_.toString(), agg.fnName_.toString() + ":merge"); } Preconditions.checkState(!result.type_.isWildcardDecimal()); return result;
// For CTAS the overall TExecRequest statement type is DDL, but the // query_exec_request should be DML result.stmt_type = analysisResult.isCreateTableAsSelectStmt() ? TStmtType.DDL : TStmtType.DML; result.query_exec_request.stmt_type = TStmtType.DML; // create finalization params of insert stmt InsertStmt insertStmt = analysisResult.getInsertStmt(); if (insertStmt.getTargetTable() instanceof HdfsTable) { TFinalizeParams finalizeParams = new TFinalizeParams(); finalizeParams.setIs_overwrite(insertStmt.isOverwrite()); finalizeParams.setTable_name(insertStmt.getTargetTableName().getTbl()); finalizeParams.setTable_id(DescriptorTable.TABLE_SINK_ID); String db = insertStmt.getTargetTableName().getDb(); finalizeParams.setTable_db(db == null ? queryCtx.session.database : db); HdfsTable hdfsTable = (HdfsTable) insertStmt.getTargetTable(); finalizeParams.setHdfs_base_dir(hdfsTable.getHdfsBaseDir()); finalizeParams.setStaging_dir( hdfsTable.getHdfsBaseDir() + "/_impala_insert_staging"); queryExecRequest.setFinalize_params(finalizeParams); }
import org.slf4j.LoggerFactory; import com.google.common.base.Objects; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** * Encapsulates all the information needed to compute a list of aggregate functions with * compatible grouping including their distributed execution. * * Each SELECT block containing aggregates will have a single MultiAggregateInfo which * will contain one AggregateInfo per unique list of DISTINCT expressions. If there is * only a single DISTINCT grouping, a single AggregateInfo will be created which will * represent that grouping and any non-DISTINCT aggregates. If there is more than one * DISTINCT grouping, the non-DISTINCT aggregates will be grouped together in their own * AggregateInfo. * * Execution is modeled as a tree of AggregateInfo objects which express the local and * merging aggregate computations. The tree structure looks as follows: * - for non-distinct aggregation: * - aggInfo: contains the original aggregation functions and grouping exprs * - aggInfo.mergeAggInfo: contains the merging aggregation functions (grouping
private long warnThresholdMs_; private static final long WARN_THRESHOLD_MS = 10000; // log INFO if we detect a pause longer than this threshold. private long infoThresholdMs_; private static final long INFO_THRESHOLD_MS = 1000; // Daemon thread running the pause monitor loop. private Thread monitorThread_; private volatile boolean shouldRun = true; // Singleton instance of this pause monitor. public static JvmPauseMonitor INSTANCE = new JvmPauseMonitor(); // Initializes the pause monitor. No-op if called multiple times. public static void initPauseMonitor() { if (INSTANCE.isStarted()) return; INSTANCE.init(); } private JvmPauseMonitor() { this(INFO_THRESHOLD_MS, WARN_THRESHOLD_MS); } private JvmPauseMonitor(long infoThresholdMs, long warnThresholdMs) { this.infoThresholdMs_ = infoThresholdMs; this.warnThresholdMs_ = warnThresholdMs; } protected void init() { monitorThread_ = new Thread(new Monitor(), "JVM pause monitor"); monitorThread_.setDaemon(true); monitorThread_.start(); }
switch (catalogObject.getType()) { case DATABASE: return "DATABASE:" + catalogObject.getDb().getDb_name().toLowerCase(); case TABLE: case VIEW: TTable tbl = catalogObject.getTable(); return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; case PRINCIPAL: // The combination of principal_id + privilege_name is guaranteed to be unique. return "PRINCIPAL:" + catalogObject.getPrincipal().getPrincipal_name() .toLowerCase(); case PRIVILEGE: return "PRIVILEGE:" + catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default:
public void testBasicsWithStats() { // Return all rows. Cardinality is row count; expectCardinality("SELECT id FROM functional.alltypes", 7300); // Return all rows. Cardinality is row count, // should not be influenced by limited NDV of selected // column. runTest("SELECT bool_col FROM functional.alltypes;", 7300); // Result cardinality reduced by limited NDV. // Boolean column has cardinality 3 (true, false, null). // Since we have metadata, and know the column is non-null, // NDV is 2. We select one of them. runTest("SELECT id FROM functional.alltypes WHERE bool_col = TRUE;", 7300/2); // Result cardinality reduced by NDV. // NDV should be 10 (from metadata). runTest("SELECT id FROM functional.alltypes WHERE int_col = 1;", 7300/10); // Assume classic 0.1 selectivity for other operators // IMPALA-7560 says this should be revised. runTest("SELECT id FROM functional.alltypes WHERE int_col != 1", 730);
protected void expectCardinality(String query, long expected) { List<PlanFragment> plan = getPlan(query); PlanNode planRoot = plan.get(0).getPlanRoot(); assertEquals(expected, planRoot.getCardinality());
protected void runTest(String query, long expected) { List<PlanFragment> plan = getPlan(query); PlanNode planRoot = plan.get(0).getPlanRoot(); assertEquals("Cardinality error for: " + query, expected, planRoot.getCardinality());
private List<PlanFragment> getPlan(String query) { // Set up the query context. Note that we need to deep copy it before planning each // time since planning modifies it. TQueryCtx queryCtx = TestUtils.createQueryContext( "default", System.getProperty("user.name")); queryCtx.client_request.setStmt(query); TQueryOptions queryOptions = queryCtx.client_request.getQuery_options(); queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.requestPlanCapture(); // Discard the actual execution plan. Return the cached // internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString( queryOptions, TExplainLevel.EXTENDED)); } return plan;
// Set up the query context. Note that we need to deep copy it before planning each // time since planning modifies it. TQueryCtx queryCtx = TestUtils.createQueryContext( "default", System.getProperty("user.name")); queryCtx.client_request.setStmt(query); TQueryOptions queryOptions = queryCtx.client_request.getQuery_options(); queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.capturePlan(); // Discard the actual execution plan. Return the cached // internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString( queryOptions, TExplainLevel.EXTENDED)); } return plan;
queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.capturePlan(); // Discard the actual execution plan. Return the cached // internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString( queryOptions, TExplainLevel.EXTENDED)); } return plan;
computeNdv(); analysisDone(); } /** * C'tor for cloning. */ private SlotRef(SlotRef other) { super(other); rawPath_ = other.rawPath_; label_ = other.label_; desc_ = other.desc_; type_ = other.type_; } /** * Adjusting the NDV-without-nulls of the stats world to the * NDV-with-nulls needed by the planner. */ private void computeNdv() { if (desc_.getStats().hasStats()) { numDistinctValues_ = desc_.getStats().getNumDistinctValues(); // Potentially adjust NDV for nulls if the column is nullable // and is not Boolean. (ColumnStats already does adjustments for // Boolean only). // Only adjust for small amounts; has no impact on larger values. // Adjust only if we don't know the null count or we know it is // not zero. // (This is an estimate, just has to be in the ball park.)
// e.g. map. We could report a better error if we stored the original // HMS string. throw new AnalysisException("Unsupported type in '" + toSql() + "'."); } numDistinctValues_ = desc_.getStats().getNumDistinctValues(); Table rootTable = resolvedPath.getRootTable(); if (rootTable != null && rootTable.getNumRows() > 0) { // The NDV cannot exceed the #rows in the table. numDistinctValues_ = Math.min(numDistinctValues_, rootTable.getNumRows()); } } @Override protected float computeEvalCost() { return SLOT_REF_COST; } @Override protected boolean isConstantImpl() { return false; } public SlotDescriptor getDesc() { Preconditions.checkState(isAnalyzed()); Preconditions.checkNotNull(desc_); return desc_; } public SlotId getSlotId() { Preconditions.checkState(isAnalyzed()); Preconditions.checkNotNull(desc_); return desc_.getId(); } public Path getResolvedPath() { Preconditions.checkState(isAnalyzed()); return desc_.getPath(); } @Override
for (String groupName: groupNames) { roles.addAll(fe.getCatalog().getAuthPolicy().getGrantedRoles(groupName)); } for (Role role: roles) { Principal rolePrincipal = getRole(role.getName()); if (rolePrincipal != null) { createShowUserPrivilegesResultRows(result, rolePrincipal.getPrivileges(), filter, rolePrincipal.getName(), TPrincipalType.ROLE); } } return result; } /** * This method adds the rows to the output for the SHOW GRANT USER statement for user * and associated roles. */ private void createShowUserPrivilegesResultRows(TResultSet result, List<PrincipalPrivilege> privileges, TPrivilege filter, String name, TPrincipalType type) { for (PrincipalPrivilege p : privileges) { TPrivilege privilege = p.toThrift(); if (filter != null && isPrivilegeFiltered(filter, privilege)) continue; TResultRowBuilder rowBuilder = new TResultRowBuilder(); rowBuilder.add(Strings.nullToEmpty(type.name().toUpperCase())); rowBuilder.add(Strings.nullToEmpty(name));
* Allows for filtering based on a specific privilege spec or showing all privileges * granted to the role. Used by the SHOW GRANT ROLE statement. */ public synchronized TResultSet getRolePrivileges(String principalName, TPrivilege filter) { TResultSet result = new TResultSet(); result.setSchema(new TResultSetMetadata()); addColumnOutputColumns(result.getSchema()); result.setRows(Lists.<TResultRow>newArrayList()); Role role = getRole(principalName); if (role != null) { for (PrincipalPrivilege p : role.getPrivileges()) { TPrivilege privilege = p.toThrift(); if (filter != null && isPrivilegeFiltered(filter, privilege)) continue; TResultRowBuilder rowBuilder = new TResultRowBuilder(); result.addToRows(addShowPrincipalOutputResults(privilege, rowBuilder).get()); } } return result; } /** * Check if the filter matches the privilege. */ private boolean isPrivilegeFiltered(TPrivilege filter, TPrivilege privilege) { filter.setPrivilege_level(privilege.getPrivilege_level()); String privName = PrincipalPrivilege.buildPrivilegeName(filter);
Type.STRING.toThrift())); addColumnOutputColumns(result.getSchema()); result.setRows(Lists.<TResultRow>newArrayList()); // A user should be considered to not exist if they do not have any groups. Set<String> groupNames = fe.getAuthzChecker().getUserGroups( new org.apache.impala.authorization.User(principalName)); if (groupNames.isEmpty()) { throw new AnalysisException(String.format("User '%s' does not exist.", principalName)); } User user = getUser(principalName); if (user != null) { for (PrincipalPrivilege p : user.getPrivileges()) { TPrivilege privilege = p.toThrift(); if (filter != null) { if (isPrivilegeFiltered(filter, privilege)) continue; } TResultRowBuilder rowBuilder = new TResultRowBuilder(); rowBuilder.add(Strings.nullToEmpty(TPrincipalType.USER.name().toUpperCase())); rowBuilder.add(Strings.nullToEmpty(principalName)); result.addToRows(addShowPrincipalOutputResults(privilege, rowBuilder).get()); } }
import org.apache.sentry.provider.common.GroupMappingService; import java.util.Map; import java.util.Set; /** * This class is used for testing complex privileges where we don't create * users and groups on the system. * * The current structure is: * user_1group -> group_1 * user_2group -> group_2a, group_2b * user1_shared -> group_3 * user2_shared -> group_3 */ public class CustomClusterGroupMapper implements GroupMappingService { private final Map<String, Set<String>> groupsMap_ = Maps.newHashMap(); public CustomClusterGroupMapper() { // Need to make sure we can resolve the dev user. String devUser = System.getProperty("user.name"); groupsMap_.put(devUser, Sets.newHashSet(devUser)); groupsMap_.put("user_1group", Sets.newHashSet("group_1")); groupsMap_.put("user_2group", Sets.newHashSet("group_2a", "group_2b")); groupsMap_.put("user1_shared", Sets.newHashSet("group_3"));
public CustomClusterResourceAuthorizationProvider(String resource, PolicyEngine policy, Model model) { super(policy, new CustomClusterGroupMapper(), model);
public CustomClusterResourceAuthorizationProvider(Configuration conf, String resource, PolicyEngine policy, Model model) { super(policy, new CustomClusterGroupMapper(), model);
import org.apache.impala.catalog.Type; import org.apache.impala.common.AnalysisException; import org.apache.impala.thrift.TExprNode; import org.apache.impala.thrift.TExprNodeType; import org.apache.impala.thrift.TSlotRef; import com.google.common.base.Joiner; import com.google.common.base.Objects; import com.google.common.base.Preconditions; public class SlotRef extends Expr { // Magic number to use to decide whether to adjust the // reported NDV value to account for possible null values. // Above this number, the adjustment is not that helpful. // Further, a higher value causes TPC-H plan tests to // fail because that has several two-value, non-nullable // fields that are marked as nullable. private static final int NULL_ADJUST_THRESHOLD = 1; private final List<String> rawPath_; private final String label_; // printed in toSql() // Results of analysis. private SlotDescriptor desc_; public SlotRef(ArrayList<String> rawPath) { super(); rawPath_ = rawPath; label_ = ToSqlUtils.getPathSql(rawPath_); }
import static org.junit.Assert.fail; import java.util.List; import org.apache.impala.common.ImpalaException; import org.apache.impala.service.Frontend.PlanCtx; import org.apache.impala.testutil.TestUtils; import org.apache.impala.thrift.TExplainLevel; import org.apache.impala.thrift.TQueryCtx; import org.apache.impala.thrift.TQueryOptions; import org.junit.Test; /** * Test the inference of tuple cardinality from NDV and * selectivity. */ public class CardinalityTest extends PlannerTestBase { /** * Test the happy path: table with stats, no all-null cols. */ @Test public void testBasicsWithStats() { // Return all rows. Cardinality is row count; verifyCardinality("SELECT id FROM functional.alltypes", 7300); // Return all rows. Cardinality is row count, // should not be influenced by limited NDV of selected // column. verifyCardinality("SELECT bool_col FROM functional.alltypes", 7300); // Result cardinality reduced by limited NDV. // Boolean column has cardinality 3 (true, false, null).
queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.requestPlanCapture(); // Discard the actual execution plan. Return the cached // internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } return planCtx.getPlan();
public void testJoinWithoutStats() { // NDV multiplied out on group by verifyCardinality( "SELECT d FROM functional.alltypes, functional.nullrows", 7300 * 26); // With that as the basis, add a GROUP BY String baseStmt = "SELECT COUNT(*) " + "FROM functional.alltypes, functional.nullrows " + "GROUP BY "; // Unique values, one group per row expectCardinality(baseStmt + "id", 7300); // NDV(a) = 26 expectCardinality(baseStmt + "a", 26); // b has NDV=1, but adjust for nulls expectCardinality(baseStmt + "b", 2); // f has NDV=6 expectCardinality(baseStmt + "f", 6); // c is all nulls expectCardinality(baseStmt + "c", 1); // NDV(a) = 26 * ndv(c) = 1 expectCardinality(baseStmt + "a, c", 26); // NDV(a) = 26 * ndv(f) = 156 // Planner does not know that a determines f expectCardinality(baseStmt + "a, f", 156);
public void testJoins() { // Cartesian product String joinClause = " FROM functional.alltypes t1, functional.alltypes t2 "; expectCardinality("SELECT t1.id" + joinClause, 7300 * 7300); // Cartesian product, reduced by NDV of group key verifyCardinality( "SELECT COUNT(*)" + joinClause + "GROUP BY t1.id", 7300); verifyCardinality( "SELECT COUNT(*)" + joinClause + "GROUP BY t1.id, t1.int_col", 7300 * 10);
import org.apache.hadoop.util.GenericOptionsParser; import org.apache.kudu.test.KuduRule; import org.junit.After; import org.junit.Rule; import org.junit.Test; import org.apache.kudu.mapreduce.CommandLineParser; import org.apache.kudu.mapreduce.HadoopTestingUtility; public class ITExportCsv { private static final String TABLE_NAME = ITExportCsv.class.getName() + "-" + System.currentTimeMillis(); private static final HadoopTestingUtility HADOOP_UTIL = new HadoopTestingUtility(); private static Schema schema; @After public void tearDown() throws Exception { HADOOP_UTIL.cleanup(); } @Test public void test() throws Exception { Configuration conf = new Configuration(); String testHome = HADOOP_UTIL.setupAndGetTestDir(ITExportCsv.class.getName(), conf).getAbsolutePath(); // create a table with on empty tablet and 3 tablets of 3 rows each. createFourTabletsTableWithNineRows(kudu.getAsyncClient(), TABLE_NAME, DEFAULT_SLEEP); String[] args = new String[] {
// KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.client; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertNotNull; import static org.junit.Assert.assertNotSame; import static org.junit.Assert.assertTrue; import com.stumbleupon.async.Deferred; import org.junit.Test; import org.apache.kudu.util.NetUtil; public class TestConnectionCache { @Rule RetryRule retryRule = new RetryRule(); @Test(timeout = 50000) public void test() throws Exception { MiniKuduCluster cluster = null; try { cluster = new MiniKuduCluster.MiniKuduClusterBuilder().numMasterServers(3).build(); final AsyncKuduClient client = new AsyncKuduClient.AsyncKuduClientBuilder(cluster.getMasterAddressesAsString()).build(); // Below we ping the masters directly using RpcProxy, so if they aren't ready to process // RPCs we'll get an error. Here by listing the tables we make sure this won't happen since
private MiniKuduClusterBuilder clusterBuilder; private MiniKuduCluster miniCluster; // We create both versions of the asyncClient for ease of use. public AsyncKuduClient asyncClient; public KuduClient client; public KuduRule(final MiniKuduClusterBuilder clusterBuilder) { this.clusterBuilder = clusterBuilder; } public KuduRule() { this.clusterBuilder = getBaseClusterBuilder(); } /** * Returns the base MiniKuduClusterBuilder used when creating a * KuduRule with the default constructor. This is useful * if you want to add to the default cluster setup. * * @return */ public static MiniKuduClusterBuilder getBaseClusterBuilder() { return new MiniKuduClusterBuilder() .numMasterServers(NUM_MASTER_SERVERS) .numTabletServers(NUM_TABLET_SERVERS); } @Override public Statement apply(Statement base, Description description) { // Set any master server flags defined in the method level annotation. MasterServerConfig masterServerConfig = description.getAnnotation(MasterServerConfig.class); if (masterServerConfig != null) { for(String flag : masterServerConfig.flags()) {
// Set any master server flags defined in the method level annotation. MasterServerConfig masterServerConfig = description.getAnnotation(MasterServerConfig.class); if (masterServerConfig != null) { for(String flag : masterServerConfig.flags()) { clusterBuilder.addMasterServerFlag(flag); } } // Set any tablet server flags defined in the method level annotation. TabletServerConfig tabletServerConfig = description.getAnnotation(TabletServerConfig.class); if (tabletServerConfig != null) { for (String flag : tabletServerConfig.flags()) { clusterBuilder.addTabletServerFlag(flag); } } // Generate the ExternalResource Statement. Statement statement = super.apply(base, description); // Wrap in the RetryRule to rerun flaky tests. // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. return new RetryRule().apply(statement, description);
// Set any tablet server flags defined in the method level annotation. TabletServerConfig tabletServerConfig = description.getAnnotation(TabletServerConfig.class); if (tabletServerConfig != null) { for(String flag : tabletServerConfig.flags()) { clusterBuilder.addTabletServerFlag(flag); } } // Generate the ExternalResource Statement. Statement statement = super.apply(base, description); // Wrap in the RetryRule to rerun flaky tests. return new RetryRule().apply(statement, description);
// Wrap in the RetryRule to rerun flaky tests. // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. return new RetryRule().apply(statement, description); } @Override public void before() throws Exception { FakeDNS.getInstance().install(); LOG.info("Creating a new MiniKuduCluster..."); miniCluster = clusterBuilder.build(); LOG.info("Creating a new Kudu client..."); asyncClient = new AsyncKuduClientBuilder(miniCluster.getMasterAddressesAsString()) .defaultAdminOperationTimeoutMs(DEFAULT_SLEEP) .build(); client = asyncClient.syncClient(); } @Override public void after() { try { if (asyncClient != null) { client.shutdown(); // No need to explicitly shutdown the async client, // shutting down the sync client effectively does that. } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } }
public void after() { try { if (client != null) { client.shutdown(); // No need to explicitly shutdown the async client, // shutting down the sync client effectively does that. } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } }
client.shutdown(); // No need to explicitly shutdown the async client, // shutting down the sync client effectively does that. } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } } public KuduClient getClient() { return client; } public AsyncKuduClient getAsyncClient() { return asyncClient; } /** * Helper method to open a table. It sets the default sleep time when joining on the Deferred. * @param name Name of the table * @return A KuduTable * @throws Exception MasterErrorException if the table doesn't exist */ public KuduTable openTable(String name) throws Exception {
// shutting down the sync client effectively does that. } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } } public KuduClient getClient() { return client; } public AsyncKuduClient getAsyncClient() { return asyncClient; } /** * Helper method to open a table. It sets the default sleep time when joining on the Deferred. * @param name Name of the table * @return A KuduTable * @throws Exception MasterErrorException if the table doesn't exist */ public KuduTable openTable(String name) throws Exception { Deferred<KuduTable> d = asyncClient.openTable(name); return d.join(DEFAULT_SLEEP); }
* into the Kerberos credential cache. * @param username the username to kinit as */ public void kinit(String username) throws IOException { miniCluster.kinit(username); } /** * Resets the clients so that their state is completely fresh, including meta * cache, connections, open tables, sessions and scanners, and propagated timestamp. */ public void resetClients() throws IOException { client.shutdown(); asyncClient = new AsyncKuduClientBuilder(miniCluster.getMasterAddressesAsString()) .defaultAdminOperationTimeoutMs(DEFAULT_SLEEP) .build(); client = asyncClient.syncClient(); } /** * An annotation that can be added to each test method to * define additional master server flags to be used when * creating the test cluster. * * ex: @MasterServerConfig(flags = { "key1=valA", "key2=valB" }) */ @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD}) public @interface MasterServerConfig { String[] flags(); } /**
public void analyzePlanHints(Analyzer analyzer) { for (PlanHint hint: planHints_) { if (!hint.is("straight_join")) { analyzer.addWarning("PLAN hint not recognized: " + hint); } }
public void analyzePlanHints(Analyzer analyzer) { for (PlanHint hint: planHints_) { if (!hint.is("straight_join")) { analyzer.addWarning("PLAN hint not recognized: " + hint); } else { analyzer.setIsStraightJoin(); } }
// be moved from this location, the user needs to have all permission. sourceDataPath_.analyze(analyzer, Privilege.ALL); // Catch all exceptions thrown by accessing files, and rethrow as AnalysisExceptions. try { Path source = sourceDataPath_.getPath(); FileSystem fs = source.getFileSystem(FileSystemUtil.getConfiguration()); if (!(fs instanceof DistributedFileSystem) && !(fs instanceof S3AFileSystem) && !(fs instanceof AzureBlobFileSystem) && !(fs instanceof SecureAzureBlobFileSystem) && !(fs instanceof AdlFileSystem)) { throw new AnalysisException(String.format("INPATH location '%s' " + "must point to an HDFS, S3A, ADL or ABFS filesystem.", sourceDataPath_)); } if (!fs.exists(source)) { throw new AnalysisException(String.format( "INPATH location '%s' does not exist.", sourceDataPath_)); } // If the source file is a directory, we must be able to read from and write to
public static byte[] deflateCompress(byte[] input) { if (input == null) return null; ByteArrayOutputStream bos = new ByteArrayOutputStream(input.length); // Experiments on a wide partitioned table with incremental stats showed that the // Deflater with 'BEST_SPEED' level provided reasonable compression ratios at much // faster speeds compared to other modes like BEST_COMPRESSION/DEFAULT_COMPRESSION. DeflaterOutputStream stream = new DeflaterOutputStream(bos, new Deflater(Deflater.BEST_SPEED)); try { stream.write(input); stream.close(); } catch (IOException e) { LOG.error("Error compressing input bytes.", e); return null; } return bos.toByteArray();
// so it's necessary to use the HMS APIs directly. HiveMetastoreConfig hmsConfig = client.getHiveMetastoreConfig(); HiveConf hiveConf = new HiveConf(); hiveConf.setVar(HiveConf.ConfVars.METASTOREURIS, hmsConfig.getHiveMetastoreUris()); hiveConf.setBoolVar( HiveConf.ConfVars.METASTORE_USE_THRIFT_SASL, hmsConfig.getHiveMetastoreSaslEnabled()); // Check that the owner of the table in the HMS matches. IMetaStoreClient hmsClient = new HiveMetaStoreClient(hiveConf); assertEquals(owner, hmsClient.getTable("default", "testOverrideTableOwner").getOwner()); // Altering the table should not result in a change of ownership. client.alterTable( tableName, new AlterTableOptions().renameTable("default.testOverrideTableOwner_renamed")); assertEquals(owner, hmsClient.getTable("default", "testOverrideTableOwner_renamed").getOwner()); } }
PrivilegeRequest request = new PrivilegeRequestBuilder() .any().onAnyTable(db.getName()).toRequest(); return authzChecker_.get().hasAccess(user, request); } /** * Returns all data sources that match the pattern. If pattern is null, * matches all data sources. */ public List<DataSource> getDataSrcs(String pattern) { return impaladCatalog_.getDataSources( PatternMatcher.createHivePatternMatcher(pattern)); } /** * Generate result set and schema for a SHOW COLUMN STATS command. */ public TResultSet getColumnStats(String dbName, String tableName) throws ImpalaException { Table table = impaladCatalog_.get().getTable(dbName, tableName); TResultSet result = new TResultSet(); TResultSetMetadata resultSchema = new TResultSetMetadata(); result.setSchema(resultSchema); resultSchema.addToColumns(new TColumn("Column", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("Type", Type.STRING.toThrift())); resultSchema.addToColumns( new TColumn("#Distinct Values", Type.BIGINT.toThrift()));
return authzChecker_.get().hasAccess(user, request); } /** * Returns all data sources that match the pattern. If pattern is null, * matches all data sources. */ public List<DataSource> getDataSrcs(String pattern) { return impaladCatalog_.getDataSources( PatternMatcher.createHivePatternMatcher(pattern)); } /** * Generate result set and schema for a SHOW COLUMN STATS command. */ public TResultSet getColumnStats(String dbName, String tableName) throws ImpalaException { Table table = impaladCatalog_.get().getTable(dbName, tableName); TResultSet result = new TResultSet(); TResultSetMetadata resultSchema = new TResultSetMetadata(); result.setSchema(resultSchema); resultSchema.addToColumns(new TColumn("Column", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("Type", Type.STRING.toThrift())); resultSchema.addToColumns( new TColumn("#Distinct Values", Type.BIGINT.toThrift())); resultSchema.addToColumns(new TColumn("#Nulls", Type.BIGINT.toThrift()));
} else { root.setLimit(stmt.getLimit()); root.computeStats(analyzer); } return root; } /** * If there are unassigned conjuncts that are bound by tupleIds or if there are slot * equivalences for tupleIds that have not yet been enforced, returns a SelectNode on * top of root that evaluates those conjuncts; otherwise returns root unchanged. * TODO: change this to assign the unassigned conjuncts to root itself, if that is * semantically correct */ private PlanNode addUnassignedConjuncts( Analyzer analyzer, List<TupleId> tupleIds, PlanNode root) { // No point in adding SelectNode on top of an EmptyNode. if (root instanceof EmptySetNode) return root; Preconditions.checkNotNull(root); // Gather unassigned conjuncts and generate predicates to enfore // slot equivalences for each tuple id. List<Expr> conjuncts = analyzer.getUnassignedConjuncts(root); for (TupleId tid: tupleIds) { analyzer.createEquivConjuncts(tid, conjuncts); } if (conjuncts.isEmpty()) return root;
// KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { /** * Perform semantic analysis of node and all of its children. * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node. */ String toSql(ToSqlOptions options); /** * Returns the SQL string corresponding to this node. * @param options controls what sql is returned * @see ToSqlOptions */ String toSql(ToSqlOptions options); }
List<Expr> tupleIsNullPreds = Lists.newArrayList(); for (Expr rhsExpr: inputSmap.getRhs()) { // Ignore substitutions that are irrelevant at this plan node and its ancestors. if (!rhsExpr.isBoundByTupleIds(input.getTupleIds())) continue; rhsExpr.collect(TupleIsNullPredicate.class, tupleIsNullPreds); } Expr.removeDuplicates(tupleIsNullPreds); sortInfo.addMaterializedExprs(tupleIsNullPreds, analyzer_); } sortInfo.getSortTupleDescriptor().materializeSlots(); return sortInfo; } /** * Create plan tree for the entire sort group, including all contained window groups. * Marks the SortNode as requiring its input to be partitioned if partitionExprs * is not null (partitionExprs represent the data partition of the entire partition * group of which this sort group is a part). */ private PlanNode createSortGroupPlan(PlanNode root, SortGroup sortGroup, List<Expr> partitionExprs) throws ImpalaException { List<Expr> partitionByExprs = sortGroup.partitionByExprs; List<OrderByElement> orderByElements = sortGroup.orderByElements;
public void computeResourceProfile(TQueryOptions queryOptions) { Preconditions.checkState(hasValidStats()); if (type_ == TSortType.TOPN) { nodeResourceProfile_ = ResourceProfile.noReservation( getSortInfo().estimateTopNMaterializedSize(cardinality_, offset_)); return; } // For an external sort, set the memory cost to be what is required for a 2-phase // sort. If the input to be sorted would take up N blocks in memory, then the // memory required for a 2-phase sort is sqrt(N) blocks. A single run would be of // size sqrt(N) blocks, and we could merge sqrt(N) such runs with sqrt(N) blocks // of memory. double fullInputSize = getChild(0).cardinality_ * avgRowSize_; boolean hasVarLenSlots = false; for (SlotDescriptor slotDesc: info_.getSortTupleDescriptor().getSlots()) { if (slotDesc.isMaterialized() && !slotDesc.getType().isFixedLengthType()) { hasVarLenSlots = true; break;
* true AND 'expr' -> 'expr' * false AND 'expr' -> false * true OR 'expr' -> true * false OR 'expr' -> 'expr' * * Unlike other rules here such as IF, we cannot in general simplify CompoundPredicates * with a NullLiteral child (unless the other child is a BoolLiteral), eg. null and * 'expr' is false if 'expr' is false but null if 'expr' is true. * * NOT is covered by FoldConstantRule. */ private Expr simplifyCompoundPredicate(CompoundPredicate expr) { if (expr.getOp() == CompoundPredicate.Operator.AND) { if (((BoolLiteral) leftChild).getValue()) { // TRUE AND 'expr', so return 'expr'. return expr.getChild(1); } else { // FALSE AND 'expr', so return FALSE. return leftChild; }
private boolean isBroadcastExchange() { // If the output of the sink is not partitioned but the target fragment is // partitioned, then the data exchange is broadcast. Preconditions.checkState(!children_.isEmpty()); DataSink sink = getChild(0).getFragment().getSink(); if (sink == null) return false; Preconditions.checkState(sink instanceof DataStreamSink); DataStreamSink streamSink = (DataStreamSink) sink; return !streamSink.getOutputPartition().isPartitioned() && fragment_.isPartitioned();
byte [] partitionStats, boolean hasIncrementalStats) { table_ = Preconditions.checkNotNull(table); spec_ = Preconditions.checkNotNull(spec); msPartition_ = Preconditions.checkNotNull(msPartition);
* nullif(expr1, expr2) * nvl(a, ifNull) * * Since every function is rewritten to a CASE * statement, the planner runs the rule to simplify CASE * after this rule. Where that other rule can perform simplifications, * those simplifications are omitted here. However, the CASE * case rules are limited (See IMPALA-7750), so several optimizations * appear here that can be removed once IMPALA-7750 is fixed. */ public class RewriteConditionalFnsRule implements ExprRewriteRule { public static RewriteConditionalFnsRule INSTANCE = new RewriteConditionalFnsRule(); private RewriteConditionalFnsRule() { } @Override public Expr apply(Expr expr, Analyzer analyzer) throws AnalysisException { if (!expr.isAnalyzed()) return expr; // Rewrite conditional functions to use CASE. The result becomes // the original expression since there is no implementation for the // rewritten function. All rewritten functions use CASE, so we'll // then want to allow CASE to do any simplification (reverting to // the original case expression if we don't pass the aggregate
Lists.newArrayList( new CaseWhenClause( // WHEN cond THEN thenExpr expr.getChild(0), expr.getChild(1))), expr.getChild(2)); // ELSE elseExpr END } /** * Rewrites IFNULL(a, x), which is an alias * for ISNULL(a, x) and NVL(a, x). * * IFNULL(NULL, x) --> x * IFNULL(a, x) --> a, if a is a non-null literal * IFNULL(a, x) --> * CASE WHEN a IS NULL THEN x ELSE a END */ private Expr rewriteIfNullFn(FunctionCallExpr expr) { Preconditions.checkState(expr.getChildren().size() == 2); Expr child0 = expr.getChild(0); return new CaseExpr(null, // CASE Lists.newArrayList( new CaseWhenClause( // WHEN a IS NULL new IsNullPredicate(child0, false), expr.getChild(1))), // THEN x child0.clone()); // ELSE a END } /**
} /** * Test some basic simplifications that are assumed in the * subsequent tests. These uncovered subtle errors and are here * to prevent regressions. */ @Test public void sanityTest() throws ImpalaException { verifySelectRewrite("null + 1", "NULL"); verifySelectRewrite("null is null", "TRUE"); verifySelectRewrite("id + (2 + 3)", "id + 5"); verifySelectRewrite("1 + 2 + id", "3 + id"); // TODO: IMPALA-7766: Perform constant folding within an expression // verifySelectRewrite("id + 1 + 2", "id + 3"); // TODO: IMPALA-7769 // verifySelectRewrite("cast(null as INT) IS NULL", "TRUE"); // verifySelectRewrite("(null + 1) is null", "TRUE"); // verifySelectRewrite("(1 + 1) is null", "FALSE"); // verifySelectRewrite("CASE WHEN null + 1 THEN 10 ELSE 20 END", "20"); } @Test public void testIf() throws ImpalaException { // Simplifications provided by CASE rewriting
// TODO: IMPALA-7766 // verifySelectRewrite("id + 1 + 2", "id + 3"); // TODO: IMPALA-7769 // verifySelectRewrite("cast(null as INT) IS NULL", "TRUE"); // verifySelectRewrite("(null + 1) is null", "TRUE"); // verifySelectRewrite("(1 + 1) is null", "FALSE"); // verifySelectRewrite("CASE WHEN null + 1 THEN 10 ELSE 20 END", "20"); } @Test public void testIf() throws ImpalaException { // Base case, no further simplificatin needed verifySelectRewrite("if(id = 0, id, id+1)", "CASE WHEN id = 0 THEN id ELSE id + 1 END"); // Simplifications provided by CASE rewriting verifySelectRewrite("if(true, id, id+1)", "id"); verifySelectRewrite("if(false, id, id+1)", "id + 1"); verifySelectRewrite("if(null, id, id+1)", "id + 1"); // Nothing to simplify verifySelectRewrite("if(id = 0, true, false)", "CASE WHEN id = 0 THEN TRUE ELSE FALSE END"); // Don't simplify if drops last aggregate verifySelectRewrite("if(true, 0, sum(id))",
SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; } public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr);
this.wrapped = wrapped; } public Expr apply(Expr expr, Analyzer analyzer) throws AnalysisException { Expr ret = wrapped.apply(expr, analyzer); if (expr != ret) rewrites++; return ret; } } public Expr RewritesOk(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOk(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOk(String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rules, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName;
return ret; } } public Expr RewritesOk(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOk(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOk(String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rules, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr();
String stmtStr = "select " + exprStr + " from " + tableName; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; } public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException {
AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; } public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getWhereClause();
return rewrittenExpr; } public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getWhereClause(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; } private Expr verifyExprEquivalence(Expr origExpr, String expectedExprStr,
// specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { /** * Perform semantic analysis of node and all of its children. * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node and its descendants. */ String toSql(ToSqlOptions options); /** * Returns the SQL string corresponding to this node and its descendants. * This should return the same result as calling toSql(ToSqlOptions.DEFAULT). */ String toSql(); }
// specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { /** * Perform semantic analysis of node and all of its children. * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node and its descendants. */ String toSql(ToSqlOptions options); /** * Returns the SQL string corresponding to this node and its descendants. * This should return the same result as calling toSql(ToSqlOptions.DEFAULT). */ String toSql(); }
* Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node and its descendants. * @param options controls the form of the sql that is returned. * @see ToSqlOptions */ String toSql(ToSqlOptions options); /** * Returns the SQL string corresponding to this node and its descendants. * This should return the same result as calling toSql(ToSqlOptions.DEFAULT). * TODO use an interface default method to implement this when we fully move to Java8. */ String toSql(); }
// Unless required by applicable law or agreed to in writing, // software distributed under the License is distributed on an // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; /** * Options to configure how Sql should be outputted by toSql() and related calls. */ public enum ToSqlOptions { /** * The default way of displaying the original SQL query without rewrites. */ DEFAULT(false, false), /** * Show rewritten query if it exists */ REWRITTEN(true, false), /** * Show Implicit Casts */ // To see implicit casts we must also show rewrites as otherwise we see original sql. // This does have the consequence that the sql with implict casts may not pssibly fail // to parse if resubmitted as, for example, rewritten semi-joins are not legal Sql. SHOW_IMPLICIT_CASTS(true, true); private boolean rewritten_;
public static String wrapString(String s, int wrapLength) { StringBuilder ret = new StringBuilder(s.length()); String[] split = s.split("\n"); for (int i = 0; i < split.length; i++) { String line = split[i]; String wrappedLine = WordUtils.wrap(line, wrapLength, null, true); // we keep any exiting newlines in text - these should be commented hints ret.append(wrappedLine); if (i < split.length - 1) ret.append("\n"); } return ret.toString();
public static String wrapString(String s, int wrapLength) { StringBuilder ret = new StringBuilder(s.length() + 32); String[] split = s.split("\n"); for (int i = 0; i < split.length; i++) { String line = split[i]; String wrappedLine = WordUtils.wrap(line, wrapLength, null, true); // we keep any existing newlines in text - these should be commented hints ret.append(wrappedLine); if (i < split.length - 1) ret.append("\n"); } return ret.toString();
checkNumericLiteralCasts(ctx, "double_col", "1", "TINYINT"); checkNumericLiteralCasts(ctx, "double_col", "1.0", "DECIMAL(2,1)"); checkNumericLiteralCasts(ctx, "double_col", "100000.001", "DECIMAL(9,3)"); } /** * Generate an insert query into a column and check that the toSql() with implicit casts * looks as expected. * columnName is the name of a column in functional.alltypesnopart. * data is the literal value to insert. * castColumn is the type to which the literal is expected to be cast. */ private void checkNumericLiteralCasts( AnalysisContext ctx, String columnName, String data, String castColumn) { String query = "insert into table functional.alltypesnopart (" + columnName + ") " + "values(" + data + ")"; String expectedToSql = "INSERT INTO TABLE " + "functional.alltypesnopart(" + columnName + ") " + "SELECT CAST(" + data + " AS " + castColumn + ")"
private void assertToSqlWithImplicitCasts( AnalysisContext ctx, String query, String expectedToSqlWithImplicitCasts) { StatementBase stmt = (StatementBase) AnalyzesOk(query, ctx); String actual = stmt.toSql(SHOW_IMPLICIT_CASTS); Assert.assertEquals("Bad sql with implicit casts from original query:\n" + query, expectedToSqlWithImplicitCasts, actual);
ignoreExplainHeader); } catch (CatalogException e) { errorLog.append(String.format("Failed to plan query\n%s\n%s", testCase.getQuery(), e.getMessage())); } actualOutput.append("====\n"); } // Create the actual output file if (GENERATE_OUTPUT_FILE) { try { outDir_.toFile().mkdirs(); FileWriter fw = new FileWriter(outDir_.resolve(testFile + ".test").toFile()); fw.write(actualOutput.toString()); fw.close(); } catch (IOException e) { errorLog.append("Unable to create output file: " + e.getMessage()); } } if (errorLog.length() != 0) { fail(errorLog.toString()); }
assertEquals("8.42PB", PrintUtils.printBytesRoundedToMb( (long)(1024L * 1024L * 1024L * 1024L * 1024L * 8.42))); // Negative values always get bytes as unit. // TODO: fix this behaviour if needed. assertEquals("-10B", PrintUtils.printBytesRoundedToMb(-10L)); assertEquals("-123456789B", PrintUtils.printBytesRoundedToMb(-123456789L)); } /** * Wrap length for testWrapText() - less than 80 to make test layout nicer. */ private static final int WRAP_LENGTH = 60; /** * Test for PrintUtils.wrapString(). * */ @Test public void testWrapText() { // Simple query wrapping. assertWrap( "Analyzed query: SELECT * FROM functional_kudu.alltypestiny WHERE CAST(bigint_col" + " AS DOUBLE) < CAST(10 AS DOUBLE)", "Analyzed query: SELECT * FROM functional_kudu.alltypestiny\n" + "WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)");
// Negative values always get bytes as unit. // TODO: fix this behaviour if needed. assertEquals("-10B", PrintUtils.printBytesRoundedToMb(-10L)); assertEquals("-123456789B", PrintUtils.printBytesRoundedToMb(-123456789L)); } /** * wrap length for testWrapText() - less than 80 to make test layout nicer */ private static final int WRAP_LENGTH = 60; /** * Test for PrintUtils.wrapString(). **/ @Test public void testWrapText() { // Simple query wrapping. assertWrap( "Analyzed query: SELECT * FROM functional_kudu.alltypestiny WHERE CAST(bigint_col" + " AS DOUBLE) < CAST(10 AS DOUBLE)", "Analyzed query: SELECT * FROM functional_kudu.alltypestiny\n" + "WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)"); // Simple query with a hint retains newlines surrounding hint. assertWrap("SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n"
assertWrap("insert into foo values (' " + " " + " ')", "insert into foo values (' \n" + "')"); // test that long words are broken up for clarity assertWrap("select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx", "select\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxx"); } /** * Check that code that has been wrapped is correctly formatted. * @param expected what it should be */ private void assertWrap(String input, String expected) { String actual = PrintUtils.wrapString(input, WRAP_LENGTH); assertEquals(expected, actual); assertNoBlankLines(actual); assertNoTerminatingNewline(actual); assertNoLongLines(actual); } /** * Assert that all lines of wrapped output are 80 chars or less. */ private void assertNoLongLines(String s) { for (String line : s.split("\n")) {
+ " " + " ')", "insert into foo values (' \n" + "')"); // test that long words are broken up for clarity assertWrap("select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx", "select\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxx"); } /** * Check that code that has been wrapped is correctly formatted. * @param expected what it should be */ private void assertWrap(String input, String expected) { String actual = PrintUtils.wrapString(input, WRAP_LENGTH); assertEquals(expected, actual); assertNoBlankLines(actual); assertNoTerminatingNewline(actual); assertNoLongLines(actual); } /** * Assert that all lines of wrapped output are 80 chars or less. */ private void assertNoLongLines(String s) { for (String line : s.split("\n")) {
import java.util.List; import org.apache.impala.analysis.Analyzer; import org.apache.impala.analysis.CaseExpr; import org.apache.impala.analysis.CaseWhenClause; import org.apache.impala.analysis.Expr; import org.apache.impala.analysis.FunctionCallExpr; import org.apache.impala.analysis.IsNullPredicate; import org.apache.impala.analysis.NullLiteral; import org.apache.impala.common.AnalysisException; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** * Rewrites conditional functions to use a CASE statement. * The conditional functions vanish from the plan after this * rewrite. * * coalesce(v1, v2, ...) * if(condition, ifTrue, ifFalseOrNull) * ifnull(a, ifNull) * isnull(a, ifNull) * nullif(expr1, expr2) * nvl(a, ifNull) * * Since every function is rewritten to a CASE * statement, the planner runs the rule to simplify CASE * after this rule. Where that other rule can perform simplifications, * those simplifications are omitted here. However, the CASE
switch (expr.getFnName().getFunction()) { case "if": return rewriteIfFn(expr); case "coalesce": return rewriteCoalesceFn(expr); case "isnull": case "nvl": case "ifnull": return rewriteIfNullFn(expr); default: return expr; } } /** * Rewrites IF(cond, thenExpr, elseExpr) --> * CASE WHEN cond THEN thenExpr ELSE elseExpr END. * * Relies on a round of CASE simplification to perform the * following simplifications after this rewrite: * * IF(TRUE, thenExpr, elseExpr) --> thenExpr * IF(FALSE|NULL, thenExpr, elseExpr) --> elseExpr * */ private Expr rewriteIfFn(FunctionCallExpr expr) { Preconditions.checkState(expr.getChildren().size() == 3); return new CaseExpr(null, // CASE Lists.newArrayList( new CaseWhenClause( // WHEN cond THEN thenExpr expr.getChild(0), expr.getChild(1))), expr.getChild(2)); // ELSE elseExpr END } /**
* include at least one of them, even if that means adding terms * A special case occurs if the resulting rules remove all * aggregate functions. If so, the rewrite must be done again to include * at least one aggregate, even if that aggregate won't ever be evaluated. * See IMPALA-5125. * * The simplifications are done here because they benefit from knowledge * of the semantics of COALESCE(), and are difficult to do once encoded * as a CASE statement. */ @SuppressWarnings("unused") private Expr rewriteCoalesceFn(FunctionCallExpr expr) { CoalesceRewriteState state = expr.contains(Expr.isAggregatePredicate()) ? CoalesceRewriteState.AWAIT_AGGREGATE : CoalesceRewriteState.STOP_AT_LITERAL; List<Expr> revised = new ArrayList<>(); top: for (Expr childExpr : expr.getChildren()) { // Skip nulls. if (childExpr.isNullLiteral()) continue; // Stop after either first literal (no aggregates) // or first literal after an aggregate (if has aggregates). switch (state) {
// Negative values always get bytes as unit. // TODO: fix this behaviour if needed. assertEquals("-10B", PrintUtils.printBytesRoundedToMb(-10L)); assertEquals("-123456789B", PrintUtils.printBytesRoundedToMb(-123456789L)); } /** * Wrap length for testWrapText() - less than 80 to make test layout nicer. */ private static final int WRAP_LENGTH = 60; /** * Test for PrintUtils.wrapString(). */ @Test public void testWrapText() { // Simple query wrapping. assertWrap( "Analyzed query: SELECT * FROM functional_kudu.alltypestiny WHERE CAST(bigint_col" + " AS DOUBLE) < CAST(10 AS DOUBLE)", "Analyzed query: SELECT * FROM functional_kudu.alltypestiny\n" + "WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)"); // Simple query with a hint retains newlines surrounding hint. assertWrap("SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n"
"Expr '%s' in select list returns a complex type '%s'.\n" + "Only scalar types are allowed in the select list.", expr.toSql(), expr.getType().toSql())); } if (!expr.getType().isSupported()) { throw new AnalysisException("Unsupported type '" + expr.getType().toSql() + "' in '" + expr.toSql() + "'."); } } if (TreeNode.contains(resultExprs_, AnalyticExpr.class)) { if (fromClause_.isEmpty()) { throw new AnalysisException("Analytic expressions require FROM clause."); } // do this here, not after analyzeAggregation(), otherwise the AnalyticExprs // will get substituted away if (selectList_.isDistinct()) { throw new AnalysisException( "cannot combine SELECT DISTINCT with analytic functions"); } } if (whereClause_ != null) { whereClause_.analyze(analyzer); if (whereClause_.contains(Expr.isAggregatePredicate())) {
public static ExprRewriteRule INSTANCE = new FoldConstantsRule(); @Override public Expr apply(Expr expr, Analyzer analyzer) throws AnalysisException { // Avoid calling Expr.isConstant() because that would lead to repeated traversals // of the Expr tree. Assumes the bottom-up application of this rule. Constant // children should have been folded at this point. for (Expr child: expr.getChildren()) if (!Expr.IS_LITERAL.apply(child)) return expr; if (Expr.IS_LITERAL.apply(expr) || !expr.isConstant()) return expr; // Do not constant fold cast(null as dataType) because we cannot preserve the // cast-to-types and that can lead to query failures, e.g., CTAS if (expr instanceof CastExpr) { CastExpr castExpr = (CastExpr) expr; if (castExpr.getChild(0) instanceof NullLiteral) { return expr; } } // Analyze constant exprs, if necessary. Note that the 'expr' may become non-constant // after analysis (e.g., aggregate functions). if (!expr.isAnalyzed()) {
public static String getPartitionKeyValueString(LiteralExpr literalValue, String nullPartitionKeyValue) { Preconditions.checkNotNull(literalValue); if (Expr.IS_NULL_LITERAL.apply(literalValue) || literalValue.getStringValue().isEmpty()) { return nullPartitionKeyValue; } return literalValue.getStringValue();
public void testUpdateCatalog() { withAllPrincipalTypes(ctx -> { String principalName = String.format("%s_update", PRINCIPAL_NAME_PREFIX); addCatalogPrincipalPrivileges(ctx.type_, ctx.catalog_, principalName, "functional"); addSentryPrincipalPrivileges(ctx.type_, ctx.sentryService_, principalName, "functional", "functional_kudu"); SentryProxy.refreshSentryAuthorization(ctx.catalog_, ctx.sentryService_, USER, false); checkCatalogPrincipalPrivileges(ctx.type_, ctx.catalog_, principalName, "server=server1->db=functional->grantoption=false", "server=server1->db=functional_kudu->grantoption=false"); });
switch (catalogObject.getType()) { case DATABASE: return "DATABASE:" + catalogObject.getDb().getDb_name().toLowerCase(); case TABLE: case VIEW: TTable tbl = catalogObject.getTable(); return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; case PRINCIPAL: // The combination of principal_id + privilege_name is guaranteed to be unique. return "PRINCIPAL:" + catalogObject.getPrincipal().getPrincipal_name() .toLowerCase(); case PRIVILEGE: return "PRIVILEGE:" + catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default:
return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; case ROLE: return "ROLE:" + catalogObject.getRole().getRole_name().toLowerCase(); case PRIVILEGE: return "PRIVILEGE:" + PrincipalPrivilege.buildPrivilegeName(catalogObject.getPrivilege()) .toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getPrincipal_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default: throw new IllegalStateException( "Unsupported catalog object type: " + catalogObject.getType()); }
for (SlotDescriptor d: slotsBySize.get(slotSize)) { Preconditions.checkState(d.isMaterialized()); d.setByteSize(slotSize); d.setByteOffset(slotOffset); d.setSlotIdx(slotIdx++); slotOffset += slotSize; // assign null indicator if (d.getIsNullable()) { d.setNullIndicatorByte(nullIndicatorByte); d.setNullIndicatorBit(nullIndicatorBit); nullIndicatorBit = (nullIndicatorBit + 1) % 8; if (nullIndicatorBit == 0) ++nullIndicatorByte; } // non-nullable slots have 0 for the byte offset and -1 for the bit mask // to make sure IS NULL always evaluates to false in the BE without having // to check nullability explicitly if (!d.getIsNullable()) { d.setNullIndicatorBit(-1); d.setNullIndicatorByte(0); } } } Preconditions.checkState(slotOffset == totalSlotSize); byteSize_ = totalSlotSize + numNullBytes_;
// specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { /** * Perform semantic analysis of node and all of its children. * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node and its descendants. */ String toSql(ToSqlOptions options); /** * Returns the SQL string corresponding to this node and its descendants. * This should return the same result as calling toSql(ToSqlOptions.DEFAULT). */ String toSql(); }
public List<NodeType> getChildren() { return children_; } /** * Return list of all nodes of the tree rooted at 'this', obtained * through pre-order traversal. * * Warning: this method is unsafe: it returns a list of nodes * of the requested type, but does not verify that the actual * nodes are indeed of that type. */ public <C extends TreeNode<NodeType>> ArrayList<C> getNodesPreOrder() { ArrayList<C> result = new ArrayList<C>(); getNodesPreOrderAux(result); return (List<C>) result; } protected void getNodesPreOrderAux(List<TreeNode<?>> result) { result.add(this); for (NodeType child: children_) child.getNodesPreOrderAux(result); } /** * Return list of all nodes of the tree rooted at 'this', obtained * through post-order traversal. * * Warning: this method is unsafe: it returns a list of nodes
} for (NodeType child: children_) child.collect(predicate, matches); } /** * Add all nodes in the tree that are of class 'cl' to the list 'matches'. * This node is checked first, followed by its children in order. If the node * itself is of class 'cl', the children are skipped. */ @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>, D extends C> void collect( Class<D> cl, Collection<D> matches) { if (cl.equals(getClass())) { matches.add((D) this); return; } for (NodeType child: children_) child.collect(cl, matches); } /** * Add all nodes in the tree that satisfy 'predicate' to the list 'matches' * This node is checked first, followed by its children in order. All nodes * that match in the subtree are added. */ @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>, D extends C> void collectAll(
public static <C extends TreeNode<C>, D extends C> void collect( Collection<C> nodeList, Predicate<? super C> predicate, Collection<D> matches) { for (C node: nodeList) node.collect(predicate, matches); } /** * For each expression in 'nodeList', collect all subexpressions of class 'cl' * into 'matches' */ public static <C extends TreeNode<C>, D extends C> void collect( Collection<C> nodeList, Class<D> cl, Collection<D> matches) { for (C node: nodeList) node.collect(cl, matches); } /** * Return true if this node or any of its children satisfy 'predicate'. */ @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>> boolean contains( Predicate<? super C> predicate) { if (predicate.apply((C) this)) return true; for (NodeType child: children_) if (child.contains(predicate)) return true; return false; } /**
public <C extends TreeNode<NodeType>> boolean contains(Class<C> cl) { if (cl.equals(getClass())) return true; for (NodeType child: children_) if (child.contains(cl)) return true; return false;
public static <C extends TreeNode<C>> boolean contains( List<C> nodeList, Class<? extends C> cl) { for (C node: nodeList) if (node.contains(cl)) return true; return false;
} return new ArrayType(convertParquetType(innerGroup.getType(0))); } /** * Converts a "logical" Parquet type to an Impala column type. * A Parquet type is considered logical when it has an annotation. The annotation is * stored as a "OriginalType". The Parquet documentation refers to these as logical * types, so we use that terminology here. */ private static Type convertLogicalParquetType( org.apache.parquet.schema.Type parquetType) throws AnalysisException { // The Parquet API is responsible for deducing logical type if only converted type // is set. LogicalTypeAnnotation logicalType = parquetType.getLogicalTypeAnnotation(); if (logicalType instanceof ListLogicalTypeAnnotation) { return convertArray(parquetType.asGroupType()); } if (logicalType instanceof MapLogicalTypeAnnotation || logicalType instanceof MapKeyValueTypeAnnotation) { // MAP_KEY_VALUE annotation should not be used any more. However, according to the // Parquet spec, some existing data incorrectly uses MAP_KEY_VALUE in place of MAP. // For backward-compatibility, a group annotated with MAP_KEY_VALUE that is not
* Construct a thrift representation of the sink. */ protected final TDataSink toThrift() { TDataSink tsink = new TDataSink(getSinkType()); tsink.setLabel(fragment_.getId() + ":" + getLabel()); TExecStats estimatedStats = new TExecStats(); estimatedStats.setMemory_used(resourceProfile_.getMemEstimateBytes()); tsink.setEstimated_stats(estimatedStats); toThrift(tsink); return tsink; } /** * Add subclass-specific information to the sink. */ abstract protected void toThriftImpl(TDataSink tsink); /** * Get the sink type of the subclass. */ abstract protected TDataSinkType getSinkType(); public void setFragment(PlanFragment fragment) { fragment_ = fragment; } public PlanFragment getFragment() { return fragment_; } public ResourceProfile getResourceProfile() { return resourceProfile_; } /** * Compute the resource profile for an instance of this DataSink. */ public abstract void computeResourceProfile(TQueryOptions queryOptions); }
public void testScalarFunctionSql() { { // Can't generate SQL for an unresolved function List<Type> args = new ArrayList<>(); Function fn = Function.createFunction("mydb", "fn1", args, Type.INT, false, TFunctionBinaryType.JAVA); try { ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); } catch (UnsupportedOperationException e) { // Expected } } { // Java function, leave off location and symbol List<Type> args = new ArrayList<>(); Function fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = new ArrayList<>();
Function fn = Function.createFunction("mydb", "fn1", args, Type.INT, false, TFunctionBinaryType.JAVA); try { ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); } catch (UnsupportedOperationException e) { // Expected } } { // Java function, leave off location and symbol List<Type> args = new ArrayList<>(); Function fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = new ArrayList<>(); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar"));
fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = new ArrayList<>(); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn.setSymbolName("MyClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN);
String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn.setSymbolName("MyClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); } { // C++ function, with location and symbol
String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); } { // C++ function, with location and symbol List<Type> args = new ArrayList<>(); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1()\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql); } { // C++ function, with location and symbol
String expected = "CREATE FUNCTION mydb.fn1()\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql); } { // C++ function, with location and symbol List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1(VARCHAR(*), BOOLEAN)\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql); }
public void testAggFnSql() { { // C++ aggregate function, with minimum state List<Type> args = Lists.newArrayList(Type.INT, Type.BOOLEAN); AggregateFunction fn = new AggregateFunction(new FunctionName("mydb", "fn1"), args, Type.BIGINT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setUpdateFnSymbol("Update"); fn.setInitFnSymbol("Init"); fn.setMergeFnSymbol("Merge"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE AGGREGATE FUNCTION mydb.fn1(INT, BOOLEAN)\n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " UPDATE_FN='Update'\n" + " INIT_FN='Init'\n" + " MERGE_FN='Merge'\n"; assertEquals(expected, sql); } { // C++ aggregate function, with full state
" RETURNS BIGINT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " UPDATE_FN='Update'\n" + " INIT_FN='Init'\n" + " MERGE_FN='Merge'\n"; assertEquals(expected, sql); } { // C++ aggregate function, with full state List<Type> args = Lists.newArrayList(Type.INT, Type.BOOLEAN); AggregateFunction fn = new AggregateFunction(new FunctionName("mydb", "fn1"), args, Type.BIGINT, false); fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setUpdateFnSymbol("Update"); fn.setInitFnSymbol("Init"); fn.setMergeFnSymbol("Merge"); fn.setFinalizeFnSymbol("Finalize"); fn.setSerializeFnSymbol("Serialize"); fn.setIntermediateType(Type.INT); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE AGGREGATE FUNCTION mydb.fn1(INT, BOOLEAN)\n" + " RETURNS BIGINT\n" +
public void testCreateFunctionSql() { { // Two functions, one C++, one Java ScalarFunction fn1 = new ScalarFunction(new FunctionName("mydb", "fn1"), new ArrayList<>(), Type.INT, false); fn1.setBinaryType(TFunctionBinaryType.JAVA); fn1.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn1.setSymbolName("MyClass"); List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn2 = new ScalarFunction(new FunctionName("mydb", "fn2"), args, Type.INT, false); fn2.setBinaryType(TFunctionBinaryType.NATIVE); fn2.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn2.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn1, fn2)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass';\n" +
ScalarFunction fn1 = new ScalarFunction(new FunctionName("mydb", "fn1"), new ArrayList<>(), Type.INT, false); fn1.setBinaryType(TFunctionBinaryType.JAVA); fn1.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn1.setSymbolName("MyClass"); List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn2 = new ScalarFunction(new FunctionName("mydb", "fn2"), args, Type.INT, false); fn2.setBinaryType(TFunctionBinaryType.NATIVE); fn2.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn2.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn1, fn2)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass';\n" + "CREATE FUNCTION mydb.fn2(VARCHAR(*), BOOLEAN)\n" + " RETURNS INT\n" +
public RetryRule() { this(Integer.getInteger("rerunFailingTestsCount", 0));
RetryRule(int retryCount) { this.retryCount = retryCount;
return new RetryStatement(base, description, retryCount); } private static class RetryStatement extends Statement { private final Statement base; private final Description description; private final int retryCount; RetryStatement(Statement base, Description description, int retryCount) { this.base = base; this.description = description; this.retryCount = retryCount; } @Override public void evaluate() throws Throwable { Throwable lastException; int attempt = 0; do { attempt++; try { base.evaluate(); return; } catch (Throwable t) { // To retry, we catch the exception from evaluate(), log an error, and loop. // We retain and rethrow the last failure if all attempts fail. lastException = t; LOG.error("{}: failed attempt {}", description.getDisplayName(), attempt, t); } } while (attempt <= retryCount); LOG.error("{}: giving up after {} attempts", description.getDisplayName(), attempt); throw lastException; } } }
public void testRetry() { if (failures < MAX_FAILURES) { failures++; assertFalse(String.format("%d failures", failures), true); } // Fall through and pass the test on the final retry.
* limitations under the License. */ package com.couchbase.client.core.env; public enum NetworkResolution { /** * Pick whatever the server returns in the config, this is the * old and backwards compatible mode (server default). */ DEFAULT, /** * Based on heuristics discovers if internal or * external resolution will be used. * * This is the default setting (not to be confused with * the default mode)! */ public static NetworkResolution AUTOMATIC = new NetworkResolution("auto"); /** * Pins it to external resolution. */ EXTERNAL }
OpenBucketRequest request; if (ClusterDependentTest.minClusterVersion()[0] >= 5) { request = new OpenBucketRequest(TestProperties.bucket(), TestProperties.adminUser(), TestProperties.adminPassword()); } else { request = new OpenBucketRequest(TestProperties.bucket(), TestProperties.username(), TestProperties.password()); } core.send(request).toBlocking().single(); BackpressureException exception = RingBufferMonitor.instance().createException(); assertEquals(0, exception.diagostics().totalCount()); core.send(new CloseBucketRequest(TestProperties.bucket())).toBlocking().single(); } }
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.core; import com.couchbase.client.core.tracing.RingBufferDiagnostics; /** * Identifies the need to back off on the supplier side when using a service, because the consumer is overloaded. * * @author Michael Nitschinger * @since 1.0 */ public class BackpressureException extends CouchbaseException { private RingBufferDiagnostics diagnostics; public BackpressureException() {} public BackpressureException(RingBufferDiagnostics diagnostics) { this.diagnostics = diagnostics; } /** * Returns a {@link RingBufferDiagnostics} which, if non-null, gives a granular breakdown of the contents of the * ringbuffer at the time of this exception */ public RingBufferDiagnostics getRingBufferDiagnostics() { return diagnostics; } private RingBufferDiagnostics diagnostics; }
@InterfaceAudience.Public @InterfaceStability.Experimental public RingBufferDiagnostics diagostics() { return diagnostics;
requestDisruptor.start(); requestRingBuffer = requestDisruptor.getRingBuffer(); } @Override @SuppressWarnings("unchecked") public <R extends CouchbaseResponse> Observable<R> send(CouchbaseRequest request) { if (request instanceof InternalRequest) { handleInternalRequest(request); return (Observable<R>) request.observable().observeOn(environment.scheduler()); } else if (request instanceof ClusterRequest) { handleClusterRequest(request); return (Observable<R>) request.observable().observeOn(environment.scheduler()); } else { RingBufferMonitor ringBufferMonitor = RingBufferMonitor.instance(); ringBufferMonitor.addRequest(request); if (coreSendHook == null) { boolean published = requestRingBuffer.tryPublishEvent(REQUEST_TRANSLATOR, request); if (!published) { request.observable().onError(RingBufferMonitor.getInstance().createException()); } return (Observable<R>) request.observable(); } else { Subject<CouchbaseResponse, CouchbaseResponse> response = request.observable(); Tuple2<CouchbaseRequest, Observable<CouchbaseResponse>> hook = coreSendHook .beforeSend(request, response); boolean published = requestRingBuffer.tryPublishEvent(REQUEST_TRANSLATOR, hook.value1()); if (!published) {
public static RingBufferMonitor instance() { return instance;
private AtomicInteger getOrAddCount(CouchbaseRequest request) { // instanceof is used instead of a more generic Map-based solution purely to provide lock-free performance if (request instanceof GenericQueryRequest) { return countQuery; } else if (request instanceof ClusterRequest) { return countCluster; } else if (request instanceof ConfigRequest) { return countConfig; } else if (request instanceof InternalRequest) { return countInternal; } else if (request instanceof BinaryRequest) { return countBinary; } else if (request instanceof SearchRequest) { return countSearch; } else if (request instanceof ViewRequest) { return countView; } else if (request instanceof AnalyticsRequest) { return countAnalytics; } else { return countOther; }
*/ private EncryptionConfig encryptionConfig; /** * Encryption prefix */ public static final String ENCRYPTION_PREFIX = "__encrypt_"; /** * Private constructor to create the object. * * The internal map is initialized with the default capacity. */ private JsonObject() { content = new HashMap<String, Object>(); encryptionPathInfo = new HashMap<String, EncryptionInfo>(); } /** * Private constructor to create the object with a custom initial capacity. */ private JsonObject(int initialCapacity) { content = new HashMap<String, Object>(initialCapacity); encryptionPathInfo = new HashMap<String, String>(); } /** * Creates a empty {@link JsonObject}. * * @return a empty {@link JsonObject}. */ public static JsonObject empty() { return new JsonObject(); } /** * Creates a empty {@link JsonObject}. * * @return a empty {@link JsonObject}. */
sb.append(", viewTimeout=").append(this.viewTimeout); sb.append(", searchTimeout=").append(this.searchTimeout); sb.append(", analyticsTimeout=").append(this.analyticsTimeout); sb.append(", kvTimeout=").append(this.kvTimeout); sb.append(", connectTimeout=").append(this.connectTimeout); sb.append(", dnsSrvEnabled=").append(this.dnsSrvEnabled); if (this.cryptoManager() != null) { sb.append(", cryptoManager=").append(this.cryptoManager.toString()); } return sb;
* allow to store such objects which can be represented by JSON. * * @author Michael Nitschinger * @author Simon Basl * @since 2.0 */ public class JsonObject extends JsonValue implements Serializable { private static final long serialVersionUID = 8817717605659870262L; /** * The backing {@link Map} for the object. */ private final Map<String, Object> content; /** * Encryption meta information for the Json values */ private volatile Map<String, String> encryptionPathInfo; /** * Configuration for decryption, set using the environment */ private EncryptionConfig encryptionConfig; /** * Encryption prefix */ public static final String ENCRYPTION_PREFIX = "__encrypt_"; /** * Private constructor to create the object. * * The internal map is initialized with the default capacity. */ private JsonObject() { content = new HashMap<String, Object>(); encryptionPathInfo = new HashMap<String, String>(); } /**
* @author Simon Basl * @since 2.0 */ public class JsonObject extends JsonValue implements Serializable { private static final long serialVersionUID = 8817717605659870262L; /** * The backing {@link Map} for the object. */ private final Map<String, Object> content; /** * Encryption meta information for the Json values */ private final Map<String, String> encryptionPathInfo; /** * Configuration for decryption, set using the environment */ private volatile CryptoManager cryptoManager; /** * Encryption prefix */ public static final String ENCRYPTION_PREFIX = "__encrypt_"; /** * Private constructor to create the object. * * The internal map is initialized with the default capacity. */ private JsonObject() { content = new HashMap<String, Object>(); encryptionPathInfo = new HashMap<String, String>(); } /** * Private constructor to create the object with a custom initial capacity. */ private JsonObject(int initialCapacity) {
/** * Decrypt value if the name starts with "__encrypt_" */ private Object decrypt(JsonObject object, String providerName) throws Exception { Object decrypted; String key = object.getString("kid"); String alg = object.getString("alg"); CryptoProvider provider = this.cryptoManager.getProvider(providerName); if (!provider.checkAlgorithmNameMatch(alg)) { throw new CryptoProviderMissingPublicKeyException("Cryptographic providers require a non-null, empty public and key identifier (kid) be configured for the alias: " + providerName); } if (!key.contentEquals(provider.getKeyStoreProvider().publicKeyName())) { throw new CryptoProviderDecryptFailedException("The decryption of the field failed for the alias: " + providerName + "(Public key mismatch)"); } byte[] encryptedBytes; String encryptedValueWithConfig; if (object.containsKey("iv")) { encryptedValueWithConfig = object.getString("kid") + object.getString("alg") + object.getString("iv") + object.getString("ciphertext");
+ object.getString("ciphertext"); encryptedBytes = Base64.decode(object.getString("ciphertext")); } if (object.containsKey("sig")) { byte[] signature = Base64.decode(object.getString("sig")); if (!provider.verifySignature(encryptedValueWithConfig.getBytes(), signature)) { throw new CryptoProviderSigningFailedException("The authentication failed while checking the signature of the message payload for the alias: " + providerName); } } byte[] decryptedBytes = provider.decrypt(encryptedBytes); String decryptedString = new String(decryptedBytes, Charset.forName("UTF-8")); decrypted = JacksonTransformers.MAPPER.readValue(decryptedString, Object.class); if (decrypted instanceof Map) { decrypted = JsonObject.from((Map<String, ?>) decrypted); } else if (decrypted instanceof List) { decrypted = JsonArray.from((List<?>) decrypted); } return decrypted; } /** * Retrieves the (potential null) content and not casting its type. * * @param name the key of the field.
public String toString() { return "DefaultPortInfo{" + "ports=" + ports + ", sslPorts=" + sslPorts + ", hostname='" + hostname + ", alternateAddresses=" + alternateAddresses + '\'' + '}';
public Credentials(String username, String password) { this.username = requireNonNull(username, "username can't be null"); this.password = requireNonNull(password, "password can't be null");
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.dcp; import java.net.InetSocketAddress; public interface CredentialsProvider { /** * Get the username/password pair to use for authentication/authorization * * @param address * @return credentials */ Credentials get(InetSocketAddress address); }
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.dcp; import java.net.InetSocketAddress; public class StaticCredentialsProvider implements CredentialsProvider { private final Credentials credentials; public StaticCredentialsProvider(String username, String password) { credentials = new Credentials(username, password); } @Override public Credentials get(InetSocketAddress address) { return credentials; } }
*/ private SaslClient saslClient; /** * Stores the selected SASL mechanism in the process. */ private String selectedMechanism; /** * Creates a new auth handler. * * @param address user/bucket name. * @param environment password of the user/bucket. */ AuthHandler(String username, String password) { this.username = username; this.password = password; } /** * Once the channel is active, start the SASL auth negotiation. */ @Override public void channelActive(final ChannelHandlerContext ctx) throws Exception { ByteBuf request = ctx.alloc().buffer(); SaslListMechsRequest.init(request); ctx.writeAndFlush(request); } /** * Every time we recieve a message as part of the negotiation process, handle * it according to the req/res process. */ @Override protected void channelRead0(final ChannelHandlerContext ctx, final ByteBuf msg) throws Exception {
private String clientContextId; private Map<String, Object> rawParams; private boolean pretty; /** * We are exposing this as a boolean, but internally the server * wants it as int to be forwards compatible (since at some * point we might want to expose this as a number to users). */ private int priority; private AnalyticsParams() { pretty = false; priority = 0;
public AnalyticsParams priority(boolean priority) { return priority(priority ? -1 : 0);
public String toString() { return "AnalyticsParams{" + "serverSideTimeout='" + serverSideTimeout + '\'' + ", clientContextId='" + clientContextId + '\'' + ", rawParams=" + rawParams + ", pretty=" + pretty + ", priority=" + priority + '}';
} public static void setOpaque(int opaque, ByteBuf buffer) { buffer.setInt(OPAQUE_OFFSET, opaque); } public static int getOpaque(ByteBuf buffer) { return buffer.getInt(OPAQUE_OFFSET); } public static long getCas(ByteBuf buffer) { return buffer.getLong(CAS_OFFSET); } private static String formatOpcode(byte opcode) { return String.format("0x%02x (%s)", opcode, getOpcodeName(opcode)); } private static String formatMagic(byte magic) { String name = magic == MAGIC_REQ ? "REQUEST" : (magic == MAGIC_RES) ? "RESPONSE" : "?"; return String.format("0x%02x (%s)", magic, name); } }
} DcpControl control = environment.dcpControl(); Credentials credentials = environment.credentialsProvider().get((InetSocketAddress) ch.remoteAddress()); pipeline.addLast(new AuthHandler(credentials.getUsername(), credentials.getPassword())) .addLast(new DcpConnectHandler(environment.connectionNameGenerator(), environment.bucket(), control)) .addLast(new DcpControlHandler(control)); if (control.noopEnabled()) { pipeline.addLast(new IdleStateHandler(2 * control.noopIntervalSeconds(), 0, 0)); } if (LOGGER.isTraceEnabled()) { pipeline.addLast(new DcpLoggingHandler(LogLevel.TRACE)); } DcpMessageHandler messageHandler = new DcpMessageHandler(ch, environment, controlHandler); pipeline.addLast(messageHandler); if (environment.persistencePollingEnabled()) { pipeline.addLast(new PersistencePollingHandler(environment, configProvider, messageHandler)); } } }
public void shouldSerializeEjectionMethod() { BucketSettings settings = DefaultBucketSettings.builder() .ejectionMethod(EjectionMethod.FULL) .build(); DefaultAsyncClusterManager clusterManager = new DefaultAsyncClusterManager("login", "password", null, null, null); String payload = clusterManager.getConfigureBucketPayload(settings, false); assertTrue(payload.contains("evictionPolicy=fullEviction"));
* distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.java.error; import com.couchbase.client.core.CouchbaseException; /** * An exception denoting that the search engine couldn't parse an FTS request. * * @author Simon Basl * @since 2.3 */ public class FtsServerOverloadException extends TemporaryFailureException { public FtsServerOverloadException(String payload) { super("Search server is overloaded. Details: " + payload); } }
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.java.error; import com.couchbase.client.core.CouchbaseException; /** * An exception denoting that the search engine couldn't parse an FTS request. * * @author Simon Basl * @since 2.3 */ public class FtsServerOverloadException extends TemporaryFailureException { public FtsServerOverloadException(String payload) { super("Search server is overloaded. Details: " + payload); } }
return applyTimeout(core.<SearchQueryResponse>send(request), request, environment, timeout, timeUnit); } }) .flatMap(new Func1<SearchQueryResponse, Observable<SearchQueryResponse>>() { @Override public Observable<SearchQueryResponse> call(final SearchQueryResponse r) { if (shouldRetry(r.statusCode())) { return Observable.error(new RetryableException(r)); } return Observable.just(r); } }) .retryWhen(RetryBuilder .anyOf(RetryableException.class) .max(10) .delay(Delay.exponential(TimeUnit.MILLISECONDS, upperRetryLimit, lowerRetryLimit)) .doOnRetry(new Action4<Integer, Throwable, Long, TimeUnit>() { @Override public void call(Integer attempt, Throwable error, Long delay, TimeUnit delayUnit) { LOGGER.debug("Retrying {} because of {} (attempt {}, delay {} {})", query.export(), error.getMessage(), attempt, delay, delayUnit); } }) .build() ) .map(new Func1<SearchQueryResponse, AsyncSearchQueryResult>() { @Override public AsyncSearchQueryResult call(final SearchQueryResponse response) {
public N1qlWriter(N1qlMode mode, boolean createDocuments) { this.mode = mode; this.conditions = whereFields == null ? null : conditions(whereFields); this.createDocuments = createDocuments;
* size is respected. * * @param spans the span list to work off of. * @param span the span to store. */ private void updateSpans(final List<ThresholdLogSpan> spans, final ThresholdLogSpan span) { spans.add(span); // We always need to keep the list properly sorted so that the highest // spans by duration are at the top Collections.sort(spans, Collections.<ThresholdLogSpan>reverseOrder()); while(spans.size() > sampleSize) { // Remove the element with the lowest duration, so we only keep // the highest ones consistently spans.remove(); } hasThresholdWritten = true; } } /** * This method is intended to be overridden in test implementations * to assert against the output. */ void logOverThreshold(final List<Map<String, Object>> toLog) { try { String result = pretty ? prettyWriter().writeValueAsString(toLog) : writer().writeValueAsString(toLog);
} @Override public void flush(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { if (originalPromise != null) { originalPromise.setFailure(cause); } ctx.fireExceptionCaught(cause); } @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { if (evt instanceof HandshakeDeadlineEvent) { originalPromise().tryFailure(new ConnectTimeoutException("Handshake did not complete before deadline.")); ctx.close(); return; } ctx.fireUserEventTriggered(evt); } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { if (!originalPromise().isDone()) { originalPromise().setFailure(new ConnectException("Channel became inactive before handshake completed.")); } ctx.fireChannelInactive(); } }
} @Override protected Tuple2<ByteBuf, Integer> doEncode(final JsonDocument document) throws Exception { addEncryption(document.content()); return Tuple.create(jsonObjectToByteBuf(document.content()), TranscoderUtils.JSON_COMPAT_FLAGS); } @Override protected JsonDocument doDecode(String id, ByteBuf content, long cas, int expiry, int flags, ResponseStatus status) throws Exception { if (!TranscoderUtils.hasJsonFlags(flags)) { throw new TranscodingException("Flags (0x" + Integer.toHexString(flags) + ") indicate non-JSON document for " + "id " + id + ", could not decode."); } JsonDocument document = newDocument(id, expiry, byteBufToJsonObject(content), cas); if (document.content() != null) { document.content().setCryptoManager(this.cryptoManager); } return document; } @Override public JsonDocument newDocument(String id, int expiry, JsonObject content, long cas) { JsonDocument document = JsonDocument.create(id, expiry, content, cas); document.content().setEncryptionConfig(this.encryptionConfig); return document; } @Override
public JsonDocument newDocument(String id, int expiry, JsonObject content, long cas) { JsonDocument document = JsonDocument.create(id, expiry, content, cas); return document;
JsonDocument doc = JsonDocument.create(id, data); Observable<JsonDocument> result; switch (opts.ingestMethod) { case INSERT: result = bucket.async().insert(doc); break; case UPSERT: result = bucket.async().upsert(doc); break; case REPLACE: result = bucket.async().replace(doc); break; default: return Observable.error( new UnsupportedOperationException("Unsupported ingest method") ); } result = result.timeout(kvTimeout, TimeUnit.MILLISECONDS); if (opts.retryBuilder != null) { result = result.retryWhen(opts.retryBuilder.build()); } if (opts.ignoreIngestError) { result = result.onErrorResumeNext(Observable.<JsonDocument>empty()); } return result;
int expiration, long cas) { this(key, path, fragment, bucket, expiration, cas, AsyncSubject.<CouchbaseResponse>create()); } /** * Creates a new {@link AbstractSubdocMutationRequest}. * * @param key the key of the document. * @param path the subdocument path to consider inside the document. * @param fragment the fragment of valid JSON to mutate into at the site denoted by the path. * @param bucket the bucket of the document. * @param expiration the TTL of the whole enclosing document. * @param cas the cas value for the operation * @param observable the observable which receives responses. * @throws NullPointerException if the path is null (see {@link #EXCEPTION_NULL_PATH}) */ protected AbstractSubdocMutationRequest(String key, String path, ByteBuf fragment, String bucket, int expiration, long cas, Subject<CouchbaseResponse, CouchbaseResponse> observable) { super(key, path, bucket, observable, fragment); this.expiration = expiration;
* distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.java.query.dsl.path; /** * . * * @author Michael Nitschinger */ public enum SelectType { DEFAULT(""), ALL("ALL"), DISTINCT("DISTINCT"), RAW("RAW"), DISTINCT_RAW("DISTINCT RAW"); private final String value; SelectType(String value) { this.value = value; } public String value() { return value; } }
public void shouldNotAllowReplaceAndUUID() { AnalyticsIngester.ingest( null, null, ingestOptions().ingestMethod(AnalyticsIngester.IngestMethod.REPLACE) );
kage com.couchbase.client.java; import java.util.Iterator; import com.couchbase.client.java.analytics.AnalyticsDeferredResultHandle; import com.couchbase.client.java.analytics.AnalyticsParams; import com.couchbase.client.java.analytics.AnalyticsQuery; import com.couchbase.client.java.analytics.AnalyticsQueryResult; import com.couchbase.client.java.analytics.AnalyticsQueryRow; /** * Stand alone test for now as it is experimental */ public class AnalyticsDeferredQueryTest { public static void main(String... args) throws Exception { Cluster cluster = CouchbaseCluster.create(); cluster.authenticate("Administrator", "password"); Bucket bucket = cluster.openBucket("default"); AnalyticsQueryResult result = bucket.query(AnalyticsQuery.simple("SELECT 1=1;", AnalyticsParams.build().deferred(true))); byte[] serialized = bucket.exportAnalyticsDeferredResultHandle(result.handle()); AnalyticsDeferredResultHandle handle = bucket.importAnalyticsDeferredResultHandle(serialized); while(!handle.status().equalsIgnoreCase("success")) { Thread.sleep(100); handle.status(); } Iterator<AnalyticsQueryRow> it = handle.rows();
import com.couchbase.client.core.annotations.InterfaceAudience; import com.couchbase.client.core.annotations.InterfaceStability; /** * An async handle to fetch the status and results of a deferred * Analytics Query * * @author Subhashni Balakrishnan * @since 2.7.2 */ @InterfaceStability.Experimental @InterfaceAudience.Public public interface AnalyticsDeferredResultHandle { /** * Get the status uri * * @return uri */ @InterfaceAudience.Private String getStatusHandleUri(); /** * Get the result uri if available * Throws {@link RuntimeException} if there is no result handle available * @return uri */ @InterfaceAudience.Private String getResultHandleUri(); /** * @return the list of all {@link AnalyticsQueryRow}, the results of the query, if successful. */ List<AnalyticsQueryRow> allRows(); /** * @return an iterator over the list of all {@link AnalyticsQueryRow}, the results of the query, if successful. */ Iterator<AnalyticsQueryRow> rows(); /**
"status='" + status + '\'' + ", finalSuccess=" + finalSuccess + ", parseSuccess=" + parseSuccess + ", allRows=" + allRows + ", signature=" + signature + ", info=" + info + ", errors=" + errors + ", requestId='" + requestId + '\'' + ", clientContextId='" + clientContextId + '\'' + ", handle='" + handle+ '\'' + '}';
public String getResultHandleUri() { if (this.resultHandle.length() == 0) { throw new IllegalStateException("There is no result handle available, retry status until success"); } return this.resultHandle;
public KeysPath useNestedLoop() { element(new NestedLoopJoinHintElement()); return new DefaultKeysPath(this);
public String export() { return "USE HASH(" + this.side + ")";
public String export() { return "USE HASH(" + this.side + ")";
* See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.java.query.dsl.path; import com.couchbase.client.core.annotations.InterfaceAudience; import com.couchbase.client.core.annotations.InterfaceStability; /** * Hash side for hash based join * * @author Subhashni Balakrishnan */ @InterfaceStability.Experimental @InterfaceAudience.Public public enum HashSide { /*The PROBE side will use that table to find matches and perform the join*/ PROBE("PROBE"), /** * The BUILD side of the join will be used to create an in-memory hash table * */ BUILD("BUILD"); private final String value; HashSide(String value) { this.value = value; } public String getValue() { return this.value; } }
/** * Hash side for hash based join * * @author Subhashni Balakrishnan */ @InterfaceStability.Experimental @InterfaceAudience.Public public enum HashSide { /*The PROBE side will use that table to find matches and perform the join*/ PROBE("PROBE"), /*The BUILD side of the join will be used to create an in-memory hash table */ BUILD("BUILD"); private final String value; HashSide(String value) { this.value = value; } @Override public String toString() { return this.value; } }
* updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of an specific reference * name. * <p> * A number that increases when a reference is updated. Implementations * define its meaning (e.g. version counter or timestamp). When the * implementation doesn't support versioning, it throws an * {@link UnsupportedOperationException}. * * @return the version of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.2 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } }
* @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of an specific reference * name. * <p> * A number that increases when a reference is updated. Implementations * define its meaning (e.g. version counter or timestamp). When the * implementation doesn't support versioning, it throws an * {@link UnsupportedOperationException}. * * @return the update index of this reference. */ default long getVersion() { throw new UnsupportedOperationException(); } }
public void testUpdateIndexNotImplemented() throws IOException { Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getVersion(); // Not implemented on FS } @Test public void testUpdateIndexNotImplemented2() throws Exception { RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref: refs) { try { ref.getVersion(); fail("FS doesn't implement ref versioning"); } catch (UnsupportedOperationException e) { // ok } } } @Test public void testGetRefs_EmptyDatabase() throws IOException { Map<String, Ref> all; all = refdir.getRefs(RefDatabase.ALL); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_HEADS); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_TAGS); assertTrue("no references", all.isEmpty()); } @Test public void testGetRefs_HeadOnOneBranch() throws IOException {
* Decorate a reference adding the update index (version) property. * * Undecorated Refs throw {@link UnsupportedOperationException} on * {@link #getVersion()}, while decorated instances return the expect value. * * The client is responsible to call {@link #getVersion()} only on refs * obtained from {@link RefDatabase} implementations that support versioning * (e.g. reftables) * * @since 5.2 */ public class VersionedRef implements Ref { private Ref ref; private long version; /** * @param ref * the Reference * @param updateIndex * its update index */ public VersionedRef(Ref ref, long updateIndex) { this.ref = ref; this.updateIndex = updateIndex; } @Override public String getName() { return ref.getName(); } @Override public boolean isSymbolic() { return ref.isSymbolic(); } @Override public Ref getLeaf() { return ref.getLeaf(); } @Override public Ref getTarget() {
private TmfFilterHelper() { // nothing to do } /** * Build an event filter from the regex string in parameter * * @param regexes * The filter regex * @param trace * The trace this filter applies to * @return An event filter */ public static @Nullable ITmfFilter buildFilterFromRegex(Collection<String> regexes, ITmfTrace trace) { FilterCu compile = FilterCu.compile(IFilterStrings.mergeFilters(regexes)); if (compile == null) { Activator.logInfo("buildFilterFromRegex: Invalid regex"); //$NON-NLS-1$ return null; } return compile.getEventFilter(trace); } /** * Get the regex that corresponds to this filter. The regex should be in the * filter language described in the * {@link org.eclipse.tracecompass.tmf.filter.parser} plugin. And as it may * be used to filter anything, so it may not be the direct string * representing of the original filter. For instance, a ITmfFilter specific * for events will do a smart conversion, so that the parameters of the
* instantiator of the Ref must override this method (e.g. with the * {@link VersionedRef} decorator) if it can provide a version value. * * @return the version of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.2 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } }
* ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */ package org.eclipse.jgit.lib; /** * Decorate a reference adding the update index (version) property. * * Undecorated Refs throw {@link UnsupportedOperationException} on * {@link #getVersion()}, while decorated instances return the expect value. * * The client is responsible to call {@link #getVersion()} only on refs obtained * from {@link RefDatabase} implementations that support versioning (e.g. * reftables). This can be checked via {@link RefDatabase#hasVersioning()} * method. * * @since 5.2 */ public class VersionedRef implements Ref { private Ref ref; private long updateIndex; /** * @param ref * the Reference * @param updateIndex * its update index */ public VersionedRef(Ref ref, long updateIndex) { this.ref = ref; this.updateIndex = updateIndex; } @Override public String getName() { return ref.getName(); } @Override public boolean isSymbolic() { return ref.isSymbolic(); } @Override
} }; } else { factory = new UMLPropertyEditorFactory(reference); } EClass type = reference.getEReferenceType(); factory.setContainerLabelProvider(new UMLFilteredLabelProvider()); factory.setReferenceLabelProvider(new EMFLabelProvider()); ITreeContentProvider contentProvider = new UMLContainerContentProvider(source, reference); ResourceSet rs = source == null ? null : source.eResource() == null ? null : source.eResource().getResourceSet(); EMFGraphicalContentProvider provider = ProviderHelper.encapsulateProvider(contentProvider, rs, HistoryUtil.getHistoryID(source, feature, "container")); //$NON-NLS-1$ factory.setContainerContentProvider(provider); factory.setReferenceContentProvider(new FeatureContentProvider(type)); return factory;
* https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation * Christian W. Damus - bug 485220 * *****************************************************************************/ package org.eclipse.papyrus.uml.tools.databinding; import org.eclipse.core.databinding.observable.IObservable; import org.eclipse.emf.edit.domain.EditingDomain; /** * @deprecated since * Use the {@link org.eclipse.papyrus.infra.services.edit.ui.databinding.AggregatedPapyrusObservableValue} API, instead. * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public class AggregatedPapyrusObservableValue extends org.eclipse.papyrus.infra.services.edit.ui.databinding.AggregatedPapyrusObservableValue { public AggregatedPapyrusObservableValue(EditingDomain domain, IObservable... observableValues) { super(domain, observableValues); } }
* which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation * Christian W. Damus - bug 485220 * *****************************************************************************/ package org.eclipse.papyrus.uml.tools.databinding; /** * @deprecated since 1.2.0 * Use the {@link org.eclipse.papyrus.infra.tools.databinding.CommandBasedObservable} API, instead. * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public interface CommandBasedObservable extends org.eclipse.papyrus.infra.tools.databinding.CommandBasedObservable { // Nothing additional }
* which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation * Christian W. Damus - bug 485220 * *****************************************************************************/ package org.eclipse.papyrus.uml.tools.databinding; /** * @deprecated since 1.2.0 * Use the {@link org.eclipse.papyrus.infra.tools.databinding.CommandBasedObservableValue} API, instead. * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public interface CommandBasedObservableValue extends CommandBasedObservable, org.eclipse.papyrus.infra.tools.databinding.CommandBasedObservableValue { // Nothing additional }
import org.eclipse.gmf.runtime.emf.type.core.requests.SetRequest; import org.eclipse.papyrus.infra.emf.gmf.command.GMFtoEMFCommandWrapper; import org.eclipse.papyrus.infra.services.edit.service.ElementEditServiceUtils; import org.eclipse.papyrus.infra.services.edit.service.IElementEditService; import org.eclipse.papyrus.infra.ui.emf.databinding.EMFObservableList; /** * An ObservableList used to edit collections of EObjects through * Papyrus commands * * @author Camille Letavernier * @deprecated since 1.2.0 * Use the {@link org.eclipse.papyrus.infra.gmfdiag.common.databinding.GMFObservableList} API, instead * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated @SuppressWarnings("unchecked") public class PapyrusObservableList extends EMFObservableList { /** * * Constructor. * * @param wrappedList * The list to be edited when #commit() is called * @param domain * The editing domain on which the commands will be executed * @param source * The EObject from which the list will be retrieved * @param feature
import org.eclipse.papyrus.infra.services.edit.service.ElementEditServiceUtils; import org.eclipse.papyrus.infra.services.edit.service.IElementEditService; import org.eclipse.papyrus.infra.tools.databinding.AggregatedObservable; import org.eclipse.papyrus.infra.tools.databinding.ReferenceCountedObservable; import org.eclipse.papyrus.infra.ui.emf.databinding.EMFObservableValue; import org.eclipse.papyrus.uml.tools.Activator; /** * An ObservableValue used to edit EObject properties through * Papyrus commands * * @author Camille Letavernier * @deprecated since 1.2.0 * Use the {@link org.eclipse.papyrus.infra.gmfdiag.common.databinding.GMFObservableValue} API, instead * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public class PapyrusObservableValue extends EMFObservableValue implements AggregatedObservable, CommandBasedObservableValue, ReferenceCountedObservable { private final ReferenceCountedObservable.Support refCount = new ReferenceCountedObservable.Support(this); /** * * Constructor. * * @param eObject * The EObject to edit * @param eStructuralFeature * The structural feature to edit * @param domain * The editing domain on which the commands will be executed
* * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.uml.tools.providers; import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; //TODO : To be refactored. Merge this class with UMLLabelProvider //should be removed in Papyrus 5.0 (see bug 540821) /** * @deprecated since 1.2.0 * @author VL222926 * */ @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName();
* * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.uml.tools.providers; import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; //TODO : To be refactored. Merge this class with UMLLabelProvider //should be removed in Papyrus 5.0 (see bug 540821) /** * @deprecated since 1.2.0 * @author VL222926 * */ @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName(); if (name == null) {
import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; //TODO : To be refactored. Merge this class with UMLLabelProvider //should be removed in Papyrus 5.0 (see bug 540821) @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; //$NON-NLS-1$ public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName(); if (name == null) { name = UNKNOWN_PROFILE; } if (ProfileUtil.isDirty(umlPackage, profile)) { name += TAG_PROFILE_CHANGED; } return name; } return super.getText(source);
long[] stack = new long[1]; stack[0] = 0; return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (call instanceof Long) ? (long) call : UNDEFINED_SYMBOL; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } /** * @param event */ private ICallStackElement getElement(ITmfEvent event) { // Find a root elements with the same PID Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(String.valueOf(name))) .findFirst();
} long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } private ICallStackElement getElement(ITmfEvent event) { // Find a root elements with the same PID Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(String.valueOf(name))) .findFirst(); Integer threadId = TmfTraceUtils.resolveIntEventAspectOfClassForEvent(event.getTrace(), LinuxTidAspect.class, event); int tid = (threadId == null) ? -1 : threadId;
* The event containing the cpu * * @return the CPU number (null for not set) */ public static @Nullable Integer getCpu(ITmfEvent event) { Integer cpuObj = TmfTraceUtils.resolveIntEventAspectOfClassForEvent(event.getTrace(), TmfCpuAspect.class, event); if (cpuObj == null) { /* We couldn't find any CPU information, ignore this event */ return null; } return cpuObj; } @Override public Map<String, Collection<Object>> getCallStack(ITmfEvent event) { Map<String, Collection<Object>> map = new HashMap<>(); ITmfEventField content = event.getContent(); ITmfEventField field = content.getField(KERNEL_CALLSTACK_FIELD); if (field != null) { map.put(KERNEL_STACK_NAME, getCallstack(field)); } field = content.getField(USER_CALLSTACK_FIELD); if (field != null) { map.put(USER_STACK_NAME, getCallstack(field)); } return map; } private static Collection<Object> getCallstack(ITmfEventField field) { Object value = field.getValue();
} long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } private ICallStackElement getElement(ITmfEvent event) { // Find a root elements with the same PID Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(String.valueOf(name))) .findFirst(); Integer threadId = TmfTraceUtils.resolveIntEventAspectOfClassForEvent(event.getTrace(), LinuxTidAspect.class, event); int tid = (threadId == null) ? -1 : threadId;
if (userCs == null) { userCs = Collections.emptyList(); } if (kernelCs.size() + userCs.size() == 0) { long[] stack = new long[1]; stack[0] = 0; return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (call instanceof Long) ? (long) call : UNDEFINED_SYMBOL; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } private ICallStackElement getElement(ITmfEvent event) { // Find a root elements with the same PID Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream()
// sufficient. //@formatter:off Optional<Resource> representationResource = Optional.ofNullable(resource) .map(rsr -> rsr.getResourceSet()) .filter(resourceSet -> !loadOnDemand || resourceSet.getURIConverter().exists(repResourceURI, new HashMap<>())) //@formatter:on .map(resourceSet -> { Resource res = null; try { res = resourceSet.getResource(repResourceURI, loadOnDemand); // CHECKSTYLE:OFF } catch (RuntimeException e) { // CHECKSTYLE:ON // an exception may occur if the segment part is malformed or if the resource does not // exists in case the representation is in its own resource. } return res; }); String repId = uri.get().fragment(); if (representationResource.isPresent() && repId != null) { // We look for the representation with the repId (retrieved from // the uri fragment) within the representation resource. return representationResource.get().getContents().stream().filter(DRepresentation.class::isInstance).map(DRepresentation.class::cast)
***************************************************************************** * Copyright (c) 2017, 2018 THALES GLOBAL SERVICES. * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *******************************************************************************/ package org.eclipse.sirius.business.internal.representation; import java.util.HashMap; import java.util.Optional; import org.eclipse.emf.common.util.URI; import org.eclipse.emf.ecore.resource.Resource; import org.eclipse.emf.ecore.util.ECrossReferenceAdapter; import org.eclipse.sirius.business.api.resource.ResourceDescriptor; import org.eclipse.sirius.viewpoint.DRepresentation; import org.eclipse.sirius.viewpoint.DRepresentationDescriptor; /** * This class is intended to manage the link between the {@link DRepresentationDescriptor} and its * {@link DRepresentation} through the {@link DRepresentationDescriptor#repPath} attribute. * * @author fbarbin * */ public class DRepresentationDescriptorToDRepresentationLinkManager {
} @Test public void testMirrorAcceptAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.ACCEPT, DifferenceState.MERGED); } @Test public void testMirrorRejectAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.REJECT, DifferenceState.DISCARDED); } private IEMFCompareConfiguration createConfiguration(boolean leftEditable, boolean rightEditable) { CompareConfiguration cc = new CompareConfiguration(); cc.setProperty(EMFCompareConfiguration.MIRRORED, Boolean.TRUE); cc.setLeftEditable(leftEditable); cc.setRightEditable(rightEditable); EMFCompareConfiguration emfCC = new EMFCompareConfiguration(cc); emfCC.setEditingDomain(editingDomain); return emfCC; } class MockMergeAction extends MergeAction { public MockMergeAction(IEMFCompareConfiguration compareConfiguration, Registry mergerRegistry, MergeMode mode, INavigatable navigatable) { super(compareConfiguration, mergerRegistry, mode, navigatable); } @Override public boolean updateSelection(IStructuredSelection selection) { return super.updateSelection(selection); } @Override protected void clearCache() { super.clearCache(); } @Override
public boolean isMirrored() { Object property = getProperty(EMFCompareConfiguration.MIRRORED); return property instanceof Boolean && ((Boolean)property).booleanValue();
public void propertyChange(PropertyChangeEvent event) { if (EMFCompareConfiguration.MIRRORED.equals(event.getProperty())) { Object newValue = event.getNewValue(); mirroredPropertyChanged(Boolean.TRUE.equals(newValue)); }
private String getCurrentValueFromViewer(MergeViewerSide side) { boolean isLeft = MergeViewerSide.LEFT == side; if (getCompareConfiguration().isMirrored()) { isLeft = MergeViewerSide.RIGHT == side; } final GetContentRunnable runnable = new GetContentRunnable(isLeft); Display.getDefault().syncExec(runnable); return (String)runnable.getResult();
} @Test public void testMirrorAcceptAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.ACCEPT, DifferenceState.MERGED); } @Test public void testMirrorRejectAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.REJECT, DifferenceState.DISCARDED); } private IEMFCompareConfiguration createConfiguration(boolean leftEditable, boolean rightEditable) { CompareConfiguration cc = new CompareConfiguration(); cc.setProperty(EMFCompareConfiguration.MIRRORED, Boolean.TRUE); cc.setLeftEditable(leftEditable); cc.setRightEditable(rightEditable); EMFCompareConfiguration emfCC = new EMFCompareConfiguration(cc); emfCC.setEditingDomain(editingDomain); return emfCC; } class MockMergeAction extends MergeAction { public MockMergeAction(IEMFCompareConfiguration compareConfiguration, Registry mergerRegistry, MergeMode mode, INavigatable navigatable) { super(compareConfiguration, mergerRegistry, mode, navigatable); } @Override public boolean updateSelection(IStructuredSelection selection) { return super.updateSelection(selection); } @Override protected void clearCache() { super.clearCache(); } @Override
try { int length = string.length(); if (length == 0) return; boolean mode = true; switch (data.textAntialias) { case SWT.DEFAULT: /* Printer is off by default */ if (!handle.isDrawingToScreen()) mode = false; break; case SWT.OFF: mode = false; break; case SWT.ON: mode = true; break; } handle.saveGraphicsState(); handle.setShouldAntialias(mode); if (length == 1 && (flags & SWT.DRAW_TRANSPARENT) != 0) { doFastDrawText(string, x, y); } else { doDrawText(string, x, y, flags); } handle.restoreGraphicsState(); } finally { uncheckGC(pool); }
} } @Override public void close() { try { ch.close(); } catch (IOException e) { // Ignore read close failures. } } private static final class LazyReadableChannel implements ReadableChannel { private final DfsReader ctx; private final DfsReftable file; private ReadableChannel ch; LazyReadableChannel(DfsReftable file, DfsReader ctx) { this.file = file; this.ctx = ctx; } private ReadableChannel channel() throws IOException { if (ch == null) { ch = ctx.db.openFile(file.desc, file.ext); } return ch; } @Override public int blockSize() { try { return open().blockSize(); } catch (IOException e) { return -1; } } @Override public long position() throws IOException { return open().position(); } @Override public void position(long newPosition) throws IOException { open().position(newPosition); } @Override public void setReadAheadBytes(int bufferSize) throws IOException {
***************************************************************************** * Copyright (c) 2016 Frank Becker and others. * * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v. 2.0 which is available at * https://www.eclipse.org/legal/epl-2.0 * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Frank Becker - initial API and implementation *******************************************************************************/ package org.eclipse.mylyn.bugzilla.rest.core.tests; import java.util.List; import org.eclipse.mylyn.commons.sdk.util.CommonTestUtil; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite.SuiteClassProvider; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite.TestConfigurationProperty; import org.eclipse.mylyn.commons.sdk.util.TestConfiguration; import org.junit.runner.RunWith; import org.junit.runners.Suite; @RunWith(ManagedSuite.class) @Suite.SuiteClasses({ RepositoryKeyTest.class, BugzillaRestFlagMapperTest.class, BugzillaRestConnectorNoFixtureTest.class }) @TestConfigurationProperty() public class AllBugzillaRestCoreTests { static { if (CommonTestUtil.fixProxyConfiguration()) {
assertTrue(new File(d, "logs/refs/heads").isDirectory()); assertFalse(new File(d, "logs/HEAD").exists()); assertEquals(0, new File(d, "logs/refs/heads").list().length); assertEquals("ref: refs/heads/master\n", read(new File(d, HEAD))); } @Test(expected = UnsupportedOperationException.class) public void testVersioningNotImplemented_exactRef() throws IOException { assertFalse(refdir.hasVersioning()); Ref ref = refdir.exactRef(HEAD); assertNotNull(ref); ref.getUpdateIndex(); // Not implemented on FS } @Test public void testVersioningNotImplemented_getRefs() throws Exception { assertFalse(refdir.hasVersioning()); RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref: refs) { try { ref.getUpdateIndex(); fail("FS doesn't implement ref versioning"); } catch (UnsupportedOperationException e) { // ok } } } @Test
public void testVersioningNotImplemented_exactRef() throws IOException { assertFalse(refdir.hasVersioning()); Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getUpdateIndex(); // Not implemented on FS } @Test public void testVersioningNotImplemented_getRefs() throws Exception { assertFalse(refdir.hasVersioning()); RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref : refs) { try { ref.getUpdateIndex(); fail("FS doesn't implement ref versioning"); } catch (UnsupportedOperationException e) { // ok } } } @Test public void testGetRefs_EmptyDatabase() throws IOException { Map<String, Ref> all; all = refdir.getRefs(RefDatabase.ALL); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_HEADS); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_TAGS); assertTrue("no references", all.isEmpty()); }
return ref; } Ref dst = ref.getTarget(); if (MAX_SYMBOLIC_REF_DEPTH <= depth) { return null; // claim it doesn't exist } dst = exactRef(dst.getName()); if (dst == null) { return ref; } dst = resolve(dst, depth + 1); if (dst == null) { return null; // claim it doesn't exist } return new SymbolicRef(ref.getName(), dst, ref.getUpdateIndex()); } /** {@inheritDoc} */ @Override public abstract void close() throws IOException; }
} /** * Get namespace used by bootstrap layer. * * @return namespace used by bootstrap layer, e.g. {@code refs/txn/}. Always * ends in {@code '/'}. */ @Nullable public String getTxnNamespace() { return txnNamespace; } /** {@inheritDoc} */ @Override public void create() throws IOException { bootstrap.create(); } /** {@inheritDoc} */ @Override public boolean performsAtomicTransactions() { return true; } /** {@inheritDoc} */ @Override public void refresh() { bootstrap.refresh(); } /** {@inheritDoc} */ @Override public void close() { refs = null; bootstrap.close(); } /** {@inheritDoc} */ @Override public Ref getRef(String name) throws IOException { String[] needle = new String[SEARCH_PATH.length];
* LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */ package org.eclipse.jgit.lib; import org.eclipse.jgit.annotations.NonNull; import org.eclipse.jgit.annotations.Nullable; /** * Pairing of a name and the {@link org.eclipse.jgit.lib.ObjectId} it currently * has. * <p> * A ref in Git is (more or less) a variable that holds a single object * identifier. The object identifier can be any valid Git object (blob, tree, * commit, annotated tag, ...). * <p> * The ref name has the attributes of the ref that was asked for as well as the * ref it was resolved to for symbolic refs plus the object id it points to and
/** * Indicator of the relative order between updates of a specific reference * name. * <p> * A number that increases when a reference is updated. Implementations * define its value (e.g. version counter or timestamp). * <p> * By default this throws an {@link UnsupportedOperationException}. The * instantiator of the Ref must override this method (e.g. by using the * {@code VersionedRef} decorator) if it can provide a version value. * * @return the version of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } }
/** * Initialize a new reference database at this location. * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on * update. * * @return true whether the implementation assigns update indices to * references. * @since 5.3 */ public abstract boolean hasVersioning(); /** * Determine if a proposed reference name overlaps with an existing one. * <p> * Reference names use '/' as a component separator, and may be stored in a * hierarchical storage such as a directory on the local filesystem. * <p> * If the reference "refs/heads/foo" exists then "refs/heads/foo/bar" must
/** * Initialize a new reference database at this location. * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on * update. * * @return true whether the implementation assigns update indices to * references. * @since 5.3 */ public abstract boolean hasVersioning(); /** * Determine if a proposed reference name overlaps with an existing one. * <p> * Reference names use '/' as a component separator, and may be stored in a * hierarchical storage such as a directory on the local filesystem. * <p> * If the reference "refs/heads/foo" exists then "refs/heads/foo/bar" must
return false; } else if (!block.next()) { long pos = block.endPosition(); if (pos >= scanEnd) { return false; } block = readBlock(pos, scanEnd); continue; } block.parseKey(); if (match != null && !block.match(match, prefix)) { block.skipValue(); return false; } ref = block.readRef(minUpdateIndex + block.readUpdateIndexDelta()); if (!includeDeletes && wasDeleted()) { continue; } return true; } } @Override public Ref getRef() { return ref; } @Override public void close() { // Do nothing. } } private class LogCursorImpl extends LogCursor { private final long scanEnd; private final byte[] match; private String refName; private long updateIndex; private ReflogEntry entry; BlockReader block; LogCursorImpl(long scanEnd, byte[] match) { this.scanEnd = scanEnd; this.match = match;
} else if (!block.next()) { long pos; if (blockPos != null) { if (listIdx >= blockPos.size()) { return false; } pos = blockPos.get(listIdx++); } else { pos = block.endPosition(); } if (pos >= scanEnd) { return false; } block = readBlock(pos, scanEnd); continue; } block.parseKey(); ref = block .readRef(minUpdateIndex + block.readUpdateIndexDelta()); ObjectId id = ref.getObjectId(); if (id != null && match.equals(id) && (includeDeletes || !wasDeleted())) { return true; } } } @Override public Ref getRef() { return ref; } @Override public void close() { // Do nothing. } } }
* name. A number that increases when a reference is updated. * * In case of symbolic references, the update index refers to the update of * the symbolic reference iself (e.g. if HEAD points to master, the HEAD * update index will only increase when HEAD changes, regarless how many * times master is updated). * * Should not be used unless the {@code RefDatabase} that instantiated the * ref supports versioning (see {@link RefDatabase#hasVersioning()} * * @return the update index (i.e. version) of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } }
protected Object createElementViewerInput() { List<TracePackageTraceElement> traceElements = new ArrayList<>(); for (TmfTraceElement tmfTraceElement : fSelectedTraces) { TracePackageTraceElement traceElement = new TracePackageTraceElement(null, tmfTraceElement); // Trace files TracePackageFilesElement filesElement = new TracePackageFilesElement(traceElement, tmfTraceElement.getResource()); filesElement.setChecked(true); children.add(filesElement); // Supplementary files try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) {
filesElement.setChecked(true); children.add(filesElement); // Supplementary files try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); new TracePackageSupplFileElement(res, name, suppFilesElement); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString();
// Supplementary files try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); new TracePackageSupplFileElement(res, name, suppFilesElement); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); }
try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); new TracePackageSupplFileElement(res, name, suppFilesElement); } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) {
TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) { // Should not happen Activator.getDefault().logError("Error finding supplementary files", e); //$NON-NLS-1$ } // Bookmarks IFile bookmarksFile = tmfTraceElement.getBookmarksFile();
import java.io.ByteArrayOutputStream; import java.io.IOException; import java.util.ArrayList; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import org.eclipse.jgit.internal.storage.io.BlockSource; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectIdRef; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefComparator; import org.eclipse.jgit.lib.SymbolicRef; import org.junit.Test; public class MergedReftableTest { @Test public void noTables() throws IOException { MergedReftable mr = merge(new byte[0][]); try (RefCursor rc = mr.allRefs()) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRef(HEAD)) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRefsWithPrefix(R_HEADS)) { assertFalse(rc.next()); } } @Test public void oneEmptyTable() throws IOException { MergedReftable mr = merge(write());
/** * Initialize a new reference database at this location. * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on * update. * <p> * @implSpec This method returns false by default. Implementations * supporting versioning must override it to return true. * @return true if the implementation assigns update indices to references. * @since 5.3 */ public abstract boolean hasVersioning(); /** * Determine if a proposed reference name overlaps with an existing one. * <p> * Reference names use '/' as a component separator, and may be stored in a * hierarchical storage such as a directory on the local filesystem. * <p> * If the reference "refs/heads/foo" exists then "refs/heads/foo/bar" must
* * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on * update. * * @return true whether the implementation assigns update indices to * references. * @since 5.3 */ public boolean hasVersioning() { return false; } /** * Determine if a proposed reference name overlaps with an existing one. * <p> * Reference names use '/' as a component separator, and may be stored in a * hierarchical storage such as a directory on the local filesystem. * <p> * If the reference "refs/heads/foo" exists then "refs/heads/foo/bar" must * not exist, as a reference cannot have a value and also be a container for * other references at the same time.
* * With symbolic references, the update index refers to updates of the * symbolic reference itself. For example, if HEAD points to * refs/heads/master, then the update index for exactRef("HEAD") will only * increase when HEAD changes to point to another ref, regardless of how * many times refs/heads/master is updated. * * Should not be used unless the {@code RefDatabase} that instantiated the * ref supports versioning (see {@link RefDatabase#hasVersioning()}) * * @return the update index (i.e. version) of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } }
* references. */ public static final String ALL = "";//$NON-NLS-1$ /** * Initialize a new reference database at this location. * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on * update. See {@link Ref#getUpdateIndex()}. * * @implSpec This method returns false by default. Implementations * supporting versioning must override it to return true. * @return true if the implementation assigns update indices to references. * @since 5.3 */ public boolean hasVersioning() { return false; } /** * Determine if a proposed reference name overlaps with an existing one. * <p> * Reference names use '/' as a component separator, and may be stored in a
*/ boolean isPeeled(); /** * How was this ref obtained? * <p> * The current storage model of a Ref may influence how the ref must be * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of a specific reference * name. A number that increases when a reference is updated. * <p> * With symbolic references, the update index refers to updates of the * symbolic reference itself. For example, if HEAD points to * refs/heads/master, then the update index for exactRef("HEAD") will only * increase when HEAD changes to point to another ref, regardless of how * many times refs/heads/master is updated. * * Should not be used unless the {@code RefDatabase} that instantiated the * ref supports versioning (see {@link RefDatabase#hasVersioning()}) *
***************************************************************************** * Copyright (c) 2009, 2018 THALES GLOBAL SERVICES and others. * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *******************************************************************************/ package org.eclipse.sirius.ui.tools.internal.actions.export; import java.util.Collection; import java.util.Iterator; import java.util.LinkedHashSet; import java.util.Set; import java.util.stream.Collectors; import org.eclipse.emf.ecore.EObject; import org.eclipse.sirius.business.api.dialect.DialectManager; import org.eclipse.sirius.business.api.query.DRepresentationDescriptorQuery; import org.eclipse.sirius.business.api.session.Session; import org.eclipse.sirius.ui.business.api.dialect.DialectUIManager; import org.eclipse.sirius.ui.business.api.dialect.ExportFormat; import org.eclipse.sirius.ui.business.api.dialect.ExportFormat.ExportDocumentFormat; import org.eclipse.sirius.viewpoint.DRepresentationDescriptor; import org.eclipse.sirius.viewpoint.provider.Messages;
public void run() { Collection<DRepresentationDescriptor> repDescriptorsToExport = getRepresentationToExport().stream().filter(Objects::nonNull).collect(Collectors.toList()); // keep only the DRepresentationDescriptor which DRepresentation is not null repDescriptorsToExport = repDescriptorsToExport.stream().filter(repDesc -> repDesc.getRepresentation() != null).collect(Collectors.toList()); if (!repDescriptorsToExport.isEmpty()) { DRepresentationDescriptor firstDRepDescriptorToExport = repDescriptorsToExport.iterator().next(); // Make sure the representation is loaded firstDRepDescriptorToExport.getRepresentation(); Session session = getSession(firstDRepDescriptorToExport); if (session != null) { IPath exportPath = getExportPath(firstDRepDescriptorToExport, session); if (exportPath != null) { exportRepresentation(exportPath, repDescriptorsToExport, session); } } } else { MessageDialog.openInformation(Display.getCurrent().getActiveShell(), Messages.ExportRepresentationsAction_noRepresentationsDialog_title, Messages.ExportRepresentationsAction_noRepresentationsDialog_message); }
* * @param name * the name of the reference. May be a short name which must be * searched for using the standard {@link #SEARCH_PATH}. * @return the reference (if it exists); else {@code null}. * @throws IOException * the reference space cannot be accessed. * @deprecated Use {@link #findRef(String)} instead. */ @Deprecated @Nullable public final Ref getRef(String name) throws IOException { return findRef(name); } /** * Read a single reference. * <p> * Aside from taking advantage of {@link #SEARCH_PATH}, this method may be * able to more quickly resolve a single reference name than obtaining the * complete namespace by {@code getRefs(ALL).get(name)}. * <p> * To read a specific reference without using @{link #SEARCH_PATH}, see * {@link #exactRef(String)}. * * @param name * the name of the reference. May be a short name which must be
public static FirstCommand fromLine(String line) { int nul = line.indexOf('\0'); if (nul < 0) { return new FirstCommand(line, emptySet()); } Set<String> opts = asList(line.substring(nul + 1).split(" ")) //$NON-NLS-1$ .stream() .collect(toSet()); return new FirstCommand(line.substring(0, nul), unmodifiableSet(opts));
protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); // look for files or folders with the given path IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (!"jar".equalsIgnoreCase(path.getFileExtension())) { //$NON-NLS-1$ IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } } return null;
protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); } IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (getType() != ARCHIVE) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } } return null;
IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); // look for files or folders with the given path IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (getType() != ARCHIVE) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); } if (getType() != ARCHIVE) { @SuppressWarnings("deprecation") IContainer[] containers = root.findContainersForLocation(path); if (containers.length > 0) { return containers[0]; } } } return null;
} } static int read(ReadableChannel rc, ByteBuffer buf) throws IOException { int n; do { n = rc.read(buf); } while (0 < n && buf.hasRemaining()); return buf.position(); } static long elapsedMicros(long start) { return (System.nanoTime() - start) / 1000L; } /** * A supplier of readable channel that opens the channel lazily. */ private static class LazyChannel implements AutoCloseable, DfsBlockCache.ReadableChannelSupplier { private final DfsReader ctx; private final DfsPackDescription desc; private final PackExt ext; LazyChannel(DfsReader ctx) { this.ctx = ctx; } @Override public ReadableChannel get() throws IOException { if (rc == null) { synchronized (this) { if (rc == null) { rc = ctx.db.openFile(desc, ext); } } } return rc; } @Override public void close() throws IOException { if (rc != null) { rc.close(); } } } }
import org.eclipse.osgi.util.NLS; final public class ChecksumVerifier extends MessageDigestProcessingStep { private String expectedChecksum; final private String algorithmName; final private String algorithmId; // public to access from tests public ChecksumVerifier(String digestAlgorithm, String algorithmId) { this.algorithmName = digestAlgorithm; this.algorithmId = algorithmId; basicInitialize(null); } @Override public final void initialize(IProvisioningAgent agent, IProcessingStepDescriptor descriptor, IArtifactDescriptor context) { super.initialize(agent, descriptor, context); basicInitialize(descriptor); if (!getStatus().isOK()) { return; } String data = descriptor.getData(); if (IArtifactDescriptor.DOWNLOAD_CHECKSUM.concat(".").concat(algorithmId).equals(data)) //$NON-NLS-1$ expectedChecksum = ChecksumHelper.getChecksums(context, IArtifactDescriptor.DOWNLOAD_CHECKSUM).get(algorithmId); else if (IArtifactDescriptor.ARTIFACT_CHECKSUM.concat(".").concat(algorithmId).equals(data)) //$NON-NLS-1$ expectedChecksum = ChecksumHelper.getChecksums(context, IArtifactDescriptor.ARTIFACT_CHECKSUM).get(algorithmId); else expectedChecksum = data; if (ofNullable(expectedChecksum).orElse("").isEmpty()) { //$NON-NLS-1$
private static String selectionToString(Table table) { StringBuilder builder = new StringBuilder(); for (TableItem tableItem : table.getSelection()) { if (buffer.length() > 0) { buffer.append(System.lineSeparator()); } for (int column = 0; column < table.getColumnCount(); column++) { if (column > 0) { buffer.append('\t'); } buffer.append(tableItem.getText(column)); } } return buffer.toString();
sessionId.toAPI(), userId.toAPI()); authorizationService.checkProjectAdminAccess( sessionId.toAPI(), null, ESProjectAdminPrivileges.DeleteOrgUnit); ACUser userToDelete = null; for (final Iterator<ACUser> iter = getUsers().iterator(); iter.hasNext();) { final ACUser user = iter.next(); /* check if we were created by the deleted user */ if (user.getCreatedBy() != null && user.getCreatedBy().equals(userId.getId())) { user.setCreatedBy(null); } /* check if we are the deleted user */ if (user.getId().equals(userId)) { userToDelete = user; } } for (final ACGroup group : getGroups()) { if (group.getCreatedBy() != null && group.getCreatedBy().equals(userId.getId())) { group.setCreatedBy(null); save(); } } /* perform deletion */ if (userToDelete != null) { final List<ACGroup> groups = getGroups(sessionId, userId);
if (user.getCreatedBy() != null && user.getCreatedBy().equals(userId.getId())) { user.setCreatedBy(null); save(); } /* check if we are the deleted user */ if (user.getId().equals(userId)) { userToDelete = user; } } for (final ACGroup group : getGroups()) { if (group.getCreatedBy() != null && group.getCreatedBy().equals(userId.getId())) { group.setCreatedBy(null); } } /* perform deletion */ if (userToDelete != null) { final List<ACGroup> groups = getGroups(sessionId, userId); for (final ACGroup acGroup : groups) { removeMember(sessionId, acGroup.getId(), userId); } getAccessControl().getOrgUnitProviderService().removeUser(userToDelete.toAPI()); // TODO: move ecore delete into ServerSpace#deleteUser implementation EcoreUtil.delete(userToDelete); save(); } } /** * {@inheritDoc} */
/* act */ adminBroker2.deleteUser(createdUser1.getId()); /* assert */ assertEquals(initialSize - 1, adminBroker.getUsers().size()); assertNull(findUser(USER_NAME_2).getCreatedBy()); } private ACUser findUser(String name) throws ESException { ACUser result = null; for (final ACUser user : adminBroker.getUsers()) { if (user.getName().equals(name)) { return user; } } return result; } private ACGroup findGroup(String name) throws ESException { ACGroup result = null; for (final ACGroup group : adminBroker.getGroups()) { if (group.getName().equals(name)) { result = group; } } return result; } @Test(expected = AccessControlException.class) public void testLoginOfCreatedUserWithNoPasswordSet() throws ESException { adminBroker.createUser(USER_NAME); ACUser user = null; for (final ACUser u : adminBroker.getUsers()) { if (u.getName().equals(USER_NAME)) { user = u; } }
throw new StorageException(StorageException.NOSAVE, e); } } private void checkForNulls(Object... objects) throws InvalidInputException { for (final Object obj : objects) { if (obj == null) { throw new InvalidInputException(); } } } private <T extends ACOrgUnit<?>> List<T> removeInvisibleOrgUnits(List<T> orgUnits, ESSessionId sessionId) throws AccessControlException { /* * regular users can't see any orgunits, while server admins can see all of them. Only project admins have * reduced visibility. */ final ESOrgUnitId adminId = getAccessControl().getSessions().resolveToOrgUnitId(sessionId); final Optional<ACOrgUnit<?>> orgUnit = ACHelper.getOrgUnit( getAccessControl().getOrgUnitProviderService(), adminId); if (!orgUnit.isPresent()) { return orgUnits; } final List<Role> allRolesOfAdmin = ACHelper.getAllRoles( getAccessControl().getOrgUnitResolverServive(), orgUnit.get()); if (Iterables.any(allRolesOfAdmin, new HasRolePredicate(ServerAdmin.class))) { return orgUnits; }
***************************************************************************** * Copyright (c) 2011-2014 EclipseSource Muenchen GmbH and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Johannes Faltermeier - initial API and implementation ******************************************************************************/ package org.eclipse.emf.emfstore.server.accesscontrol.test; import static org.eclipse.emf.emfstore.client.test.common.util.ProjectUtil.share; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertTrue; import static org.junit.Assert.fail; import java.util.Arrays; import java.util.LinkedHashSet; import java.util.List; import java.util.Set; import org.eclipse.emf.emfstore.client.ESUsersession; import org.eclipse.emf.emfstore.client.test.common.dsl.Roles; import org.eclipse.emf.emfstore.client.test.common.util.ServerUtil; import org.eclipse.emf.emfstore.internal.server.model.accesscontrol.ACGroup; import org.eclipse.emf.emfstore.internal.server.model.accesscontrol.ACOrgUnit;
getAdminBroker().addMember(group, otherGroup); getAdminBroker().addMember(otherGroup, newUser); ProjectUtil.share(getUsersession(), getLocalProject()); final ProjectSpace clonedProjectSpace = cloneProjectSpace(getProjectSpace()); ProjectUtil.share(getSuperUsersession(), clonedProjectSpace.toAPI()); getSuperAdminBroker().changeRole(getProjectSpace().getProjectId(), group, Roles.writer()); final int oldSize = getSuperAdminBroker().getGroups().size(); getAdminBroker().deleteGroup(group); assertEquals(oldSize - 1, getAdminBroker().getGroups().size()); } /** * @throws ESException */ @Test public void deleteUser() throws ESException { makeUserPA(); final ACOrgUnitId newUser = ServerUtil.createUser(getSuperUsersession(), getNewUsername()); final ACOrgUnitId group = ServerUtil.createGroup(getSuperUsersession(), getNewGroupName()); final ACOrgUnitId otherGroup = ServerUtil.createGroup(getSuperUsersession(), getNewOtherGroupName());
import org.junit.runners.Parameterized.Parameters; import org.mockito.ArgumentCaptor; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @RunWith(ParameterizedPlatformTestRunner.class) public class JmsMomImplementorTest { private static final Logger LOG = LoggerFactory.getLogger(JmsMomImplementorTest.class); @ClassRule public static final ArtemisJmsBrokerTestRule ARTEMIS_RULE = new ArtemisJmsBrokerTestRule(); private IBean<? extends JmsTestMom> m_momBean; private IBean<? extends IJmsMessageHandler> m_messageHandlerBean; private List<IDisposable> m_disposables; private String m_testJobExecutionHint; @Rule public TestName m_testName = new TestName(); public long m_t0; private static final AtomicInteger MOM_COUNTER = new AtomicInteger(0); @Parameters public static List<IScoutTestParameter> getParameters() { List<IScoutTestParameter> parametersList = new LinkedList<IScoutTestParameter>(); // We do not need jmx for unit testing. Also we must disable watchTopicAdvisories else some concurrent issues with broker recreation will happen
try { Jobs.getJobManager().awaitDone(testJobsFilter, 10, TimeUnit.SECONDS); LOG.info("All jobs have finished after {} ms", StringUtility.formatNanos(System.nanoTime() - t0)); } catch (TimedOutError e) { LOG.warn("Some cancelled jobs are still running after {} ms! Please check their implementation.", StringUtility.formatNanos(System.nanoTime() - t0)); } } uninstallTestMessagehandler(); uninstallTestMom(); // ensure activeMQ is stopped BrokerService brokerService = BrokerRegistry.getInstance().findFirst(); if (brokerService != null) { brokerService.stop(); brokerService.waitUntilStopped(); } LOG.info("Finished test in {} ms", StringUtility.formatNanos(System.nanoTime() - m_t0)); LOG.info("</{}>", m_testName.getMethodName()); } @Test @NonParameterized public void testInstanceScoped() { JmsMomImplementor mom1 = BEANS.get(JmsMomImplementor.class);
} })); // Initiate 'request-reply' communication final String request = "hello world"; String testee = MOM.request(JmsTestMom.class, queue, request); // Verify final String expectedReply = "HELLO WORLD"; assertEquals(expectedReply, testee); IMarshaller marshaller = BEANS.get(CONFIG.getPropertyValue(DefaultMarshallerProperty.class)); verifyRequestReplyMessageLogger(queue, marshaller, request, expectedReply); } protected static <DTO> void verifyRequestReplyMessageHandler(IDestination<DTO> expectedDestination, IMarshaller marshaller, DTO expectedRequest, DTO expectedReply) { verify(BEANS.get(IJmsMessageHandler.class), times(2)).handleOutgoing(any(), any(), any()); verifyMessageLoggerHandleOutgoingCalled(expectedDestination, marshaller, expectedRequest); verifyMessageLoggerHandleOutgoingCalled(null, marshaller, expectedReply); // "reply" message is sent only with JMS destination (but without a Scout MOM destination) verify(BEANS.get(IJmsMessageHandler.class), times(2)).handleIncoming(eq(expectedDestination), any(), any()); verifyMessageLoggerHandleIncomingCalled(expectedDestination, marshaller, expectedRequest, expectedReply); }
* @param properties * the MOM environment properties provided to the JMS implementor * @see org.eclipse.scout.rt.mom.api.IMomImplementor.init(Map<Object, Object>) */ void init(Map<Object, Object> properties); /** * Handles JMS messages consumed by a {@link javax.jms.MessageConsumer}. * <p> * This method is called directly after a JMS message has been received. * <p> * The message has not yet been processed (unmarshalled) by the MOM framework. */ void handleIncoming(IDestination<?> destination, Message message, IMarshaller marshaller); /** * Handles JMS messages being sent by a {@link javax.jms.MessageProducer}. * <p> * This method is called directly before a JMS message is "sent" by the <i>MessageProducer</i>. "Sent" means that the * <i>send</i> method of the message producer is called. Therefore it is not guaranteed that the time, at which this
* <p> * This method is called directly before a JMS message is "sent" by the <i>MessageProducer</i>. "Sent" means that the * <i>send</i> method of the message producer is called. Therefore it is not guaranteed that the time, at which this * method is called, is the <i>sent time</i> of the JMS message (e.g. in a transactional context). * <p> * The message has already been processed (marshalled) by the MOM framework. * * @param destination * the MOM destination this message is being sent to. <b>Attention:</b> This might be <code>null</code> in * case of a 'request-reply' communication, where the reply message is only sent back through the JMS * destination defined by {@link Message#getJMSReplyTo()} (and not through a MOM destination) */ void handleOutgoing(IDestination<?> destination, Message message, IMarshaller marshaller); }
*/ protected Message createMessage(final int messageType, final Session session) throws JMSException { switch (messageType) { case MESSAGE_TYPE_TEXT: return session.createTextMessage(); case MESSAGE_TYPE_BYTES: return session.createBytesMessage(); case MESSAGE_TYPE_NO_PAYLOAD: return session.createMessage(); default: throw new PlatformException("Unsupported message type '{}'", messageType); } } /** * @return the writer's {@link IMarshaller} used to transform the transfer object (never <code>null</code>). */ public IMarshaller getMarshaller() { return m_marshaller; } /** * Writes the given transfer object, and uses the writer's {@link IMarshaller} to transform the object into its * transport type. * * @see JmsMessageReader#readTransferObject() */ public JmsMessageWriter writeTransferObject(final Object transferObject) throws JMSException { final Object transportObject = m_marshaller.marshall(transferObject, m_marshallerContext); m_marshallerContext.put(CTX_PROP_NULL_OBJECT, Boolean.valueOf(transferObject == null).toString());
* Writes the given {@link Map} as message properties. * * @see JmsMessageReader#readContext(String) */ protected JmsMessageWriter writeContext(final String property, final Map<String, String> context) throws JMSException { if (context.isEmpty()) { return this; } final String json = (String) BEANS.get(JsonMarshaller.class).marshall(context, new HashMap<>()); writeProperty(property, json); return this; } /** * Finish writing and get the message. * <p> * If the message is a {@link javax.jms.BytesMessage}, the message body is put in read-only mode and repositions the * stream of bytes to the beginning. * * @return the JMS message in read-only mode * @see BytesMessage#reset() */ public Message build() throws JMSException { writeContext(JMS_PROP_MARSHALLER_CONTEXT, m_marshallerContext); if (m_message instanceof BytesMessage) { ((BytesMessage) m_message).reset(); } return m_message; } /**
} /** * @return the identifier to name the {@link Connection}. */ protected String computeClientId(final Map<Object, Object> properties) { final String clientId = ObjectUtility.toString(properties.get(JMS_CLIENT_ID)); if (clientId != null) { return clientId; } final String nodeId = BEANS.get(NodeIdentifier.class).get(); return StringUtility.join(" ", m_symbolicName, StringUtility.box("(", nodeId, ")")); } /** * @return the associated {@link IJmsMessageHandler} for this JMS MOM implementor. It is never <code>null</code>. */ public IJmsMessageHandler getMessageHandler() { return m_messageHandler; } /** * Exception Handler used in MOM. */ public static class MomExceptionHandler extends ExceptionHandler { } }
public class BundleWriterTest extends SampleDataRepositoryTestCase { @Rule public ExpectedException thrown = ExpectedException.none(); @Test public void testEmptyBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, new byte[0]); } @Test public void testNonBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, "Not a bundle file".getBytes(UTF_8)); } @Test public void testGarbageBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, (TransportBundle.V2_BUNDLE_SIGNATURE + '\n' + "Garbage") .getBytes(StandardCharsets.UTF_8)); } @Test public void testWriteSingleRef() throws Exception { // Create a tiny bundle, (well one of) the first commits only final byte[] bundle = makeBundle("refs/heads/firstcommit",
* key is not specified) * @param credentialsProvider * provider to use when querying for signing key credentials (eg. * passphrase) * @throws CanceledException * when signing was canceled (eg., user aborted when entering * passphrase) */ public abstract void sign(@NonNull CommitBuilder commit, String gpgSigningKey, @NonNull PersonIdent committer, CredentialsProvider credentialsProvider) throws CanceledException; /** * Indicates if a signing key is available for the specified committer * and/or signing key. * * @param gpgSigningKey * the signing key (passed as is to the GPG signing tool) * @param committer * the signing identity (to help with key lookup in case signing * key is not specified) * @param credentialsProvider * provider to use when querying for signing key credentials (eg. * passphrase) * @return <code>true</code> if a signing key is available, * <code>false</code> otherwise * @throws CanceledException
* passphrase) * @throws CanceledException * when signing was canceled (eg., user aborted when entering * passphrase) */ public abstract void sign(@NonNull CommitBuilder commit, String gpgSigningKey, @NonNull PersonIdent committer, CredentialsProvider credentialsProvider) throws CanceledException; /** * Indicates is a signing key is available for the specified committer * and/or signing key. * * @param gpgSigningKey * the signing key to locate (passed as is to the GPG signing * tool as is; eg., value of <code>user.signingkey</code>) * @param committer * the signing identity (to help with key lookup in case signing * key is not specified) * @param credentialsProvider * provider to use when querying for signing key credentials (eg. * passphrase) * @return <code>true</code> if a signing key is available, * <code>false</code> otherwise * @throws CanceledException * when signing was canceled (eg., user aborted when entering * passphrase) */ public abstract boolean canLocateSigningKey(String gpgSigningKey,
protected void doSetValue(Object value) { // value = dataType instance super.doSetValue(value); // TODO : real type of the value ? type compatibility ?
* * @author dlecan */ public class RevealElementsAction extends AbstractRevealElementsAction<Object> { /** * Constructor. */ public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } /** * Constructor. * * @param text the label */ public RevealElementsAction(final String text) { super(text); } /** * Tests whether this action should be active. The action is active if the given {@link IDiagramElementEditPart} is * hidden. * * @param selectedElement * The current selection * @return true if all selected element is hidden hidden. */ public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection
/** * Constructor. */ public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } /** * Constructor. * * @param text the label */ public RevealElementsAction(final String text) { super(text); } /** * Tests whether the given {@link IDiagramElementEditPart} is hidden. * * @param selectedElement * The current selection * @return true if the selected element is hidden. */ public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden. */
/** * Constructor. */ public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } /** * Constructor. * * @param text the label */ public RevealElementsAction(final String text) { super(text); } /** * Tests whether the given {@link IDiagramElementEditPart} is hidden. * * @param selectedElement * The current selection * @return true if the selected element is hidden. */ public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden. */
/** * Constructor. */ public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } /** * Constructor. * * @param text the label */ public RevealElementsAction(final String text) { super(text); } /** * Tests whether the given {@link IDiagramElementEditPart} is hidden. * * @param selectedElement * The current selection * @return true if the selected element is hidden. */ public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden. */
* * @param selectedElement * The current selection * @return true if all selected element is hidden hidden. */ public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether this action should be active. The action is active if the the given selection contains only hidden * diagram graphical element. * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden. */ public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next);
public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection * @return true if all selected elements are hidden. */ public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); } else { result = false; } } return result; } /** * {@inheritDoc} */ @Override
public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection * @return true if all selected elements are hidden. */ public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); } else { result = false; } } return result; } /** * {@inheritDoc} */ @Override
public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object selectedElement = iterator.next(); if (selectedElement instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) selectedElement); } else { result = false; } } return result;
if (vpe instanceof DDiagramElement && this.selection instanceof DiagramOutlinePage.TreeSelectionWrapper) { final DiagramOutlinePage.TreeSelectionWrapper wrapper = (DiagramOutlinePage.TreeSelectionWrapper) this.selection; final RootEditPart root = wrapper.getRoot(); final DDiagramEditor diagramEditor = (DDiagramEditor) wrapper.getViewer().getProperty(DDiagramEditor.EDITOR_ID); runRevealCommand(root, diagramEditor, (DDiagramElement) vpe); } else if (vpe instanceof IDiagramElementEditPart) { Optional<DDiagramElement> optionalDiagramElement = Optional.of((IGraphicalEditPart) vpe).map(IGraphicalEditPart::resolveSemanticElement).filter(DDiagramElement.class::isInstance) .map(DDiagramElement.class::cast); if (optional.isPresent()) { IDiagramElementEditPart diagramElementEditPart = (IDiagramElementEditPart) vpe; SelectionRequest request = new SelectionRequest(); request.setType(RequestConstants.REQ_OPEN); diagramElementEditPart.performRequest(request); } }
private void runRevealCommand(final RootEditPart root, final DDiagramEditor editor, final DDiagramElement vpe) { final Object adapter = editor.getAdapter(IDiagramCommandFactoryProvider.class); final IDiagramCommandFactoryProvider cmdFactoryProvider = (IDiagramCommandFactoryProvider) adapter; final TransactionalEditingDomain transactionalEditingDomain = TransactionUtil.getEditingDomain(editor.getEditingDomain().getResourceSet()); final IDiagramCommandFactory emfCommandFactory = cmdFactoryProvider.getCommandFactory(transactionalEditingDomain); final Command cmd = emfCommandFactory.buildRevealCommand(vpe); CompoundCommand allInOne = new CompoundCommand(cmd.getLabel()); allInOne.append(cmd); domain.getCommandStack().execute(allInOne);
* * Contributors: * Obeo - initial API and implementation *******************************************************************************/ package org.eclipse.sirius.diagram.ui.tools.internal.actions.visibility; import org.eclipse.gef.Disposable; import org.eclipse.gmf.runtime.diagram.ui.parts.IDiagramWorkbenchPart; import org.eclipse.jface.action.IAction; import org.eclipse.jface.viewers.ISelection; import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.PlatformUI; /** * Extends the {@link RevealElementsAction} to make it compatible with the tabbar by making it disposable and by * handling the selection changes. * * @author fbarbin */ public class TabbarRevealElementsAction extends RevealElementsAction implements Disposable { private IDiagramWorkbenchPart representationPart; /** * Constructor. * * @param text the label */ public TabbarRevealElementsAction(final String text) { super(text); } public void setActionPart(IDiagramWorkbenchPart part) { this.representationPart = part; } @Override public void selectionChanged(IAction action, ISelection s) {
import org.eclipse.jface.viewers.ISelection; import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.PlatformUI; /** * Extends the {@link RevealElementsAction} to make it compatible with the tabbar by make it disposable and by handling * the selection changes. * * @author fbarbin */ public class TabbarRevealElementsAction extends RevealElementsAction implements Disposable { private IDiagramWorkbenchPart representationPart; /** * Constructor. * * @param label the label */ public TabbarRevealElementsAction(final String text) { super(text); } public void setActionPart(IDiagramWorkbenchPart part) { this.representationPart = part; } @Override public void selectionChanged(IAction action, ISelection s) { IWorkbenchPart selectedPart = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage().getActivePart(); if (representationPart != null && !representationPart.equals(selectedPart)) { return; } super.selectionChanged(action, s); setEnabled(isEnabled()); } @Override public boolean isEnabled() {
import org.eclipse.sirius.diagram.ui.tools.internal.actions.visibility.RevealElementsAction; /** * Tester to know if all selected elements can be revealed and are not visible. * * @author fbarbin * */ public class CanShowElementTester extends PropertyTester { @Override public boolean test(Object receiver, String property, Object[] args, Object expectedValue) { boolean result = false; if ("canShowElement".equals(property)) { //$NON-NLS-1$ if (receiver instanceof IStructuredSelection) { result = RevealElementsAction.isActive((IStructuredSelection) receiver); } else if (receiver instanceof IDiagramElementEditPart) { result = RevealElementsAction.isActive((IDiagramElementEditPart) receiver); } } return result; } }
activateShowHideModeUsingTabbar(); SWTBotGefEditPart swtBotEditPart = getEditPart("new EClass 4", DNodeNameEditPart.class); hideShow(element, swtBotEditPart, true); } /** * Make a double click on the diagram element and verifies it is hidden. And do a double click again and verifies it * is shown again. * * @param element * element to hide and reveal * @param swtBotEditPart * the corresponding part. */ private void hideShow(DDiagramElement element, SWTBotGefEditPart swtBotEditPart, boolean isLabelHidden) { int count = 1; if (!isLabelHidden) { count = 3; } for (int i = 1; i <= count; i++) { editor.reveal(swtBotEditPart.part()); OperationDoneCondition done = new OperationDoneCondition(); performHideReveal(swtBotEditPart, i, "Hide element"); bot.waitUntil(done); SWTBotUtils.waitAllUiEvents(); if (isLabelHidden) {
bot.waitUntil(done); SWTBotUtils.waitAllUiEvents(); if (isLabelHidden) { assertFalse("The node should not have its label filtered.", element.getGraphicalFilters().stream().anyMatch(HideLabelFilter.class::isInstance)); } else { assertFalse("The node should not be filtered.", element.getGraphicalFilters().stream().anyMatch(HideFilter.class::isInstance)); } } } /** * We perform the Show / Hide for each action according to the i argument: * <ul> * <li>Double-click</li> * <li>Contextual menu action</li> * <li>Tabbar action</li> * </ul> * * @param swtBotEditPart * the selected edit part. * @param i * the action to perform: a double click, contextual menu or tabbar. * @param toolTip * the tooltip of the action to perform: Show element or Hide element. */ private void performHideReveal(SWTBotGefEditPart swtBotEditPart, int i, String toolTip) { switch (i) {
pattern.setValue("yyyy/yyyy"); input.setValue("2018/2019"); new SimpleDateFormat(pattern.getValue()).parse(input.getValue()); ScoutAssert.assertThrows(ParseException.class, () -> new StrictSimpleDateFormat(pattern.getValue()).parse(input.getValue())); } @Test public void testJavaScriptJsonString() throws ParseException { final StringHolder pattern = new StringHolder(); final String input = "2019-01-18T12:42:03.409Z"; pattern.setValue(IValueFormatConstants.DEFAULT_DATE_PATTERN); ScoutAssert.assertThrows(ParseException.class, () -> new SimpleDateFormat(pattern.getValue()).parse(input.getValue())); ScoutAssert.assertThrows(ParseException.class, () -> new StrictSimpleDateFormat(pattern.getValue()).parse(input.getValue())); pattern.setValue(IValueFormatConstants.TIMESTAMP_PATTERN); ScoutAssert.assertThrows(ParseException.class, () -> new SimpleDateFormat(pattern.getValue()).parse(input.getValue())); ScoutAssert.assertThrows(ParseException.class, () -> new StrictSimpleDateFormat(pattern.getValue()).parse(input.getValue()));
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */ package org.eclipse.jgit.lib; import static java.util.stream.Collectors.toList; import java.io.IOException; import java.util.ArrayList; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Set; import java.util.stream.Collectors; import org.eclipse.jgit.annotations.NonNull; import org.eclipse.jgit.annotations.Nullable; /** * Abstraction of name to {@link org.eclipse.jgit.lib.ObjectId} mapping. * <p> * A reference database stores a mapping of reference names to * {@link org.eclipse.jgit.lib.ObjectId}. Every * {@link org.eclipse.jgit.lib.Repository} has a single reference database, * mapping names to the tips of the object graph contained by the
* the reference space cannot be accessed. * @since 5.2 */ @NonNull public List<Ref> getRefsByPrefix(String... prefixes) throws IOException { List<Ref> result = new ArrayList<>(); for (String prefix : prefixes) { result.addAll(getRefsByPrefix(prefix)); } return Collections.unmodifiableList(result); } /** * Returns all refs that resolve directly to the given {@link ObjectId}. * Includes peeled {@linkObjectId}s. This is the inverse lookup of * {@link #exactRef(String...)}. * * <p> * The default implementation uses a linear scan. Implementors of * {@link RefDatabase} should override this method directly if a better * implementation is possible. * * @param id * {@link ObjectId} to resolve * @return a {@link Set} of {@link Ref}s whose tip points to the provided * id. * @throws java.io.IOException * the reference space cannot be accessed.
* Includes peeled {@linkObjectId}s. This is the inverse lookup if * {@link #exactRef(String...)}. * * <p> * The default implementation uses a linear scan. Implementors of * {@link RefDatabase} should override this method directly if a better * implementation is possible. * * @param id * {@link ObjectId} to resolve * @return a {@link Set} of {@link Ref}s whose tips point to the provided * id. * @throws java.io.IOException * the reference space cannot be accessed. * @since 5.3 */ @NonNull public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { return getRefs().stream() .filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())) .collect(Collectors.toSet()); } /** * Check if any refs exist in the ref database. * <p>
* @return a {@link Set} of {@link Ref}s whose tip points to the provided * id. * @throws java.io.IOException * the reference space cannot be accessed. * @since 5.3 */ @NonNull public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { return getRefs().stream().filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())).collect(toSet()); } /** * Check if any refs exist in the ref database. * <p> * This uses the same definition of refs as {@link #getRefs()}. In * particular, returns {@code false} in a new repository with no refs * under {@code refs/} and {@code HEAD} pointing to a branch yet to be * born, and returns {@code true} in a repository with no refs under * {@code refs/} and a detached {@code HEAD} pointing to history. *
*******************************************************************************/ package org.eclipse.tracecompass.analysis.os.linux.core.inputoutput; import org.eclipse.jdt.annotation.Nullable; import org.eclipse.osgi.util.NLS; /** * Externalized message strings from the I/O Analysis * * @author Houssem Daoud */ public class Messages extends NLS { private static final String BUNDLE_NAME = "org.eclipse.linuxtools.lttng2.kernel.core.inputoutput.analysis.messages"; //$NON-NLS-1$ /** Help text for the IO analysis */ public static @Nullable String LttngInputOutputModule_Help; static { // initialize resource bundle NLS.initializeMessages(BUNDLE_NAME, Messages.class); } private Messages() { } }
* http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.analysis.os.linux.core.threadstatus; import org.eclipse.osgi.util.NLS; /** * Externalized Strings for the {@link ThreadStatusDataProvider} package */ class Messages extends NLS { private static final String BUNDLE_NAME = "org.eclipse.tracecompass.internal.analysis.os.linux.core.threadstatus.messages"; //$NON-NLS-1$ /** attribute cpu name */ public static String ThreadStatusDataProvider_attributeCpuName; /** The data provider title text */ public static String ThreadStatusDataProviderFactory_title; /** * DataProvider help text */ public static String ThreadStatusDataProviderFactory_descriptionText; static { // initialize resource bundle NLS.initializeMessages(BUNDLE_NAME, Messages.class); } private Messages() { } }
List<IDataProviderDescriptor> descriptors = new ArrayList<>(); Set<String> existingModules = new HashSet<>(); for (ISegmentStoreProvider module : modules) { IAnalysisModule analysis = (IAnalysisModule) module; // Only add analysis once per trace (which could be an experiment) if (!existingModules.contains(analysis.getId())) { DataProviderDescriptor.Builder builder = new DataProviderDescriptor.Builder(); builder.setId(SegmentStoreScatterDataProvider.ID + DataProviderConstants.ID_SEPARATOR + analysis.getId()) .setName(Objects.requireNonNull(NLS.bind(Messages.SegmentStoreScatterGraphDataProvider_title, analysis.getName()))) .setDescription(Objects.requireNonNull(NLS.bind(Messages.SegmentStoreScatterGraphDataProvider_description, analysis.getName()))) .setProviderType(ProviderType.TREE_TIME_XY); descriptors.add(builder.build()); } } return descriptors;
return Status.OK_STATUS; } public File getPath() { return path; } public boolean isDirty() { return false; } public InputStream read(String item, IProgressMonitor monitor) throws IOException { File file = getFile(item); return new FileInputStream(file); } public void release() { store.release(this); } public OutputStream write(String item, IProgressMonitor monitor) throws IOException { File file = getFile(item); return new FileOutputStream(file); } private File getFile(String item) { File file = new File(path, item); if (!file.getParentFile().exists()) { file.getParentFile().mkdirs(); } return file; } }
* http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Tasktop Technologies - initial API and implementation *******************************************************************************/ package org.eclipse.mylyn.monitor.core; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; import org.eclipse.core.runtime.IStatus; import org.eclipse.core.runtime.Status; import org.eclipse.mylyn.commons.core.StatusHandler; import org.eclipse.mylyn.internal.monitor.core.IMonitorCoreConstants; /** * Used for logging interaction events. * * @author Mik Kersten * @since 2.0 */ public abstract class AbstractMonitorLog { protected File outputFile; protected FileOutputStream outputStream; protected boolean started = false; public AbstractMonitorLog() { super(); } public void startMonitoring() { synchronized (this) { if (started) { return; } else { started = true; } } try { if (!outputFile.exists()) { outputFile.createNewFile(); } outputStream = new FileOutputStream(outputFile, true); } catch (Exception e) {
if (!destinationFile.exists()) { destinationFile.mkdirs(); } while (entries.hasMoreElements()) { ZipEntry entry = entries.nextElement(); File outputFile = new File(destinationFile, entry.getName()); if (entry.isDirectory() && !outputFile.exists()) { outputFile.mkdirs(); continue; } if (!outputFile.getParentFile().exists()) { outputFile.getParentFile().mkdirs(); } try (InputStream inputStream = new BufferedInputStream(zipFile.getInputStream(entry)); OutputStream outStream = new BufferedOutputStream(new FileOutputStream(outputFile))) { copyStream(inputStream, outStream); } outputFiles.add(outputFile); if (monitor != null) { monitor.worked(1); } } return outputFiles; } } private static void copyStream(InputStream in, OutputStream out) throws IOException { Assert.isNotNull(in); Assert.isNotNull(out); byte[] buffer = new byte[4096]; int readCount;
private final CommonStore store; public CommonStorable(CommonStore store, File path) { this.store = store; this.path = path; } public void delete(String item) throws CoreException { getFile(item).delete(); } public void deleteAll() throws CoreException { File[] children = path.listFiles(); if (children != null) { // validate for (File child : children) { if (child.isDirectory()) { throw new CoreException(new Status(IStatus.ERROR, CommonsCorePlugin.ID_PLUGIN, NLS.bind( "The storage location ''{0}'' contains sub directories", path))); //$NON-NLS-1$ } } // delete all files for (File child : children) { child.delete(); } } if (path.exists()) { path.delete(); } } public boolean exists(String handle) { if (!path.exists()) { return false; } return getFile(handle).exists(); } public IStatus flush() { return Status.OK_STATUS; }
public static void createZipFile(File zipFile, List<File> files, String rootPath, IProgressMonitor monitor) throws FileNotFoundException, IOException { if (rootPath == null) { rootPath = ""; //$NON-NLS-1$ } else if (!rootPath.endsWith("\\") || !rootPath.endsWith("/")) { //$NON-NLS-1$ //$NON-NLS-2$ rootPath += "/"; //$NON-NLS-1$ } try (ZipOutputStream zipOut = new ZipOutputStream(new BufferedOutputStream(new FileOutputStream(zipFile)))) { for (File file : files) { try { addZipEntry(zipOut, rootPath, file); if (monitor != null) { monitor.worked(1); } } catch (Exception e) { StatusHandler.log(new Status(IStatus.ERROR, ICommonsCoreConstants.ID_PLUGIN, "Could not add " //$NON-NLS-1$ + file.getName() + " to zip", e)); //$NON-NLS-1$ } } } } /** * @author Shawn Minto */
* a path separator character * @return the file path with its separator character changed from the given old separator to the given new * separator */ public static String changeSeparator(String path, char oldSeparator, char newSeparator) { return path.replace(oldSeparator, newSeparator); } /** * Copies the given source file to the given destination file. */ public static void copy(File source, File dest) throws IOException { try (InputStream in = new FileInputStream(source); OutputStream out = new BufferedOutputStream(new FileOutputStream(dest))) { transferData(in, out); } } } /** * Copies all files in the current data directory to the specified folder. Will overwrite. */ public static void copyFolder(File sourceFolder, File targetFolder) throws IOException { for (File currFile : sourceFolder.listFiles()) { if (currFile.isFile()) { File destFile = new File(targetFolder, currFile.getName()); copy(currFile, destFile);
* http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Tasktop Technologies - initial API and implementation *******************************************************************************/ package org.eclipse.mylyn.monitor.core; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; import org.eclipse.core.runtime.IStatus; import org.eclipse.core.runtime.Status; import org.eclipse.mylyn.commons.core.StatusHandler; import org.eclipse.mylyn.internal.monitor.core.IMonitorCoreConstants; /** * Used for logging interaction events. * * @author Mik Kersten * @since 2.0 */ public abstract class AbstractMonitorLog { protected File outputFile; protected FileOutputStream outputStream; protected boolean started = false; public AbstractMonitorLog() { super(); } public void startMonitoring() { synchronized (this) { if (started) { return; } else { started = true; } } try { if (!outputFile.exists()) { outputFile.createNewFile(); } outputStream = new FileOutputStream(outputFile, true); } catch (Exception e) {
public void dispose() { if (fExpressionHistory != null) { fExpressionHistory.dispose(); } fListeners.clear(); super.dispose();
DNode element = (DNode) ((Node) part.getModel()).getElement(); assertFalse("The node should not have its label filtered.", element.getGraphicalFilters().stream().anyMatch(HideLabelFilter.class::isInstance)); activateShowHideModeUsingTabbar(); SWTBotGefEditPart swtBotEditPart = getEditPart("new EClass 4", DNodeNameEditPart.class); hideShow(element, swtBotEditPart, true); } /** * Performs a hide and show action on the diagram element by using those three different ways: * <ul> * <li>The double-click</li> * <li>The contextual menu action</li> * <li>The tabbar action</li> * </ul> * * @param element * element to hide and reveal * @param swtBotEditPart * the corresponding part. */ private void hideShow(DDiagramElement element, SWTBotGefEditPart swtBotEditPart, boolean isLabelHidden) { int count = 0; if (!isLabelHidden) { count = 2; }
Diagram data = (Diagram) annotationEntry.getData(); Optional<?> missingNode = data.getChildren().stream().filter(child -> "_Sx9-MCLeEemN0s24dvRntQ".equals(((IdentifiedElement) ((Node) child).getElement()).getUid())).findFirst(); assertFalse("GMF cleaning has not been done while refreshing representation.", missingNode.isPresent()); } }
* which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Boeing - initial API and implementation *******************************************************************************/ package org.eclipse.osee.framework.jdk.core.type; import java.util.ArrayList; import java.util.Collection; import java.util.List; public class TreeNode<treeType> { private treeType myself; private TreeNode<treeType> parent; private List<TreeNode<treeType>> children; protected TreeNode(TreeNode<TreeType> parent, TreeType myself) { this.parent = parent; this.myself = myself; this.children = new ArrayList<>(); } public TreeNode(treeType myself) { this(null, myself); } @SuppressWarnings("null") public TreeNode() { this(null); } public TreeNode<treeType> getParent() { return parent; } public treeType getSelf() { return myself; } public List<TreeNode<treeType>> getChildren() { return children; }
import java.util.List; import java.util.Objects; import java.util.function.Function; import java.util.function.Predicate; import org.eclipse.tracecompass.internal.tmf.analysis.xml.core.fsm.model.values.DataDrivenValue; import org.eclipse.tracecompass.internal.tmf.analysis.xml.core.fsm.module.IAnalysisDataContainer; import org.eclipse.tracecompass.statesystem.core.ITmfStateSystem; import org.eclipse.tracecompass.tmf.core.event.ITmfEvent; /** * A data-driven condition. * * @author Genevive Bastien * @author Florian Wininger */ public interface DataDrivenCondition extends IDataDrivenRuntimeObject { /** * Condition operators used to compare 2 values together */ public enum ConditionOperator implements Predicate<Integer> { /** equal */ EQ(i -> i == 0), /** not equal */ NE(i -> i != 0), /** Greater or equal */ GE(i -> i >= 0), /** Greater than */ GT(i -> i > 0), /** Less or equal */ LE(i -> i <= 0), /** Less than */ LT(i -> i < 0);
private static String[] getProtocolsToKeep(final String[] enabledProtocols) { final List<String> remainingProtocols = new ArrayList<String>(); for (final String protocol : enabledProtocols) { if (protocol.equals(SSLV3) || protocol.equals(SSLV2_HELLO)) { continue; } remainingProtocols.add(protocol); } if (remainingProtocols.isEmpty()) { throw new FatalSocketException(); } return remainingProtocols.toArray(new String[remainingProtocols.size()]);
final SSLContext context = SSLContext.getInstance("TLS"); //$NON-NLS-1$ context.init(ServerKeyStoreManager.getInstance().getKeyManagerFactory().getKeyManagers(), null, null); serverSocketFactory = context.getServerSocketFactory(); } catch (final NoSuchAlgorithmException exception) { shutdown(serverSocketFactory, exception); } catch (final KeyManagementException exception) { shutdown(serverSocketFactory, exception); } catch (final ServerKeyStoreException exception) { shutdown(serverSocketFactory, exception); } try { return disableSSLv3AndReturn(serverSocketFactory.createServerSocket(pPort, backlog, addr)); } catch (final FatalSocketException ex) { shutdown(serverSocketFactory, ex); throw new IOException(ex.getMessage()); } } private void shutdown(SSLServerSocketFactory serverSocketFactory, Exception e) { if (serverSocketFactory == null) { ModelUtil.logException(Messages.XmlRpcBuiltinWebServer_ServerSocketInitFailed, e); EMFStoreController.getInstance().shutdown(new FatalESException()); } } }
private static final String TAG_SELECTION = "selection"; //$NON-NLS-1$ private static final String TAG_EXPANDED = "expanded"; //$NON-NLS-1$ private static final String TAG_ELEMENT = "element"; //$NON-NLS-1$ private static final String TAG_IS_ENABLED = "isEnabled"; //$NON-NLS-1$ private static final String TAG_PATH = "path"; //$NON-NLS-1$ private static final String TAG_CURRENT_FRAME = "currentFrame"; //$NON-NLS-1$ private IPartListener partListener = new IPartListener() { @Override public void partActivated(IWorkbenchPart part) { if (part instanceof IEditorPart) { editorActivated((IEditorPart) part); } } @Override public void partBroughtToTop(IWorkbenchPart part) { if (part instanceof IEditorPart) { editorActivated((IEditorPart) part); } } @Override public void partClosed(IWorkbenchPart part) { } @Override public void partDeactivated(IWorkbenchPart part) { } @Override public void partOpened(IWorkbenchPart part) {
private static final String MEMENTO_REGEXP_FILTER_REGEXP_ATTRIBUTE = "regexp"; //$NON-NLS-1$ private static final String MEMENTO_REGEXP_FILTER_ENABLED_ATTRIBUTE = "enabled"; //$NON-NLS-1$ private int rootMode; /** * Used only in the case of top level = PROJECTS and only when some * working sets are selected. */ private String workingSetLabel; private List<UserFilter> userFilters; private EmptyWorkspaceHelper emptyWorkspaceHelper; @Override public void init(IViewSite site, IMemento memento) throws PartInitException { super.init(site, memento); userFilters = new ArrayList<UserFilter>(); if (memento != null) { IMemento[] filters = memento.getChildren(MEMENTO_REGEXP_FILTER_ELEMENT); for (IMemento filterMemento : filters) { String regexp = filterMemento.getString(MEMENTO_REGEXP_FILTER_REGEXP_ATTRIBUTE); Boolean enabled = filterMemento.getBoolean(MEMENTO_REGEXP_FILTER_ENABLED_ATTRIBUTE); userFilters.add(new UserFilter(regexp, enabled)); } } } @Override public void saveState(IMemento aMemento) {
public void createPartControl(Composite aParent) { emptyWorkspaceHelper = new EmptyWorkspaceHelper(aParent); super.createPartControl(aParent); getCommonViewer().setMapper(new ResourceToItemsMapper(getCommonViewer())); getCommonViewer().setData(NavigatorPlugin.RESOURCE_REGEXP_FILTER_DATA, this.userFilters); if (this.userFilters.stream().anyMatch(UserFilter::isEnabled)) { getCommonViewer().refresh(); }
private final Map<EPackage, String> packageToInferedSource = new LinkedHashMap<EPackage, String>(); private final Map<EPackage, Text> packageToSourceText = new LinkedHashMap<EPackage, Text>(); private final Map<EPackage, Text> packageToTargetText = new LinkedHashMap<EPackage, Text>(); private final Map<EPackage, Button> packageToUpdateButton = new LinkedHashMap<EPackage, Button>(); private final List<EPackage> packages; private final Set<EPackage> changedPackages; /** * Constructs a new {@link ReleaseWizardPage}. * * @param pageName * @param description * @param titleImage * @param packages the packages * @param changedPackages the changed packages */ protected ReleaseWizardPage(String pageName, String description, ImageDescriptor titleImage, List<EPackage> packages, Set<EPackage> changedPackages) { super(pageName, pageName, titleImage); setDescription(description); this.packages = packages;
IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { PlatformUI.getWorkbench().getDisplay() .asyncExec(() -> PlatformUI.getWorkbench().getDisplay().timerExec(200, switchTopControlRunnable)); return; } } }
* contains links to: * <ol> * <li>Project creation wizards specific to the current perspective</li> * <li>The "New Project Wizard" to allow creation of project of any type</li> * </ol> * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown. * * This class also takes care of refreshing these links when the user switches * the perspective. * */ public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions = null; private IAction newProjectAction = null; /** * This method should be called at the point in time when the view's controls * are created. * * @param parent The composite where the explanatory text should be put into. */ public EmptyWorkspaceHelper(Composite parent) {
* <li>The "New Project Wizard" to allow creation of project of any type</li> * </ol> * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown. * * This class also takes care of refreshing these links when the user switches * the perspective. * * @since 3.15 * */ public final class EmptyWorkspaceHelper { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions = null; private IAction newProjectAction = null; /** * This method should be called at the point in time when the view's controls * are created. * * @param parent The composite where the explanatory text should be put into. */ public EmptyWorkspaceHelper(Composite parent) { displayArea = parent; layout = new StackLayout(); displayArea.setLayout(layout); createEmptyArea(displayArea);
* If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown. * * This class also takes care of refreshing these links when the user switches * the perspective. * * @since 3.15 * */ public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions; private IAction newProjectAction; /** * This method should be called at the point in time when the view's controls * are created. * * @param parent The composite where the explanatory text should be put into. */ public EmptyWorkspaceHelper(Composite parent) { displayArea = parent; layout = new StackLayout(); displayArea.setLayout(layout); createEmptyArea(displayArea); registerListeners(); } /**
public void setNonEmptyControl(Control control) { this.control = control; emptyArea.setBackground(control.getBackground()); switchTopControl();
private void dispose(Listener listener) { PlatformUI.getWorkbench().getActiveWorkbenchWindow().removePerspectiveListener(listener); ResourcesPlugin.getWorkspace().removeResourceChangeListener(listener); JFaceResources.getColorRegistry().removeListener(listener); parent.removeDisposeListener(listener);
private void readProjectWizardActions() { IWorkbench wb = PlatformUI.getWorkbench(); IWorkbenchWindow win = wb.getActiveWorkbenchWindow(); IWorkbenchPage page = win.getActivePage(); String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { IWizardRegistry newWizardRegistry = WorkbenchPlugin.getDefault().getNewWizardRegistry(); IWizardDescriptor wizardDesc = newWizardRegistry.findWizard(wizardId); if (wizardDesc == null) { continue; String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(WorkbenchPlugin.getDefault().getNewWizardRegistry(), wizardId); projectWizardActions.add(action); } } }
private void readProjectWizardActions() { IWorkbench wb = PlatformUI.getWorkbench(); IWorkbenchWindow win = wb.getActiveWorkbenchWindow(); IWorkbenchPage page = win.getActivePage(); String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { IWizardRegistry newWizardRegistry = WorkbenchPlugin.getDefault().getNewWizardRegistry(); IWizardDescriptor wizardDesc = newWizardRegistry.findWizard(wizardId); if (wizardDesc == null) { continue; String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(WorkbenchPlugin.getDefault().getNewWizardRegistry(), wizardId); projectWizardActions.add(action); } } }
private boolean switchTopControl() { if (control.isDisposed() || emptyArea.isDisposed()) { return false; } Control oldTop = layout.topControl; IProject[] projs = ResourcesPlugin.getWorkspace().getRoot().getProjects(); if (projs.length > 0) { layout.topControl = control; } else { layout.topControl = emptyArea; } return oldTop != layout.topControl;
public void resourceChanged(IResourceChangeEvent event) { IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { Display.getDefault().asyncExec(() -> Display.getDefault().timerExec(200, switchTopControlRunnable)); } } }
public void propertyChange(PropertyChangeEvent event) { if (event.getProperty().equals(JFacePreferences.HYPERLINK_COLOR)) { recreateEmptyArea(); } @Override public void widgetDisposed(DisposeEvent e) { dispose(this); }
IWorkingSetManager workingSetManager = getPlugin().getWorkbench() .getWorkingSetManager(); workingSetManager.removePropertyChangeListener(propertyChangeListener); if (collapseAllHandler != null) { collapseAllHandler.dispose(); } if (getActionGroup() != null) { getActionGroup().dispose(); } Control control = viewer.getControl(); if (dragDetectListener != null && control != null && control.isDisposed() == false) { control.removeListener(SWT.DragDetect, dragDetectListener); } super.dispose();
* content into here?" * * This class uses a stack layout to switch between the "original" composite of * the view and an additional composite given the user the explanatory text. * This text is displayed when no projects are in the workspace. Once projects * are created this class switches back to the "original" composite of the view. * * The explanatory text explains the current situation that no projects are * available and provides a list of options to create projects. This list * contains links to: * <ol> * <li>Project creation wizards specific to the current perspective</li> * <li>The "New Project Wizard" to allow creation of project of any type</li> * </ol> * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown. * * This class also takes care of refreshing these links when the user switches * the perspective. * */ public final class EmptyWorkspaceHelper {
private void dispose(Listener listener) { PlatformUI.getWorkbench().getActiveWorkbenchWindow().removePerspectiveListener(listener); ResourcesPlugin.getWorkspace().removeResourceChangeListener(listener); JFaceResources.getColorRegistry().removeListener(listener); parent.removeDisposeListener(listener); // paranoia parent = null; emptyArea = null; layout = null; control = null; displayArea = null; projectWizardActions = null; newProjectAction = null;
String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { IWizardRegistry newWizardRegistry = WorkbenchPlugin.getDefault().getNewWizardRegistry(); IWizardDescriptor wizardDesc = newWizardRegistry.findWizard(wizardId); if (wizardDesc == null) { continue; } String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(newWizardRegistry, wizardId); if (action != null) { projectWizardActions.add(action); } } } }
public void resourceChanged(IResourceChangeEvent event) { IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { PlatformUI.getWorkbench().getDisplay() .asyncExec(() -> Display.getDefault().timerExec(200, switchTopControlRunnable)); return; } } }
* * Contributors: * Lucas Koehler - initial API and implementation ******************************************************************************/ package org.eclipse.emfforms.spi.common.sort; import java.math.BigInteger; import java.util.Comparator; import java.util.regex.Matcher; import java.util.regex.Pattern; /** * A comparator for strings that compares numbers which are part of compared string as numbers and not as strings. * This allows to sort strings that are a mixture of numbers and text (e.g. house numbers) in an intuitive fashion. * For instance, plain string sorting sorts 200A greater than 1000A. This comparator sorts 1000A greater than 200A. * * @author Lucas Koehler * @since 1.20 * */ public final class NumberAwareStringComparator implements Comparator<String> { // First group matches zero or more non-digits. Second group matches zero or more digits private static final Pattern PATTERN = Pattern.compile("(\\D*)(\\d*)"); //$NON-NLS-1$ private static NumberAwareStringComparator instance; /** * @return the static {@link NumberAwareStringComparator} instance. */
private Action fOpenManifestAction; private Action fOpenSchemaAction; private Action fOpenSystemEditorAction; private Action fOpenClassFileAction; private Action fOpenTextEditorAction; private Action fSelectDependentAction; private Action fSelectInJavaSearchAction; private Action fSelectAllAction; private PDERefactoringAction fRefactorAction; private CollapseAllAction fCollapseAllAction; private DisabledFilter fHideExtEnabledFilter = new DisabledFilter(true); private DisabledFilter fHideExtDisabledFilter = new DisabledFilter(false); private WorkspaceFilter fHideWorkspaceFilter = new WorkspaceFilter(); private JavaFilter fJavaFilter = new JavaFilter(); private CopyToClipboardAction fCopyAction; private Clipboard fClipboard; private Object fRoot = null; class DisabledFilter extends ViewerFilter { boolean fEnabled; DisabledFilter(boolean enabled) { fEnabled = enabled; } @Override public boolean select(Viewer v, Object parent, Object element) { if (element instanceof IPluginModelBase) { IPluginModelBase model = (IPluginModelBase) element; return model.getUnderlyingResource() != null || model.isEnabled() != fEnabled; } return true;
boolean hideDisabledExternal = !settings.getBoolean(SHOW_EXDISABLED); if (hideWorkspace) fTreeViewer.addFilter(fHideWorkspaceFilter); if (hideEnabledExternal) fTreeViewer.addFilter(fHideExtEnabledFilter); if (hideDisabledExternal) fTreeViewer.addFilter(fHideExtDisabledFilter); fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); Job.createSystem("", monitor -> { //$NON-NLS-1$ PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> { fSourcePluginFilter = new SourcePluginFilter(state); fTreeViewer.addFilter(fSourcePluginFilter); }); } }).schedule();
boolean hideEnabledExternal = settings.getBoolean(HIDE_EXENABLED); boolean hideDisabledExternal = !settings.getBoolean(SHOW_EXDISABLED); if (hideWorkspace) fTreeViewer.addFilter(fHideWorkspaceFilter); if (hideEnabledExternal) fTreeViewer.addFilter(fHideExtEnabledFilter); if (hideDisabledExternal) fTreeViewer.addFilter(fHideExtDisabledFilter); fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); if (PDECore.getDefault().getModelManager().isInitialized()) { PDEState state = PDECore.getDefault().getModelManager().getState(); fSourcePluginFilter = new SourcePluginFilter(state); } else { Job.createSystem("", monitor -> { //$NON-NLS-1$ PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> {
fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); // when TP state is already initialized apply the SourcePluginFilter // directly, // otherwise defer state initialization to a background job and apply // the filter // when it is available. if (PDECore.getDefault().getModelManager().isInitialized()) { PDEState state = PDECore.getDefault().getModelManager().getState(); fSourcePluginFilter = new SourcePluginFilter(state); fTreeViewer.addFilter(fSourcePluginFilter); } else { Job.createSystem("", monitor -> { //$NON-NLS-1$ PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> { fSourcePluginFilter = new SourcePluginFilter(state); fTreeViewer.addFilter(fSourcePluginFilter); }); } }).schedule(); }
IContainer parent = tpdFile.getParent(); String fileName = tpdFile.getFullPath().removeFileExtension().addFileExtension("target").lastSegment(); //$NON-NLS-1$ IFile portableTargetFile = parent.getFile(new Path(fileName)); IFolder eclipseFolder = parent.getParent().getFolder(new Path(targetSuffix)); if (!eclipseFolder.exists()) { eclipseFolder.create(true, true, new NullProgressMonitor()); } IFile eclipseTargetFile = eclipseFolder.getFile(fileName.replaceAll("portable", targetSuffix)); //$NON-NLS-1$ InputStream convertedStream = convert(portableTargetFile.getContents(), "http://download.eclipse.org/", "file:/home/data/httpd/download.eclipse.org/"); //$NON-NLS-1$ //$NON-NLS-2$ convertedStream = convert(convertedStream, "https://download.eclipse.org/", "file:/home/data/httpd/download.eclipse.org/"); //$NON-NLS-1$ //$NON-NLS-2$ if (eclipseTargetFile.exists()) { eclipseTargetFile.setContents(convertedStream, IResource.NONE, null); } else { eclipseTargetFile.create(convertedStream, true, null); }
* {@link RefDatabase} should override this method directly if a better * implementation is possible. * * @param id * {@link ObjectId} to resolve * @return a {@link Set} of {@link Ref}s whose tips point to the provided * id. * @throws java.io.IOException * the reference space cannot be accessed. * @since 5.3 */ @NonNull public Set<Ref> getTipsWithSha1(ObjectId id) throws IOException { return getRefs().stream().filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())).collect(toSet()); } /** * Check if any refs exist in the ref database. * <p> * This uses the same definition of refs as {@link #getRefs()}. In * particular, returns {@code false} in a new repository with no refs * under {@code refs/} and {@code HEAD} pointing to a branch yet to be
protected IStatus run(IProgressMonitor monitor) { Diagnostic result = converter.generateTargetDefinitionFile(tpdURI, new NullProgressMonitor()); if (result.getSeverity() >= Diagnostic.WARNING) { Activator.getDefault().getLog().log(BasicDiagnostic.toIStatus(result)); } try { file.getParent().refreshLocal(IResource.DEPTH_ONE, null); generateEclipseTarget(file); } catch (CoreException ex) { return new Status(IStatus.ERROR, Activator.PLUGIN_ID, Messages.GenerateTargetsHandler_UnexpectedException, ex); } return BasicDiagnostic.toIStatus(result);
* buttonFactory.text("Button 1").create(parent); * buttonFactory.text("Button 2").create(parent); * buttonFactory.text("Button 3").create(parent); * </pre> * <p> * The above example creates three buttons using the same instance of * ButtonFactory. * <p> */ public final class WidgetFactory { private WidgetFactory() { } /** * @param style SWT style applicable for Button. Refer to * {@link Button#Button(Composite, int)} for supported styles. * @return ButtonFactory */ public static ButtonFactory button(int style) { return ButtonFactory.newButton(style); } /** * @param style SWT style applicable for Text. Refer to * {@link Text#Text(Composite, int)} for supported styles. * @return TextFactory */ public static TextFactory text(int style) { return TextFactory.newText(style); } /** * @param style SWT style applicable for Label. Refer to
public void testUniqueLayoutData() { GridDataFactory gridDataFactory = GridDataFactory.fillDefaults().grab(true, false); TestFactory factory = TestFactory.newTest().layoutData(gridDataFactory::create); Label label = factory.create(shell); Label label2 = factory.create(shell); assertNotEquals(label.getLayoutData(), label2.getLayoutData());
public void testUniqueLayoutData() { GridDataFactory gridDataFactory = GridDataFactory.fillDefaults().grab(true, false); TestFactory factory = TestFactory.newTest().tooltip("toolTip").enabled(false).layoutData(gridDataFactory::create); Label label = factory.create(shell); Label label2 = factory.create(shell); assertNotSame(label.getLayoutData(), label2.getLayoutData());
indent.addSelectionListener(widgetSelectedAdapter(event -> { Spinner spinner = (Spinner) event.widget; styledText.setIndent(spinner.getSelection()); })); label = new Label(composite, SWT.NONE); label.setText(getResourceString("Spacing")); //$NON-NLS-1$ Spinner spacing = new Spinner(composite, SWT.BORDER); spacing.addSelectionListener(widgetSelectedAdapter(event -> { Spinner spinner = (Spinner) event.widget; styledText.setLineSpacing(spinner.getSelection()); })); coolItem = new CoolItem(coolBar, SWT.NONE); coolItem.setControl(composite); CoolItem[] coolItems = coolBar.getItems(); for (CoolItem item : coolItems) { Control control = item.getControl(); Point size = control.computeSize(SWT.DEFAULT, SWT.DEFAULT); item.setMinimumSize(size);
private static String internalGetString(String key) { try { return RESOURCE_BUNDLE.getString(key); } catch (MissingResourceException e) { return '!' + key + '!'; //$NON-NLS-1$ //$NON-NLS-2$ }
public String toString() { if (eObject == null) { return "<null>-" + side; //$NON-NLS-1$ } return eObject.eClass().getName() + '-' + side.getName(); //$NON-NLS-1$
public String toString() { return super.toString() + '-' + side.getName(); //$NON-NLS-1$
shortMessage += "..."; //$NON-NLS-1$ } // Get the author String author = null; if (lastCommit.getFullMessage().contains(Constants.SIGNED_OFF_BY_TAG)) { try { final String subSignedOff = lastCommit.getFullMessage().substring(lastCommit.getFullMessage().indexOf(Constants.SIGNED_OFF_BY_TAG) + Constants.SIGNED_OFF_BY_TAG.length()); author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; //$NON-NLS-1$ //$NON-NLS-2$ } catch (Exception e) { // Do nothing } } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } if (!shortMessage.isEmpty() && !author.isEmpty()) { constructName.append("("); //$NON-NLS-1$ if (!shortMessage.isEmpty()) { constructName.append("\""); //$NON-NLS-1$ constructName.append(shortMessage); constructName.append("\", "); //$NON-NLS-1$ }
final String projectName = project.getName(); // Get the branch name final String fullBranchName = branch.getName(); final String shortBranchName = fullBranchName.substring(fullBranchName.indexOf(Constants.R_REMOTES) + Constants.R_REMOTES.length() + Constants.DEFAULT_REMOTE_NAME.length() + 1); final List<IProject> importedProject = new ArrayList<IProject>(1); try { new ProgressMonitorDialog(shell).run(true, false, monitor -> { monitor.beginTask(taskName, 6); try { // First, reset the current branch monitor.subTask("Reset the branch"); //$NON-NLS-1$ GitUtils.resetHardCurrentBranch(git); monitor.worked(1); // First, checkout the master branch (else we can't delete the other branch) monitor.subTask("Checkout the master"); //$NON-NLS-1$ GitUtils.checkoutExistingBranch(git, Constants.MASTER); monitor.worked(1); // Second, we have to delete local branch if exist monitor.subTask("Delete the local branch"); //$NON-NLS-1$
protected Element getRootElement(final Object selectedObject) { Element result = null; // Manage the possible selected file final IFile file = PapyrusFileUtils.getFile(selectedObject); if (null != file) { String fullPath = file.getFullPath().toString(); URI modelURI = URI.createPlatformResourceURI(fullPath, false); if (!"uml".equals(modelURI.fileExtension())) { //$NON-NLS-1$ modelURI = modelURI.trimFileExtension().appendFileExtension("uml"); //$NON-NLS-1$ } final ModelSet modelSet = new ModelSet(); final Resource resource = modelSet.getResource(modelURI, true); if (null != resource) { final EObject root = resource.getContents().get(0); if (root instanceof Element) { result = (Element) root; } } } // Manage other possibilities if (null == result && selectedObject instanceof IAdaptable) {
public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); PersonIdent authorIdent = lastCommit.getAuthorIdent(); Date authorDate = authorIdent.getWhen(); SimpleDateFormat dateFormat = new SimpleDateFormat("dd-MM-yyyy HH:mm:ss"); //$NON-NLS-1$ return dateFormat.format(authorDate); } return "Not specified";
public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); PersonIdent authorIdent = lastCommit.getAuthorIdent(); Date authorDate = authorIdent.getWhen(); SimpleDateFormat dateFormat = new SimpleDateFormat("dd-MM-yyyy HH:mm:ss"); return dateFormat.format(authorDate); } return "Not specified"; //$NON-NLS-1$
final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); String author = null; if (lastCommit.getFullMessage().contains(Constants.SIGNED_OFF_BY_TAG)) { try { final String subSignedOff = lastCommit.getFullMessage().substring(lastCommit.getFullMessage().indexOf(Constants.SIGNED_OFF_BY_TAG) + Constants.SIGNED_OFF_BY_TAG.length()); author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; //$NON-NLS-1$ //$NON-NLS-2$ } catch (Exception e) { // Do nothing } } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } return author; } return "Unknown";
author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; } catch (Exception e) { // Do nothing } } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } return author; } return "Unknown"; //$NON-NLS-1$
public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); return lastCommit.getShortMessage(); } return "Not specified"; //$NON-NLS-1$
* Nicolas FAUVERGUE (CEA LIST) nicolas.fauvergue@cea.fr - Initial API and implementation * *****************************************************************************/ package org.eclipse.papyrus.gitlight.git.data; import java.util.NoSuchElementException; import java.util.StringTokenizer; /** * This class represent the catalog version. */ public class CatalogVersion { /** The major version number. */ protected int major; /** The minor version number. */ protected int minor; /** The separator for the version string. */ private final static String SEPARATOR = "."; //$NON-NLS-1$ /** The empty version "0.0". Equivalent to calling <code>new Version(0,0)</code>. */ public static final CatalogVersion emptyVersion = new CatalogVersion(0, 0); /** * Creates a new Version. * * @param major * The major version value (should be positive). * @param minor * The minor version value (should be positive). */ public CatalogVersion(final int major, final int minor) { updateVersion(major, minor); } /**
/** * The 'version' details name key. */ public static final String VERSION_DETAILS_NAME = "current"; //$NON-NLS-1$ /** * The master repository path. */ public static final String MASTER_REPOSITORY_PATH = Constants.DEFAULT_REMOTE_NAME + "/" + Constants.MASTER; //$NON-NLS-1$ /** * The contribution branch name prefix. */ public static final String CONTRIBUTION_BRANCH_PREFIX = "Review_"; //$NON-NLS-1$ /** * The initial commit message. */ public static final String INITIAL_COMMIT_MESSAGE = "Initial commit"; /** * The git folder. */ public static final String GIT_FOLDER = "\\" + Constants.DOT_GIT; //$NON-NLS-1$ /** * The change id. */ public static final String CHANGE_ID = "Change-Id: I0000000000000000000000000000000000000000"; //$NON-NLS-1$ }
public static void copyProject(final Git git, final IProject project) { final Repository repository = git.getRepository(); final URI gitPath = URI.createURI(repository.getWorkTree().toString().replace("\\", "/")); //$NON-NLS-1$ //$NON-NLS-2$ // Copy all project and sub files copySubFolder(project, gitPath); // Add this copied files to git addGitFiles(git, repository.getWorkTree(), ""); //$NON-NLS-1$
public static void copyFolder(final String source, final String dest) { final File srcFolder = getFolder(source); final File destFolder = getFolder(dest); if (srcFolder.exists()) { if (!destFolder.exists()) { destFolder.mkdir(); } // Copy sub folders and files for (final File subFile : srcFolder.listFiles()) { if (subFile.isDirectory()) { copyFolder(subFile.getAbsolutePath(), dest + "/" + subFile.getName()); //$NON-NLS-1$ } else { try { copyFile(subFile.getAbsolutePath(), dest + "/" + subFile.getName()); } catch (IOException e) { Activator.getLogHelper().error(e); } } } }
* https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Nicolas FAUVERGUE (CEA LIST) nicolas.fauvergue@cea.fr - Initial API and implementation * *****************************************************************************/ package org.eclipse.papyrus.gitlight.review.profile; import org.eclipse.emf.common.EMFPlugin; import org.eclipse.emf.common.util.ResourceLocator; /** * This is the central singleton for the Reviewprofile model plugin. <!-- * begin-user-doc --> <!-- end-user-doc --> */ public final class Activator extends EMFPlugin { /** * Keep track of the singleton. <!-- begin-user-doc --> <!-- end-user-doc * --> * * @generated */ public static final Activator INSTANCE = new Activator(); /** * Keep track of the singleton. <!-- begin-user-doc --> <!-- end-user-doc * --> * * @generated */ private static Implementation plugin; /**
* the display to search for potential controls * @param locationToFind * the position, in display coordinates, to be located * @return the most specific SWT control at the given location */ public static Control findControl(Display displayToSearch, Point locationToFind) { Shell[] shells = displayToSearch.getShells(); fixShellOrder(displayToSearch, shells); return findControl(shells, locationToFind); } /** * Finds the active shell and moves it to the end of the given array, so that * findControl() will find the controls from the active shell first. */ private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } // find the index of the active shell and exchange last one with active
* the position, in display coordinates, to be located * @return the most specific SWT control at the given location */ public static Control findControl(Display displayToSearch, Point locationToFind) { Shell[] shells = displayToSearch.getShells(); fixShellOrder(displayToSearch, shells); return findControl(shells, locationToFind); } /** * Finds the active shell and moves it to the end of the given array, so that * findControl() will find the controls from the active shell first. */ private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } // find the index of the active shell and exchange last one with active for (int i = 0; i < shells.length; i++) { if (shells[i] == activeShell) {
private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } // Find the index of the active shell and exchange last one with active for (int i = 0; i < shells.length; i++) { if (shells[i] == activeShell) { Shell toMove = shells[lastIndex]; shells[i] = toMove; shells[lastIndex] = activeShell; break; } }
* * All rights reserved. This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1.0 which * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model; import java.util.ArrayList; import java.util.List; /** * Generic TimeEvent implementation * * @author Matthew Khouzam * @since 4.3 */ public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; private final ITimeGraphEntry fEntry; private final long fTime; private final long fDuration; /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param duration * The duration of the event */ public TimeLineEvent(ITimeGraphEntry entry, long time, long duration) { this(entry, time, duration, new ArrayList<>()); } /**
int columns = headers.length; sheetWriter.startSheet(setPrimary.getName(), headers.length); sheetWriter.writeRow((Object[]) headers); for (DispoItem item : items) { Map<String, MCDCCoverageData> mcdcToCoverageData = new HashMap<>(); List<DispoAnnotationData> annotations = item.getAnnotationsList(); for (DispoAnnotationData annotation : annotations) { writeRowAnnotation(sheetWriter, columns, item, annotation, setPrimary.getName(), levelToResolutionTypesToCount, leveltoUnitToCovered, mcdcToCoverageData, levelsInSet); } } sheetWriter.endSheet(); // START COVER SHEET sheetWriter.startSheet("Cover Sheet", headers.length); List<String> coverSheetHeadersList = new ArrayList<>(); coverSheetHeadersList.add(" "); if (levelsInSet.contains(CoverageLevel.A)) { coverSheetHeadersList.add("MCDC"); } if (levelsInSet.contains(CoverageLevel.B)) { coverSheetHeadersList.add("Branch");
return null; } String contextPath = contextControllers.iterator().next().getContextPath(); requestURI = requestURI.substring(contextPath.length()); int pos = requestURI.lastIndexOf('/'); String servletPath = requestURI; String pathInfo = null; if (match == Match.CONTEXT_ROOT) { pathInfo = Const.SLASH; servletPath = Const.BLANK; } do { for (ContextController contextController : contextControllers) { DispatchTargets dispatchTargets = contextController.getDispatchTargets( null, requestURI, servletPath, pathInfo, extension, queryString, match, requestInfoDTO); if (dispatchTargets != null) { return dispatchTargets; } } if ((match == Match.EXACT) || (match == Match.CONTEXT_ROOT) || (match == Match.DEFAULT_SERVLET)) { break; } if (pos > -1) { String newServletPath = requestURI.substring(0, pos); pathInfo = requestURI.substring(pos);
// check for new pack files. If set to true (default) we use the // lastmodified attribute of the folder and assume that no new // pack files can be in this folder if his modification time has // not changed. boolean trustFolderStat = config.getBoolean( ConfigConstants.CONFIG_CORE_SECTION, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, true); if (force || (!trustFolderStat) || old.snapshot.isModified(packDirectory)) { PackList newList = scanPacks(old, force); return old != newList; } return false;
if (mapping != null) { Repository repository = mapping.getRepository(); if (repository != null) { try { createHeadLink(repository, composite); fillValues(repository); } catch (IOException e) { if (GitTraceLocation.UI.isActive()) GitTraceLocation.getTrace().trace( GitTraceLocation.UI.getLocation(), e.getMessage(), e); } } } return composite; } private void createHeadLink(final Repository repository, Composite composite) throws IOException { String fullBranch = repository.getFullBranch(); if (fullBranch != null) { objectId = repository.resolve(fullBranch); } if (objectId == null) { Text headLabel = createLabeledReadOnlyText(composite, UIText.GitProjectPropertyPage_LabelId); if (repository.getRefDatabase().getRefsByPrefix(RefDatabase.ALL) .isEmpty()) headLabel.setText(UIText.GitProjectPropertyPage_ValueEmptyRepository); else headLabel.setText(UIText.GitProjectPropertyPage_ValueUnbornBranch); } else { Hyperlink headLink = createHeadHyperLink(composite, UIText.GitProjectPropertyPage_LabelId);
private final Map<String, Object> nameMap; public CapabilityIndex(Iterator<IInstallableUnit> itor) { nameMap = new HashMap<>(300); namespaceMap = new HashMap<>(10); while (itor.hasNext()) { IInstallableUnit iu = itor.next(); Collection<IProvidedCapability> pcs = iu.getProvidedCapabilities(); for (IProvidedCapability pc : pcs) { namespaceMap.computeIfAbsent(pc.getNamespace(), namespace -> new HashSet<>()).add(iu); nameMap.compute(pc.getName(), (name, prev) -> { if (prev == null || prev == iu) { return iu; } else if (v instanceof IInstallableUnit) { Collection<IInstallableUnit> list = new HashSet<>(); list.add((IInstallableUnit) v); list.add(iu); return list; } else { ((Collection<IInstallableUnit>) v).add(iu); return v; } }); } } } private Object getRequirementIDs(IEvaluationContext ctx, IExpression requirement, Object queriedKeys) { switch (requirement.getExpressionType()) { case IExpression.TYPE_AND :
private static void collectMatchingIUs(Map<String, ?> indexToUse, String name, Collection<IInstallableUnit> collector) { Object v = indexToUse.get(name); if (v == null) return; if (v instanceof IInstallableUnit) collector.add((IInstallableUnit) v); else collector.addAll((Collection<IInstallableUnit>) v);
private void validatePage() { String message = null; if (userText.getText().trim().length() == 0) message = Messages.CredentialsWizardPage_ErrorUser; } else if (passwordText.getText().trim().isEmpty()) { message = Messages.CredentialsWizardPage_ErrorPassword; setErrorMessage(message); setPageComplete(message == null);
while (itor.hasNext()) { IInstallableUnit iu = itor.next(); Collection<IProvidedCapability> pcs = iu.getProvidedCapabilities(); for (IProvidedCapability pc : pcs) { namespaceMap.computeIfAbsent(pc.getNamespace(), n -> new HashSet<>()).add(iu); nameMap.compute(pc.getName(), (n, v) -> { if (v == null || v == iu) { return iu; } else if (prev instanceof IInstallableUnit) { Collection<IInstallableUnit> ius = new HashSet<>(); ius.add((IInstallableUnit) prev); ius.add(iu); return ius; } else { ((Collection<IInstallableUnit>) v).add(iu); return v; } }); } } } private Object getRequirementIDs(IEvaluationContext ctx, IExpression requirement, Object queriedKeys) { switch (requirement.getExpressionType()) { case IExpression.TYPE_AND : // AND is OK if at least one of the branches require the queried key for (IExpression expr : ExpressionUtil.getOperands(requirement)) {
public void createArtifact(@Nullable ArtifactToken parent, ArtifactToken artifact) { ArtifactToken art = createArtifact(artifact); if (parent != null) { addChild(parent, art); }
public boolean post (Event event) { /* * Get the operating system lock before synchronizing on the device * lock so that the device lock will not be held should another * thread already be in the operating system. This avoids deadlock * should the other thread need the device lock. */ Lock lock = OS.lock; lock.lock(); try { synchronized (Device.class) { if (isDisposed ()) error (SWT.ERROR_DEVICE_DISPOSED); if (event == null) error (SWT.ERROR_NULL_ARGUMENT); int type = event.type; switch (type) { case SWT.KeyDown: case SWT.KeyUp: { int keyCode = 0; long /*int*/ keysym = untranslateKey (event.keyCode); if (keysym != 0) keyCode = OS.XKeysymToKeycode (xDisplay, keysym); if (keyCode == 0) { char key = event.character;
import org.eclipse.uml2.uml.Type; import org.eclipse.uml2.uml.UMLFactory; import org.eclipse.uml2.uml.UMLPackage; /** * Utility class for <code>org.eclipse.uml2.uml.Package</code><BR> */ public class PackageUtil { /** * Extension of UML models (also declared in class UmlModel. This class is not accessible here, * since oep.uml.tools depends on oep.uml.tools.utils, but not vice versa */ public static final String UML_EXT = org.eclipse.papyrus.uml.tools.model.UmlModel.UML_FILE_EXTENSION; /** * Apply a profile and every subprofiles to a package. Also import types defined in profile * * @param profileToApply * profile to apply on package * @param package_ * on which profiles are applied * @param withSubProfiles * true if subprofiles must be automatically imported */ public static boolean applyProfile(org.eclipse.uml2.uml.Package package_, org.eclipse.uml2.uml.Profile profileToApply, boolean withSubProfiles) { // Returnstrue if the model was modified
public static Package getUserModel(ExecutionEvent event) { ServiceUtilsForHandlers serviceUtils = ServiceUtilsForHandlers.getInstance(); try { ModelSet modelSet = serviceUtils.getModelSet(event); URI uri = modelSet.getURIWithoutExtension().appendFileExtension(UML_EXT); Resource userResource = modelSet.getResource(uri, false); if (userResource != null && userResource.getContents().size() > 0) { EObject topEObj = userResource.getContents().get(0); if ((topEObj instanceof Package) && (!(topEObj instanceof Profile))) { return (Package) topEObj; } } } catch (ServiceException e) { Activator.log.error(e); } return null;
breakStatement.setSourceRange(statement.sourceStart, statement.sourceEnd - statement.sourceStart + 1); } if (statement.label != null) { final SimpleName name = new SimpleName(this.ast); name.internalSetIdentifier(new String(statement.label)); retrieveIdentifierAndSetPositions(statement.sourceStart, statement.sourceEnd, name); breakStatement.setLabel(name); } else if (statement.expression != null && this.ast.apiLevel >= AST.JLS12_INTERNAL) { final Expression expression= convert(statement.expression); breakStatement.setExpression(expression); int sourceEnd = statement.sourceEnd; if (sourceEnd == -1) { breakStatement.setSourceRange(statement.sourceStart, statement.sourceEnd - statement.sourceStart + 2); } else { breakStatement.setSourceRange(statement.sourceStart, sourceEnd - statement.sourceStart + 1); } } return breakStatement;
private void disposeIfExited(final Control control, MouseEvent e) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if(!bounds.contains(pt)) { tipShell.dispose(); } }
Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if(bounds.x == 0 && bounds.y== 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); } }
imgData.type = getImageFormat(loader); imgDataList.add(imgData); } else { // Image with multiple frames, iterate through each frame and convert // each frame to ImageData long /*int*/ start_time = OS.g_malloc(8); OS.g_get_current_time(start_time); long /*int*/ animation_iter = GDK.gdk_pixbuf_animation_get_iter (pixbuf_animation, start_time); int delay_time = 0; int time_offset = 0; // Fix the number of GIF frames as GdkPixbufAnimation does not provide an API to // determine number of frames. int num_frames = 32; for (int i = 0; i < num_frames; i++) { // Calculate time offset from start_time to next frame delay_time = GDK.gdk_pixbuf_animation_iter_get_delay_time (animation_iter); time_offset += delay_time; OS.g_time_val_add(start_time, time_offset * 1000); boolean update = GDK.gdk_pixbuf_animation_iter_advance (animation_iter, start_time); if (update) { long /*int*/ curr_pixbuf = GDK.gdk_pixbuf_animation_iter_get_pixbuf (animation_iter);
delay_time = GDK.gdk_pixbuf_animation_iter_get_delay_time (animation_iter); time_offset += delay_time; OS.g_time_val_add(start_time, time_offset * 1000); boolean update = GDK.gdk_pixbuf_animation_iter_advance (animation_iter, start_time); if (update) { long curr_pixbuf = GDK.gdk_pixbuf_animation_iter_get_pixbuf (animation_iter); long pixbuf_copy = GDK.gdk_pixbuf_copy(curr_pixbuf); // copy because curr_pixbuf might get disposed on next advance ImageData imgData = pixbufToImageData(pixbuf_copy); if (this.logicalScreenHeight == 0 && this.logicalScreenWidth == 0) { this.logicalScreenHeight = imgData.height; this.logicalScreenWidth = imgData.width; } imgData.type = getImageFormat(loader); imgData.delayTime = delay_time; imgDataList.add(imgData); } else { break; } } } ImageData [] imgDataArray = new ImageData [imgDataList.size()];
public ImageData[] load(String filename) { if (filename == null) SWT.error(SWT.ERROR_NULL_ARGUMENT); InputStream stream = null; try { stream = new FileInputStream(filename); return load(stream); } catch (IOException e) { SWT.error(SWT.ERROR_IO, e); } finally { try { if (stream != null) stream.close(); } catch (IOException e) { // Ignore error } } return null;
} } return imgData; } /** * Returns GdkPixbuf pointer by loading an image from filename (Java string) * @param filename * @return */ static long /*int*/ gdk_pixbuf_new_from_file(String filename) { int length = filename.length (); char [] chars = new char [length]; filename.getChars (0, length, chars, 0); byte [] buffer = Converter.wcsToMbcs(chars, true); return GDK.gdk_pixbuf_new_from_file(buffer, null); } /** * Convert java object ImageData to a new GdkPixbuf for saving * @param imgData * @return */ static long /*int*/ imageDataToPixbuf(ImageData imgData) { int colorspace = GDK.GDK_COLORSPACE_RGB; boolean has_alpha = imgData.alphaData != null; int width = imgData.width; int height = imgData.height; int rowstride = imgData.scanlinePad; long /*int*/ buffer_ptr = OS.g_malloc(imgData.data.length); C.memmove(buffer_ptr, imgData.data, imgData.data.length);
long /*int*/ [] len = new long /*int*/ [1]; if (type == null) SWT.error(SWT.ERROR_UNSUPPORTED_FORMAT); GDK.gdk_pixbuf_save_to_bufferv(pixbuf, buffer, len, type, null, null, null); byte[] byteArray = new byte[(int) len[0]]; C.memmove(byteArray, buffer[0], byteArray.length); try { stream.write(byteArray); } catch (IOException e) { SWT.error(SWT.ERROR_IO); }
/** * Abstract tool tip handler. * * @since 3.2 * @author Loic Prieur-Drevon - extracted from {@link TimeGraphTooltipHandler} */ public abstract class TmfAbstractToolTipHandler { private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; /** * Important note: this is being added to a display filter, this may leak, * make sure it is removed when not needed. */ private final Listener fListener = this::disposeIfExited; private void disposeIfExited(final Control control, Event e) { if (!control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) {
private void disposeIfExited(final Control control, Event e) { if (!control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); }
Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); }
createTooltipShell(timeGraphControl.getShell()); for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { // avoid displaying empty tool tips. return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); Display.getDefault().addFilter(SWT.MouseMove, fListener);
public static void beforeClass() { SWTBotUtils.initialize(); Thread.currentThread().setName("SWTBotTest"); /* set up for swtbot */ SWTBotPreferences.TIMEOUT = 60000; /* 60 second timeout */ SWTBotPreferences.KEYBOARD_LAYOUT = "EN_US"; SWTWorkbenchBot bot = new SWTWorkbenchBot(); SWTBotUtils.closeView("welcome", bot); /* Prepare the workspace */ prepareWorkspace(); /* Finish waiting for eclipse to load */ WaitUtils.waitForJobs(); /* Create project */ SWTBotUtils.createProject(PROJECT_NAME);
checkWidget (); if (listener == null) error (SWT.ERROR_NULL_ARGUMENT); if (eventTable == null) return; eventTable.unhook (SWT.Verify, listener); } @Override GdkRGBA getContextBackgroundGdkRGBA () { if (background != null && (state & BACKGROUND) != 0) { return background; } return defaultBackground(); } @Override void setBackgroundGdkRGBA (long /*int*/ context, long /*int*/ handle, GdkRGBA rgba) { if (GTK.GTK4) { background = rgba; } if (GTK.GTK4) { super.setBackgroundGdkRGBA(context, handle, rgba); } else { if (rgba == null) { background = defaultBackground(); } else { background = rgba; } String css; String properties; String name; name = GTK.GTK_VERSION >= OS.VERSION(3, 20, 0) ? "spinbutton" : "GtkSpinButton"; String color = display.gtk_rgba_to_css_string (background);
assertNotNull(testFile); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, testFile.getAbsolutePath(), TRACE_TYPE); fEditorBot = SWTBotUtils.activateEditor(fBot, testFile.getName()); fAbsolutePath = TmfTraceManager.getTemporaryDirPath() + File.separator + "exportToTsvTest.tsv"; TmfFileDialogFactory.setOverrideFiles(fAbsolutePath); } /** * Test full export * * @throws IOException * File not found or such */ @Test public void testExport() throws IOException { SWTBotEditor editorBot = fEditorBot; assertNotNull(editorBot); final SWTBotTable tableBot = editorBot.bot().table(); tableBot.getTableItem(1).contextMenu(EXPORT_TO_TSV).click(); File file = new File(fAbsolutePath); fBot.waitUntil(new FileLargerThanZeroCondition(file)); try (BufferedReader br = new BufferedReader(new FileReader(file))) { long lines = br.lines().count(); assertEquals("Line count", 23, lines); } finally { new File(fAbsolutePath).delete(); } } /**
assertNotNull(editorBot); final SWTBotTable tableBot = editorBot.bot().table(); tableBot.getTableItem(0).click(3); SWTBotText textBot = editorBot.bot().text(); textBot.typeText("LoggerA|LoggerB|LoggerC"); textBot.pressShortcut(Keystrokes.CTRL, Keystrokes.CR); fBot.waitUntil(Conditions.tableHasRows(tableBot, 6), 5000); tableBot.getTableItem(1).contextMenu(EXPORT_TO_TSV).click(); assertTsvContentsEquals(ImmutableList.of(HEADER_TEXT, EVENT1_TEXT, EVENT2_TEXT, EVENT3_TEXT)); } private static void assertTsvContentsEquals(final List<String> expected) throws FileNotFoundException, IOException { File file = new File(fAbsolutePath); fBot.waitUntil(new FileLargerThanZeroCondition(file)); try (BufferedReader br = new BufferedReader(new FileReader(file))) { List<String> lines = br.lines().collect(Collectors.toList()); assertEquals("File content", expected, lines); } finally { file.delete(); } } }
import org.eclipse.sirius.viewpoint.Messages; import com.google.common.base.Preconditions; /** * A class providing useful methods for refresh. * * @author mbats */ public final class RefreshHelper { private static List<Predicate<Notification>> impactingNotificationPredicates = new ArrayList<>(); /** * Prevent instantiation. */ private RefreshHelper() { } /** * Checks whether at least one change of which we are notified, concerns a semantic model or a specific graphical * change (registered through {@link #registerImpactingNotification(Predicate)}). * * @param notifications * the model changes. * @return <code>true</code> if the changes impact a semantic model or a specific graphical change. */ public static boolean isImpactingNotification(final Collection<Notification> notifications) { boolean isImpactingNotification = false; Set<EObject> alreadyDoneNotifiers = new HashSet<>(); for (Notification notification : notifications) { Object notifier = notification.getNotifier(); if (notifier instanceof EObject) { EObject eObjectNotifier = (EObject) notifier;
import org.eclipse.sirius.viewpoint.Messages; import com.google.common.base.Preconditions; /** * A class providing useful methods for refresh. * * @author mbats */ public final class RefreshHelper { private static List<Predicate<Notification>> impactingNotificationPredicates = new ArrayList<>(); /** * Prevent instantiation. */ private RefreshHelper() { } /** * Checks whether at least one change of which we are notified, concerns a semantic model or a specific graphical * change (registered through {@link #registerImpactingNotification(Predicate)}). * * @param notifications * the model changes. * @return <code>true</code> if the changes impact a semantic model or a specific graphical change. */ public static boolean isImpactingNotification(final Collection<Notification> notifications) { boolean isImpactingNotification = false; Set<EObject> alreadyDoneNotifiers = new HashSet<>(); for (Notification notification : notifications) { Object notifier = notification.getNotifier(); if (notifier instanceof EObject) { EObject eObjectNotifier = (EObject) notifier;
} } } return false; } /** * Checks whether this notification concerns a semantic model change or a specific graphical change (registered * through {@link #registerImpactingNotification(Predicate)}). * * @param notification * the model change. * @param notifier * the EObject which is concerned by this notification * @param alreadyDoneNotifiers * list of notifiers that have already been checked before * @param notifierWithResource * a cache map used to retrieve the resource from a notifier * @param notifierIsInAirdOrSrmResource * map cache that for a notifier has the result of the method * <code>ResourceQuery(Resource).isAirdOrSrmResource()</code> * @return <code>true</code> if the change impact a semantic model or a specific graphical change. */ protected static boolean isImpactingNotification(Notification notification, EObject notifier, Set<EObject> alreadyDoneNotifiers, Map<EObject, Resource> notifierWithResource, Map<EObject, Boolean> notifierIsInAirdOrSrmResource) { Resource notifierResource = notifierWithResource.get(notifier);
private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; /** * Important note: this is being added to a display filter, this may leak, * make sure it is removed when not needed. */ private final Listener fListener = this::disposeIfExited; /** * Dispose the shell if we exit the range. * * @param e * The event which occurred */ private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); bounds.x -= OFFSET; bounds.y -= OFFSET;
createTooltipShell(timeGraphControl.getShell()); for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { // avoid displaying empty tool tips. return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); Display display = Display.getDefault(); display.addFilter(SWT.MouseMove, fListener); display.addFilter(SWT.FocusOut, fListener);
private void createTooltipShell(Shell parent) { final Display display = parent.getDisplay(); if (fTipShell != null && !fTipShell.isDisposed()) { fTipShell.dispose(); } fTipShell = new Shell(parent, SWT.ON_TOP | SWT.TOOL); fTipShell.addDisposeListener(e -> e.display.removeFilter(SWT.MouseMove, fListener)); fTipShell.addDisposeListener(e -> e.display.removeFilter(SWT.FocusOut, fListener)); GridLayout gridLayout = new GridLayout(); gridLayout.numColumns = 2; gridLayout.marginWidth = 2; gridLayout.marginHeight = 2; fTipShell.setLayout(gridLayout); fTipShell.setBackground(display.getSystemColor(SWT.COLOR_INFO_BACKGROUND)); fTipComposite = new Composite(fTipShell, SWT.NONE); fTipComposite.setLayout(new GridLayout(3, false)); setupControl(fTipComposite);
public static void cleanUp() { SWTBotUtils.closeViewById(UML2DVIEW_ID, fBot); fFileLocation.delete(); SWTBotUtils.deleteProject(PROJECT_NAME, fBot); fLogger.removeAllAppenders();
public static void cleanUp() { fLogger.removeAllAppenders(); fFileLocation.delete(); tearDown();
for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { // avoid displaying empty tool tips. return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); Display display = Display.getDefault(); display.addFilter(SWT.MouseMove, fListener); display.addFilter(SWT.FocusOut, fFocusLostListener);
import org.eclipse.jdt.core.IJavaElement; import org.eclipse.jdt.core.IMethod; import org.eclipse.jdt.core.JavaModelException; import org.eclipse.jdt.core.dom.CompilationUnit; import org.eclipse.jdt.core.dom.ConstructorInvocation; import org.eclipse.jdt.core.dom.Expression; import org.eclipse.jdt.core.dom.IMethodBinding; import org.eclipse.jdt.core.dom.MethodInvocation; import org.eclipse.jdt.internal.corext.dom.HierarchicalASTVisitor; import org.eclipse.jdt.internal.ui.JavaPlugin; public class CalleeJavaMethodParameterVisitor extends HierarchicalASTVisitor { private final List<ICodeMining> minings; private final ICodeMiningProvider provider; public CalleeJavaMethodParameterVisitor(CompilationUnit cu, List<ICodeMining> minings, ICodeMiningProvider provider) { this.cu= cu; this.minings= minings; this.provider= provider; } @Override public boolean visit(ConstructorInvocation constructorInvocation) { List<?> arguments= constructorInvocation.arguments(); if (!arguments.isEmpty()) { IMethod method = resolveMethodBinding(constructorInvocation.resolveConstructorBinding()); collectParameterNamesCodeMinings(method, arguments); } return super.visit(constructorInvocation); } @Override
String targets[] = { "peer1", "peer2" }; try (BufferedRandomAccessFile braf = new BufferedRandomAccessFile(fFileLocation, "rw")) { braf.writeBytes(TRACE_START); for (int i = 0; i < 20000; i++) { braf.writeBytes(makeEvent(i * 100, eventNames[i % 2], targets[i % 2], targets[(i + 1) % 2], Integer.toString(i % 2 + 1000))); } braf.writeBytes(TRACE_END); } /** * Open a trace in an editor */ public static void beforeTest() { SWTBotUtils.createProject(PROJECT_NAME); SWTBotTreeItem treeItem = SWTBotUtils.selectTracesFolder(fBot, PROJECT_NAME); assertNotNull(treeItem); SWTBotUtils.openTrace(PROJECT_NAME, fFileLocation.getAbsolutePath(), XMLSTUB_ID); SWTBotUtils.openView(UML2DVIEW_ID); } /** * Delete the file */ @AfterClass public static void cleanUp() { SWTBotUtils.closeViewById(UML2DVIEW_ID, fBot); fFileLocation.delete();
public void tearDown() { fBot.closeAllEditors();
fBot = new SWTWorkbenchBot(); /* finish waiting for eclipse to load */ WaitUtils.waitForJobs(); fFileLocation = File.createTempFile("sample", ".xml"); try (BufferedRandomAccessFile braf = new BufferedRandomAccessFile(fFileLocation, "rw")) { braf.writeBytes(TRACE_START); for (int i = 0; i < 100; i++) { braf.writeBytes(makeEvent(i * 100, i % 4)); } braf.writeBytes(TRACE_END); } /* Creating project and open the trace */ SWTBotUtils.createProject(PROJECT_NAME); SWTBotTreeItem treeItem = SWTBotUtils.selectTracesFolder(fBot, PROJECT_NAME); assertNotNull(treeItem); SWTBotUtils.openTrace(PROJECT_NAME, fFileLocation.getAbsolutePath(), XMLSTUB_ID); SWTBotUtils.openView(ColorsView.ID); } /** * Delete the file */ @AfterClass public static void cleanUp() { fLogger.removeAllAppenders(); fFileLocation.delete(); tearDown(); } /** * Close the editor
public static void cleanUp() { fLogger.removeAllAppenders(); fFileLocation.delete();
mgr.addJobChangeListener(changeListener); for (int i = 0; i < 5; i++) { SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); // Add little delay so that treads have a chance to start SWTBotUtils.delay(1000); workbenchbot.closeAllEditors(); if (!status.isOK()) { SWTBotUtils.deleteProject(TRACE_PROJECT_NAME, workbenchbot); fail(handleErrorStatus(status)); } } SWTBotUtils.deleteProject(TRACE_PROJECT_NAME, workbenchbot);
IKernelTrace trace = new TmfXmlKernelTraceStub(); IPath filePath = Activator.getAbsoluteFilePath(CPU_USAGE_FILE); IStatus status = trace.validate(null, filePath.toOSString()); if (!status.isOK()) { fail(status.getException().getMessage()); } try { trace.initTrace(null, filePath.toOSString(), TmfEvent.class); } catch (TmfTraceException e) { fail(e.getMessage()); } deleteSuppFiles(trace); ((TmfTrace) trace).traceOpened(new TmfTraceOpenedSignal(this, trace, null)); /* * FIXME: Make sure this analysis is finished before running the CPU * analysis. This block can be removed once analysis dependency and * request precedence is implemented */ IAnalysisModule module = null; for (IAnalysisModule mod : TmfTraceUtils.getAnalysisModulesOfClass(trace, TidAnalysisModule.class)) { module = mod; } assertNotNull(module); module.schedule(); module.waitForCompletion(); /* End of the FIXME block */ fModule = TmfTraceUtils.getAnalysisModuleOfClass(trace, KernelCpuUsageAnalysis.class, KernelCpuUsageAnalysis.ID);
public static void setUp() { ITmfTrace trace = KERNEL_TEST_CASE.getKernelTrace(); deleteSuppFiles(trace); ((TmfTrace) trace).traceOpened(new TmfTraceOpenedSignal(this, trace, null)); IAnalysisModule module = null; for (IAnalysisModule mod : TmfTraceUtils.getAnalysisModulesOfClass(trace, KernelAnalysisModule.class)) { module = mod; } assertNotNull(module); module.schedule(); module.waitForCompletion(); fModule = TmfTraceUtils.getAnalysisModuleOfClass(trace, KernelAnalysisModule.class, KernelAnalysisModule.ID); fTrace = trace;
* for a description of the problem. * <p> * XXX remove once the underlying problem (https://bugs.eclipse.org/bugs/show_bug.cgi?id=66176) is solved. * </p> */ private final Object fReconcilerLock= new Object(); /** * The templates page. * @since 3.4 */ private JavaTemplatesPage fTemplatesPage; /** * The Java reconciling listener used to update code minings */ private IJavaReconcilingListener fCodeMiningsReconcilingListener; /** * Creates a new compilation unit editor. */ public CompilationUnitEditor() { setDocumentProvider(JavaPlugin.getDefault().getCompilationUnitDocumentProvider()); setEditorContextMenuId("#CompilationUnitEditorContext"); //$NON-NLS-1$ setRulerContextMenuId("#CompilationUnitRulerContext"); //$NON-NLS-1$ setOutlinerContextMenuId("#CompilationUnitOutlinerContext"); //$NON-NLS-1$ // don't set help contextId, we install our own help context fSavePolicy= null; fJavaEditorErrorTickUpdater= new JavaEditorErrorTickUpdater(this); fCorrectionCommands= null;
* are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation *******************************************************************************/ package org.eclipse.jdt.ui.tests.activation; import java.util.Arrays; import java.util.HashSet; import java.util.Set; import org.junit.Assert; import org.osgi.framework.Bundle; import org.eclipse.jdt.testplugin.JavaProjectHelper; import org.eclipse.core.runtime.Platform; import org.eclipse.ui.IWorkbench; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.PlatformUI; import org.eclipse.jdt.core.ICompilationUnit; import org.eclipse.jdt.core.IJavaProject; import org.eclipse.jdt.core.IPackageFragment; import org.eclipse.jdt.core.IPackageFragmentRoot; import org.eclipse.jdt.internal.ui.javaeditor.EditorUtility; import junit.framework.TestCase; public class JavaActivationTest extends TestCase { private IJavaProject project;
//import org.junit.Assert; import org.osgi.framework.Bundle; import org.eclipse.jdt.testplugin.JavaProjectHelper; import org.eclipse.core.runtime.Platform; import org.eclipse.ui.IWorkbench; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.PlatformUI; import org.eclipse.jdt.core.ICompilationUnit; import org.eclipse.jdt.core.IJavaProject; import org.eclipse.jdt.core.IPackageFragment; import org.eclipse.jdt.core.IPackageFragmentRoot; import org.eclipse.jdt.internal.ui.javaeditor.EditorUtility; import junit.framework.TestCase; public class JavaActivationTest extends TestCase { private IJavaProject project; private static final String[] inactiveBundles= new String[] { "org.apache.xerces", "org.eclipse.jdt.astview", "org.eclipse.jdt.jeview", "org.eclipse.reftracker", "org.eclipse.swt.sleak", "org.eclipse.swt.spy", "com.jcraft.jsch", "javax.servlet", "javax.servlet.jsp", "org.apache.ant", "org.apache.commons.el", "org.apache.commons.logging", "org.apache.jasper", "org.apache.lucene", "org.apache.lucene.analysis",
IPackageFragment pack= sourceFolder.createPackageFragment("pack0", false, null); StringBuffer buf= new StringBuffer(); buf.append("package pack0;\n"); buf.append("public class List1 {\n}\n"); return pack.createCompilationUnit("List1.java", buf.toString(), false, null); } public void testOpenJavaEditor() throws Exception { ICompilationUnit unit= createTestCU(); EditorUtility.openInEditor(unit); Set<String> set= new HashSet<>(Arrays.asList(inactiveTestBundles)); checkNotLoaded(set); } public void checkNotLoaded(Set inactiveBundles) { Bundle bundle= Platform.getBundle("org.eclipse.jdt.ui.tests"); Bundle[] bundles= bundle.getBundleContext().getBundles(); for (int i= 0; i < bundles.length; i++) { if (bundles[i].getState() == Bundle.ACTIVE && inactiveBundles.contains(bundles[i].getSymbolicName())) { Assert.fail ("plugin should not be activated: "+bundles[i].getSymbolicName()) ; } } } }
private static IType createAutoType(ICPPASTInitializerClause initClause, IASTDeclSpecifier declSpec, IASTDeclarator declarator) { // C++0x: 7.1.6.4 IType type = AutoTypeResolver.AUTO_TYPE; IType initType = null; ValueCategory valueCat= null; ICPPClassTemplate initializer_list_template = null; if (initClause instanceof ICPPASTInitializerList) { initializer_list_template = get_initializer_list(declSpec); if (initializer_list_template == null) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } type = (IType) CPPTemplates.instantiate(initializer_list_template, new ICPPTemplateArgument[] { new CPPTemplateTypeArgument(type) }, initClause); if (type instanceof IProblemBinding) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } } type = decorateType(type, declSpec, declarator); final ICPPEvaluation evaluation = initClause.getEvaluation(); initType= evaluation.getTypeOrFunctionSet(declarator); valueCat= evaluation.getValueCategory(declarator);
} return recreate(ref, newLeaf, hasVersioning()); } Ref doPeel(Ref leaf) throws MissingObjectException, IOException { try (RevWalk rw = new RevWalk(repository)) { RevObject obj = rw.parseAny(leaf.getObjectId()); if (obj instanceof RevTag) { return new ObjectIdRef.PeeledTag( leaf.getStorage(), leaf.getName(), leaf.getObjectId(), rw.peel(obj).copy(), hasVersioning() ? leaf.getUpdateIndex() : UNDEFINED_UPDATE_INDEX); } else { return new ObjectIdRef.PeeledNonTag( leaf.getStorage(), leaf.getName(), leaf.getObjectId(), hasVersioning() ? leaf.getUpdateIndex() : Ref.UNDEFINED_UPDATE_INDEX); } } } static Ref recreate(Ref old, Ref leaf, boolean hasVersioning) { if (old.isSymbolic()) { Ref dst = recreate(old.getTarget(), leaf, hasVersioning); return new SymbolicRef(old.getName(), dst, hasVersioning ? old.getUpdateIndex()
*/ public abstract class TmfAbstractToolTipHandler { private static final int MOUSE_DEADZONE = 5; private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; /** * Important note: this is being added to a display filter, this may leak, * make sure it is removed when not needed. */ private final Listener fListener = this::disposeIfExited; private final Listener fFocusLostListener = event -> { Shell tipShell = fTipShell; if (tipShell!= null) { tipShell.dispose(); } }; /** * Dispose the shell if we exit the range. * * @param e * The event which occurred */ private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell;
private static final int MOUSE_DEADZONE = 5; private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; /** * Important note: this is being added to a display filter, this may leak, * make sure it is removed when not needed. */ private final Listener fListener = this::disposeIfExited; private final Listener fFocusLostListener = event -> { Shell tipShell = fTipShell; if (tipShell!= null) { tipShell.dispose(); } }; /** * Dispose the shell if we exit the range. * * @param e * The event which occurred */ private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell;
} return result; } /** * Sets the completion proposal categories which are excluded from the * default proposal list and reloads the registry. * * @param categories the array with the IDs of the excluded categories * @see #CODEASSIST_EXCLUDED_CATEGORIES * @since 3.4 */ public static void setExcludedCompletionProposalCategories(String[] categories) { Assert.isLegal(categories != null); StringBuilder buf= new StringBuilder(50 * categories.length); for (String category : categories) { buf.append(category); buf.append('\0'); } getPreferenceStore().setValue(CODEASSIST_EXCLUDED_CATEGORIES, buf.toString()); CompletionProposalComputerRegistry.getDefault().reload(); } /** * Returns the value for the given key in the given context. * @param key The preference key * @param project The current context or <code>null</code> if no context is available and the * workspace setting should be taken. Note that passing <code>null</code> should * be avoided.
public boolean visit(ConstructorInvocation constructorInvocation) { List<?> arguments= constructorInvocation.arguments(); if (!arguments.isEmpty()) { IMethodBinding constructorBinding= constructorInvocation.resolveConstructorBinding(); if (constructorBinding != null) { IMethod method = resolveMethodBinding(constructorBinding); collectParameterNamesCodeMinings(method, arguments, constructorBinding.isVarargs()); } } return super.visit(constructorInvocation);
public boolean visit(MethodInvocation methodInvocation) { List<?> arguments= methodInvocation.arguments(); if (!arguments.isEmpty()) { IMethodBinding methodBinding= methodInvocation.resolveMethodBinding(); if (methodBinding != null) { IMethod method = resolveMethodBinding(methodBinding); collectParameterNamesCodeMinings(method, arguments, methodBinding.isVarargs()); } } return super.visit(methodInvocation);
***************************************************************************** * Copyright (c) 2010-2019, Tamas Szabo, itemis AG, Gabor Bergmann, IncQuery Labs Ltd. * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v. 2.0 which is available at * http://www.eclipse.org/legal/epl-v20.html. * * SPDX-License-Identifier: EPL-2.0 *******************************************************************************/ package org.eclipse.viatra.query.runtime.matchers.memories; /** * Represents a replacement between timestamps. * Either the old or the new timestamp can be null, but not at the same time. * * @author Tamas Szabo */ public class TimestampReplacement<Timestamp extends Comparable<Timestamp>> { public final Timestamp oldValue; public final Timestamp newValue; public TimestampReplacement(final Timestamp oldValue, final Timestamp newValue) { if (oldValue == null && newValue == null) { throw new IllegalArgumentException("Old and new cannot be both null at the same time!"); } this.oldValue = oldValue; this.newValue = newValue; } }
* This program and the accompanying materials are made available under the * terms of the Eclipse Public License v. 2.0 which is available at * http://www.eclipse.org/legal/epl-v20.html. * * SPDX-License-Identifier: EPL-2.0 *******************************************************************************/ package org.eclipse.viatra.query.runtime.matchers.memories; /** * Represents a replacement between timestamps. * Either the old or the new timestamp can be null, but not at the same time. * * @author Tamas Szabo */ public class TimestampReplacement<Timestamp extends Comparable<Timestamp>> { public final Timestamp oldValue; public final Timestamp newValue; public TimestampReplacement(final Timestamp oldValue, final Timestamp newValue) { if (oldValue == null && newValue == null) { throw new IllegalArgumentException("Old and new cannot be both null at the same time!"); } this.oldValue = oldValue; this.newValue = newValue; } }
*************************************************************************** * Copyright (c) 2019 CEA LIST and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Vincent Lorenzo (CEA LIST) vincent.lorenzo@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.model2doc.core.generatorconfiguration.operations; import org.eclipse.emf.common.util.URI; import org.eclipse.osgi.util.NLS; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentStructureGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.internal.Activator; /** * utility class for the operations of GeneratorConfiguration metamodel */ public class GeneratorConfigurationOperations { /** * * @param generatorConfiguration * a generatorConfiguration element * @param uriKind * the kind of expected URI * @param fileExtension
* * SPDX-License-Identifier: EPL-2.0 * * Contributors: * CEA LIST - Initial API and implementation * *****************************************************************************/ package org.eclipse.papyrus.model2doc.core.generatorconfiguration.operations; import org.eclipse.emf.common.util.URI; import org.eclipse.osgi.util.NLS; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentStructureGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.internal.Activator; /** * Utility class for the operations of GeneratorConfiguration metamodel */ public class GeneratorConfigurationOperations { /** * * @param generatorConfiguration * a generatorConfiguration element * @param uriKind * the kind of expected URI * @param fileExtension * the extension file * @return * the path of the file build from the paramaters */ public static final String getDocumentStructureFileEcoreURI(final DefaultDocumentStructureGeneratorConfiguration generatorConfiguration, final String fileExtension) { final String folderName = generatorConfiguration.getStructureFolder(); final String documentName = generatorConfiguration.getDocumentName();
return newURI.toString(); } if (false == uri.isPlatform()) { // we convert a local URI as platform resource URI final String projectName = generatorConfiguration.eResource().getURI().segment(1); uri = URI.createPlatformResourceURI(projectName, true).appendSegment(folderName); } if (uri.isPlatform()) { if (uri.isPlatformPlugin()) { Activator.log.warn(NLS.bind("The path {0} must not be a platform path", uri.toString())); //$NON-NLS-1$ return null; } return uri.appendSegment(documentName).appendFileExtension(fileExtension).toString(); } return null; } /** * TODO : check if used! * * @param configuration * @param fileExtension * @return */ public static final String getDocumentFileOSURI(final DefaultDocumentGeneratorConfiguration configuration, final String fileExtension) { final String folderName = configuration.getDocumentFolder(); final String documentName = configuration.getDocumentName(); URI uri = URI.createURI(folderName);
return newURI.toString(); } if (false == uri.isPlatform()) { // we convert a local URI as platform resource URI final String projectName = configuration.eResource().getURI().segment(1); uri = URI.createPlatformResourceURI(projectName, true).appendSegment(folderName); } if (uri.isPlatform()) { if (uri.isPlatformPlugin()) { Activator.log.warn(NLS.bind("The path {0} must not be a platform path", uri.toString())); //$NON-NLS-1$ return null; } uri = uri.appendSegment(documentName).appendFileExtension(fileExtension); } return null; } }
private static ITmfTrace fNewExperiment; // ------------------------------------------------------------------------ // Test instance maintenance // ------------------------------------------------------------------------ /** * Default constructor */ public CtfTmfExperimentTrimmingTest() { // do nothing } /** * Setup before the test suite * * @throws IOException * failed to load the file */ @BeforeClass public static void beforeClass() throws IOException { SWTBotUtils.initialize(); /* set up for swtbot */ SWTBotPreferences.TIMEOUT = 50000; /* 50 second timeout */ fLogger.removeAllAppenders(); fLogger.addAppender(new NullAppender()); File parentDir = FileUtils.toFile(FileLocator.toFileURL(CtfTestTrace.TRACE_EXPERIMENT.getTraceURL())); File[] traceFiles = parentDir.listFiles(); ITmfTrace traceValidator = new CtfTmfTrace(); fBot = new SWTWorkbenchBot(); SWTBotUtils.createProject(PROJECT_NAME); int openedTraces = 0; for (File traceFile : traceFiles) { String absolutePath = traceFile.getAbsolutePath(); if (traceValidator.validate(null, absolutePath).isOK()) {
protected boolean hasJREInClassPath(IJavaProject javaProject) { if (javaProject != null) { try { IClasspathEntry[] oldClasspaths= javaProject.getRawClasspath(); for (int i= 0; i < oldClasspaths.length; i++) { if (isJREContainer(oldClasspaths[i].getPath())) { return true; } } } catch (JavaModelException e) { // do nothing } } return false;
getRequirementFilter(symbolicName, versionRange)); Collection<BundleCapability> matchingBundleCapabilities = fwkWiring.findProviders(ModuleContainer .createRequirement(IdentityNamespace.IDENTITY_NAMESPACE, directives, Collections.emptyMap())); if (matchingBundleCapabilities.isEmpty()) { return null; } Bundle[] results = matchingBundleCapabilities.stream().map(c -> c.getRevision().getBundle()) // Remove all the bundles that are installed or uninstalled .filter(bundle -> (bundle.getState() & (Bundle.INSTALLED | Bundle.UNINSTALLED)) == 0) .sorted((b1, b2) -> b2.getVersion().compareTo(b1.getVersion())) // highest version first .toArray(Bundle[]::new); return results.length > 0 ? results : null;
try { XMultiServiceFactory xMultiServiceFactory = odtEditor.getXMultiServiceFactory(); // create a text table Object obj = xMultiServiceFactory.createInstance("com.sun.star.text.TextTable"); // $NON-NLS-1$ XTextTable textTable = UnoRuntime.queryInterface(XTextTable.class, obj); // Default background color Object backColor = 0x6AA84F; // // If defined style then update backColor if (style != null) { backColor = style; } if (numCols > 0) { // Verify if there are row titles if (table.getRowTitles() != null && !table.getRowTitles().isEmpty()) { // update column counters numCols++; } // Verify if there are column titles if (table.getColumnTitles() != null && !table.getColumnTitles().isEmpty()) { // update row counter numRows++; } // Initialize and add table textTable.initialize(numRows, numCols); addTextContent(xTextCursor, textTable); endParagraph(xTextCursor);
/** * Returns {@code true} if the value of the expression depends on template parameters. */ boolean isValueDependent(); /** * Returns {@code true} if the expression is a compile-time constant expression. * * @param point the point of instantiation, determines the scope for name lookups */ boolean isConstantExpression(); /** * Return the result of the noexcept-operator applied to the expression. * [expr.unary.noexcept] * @param inCalledContext {@code true} if the evaluation is the target of a function call */ boolean isNoexcept(boolean inCalledContext); /** * Returns {@code true} if this expression is equivalent to 'other' for * declaration matching purposes. */ boolean isEquivalentTo(ICPPEvaluation other); /** * Returns the type of the expression. * * If the expression evaluates to a function set, a {@code FunctionSetType} is returned. */ IType getType(); /** * Returns the value of the expression. */ IValue getValue(); /**
public boolean isNoexcept(boolean inCalledContext) { return true;
public boolean isNoexcept(boolean inCalledContext) { return fPositive.isNoexcept(inCalledContext) && fNegative.isNoexcept(inCalledContext);
public boolean isNoexcept(boolean inCalledContext) { // assert false; // TODO this assert is hit return true;
public boolean isNoexcept(boolean inCalledContext) { assert false; return true;
public boolean isNoexcept(boolean inCalledContext) { return true;
public boolean isNoexcept(boolean inCalledContext) { assert false; return true;
private void ensureSize(int index) { List<@Nullable IEventDeclaration> list = fEvents; if (list instanceof ArrayList) { if (index > 50000) { fEvents = new SparseList(fEvents); } ((ArrayList<@Nullable IEventDeclaration>) list).ensureCapacity(index); while (list.size() <= index) { list.add(null); } } else if( list instanceof SparseList) { SparseList sparseList = (SparseList) list; sparseList.ensureSize(index); }
public SparseList(List<@Nullable IEventDeclaration> events) { for (int i = 0; i < events.size(); i++) { IEventDeclaration event = events.get(i); if(event!= null) { add(i, event); } }
public boolean add(@Nullable IEventDeclaration e) { synchronized (this) { fInnerEvents.put(fSize, e); fSize++; } return true;
public boolean addAll(int index, Collection<? extends @Nullable IEventDeclaration> c) { int key= index; for (IEventDeclaration event : c) { if (event!= null) { add(key, event); } key++; } return true;
public void add(int index, @Nullable IEventDeclaration element) { if (index > fSize) { fSize = index; } add(element);
*/ public class Text extends Scrollable { int tabs, oldStart, oldEnd; boolean doubleClick, ignoreModify, ignoreVerify, ignoreCharacter, allowPasswordChar; String message; int[] segments; int clearSegmentsCount = 0; RECT searchRect, cancelRect; boolean mouseInSearch, mouseInCancel; static final char LTR_MARK = '\u200e'; static final char RTL_MARK = '\u200f'; static final int IDI_SEARCH = 101; static final int IDI_CANCEL = 102; static final int SEARCH_ICON_MARGIN = 4; /** * The maximum number of characters that can be entered * into a text widget. * <p> * Note that this value is platform dependent, based upon * the native widget implementation. * </p> */ public static final int LIMIT; /** * The delimiter used by multi-line text widgets. When text * is queried and from the widget, it will be delimited using * this delimiter. */ public static final String DELIMITER; /* * This code is intentionally commented.
* header until end of trailer. * * @return time in milliseconds spent writing the pack output, from start of * header until end of trailer. The transfer speed can be * approximated by dividing {@link #getTotalBytes()} by this value. */ public long getTimeWriting() { return statistics.timeWriting; } /** * @return number of trees traversed in the walk when writing the pack. * @since 5.4 */ public long getTreesTraversed() { return statistics.treesTraversed; } /** * Get total time spent processing this pack. * * @return total time spent processing this pack. */ public long getTimeTotal() { return statistics.timeCounting + statistics.timeSearchingForReuse + statistics.timeSearchingForSizes + statistics.timeCompressing + statistics.timeWriting; } /** * Get the average output speed in terms of bytes-per-second. *
***************************************************************************** * Copyright (c) 2017, 2019 Ericsson * * All rights reserved. This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1.0 which * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.tmf.ui.viewers; import org.eclipse.swt.SWT; import org.eclipse.swt.events.MouseEvent; import org.eclipse.swt.events.MouseTrackAdapter; import org.eclipse.swt.graphics.Point; import org.eclipse.swt.graphics.Rectangle; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.layout.GridLayout; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Control; import org.eclipse.swt.widgets.Display; import org.eclipse.swt.widgets.Event; import org.eclipse.swt.widgets.Label; import org.eclipse.swt.widgets.Listener; import org.eclipse.swt.widgets.Shell; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.widgets.TimeGraphTooltipHandler; /** * Abstract tool tip handler. * * @since 3.2
final Display display = parent.getDisplay(); if (fTipShell != null && !fTipShell.isDisposed()) { fTipShell.dispose(); } fTipShell = new Shell(parent, SWT.ON_TOP | SWT.TOOL); // Deregister display filters on dispose fTipShell.addDisposeListener(e -> e.display.removeFilter(SWT.MouseMove, fListener)); fTipShell.addDisposeListener(e -> e.display.removeFilter(SWT.FocusOut, fFocusLostListener)); fTipShell.addListener(SWT.Deactivate, e -> { if (!fTipShell.isDisposed()) { fTipShell.dispose(); } }); GridLayout gridLayout = new GridLayout(); gridLayout.numColumns = 2; gridLayout.marginWidth = 2; gridLayout.marginHeight = 2; fTipShell.setLayout(gridLayout); fTipShell.setBackground(display.getSystemColor(SWT.COLOR_INFO_BACKGROUND)); fTipComposite = new Composite(fTipShell, SWT.NONE); fTipComposite.setLayout(new GridLayout(3, false)); setupControl(fTipComposite);
private boolean considerBinding(IBinding binding, ASTNode node) { if (!(binding instanceof IVariableBinding)) return false; boolean result= Bindings.equals(fFieldBinding, ((IVariableBinding)binding).getVariableDeclaration()); if (!result || fEncapsulateDeclaringClass) return result; AbstractTypeDeclaration type= ASTNodes.getParent(node, AbstractTypeDeclaration.class); if (type != null) { ITypeBinding declaringType= type.resolveBinding(); return !Bindings.equals(fDeclaringClassBinding, declaringType); } return true;
invocation.setName(ast.newSimpleName(fSetter)); if (receiver != null) invocation.setExpression((Expression)fRewriter.createCopyTarget(receiver)); invocation.arguments().add(argument); if ("++".equals(operator)) { //$NON-NLS-1$ argument.setOperator(InfixExpression.Operator.PLUS); } else if ("--".equals(operator)) { //$NON-NLS-1$ argument.setOperator(InfixExpression.Operator.MINUS); } else { Assert.isTrue(false, "Should not happen"); //$NON-NLS-1$ } MethodInvocation getter= ast.newMethodInvocation(); getter.setName(ast.newSimpleName(fGetter)); if (receiver != null) getter.setExpression((Expression)fRewriter.createCopyTarget(receiver)); argument.setLeftOperand(getter); argument.setRightOperand(ast.newNumberLiteral("1")); //$NON-NLS-1$ fReferencingGetter= true; return invocation;
if (fEncapsulateDeclaringClass) comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_use_accessors); else comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_do_not_use_accessors); if (fGenerateJavadoc) comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_generate_comments); final EncapsulateFieldDescriptor descriptor= RefactoringSignatureDescriptorFactory.createEncapsulateFieldDescriptor(project, description, comment.asString(), arguments, flags); arguments.put(JavaRefactoringDescriptorUtil.ATTRIBUTE_INPUT, JavaRefactoringDescriptorUtil.elementToHandle(project, fField)); arguments.put(ATTRIBUTE_VISIBILITY, Integer.valueOf(fVisibility).toString()); arguments.put(ATTRIBUTE_INSERTION, Integer.valueOf(fInsertionIndex).toString()); if (fCreateSetter) { arguments.put(ATTRIBUTE_SETTER, fSetterName); } if (fCreateGetter) { arguments.put(ATTRIBUTE_GETTER, fGetterName); } arguments.put(ATTRIBUTE_COMMENTS, Boolean.valueOf(fGenerateJavadoc).toString()); arguments.put(ATTRIBUTE_DECLARING, Boolean.valueOf(fEncapsulateDeclaringClass).toString()); final DynamicValidationRefactoringChange result= new DynamicValidationRefactoringChange(descriptor, getName()); TextChange[] changes= fChangeManager.getAllChanges(); pm.beginTask(NO_NAME, changes.length);
//extern "C"{ //void func(); //} public void testLinkage2_Bug299482() throws Exception { fOptions.put(DefaultCodeFormatterConstants.FORMATTER_INSERT_SPACE_BEFORE_OPENING_BRACE_IN_LINKAGE_DECLARATION, DefaultCodeFormatterConstants.FALSE); assertFormatterResult(); } //extern "C" { //void func(); //} //extern "C" //{ //void func(); //} public void testLinkage3_Bug299482() throws Exception { fOptions.put(DefaultCodeFormatterConstants.FORMATTER_BRACE_POSITION_FOR_LINKAGE_DECLARATION, DefaultCodeFormatterConstants.NEXT_LINE); assertFormatterResult(); } //#define EMPTY1(x) //#define EMPTY2(x) //int main() { // EMPTY1(bool x = true); // EMPTY2(bool x = true); // return 0; //} //#define EMPTY1(x) //#define EMPTY2(x) //int main() { // EMPTY1(bool x = true); // EMPTY2(bool x = true); // return 0; //} public void testEmptyMacros_Bug361768() throws Exception { assertFormatterResult(); }
***************************************************************************** * Copyright (c) 2015, 2019 Obeo. * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *******************************************************************************/ package org.eclipse.sirius.tests.sample.component.service; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.List; import java.util.function.Predicate; import org.eclipse.emf.common.notify.Notification; import org.eclipse.emf.ecore.EObject; import org.eclipse.gmf.runtime.notation.DrawerStyle; import org.eclipse.gmf.runtime.notation.Node; import org.eclipse.gmf.runtime.notation.NotationPackage; import org.eclipse.sirius.diagram.DDiagram; import org.eclipse.sirius.diagram.DDiagramElement; import org.eclipse.sirius.diagram.DNodeContainer; import org.eclipse.sirius.diagram.business.api.query.EObjectQuery; import org.eclipse.sirius.diagram.ui.business.api.view.SiriusGMFHelper; import org.eclipse.sirius.ext.base.Option;
components.addAll(component.getReferences2()); for (Component child : component.getChildren()) { components.addAll(getReference2Hierarchy(child)); } return components; } /** * A reference is to display if: * <UL> * <LI>the source is not collapsed and the target is not collapsed and there is no "shortest reference" to * display</LI> * <LI></LI> * <LI></LI> * </UL> * * @param source * Semantic element corresponding to the source of the reference * @param sourceView * @param targetView * @return */ public boolean isReferenceToDisplay(Component source, DNodeContainer sourceView, DNodeContainer targetView) { if (!isIndirectlyCollapsed(sourceView) && !isIndirectlyCollapsed(targetView)) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer) { if (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion")) { for (DDiagramElement child2 : ((DNodeContainer) child).getOwnedDiagramElements()) {
if (isReferenceDisplayByChild((Component) child2.getTarget(), (DNodeContainer) child2, targetView)) { return true; } } } } } return true; } return false; } protected boolean isIndirectlyCollapsed(DNodeContainer container) { if (isContainerCollapsed(container)) { return true; } else if (container.eContainer() instanceof DNodeContainer && isContainerCollapsed((DNodeContainer) container.eContainer())) { return true; } else { return false; } } protected boolean isContainerCollapsed(DNodeContainer container) { Node gmfNode = SiriusGMFHelper.getGmfNode(container); if (gmfNode != null) { for (Object subNode : gmfNode.getChildren()) { if (subNode instanceof Node) { for (Object style : ((Node) subNode).getStyles()) { if (style instanceof DrawerStyle) { return ((DrawerStyle) style).isCollapsed(); } } } } } return false; } private void appendChildren(Component component, Collection<Component> allChildren) {
SWTBotGefEditPart parentEdgeTargetEditPart = editor.getEditPart("DC.2.1", AbstractDiagramElementContainerEditPart.class); DEdgeEditPart edgeEditPart = (DEdgeEditPart) ((AbstractDiagramElementContainerEditPart) edgeSourceEditPart.part()).getSourceConnections().get(0); assertTrue("The edge should be visible after diagram opening.", edgeEditPart.getFigure().isVisible()); collapseOrExpandContainer(parentEdgeSourceEditPart); // Check that the original edge is no longer visible but is always here assertFalse("The edge should be hidden after collapsing the container of the target of the edge.", edgeEditPart.getFigure().isVisible()); assertEquals("The edge already exists, even if it is not visible.", 1, ((AbstractDiagramElementContainerEditPart) edgeSourceEditPart.part()).getSourceConnections().size()); // Check that no other edge appears (because the collapse notification has not yet been registered) assertEquals("No edge from the collapsed container should appear because the collapse notification has not yet been registered.", 0,
private void collapseOrExpandContainer(SWTBotGefEditPart container) { ICondition editPartResizedCondition = new CheckEditPartResized(container); // Select the region contained in the container AbstractDiagramElementContainerEditPart part = (AbstractDiagramElementContainerEditPart) container.part(); GraphicalHelper.getAbsoluteBoundsIn100Percent(part); Point top = GraphicalHelper.getAbsoluteBoundsIn100Percent(part).getTop(); editor.click(top.getTranslated(0, 40)); // Collapse the region // Add a wait condition to have the collapse button displayed and click on it bot.waitUntil(new DefaultCondition() { @Override public boolean test() throws Exception { IFigure handleLayer = LayerManager.Helper.find(part).getLayer(LayerConstants.HANDLE_LAYER); Point toggleFigureLocation; if (handleLayer != null) { for (Object figure : handleLayer.getChildren()) { if (figure instanceof CompartmentCollapseHandle) { toggleFigureLocation = ((CompartmentCollapseHandle) figure).getLocation(); if (toggleFigureLocation.x != 0 && toggleFigureLocation.y != 0) { // Use the center of the figure and click on it
private Repository remoteRepository; private URIish remoteURI; @Override @Before public void setUp() throws Exception { super.setUp(); final TestRepository<Repository> src = createTestRepository(); final String srcName = src.getRepository().getDirectory().getName(); ServletContextHandler app = server.addContext("/git"); GitServlet gs = new GitServlet(); gs.setRepositoryResolver((HttpServletRequest req, String name) -> { if (!name.equals(srcName)) throw new RepositoryNotFoundException(name); final Repository db = src.getRepository(); db.incrementOpen(); return db; }); gs.setReceivePackFactory(new DefaultReceivePackFactory() { @Override public ReceivePack create(HttpServletRequest req, Repository db) throws ServiceNotEnabledException, ServiceNotAuthorizedException { ReceivePack rp = super.create(req, db); rp.sendError("message line 1"); rp.sendError("no soup for you!"); rp.sendError("come back next year!"); return rp; } }); app.addServlet(new ServletHolder(gs), "/*");
private URIish remoteURI; @Override @Before public void setUp() throws Exception { super.setUp(); final TestRepository<Repository> src = createTestRepository(); final String srcName = src.getRepository().getDirectory().getName(); ServletContextHandler app = server.addContext("/git"); GitServlet gs = new GitServlet(); gs.setRepositoryResolver((HttpServletRequest req, String name) -> { if (!name.equals(srcName)) throw new RepositoryNotFoundException(name); final Repository db = src.getRepository(); db.incrementOpen(); return db; }); gs.setReceivePackFactory(new DefaultReceivePackFactory() { @Override public ReceivePack create(HttpServletRequest req, Repository db) throws ServiceNotEnabledException, ServiceNotAuthorizedException { ReceivePack rp = super.create(req, db); rp.sendError("message line 1"); rp.sendError("no soup for you!"); rp.sendError("come back next year!"); return rp; } }); app.addServlet(new ServletHolder(gs), "/*"); server.setUp();
private void verifyObjectsOrder(ObjectId objectsOrder[]) { final List<PackIndex.MutableEntry> entries = new ArrayList<>(); for (MutableEntry me : pack) { entries.add(me.cloneEntry()); } Collections.sort(entries, (MutableEntry o1, MutableEntry o2) -> Long .signum(o1.getOffset() - o2.getOffset())); int i = 0; for (MutableEntry me : entries) { assertEquals(objectsOrder[i++].toObjectId(), me.toObjectId()); }
public Optional<T> getFirstResult() { if (result != null) { return result.stream().findFirst(); } return Optional.empty();
protected void setResult(Collection<T> newUserSelection) { result = newUserSelection;
if (name1 == null) { name1 = ""; //$NON-NLS-1$ } if (name2 == null) { name2 = ""; //$NON-NLS-1$ } return coll.compare(name1, name2); } }); // Find primary feature for (AboutInfo feature : features) { if (feature.getFeatureId().equals(primaryFeatureId)) { setInitialSelection(feature); return; } }
* selection (via <code>getResult</code>) after completion. * <p> * Clients may subclass this dialog to inherit its selection facilities. * </p> * * @param <T> * which declares the type of the elements in the * {@link AbstractSelectionDialog}. * @since 3.11 * */ public abstract class AbstractSelectionDialog<T> extends TrayDialog { // the final collection of selected elements private Collection<T> result; // a list of the initially-selected elements private List<T> initialSelection; // title of dialog private String title; // message to show user private String message = ""; //$NON-NLS-1$ // dialog bounds strategy private int dialogBoundsStrategy = Dialog.DIALOG_PERSISTLOCATION | Dialog.DIALOG_PERSISTSIZE; // dialog settings for storing bounds private IDialogSettings dialogBoundsSettings = null; /** * Creates a dialog instance. * * @param parentShell * the parent shell */ protected AbstractSelectionDialog(Shell parentShell) { super(parentShell); }
public Optional<T> getFirstResult() { Collection<T> list = getResult(); if (list == null) { return null; } Iterator<T> iterator = list.iterator(); if (iterator.hasNext()) { return iterator.next(); } return null;
protected void setResult(Collection<T> newUserSelection) { if (newUserSelection == null) { result = null; } else { result = newUserSelection; }
protected void setResult(T... newUserSelection) { if (newUserSelection == null) { result = null; } else { result = Arrays.asList(newUserSelection); }
import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } @Test
ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime() throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); assertTrue(dir.searchPacksAgain(dir.packList.get())); // Make sure that timestamps are modified and read so that a full // file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION,null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir(
assertNotNull(fIterator); assertEquals(fIterator, fIterator); try (CtfIterator obj = (CtfIterator) fTrace.createIterator();) { assertNotNull(obj); assertNotEquals(fIterator, obj); CtfLocation ctfLocation1 = new CtfLocation(new CtfLocationInfo(1, 0)); obj.setLocation(ctfLocation1); obj.increaseRank(); assertEquals(fIterator, obj); } CtfTmfTrace trace = CtfTmfTestTraceUtils.getTrace(CtfTestTrace.FUNKY_TRACE); assertNotNull(trace); try (CtfIterator funky = (CtfIterator) trace.createIterator()) { assertNotEquals(fIterator, funky); } try(CtfIterator iter = (CtfIterator) fTrace.createIterator();){ CTFTrace otherTrace = new CTFTrace(fTrace.getPath()); try(CTFTraceReader tr = new CTFTraceReader(otherTrace)){ assertNotEquals(iter, tr); } } trace.dispose(); try(CtfIterator iter1 = (CtfIterator) fTrace.createIterator(); CtfIterator iter2 = (CtfIterator) fTrace.createIterator()){ assertEquals(iter1, iter2); iter2.setRank(2); assertNotEquals(iter1, iter2); } } /**
assertNotNull(obj); assertNotEquals(fIterator, obj); CtfLocation ctfLocation1 = new CtfLocation(new CtfLocationInfo(1, 0)); obj.setLocation(ctfLocation1); obj.increaseRank(); assertEquals(fIterator, obj); } CtfTmfTrace trace = CtfTmfTestTraceUtils.getTrace(CtfTestTrace.FUNKY_TRACE); assertNotNull(trace); try(CtfIterator funky = (CtfIterator) trace.createIterator()){ assertNotEquals(fIterator, funky); } try (CtfIterator iter = (CtfIterator) fTrace.createIterator();) { CTFTrace otherTrace = new CTFTrace(fTrace.getPath()); try(CTFTraceReader tr = new CTFTraceReader(otherTrace)){ assertNotEquals(iter, tr); } } trace.dispose(); try(CtfIterator iter1 = (CtfIterator) fTrace.createIterator(); CtfIterator iter2 = (CtfIterator) fTrace.createIterator()){ assertEquals(iter1, iter2); iter2.setRank(2); assertNotEquals(iter1, iter2); } } /** * Run the boolean equals(Object) method test. Compare with an empty object. */ @Test public void testEquals_empty() {
assertNotNull(trace); try(CtfIterator funky = (CtfIterator) trace.createIterator()){ assertNotEquals(fIterator, funky); } try(CtfIterator iter = (CtfIterator) fTrace.createIterator();){ CTFTrace otherTrace = new CTFTrace(fTrace.getPath()); try(CTFTraceReader tr = new CTFTraceReader(otherTrace)){ assertNotEquals(iter, tr); } } trace.dispose(); try (CtfIterator iter1 = (CtfIterator) fTrace.createIterator(); CtfIterator iter2 = (CtfIterator) fTrace.createIterator()) { assertEquals(iter1, iter2); iter2.setRank(2); assertNotEquals(iter1, iter2); } } /** * Run the boolean equals(Object) method test. Compare with an empty object. */ @Test public void testEquals_empty() { assertNotEquals(new Object(), fIterator); } /** * Run the CtfTmfTrace getCtfTmfTrace() method test. */ @Test public void testGetCtfTmfTrace() { CtfTmfTrace result = fIterator.getCtfTmfTrace(); assertNotNull(result); } /**
// if ret == true, then currentEvent is non-null if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); } /* Update the current location accordingly */ if (ret) { long time = Objects.requireNonNull(currentEvent).getTimestamp().getValue(); fCurLocation = new CtfLocation(new CtfLocationInfo(time, time != seekToTimestamp ? 0 : index)); } else { fCurLocation = NULL_LOCATION; } return ret;
* STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */ package org.eclipse.jgit.internal.storage.file; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.concurrent.Callable; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase {
*/ package org.eclipse.jgit.internal.storage.file; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.concurrent.Callable; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; import org.eclipse.jgit.internal.storage.pack.PackWriter; import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false);
import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase();
import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(Boolean.TRUE, Boolean.FALSE); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime() throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase();
FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); assertTrue(dir.searchPacksAgain(dir.packList.get())); // Make sure that the modified and read timestamps so that a full // file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository<FileRepository>(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION,null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir( final ObjectDirectory dir) { Callable<ObjectId> callable = new Callable<ObjectId>() { public ObjectId call() throws Exception { return dir.newInserter().insert(Constants.OBJ_BLOB, new byte[0]); } };
// file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION,null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats.booleanValue()); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir( final ObjectDirectory dir) { Callable<ObjectId> callable = new Callable<ObjectId>() { public ObjectId call() throws Exception { return dir.newInserter().insert(Constants.OBJ_BLOB, new byte[0]); } }; return Collections.nCopies(4, callable); } }
assertTrue(traceAdapter.isThereATraceBetween(_A, _B, upDatedTraceModel)); // Clear selection view SelectionView.getOpenedView().clearSelection(); // create a selection with class A List<Object> selection = new ArrayList<>(); selection.add(_A); // test that internal links show for direct elements ToggleTransitivityHandler.setTraceViewTransitive(false); DisplayInternalLinksHandler.showInternalLinks(true); DiagramTextProviderHandler provider = new DiagramTextProviderHandler(); String directlyConnectedElements = provider.getDiagramText(selection); assertTrue(directlyConnectedElements.equals(EXPECTED_TEXT_FOR_INTERNAL_LINKS)); } }
assertEquals(1331668250328561095L, middleEvent.getTimestamp().toNanos()); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); // double timestamp at 15:50:47.328921944 assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 1L))); CtfTmfEvent doubleEvent = iterator.getCurrentEvent(); assertNotNull(doubleEvent); assertEquals(1331668247328921944L, doubleEvent.getTimestamp().toNanos()); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); // test that events will be in cpu order assertEquals("sched_switch", event.getName()); assertEquals(duplicateLocationIndexedOne, iterator.getLocation().getLocationInfo()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 9001000000L))); CtfTmfEvent overNineThousandEvent = iterator.getCurrentEvent(); assertNotNull(overNineThousandEvent); assertEquals(1331668247328925363L, overNineThousandEvent.getTimestamp().toNanos()); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", overNineThousandEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 4L))); CtfTmfEvent quadEvent = iterator.getCurrentEvent(); assertNotNull(quadEvent);
assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 1L))); CtfTmfEvent doubleEvent = iterator.getCurrentEvent(); assertNotNull(doubleEvent); assertEquals(1331668247328921944L, doubleEvent.getTimestamp().toNanos()); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); // test that events will be in cpu order assertEquals("sched_switch", doubleEvent.getName()); CtfLocationInfo duplicateLocationOutOfBounds = new CtfLocationInfo(1331668247328921944L, 4L); assertTrue(iterator.seek(duplicateLocationOutOfBounds)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328925363L, getTimestampInNanos(event)); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", overNineThousandEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 4L))); CtfTmfEvent quadEvent = iterator.getCurrentEvent(); assertNotNull(quadEvent); assertEquals(1331668247328925363L, quadEvent.getTimestamp().toNanos()); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", quadEvent.getName()); assertFalse(iterator.seek(CtfLocation.INVALID_LOCATION));
} } catch (CTFException e) { Activator.getDefault().logError(e.getMessage(), e); return false; } /* * Check if there is already one or more events for that timestamp, and * assign the location index correctly */ long index = 0; ITmfEvent currentEvent = getCurrentEvent(); ret &= (currentEvent != null); long offset = ctfLocationData.getIndex(); while (currentEvent != null && index < offset) { if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { index = 0; break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); } /* Update the current location accordingly */ if (ret) { fCurLocation = new CtfLocation(new CtfLocationInfo(Objects.requireNonNull(previousEvent).getTimestamp().getValue(), index)); } else { fCurLocation = NULL_LOCATION; }
// if ret == true, then currentEvent is non-null if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { index = 0; break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); } /* Update the current location accordingly */ if (ret) { long time = Objects.requireNonNull(currentEvent).getTimestamp().getValue(); fCurLocation = new CtfLocation(new CtfLocationInfo(time, time != seekToTimestamp ? 0 : index)); } else { fCurLocation = NULL_LOCATION; } return ret;
block.scope = this.scope; // (upper scope) see Block.resolve() for similar } else { Statement[] newArray = new Statement[l + 1]; System.arraycopy(block.statements, 0, newArray, 0, l); newArray[l] = breakStatement; block.statements = newArray; } return BREAKING; } } return FALLTHROUGH; } protected void completeNormallyCheck(BlockScope blockScope) { // do nothing } protected boolean checkNullDefaultFlow() { return true; } @Override public FlowInfo analyseCode(BlockScope currentScope, FlowContext flowContext, FlowInfo flowInfo) { try { flowInfo = this.expression.analyseCode(currentScope, flowContext, flowInfo); if ((this.expression.implicitConversion & TypeIds.UNBOXING) != 0 || (this.expression.resolvedType != null && (this.expression.resolvedType.id == T_JavaLangString || this.expression.resolvedType.isEnum()))) { this.expression.checkNPE(currentScope, flowContext, flowInfo, 1); } SwitchFlowContext switchContext =
ServletContext ctx = config.getServletContext(); filter.init(new NoParameterFilterConfig(name, ctx)); } /** {@inheritDoc} */ @Override public void destroy() { filter.destroy(); } /** {@inheritDoc} */ @Override protected void service(HttpServletRequest req, HttpServletResponse res) throws ServletException, IOException { filter.doFilter(req, res, (ServletRequest request, ServletResponse response) -> { ((HttpServletResponse) response).sendError(SC_NOT_FOUND); }); } /** * Configure a newly created binder. * * @param b * the newly created binder. * @return binder for the caller, potentially after adding one or more * filters into the pipeline. */ protected ServletBinder register(ServletBinder b) { return filter.register(b); } }
* made available under the terms of the Eclipse Public License v1.0 which * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.views; /** * Interface with a method for time navigation in time-based views. * * @author Bernd Hufmann * */ public interface ITmfTimeNavigationProvider { /** * Method to implement to scroll left or right * * @param left * true to scroll left else false */ void horizontalScroll(boolean left); }
***************************************************************************** * Copyright (c) 2019 Ericsson * * All rights reserved. This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1.0 which * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.views; /** * Interface for a view to support zoom to selection. * * @author Bernd Hufmann * */ public interface ITmfZoomToSelectionProvider { /** * Zoom to selection */ void zoomToSelection(); }
* http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.views.handler; import org.eclipse.core.commands.AbstractHandler; import org.eclipse.core.commands.ExecutionEvent; import org.eclipse.core.commands.ExecutionException; import org.eclipse.tracecompass.tmf.ui.views.TmfView; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.IWorkbenchWindow; import org.eclipse.ui.PlatformUI; import org.eclipse.ui.handlers.HandlerUtil; /** * Base handler, makes sure we have a TMF view control selected. * * @author Matthew Khouzam * */ abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute(ExecutionEvent event) throws ExecutionException { // Check if we are closing down IWorkbenchWindow window = PlatformUI.getWorkbench().getActiveWorkbenchWindow(); if (window == null) { return null; } IWorkbenchPart part = HandlerUtil.getActivePart(event); if (part instanceof TmfView) { execute((TmfView) part); } return null; } public abstract void execute(TmfView timegraph); }
* * @author Matthew Khouzam * */ abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute(ExecutionEvent event) throws ExecutionException { // Check if we are closing down IWorkbenchWindow window = PlatformUI.getWorkbench().getActiveWorkbenchWindow(); if (window == null) { return null; } IWorkbenchPart part = HandlerUtil.getActivePart(event); if (part instanceof TmfView) { execute((TmfView) part); } return null; } public abstract void execute(TmfView view); }
* accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.views.handler; import org.eclipse.tracecompass.internal.tmf.ui.views.ITmfTimeZoomProvider; import org.eclipse.tracecompass.tmf.ui.views.TmfView; /** * Zoom-in handler for TMF views. * * @author Matthew Khouzam * @author Bernd Hufmann */ public class TmfViewZoomInHandler extends TmfViewBaseHandler { @Override public void execute(TmfView view) { ITmfTimeZoomProvider zoomer = view.getAdapter(ITmfTimeZoomProvider.class); if (zoomer != null) { zoomer.zoom(true); } } }
import org.eclipse.sirius.tests.swtbot.support.api.editor.SWTBotSiriusDiagramEditor; import org.eclipse.sirius.tests.swtbot.support.utils.SWTBotUtils; import org.eclipse.swt.SWT; import org.eclipse.swtbot.eclipse.gef.finder.widgets.SWTBotGefEditPart; /** * Tests to check the behavior of the editor when selecting a node or edge edit * part. * * @author lfasani */ public class EditPartSelectionTest extends AbstractSiriusSwtBotGefTestCase { private static final String DATA_UNIT_DIR = "/data/unit/selection/"; private static final String MODEL = "TestSelection.ecore"; private static final String SESSION_FILE = "TestSelection.aird"; private static final String VSM_FILE = "My.odesign"; private static final String REPRESENTATION_DECRIPTION_NAME = "Entities"; private static final String REPRESENTATION_NAME = "diagram"; private static final PrecisionPoint INITIAL_NODE_CENTER_POSITION = new PrecisionPoint(856.0, 412.0); private Session session; @Override protected void onSetUpBeforeClosingWelcomePage() throws Exception {
} /** * Run the void setRank() method test. */ @Test public void testSetRank() { long rank = fIterator.getRank(); fIterator.increaseRank(); assertEquals(rank + 1, fIterator.getRank()); fIterator.setRank(rank); assertEquals(rank, fIterator.getRank()); } /** * Run the boolean seek(long) method test. */ @Test public void testSeek() { // Trace 2 has duplicate time stamps CtfTmfTrace trace = CtfTmfTestTraceUtils.getTrace(CtfTestTrace.TRACE2); try (CtfIterator iterator = (CtfIterator) trace.createIterator()) { assertTrue(iterator.seek(1L)); CtfTmfEvent event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247314038062L, getTimestampInNanos(event)); assertEquals(1331668247314038062L, iterator.getCurrentTimestamp()); assertFalse(iterator.seek(Long.MAX_VALUE)); assertNull(getCurrentEvent(iterator)); assertEquals(0L, iterator.getCurrentTimestamp()); assertFalse(iterator.advance()); // seek to a time after trace start.
assertNull(getCurrentEvent(iterator)); assertEquals(0L, iterator.getCurrentTimestamp()); assertFalse(iterator.advance()); // seek to a time after trace start. CtfLocationInfo middleLocation = new CtfLocationInfo(1331668250328561095L, 0L); assertTrue(iterator.seek(middleLocation)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561095L, getTimestampInNanos(event)); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); CtfLocationInfo middleLocationIndexOne = new CtfLocationInfo(1331668250328561095L, 1L); assertTrue(iterator.seek(middleLocationIndexOne)); event = iterator.getCurrentEvent(); assertNotNull(event); assertEquals(1331668250328561761L, getTimestampInNanos(event)); assertEquals(1331668250328561761L, iterator.getCurrentTimestamp()); assertEquals(new CtfLocationInfo(1331668250328561761L, 0L), iterator.getLocation().getLocationInfo()); // double timestamp at 15:50:47.328921944 CtfLocationInfo duplicateLocationIndexedOne = new CtfLocationInfo(1331668247328921944L, 1L); assertTrue(iterator.seek(duplicateLocationIndexedOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328921944L, getTimestampInNanos(event));
assertTrue(iterator.seek(middleLocation)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561095L, getTimestampInNanos(event)); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); CtfLocationInfo middleLocationIndexeOne = new CtfLocationInfo(1331668250328561095L, 1L); assertTrue(iterator.seek(middleLocationIndexeOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561761L, getTimestampInNanos(event)); assertEquals(1331668250328561761L, iterator.getCurrentTimestamp()); // next event location assertEquals(new CtfLocationInfo(1331668250328561761L, 0L), iterator.getLocation().getLocationInfo()); // double timestamp at 15:50:47.328921944 CtfLocationInfo duplicateLocationIndexedOne = new CtfLocationInfo(1331668247328921944L, 1L); assertTrue(iterator.seek(duplicateLocationIndexedOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328921944L, getTimestampInNanos(event)); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); // test that events will be in cpu order assertEquals("sched_switch", event.getName()); assertEquals(duplicateLocationIndexedOne, iterator.getLocation().getLocationInfo());
CtfLocationInfo duplicateLocationOutOfBounds = new CtfLocationInfo(1331668247328921944L, 4L); assertTrue(iterator.seek(duplicateLocationOutOfBounds)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328925363L, getTimestampInNanos(event)); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", event.getName()); // next event location assertEquals(new CtfLocationInfo(1331668247328925363L, 0L), iterator.getLocation().getLocationInfo()); CtfLocationInfo duplicateLocationIndexHuge = new CtfLocationInfo(1331668247328921944L, 9001000000L); assertTrue(iterator.seek(duplicateLocationIndexHuge)); event = iterator.getCurrentEvent(); assertNotNull(event); assertEquals(1331668247328925363L, getTimestampInNanos(event)); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", event.getName()); // next event location assertEquals(new CtfLocationInfo(1331668247328925363L, 0L), iterator.getLocation().getLocationInfo()); assertFalse(iterator.seek(CtfLocation.INVALID_LOCATION)); // last valid seek location assertEquals(event, getCurrentEvent(iterator)); } trace.dispose(); }
assertEquals(1331668247328925363L, getTimestampInNanos(event)); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", event.getName()); // next event location assertEquals(new CtfLocationInfo(1331668247328925363L, 0L), iterator.getLocation().getLocationInfo()); assertFalse(iterator.seek(CtfLocation.INVALID_LOCATION)); // last valid seek location assertEquals(event, getCurrentEvent(iterator)); } trace.dispose(); } /** * Run the void setLocation(ITmfLocation<?>) method test. */ @Test public void testSetLocation() { CtfLocation location = new CtfLocation(new CtfLocationInfo(1, 0)); fIterator.setLocation(location); } }
assertEquals("sys_poll", event.getName()); // next event location assertEquals(new CtfLocationInfo(1331668247328925363L, 0L), iterator.getLocation().getLocationInfo()); assertFalse(iterator.seek(CtfLocation.INVALID_LOCATION)); // last valid seek location assertEquals(event, getCurrentEvent(iterator)); } trace.dispose(); } /** * Run the void setLocation(ITmfLocation<?>) method test. */ @Test public void testSetLocation() { CtfLocation location = new CtfLocation(new CtfLocationInfo(1, 0)); fIterator.setLocation(location); } }
public boolean isReferenceToDisplay(Component source, DNodeContainer sourceView, DNodeContainer targetView) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer && (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion"))) { for (DDiagramElement grandchild : ((DNodeContainer) child).getOwnedDiagramElements()) { if (isReferenceDisplayedByChild((DNodeContainer) grandchild, targetView)) { return false; } } } } return true; // } // return false;
// if (!isIndirectlyCollapsed(sourceView) && !isIndirectlyCollapsed(targetView)) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer && (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion"))) { for (DDiagramElement grandchild : ((DNodeContainer) child).getOwnedDiagramElements()) { if (isReferenceDisplayedByChild((DNodeContainer) grandchild, targetView)) { return false; } } } } return true;
* Copyright (c) 2010, 2019 THALES GLOBAL SERVICES * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - Initial API and implementation */ package org.eclipse.sirius.tests.swtbot.support.api.editor; import java.util.Iterator; import java.util.List; import java.util.concurrent.atomic.AtomicBoolean; import org.eclipse.core.runtime.IAdaptable; import org.eclipse.draw2d.FigureCanvas; import org.eclipse.draw2d.IFigure; import org.eclipse.draw2d.Label; import org.eclipse.draw2d.LightweightSystem; import org.eclipse.draw2d.geometry.Point; import org.eclipse.draw2d.text.TextFlow; import org.eclipse.gef.EditPart; import org.eclipse.gef.GraphicalEditPart; import org.eclipse.gef.GraphicalViewer; import org.eclipse.sirius.ext.gmf.runtime.gef.ui.figures.SiriusWrapLabel; import org.eclipse.sirius.tests.swtbot.support.api.widget.SWTBotSiriusFigureCanvas;
* Copyright (c) 2012, 2019 THALES GLOBAL SERVICES * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - Initial API and implementation */ package org.eclipse.sirius.tests.swtbot.support.api.widget; import java.util.concurrent.atomic.AtomicBoolean; import org.eclipse.draw2d.FigureCanvas; import org.eclipse.draw2d.LightweightSystem; import org.eclipse.swt.SWT; import org.eclipse.swt.events.KeyEvent; import org.eclipse.swt.widgets.Canvas; import org.eclipse.swt.widgets.Event; import org.eclipse.swt.widgets.Text; import org.eclipse.swtbot.eclipse.gef.finder.widgets.SWTBotGefFigureCanvas; import org.eclipse.swtbot.swt.finder.exceptions.WidgetNotFoundException; import org.eclipse.swtbot.swt.finder.finders.UIThreadRunnable; import org.eclipse.swtbot.swt.finder.results.Result; import org.eclipse.swtbot.swt.finder.results.VoidResult; import org.eclipse.swtbot.swt.finder.utils.SWTUtils; /**
***************************************************************************** * Copyright (c) 2017, 2019 THALES GLOBAL SERVICES. * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *******************************************************************************/ package org.eclipse.sirius.tests.swtbot; import org.eclipse.draw2d.IFigure; import org.eclipse.draw2d.geometry.PrecisionPoint; import org.eclipse.draw2d.geometry.Rectangle; import org.eclipse.gef.GraphicalEditPart; import org.eclipse.gef.LayerConstants; import org.eclipse.gef.editparts.LayerManager; import org.eclipse.gmf.runtime.diagram.ui.editparts.AbstractBorderedShapeEditPart; import org.eclipse.gmf.runtime.diagram.ui.editparts.ConnectionEditPart; import org.eclipse.gmf.runtime.diagram.ui.editparts.IGraphicalEditPart; import org.eclipse.gmf.runtime.draw2d.ui.figures.PolylineConnectionEx; import org.eclipse.sirius.business.api.session.Session; import org.eclipse.sirius.diagram.DDiagram; import org.eclipse.sirius.diagram.ui.edit.api.part.AbstractDiagramBorderNodeEditPart;
} @Override protected void tearDown() throws Exception { assertEquals("Test triggered errors.", 0, loggedErrors.get()); Platform.removeLogListener(errorLogListener); super.tearDown(); } /** * Test if two byte UTF-8 characters get disrupted on there way from process * console to the runtime process. * <p> * This test starts every two byte character on an even byte offset. * </p> */ public void testUTF8InputEven() throws Exception { // 5000 characters result in 10000 bytes which should be more than most // common buffer sizes. processConsoleUTF8Input("", 5000); } /** * Test if two byte UTF-8 characters get disrupted on there way from process * console to the runtime process. * <p> * This test starts every two byte character on an odd byte offset. * </p> * * @throws Exception if the test gets in trouble
import org.eclipse.debug.tests.AbstractDebugTest; /** * Tests the {@link StreamsProxy}. */ public class StreamsProxyTests extends AbstractDebugTest { public StreamsProxyTests() { super(StreamsProxyTests.class.getSimpleName()); } public StreamsProxyTests(String name) { super(name); } /** * Test console receiving UTF-8 output from process where two-byte UTF-8 * characters start at even offsets. */ public void testReceiveUTF8Even() throws Exception { // 4500 characters results in 9000 byte of output which should be more // than most common buffer sizes. receiveUTF8Test("", 4500); } /** * Test console receiving UTF-8 output from process where two-byte UTF-8 * characters start at odd offsets. * * @throws Exception if the test gets in trouble */ public void testReceiveUTF8Odd() throws Exception { // 4500 characters results in 9000 byte of output which should be more
public void testSet() { List<String> reference = Arrays.asList("Pomme", "Peche", "Poire", "Banane"); List<String> test = createList(reference); assertEquals(reference, test); test.set(0, "pomme"); assertNotEquals(reference, test); try { test.set(-1, "pomme"); fail("Should not get here"); } catch (IndexOutOfBoundsException e) { // correct flow } try { test.set(5, "pomme"); fail("Should not get here"); } catch (IndexOutOfBoundsException e) { // correct flow }
assertEquals("yo", iterator.next()); iterator.previous(); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); iterator.next(); iterator.next(); iterator.next(); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.previous(); assertEquals(3, iterator.previousIndex()); assertEquals(4, iterator.nextIndex()); try { iterator.remove(); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.set("hej"); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.add("hi"); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow }
* accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.ctf.core.utils; import java.util.Collection; import java.util.Iterator; import java.util.LinkedHashMap; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; /** * Sparse list, a list optimized for when most (> 90%) of the data is * <code>null</code>. * * Note: this iterates in the sorted order. * * This implementation supports: * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()} , {@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li> * <li>{@link #lastIndexOf(Object)}</li> * </ul> *
private int getThreshold() { if (!selectFeedbackEnabled) { if (getViewer().getControl() instanceof Table) return ((Table) getViewer().getControl()).getItemHeight() / 2; if (getViewer().getControl() instanceof Tree) return ((Tree) getViewer().getControl()).getItemHeight() / 2; if (getViewer().getControl() instanceof List) return ((List) getViewer().getControl()).getItemHeight() / 2; } // fixed default threshold return 5;
public GenericReadOnlyListIterator(List<E> list, int start, int end) { fList = list; fCursor = start - 1;
* http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.ctf.core.utils; import java.util.Collection; import java.util.HashMap; import java.util.Iterator; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; /** * Sparse list, a list optimized for when most of the data is <code>null</code>. * Nulls will increment the size of the datastructure but not stored as null * means the data is not present. * * Note: this iterates in the sorted order. * * This implementation supports: * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()}</li> * <li>{@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li>
* <li>{@link #clear()}</li> * <li>{@link #iterator()}</li> * <li>{@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li> * <li>{@link #lastIndexOf(Object)}</li> * </ul> * * TODO: Keep an eye out for a better datastructure... this is fine, but if it * can be replaced by an externally maintained datastructure, that would be * better. * * @author Matthew Khouzam * @param <E> * the element type */ public class SparseList<E> implements List<E> { private final Map<Integer, E> fInnerEvents = new HashMap<>(); private int fSize = 0; /** * Copy constructor * * @param events * list of events */ public SparseList(List<E> events) { ensureSize(events.size()); for (int i = 0; i < events.size(); i++) { E element = events.get(i);
* <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li> * <li>{@link #lastIndexOf(Object)}</li> * </ul> * * TODO: remove when a public (open source) sparselist is available. * * @author Matthew Khouzam * @param <E> * the element type */ public class SparseList<E> implements List<E> { private final Map<Integer, E> fInnerElements = new HashMap<>(); private int fSize = 0; /** * Copy constructor * * @param events * list of events */ public SparseList(List<E> events) { ensureSize(events.size()); for (int i = 0; i < events.size(); i++) { E element = events.get(i); if (element != null) { set(i, element); } } } /** * default constructor */ public SparseList() { // Do nothing } @Override public int size() {
public boolean contains(Object o) { return fInnerElements.containsValue(o);
public boolean add(E e) { if (e != null) { fInnerElements.put(fSize, e); } return true;
public boolean containsAll(Collection<?> c) { return fInnerElements.values().containsAll(c);
public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { set(key, event); key++; } return true;
public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { set(key, event); key++; } return true;
} @Override public boolean containsAll(Collection<?> c) { return fInnerEvents.values().containsAll(c); } @Override public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { if (event != null) { set(key, event); } key++; } return true; } /** * {@inheritDoc} * * Returns null if there is no element found at that index. */ @Override public E get(int index) { if (index < 0 || index >= fSize) { throw new IndexOutOfBoundsException("Tried to access index " + index + " Sparse list size " + fSize); //$NON-NLS-1$ //$NON-NLS-2$ } return fInnerEvents.get(index); } @Override public E set(int index, E element) { if (index < 0 || index >= fSize) {
public ELEMENT next() { if (!hasNext()) { throw new NoSuchElementException(); } fCursor++; return fList.get(fCursor);
public int nextIndex() { return fCursor + 1;
// constexpr bool comma_is_not_noexcept = noexcept(fun(), fun_noexcept()); // constexpr bool ctor_is_noexcept = noexcept(myclass{}); // constexpr bool ctor_is_not_noexcept = noexcept(myclass{1}); // constexpr bool constexpr_ctor_is_noexcept = noexcept(myclass{1, 1}); // constexpr bool aggregate_init_is_noexcept = noexcept(myaggregate{{1}}); // constexpr bool aggregate_init_is_not_noexcept = noexcept(myaggregate{{my_int}}); // constexpr bool aggregate_access_is_noexcept = noexcept(agg.a); // constexpr bool not_noexcept_conditional = noexcept(condition() ? fun() : fun_noexcept()); // constexpr bool is_noexcept_conditional = noexcept(condition() ? fun_noexcept() : fun_noexcept()); // constexpr bool throw_is_not_noexcept = noexcept(throw fun_noexcept()); public void testNoexceptOperatorFunctions_545021() throws Exception { parseAndCheckBindings(); BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("fun_is_not_noexcept", 0); helper.assertVariableValue("unevaluated_fun_is_noexcept", 1); helper.assertVariableValue("fun_noexcept_is_noexcept", 1);
helper.assertVariableValue("constexpr_ctor_is_noexcept", 1); helper.assertVariableValue("aggregate_init_is_noexcept", 1); helper.assertVariableValue("not_noexcept_conditional", 0); helper.assertVariableValue("is_noexcept_conditional", 1); helper.assertVariableValue("throw_is_not_noexcept", 0); } // int fun(); // int fun(int); // template<typename T> // int funt(T); // template<typename T> // int funt_noexcept(T) noexcept; // // constexpr bool funt_is_not_noexcept = noexcept(funt(1)); // constexpr bool funt_noexcept_is_noexcept = noexcept(funt_noexcept(1)); public void testNoexceptOperator2_545021() throws Exception { BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("unevaluated_fun_is_noexcept", 1); helper.assertVariableValue("funt_is_not_noexcept", 0); helper.assertVariableValue("funt_noexcept_is_noexcept", 1); } // struct type1{ // void operator=(int); // bool operator!(); // }; // type1 t1;
// void operator=(int); // bool operator!(); // }; // type1 t1; // struct type2{ // void operator=(int) noexcept; // bool operator!() noexcept; // }; // type2 t2; // constexpr bool binaryop_is_not_noexcept = noexcept(t1 = 1); // constexpr bool unaryop_is_not_noexcept = noexcept(!t1); // constexpr bool noexcept_binaryop_is_noexcept = noexcept(t2 = 1); // constexpr bool noexcept_unaryop_is_noexcept = noexcept(!t2); public void testNoexceptOperatorOverloadedOperators_545021() throws Exception { parseAndCheckBindings(); BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("binaryop_is_not_noexcept", 0); helper.assertVariableValue("unaryop_is_not_noexcept", 0); helper.assertVariableValue("noexcept_binaryop_is_noexcept", 1); helper.assertVariableValue("noexcept_unaryop_is_noexcept", 1); } // void fun(); // void fun_taking_funptr(void(*ptr)()) noexcept; // // constexpr bool is_noexcept = noexcept(fun_taking_funptr(fun));
private final boolean isRValueReference; private final boolean takesVarargs; private final ICPPEvaluation noexceptSpecifier; public CPPFunctionType(IType returnType, IType[] types, ICPPEvaluation noexceptSpecifier) { this(returnType, types, noexceptSpecifier, false, false, false, false, false);
public boolean isNoexcept(boolean inCalledContext) { ICPPFunction overload = getOverload(); if (overload != null) { if (!EvalUtil.evaluateNoexceptSpecifier(overload.getType().getNoexceptSpecifier())) return false; } return fArg1.isNoexcept(inCalledContext) && fArg2.isNoexcept(inCalledContext);
public boolean isNoexcept(boolean inCalledContext) { return fCondition.isNoexcept(inCalledContext) && fPositive.isNoexcept(inCalledContext) && fNegative.isNoexcept(inCalledContext);
public boolean isNoexcept(boolean inCalledContext) { return EvalUtil.evaluateNoexceptSpecifier(fConstructor.getType().getNoexceptSpecifier());
public boolean isNoexcept(boolean inCalledContext) { assert false; // Shouldn't exist outside of a dependent context return true;
public boolean isNoexcept(boolean inCalledContext) { assert false; // Shouldn't exist outside of a dependent context return true;
public boolean isNoexcept(boolean inCalledContext) { if (!fOwnerEval.isNoexcept(inCalledContext)) return false; if (inCalledContext) { return EvalUtil.bindingIsNoexcept(getMember()); } else return true; // in unevaluated context
public boolean isNoexcept(boolean inCalledContext) { assert false; // Shouldn't exist outside of a dependent context return true;
public boolean isNoexcept(boolean inCalledContext) { if (fOperator == op_throw) return false; ICPPFunction overload = getOverload(); if (overload != null) { if (!EvalUtil.evaluateNoexceptSpecifier(overload.getType().getNoexceptSpecifier())) return false; } return fArgument.isNoexcept(inCalledContext);
public void testToString() { List<String> reference = Arrays.asList("Pomme", "Peche", "Poire", null, "Banane"); List<String> test = createList(reference); assertEquals("[0:Pomme, 1:Peche, 2:Poire, 3:Banane]", test.toString());
private static void testListIterator(List<String> test) { ListIterator<String> iterator = test.listIterator(0); assertTrue(iterator.hasNext()); assertFalse(iterator.hasPrevious()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); assertEquals("yo", iterator.next()); assertEquals("yo", iterator.previous()); assertEquals("Hola", iterator.previous()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); iterator.next(); iterator.next(); iterator.next(); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.previous(); assertEquals(3, iterator.previousIndex()); assertEquals(4, iterator.nextIndex()); try { iterator.remove(); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.set("hej"); fail("Should not get here");
import java.util.HashMap; import java.util.Iterator; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; import org.eclipse.jdt.annotation.Nullable; /** * Sparse list, a list optimized for when most of the data is <code>null</code>. * Nulls will increment the size of the SparseList but they are not stored * internally. * </p> * <p> * Note: this iterates in the list order. * </p> * This implementation supports: * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()}</li> * <li>{@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li>
import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; import org.eclipse.jdt.annotation.Nullable; /** * Sparse list, a list optimized for when most of the data is <code>null</code>. * Nulls will increment the size of the SparseList but they are not stored * internally. * </p> * <p> * Note: this iterates in the list order. * </p> * This implementation supports: * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()}</li> * <li>{@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li>
* <li>{@link #lastIndexOf(Object)}</li> * </ul> * * TODO: Keep an eye out for a better datastructure... this is fine, but if it * can be replaced by an externally maintained datastructure, that would be * better. * * @author Matthew Khouzam * @param <E> * the element type */ public class SparseList<E> implements List<E> { /** * A backing map used to store the non-null elements */ private final Map<Integer, @NonNull E> fInnerElements = new HashMap<>(); /** * The list size: map size + number of nulls */ private int fSize = 0; /** * Copy constructor * * @param events * list of events */ public SparseList(List<E> events) { ensureSize(events.size()); for (int i = 0; i < events.size(); i++) { E element = events.get(i); if (element != null) { set(i, element); } } } /** * default constructor */ public SparseList() { // Do nothing } @Override public int size() {
public boolean isEmpty() { return fSize == 0;
public boolean contains(Object o) { return (o == null && size() > fInnerElements.size()) || fInnerElements.containsValue(o);
int size = fInnerElements.size(); Object[] retVal = new Object[size]; Iterator<E> iterator = iterator(); for (int i = 0; i < size; i++) { Object next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } retVal[i] = next; } return retVal; } @Override public <T> T[] toArray(T[] a) { int size = Math.min(a.length, fInnerElements.size()); Iterator<E> iterator = iterator(); for (int i = 0; i < size; i++) { @Nullable E next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } a[i] = (T) next; } return a; } @Override public boolean add(E e) { if (e != null) {
public int indexOf(Object o) { if (o == null && contains(null)) { for (int i = 0; i < size(); i++) { if (!fInnerElements.containsKey(i)) { return i; } } } for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { return entry.getKey(); } } return -1;
public int lastIndexOf(Object o) { int last = -1; if (o == null && contains(null)) { for (int i = size() -1; i >= 0; i--) { if (!fInnerElements.containsKey(i)) { return i; } } } for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { last = Math.max(last, entry.getKey()); } } return last;
private void fixSize() { perspSwitcherToolbar.pack(); perspSwitcherToolbar.getParent().pack(); perspSwitcherToolbar.requestLayout();
public TimeGraphEntry(@NonNull TimeGraphEntryModel model) { fModel = model; fStartTime = model.getStartTime(); fEndTime = model.getEndTime();
public boolean equals(Object obj) { if(!super.equals(obj)) { return false; } if (obj instanceof TimeLineEvent) { TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false;
protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); if (getType() == PROJECT) { // project entry always has workspace relative path return root.findMember(path); } // look for files or folders with the given path IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (getType() != ARCHIVE) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } @SuppressWarnings("deprecation") IFile[] files = root.findFilesForLocation(path); if (files.length > 0) { return files[0]; } if (getType() != ARCHIVE) { @SuppressWarnings("deprecation") IContainer[] containers = root.findContainersForLocation(path); if (containers.length > 0) { return containers[0]; } } } return null;
import org.eclipse.jdt.core.IMember; import org.eclipse.jdt.core.search.IJavaSearchConstants; /** * This class represents the general parts of a method call (either to or from a * method). * */ public abstract class MethodWrapper extends PlatformObject { public static IMethodWrapperDynamic fMethodWrapperCore= new MethodWrapperDynamicCore(); /** * Set the IMethodWrapperCore class to use in MethodWrapper * * @param core the IMethodWrapperCore class to store */ public static final void setMethodWrapperDynamic(IMethodWrapperDynamic core) { fMethodWrapperCore= core; } private Map<String, MethodCall> fElements = null; /* * A cache of previously found methods. This cache should be searched * before adding a "new" method object reference to the list of elements. * This way previously found methods won't be searched again. */ private Map<String, Map<String, MethodCall>> fMethodCache; private final MethodCall fMethodCall; private final MethodWrapper fParent; private int fLevel;
private static void testListIterator(List<String> test) { ListIterator<String> iterator = test.listIterator(0); assertTrue(iterator.hasNext()); assertFalse(iterator.hasPrevious()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } assertEquals("Hola", iterator.next()); assertEquals("yo", iterator.next()); assertEquals("yo", iterator.previous()); assertEquals("Hola", iterator.previous()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } assertEquals("Hola", iterator.next()); assertEquals("yo", iterator.next()); assertEquals("quiero", iterator.next()); assertEquals("un", iterator.next()); assertEquals("UNSUPPORTEDOPERATIONEXCEPTION!", iterator.next()); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } assertEquals("UNSUPPORTEDOPERATIONEXCEPTION!", iterator.previous()); assertEquals(3, iterator.previousIndex());
public GenericReadOnlyListIterator(List<E> list, int start, int end) { fList = list; fCursor = start - 1;
public GenericReadOnlyListIterator(List<E> list, int start, int end) { fList = list; fCursor = start - 1;
public boolean hasNext() { return nextIndex() < fList.size();
public boolean hasPrevious() { return previousIndex() >= 0;
public boolean contains(Object o) { return o == null ? size() > fInnerElements.size() : fInnerElements.containsValue(o);
@Nullable E next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } if (next != null) { Class<? extends @NonNull Object> elementClass = next.getClass(); if (!Objects.equals(elementClass, componentType) && !elementClass.isInstance(componentType)) { throw new ArrayStoreException("Cannot convert from (" + elementClass + " to " + newArray.getClass().getComponentType()); //$NON-NLS-1$ //$NON-NLS-2$ } } returnArray[i] = (T) next;
public int indexOf(Object o) { if (o == null && contains(null)) { for (int i = 0; i < size(); i++) { if (!fInnerElements.containsKey(i)) { return i; } } } for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { first = Math.min(entry.getKey(), first); } } return -1;
public Spliterator<E> spliterator() { return Spliterators.spliterator(iterator(), fSize, Spliterator.ORDERED);
public ListIterator<E> listIterator(int index) { return new GenericReadOnlyListIterator<>(this, index);
public void add(int index, E element) { throw new UnsupportedOperationException("No add(int, E) in " + this.getClass().getName()); //$NON-NLS-1$
public E remove(int index) { throw new UnsupportedOperationException("No delete(int) in " + this.getClass().getName()); //$NON-NLS-1$
public boolean remove(Object o) { throw new UnsupportedOperationException("No remove(Object) in " + this.getClass().getName()); //$NON-NLS-1$
public boolean addAll(int index, Collection<? extends E> c) { throw new UnsupportedOperationException("No addAll(int, Collection<? extends E>) in " + this.getClass().getName()); //$NON-NLS-1$
throw new UnsupportedOperationException("No removeAll in " + this.getClass().getName()); //$NON-NLS-1$ } @Override public boolean retainAll(Collection<?> c) { throw new UnsupportedOperationException("No retainAll in " + this.getClass().getName()); //$NON-NLS-1$ } @Override public @NonNull List<E> subList(int fromIndex, int toIndex) { throw new UnsupportedOperationException("No subList(int, int) in " + this.getClass().getName()); //$NON-NLS-1$ } }
***************************************************************************** * Copyright (c) 2019 vogella GmbH and others. * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Simon Scholz <simon.scholz@vogella.com> - initial API and implementation ******************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.di.annotations.Evaluate; import org.eclipse.e4.ui.model.application.ui.MImperativeExpression; public class ImperativeExpressionTestEvaluationPersistedState { public static final String PERSISTED_STATE_TEST = "persisted-state-test"; @Evaluate public boolean isVisible(MImperativeExpression exp) { return exp.getPersistedState().containsKey(PERSISTED_STATE_TEST); } }
* {@link BitmapWalker}. * * @since 5.5 */ final class BitmapCalculator { private final RevWalk walk; private final BitmapIndex bitmapIndex; private final ProgressMonitor pm; private long countOfBitmapIndexMisses; private final BitmapWalkHook preWalkHook; private final BitmapWalkHook postWalkHook; /** * This is intended to be used only by {@link BitmapWalker}. */ interface BitmapWalkHook { /** * Hooked invoked before and after traversing the tree building a commit * bitmap. * * @param walk * revwalk in use. * @param bitmapResult * bitmap calculated so far. * @param pm * progress monitor * @throws IOException */ void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) throws IOException; }
private final RevWalk walk; private final BitmapIndex bitmapIndex; private final ProgressMonitor pm; private long countOfBitmapIndexMisses; private final BitmapWalkHook preWalkHook; private final BitmapWalkHook postWalkHook; /** * Hook that can be invoked before or after the walk building the bitmap of * a commit that doesn't have one. * <p> * This is intended to be used only by {@link BitmapWalker}. */ interface BitmapWalkHook { /** * This is invoked just before starting to walk looking for the closes * bitmap. Can be used to tune the walker configuration. * * @param walk * revwalk in use. * @param bitmapResult * bitmap calculated so far. * @param pm * progress monitor * @throws IOException */ void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) throws IOException; } private static final BitmapWalkHook NULL_BITMAP_HOOK = new BitmapWalkHook() { @Override public void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) {
BitmapBuilder seen, boolean ignoreMissing) throws MissingObjectException, IncorrectObjectTypeException, IOException { return this.bitmapCalculator.getBitmapFor(start, seen, ignoreMissing); } /** * Filter that excludes objects already in the given bitmap. */ static class BitmapObjectFilter extends ObjectFilter { private final BitmapBuilder bitmap; BitmapObjectFilter(BitmapBuilder bitmap) { this.bitmap = bitmap; } @Override public final boolean include(ObjectWalk walker, AnyObjectId objid) throws MissingObjectException, IncorrectObjectTypeException, IOException { return !bitmap.contains(objid); } } }
public void set(Object[] newContents) { Assert.isNotNull(newContents); data.clear(); data.addAll(Arrays.asList(newContents)); IConcurrentModelListener[] listeners = getListeners(); for (IConcurrentModelListener listener : listeners) { listener.setContents(newContents); }
// copy only linked resource children (267173) if (source.isLinked() && source.getLocation().equals(existing.getLocation())) children = filterNonLinkedResources(children); ResourceDescription[] overwritten = copy(children, destinationPath, resourcesAtDestination, iterationProgress, uiInfo, false, createVirtual, createLinks, relativeToVariable); // We don't record the copy since this recursive call will // do so. Just record the overwrites. overwrittenResources.addAll(Arrays.asList(overwritten)); } else { // delete the destination folder, copying a linked folder // over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(1), uiInfo, false); iterationProgress.setWorkRemaining(100); if ((createLinks || createVirtual) && (source.isLinked() == false) && (source.isVirtual() == false)) { IFolder folder = workspaceRoot.getFolder(destinationPath); if (createVirtual) { folder.create(IResource.VIRTUAL, true, iterationProgress.split(1));
if (mapping == null) continue; ResourceTraversal[] traversals = null; try { traversals = mapping.getTraversals( ResourceMappingContext.LOCAL_CONTEXT, new NullProgressMonitor()); } catch (CoreException e) { StatusManager.getManager().handle(e, IDEWorkbenchPlugin.IDE_WORKBENCH); } if (traversals != null) { IResource[] resources = null; for (ResourceTraversal traversal : traversals) { resources = traversal.getResources(); if (resources != null) { result.addAll(Arrays.asList(resources)); } } } } else result.add(resource); } // all that can be converted are done, answer new selection if (result.isEmpty()) { return StructuredSelection.EMPTY; } return new StructuredSelection(result.toArray());
static Set<IResource> getResourcesForFilter(MarkerFieldFilterGroup group, IResource[] selectedResources, IWorkspaceRoot root) { HashSet<IResource> resourceSet = new HashSet<>(); switch (group.getScope()) { case MarkerFieldFilterGroup.ON_ANY: { resourceSet.add(root); break; } case MarkerFieldFilterGroup.ON_SELECTED_ONLY: case MarkerFieldFilterGroup.ON_SELECTED_AND_CHILDREN: { resourceSet.addAll(Arrays.asList(selectedResources)); break; } case MarkerFieldFilterGroup.ON_ANY_IN_SAME_CONTAINER: { for (IResource resource : getProjects(selectedResources)) { resourceSet.add(resource); } break; } case MarkerFieldFilterGroup.ON_WORKING_SET: { group.refresh(); resourceSet.addAll(Arrays.asList(group.getResourcesInWorkingSet())); break; } } return resourceSet;
* * @author Alvaro Sanchez-Leon * @author Patrick Tasse */ public interface ITimeGraphEntry extends ISelection { /** * An enumeration of the display style of the time graph entries * * @author Genevive Bastien * @since 5.0 */ public enum DisplayStyle { /** * Display states, ie rectangle representing a discrete state that has a * beginning and an end */ STATE, /** * Display XY lines for this entry, ie one or more continuous lines that change * over time */ LINE } /** * Returns the parent of this entry, or <code>null</code> if it has none. * * @return the parent element, or <code>null</code> if it has none */ ITimeGraphEntry getParent(); /** * Returns whether this entry has children. * * @return <code>true</code> if the given element has children, * and <code>false</code> if it has no children */ boolean hasChildren();
public void addEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Needs to be a TimeLineEvent"); //$NON-NLS-1$ } super.addEvent(event);
public void addEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Needs to be a TimeLineEvent"); //$NON-NLS-1$ } super.addEvent(event);
public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>());
public TimeLineEvent(ITimeGraphEntry entry, long time, List<Long> values) { super(entry, time, 0); fValues = values;
public boolean equals(Object obj) { if (!super.equals(obj)) { return false; } if(obj instanceof TimeLineEvent) { TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false;
public boolean equals(Object obj) { if(!super.equals(obj)) { return false; } if (obj instanceof TimeLineEvent) { TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false;
public String toString() { StringBuilder builder = new StringBuilder(); builder.append("[TimeLineEvent Values=").append(getValues()) //$NON-NLS-1$ .append(", Entry=").append(getEntry()) //$NON-NLS-1$ .append(", fTime=").append(getTime()) //$NON-NLS-1$ .append(", Duration=").append(getDuration()) //$NON-NLS-1$ .append(']').toString();
private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { // clamp 0 - max positive long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); List<List<LongPoint>> seriesModel = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); // todo: update when we want mutliple series ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec));
private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { // clamp 0 - max positive long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); List<List<LongPoint>> seriesModel = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); // todo: update when we want mutliple series ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec));
// clamp 0 - max positive long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); List<List<LongPoint>> toDraw = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); // todo: update when we want mutliple series ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = -1; while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds
} while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; }
if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) {
} int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i));
if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); seriesModel.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); seriesModel.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (TimeLineEvent ref : refs) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(ref); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < nbSeries; i++) { RGBA rgba = colors.get(i);
long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (TimeLineEvent ref : refs) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(ref); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < nbSeries; i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha);
Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha); gc.setForeground(color); List<LongPoint> series = toDraw.get(i); int[] points = new int[series.size() * 2]; for (int point = 0; point < series.size(); point++) { LongPoint longPoint = series.get(point); points[point * 2] = longPoint.x;
***************************************************************************** * Copyright (c) 2000, 2019 IBM Corporation and others. * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation *******************************************************************************/ package org.eclipse.jface.viewers; import org.eclipse.core.runtime.Assert; import org.eclipse.swt.dnd.DND; import org.eclipse.swt.dnd.DropTargetAdapter; import org.eclipse.swt.dnd.DropTargetEvent; import org.eclipse.swt.dnd.TransferData; import org.eclipse.swt.graphics.Point; import org.eclipse.swt.graphics.Rectangle; import org.eclipse.swt.widgets.Item; import org.eclipse.swt.widgets.List; import org.eclipse.swt.widgets.Table; import org.eclipse.swt.widgets.TableItem; import org.eclipse.swt.widgets.Tree; import org.eclipse.swt.widgets.TreeItem; /** * This adapter class provides generic drag-and-drop support for a viewer. * <p>
for (int i = 0; i < resources.length; i++) { // Copy the resources and record the overwrites that would // be restored if this operation were reversed ResourceDescription[] overwrites; overwrites = WorkspaceUndoUtil.copy(new IResource[] { resources[i] }, getDestinationPath(resources[i], i), resourcesAtDestination, subMonitor.split(1), uiInfo, true, fCreateGroups, fCreateLinks, fRelativeToVariable); // Accumulate the overwrites into the full list overwrittenResources.addAll(Arrays.asList(overwrites)); } // Are there any previously overwritten resources to restore now? if (resourceDescriptions != null) { for (ResourceDescription resourceDescription : resourceDescriptions) { if (resourceDescription != null) { resourceDescription.createResource(subMonitor.split(1)); } } } // Reset resource descriptions to the just overwritten resources setResourceDescriptions(overwrittenResources .toArray(new ResourceDescription[overwrittenResources.size()])); // Reset the target resources to refer to the resources in their new // location. setTargetResources(resourcesAtDestination
for (int i = 0; i < resources.length; i++) { // Move the resources and record the overwrites that would // be restored if this operation were reversed ResourceDescription[] overwrites; overwrites = WorkspaceUndoUtil.move(new IResource[] { resources[i] }, getDestinationPath(resources[i], i), resourcesAtDestination, undoDestinationPaths, subMonitor.split(1), uiInfo, true); // Accumulate the overwrites into the full list overwrittenResources.addAll(Arrays.asList(overwrites)); } // Are there any previously overwritten resources to restore now? if (resourceDescriptions != null) { for (ResourceDescription resourceDescription : resourceDescriptions) { if (resourceDescription != null) { resourceDescription.createResource(subMonitor.split(1)); } } } // Reset resource descriptions to the just overwritten resources setResourceDescriptions(overwrittenResources .toArray(new ResourceDescription[overwrittenResources.size()])); // Reset the target resources to refer to the resources in their new // location. setTargetResources(resourcesAtDestination .toArray(new IResource[resourcesAtDestination.size()]));
// copy only linked resource children (267173) if (source.isLinked() && source.getLocation().equals(existing.getLocation())) children = filterNonLinkedResources(children); ResourceDescription[] overwritten = copy(children, destinationPath, resourcesAtDestination, iterationProgress, uiInfo, false, createVirtual, createLinks, relativeToVariable); // We don't record the copy since this recursive call will // do so. Just record the overwrites. overwrittenResources.addAll(Arrays.asList(overwritten)); } else { // delete the destination folder, copying a linked folder // over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(1), uiInfo, false); iterationProgress.setWorkRemaining(100); if ((createLinks || createVirtual) && (source.isLinked() == false) && (source.isVirtual() == false)) { IFolder folder = workspaceRoot.getFolder(destinationPath); if (createVirtual) { folder.create(IResource.VIRTUAL, true, iterationProgress.split(1));
IResource[] children = ((IContainer) resource).members(); // move only linked resource children (267173) if (resource.isLinked() && resource.getLocation().equals(existing.getLocation())) children = filterNonLinkedResources(children); ResourceDescription[] overwritten = move(children, destinationPath, resourcesAtDestination, reverseDestinations, iterationProgress.split(90), uiInfo, false); // We don't record the moved resources since the recursive // call has done so. Just record the overwrites. overwrittenResources.addAll(Arrays.asList(overwritten)); // Delete the source. No need to record it since it // will get moved back. delete(resource, iterationProgress.split(10), uiInfo, false, false); } else { // delete the destination folder, moving a linked folder // over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(10), uiInfo, false); // Record the original path reverseDestinations.add(resource.getFullPath());
if (mapping == null) continue; ResourceTraversal[] traversals = null; try { traversals = mapping.getTraversals( ResourceMappingContext.LOCAL_CONTEXT, new NullProgressMonitor()); } catch (CoreException e) { StatusManager.getManager().handle(e, IDEWorkbenchPlugin.IDE_WORKBENCH); } if (traversals != null) { IResource[] resources = null; for (ResourceTraversal traversal : traversals) { resources = traversal.getResources(); if (resources != null) { result.addAll(Arrays.asList(resources)); } } } } else result.add(resource); } // all that can be converted are done, answer new selection if (result.isEmpty()) { return StructuredSelection.EMPTY; } return new StructuredSelection(result.toArray());
Map<MarkerQueryResult, Collection<IConfigurationElement>> resultsTable = entry.getValue(); if (resultsTable.containsKey(result)) { Iterator<IConfigurationElement> elements = resultsTable.get(result).iterator(); while (elements.hasNext()) { IConfigurationElement element = elements.next(); IMarkerResolutionGenerator generator = null; try { generator = (IMarkerResolutionGenerator) element.createExecutableExtension(ATT_CLASS); IMarkerResolution[] res = generator.getResolutions(marker); if (res != null) { resolutions.addAll(Arrays.asList(res)); } else { StatusManager.getManager() .handle(new Status(IStatus.ERROR, IDEWorkbenchPlugin.IDE_WORKBENCH, IStatus.ERROR, "Failure in " + generator.getClass().getName() + //$NON-NLS-1$ " from plugin " + element.getContributor().getName() + //$NON-NLS-1$ ": getResolutions(IMarker) must not return null", //$NON-NLS-1$ null), StatusManager.LOG); } } catch (CoreException e) { Policy.handle(e); } } } } }
IPath location = resources[i].getLocation(); // location may be null. See bug 29491. if (location != null) { fileNames[actualLength++] = location.toOSString(); } } if (actualLength > 0) { // was one or more of the locations null? if (actualLength < length) { String[] tempFileNames = fileNames; fileNames = new String[actualLength]; System.arraycopy(tempFileNames, 0, fileNames, 0, actualLength); } anEvent.data = fileNames; if (Policy.DEBUG_DND) System.out .println("ResourceDragAdapterAssistant.dragSetData set FileTransfer"); //$NON-NLS-1$ return true; } } } return false;
private INavigatorContentDescriptor contributor; private INavigatorContentDescriptor firstClassContributor; private NavigatorContentService contentService; /** * Construct a tracking set. * * @param aContentService */ public ContributorTrackingSet(NavigatorContentService aContentService) { contentService = aContentService; } /** * Construct a tracking set. * * @param aContentService * @param elements */ public ContributorTrackingSet(NavigatorContentService aContentService, Object[] elements) { super.addAll(Arrays.asList(elements)); contentService = aContentService; } @Override public boolean add(Object o) { if (contributor != null) { contentService.rememberContribution(contributor, firstClassContributor, o); } return super.add(o); } @Override public boolean remove(Object o) { contentService.forgetContribution(o); return super.remove(o); } @Override public void clear() { Iterator it = iterator(); while (it.hasNext()) contentService.forgetContribution(it.next()); super.clear(); } /** *
updateFilterActivation = true; } // We don't turn of non-UI visible filters here, they have to be manipulated explicitly if (!visibleFilterDescriptors[i].isVisibleInUi()) { if (nonUiVisible == null) nonUiVisible = new ArrayList<String>(); nonUiVisible.add(visibleFilterDescriptors[i].getId()); } } /* If so, update */ if (updateFilterActivation) { if (nonUiVisible != null) { nonUiVisible.addAll(Arrays.asList(filterIdsToActivate)); filterIdsToActivate = nonUiVisible.toArray(new String[]{}); } setActiveFilterIds(filterIdsToActivate); persistFilterActivationState(); updateViewer(); // the action providers may no longer be enabled, so we // reset the selection. StructuredViewer commonViewer = (StructuredViewer) contentService.getViewer(); commonViewer.setSelection(StructuredSelection.EMPTY); }
new WizardPatternFilter(), true); viewer = filteredTree.getViewer(); filteredTree.setFont(parent.getFont()); filteredTree.setQuickSelectionMode(true); viewer.setContentProvider(new WizardContentProvider()); viewer.setLabelProvider(new WorkbenchLabelProvider()); viewer.setComparator(DataTransferWizardCollectionComparator.INSTANCE); ArrayList inputArray = new ArrayList(); boolean expandTop = false; if (wizardCategories != null) { if (wizardCategories.getParent() == null) { inputArray.addAll(Arrays.asList(wizardCategories.getCategories())); } else { expandTop = true; inputArray.add(wizardCategories); } } // ensure the category is expanded. If there is a remembered expansion it will // be set later. if (expandTop) { viewer.setAutoExpandLevel(2); } AdaptableList input = new AdaptableList(inputArray); // filter wizard list according to capabilities that are enabled viewer.addFilter(new WizardActivityFilter()); viewer.setInput(input);
filterTree.setQuickSelectionMode(true); final TreeViewer treeViewer = filterTree.getViewer(); treeViewer.setContentProvider(new WizardContentProvider()); treeViewer.setLabelProvider(new WorkbenchLabelProvider()); treeViewer.setComparator(NewWizardCollectionComparator.INSTANCE); treeViewer.addSelectionChangedListener(this); ArrayList inputArray = new ArrayList(); inputArray.addAll(Arrays.asList(primaryWizards)); boolean expandTop = false; if (wizardCategories != null) { if (wizardCategories.getParent() == null) { inputArray.addAll(Arrays.asList(wizardCategories.getCategories())); } else { expandTop = true; inputArray.add(wizardCategories); } } // ensure the category is expanded. If there is a remembered expansion it will // be set later. if (expandTop) { treeViewer.setAutoExpandLevel(2); } AdaptableList input = new AdaptableList(inputArray); treeViewer.setInput(input); filterTree.setBackground(parent.getDisplay().getSystemColor(SWT.COLOR_WIDGET_BACKGROUND)); treeViewer.getTree().setFont(parent.getFont()); treeViewer.addDoubleClickListener(event -> {
queuedEvents.add(prefId); return; } if (listeners != null) { listeners.firePropertyChange(prefId); } } @Override public final void addListener(String[] eventsOfInterest, IPropertyMapListener listener) { if (listeners == null) { listeners = new PropertyListenerList(); attachListener(); } listeners.add(eventsOfInterest, listener); } protected final void firePropertyChange(String[] prefIds) { if (ignoreCount > 0) { queuedEvents.addAll(Arrays.asList(prefIds)); return; } if (listeners != null) { listeners.firePropertyChange(prefIds); } } public final void startTransaction() { ignoreCount++; } public final void endTransaction() { ignoreCount--; if (ignoreCount == 0 && !queuedEvents.isEmpty()) { if (listeners != null) { listeners.firePropertyChange((String[]) queuedEvents.toArray(new String[queuedEvents.size()])); } queuedEvents.clear(); } } @Override public boolean equals(Object toCompare) {
package org.eclipse.e4.ui.tests.workbench; import java.util.ArrayList; import java.util.Arrays; /** * Class used to capture the SWT structure expected when rendering a partuclar * UI model. */ public class SWTResult { public Class clazz; public String text; public ArrayList kids = new ArrayList(); public SWTResult(Class theClass, String theText, SWTResult[] children) { clazz = theClass; text = theText; if (children != null) { kids.addAll(Arrays.asList(children)); } } }
public void setSize(int size) { currentElements = new TestElement[size]; System.arraycopy(allElements, 0, currentElements, 0, currentElements.length);
public void addMember(String person){ TeamMember newMember = new TeamMember(person, this); TeamMember[] newMembers = new TeamMember[members.length + 1]; System.arraycopy(members, 0, newMembers, 0, members.length); newMembers[newMembers.length - 1] = newMember; members = null; members = newMembers; newMembers = null; fireModelChanged(new ComparatorModelChange(TestModelChange.INSERT, this, newMember));
protected LeasedSmtpConnection withConnectionPool(SmtpConnectionPool connectionPool) { m_connectionPool = connectionPool; return this;
protected Transport getTransport() { return m_transport; } public boolean isClosed() { return m_closed; }
* which causes them to return to step 1 and recheck for idle connections or space left in the pool.<br> * As soon as a connection is created, a background job is started which monitors idle connections. If they reach the * max idle time ({@link SmtpPoolMaxIdleTimeProperty}) or max connection lifetime, they are closed and removed from the * pool. */ @ApplicationScoped public class SmtpConnectionPool { private static final Logger LOG = LoggerFactory.getLogger(SmtpConnectionPool.class); protected static final String JOB_NAME_CLOSE_IDLE_CONNECTIONS = "smtp-close-idle-connections"; private final Object m_poolLock = new Object(); private final Set<SmtpConnectionPoolEntry> m_idleEntries = new HashSet<>(); private final Set<SmtpConnectionPoolEntry> m_leasedEntries = new HashSet<>(); private final String m_jobExecutionHint = "smtp-connection-pool." + UUID.randomUUID().toString(); private long m_lastPoolEntryNo = 0; private long m_maxIdleTime; private long m_maxConnectionLifetime; private boolean m_destroyed; /**
protected void destroy() { if (m_destroyed) { return; } synchronized (m_poolLock) { if (m_destroyed) { return; } Jobs.getJobManager().cancel(Jobs.newFutureFilterBuilder() .andMatchExecutionHint(m_jobExecutionHint) .toFilter(), true); Stream.of(m_idleEntries, m_leasedEntries) .flatMap(Collection::stream) .forEach(this::safeCloseTransport); m_idleEntries.clear(); m_leasedEntries.clear(); m_destroyed = true; }
kage org.eclipse.scout.rt.mail.smtp; import javax.mail.Session; import javax.mail.Transport; import org.eclipse.scout.rt.platform.Bean; @Bean public class SmtpConnectionPoolEntry { private String m_name; private SmtpServerConfig m_smtpServerConfig; private Session m_session; private Transport m_transport; // creation time of this pool entry object in milliseconds private long m_createTime; private long m_idleSince; public SmtpConnectionPoolEntry withName(String name) { m_name = name; return this; } public SmtpConnectionPoolEntry withSmtpServerConfig(SmtpServerConfig smtpServerConfig) { m_smtpServerConfig = smtpServerConfig; return this; } public SmtpConnectionPoolEntry withSession(Session session) { m_session = session; return this; } public SmtpConnectionPoolEntry withTransport(Transport transport) { m_transport = transport; return this; } public SmtpConnectionPoolEntry withCreateTime(long createTime) { m_createTime = createTime; return this; } public SmtpConnectionPoolEntry withIdleSince(long idleSince) { m_idleSince = idleSince; return this; } public Session getSession() {
} public Map<String, String> getAdditionalSessionProperties() { return m_additionalSessionProperties; } /** * These properties are added after the other properties, thus can override predefined properties such as host, port * or user. * * @param additionalSessionProperties * Additional properties used to create {@link Session} for SMTP server connection. */ public SmtpServerConfig withAdditionalSessionProperties(Map<String, String> additionalSessionProperties) { m_additionalSessionProperties = additionalSessionProperties; return this; } /** * @return Returns the poolSize specified for this {@link SmtpServerConfig} object. */ public int getPoolSize() { return m_poolSize; } /** * @param poolSize * Specifies the size of the connection pool to use with this {@link SmtpServerConfig#}. If 0, smtp * connection pooling is disabled. */ public SmtpServerConfig withPoolSize(int poolSize) { m_poolSize = poolSize; return this; } @Override public int hashCode() { final int prime = 31; int result = 1;
ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = -1; while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i);
// event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (TimeLineEvent ref : refs) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(ref); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
} TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (TimeLineEvent ref : refs) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(ref); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
***************************************************************************** * Copyright (c) 2019 Bachmann electronic GmbH and others. * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation ******************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.contexts.IEclipseContext; import org.eclipse.e4.ui.internal.workbench.E4Workbench; import org.eclipse.e4.ui.internal.workbench.swt.E4Application; import org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine; import org.eclipse.e4.ui.model.application.MApplication; import org.eclipse.e4.ui.model.application.ui.advanced.MArea; import org.eclipse.e4.ui.model.application.ui.basic.MCompositePart; import org.eclipse.e4.ui.model.application.ui.basic.MPart; import org.eclipse.e4.ui.model.application.ui.basic.MPartStack; import org.eclipse.e4.ui.model.application.ui.basic.MWindow;
***************************************************************************** * Copyright (c) 2019 IBM Corporation and others. * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Bachmann electronic GmbH - initial API and implementation ******************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.contexts.IEclipseContext; import org.eclipse.e4.ui.internal.workbench.E4Workbench; import org.eclipse.e4.ui.internal.workbench.swt.E4Application; import org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine; import org.eclipse.e4.ui.model.application.MApplication; import org.eclipse.e4.ui.model.application.ui.advanced.MArea; import org.eclipse.e4.ui.model.application.ui.basic.MCompositePart; import org.eclipse.e4.ui.model.application.ui.basic.MPart; import org.eclipse.e4.ui.model.application.ui.basic.MPartStack; import org.eclipse.e4.ui.model.application.ui.basic.MWindow;
public void testMultipleStacksUnderTheAreaCreateACTabFolder() { MWindow window = ems.createModelElement(MWindow.class); MArea area = ems.createModelElement(MArea.class); // Create two PartStacks with MParts inside MPartStack stack1 = ems.createModelElement(MPartStack.class); stack1.getChildren().add(ems.createModelElement(MPart.class)); stack1.getChildren().add(ems.createModelElement(MPart.class)); MPartStack stack2 = ems.createModelElement(MPartStack.class); stack2.getChildren().add(ems.createModelElement(MPart.class)); stack2.getChildren().add(ems.createModelElement(MPart.class)); // Place the containers in the area area.getChildren().add(stack1); area.getChildren().add(stack2); // Add area to the window window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext); wb.createAndRunUI(window); // Make sure the widget is now a CTabFolder
public void testStackInsideMCompositePartDoesNotCreateACTabFolder() { MWindow window = ems.createModelElement(MWindow.class); MArea area = ems.createModelElement(MArea.class); // Create a CompositePart with MParts inside MCompositePart composite = ems.createModelElement(MCompositePart.class); MPartStack stack1 = ems.createModelElement(MPartStack.class); stack1.getChildren().add(ems.createModelElement(MPart.class)); stack1.getChildren().add(ems.createModelElement(MPart.class)); MPartStack stack2 = ems.createModelElement(MPartStack.class); stack2.getChildren().add(ems.createModelElement(MPart.class)); stack2.getChildren().add(ems.createModelElement(MPart.class)); composite.getChildren().add(stack1); composite.getChildren().add(stack2); // Place the container in the area area.getChildren().add(composite); // Add area to the window window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext);
composite.getChildren().add(stack1); composite.getChildren().add(stack2); // Place the container in the area area.getChildren().add(composite); // Add area to the window window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext); wb.createAndRunUI(window); // Make sure the widget is not a CTabFolder Assert.assertFalse(area.getWidget() instanceof CTabFolder);
public void testDynamicItem_AddOne() { contextRule.createAndRunWorkbench(window); ToolBarManager tbm = getManager(toolBar); assertEquals(tbm.getSize(), 0); MToolItem toolItem1 = ems.createModelElement(MDirectToolItem.class); toolBar.getChildren().add(toolItem1); assertTrue(tbm.getSize() == 1);
protected int getThreshold() { // fixed default threshold provided up to v3.15 return 5;
public void refresh() { fCategoryViewer.refresh(); super.refresh();
import org.eclipse.cdt.core.dom.ast.cpp.ICPPConstructor; import org.eclipse.cdt.core.dom.ast.cpp.ICPPMethod; import org.eclipse.cdt.core.dom.ast.cpp.SemanticQueries; import org.eclipse.cdt.internal.core.dom.parser.ASTQueries; import org.eclipse.cdt.internal.core.dom.parser.cpp.ClassTypeHelper; import org.eclipse.cdt.internal.core.dom.parser.cpp.ICPPDeferredClassInstance; @SuppressWarnings("restriction") public class VirtualMethodCallChecker extends AbstractIndexAstChecker { public static final String VIRTUAL_CALL_ID = "org.eclipse.cdt.codan.internal.checkers.VirtualMethodCallProblem"; //$NON-NLS-1$ @Override public void processAst(IASTTranslationUnit ast) { ast.accept(new OnEachClass()); } private enum DECL_TYPE { CTOR, DTOR } class OnEachClass extends ASTVisitor { // NOTE: Classes can be nested and even can be declared in constructors of the other classes private final Stack<DECL_TYPE> ctorDtorStack = new Stack<>(); OnEachClass() { shouldVisitDeclarations = true;
private static SyscallLookup create() { try { IPath path = Activator.getDefault().getAbsolutePath(new Path(SYSCALL_TSV_PATH)); if (path != null) { File file = path.toFile(); if (!file.exists()) { Activator.getDefault().logError("Syscall names not available!"); //$NON-NLS-1$ return new SyscallLookup(Collections.emptyList()); } return new SyscallLookup(FileUtils.readLines(file, "UTF-8")); //$NON-NLS-1$ } } catch (IOException e) { Activator.getDefault().logError("Failed to read file", e); //$NON-NLS-1$ } return new SyscallLookup(Collections.emptyList());
* the provider is an instance of {@link IAnalysisModule}, analysis is also * scheduled. * <p> * If the trace has multiple analysis modules with the same secondary ID, * <code>null</code> is returned so the caller can try to make a * {@link TmfTreeXYCompositeDataProvider} for all the traces instead * * @param trace * A trace on which we are interested to fetch a model * @param secondaryId * The ID of the analysis to use for this provider * @return An instance of SegmentStoreDataProvider. Returns a null if the * ISegmentStoreProvider is null. * @since 4.0 */ public static @Nullable ITmfTreeDataProvider<? extends ITmfTreeDataModel> create(ITmfTrace trace, String secondaryId) { // The trace can be an experiment, so we need to know if there are multiple // analysis modules with the same ID Iterable<ISegmentStoreProvider> modules = TmfTraceUtils.getAnalysisModulesOfClass(trace, ISegmentStoreProvider.class);
public boolean visit(LambdaExpression lambdaExpression) { IMethodBinding binding = lambdaExpression.resolveMethodBinding(); IVariableBinding[] synVars = binding.getSyntheticOuterLocals(); if (synVars == null || synVars.length == 0) {// name cannot be updated if Synthetic Outer Locals are not available return true; } List<Field> allFields = underlyingThisObject.referenceType().fields(); ListIterator<Field> listIterator = allFields.listIterator(); int i = 0; if (getUnderlyingMethod().isStatic()) { if (synVars.length == allFields.size()) { while (listIterator.hasNext()) { FieldImpl field = (FieldImpl) listIterator.next(); String newName = synVars[i].getName(); FieldImpl newField = new FieldImpl((VirtualMachineImpl) field.virtualMachine(), (ReferenceTypeImpl) field.declaringType(), field.getFieldID(), newName, field.signature(), field.genericSignature(), field.modifiers()); listIterator.set(newField); } } } else { if (synVars.length + 1 == allFields.size()) { while (listIterator.hasNext()) { FieldImpl field = (FieldImpl) listIterator.next(); String newName = field.name();
int auto = repo.getConfig().getInt(ConfigConstants.CONFIG_GC_SECTION, ConfigConstants.CONFIG_KEY_AUTO, DEFAULT_AUTOLIMIT); if (auto <= 0) { return false; } int n = 0; int threshold = (auto + 255) / 256; Path dir = repo.getObjectsDirectory().toPath().resolve("17"); //$NON-NLS-1$ if (!Files.exists(dir)) { return false; } try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir, new DirectoryStream.Filter<Path>() { @Override public boolean accept(Path file) throws IOException { return Files.isRegularFile(file) && PATTERN_LOOSE_OBJECT .matcher(file.getFileName().toString()) .matches(); } })) { Iterator<Path> iter = stream.iterator(); while (iter.hasNext()) { if (n++ > threshold) { return true; } } } catch (IOException e) { LOG.error(e.getMessage(), e); } return false;
public void setAllChecked(boolean state) { for (TreeItem item: super.getTree().getItems()) item.setChecked(state); if (state) { // Find all visible children, add only the visible leaf nodes to the check state cache Object[] visible = getFilteredChildren(getRoot()); ITreeContentProvider contentProvider = null; if (getContentProvider() instanceof ITreeContentProvider) { contentProvider = (ITreeContentProvider) getContentProvider(); } if (contentProvider == null) { for (int i = 0; i < visible.length; i++) { checkState.add(visible[i]); } } else { Set<Object> toCheck = new HashSet<>(); for (Object element : visible) { addFilteredChildren(element, contentProvider, toCheck); } checkState.addAll(toCheck); } } else { // Remove any item in the check state that is visible (passes the filters) if (checkState != null) { Object[] visible = filter(checkState.toArray()); for (Object element : visible) { checkState.remove(element); } } } } /**
* return the token. * * @return the {@link IToken}, or {@code null} if none. */ protected IToken scanToken() { return null; } private @NonNull Set<IHyperlinkDetector> getHyperlinkDetectors() { Set<IHyperlinkDetector> allDetectors = new LinkedHashSet<>(); IHyperlinkDetector[] configuredDetectors = configuration .getHyperlinkDetectors(viewer); if (configuredDetectors != null && configuredDetectors.length > 0) { allDetectors.addAll(Arrays.asList(configuredDetectors)); if (preferenceStore.getBoolean(URL_HYPERLINK_DETECTOR_KEY) || !preferenceStore.getBoolean( AbstractTextEditor.PREFERENCE_HYPERLINKS_ENABLED)) { return allDetectors; } // URLHyperlinkDetector can only detect hyperlinks at the start of // the range. We need one that can detect all hyperlinks in a given // region. allDetectors.add(new MultiURLHyperlinkDetector()); } return allDetectors; } /** * A {@link URLHyperlinkDetector} that returns all hyperlinks in a region. * <p> * This internal class assumes that the region is either empty or else spans
public static boolean evaluateNoexceptSpecifier(ICPPEvaluation noexceptSpecifier) { if (noexceptSpecifier != null && noexceptSpecifier.getValue() instanceof IntegralValue) { IntegralValue v = (IntegralValue) noexceptSpecifier.getValue(); if (v.numberValue() != null) return v.numberValue().longValue() == 1; } return false;
candidate = entry; it.remove(); break; } } if (candidate != null && !candidate.getTransport().isConnected()) { LOG.debug("Releasing pooled SMTP connection {}; transport is already closed, not returning to idle pool.", candidate); candidate = null; } if (candidate != null) { IDateProvider dateProvider = BEANS.get(IDateProvider.class); P_ReuseCheckResult reuseCheckResult = isReuseAllowed(candidate); if (reuseCheckResult.isReuseAllowed()) { LOG.debug("Releasing pooled SMTP connection {}; returning to idle pool.", candidate); candidate.withIdleSince(dateProvider.currentMillis().getTime()); m_idleEntries.add(candidate); } else { LOG.debug("Releasing pooled SMTP connection {}; pooled connection reached max lifetime of {}s, not returning to idle pool.", candidate, m_maxConnectionLifetime / 1000d); } } m_poolLock.notifyAll(); }
} /** * These properties are added after the other properties, thus can override predefined properties such as host, port * or user. * * @param additionalSessionProperties * Additional properties used to create {@link Session} for SMTP server connection. */ public SmtpServerConfig withAdditionalSessionProperties(Map<String, String> additionalSessionProperties) { m_additionalSessionProperties = additionalSessionProperties; return this; } /** * @return Returns the size of the connection pool to use with this {@link SmtpServerConfig}. If 0, smtp connection * pooling is disabled. */ public int getPoolSize() { return m_poolSize; } /** * @param poolSize * Specifies the size of the connection pool to use with this {@link SmtpServerConfig#}. If 0, smtp * connection pooling is disabled. */ public SmtpServerConfig withPoolSize(int poolSize) { m_poolSize = poolSize; return this; } @Override public int hashCode() { final int prime = 31; int result = 1;
int cpusNode = cpuSs.getQuarkAbsolute(Attributes.CPUS); final @NonNull List<@NonNull Integer> subAttributes = cpuSs.getSubAttributes(cpusNode, false); int cpus = Integer.MIN_VALUE; for (Integer quark : subAttributes) { cpus = Math.max(Integer.parseInt(cpuSs.getAttributeName(quark)), cpus); } return Math.max(subAttributes.size(), cpus); } catch (AttributeNotFoundException e) { Activator.getDefault().logError(e.getMessage(), e); } } return -1;
if (cpuSs != null) { try { int cpusNode = cpuSs.getQuarkAbsolute(Attributes.CPUS); final @NonNull List<@NonNull Integer> subAttributes = cpuSs.getSubAttributes(cpusNode, false); int cpus = Integer.MIN_VALUE; for (Integer quark : subAttributes) { cpus = Math.max(Integer.parseInt(cpuSs.getAttributeName(quark)), cpus); } return Math.max(subAttributes.size(), cpus); } catch (AttributeNotFoundException e) { Activator.getDefault().logError("Error: getting number of core " + e.getMessage(), e); //$NON-NLS-1$ } } return -1;
if (url == null) { return false; } if (WORKSPACE_CHECK_REFERENCE_BUNDLE_VERSION == null) { // no reference bundle installed, no check possible return true; } Version version = readWorkspaceVersion(url); // if the version could not be read, then there is not any existing // workspace data to trample, e.g., perhaps its a new directory that // is just starting to be used as a workspace if (version == null) { return true; } int versionCompareResult = compareWorkspaceAndIdeVersions(url); // equality test is required since any version difference (newer // or older) may result in data being trampled if (versionCompareResult == 0) { return true; } // At this point workspace has been detected to be from a version // other than the current ide version -- find out if the user wants // to use it anyhow.
public @Nullable ImageDescriptor getImageDescripterFromPath(String path) { return AbstractUIPlugin.imageDescriptorFromPlugin(PLUGIN_ID, path);
} else if (columnIndex == 1) { try { return attribute.getDisplayableString(); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else if (columnIndex == 2) { try { return String.valueOf(attribute.getId()); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else if (columnIndex == 3) { try { return attribute.getAttributeType().getIdString(); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else { return String.valueOf(attribute.getGammaId()); }
super.applyId(value); onUrlDependencyChanged(value); } @Override protected void applyVersion(String value) throws CoreException { super.applyVersion(value); onUrlDependencyChanged(value); } private void onUrlDependencyChanged(String dependencyValue) throws CoreException { boolean includeUrl = (dependencyValue != null) && fIncludeUrlCheckbox.getSelection(); applyUrl(includeUrl); updateUrlEnablement(); } private void applyUrl(boolean include) throws CoreException { ISiteFeature feature = getCurrentItem(); if (feature != null) { String value = include ? recomputeUrl() : null; feature.setURL(value); } } private String recomputeUrl() { ISiteFeature feature = getCurrentItem(); if (feature == null) { return null; } StringBuilder sb = new StringBuilder(); sb.append("features/").append(feature.getId()).append("_"); //$NON-NLS-1$ //$NON-NLS-2$ try { sb.append(new Version(feature.getVersion())); } catch (Exception e) { sb.append("0.0.0"); //$NON-NLS-1$ } sb.append(".jar"); //$NON-NLS-1$
public static SyscallLookup getInstance() { SyscallLookup instance = sInstance; if(instance == null) { instance = create(); INSTANCE = instance; } return instance;
private static SyscallLookup create() { try { IPath path = Activator.getDefault().getAbsolutePath(new Path(SYSCALL_TSV_PATH)); if (path != null) { File file = path.toFile(); if (!file.exists()) { Activator.getDefault().logWarning("Syscall names not available!"); //$NON-NLS-1$ return new SyscallLookup(Collections.emptyList()); } return new SyscallLookup(FileUtils.readLines(file, "UTF-8")); //$NON-NLS-1$ } } catch (IOException e) { Activator.getDefault().logError("Failed to read file", e); //$NON-NLS-1$ } return new SyscallLookup(Collections.emptyList());
dependentSelector.getCurrentCandidate())) { // return false since we do not want to allow this requirement // to substitute the capability return false; } } } } } } return candidates.getRemainingCandidateCount() > 1 || Util.isOptional(req); } return false; } static class DynamicImportFailed extends ResolutionError { private final Requirement requirement; public DynamicImportFailed(Requirement requirement) { this.requirement = requirement; } public String getMessage() { return "Dynamic import failed."; } @Override public Collection<Requirement> getUnresolvedRequirements() { return Collections.singleton(requirement); } @Override public ResolutionException toException() { return new ReasonException(ReasonException.Reason.DynamicImport, getMessage(), null, getUnresolvedRequirements()); } } static class FragmentNotSelectedError extends ResolutionError { private final Resource resource; public FragmentNotSelectedError(Resource resource) { this.resource = resource; } @Override public String getMessage() {
if (type == null) { return value; } IJavaStackFrame stackFrame = getStackFrame(javaValue); if (stackFrame == null) { return value; } IJavaProject project = JavaDebugUtils.resolveJavaProject(stackFrame); if (project == null) { return value; } IAstEvaluationEngine evaluationEngine = JDIDebugPlugin.getDefault() .getEvaluationEngine(project, (IJavaDebugTarget) stackFrame.getDebugTarget()); EvaluationBlock evaluationBlock = new EvaluationBlock(javaValue, type, (IJavaThread) stackFrame.getThread(), evaluationEngine); if (fValue == null) { // evaluate each variable IJavaVariable[] variables = new IJavaVariable[fVariables.length]; for (int i = 0; i < fVariables.length; i++) { variables[i] = new JDIPlaceholderVariable(fVariables[i][0], evaluationBlock.evaluate(fVariables[i][1]), javaValue); } return new LogicalObjectStructureValue(javaValue, variables); } // evaluate the logical value IJavaValue logicalValue = evaluationBlock.evaluate(fValue); if (logicalValue instanceof JDIValue) {
.getEvaluationEngine(project, (IJavaDebugTarget) stackFrame.getDebugTarget()); EvaluationBlock evaluationBlock = new EvaluationBlock(javaValue, type, (IJavaThread) stackFrame.getThread(), evaluationEngine); if (fValue == null) { // evaluate each variable IJavaVariable[] variables = new IJavaVariable[fVariables.length]; for (int i = 0; i < fVariables.length; i++) { variables[i] = new JDIPlaceholderVariable(fVariables[i][0], evaluationBlock.evaluate(fVariables[i][1]), javaValue); } return new LogicalObjectStructureValue(javaValue, variables); } // evaluate the logical value IJavaValue logicalValue = evaluationBlock.evaluate(fValue); if (logicalValue instanceof JDIValue) { ((JDIValue) logicalValue).setLogicalParent(javaValue); } return logicalValue; } catch (CoreException e) { if (e.getStatus().getCode() == IJavaThread.ERR_THREAD_NOT_SUSPENDED) { throw e; } JDIDebugPlugin.log(e); } return value; } /** * Returns the <code>IJavaReferenceType</code> from the specified
private void createLink(String prefix, final Artifact art, String action, Artifact thisArt, RelationTypeSide relation) { try { Label label = editor.getToolkit().createLabel(this, prefix + " \"" + getObjectName( thisArt) + "\" " + action + getCompletedCancelledString(art) + " \"" + getObjectName(art) + "\" "); Hyperlink link = editor.getToolkit().createHyperlink(this, String.format("\"%s\" - %s", art.getName().length() < 60 ? art.getName() : art.getName().substring(0, 60), AtsClientService.get().getAtsId(art)), SWT.NONE); if (art.equals(thisArt)) { artAndRelToHyperlink.put(thisArt, relation, link); artAndRelToLabel.put(thisArt, relation, label); } else { artAndRelToHyperlink.put(art, relation, link); artAndRelToLabel.put(art, relation, label); } link.addHyperlinkListener(new IHyperlinkListener() { @Override public void linkEntered(HyperlinkEvent e) { // do nothing
IASTExpression fNameExp = fCall.getFunctionNameExpression(); IBinding fBinding = null; if (fNameExp instanceof IASTIdExpression) { IASTIdExpression fName = (IASTIdExpression) fNameExp; fBinding = fName.getName().resolveBinding(); } else if (fNameExp instanceof IASTFieldReference) { IASTFieldReference fName = (IASTFieldReference) fNameExp; if (referencesThis(fName.getFieldOwner())) fBinding = fName.getFieldName().resolveBinding(); } if (fBinding instanceof ICPPMethod) { ICPPMethod method = (ICPPMethod) fBinding; if (method.isPureVirtual() || ClassTypeHelper.isVirtual(method)) { reportProblem(VIRTUAL_CALL_ID, expression); } } } } return PROCESS_CONTINUE;
fBinding = fName.getName().resolveBinding(); } else if (fNameExp instanceof IASTFieldReference) { IASTFieldReference fName = (IASTFieldReference) fNameExp; if (referencesThis(fName.getFieldOwner())) fBinding = fName.getFieldName().resolveBinding(); } if (fBinding != null && fBinding instanceof ICPPMethod) { ICPPMethod method = (ICPPMethod) fBinding; if (method.isPureVirtual() || ClassTypeHelper.isVirtual(method)) { reportProblem(VIRTUAL_CALL_ID, problemNode); } } } } return PROCESS_CONTINUE;
if (functionDefinition.isDefaulted() && SemanticQueries.isCopyOrMoveConstructor(constructor)) return null; if (constructor.getClassOwner().getKey() == ICompositeType.k_union) return null; // Skip delegating constructors. for (ICPPASTConstructorChainInitializer memberInitializer : functionDefinition .getMemberInitializers()) { IASTName memberName = memberInitializer.getMemberInitializerId(); if (memberName != null) { IBinding memberBinding = memberName.resolveBinding(); ICPPClassType classType = null; if (memberBinding instanceof ICPPConstructor) { classType = ((ICPPConstructor) memberBinding).getClassOwner(); } if (classType instanceof ICPPDeferredClassInstance) { classType = ((ICPPDeferredClassInstance) classType).getClassTemplate(); } if (classType != null && classType.isSameType(constructor.getClassOwner())) return null; } } return constructor; } } return null;
* {@link org.eclipse.tracecompass.tmf.ui.viewers.events.TmfEventsTable#TmfEventsTable(org.eclipse.swt.widgets.Composite, int, java.util.Collection)} * * @author Alexandre Montplaisir * @noextend This class should not be extended directly. You should instead * implement an {@link ITmfEventAspect}. */ @NonNullByDefault public class TmfEventTableColumn { // ------------------------------------------------------------------------ // Fields // ------------------------------------------------------------------------ private final List<ITmfEventAspect<?>> fAspects = new ArrayList<>(); // ------------------------------------------------------------------------ // Constructors // ------------------------------------------------------------------------ /** * Constructor * * @param aspect * The {@link ITmfEventAspect} to be used to populate this * column. */ public TmfEventTableColumn(ITmfEventAspect<?> aspect) { fAspect = aspect; fAspectDuplicate.add(aspect); } // ------------------------------------------------------------------------ // adders // ------------------------------------------------------------------------ /** * Add another Aspect with the same name * * @param duplicate * the aspect with the same name * @since 5.0 */
public TmfEventTableColumn(ITmfEventAspect<?> aspect) { fAspects.add(aspect);
public String getItemString(ITmfEvent event) { final String EMPTY_STRING = ""; //$NON-NLS-1$ String s = NonNullUtils.nullToEmptyString(fAspect.resolve(event)); if (fAspectDuplicate.size() > 1 && s.equals(EMPTY_STRING)) { for (int i = 1; i < fAspectDuplicate.size(); i++) { String eventString = NonNullUtils.nullToEmptyString(fAspectDuplicate.get(i).resolve(event)); if (eventString != EMPTY_STRING) { s = eventString; } } } return EMPTY_STRING;
public String getItemString(ITmfEvent event) { for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if(eventString != EMPTY_STRING) { return eventString; } } return EMPTY_STRING;
public String getItemString(ITmfEvent event) { final String EMPTY_STRING = ""; //$NON-NLS-1$ for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if (eventString != EMPTY_STRING) { return eventString; } } return EMPTY_STRING;
public String getItemString(ITmfEvent event) { for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if (!eventString.isEmpty()) { return eventString; } } return EMPTY_STRING;
***************************************************************************** * Copyright (c) 2011-2019 EclipseSource Muenchen GmbH and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Johannes Faltermeier - initial API and implementation ******************************************************************************/ package org.eclipse.emf.emfstore.client.test.ui.controllers; import java.io.IOException; import org.eclipse.emf.emfstore.common.ESObserver; import org.eclipse.emf.emfstore.internal.client.model.ESWorkspaceProviderImpl; import org.eclipse.emf.emfstore.internal.client.ui.controller.UIShowHistoryController; import org.eclipse.emf.emfstore.internal.common.observer.ObserverExceptionListener; import org.eclipse.emf.emfstore.server.exceptions.ESException; import org.eclipse.swtbot.eclipse.finder.widgets.SWTBotView; import org.eclipse.swtbot.swt.finder.finders.UIThreadRunnable; import org.eclipse.swtbot.swt.finder.results.VoidResult; import org.junit.Test; public class UIHistoryViewCloseTest extends AbstractUIControllerTestWithCommit { @Override @Test public void testController() throws ESException {
public void init(IWorkbench workbench) { setDescription(PREFERENCE_PAGE_DESCRIPTION); setPreferenceStore(new ScopedPreferenceStore(InstanceScope.INSTANCE, CAPRA_PREFERENCE_PAGE_ID));
* side * * MasterDetailRenderer implements IEditingDomainProvider to allow Undo/Redo/Copy/Cut/Paste actions to be performed * externally. * * MasterDetailRenderer provides an ISelectionProvider to get the currently selected items in the tree * */ @SuppressWarnings("restriction") public class TreeMasterDetailComposite extends Composite implements IEditingDomainProvider { /** The input. */ private final Object input; /** The editing domain. */ private final EditingDomain editingDomain; /** The tree viewer. */ private TreeViewer treeViewer; /** The selection provider. */ private IMasterDetailSelectionProvider selectionProvider; /** The vertical sash. */ private Sash verticalSash; /** The detail scrollable composite. */ private Composite detailComposite; /** Manager of the currently rendered ECPSWTView with caching. */ private DetailViewManager detailManager; private Object lastRenderedObject; private final TreeMasterDetailSWTCustomization customization;
public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { boolean result = false; for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { // check if os/arch is different String propOs = property.getOs().trim(); if (ALL_OS.equals(propOs) || ALL_OS.equals(os)) { return true; } else if (os.equals(propOs)) { String propArch = property.getArch(); // length zero means all architecture versions if (arch.length() == 0 || propArch.length() == 0) { result = true; break; } } else { continue; } } } return result;
public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { boolean result = false; for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { // check if os/arch is different String propOs = property.getOs().trim(); if (ALL_OS.equals(propOs) || ALL_OS.equals(os)) { return true; } else if (os.equals(propOs)) { String propArch = property.getArch(); // length zero means all architecture versions if (arch.length() == 0 || propArch.length() == 0) { result = true; break; } } else { continue; } } } return result;
if (name.equals(property.getName().trim())) { // check if os/arch is different String propOs = property.getOs().trim(); // length zero means all OS versions if (propOs.length() == 0 || os.length() == 0) { result = true; break; } else if (os.equals(propOs)) { String propArch = property.getArch(); if (ALL_ARCH.equals(arch) || ALL_ARCH.equals(propArch)) { return true; } } else { continue; } } } return result;
// check if os/arch is different String propOs = property.getOs().trim(); // length zero means all OS versions if (propOs.length() == 0 || os.length() == 0) { result = true; break; } else if (os.equals(propOs)) { String propArch = property.getArch(); if (ALL_ARCH.equals(arch) || ALL_ARCH.equals(propArch)) { return true; } } else { continue; } } } return result;
String propOs = property.getOs().trim(); // length zero means all OS versions if (propOs.length() == 0 || os.length() == 0) { result = true; break; } else if (os.equals(propOs)) { String propArch = property.getArch(); // length zero means all architecture versions if (arch.length() == 0 || propArch.length() == 0) { result = true; break; } } } } return result;
IConfigurationProperty configuration = (IConfigurationProperty) obj; switch (index) { case 0 : return configuration.getName(); //return super.getColumnText(PluginRegistry.findModel(configuration.getId()), index); case 1 : return configuration.getValue(); case 2 : return configuration.getOs(); case 3 : return configuration.getArch(); } return null; } } private class PropertyDialog extends StatusDialog { private static final String ALL_ARCH = ""; //$NON-NLS-1$ private static final String ALL_OS = ""; //$NON-NLS-1$ private Text fName; private Text fValue; private Combo fOS; private Combo fArch; private IConfigurationProperty fEdit; private Set<IConfigurationProperty> fExistingProperties; private String[] COMBO_OSLABELS = new String[] { PDEUIMessages.PropertiesSection_All, Platform.OS_LINUX, Platform.OS_MACOSX, Platform.OS_WIN32 }; private String[] COMBO_ARCHLABELS = new String[] { PDEUIMessages.PropertiesSection_All, Platform.ARCH_X86, Platform.ARCH_X86_64 }; public PropertyDialog(Shell shell, IConfigurationProperty property, Set<IConfigurationProperty> existingProperties) { super(shell); fEdit = property;
public void addEvent(ITimeEvent event) { if (isValidEvent(event)) { super.addEvent(event); } super.addEvent(event);
public void setEventList(List<ITimeEvent> eventList) { if (eventList != null) { // Sets a filtered list super.setEventList(eventList.stream().map(timeEvent -> isValidEvent(timeEvent) ? timeEvent : null).collect(Collectors.toList())); }
public void updateZoomedEvent(ITimeEvent event) { if (isValidEvent(event)) { super.updateZoomedEvent(event); }
private static boolean isValidEvent(ITimeEvent event) { return (event instanceof TimeLineEvent);
// add style Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; seriesToAdd.add(new LongPoint(x, val)); } } if (isEmpty) { return; } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha); gc.setForeground(color); List<LongPoint> series = seriesModel.get(i);
public String toString() { return getClass().getSimpleName() + " time=" + fTime + " value=[" + getLabel() + ']'; //$NON-NLS-1$ //$NON-NLS-2$
seriesModel.add(new ArrayList<>()); // add style Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } /* * In the case of missing data, (WHICH SHOULD NOT HAPPEN, just * persist the current value. */ long val = values.get(i); // get max and min, this is a relative scale. max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } } } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i);
// add style Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } /* * In the case of missing data, (WHICH SHOULD NOT HAPPEN, just * persist the current value. */ long val = values.get(i); // get max and min, this is a relative scale. max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } } } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i);
Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } /* * In the case of missing data, (WHICH SHOULD NOT HAPPEN, just * persist the current value. */ long val = values.get(i); // get max and min, this is a relative scale. max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } } } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString());
public void addEvent(ITimeEvent event) { isValidEvent(event); super.addEvent(event);
RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } /* * In the case of missing data, (WHICH SHOULD NOT HAPPEN, just * persist the current value. */ if (values.size() < i) { long val = values.get(i); // get max and min, this is a relative scale. max = Math.max(Math.abs(val), max); min = 0; seriesToAdd.add(new LongPoint(x, val)); } } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha();
throw new IllegalArgumentException("Needs to be a TimeLineEvent"); //$NON-NLS-1$ } super.setEventList(eventList); } @Override public void updateZoomedEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Needs to be a TimeLineEvent"); //$NON-NLS-1$ } super.updateZoomedEvent(event); } @Override public DisplayStyle getStyle() { return DisplayStyle.LINE; } }
* accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.widgets.timegraph.model; import java.text.NumberFormat; import java.util.ArrayList; import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.StringJoiner; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.ITimeGraphEntry; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.TimeEvent; /** * Generic TimeLineEvent implementation, basically a point with multiple * potential Y values and one X * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; private String fLabel = null; /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry * The entry matching this event
*******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.widgets.timegraph.model; import java.text.NumberFormat; import java.util.ArrayList; import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.StringJoiner; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.ITimeGraphEntry; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.TimeEvent; /** * Generic TimeEvent implementation * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { /** * One time line X and mutliple Ys. Able to support multiple lines for a * series. */ private final List<Long> fValues; private String fLabel = null; /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values
/** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values * The values to display at this given timestamp */ public TimeLineEvent(ITimeGraphEntry entry, long time, List<Long> values) { super(entry, time, 0); fValues = values; } /** * Add a value * * @param value * the value to add, it will be displayed as a line */ public void addValue(long value) { fValues.add(value); } @Override public String getLabel() { String label = fLabel; if (label == null) {
private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { // clamp 0 - max positive long max = Long.MIN_VALUE; long min = 0; List<List<LongPoint>> seriesModel = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = -1; boolean isEmpty = true; while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); }
public void setEventList(List<ITimeEvent> eventList) { sanitizeList(eventList, super::setEventList);
public String getLabel() { String label = fLabel; if (label == null) { StringJoiner sj = new StringJoiner(", "); //$NON-NLS-1$ getValues().forEach((Long value) -> sj.add(value == null ? String.valueOf(value) : NumberFormat.getNumberInstance(Locale.getDefault()).format(value))); label = sj.toString(); fLabel = label; } return label;
public List<Long> getValues() { return Collections.unmodifiableList(fValues);
public void register() { Chart chart = getChart(); chart.getPlotArea().addMouseMoveListener(this); chart.getPlotArea().addPaintListener(this); fTooltipHandler.activateHoverHelp(chart.getPlotArea());
public void deregister() { Chart chart = getChart(); if ((chart != null) && !chart.isDisposed()) { chart.getPlotArea().removeMouseMoveListener(this); chart.getPlotArea().removePaintListener(this); fTooltipHandler.deactivateHoverHelp(chart.getPlotArea()); }
for (int i = 0; i < 10; i++) { appendRandomLine(f); git.add().addFilepattern("file").call(); git.commit().setMessage("message" + i).call(); } FileBasedConfig c = db.getConfig(); c.setInt(ConfigConstants.CONFIG_GC_SECTION, null, ConfigConstants.CONFIG_KEY_AUTOPACKLIMIT, 1); c.save(); Collection<PackFile> packs = gc(Deflater.NO_COMPRESSION); assertEquals("expected 1 packfile after gc", 1, packs.size()); PackFile p1 = packs.iterator().next(); PackFileSnapshot snapshot = p1.getFileSnapshot(); packs = gc(Deflater.BEST_COMPRESSION); assertEquals("expected 1 packfile after gc", 1, packs.size()); PackFile p2 = packs.iterator().next(); File pf = p2.getPackFile(); // changing compression level with aggressive gc may change size, // fileKey (on *nix) and checksum. Hence FileSnapshot.isModified can // return true already based on size or fileKey.
public void setEventList(List<ITimeEvent> eventList) { sanitizeList(eventList, super::setEventList);
public void addValue(@Nullable Long value) { fValues.add(value); fLabel = null;
protected SWTBotTreeItem[] getPaneBasedSelectionWizardTreeitems() { SWTBotSiriusDiagramEditor representation = (SWTBotSiriusDiagramEditor) openRepresentation(localSession.getOpenedSession(), REPRESENTATION_DESCRIPTION_NAME, REPRESENTATION_NAME, DDiagram.class); representation.setFocus(); representation.activateTool("Pane Based Selection"); representation.click(50, 100); SWTBot wizardBot = SWTBotSiriusHelper.getShellBot("Pane Based"); SWTBotTree tree = wizardBot.tree().select(0); SWTBotTreeItem swtBotTreeItem = tree.getAllItems()[0]; SWTBotTreeItem[] items = swtBotTreeItem.getItems(); return items;
assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } /** * Test the cancel on the first wizard. * */ public void testCancelFirstWizard() { cancelFirstWizard(); Session session = localSession.getOpenedSession(); assertNotNull(THERE_IS_NO_SESSION, session); assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } /** * Test the cancel on the first wizard. * */ public void testCancelSecondWizard() { cancelSecondWizard(TREE_NAME); Session session = localSession.getOpenedSession(); assertNotNull(THERE_IS_NO_SESSION, session); assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } /** * Test that empty viewpoint are not displayed */ public void testEmptySirius() { // create representation createOnContextMenu(); // select representation to create bot.waitUntil(Conditions.shellIsActive("Create Representation Wizard")); SWTBotShell shell = bot.shell("Create Representation Wizard");
public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { // check if os/arch is different String propOs = property.getOs() != null ? property.getOs().trim() : ALL_OS; if (ALL_OS.equals(propOs) || ALL_OS.equals(os) || propOs.equals(os)) { String propArch = property.getArch() != null ? property.getArch().trim() : ""; //$NON-NLS-1$ if (propArch.equals(arch) || ALL_ARCH.equals(arch) || ALL_ARCH.equals(propArch)) { return true; } } } } return false;
* * SPDX-License-Identifier: EPL-2.0 * * Contributors: * AixpertSoft GmbH - initial API and implementation *******************************************************************************/ package org.eclipse.pde.core.tests.internal.util; import java.util.HashSet; import java.util.Set; import junit.framework.TestCase; import org.eclipse.core.runtime.Platform; import org.eclipse.pde.internal.core.iproduct.IConfigurationProperty; import org.eclipse.pde.internal.core.product.ProductModel; import org.eclipse.pde.internal.core.product.ProductModelFactory; import org.eclipse.pde.internal.core.util.PDESchemaHelper; public class PDESchemaHelperTest extends TestCase { private ProductModelFactory fProductModelFactory; Set<IConfigurationProperty> fConfigurationProperties = new HashSet<>(); public PDESchemaHelperTest() { initConfigurationProperties(); } private void initConfigurationProperties() { ProductModel productModel = new ProductModel(); fProductModelFactory = new ProductModelFactory(productModel); // create a single property for win32 / all architectures IConfigurationProperty property = fProductModelFactory.createConfigurationProperty(); property.setName("org.osgi.instance.area");
private static void sanitizeList(List<ITimeEvent> sourceList, Consumer<List<ITimeEvent>> listConsumer) { if (sourceList != null) { // Sets a filtered list List<ITimeEvent> events = new ArrayList<>(); for (ITimeEvent event : sourceList) { if (isValidEvent(event)) { events.add(event); } } listConsumer.accept(events); }
} private void appendRandomLine(File f, int length, Random r) throws IOException { try (Writer w = Files.newBufferedWriter(f.toPath(), StandardOpenOption.APPEND)) { appendRandomLine(w, length, r); } } private void appendRandomLine(File f) throws IOException { appendRandomLine(f, 5, new Random()); } private void appendRandomLine(Writer w, int len, Random r) throws IOException { final int a = 32; // ' ' int e = 126; // '~' for (int i = 0; i < len; i++) { w.append((char) (a + r.nextInt(1 + e - a))); } } private Git createTestRepo(int testDataSeed, int testDataLength) throws IOException, GitAPIException, NoFilepatternException, NoHeadException, NoMessageException, UnmergedPathsException, ConcurrentRefUpdateException, WrongRepositoryStateException, AbortedByHookException { // Create a repo with two commits and one file. Each commit adds // testDataLength number of bytes. Data are random bytes. Since the
appendRandomLine(f, testDataLength, r); git.add().addFilepattern("file").call(); git.commit().setMessage("message2").call().getId(); return git; } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetectModificationAlthoughSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); // tell JGit not to used mtime of the parent folder to detect file // modifications. config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null);
git.commit().setMessage("message2").call().getId(); return git; } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetectModificationAlthoughSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); // tell JGit not to used mtime of the parent folder to detect file // modifications. config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum();
git.commit().setMessage("message2").call().getId(); return git; } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetectModificationAlthoughSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); // tell JGit not to used mtime of the parent folder to detect file // modifications. config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum();
// content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); // don't use mtime of the parent folder to detect file modification. config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); String name = pf.getPackName(); Long length = Long.valueOf(pf.getPackFile().length()); long m1 = packFilePath.toFile().lastModified();
// content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); // don't use mtime of the parent folder to detect file modification. config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); String name = pf.getPackName(); Long length = Long.valueOf(pf.getPackFile().length()); long m1 = packFilePath.toFile().lastModified();
.getPackChecksum()); assumeTrue(m3 == m2); } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // To avoid that JGit detects modifications by checking the filekey create // two new packfiles upfront and create copies of them. Then modify the // packfiles inplace by opening them for write and copy content. @Test public void testDetectModificationAlthoughSameSizeAndModificationtimeAndFileKey() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile. Make a copy of it PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); Path packFileBasePath = packFilePath.resolveSibling(
.getPackChecksum()); assumeTrue(m3 == m2); } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // To avoid that JGit detects modifications by checking the filekey create // two new packfiles upfront and create copies of them. Then modify the // packfiles inplace by opening them for write and copy content. @Test public void testDetectModificationAlthoughSameSizeAndModificationtimeAndFileKey() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile. Make a copy of it PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); Path packFileBasePath = packFilePath.resolveSibling(
Long oldLength, AnyObjectId oldChkSum) throws IOException, ParseException { PackFile p = getSinglePack(gc(compressionLevel)); File pf = p.getPackFile(); // The following two assumptions should not cause the test to fail. If // on a certain platform we get packfiles where the lengths differ or // the checksums don't differ we just skip this test. A reason for that // could be that compression works differently or random number // generator works differently. Then we have to search for more // consistent // test data or checkin these packfiles as test resources assumeTrue(oldLength == null || pf.length() == oldLength.longValue()); assumeTrue(oldChkSum == null || !p.getPackChecksum().equals(oldChkSum)); assertTrue(oldName == null || p.getPackName().equals(oldName)); return p; } // private void printFilesMetaData(Path... paths) throws IOException { // for (Path p : paths) { // System.out.println(describe(p)); // } // }
public void setImage (Image image) { checkWidget (); if ((style & SWT.SEPARATOR) != 0) return; if (image != null && image.isDisposed()) error(SWT.ERROR_INVALID_ARGUMENT); this.image = image; updateStyleBits(image == null); OS.InvalidateRect (handle, null, true);
public void setText (String string) { checkWidget (); if (string == null) error (SWT.ERROR_NULL_ARGUMENT); if ((style & SWT.SEPARATOR) != 0) return; updateStyleBits(true); /* * Feature in Windows. For some reason, SetWindowText() for * static controls redraws the control, even when the text has * has not changed. The fix is to check for this case and do * nothing. */ if (string.equals (text)) return; text = string; string = Display.withCrLf (string); TCHAR buffer = new TCHAR (getCodePage (), string, true); OS.SetWindowText (handle, buffer); if ((state & HAS_AUTO_DIRECTION) != 0) { updateTextDirection (AUTO_TEXT_DIRECTION); }
protected List<ISourceContainer> getEntriesAsList() { ISourceContainer[] entries = getViewer().getEntries(); List<ISourceContainer> list = new ArrayList<>(entries.length); for (int i = 0; i < entries.length; i++) { list.add(entries[i]); } return list;
public void setEntries(ISourceContainer[] entries) { fEntries.clear(); for (int i = 0; i < entries.length; i++) { if(entries[i] != null) { fEntries.add(entries[i]); } } if (getInput() == null) { setInput(fEntries); //select first item in list if(!fEntries.isEmpty() && fEntries.get(0)!=null) { setSelection(new StructuredSelection(fEntries.get(0))); } } else { refresh(); } fPanel.setDirty(true); fPanel.updateLaunchConfigurationDialog();
public void addEntries(ISourceContainer[] entries) { int index = 0; IStructuredSelection sel = getStructuredSelection(); if (!sel.isEmpty()) { index = fEntries.indexOf(sel.getFirstElement()); } for (int i = 0; i < entries.length; i++) { if (!fEntries.contains(entries[i])) { fEntries.add(index, entries[i]); index++; } } refresh(); if(entries.length > 0) { setSelection(new StructuredSelection(entries)); } fPanel.setDirty(true); fPanel.updateLaunchConfigurationDialog();
public void setOrganizers(IBreakpointOrganizer[] organizers) { // remove previous listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.removePropertyChangeListener(this); } } fOrganizers = organizers; if (organizers != null && organizers.length == 0) { fOrganizers = null; } // add listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.addPropertyChangeListener(this); } } if (!fDisposed) { fViewer.getControl().setRedraw(false); // maintain expansion based on visible breakpoints IBreakpoint[] breakpoints = null; if (isShowingGroups()) { breakpoints = fViewer.getVisibleBreakpoints(); } reorganize(); if (isShowingGroups() && breakpoints != null) { // restore expansion for (Object fElement : fElements) { BreakpointContainer container = (BreakpointContainer) fElement; for (IBreakpoint breakpoint : breakpoints) { if (container.contains(breakpoint)) { fViewer.expandToLevel(container, AbstractTreeViewer.ALL_LEVELS); fViewer.updateCheckedState(container);
public void setOrganizers(IBreakpointOrganizer[] organizers) { // remove previous listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.removePropertyChangeListener(this); } } fOrganizers = organizers; if (organizers != null && organizers.length == 0) { fOrganizers = null; } // add listeners if (fOrganizers != null) { for (int i = 0; i < fOrganizers.length; i++) { fOrganizers[i].addPropertyChangeListener(this); } } if (!fDisposed) { fViewer.getControl().setRedraw(false); // maintain expansion based on visible breakpoints IBreakpoint[] breakpoints = null; if (isShowingGroups()) { breakpoints = fViewer.getVisibleBreakpoints(); } reorganize(); if (isShowingGroups() && breakpoints != null) { // restore expansion for (Object fElement : fElements) { BreakpointContainer container = (BreakpointContainer) fElement; for (IBreakpoint breakpoint : breakpoints) { if (container.contains(breakpoint)) { fViewer.expandToLevel(container, AbstractTreeViewer.ALL_LEVELS); fViewer.updateCheckedState(container);
public boolean isValidProperty(String property) { if (fFilters == null) { return true; } for (int i = 0; i < fFilters.length; i++) { if (fFilters[i].equals(property)) { return true; } } return false;
} return ret.toArray(new MemoryByte[ret.size()]); } public String getRawMemoryString() { if (fStrRep == null) { StringBuffer buffer = new StringBuffer(); fStrRep = RenderingsUtil.convertByteArrayToHexString(getByteArray()); fStrRep = fStrRep.toUpperCase(); buffer = buffer.append(fStrRep); // pad unavailable bytes with padded string from memory block String paddedString = null; int bufferCounter = 0; for (int i=0; i<fBytes.length; i++) { // if byte is invalid if (!fByte.isReadable()) { if (paddedString == null) { paddedString = fPaddedString; if (paddedString.length() > TableRenderingLine.numCharPerByteForHex) { paddedString = paddedString.substring(0, TableRenderingLine.numCharPerByteForHex); } } buffer.replace(bufferCounter, bufferCounter+TableRenderingLine.numCharPerByteForHex, paddedString); } bufferCounter += TableRenderingLine.numCharPerByteForHex; } fStrRep = buffer.toString(); } return fStrRep; }
fSashForm.setMaximizedControl(variablesViewer.getControl()); fDetailsAnchor = SWTFactory.createComposite(fSashForm, parent.getFont(), 1, 1, GridData.FILL_BOTH, 0, 0); fSashForm.setWeights(getLastSashWeights()); fSelectionProvider = new SelectionProviderWrapper(variablesViewer); getSite().setSelectionProvider(fSelectionProvider); createOrientationActions(variablesViewer); IPreferenceStore prefStore = DebugUIPlugin.getDefault().getPreferenceStore(); String orientation = prefStore.getString(getDetailPanePreferenceKey()); for (int i = 0; i < fToggleDetailPaneActions.length; i++) { fToggleDetailPaneActions[i].setChecked(fToggleDetailPaneActions[i].getOrientation().equals(orientation)); } fDetailPane = new DetailPaneProxy(this); fDetailPane.addProperyListener(new IPropertyListener() { @Override public void propertyChanged(Object source, int propId) { firePropertyChange(propId); } }); setDetailPaneOrientation(orientation); IMemento memento = getMemento(); if (memento != null) { variablesViewer.initState(memento); } variablesViewer.addModelChangedListener(this); variablesViewer.addViewerUpdateListener(this); initDragAndDrop(variablesViewer); return variablesViewer;
protected void saveAllCheckedActionStates() { IToolBarManager tbm= getViewSite().getActionBars().getToolBarManager(); IContributionItem[] items= tbm.getItems(); for (int i = 0; i < items.length; i++) { IContributionItem iContributionItem = items[i]; if (iContributionItem instanceof ActionContributionItem) { ActionContributionItem item= (ActionContributionItem)iContributionItem; IAction action= item.getAction(); if (action.getStyle() == IAction.AS_CHECK_BOX && action.isEnabled()) { saveCheckedActionState(action); } } }
* * @param breakpoints the breakpoints to export * @since 3.5 */ public ExportBreakpointsOperation(IBreakpoint[] breakpoints) { fBreakpoints = breakpoints; fWriter = new StringWriter(); } @Override public void run(IProgressMonitor monitor) throws InvocationTargetException { SubMonitor localmonitor = SubMonitor.convert(monitor, ImportExportMessages.ExportOperation_0, fBreakpoints.length); XMLMemento memento = XMLMemento.createWriteRoot(IImportExportConstants.IE_NODE_BREAKPOINTS); try (Writer writer = fWriter;) { for (int i = 0; i < fBreakpoints.length; i++) { if (localmonitor.isCanceled()) { return; } IBreakpoint breakpoint = fBreakpoint; //in the event we are in working set view, we can have multiple selection of the same breakpoint //so do a simple check for it IMarker marker = breakpoint.getMarker(); IMemento root = memento.createChild(IImportExportConstants.IE_NODE_BREAKPOINT); root.putString(IImportExportConstants.IE_BP_ENABLED, Boolean.toString(breakpoint.isEnabled())); root.putString(IImportExportConstants.IE_BP_REGISTERED, Boolean.toString(breakpoint.isRegistered()));
*/ public ExportBreakpointsOperation(IBreakpoint[] breakpoints) { fBreakpoints = breakpoints; fWriter = new StringWriter(); } @Override public void run(IProgressMonitor monitor) throws InvocationTargetException { SubMonitor localmonitor = SubMonitor.convert(monitor, ImportExportMessages.ExportOperation_0, fBreakpoints.length); XMLMemento memento = XMLMemento.createWriteRoot(IImportExportConstants.IE_NODE_BREAKPOINTS); try (Writer writer = fWriter;) { for (IBreakpoint fBreakpoint : fBreakpoints) { if (localmonitor.isCanceled()) { return; } IBreakpoint breakpoint = fBreakpoints[i]; //in the event we are in working set view, we can have multiple selection of the same breakpoint //so do a simple check for it IMarker marker = breakpoint.getMarker(); IMemento root = memento.createChild(IImportExportConstants.IE_NODE_BREAKPOINT); root.putString(IImportExportConstants.IE_BP_ENABLED, Boolean.toString(breakpoint.isEnabled())); root.putString(IImportExportConstants.IE_BP_REGISTERED, Boolean.toString(breakpoint.isRegistered())); root.putString(IImportExportConstants.IE_BP_PERSISTANT, Boolean.toString(breakpoint.isPersisted())); //write out the resource information
if (scroll != null && !scroll.isDisposed()) { scroll.removeSelectionListener(fScrollbarSelectionListener); } if (!fTableCursor.isDisposed()) { fTableCursor.removeTraverseListener(fCursorTraverseListener); fTableCursor.removeKeyListener(fCursorKeyAdapter); fTableCursor.removeMouseListener(fCursorMouseListener); } fCursorEditor.dispose(); fTextViewer = null; fTableViewer = null; fTableCursor = null; // clean up cell editors for (int i=0; i<fEditors.length; i++) { fEditors[i].dispose(); } // remove font change listener when the view tab is disposed JFaceResources.getFontRegistry().removeListener(this); // remove the view tab from the synchronizer IMemoryRenderingSynchronizationService syncService = getMemoryRenderingContainer().getMemoryRenderingSite().getSynchronizationService(); if (syncService != null) { syncService.removePropertyChangeListener(this); } DebugUIPlugin.getDefault().getPreferenceStore().removePropertyChangeListener(this); fToolTipShell.dispose(); if (getPopupMenuManager() != null) { getPopupMenuManager().removeMenuListener(fMenuListener); } super.dispose();
import org.eclipse.emf.edit.provider.ComposedAdapterFactory; import org.eclipse.emf.edit.provider.ReflectiveItemProviderAdapterFactory; import org.eclipse.jface.databinding.swt.WidgetValueProperty; import org.eclipse.jface.viewers.CellEditor; import org.eclipse.swt.SWT; import org.eclipse.swt.events.FocusEvent; import org.eclipse.swt.events.FocusListener; import org.eclipse.swt.graphics.Image; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Control; /** * Single reference cell editor implementation. * * @author Mat Hansen <mhansen@eclipsesource.com> * @author Eugen Neufeld <eneufeld@eclipsesource.com> * @since 1.22 * */ @SuppressWarnings("restriction") public class SingleReferenceCellEditor extends CellEditor implements ECPCellEditor, ECPElementAwareCellEditor { private EObject rowElement; private ReferenceService referenceService; private EReference eReference; private Composite composite; private ComposedAdapterFactory composedAdapterFactory; private AdapterFactoryItemDelegator adapterFactoryItemDelegator; /** * The constructor. * * @param parent the parent composite */ public SingleReferenceCellEditor(Composite parent) { super(parent); } /** * Alternate constructor with SWT style bits. *
public String getFormatedString(Object value) { if (value == null) { return ""; } return adapterFactoryItemDelegator.getText(value);
* * Contributors: * EclipseSource Munich - initial API and implementation */ package org.eclipse.emf.ecp.view.internal.table.swt.cell; import org.eclipse.emf.ecore.EObject; import org.eclipse.emf.ecore.EReference; import org.eclipse.emf.ecore.EStructuralFeature; import org.eclipse.emf.ecp.edit.spi.swt.table.ECPCellEditorTester; import org.eclipse.emf.ecp.view.spi.context.ViewModelContext; /** * Single reference cell editor tester. * * @author Mat Hansen <mhansen@eclipsesource.com> * @author Eugen Neufeld <eneufeld@eclipsesource.com> * @since 1.22 * */ public class SingleReferenceCellEditorTester implements ECPCellEditorTester { @Override public int isApplicable(EObject eObject, EStructuralFeature eStructuralFeature, ViewModelContext viewModelContext) { if (!EReference.class.isInstance(eStructuralFeature)) { return NOT_APPLICABLE; } final EReference eReference = EReference.class.cast(eStructuralFeature); if (eReference.getUpperBound() == 1) { return 10; } return NOT_APPLICABLE; } }
private void analyseSomeReferencedPackages(PackageVisibilityStatement[] stats, CompilationUnitScope skope) { for (PackageVisibilityStatement stat : stats) { PackageBinding pb = stat.resolvedPackage; if (pb == null) continue; pb = pb.getIncarnation(this.binding); if (pb != null && pb.hasCompilationUnit(true)) continue; skope.problemReporter().invalidPackageReference(IProblem.PackageDoesNotExistOrIsEmpty, export); }
if (checkForSplit && this.environment.useModuleSystem) { char[][] declaringModuleNames = null; if (isUnnamed()) { IModuleAwareNameEnvironment moduleEnv = (IModuleAwareNameEnvironment) this.environment.nameEnvironment; declaringModuleNames = moduleEnv.getUniqueModulesDeclaringPackage(new char[][] {packageName}, ANY); } packageBinding = combineWithPackagesFromOtherRelevantModules(packageBinding, packageBinding.compoundName, declaringModuleNames); } this.declaredPackages.put(packageName, packageBinding.getIncarnation(this)); if (packageBinding.parent == null) { this.environment.knownPackages.put(packageName, packageBinding); } } return packageBinding; } private PackageBinding combineWithPackagesFromOtherRelevantModules(PackageBinding currentBinding, char[][] compoundName, char[][] declaringModuleNames) { boolean save = this.isPackageLookupActive; this.isPackageLookupActive = true; try { for (ModuleBinding moduleBinding : otherRelevantModules(declaringModuleNames)) { if (!moduleBinding.isPackageLookupActive) { PackageBinding nextBinding = moduleBinding.getDeclaredPackage(CharOperation.concatWith(compoundName, '.'));
PackageBinding combineWithSiblings(PackageBinding childPackage, char[] name, ModuleBinding module) { ModuleBinding primaryModule = childPackage.enclosingModule; // see if other incarnations contribute to the child package, too: boolean activeSave = primaryModule.isPackageLookupActive; primaryModule.isPackageLookupActive = true; try { char[] flatName = CharOperation.concatWith(childPackage.compoundName, '.'); for (PackageBinding incarnation : this.incarnations) { ModuleBinding moduleBinding = incarnation.enclosingModule; if (moduleBinding == module) continue; if (childPackage.isDeclaredIn(moduleBinding)) continue; PackageBinding next = moduleBinding.getDeclaredPackage(flatName); childPackage = combine(next, childPackage, primaryModule); } return childPackage; } finally { primaryModule.isPackageLookupActive = activeSave; }
final Object image = adapterFactoryItemDelegator.getImage(value); return SWTImageHelper.getImage(image); } @Override public int getColumnWidthWeight() { return 0; } @Override public UpdateValueStrategy getTargetToModelStrategy(DataBindingContext databindingContext) { return null; } @Override public UpdateValueStrategy getModelToTargetStrategy(DataBindingContext databindingContext) { return null; } @Override public void setEditable(boolean editable) { } @Override public int getMinWidth() { return 100; } @Override protected Control createControl(Composite parent) { composite = new Composite(parent, SWT.NONE); composite.addFocusListener(new FocusListener() { private boolean focused; @Override public void focusLost(FocusEvent e) { } @Override public void focusGained(FocusEvent e) { if (focused) { return; } focused = true; try {
* * Contributors: * Vincent Lorenzo (CEA LIST) vincent.lorenzo@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.model2doc.odt.internal.transcription; /** * This class contains the custom fields used to generate LibreOffice document */ public class CustomFields { /** * Constructor. * */ private CustomFields() { // to prevent instanciation } /** * The custom field Authors */ public static final String AUTHORS = "Authors"; //$NON-NLS-1$ /** * The custom field Version */ public static final String VERSION = "Version"; }
*****************************************************************************/ package org.eclipse.papyrus.model2doc.odt.internal.transcription; /** * This class contains the custom fields used to generate LibreOffice document */ public class CustomFields { /** * Constructor. * */ private CustomFields() { // to prevent instanciation } /** * The custom field Authors */ public static final String AUTHORS = "Authors"; /** * The custom field Version */ public static final String VERSION = "Version"; //$NON-NLS-1$ }
public void writeAuthors(final Collection<IAuthor> authors) { if (authors.size() > 0) { final XTextDocument document = odtEditor.getXTextDocument(); final XDocumentPropertiesSupplier xsDocProp = UnoRuntime.queryInterface(XDocumentPropertiesSupplier.class, document); XDocumentProperties props = xsDocProp.getDocumentProperties(); final Iterator<IAuthor> iterator = authors.iterator(); String allAuthorsLabel = ""; //$NON-NLS-1$ if (iterator.hasNext()) { final IAuthor firstAuthor = iterator.next(); allAuthorsLabel = firstAuthor.buildMultiAuthorLabel(ECollections.toEList(authors)); props.setAuthor(firstAuthor.buildAuthorLabel()); } XPropertyContainer userDefined = props.getUserDefinedProperties(); // we need to remove the property if it already exist, in order to be change its value try { userDefined.removeProperty(CustomFields.AUTHORS); } catch (UnknownPropertyException | NotRemoveableException e) { // nothing to do } try { userDefined.addProperty(CustomFields.AUTHORS, com.sun.star.beans.PropertyAttribute.REMOVABLE, allAuthorsLabel); } catch (IllegalArgumentException | PropertyExistException | IllegalTypeException e) { Activator.log.error(e); }
String allAuthorsLabel = ""; if (iterator.hasNext()) { final IAuthor firstAuthor = iterator.next(); allAuthorsLabel = firstAuthor.buildMultiAuthorLabel(ECollections.toEList(authors)); props.setAuthor(firstAuthor.buildAuthorLabel()); } XPropertyContainer userDefined = props.getUserDefinedProperties(); // we need to remove the property if it already exist, in order to be change its value try { userDefined.removeProperty(CustomFields.AUTHORS); } catch (UnknownPropertyException e) { // nothing to do. If the property doesn't exist, we probably get an exception for nothing! } catch (NotRemoveableException e) { Activator.log.error(e); } try { userDefined.addProperty(CustomFields.AUTHORS, com.sun.star.beans.PropertyAttribute.REMOVABLE, allAuthorsLabel); } catch (IllegalArgumentException | PropertyExistException | IllegalTypeException e) { Activator.log.error(e); } }
@NonNull ITmfStateInterval interval = stateSystem.querySingleState(END_TIME, quark); long count1 = interval.getStateValue().unboxLong(); quark = stateSystem.getQuarkAbsolute("fsm2"); interval = stateSystem.querySingleState(END_TIME, quark); long count2 = interval.getStateValue().unboxLong(); assertEquals("Test the count value", count1, count2); } catch (AttributeNotFoundException | StateSystemDisposedException e) { fail("Failed to query the state system"); } } /** * Compare the execution of two state machines doing the same job, the tid * condition is ignored with the initial element and used with the * initialState element. The result should be different. */ @Test public void testInitialStateWithCondition() { ITmfStateSystem stateSystem = fModule.getStateSystem(fModule.getId()); assertNotNull("state system exist", stateSystem); try { int quark = stateSystem.getQuarkAbsolute("fsm1"); @NonNull ITmfStateInterval interval = stateSystem.querySingleState(END_TIME, quark);
if (!isPinned) { // Remove and dispose any previous adorned image Image previouslyAdornedImage = (Image) element.getTransientData().get("previouslyAdorned"); //$NON-NLS-1$ if (previouslyAdornedImage != null && !previouslyAdornedImage.isDisposed()) previouslyAdornedImage.dispose(); element.getTransientData().remove(IPresentationEngine.ADORNMENT_PIN); } else { adornedImage = resUtils.adornImage(image, pinImage); if (adornedImage != image) element.getTransientData().put( "previouslyAdorned", adornedImage); //$NON-NLS-1$ } return image;
public Image getImage(MUILabel element) { Image image = (Image) ((MUIElement) element).getTransientData().get( IPresentationEngine.OVERRIDE_ICON_IMAGE_KEY);
private Image adornImage(MUIElement element, Image image, boolean imageChanged) { if (element.getTags().contains(IPresentationEngine.ADORNMENT_PIN)) {// Only if Pinned Image previousImage = (Image) element.getTransientData().get(ADORN_ICON_IMAGE_KEY); boolean exist = previousImage != null && !previousImage.isDisposed(); // Cached image exist if (!exist) { Image adornedImage = resUtils.adornImage(image, pinImage); if (adornedImage != image) { element.getTransientData().put(ADORN_ICON_IMAGE_KEY, adornedImage); } return adornedImage; } return previousImage; } return image;
protected void showTab(MUIElement tabElement) { MPerspective persp = (MPerspective) tabElement; Control ctrl = (Control) persp.getWidget(); if (ctrl == null) { ctrl = (Control) renderer.createGui(persp); } else if (ctrl.getParent() != persp.getParent().getWidget()) { Composite parent = (Composite) persp.getParent().getWidget(); ctrl.setParent(parent); } super.showTab(persp); // relayout the perspective final Composite psComp = ctrl.getParent(); StackLayout sl = (StackLayout) psComp.getLayout(); if (sl != null) { sl.topControl = ctrl; psComp.layout(); } ctrl.moveAbove(null); // Force a context switch final IEclipseContext context = persp.getContext(); context.get(EPartService.class).switchPerspective(persp); // Move any other controls to 'limbo' Control[] kids = psComp.getChildren(); Shell limbo = (Shell) context.get("limbo"); //$NON-NLS-1$ for (Control child : kids) { if (child != ctrl) {
private boolean loadMappingsFromOldWorkspace(Map<String, Integer> map) { // File name of the persisted file type information String STATE_FILE = ".fileTypes"; //$NON-NLS-1$ IPath pluginStateLocation = TeamPlugin.getPlugin().getStateLocation().append(STATE_FILE); File f = pluginStateLocation.toFile(); if (!f.exists()) return false; try { DataInputStream input = new DataInputStream(new FileInputStream(f)); try { map.putAll(readOldFormatExtensionMappings(input)); } finally { input.close(); f.delete(); } } catch (IOException ex) { TeamPlugin.log(IStatus.ERROR, ex.getMessage(), ex); return false; } return true;
} return bytes; } /** * Converts an hex string (in format "0123456789ABCDEF") into a byte array * * @param hexString the hex string * @return the corresponding byte array */ public static byte[] hexToBytes(String hexString) { return hexToBytes(hexString, "(?<=\\G.{2})"); } /** * Convert an upper case hex character to a byte * * @param character an upper case hex character * @return the byte value of the character * @throws IllegalArgumentException if a value is found which is not an upper case hex character */ private static byte hexCharacterToBin(char character) { if ('0' <= character && character <= '9') { return (byte) (character - ASCII_DIGITS_START_POSITION); } else if ('A' <= character && character <= 'F') { return (byte) (character - ASCII_UPPERCASE_LETTERS_START_POSITION + 10); } else {
public TableUserFilterManager getUserFilterManager() { return (TableUserFilterManager) propertySupport.getProperty(PROP_USER_FILTER_MANAGER); } @Override public void setUserFilterManager(TableUserFilterManager m) { propertySupport.setProperty(PROP_USER_FILTER_MANAGER, m); } @Override public ITableCustomizer getTableCustomizer() { return (ITableCustomizer) propertySupport.getProperty(PROP_TABLE_CUSTOMIZER); } @Override public void setTableCustomizer(ITableCustomizer c) { propertySupport.setProperty(PROP_TABLE_CUSTOMIZER, c); } @Override public ITypeWithClassId getContainer() { IWidget parentWidget = getParent(); if (parentWidget != null) { return parentWidget; } return getParentPage(); } /** * do not use this internal method */ public void setParentPageInternal(IPage<?> container) { propertySupport.setProperty(PROP_PARENT_PAGE, container); } @Override public boolean isSortEnabled() { return propertySupport.getPropertyBool(PROP_SORT_ENABLED); } @Override
* drop can be aborted if appropriate. * * This class is not intended to be subclassed. * * @since 3.2 */ public class LocalSelectionTransfer extends ByteArrayTransfer { // First attempt to create a UUID for the type name to make sure that // different Eclipse applications use different "types" of // <code>LocalSelectionTransfer</code> private static final String TYPE_NAME = "local-selection-transfer-format" + System.currentTimeMillis(); //$NON-NLS-1$ ; private static final int TYPEID = registerType(TYPE_NAME); private static final LocalSelectionTransfer INSTANCE = new LocalSelectionTransfer(); private ISelection selection; private long selectionSetTime; /** * Only the singleton instance of this class may be used. */ protected LocalSelectionTransfer() { // do nothing } /** * Returns the singleton. * * @return the singleton */ public static LocalSelectionTransfer getTransfer() { return INSTANCE; } /** * Returns the local transfer data. *
private String convertToEditableTimeInterval(String string) { if (string.length() == 0) return string; long value; try { value = Long.parseLong(string); } catch (NumberFormatException e) { value = 0; } if (value == 0) return Long.toString(0); for (int i = 0; i < timeIntervalPrefixes.length - 1; i++) { if (value % timeIntervalScale[i] != 0) return Long.toString(value) + timeIntervalPrefixes[i]; value /= timeIntervalScale[i]; } return value + timeIntervalPrefixes[timeIntervalPrefixes.length - 1]; } private String convertFromEditableTimeInterval(String string) { if (string.length() == 0) return string; for (int i = 1; i < timeIntervalPrefixes.length; i++) { if (string.endsWith(timeIntervalPrefixes[i])) { long value = Long.parseLong(string.substring(0, string.length() - 1)); for (int j = 0; j < i; j++) value *= timeIntervalScale[j]; return Long.toString(value); } }
public String toString() { String rv = "Item "; if (parent != null) { rv = parent + "."; } rv += counter; return rv;
produce = false; else { if (filter.requiresCommitBody()) c.parseBody(walker); produce = filter.include(walker, c); } for (int i = 0; i < c.parents.length; i++) { RevCommit p = c.parents[i]; if ((p.flags & SEEN) != 0) continue; if ((p.flags & PARSED) == 0) p.parseHeaders(walker); p.flags |= SEEN; pending.add(p); } walker.carryFlagsImpl(c); if ((c.flags & UNINTERESTING) != 0) { if (pending.everbodyHasFlag(UNINTERESTING)) { final RevCommit n = pending.peek(); if (n != null && n.commitTime >= last.commitTime) { // This is too close to call. The next commit we // would pop is dated after the last one produced. // We have to keep going to ensure that we carry // flags as much as necessary. //
setTypes(queryResp.getQueryResult()); } catch (Exception e) { logger.error(MessageFormat.format(Messages.DTL_QueryFailed, "FB Types")); //$NON-NLS-1$ } } @Override public void createFBInstance(final FBDeploymentData fbData, final Resource res) throws DeploymentException { // check first if FBType exists Map<String, AdapterType> adapters = getAdapterTypes(fbData.getFb().getType().getInterfaceList()); if (!adapters.isEmpty()) { queryAdapterTypes(adapters, res); createAdapterTypes(adapters); } // if the FPType does not exist create it if (!getTypes().contains(fbData.getFb().getType().getName())) { try { createFBType(fbData.getFb().getType(), res); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fbData.getFb().getType().getName())); } } super.createFBInstance(fbData, res); } private static Map<String, AdapterType> getAdapterTypes(InterfaceList interfaceList) {
RevCommit a = commit(); RevCommit b1 = commit(a); RevCommit b2 = commit(a); RevCommit c1 = commit(b1); RevCommit c2 = commit(b2); RevCommit d = commit(c1, c2); rw.reset(); rw.setFirstParent(true); markStart(d); assertCommit(d, rw.next()); assertCommit(c1, rw.next()); assertCommit(b1, rw.next()); assertCommit(a, rw.next()); assertNull(rw.next()); } @Test public void testSecondParentAncestorOfFirstParent() throws Exception { RevCommit a = commit(); RevCommit b = commit(a); RevCommit c = commit(b, a); rw.reset(); rw.setFirstParent(true); markStart(c); assertCommit(c, rw.next()); assertCommit(b, rw.next()); assertCommit(a, rw.next()); assertNull(rw.next()); } @Test public void testFirstParentMultipleOccurrences() throws Exception { RevCommit a = commit(); RevCommit b = commit(a); RevCommit c = commit(b);
/** Output may have {@link RevWalk#REWRITE} marked on it. */ static final int HAS_REWRITE = 1 << 1; /** Output needs {@link RewriteGenerator}. */ static final int NEEDS_REWRITE = 1 << 2; /** Topological ordering is enforced (all children before parents). */ static final int SORT_TOPO = 1 << 3; /** Output may have {@link RevWalk#UNINTERESTING} marked on it. */ static final int HAS_UNINTERESTING = 1 << 4; protected final boolean firstParent; protected Generator(boolean firstParent) { this.firstParent = firstParent; } /** * Connect the supplied queue to this generator's own free list (if any). * * @param q * another FIFO queue that wants to share our queue's free list. */ void shareFreeList(BlockRevQueue q) { // Do nothing by default. } /** * Obtain flags describing the output behavior of this generator. *
} } return list; } /** * Remove a data provider from the instances * * @param <T> * The type of data provider * @param trace * The trace for which to remove the data provider * @param provider * The data provider to remove * @since 5.1 */ public <T extends ITmfTreeDataProvider<? extends ITmfTreeDataModel>> boolean removeDataProvider(ITmfTrace trace, T provider) { return fInstances.remove(trace, provider); } }
private void checkCreateFBType(FB fb) { // if the FPType does not exist create it if (!getTypes().contains(fb.getType().getName())) { try { createFBType(fb.getType(), res); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fb.getType().getName())); } }
// if the FPType does not exist create it if (!getTypes().contains(fb.getType().getName())) { try { createFBType(fb.getType(), res); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fb.getType().getName())); } } } public void createFBType(final FBType fbType) throws DeploymentException { setAttribute(getDevice(), "FBType", getTypes()); //$NON-NLS-1$ if (fbType instanceof BasicFBType || fbType instanceof CompositeFBType) { if (fbType instanceof CompositeFBType) { createFBTypesOfCFB(fbType, res); } String request = createLuaRequestMessage(fbType); sendCreateFBTypeREQ(fbType, request); } } private void sendCreateFBTypeREQ(final FBType fbType, String request) throws DeploymentException { try { String result = sendREQ("", request); //$NON-NLS-1$ if (result.contains("Reason")) { //$NON-NLS-1$
addLocalDeclarationSplit(rewrite); else addLocalDeclarationRemoval(rewrite); if (fInitializeIn == INITIALIZE_IN_CONSTRUCTOR) addInitializersToConstructors(rewrite); addTempRenames(rewrite); addFieldDeclaration(rewrite); CompilationUnitChange result= new CompilationUnitChange(RefactoringCoreMessages.PromoteTempToFieldRefactoring_name, fCu); result.setDescriptor(new RefactoringChangeDescriptor(getRefactoringDescriptor())); TextEdit resultingEdits; if (fFormatterOptions == null) { resultingEdits= rewrite.rewriteAST(); } TextChangeCompatibility.addTextEdit(result, RefactoringCoreMessages.PromoteTempToFieldRefactoring_editName, resultingEdits); return result; } finally { pm.done(); } } private void addTempRenames(ASTRewrite rewrite) { boolean noNameChange= fFieldName.equals(fTempDeclarationNode.getName().getIdentifier()); if (fLinkedProposalModel == null && noNameChange) { return; // no changes needed }
addInitializersToConstructors(rewrite); addTempRenames(rewrite); addFieldDeclaration(rewrite); CompilationUnitChange result= new CompilationUnitChange(RefactoringCoreMessages.PromoteTempToFieldRefactoring_name, fCu); result.setDescriptor(new RefactoringChangeDescriptor(getRefactoringDescriptor())); TextEdit resultingEdits; Map<String, String> formatter= (this.fFormatterOptions == null) ? fCu.getJavaProject().getOptions(true) : this.fFormatterOptions; try { resultingEdits= rewrite.rewriteAST(new Document(fCu.getSource()), formatter); } catch (JavaModelException e) { resultingEdits= rewrite.rewriteAST(); } else { resultingEdits= rewrite.rewriteAST(new Document(fCu.getSource()), fFormatterOptions); } TextChangeCompatibility.addTextEdit(result, RefactoringCoreMessages.PromoteTempToFieldRefactoring_editName, resultingEdits); return result; } finally { pm.done(); } } private void addTempRenames(ASTRewrite rewrite) { boolean noNameChange= fFieldName.equals(fTempDeclarationNode.getName().getIdentifier()); if (fLinkedProposalModel == null && noNameChange) { return; // no changes needed } TempOccurrenceAnalyzer analyzer= new TempOccurrenceAnalyzer(fTempDeclarationNode, false); analyzer.perform();
* <code>ILabelProvider</code>. If it is an * <code>ITableLabelProvider</code>, then it provides a separate label * text and image for each column. If it is an <code>ILabelProvider</code>, * then it provides only the label text and image for the first column, and * any remaining columns are blank. */ @Override public IBaseLabelProvider getLabelProvider() { return super.getLabelProvider(); } @SuppressWarnings("rawtypes") @Override protected List getSelectionFromWidget() { if (virtualManager != null) { return getVirtualSelection(); } Widget[] items = doGetSelection(); List<Object> list = new ArrayList<>(items.length); for (Widget item : items) { Object e = item.getData(); if (e != null) { list.add(e); } } return list; } /** * Get the virtual selection. Avoid calling SWT whenever possible to prevent * extra widget creation. * * @return List of Object */
Policy.getLog().log( new Status(IStatus.WARNING, Policy.JFACE, message, new RuntimeException())); return; } } } } /** * Returns all selected items for the given SWT control. * * @param control * the control * @return the list of selected items */ protected abstract Item[] getSelection(Control control); @SuppressWarnings("rawtypes") @Override protected List getSelectionFromWidget() { Widget[] items = getSelection(getControl()); List<Object> list = new ArrayList<>(items.length); for (Widget item : items) { Object e = item.getData(); if (e != null) { list.add(e); } } return list; } /* * Overridden in AbstractTreeViewer to fix bug 108102 (code copied from * StructuredViewer to avoid introducing new API) */ @Override protected void handleDoubleSelect(SelectionEvent event) { // handle case where an earlier selection listener disposed the control. Control control = getControl();
protected void setSelectionToWidget(ISelection selection, boolean reveal) { if (selection instanceof ITreeSelection) { ITreeSelection treeSelection = (ITreeSelection) selection; setSelectionToWidget(Arrays.asList(treeSelection.getPaths()), reveal); } else { super.setSelectionToWidget(selection, reveal); }
* are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation * Oakland Software (Francis Upton - francisu@ieee.org) * bug 197113 Project Explorer drag and drop selection not working properly *******************************************************************************/ package org.eclipse.ui.navigator; import java.util.ArrayList; import java.util.Iterator; import java.util.List; import org.eclipse.jface.viewers.IBaseLabelProvider; import org.eclipse.jface.viewers.ISelection; import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.jface.viewers.LabelProviderChangedEvent; import org.eclipse.jface.viewers.StructuredSelection; import org.eclipse.jface.viewers.TreeViewer; import org.eclipse.jface.viewers.ViewerSorter; import org.eclipse.swt.dnd.DND; import org.eclipse.swt.events.DisposeEvent; import org.eclipse.swt.events.MouseAdapter; import org.eclipse.swt.events.MouseEvent;
private void checkCreateFBType(FBType fbType) { // if the FPType does not exist create it if (!getTypes().contains(fb.getType().getName())) { try { createFBType(fb.getType()); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fb.getType().getName())); } }
private static List<IProject> getSelectedProjects(ISelection selection) { List<IProject> projectSelection = new ArrayList<>(); if (selection instanceof IStructuredSelection) { for (Object element : ((StructuredSelection) selection).toList()) { if (element instanceof AutomationSystem) { projectSelection.add(((AutomationSystem) element).getProject()); } else if (element instanceof IProject) { projectSelection.add((IProject) element); } } } return projectSelection;
public void reveal() { // I have nothing of my own to reveal; only the next step to drill down into
private static Collection<LSBasedHyperlink> toHyperlinks(final IDocument document, final IRegion linkRegion, Either<List<? extends Location>, List<? extends LocationLink>> locations) { if (locations == null) { return; } else if (locations.isLeft()) { allLinks.addAll(locations.getLeft().stream().filter(Objects::nonNull).map(location -> new LSBasedHyperlink(location, linkRegion)).collect(Collectors.toList())); } else { allLinks.addAll( locations.getRight().stream().filter(Objects::nonNull).map(locationLink -> { IRegion selectionRegion = linkRegion; Range originSelectionRange = locationLink.getOriginSelectionRange(); if (originSelectionRange != null) { try { int offset = LSPEclipseUtils .toOffset(originSelectionRange.getStart(), document); int endOffset = LSPEclipseUtils .toOffset(originSelectionRange.getEnd(), document); selectionRegion = new Region(offset, endOffset - offset); } catch (BadLocationException e) { LanguageServerPlugin.logError(e.getMessage(), e); } }
protected void addChildVisual(final EditPart childEditPart, final int index) { boolean visible = true; if (childEditPart instanceof InterfaceEditPart) { IInterfaceElement iElement = ((InterfaceEditPart) childEditPart).getModel(); if (iElement instanceof AdapterDeclaration){ //if we are in a subapptype we want to show the adapter as type interface element visible = isVarVisible(); } } EditPart refEditPart = null; if (index < getChildren().size()) { refEditPart = (EditPart) getChildren().get(index); } if (childEditPart instanceof InterfaceEditPart) { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).getModel().isIsInput()) { if (((InterfaceEditPart) childEditPart).isEvent()) { insertChild(getLeftEventInterfaceContainer(), refEditPart, child); } else { if (visible) { // add adapter interface elemetns directly to the container and set them to visible = false insertChild(getLeftVarInterfaceContainer(), refEditPart, child);
protected void removeChildVisual(final EditPart childEditPart) { boolean visible = true; if (childEditPart.getModel() instanceof AdapterDeclaration) { visible = isVarVisible(); } } if (childEditPart instanceof InterfaceEditPart){ if (((InterfaceEditPart) childEditPart).getModel().isIsInput()) { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).isEvent()) { getLeftEventInterfaceContainer().remove(child); } else { if (visible) { getLeftVarInterfaceContainer().remove(child); } else{ getLeftInterfaceContainer().remove(child); } } } else { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).isEvent()) { getRightEventInterfaceContainer().remove(child); } else { if (visible) { getRightVarInterfaceContainer().remove(child); } else { getRightInterfaceContainer().remove(child); } } } } else { super.removeChildVisual(childEditPart); }
import org.eclipse.emf.ecore.EObject; import org.eclipse.emf.ecore.EStructuralFeature; import org.eclipse.emf.ecore.InternalEObject; import org.eclipse.emf.ecore.resource.Resource; import com.google.common.base.Objects; /** * An helper to check EObject equality.</br> * It extends and override EcoreUtil.EqualityHelper so that equals methods ignore EAttribute that are ID=true. * * @author mchauvin */ public final class EqualityHelper extends org.eclipse.emf.ecore.util.EcoreUtil.EqualityHelper { private static boolean enableUriFragmentCache = false; private static final Map<EObject, String> eUriFragmentCache = new HashMap<>(); private static final Map<EObject, EObject> eUriFragmentContainerCache = new HashMap<>(); private static final Map<EObject, EStructuralFeature> eUriFragmentContainingFeatureCache = new HashMap<>(); @Override protected boolean haveEqualAttribute(EObject eObject1, EObject eObject2, EAttribute attribute) { boolean isID = attribute.isID(); return isID || super.haveEqualAttribute(eObject1, eObject2, attribute); } /**
} /** * Check if a diagram element is in an activated layer or not and visible. * * @param session * the current session. * @param element * the diagram element. * @param parentDiagram * the parent diagram of the diagram element. This information can be retrieved from the diagram element * but sometimes it is already known by the caller or it can be null (during drag'n'drop of element with * bordered nodes for example : PortLocationAfterDragAndDropTest. * testPortLocationFromParentDnDFromModelExplorerView()) this method is called before setting all parents * hierarchy of diagram element. * @return <code>true</code> if it is, <code>false</code> otherwise */ public static boolean isInActivatedLayer(DiagramMappingsManager session, final DDiagramElement element, final DDiagram parentDiagram) { final DiagramElementMapping mapping = element.getDiagramElementMapping(); if (!LayerHelper.withoutLayersMode(mapping)) { final DDiagram diagram; if (parentDiagram != null) { diagram = parentDiagram;
*/ boolean reveal(EObject object, EStructuralFeature feature); /** * Attempt to reveal an {@code object} in the most appropriate (by best effort) * control within the given {@code scope}. * * @param object an object to reveal * @param scope a control within which to attempt to reveal the {@code object} * * @return a step-wise chain of operations to progressively reveal the {@code object} * in the given {@code scope}, or {@linkplain RevealStep#fail() a failed step} if none */ RevealStep reveal(EObject object, VElement scope); /** * Attempt to reveal a {@code feature} of an {@code object} in the most appropriate * (by best effort) control within the given {@code scope}. * * @param object an object to reveal * @param feature a specific feature (implying a detail control) to reveal * @param scope a control within which to attempt to reveal the {@code object} *
/** * Attempt to reveal a {@code feature} of an {@code object} in the most appropriate * (by best effort) control within the given {@code scope}. * * @param object an object to reveal * @param feature a specific feature (implying a detail control) to reveal * @param scope a control within which to attempt to reveal the {@code object} * * @return a step-wise chain of operations to progressively reveal the {@code object} * in the given {@code scope}, or {@linkplain RevealStep#fail() a failed step} if none */ RevealStep reveal(EObject object, EStructuralFeature feature, VElement scope); /** * Register a reveal provider. * * @param provider the reveal provider to register */ void addRevealProvider(EMFFormsRevealProvider provider); /** * Unregister a reveal provider. * * @param provider the reveal provider to unregister */ void removeRevealProvider(EMFFormsRevealProvider provider); }
public int getRed() { if (isDisposed()) SWT.error(SWT.ERROR_GRAPHIC_DISPOSED); /* * Conversion formula comes from Cairo's _cairo_color_double_to_short() * and color_to_pixel() functions. See bug 549181 and 549101 for more info. */ int r = (((int)(handle.red * 65535.0 + 0.5)) >> 8); return Math.min(r, 255);
public int getRed() { if (isDisposed()) SWT.error(SWT.ERROR_GRAPHIC_DISPOSED); /* * Conversion formula comes from Cairo's _cairo_color_double_to_short() * and color_to_pixel() functions. See bug 549181 and 549101 for more info. */ int r = (((int)(handle.red * 65535.0 + 0.5)) >> 8); return Math.min(r, 255);
buf.append(" System.out.println(list.get(i));\n"); buf.append(" }\n"); buf.append(" }\n"); buf.append("}\n"); ICompilationUnit cu= pack1.createCompilationUnit("A.java", buf.toString(), false, null); List<IJavaCompletionProposal> proposals= fetchConvertingProposal(buf, cu); assertNotNull(fConvertLoopProposal); String preview1= getPreviewContent(fConvertLoopProposal); buf= new StringBuilder(); buf.append("package test1;\n"); buf.append("public class A {\n"); buf.append(" public void foo() {\n"); buf.append(" java.util.List list = new ArrayList();\n"); buf.append(" list.add(null);\n"); buf.append(" for (Object element : list) {\n"); buf.append(" System.out.println(element);\n"); buf.append(" }\n"); buf.append(" }\n"); buf.append("}\n"); String expected= buf.toString(); assertEqualString(preview1, expected); assertCorrectLabels(proposals); assertCorrectLabels(proposals); }
StaticProfileTest.class, DynamicProfileTest.class, StaticStereotypeTest.class, StaticStereotypedElementChangeTests.class, DynamicStereotypeTest.class, DynamicStereotypedElementChangeTests.class, ImplicationsAssociationTest.class, ImplicationsTransitionTest.class, ImplicationsInterfaceRealizationTest.class, StaticStereotypedElementItemProviderTest.class, DynamicStereotypedElementItemProviderTest.class, OpaqueElementBodyChangeDiffTest.class, OpaqueElementBodyChangeMergeTest.class, DanglingStereotypeApplicationTest.class, TestNonRegPseudoConflict_484576.class, RemoveStereotypeApplicationPseudoConflictTest.class, MultiplicityElementChangesTest.class, InstanceSpecificationClassifiersMergeTest.class, AddMessageSubDiffTest.class, StereotypeApplicationConflictTests.class, }) public class AllTests { /** * Standalone launcher for all of compare's tests. * * @generated */ public static void main(String[] args) { TestRunner.run(suite()); } /** * This will return a suite populated with all tests available through this class. * * @generated */ public static Test suite() { return new JUnit4TestAdapter(AllTests.class); } }
***************************************************************************** * Copyright (c) 2014, 2017 Obeo and others. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Obeo - initial API and implementation * Christian W. Damus - bug 522080 *******************************************************************************/ package org.eclipse.emf.compare.uml2.internal.postprocessor; import java.util.HashMap; import java.util.Iterator; import java.util.Map; import org.eclipse.emf.common.util.Monitor; import org.eclipse.emf.common.util.URI; import org.eclipse.emf.compare.Comparison; import org.eclipse.emf.compare.ComparisonCanceledException; import org.eclipse.emf.compare.Diff; import org.eclipse.emf.compare.Match; import org.eclipse.emf.compare.diff.DefaultDiffEngine; import org.eclipse.emf.compare.diff.FeatureFilter; import org.eclipse.emf.compare.postprocessor.IPostProcessor; import org.eclipse.emf.compare.uml2.internal.postprocessor.extension.stereotype.UMLStereotypedElementChangeFactory;
private static URI getStereotypeURI(EObject stereotypeApplication) { return EcoreUtil.getURI(stereotypeApplication.eClass());
* the second level key * @param value * the value * @return the previous value for these keys, if or {@code null} if there was none * @param <K> * the top level key type * @param <L> * the second level key type * @param <V> * the value type */ private static <K, L, V> V put(Map<K, Map<L, V>> mapOfMaps, K key1, L key2, V value) { Map<L, V> map = mapOfMaps.get(key1); if (map == null) { map = Maps.newHashMap(); mapOfMaps.put(key1, map); } return map.put(key2, value); } /** * Queries whether an {@code object} is a stereotype application. * * @param object * an object * @return {@code true} if it is a stereotype application; {@code false}, otherwise */ protected boolean isStereotypeApplication(EObject object) {
* http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Boeing - initial API and implementation *******************************************************************************/ package org.eclipse.ote.simple.oteide.product.load; import java.io.IOException; import java.net.URL; import java.util.ArrayList; import java.util.List; import java.util.logging.Level; import org.eclipse.osee.framework.jdk.core.util.Lib; import org.eclipse.osee.framework.logging.OseeLog; import org.eclipse.ote.services.core.BundleUtility; import org.eclipse.ote.services.core.LoadBundleProvider; /** * @author Andrew M. Finkbeiner */ public class FileProvider implements LoadBundleProvider { @Override public List<String> getBundleSymbolicNames() { List<String> names = new ArrayList<String>(); try { URL entry = BundleUtility.findEntry("org.eclipse.ote.simple.oteide.product.load", "data/precompiledServerBundleList.txt"); String fileContent = Lib.inputStreamToString(entry.openStream()); String[] strNames = fileContent.split("\n"); for(int i = 0; i < strNames.length; i++){
import java.util.Dictionary; import java.util.logging.Level; import java.util.regex.Matcher; import java.util.regex.Pattern; import org.eclipse.core.runtime.Platform; import org.eclipse.core.runtime.preferences.IEclipsePreferences; import org.eclipse.core.runtime.preferences.InstanceScope; import org.eclipse.osee.framework.logging.OseeLog; import org.eclipse.ote.services.core.ServiceUtility; import org.eclipse.swt.widgets.Display; import org.eclipse.ui.IStartup; import org.osgi.framework.Bundle; import org.osgi.framework.BundleEvent; import org.osgi.framework.BundleListener; /** * @author Andrew M. Finkbeiner */ public class SetTitleBar implements IStartup { @Override public void earlyStartup() { String title = getTitle(); if(title != null) { setTitle(title); } else if(ServiceUtility.getContext() != null){ ServiceUtility.getContext().addBundleListener(new BundleListener() { @Override public void bundleChanged(BundleEvent event) { if(event.getType() == Bundle.ACTIVE){ if(event.getBundle().getSymbolicName().equals("bundle.to.base.off.here")){ String t = getTitle(); if(t != null){
import java.io.File; import org.eclipse.core.resources.ResourcesPlugin; import org.eclipse.jface.action.Action; import org.eclipse.jface.action.IContributionItem; import org.eclipse.swt.program.Program; import org.eclipse.swt.widgets.Display; import org.eclipse.ui.IPartListener; import org.eclipse.ui.IViewPart; import org.eclipse.ui.IViewReference; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.IWorkbenchWindow; import org.eclipse.ui.PlatformUI; import org.eclipse.ui.part.ViewPart; import org.eclipse.ui.texteditor.StatusLineContributionItem; /** * @author Andrew M. Finkbeiner */ public class WorkspaceStatusLineContributionItem { private static String ID = "org.eclipse.ote.simple.oteide.product.load"; private String shortText; private StatusLineContributionItem item; private String path; public WorkspaceStatusLineContributionItem() { path = ResourcesPlugin.getWorkspace().getRoot().getLocation().toString(); shortText = getShortPath(path); item = new StatusLineContributionItem(ID, true, shortText.length()); } private static String getShortPath(String path) {
} } else { uriFragment = container.eURIFragmentSegment(eContainingFeature, eObj); } return uriFragment; } private static boolean sameType(EObject eObj1, EObject eObj2) { return eObj1 != null && eObj2 != null && eObj1.getClass() == eObj2.getClass(); } /** * Enable or disable the ability to cache the computed values. The cache is cleared when this method is called to * disable the cache. * * @param enable * <code>true</code> to allow this helper to put the computed values in a cache, <code>false</code> * otherwise. */ public static synchronized void setUriFragmentCacheEnabled(boolean enable) { enableUriFragmentCache = enable; if (!enable) { E_URI_FRAGMENT_CACHE.clear(); } } private static class Record { private final String uriFragment; private final EObject eContainer; private final EStructuralFeature containingFeature; Record(String uriFragment, EObject container, EStructuralFeature containingFeature) { this.uriFragment = uriFragment;
* return BEANS.get(ApiDocGenerator.class).getWebContent(staticResource); * } * </pre> */ @ApplicationScoped public class ApiDocGenerator { /** * Query parameter for static resource file names. This is used by HTML content generated by * {@link #getWebContent(String)}. */ public static final String STATIC_RESOURCE_PARAM = "r"; protected static final String TEXT_ELEMENT_SEPARATOR = "\t"; protected static final String TEXT_LINE_SEPARATOR = "\n"; public List<ResourceDescriptor> getResourceDescriptors() { return BEANS.all(IRestResource.class).stream() .filter(this::acceptRestResource) .sorted(Comparator.comparing(res -> res.getClass().getSimpleName())) .sorted(Comparator.comparing(res -> "/" + getPath(res))) .map(this::toResourceDescriptor) .filter(Objects::nonNull) .collect(Collectors.toList()); } protected ResourceDescriptor toResourceDescriptor(IRestResource resource) { String resourcePath = "/" + getPath(resource);
sb.append(TEXT_ELEMENT_SEPARATOR); sb.append(StringUtility.emptyIfNull(m.getProduces())); sb.append(TEXT_ELEMENT_SEPARATOR); sb.append(m.getDescriptionText()); sb.append(TEXT_LINE_SEPARATOR); }); }); return sb.toString(); } public static class ResourceDescriptor { private IRestResource m_resource; private String m_path; private String m_basePath; // first segment of "path" private String m_name; private String m_anchor; private DescriptionDescriptor m_description; private List<MethodDescriptor> m_methods; public IRestResource getResource() { return m_resource; } public ResourceDescriptor withResource(IRestResource resource) { m_resource = resource; return this; } public String getPath() { return m_path; } public ResourceDescriptor withPath(String path) { m_path = path; return this; } public String getBasePath() { return m_basePath; } public ResourceDescriptor withBasePath(String basePath) { m_basePath = basePath;
import org.eclipse.scout.rt.shared.AbstractIcons; import org.eclipse.scout.rt.shared.data.basic.FontSpec; import org.eclipse.scout.rt.shared.services.lookup.ILookupCall; import org.eclipse.scout.rt.shared.services.lookup.ILookupRow; import org.eclipse.scout.rt.shared.services.lookup.LocalLookupCall; import org.eclipse.scout.rt.shared.services.lookup.LookupRow; @ClassId("c6ee18fd-e630-4d92-81b1-cd0147c902d4") public class DefaultTileTableHeaderBox extends AbstractGroupBox implements ITileTableHeaderBox { private TableListener m_tableListener; private boolean m_isGrouping; private boolean m_isSorting; protected TableListener createTableListener() { return new TableAdapter() { @Override public void tableChanged(TableEvent e) { switch (e.getType()) { case TableEvent.TYPE_COLUMN_HEADERS_UPDATED: syncSortingGroupingFields(); break; } } }; } protected void syncSortingGroupingFields() { try { // don't call execChangedValue since it would trigger sort/group again getSortByField().setValueChangeTriggerEnabled(false);
protected void execChangedValue() { try { m_isGrouping = true; if (getValue() == null) { getTable().getColumnSet().removeGroupColumn(CollectionUtility.firstElement(getTable().getColumnSet().getGroupedColumns())); } else { getTable().getColumnSet().handleGroupingEvent(getValue(), false, true); ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); } } finally { m_isGrouping = false; }
protected void execChangedValue() { try { m_isSorting = true; if (getValue() == null) { getTable().getColumnSet().removeSortColumn(CollectionUtility.firstElement(getTable().getColumnSet().getSortColumns())); } else { getTable().getColumnSet().handleSortEvent(getValue().getLeft(), false, getValue().getRight()); ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); } } finally { m_isSorting = false; }
* BSI Business Systems Integration AG - initial API and implementation ******************************************************************************/ package org.eclipse.scout.rt.rest.error; import javax.ws.rs.core.MediaType; import javax.ws.rs.core.Response; import javax.ws.rs.core.Response.Status; import org.eclipse.scout.rt.platform.BEANS; import org.eclipse.scout.rt.platform.Bean; import org.eclipse.scout.rt.platform.context.CorrelationId; /** * Builder for {@link ErrorDo} and {@link ErrorResponse} objects. */ @Bean public class ErrorResponseBuilder { private int m_httpStatus; private String m_errorCode; private String m_title; private String m_message; public ErrorResponseBuilder withStatus(int status) { m_status = status; return this; } public ErrorResponseBuilder withStatus(Status status) { m_status = status.getStatusCode(); return this; } public ErrorResponseBuilder withTitle(String title) { m_title = title; return this; } public ErrorResponseBuilder withMessage(String message) { m_message = message; return this; } public ErrorResponseBuilder withCode(int code) {
******************************************************************************/ package org.eclipse.scout.rt.rest.error; import javax.ws.rs.core.MediaType; import javax.ws.rs.core.Response; import javax.ws.rs.core.Response.Status; import org.eclipse.scout.rt.platform.BEANS; import org.eclipse.scout.rt.platform.Bean; import org.eclipse.scout.rt.platform.context.CorrelationId; /** * Builder for {@link ErrorDo} and {@link ErrorResponse} objects. */ @Bean public class ErrorResponseBuilder { private int m_httpStatus; private String m_errorCode; private String m_title; private String m_message; public ErrorResponseBuilder withStatus(int status) { m_status = status; return this; } public ErrorResponseBuilder withStatus(Status status) { m_status = status.getStatusCode(); return this; } public ErrorResponseBuilder withTitle(String title) { m_title = title; return this; } public ErrorResponseBuilder withMessage(String message) { m_message = message; return this; } public ErrorResponseBuilder withCode(int code) { m_code = String.valueOf(code); return this; }
public ErrorResponseBuilder withHttpStatus(int httpStatus) { m_httpStatus = httpStatus; return this;
public ErrorResponseBuilder withErrorCode(int errorCode) { m_errorCode = String.valueOf(errorCode); return this;
public ErrorResponseBuilder withErrorCode(String errorCode) { m_errorCode = errorCode; return this;
@Override public Object execute(ExecutionEvent event) throws ExecutionException { Shell activeShell= HandlerUtil.getActiveShell(event); Object newNameValue= HandlerUtil.getVariable(event, LTK_RENAME_COMMAND_NEWNAME_PARAMETER_KEY); String newName= null; if (newNameValue instanceof String) { newName= (String) newNameValue; } else if (newNameValue != null) { RefactoringUIPlugin.logErrorMessage(RefactoringUIMessages.RenameResourceHandler_ERROR_EXPECTED_STRING + newNameValue.getClass().getName()); } ISelection sel= HandlerUtil.getCurrentSelection(event); if (sel instanceof IStructuredSelection) { IResource resource= getCurrentResource((IStructuredSelection) sel); if (resource != null) { RenameResourceWizard refactoringWizard; if (newName != null) { refactoringWizard= new RenameResourceWizard(resource, newName); } else { refactoringWizard= new RenameResourceWizard(resource); } RefactoringWizardOpenOperation op= new RefactoringWizardOpenOperation(refactoringWizard); try { op.run(activeShell, RefactoringUIMessages.RenameResourceHandler_title); } catch (InterruptedException e) { // do nothing } } } return null; }
protected void addUserInputPages() { RenameResourceProcessor processor= getRefactoring().getAdapter(RenameResourceProcessor.class); addPage(new RenameResourceRefactoringConfigurationPage(processor));
@Override public Object execute(ExecutionEvent event) throws ExecutionException { Shell activeShell= HandlerUtil.getActiveShell(event); Object newNameValue= HandlerUtil.getVariable(event, LTK_RENAME_COMMAND_NEWNAME_PARAMETER_KEY); String newName= null; if (newNameValue instanceof String) { newName= (String) newNameValue; } else if (newNameValue != null) { RefactoringUIPlugin.logErrorMessage(NLS.bind(RefactoringUIMessages.RenameResourceHandler_ERROR_EXPECTED_STRING, newNameValue.getClass().getName())); } ISelection sel= HandlerUtil.getCurrentSelection(event); if (sel instanceof IStructuredSelection) { IResource resource= getCurrentResource((IStructuredSelection) sel); if (resource != null) { RenameResourceWizard refactoringWizard; if (newName != null) { refactoringWizard= new RenameResourceWizard(resource, newName); } else { refactoringWizard= new RenameResourceWizard(resource); } RefactoringWizardOpenOperation op= new RefactoringWizardOpenOperation(refactoringWizard); try { op.run(activeShell, RefactoringUIMessages.RenameResourceHandler_title); } catch (InterruptedException e) { // do nothing } } } return null; }
inputViewer.setInput(getType()); commandStack = commandStackBuffer; } }); } } private ChangeNameCommand getRenameCommand(String newValue) { INamedElement element = getType(); if (element instanceof FBNetworkElement) { return new ChangeFBNetworkElementName((FBNetworkElement) element, newValue); } return new ChangeNameCommand(getType(), nameText.getText()); } private class ValueCommentCellModifier implements ICellModifier { @Override public boolean canModify(final Object element, final String property) { return (VALUE_PROPERTY.equals(property) || COMMENT_PROPERTY.equals(property)); } @Override public Object getValue(final Object element, final String property) { switch (property) { case VALUE_PROPERTY: return getVarDeclarationValue((VarDeclaration) element); case COMMENT_PROPERTY: return ((INamedElement) element).getComment() != null ? ((INamedElement) element).getComment() : ""; //$NON-NLS-1$ default: return null; } } @Override public void modify(final Object element, final String property, final Object value) {
import org.eclipse.fordiac.ide.model.commands.change.ChangeCommentCommand; import org.eclipse.fordiac.ide.model.commands.change.ChangeNameCommand; import org.eclipse.fordiac.ide.model.libraryElement.Device; import org.eclipse.gef.EditPart; import org.eclipse.swt.SWT; import org.eclipse.swt.events.SelectionAdapter; import org.eclipse.swt.events.SelectionEvent; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.layout.GridLayout; import org.eclipse.swt.widgets.Button; import org.eclipse.swt.widgets.Combo; import org.eclipse.swt.widgets.Composite; public class DeviceSection extends AbstractDevResInterfaceSection { protected static String[] profileNames = null; protected Combo profile; protected Button getResources; @Override public void refresh() { super.refresh(); if (null != type) { setProfile(); getResources.setEnabled("DynamicTypeLoad".equals(((Device) getType()).getProfile())); } } private void setProfile() { int i = 0; for (String p : profile.getItems()) { if (p.equals(((Device) getType()).getProfile())) { profile.select(i); break;
teamArt.getAtsId()); } // Confirm that all blocking reviews are completed // Loop through this state's blocking reviews to confirm complete if (teamArt.isTeamWorkflow()) { for (IAtsAbstractReview review : ReviewManager.getReviewsFromCurrentState(teamArt)) { AbstractReviewArtifact reviewArt = (AbstractReviewArtifact) AtsClientService.get().getQueryService().getArtifact(review); if (reviewArt.getReviewBlockType() == ReviewBlockType.Commit && !reviewArt.isCompletedOrCancelled()) { AWorkbench.popup("Commit Branch Error!", "All blocking reviews must be completed before committing a new branch. Please complete all blocking reviews in order to continue."); return; } } } if (!overrideStateValidation) { final MutableBoolean adminOverride = new MutableBoolean(false); // Check extension points for valid commit for (IAtsStateItem item : AtsStateItemManager.getStateItems()) { final Result tempResult = item.committing(teamArt); if (tempResult.isFalse()) { // Allow Admin to override state validation
null); // private Collection derivedEntities; @Override public String getMarkingTag() { return ManagedEntityArtifact.MARKING_TAG; } @Override public IAbstractArtifactInternal getModel() { return MODEL; } public String getLabel() { return getMetadata().getLabel(this); } // public Collection getDerivedEntities() { // return this.derivedEntities; // } // public ManagedEntityArtifact(ArtifactManager artifactMgr) { super(artifactMgr); setIStandardSpecifics(new OssjEntitySpecifics(this)); } @Override public IAbstractArtifactInternal extractFromClass(JavaClass javaClass, ArtifactManager artifactMgr, IProgressMonitor monitor) { ManagedEntityArtifact result = new ManagedEntityArtifact(javaClass, artifactMgr, monitor); return result; } public ManagedEntityArtifact(JavaClass javaClass, ArtifactManager artifactMgr, IProgressMonitor monitor) { super(javaClass, artifactMgr, monitor); // this.derivedEntities = new ArrayList(); OssjEntitySpecifics specifics = new OssjEntitySpecifics(this); specifics.build(); setIStandardSpecifics(specifics); } // @Override // public void resolveReferences(IProgressMonitor monitor)
} else if (OS.RegOpenKeyEx(OS.HKEY_LOCAL_MACHINE, key, 0, OS.KEY_READ, phkResult) == 0) { // Try reading from HKLM regKeyFound = true; } if (regKeyFound) { int [] lpcbData = new int [1]; TCHAR buffer = new TCHAR (0, "AppsUseLightTheme", true); //$NON-NLS-1$ int result = OS.RegQueryValueEx (phkResult [0], buffer, 0, null, (TCHAR)null, lpcbData); if (result == 0) { isDarkTheme = (lpData[0] == 0); } OS.RegCloseKey (phkResult [0]); } } return isDarkTheme;
* instance is modified to represent a different object name. */ public abstract class AnyObjectId implements Comparable<AnyObjectId> { /** * Compare to object identifier byte sequences for equality. * * @param firstObjectId * the first identifier to compare. Must not be null. * @param secondObjectId * the second identifier to compare. Must not be null. * @return true if the two identifiers are the same. */ @Deprecated @SuppressWarnings("AmbiguousMethodReference") public static boolean equals(final AnyObjectId firstObjectId, final AnyObjectId secondObjectId) { if (firstObjectId == secondObjectId) return true; // We test word 3 first since the git file-based ODB // uses the first byte of w1, and we use w2 as the // hash code, one of those probably came up with these // two instances which we are comparing for equality. // Therefore the first two words are very likely to be
handleMiddleClick(event); }); } private void handleMiddleClick(MouseEvent event) throws CoreException { if (event.button == 2 && event.widget instanceof Tree) { TreeItem item = ((Tree) event.widget).getItem(new Point(event.x, event.y)); if (item == null) { return; } Object data = item.getData(); if (data instanceof IProject) { IProject project = (IProject) data; CloseResourceAction cra = new CloseResourceAction(() -> null); cra.selectionChanged(new StructuredSelection(project)); cra.run(); } } } });
} @Override public boolean isHidden(File path) throws IOException { return FileUtil.isHidden(path); } @Override public void setHidden(File path, boolean hidden) throws IOException { FileUtil.setHidden(path, hidden); } @Override public String readSymLink(File path) throws IOException { return FileUtil.readSymlink(path); } @Override public void createSymLink(File path, String target) throws IOException { FileUtil.createSymLink(path, target); } /** * @since 3.3 */ @Override public Attributes getAttributes(File path) { return FileUtils.getFileAttributesBasic(this, path); } }
RebaseTodoLine line = null; String commentString = RawParseUtils.decode(buf, tokenBegin, lineEnd + 1); try { int skip = tokenBegin + 1; // skip '#' skip = nextParsableToken(buf, skip, lineEnd); if (skip != -1) { // try to parse the line as non-comment line = parseLine(buf, skip, lineEnd); // successfully parsed as non-comment line // mark this line as a comment explicitly if (line != null) { // successfully parsed as a non-comment line // mark this line as a comment explicitly line.setAction(Action.COMMENT); // use the read line as comment string line.setComment(commentString); } } } catch (Exception e) { // parsing as non-comment line failed line = null; } finally { if (line == null) line = new RebaseTodoLine(commentString); r.add(line); }
* @param treeStyle the style bits for the <code>Tree</code> * @param filter the filter to be used * * @deprecated As of 3.116, replaced by * {@link #FilteredTree(Composite, int, PatternFilter, boolean, boolean)} * * */ @Deprecated public FilteredTree(Composite parent, int treeStyle, PatternFilter filter) { super(parent, SWT.NONE); this.parent = parent; init(treeStyle, filter); } /** * Create a new instance of the receiver. * * <p> * <b>WARNING:</b> Using this constructor results in a slow performing tree and * should not be used if the underlying data model uses a stable and correct * hashCode and equals implementation. Prefer the usage of * {@link #FilteredTree(Composite, int, PatternFilter, boolean, boolean)} if * possible * </p> * * @param parent the parent <code>Composite</code>
private void add(String... searchStrings) { boolean hasStrings= false; if (searchStrings != null) { for (String searchString : searchStrings) { hasStrings|= insert(searchString); } Node node= root; for (char c : searchString.toCharArray()) { node= node.add(c); } node.match= searchString; }
* * @since 3.9 */ public class MultiStringMatcher { // An implementation of the Aho-Corasick algorithm (without the DFA construction from section 6 of the // paper; just the failure and output links). // // See Aho, Alfred A.; Corasick, Margaret J.: "Efficient String Matching: An Aid to Bibliographic Search", // CACM 18(6), 1975. // // The algorithm has been modified to support both reporting all matches or only leftmost longest matches. /** * Describes a match result of {@link MultiStringMatcher#indexOf(String, int)}, giving access to * the matched string and the offset in the text it was matched at. */ public static interface Match { /** * Obtains the matched string. * * @return the text matched */ String getText(); /** * Obtains the offset the {@link #getText() text} was matched at. * * @return the offset */ int getOffset(); }
* <p> * Performs a simultaneous search for all the strings, returning the leftmost match. If multiple * search strings match at the same index, the longest match is returned. * </p> * * @param text to search * @param offset to start searching at * @return the leftmost longest match found, or {@code null} if no match was found. */ public Match indexOf(String text, int offset) { List<Match> matches= find(text, offset, true); if (matches.isEmpty()) { return null; } // Find the leftmost longest match. Maybe there's an awfully clever way to keep only // one match? Iterator<Match> m= matches.iterator(); Match result= m.next(); while (m.hasNext()) { Match cand= m.next(); int cmp= Integer.compare(cand.getOffset(), result.getOffset()); if (cmp < 0) { result= cand;
// we have a full match. Standard Aho-Corasick would take the fail link on // the next character, which may or may not take us to root, and keep on // looking for more matches. We stop instead if we are looking only for the // first match. Note that we _do_ have a match at least from this node itself. matches.add(new MatchResult(node.match, i - node.match.length() + 1)); break; } if (node.match != null) { matches.add(new MatchResult(node.match, i - node.match.length() + 1)); } if (!firstOnly || matches.isEmpty()) { Node out= node.output; while (out != null) { matches.add(new MatchResult(out.match, i - out.match.length() + 1)); out= out.output; } } } } return matches;
testList(matches, "[[x, 2]]"); } @Test public void noStrings001() throws Exception { thrown.expect(IllegalStateException.class); MultiStringMatcher.builder().build(); } @Test public void noStrings002() throws Exception { thrown.expect(IllegalStateException.class); MultiStringMatcher.builder().add("").build(); } @Test public void noStrings003() throws Exception { MultiStringMatcher m = MultiStringMatcher.builder().add((String[]) null).build(); List<Match> matches = m.find("dddhiheddd", 0); assertEquals("Expected no match", 0, matches.size()); } @Test public void fluent001() throws Exception { MultiStringMatcher m = MultiStringMatcher.builder().add("he", "she", "his", "hers").build(); test(m.indexOf("ushers", 0), "she", 1); } @Test public void fluent002() throws Exception { MultiStringMatcher m = MultiStringMatcher.builder().add("he", "she").add("his", "hers").build(); testList(m.find("ushers", 0), "[[she, 1], [he, 2], [hers, 2]]"); }
public Match indexOf(String text, int offset) { List<Match> matches= find(text, offset, true); if (matches.isEmpty()) { return null; } // Find the leftmost longest match. Maybe there's an awfully clever way to keep only // one match? Iterator<Match> m= matches.iterator(); Match result= m.next(); while (m.hasNext()) { Match cand= m.next(); if (cand.getOffset() > result.getOffset()) { // Results are ordered by offset. // We are searching for the leftmost so all remaining candidates do not matter. break; } if (cand.getText().length() > result.getText().length()) { result= cand; } } return result;
package org.eclipse.tycho.pomless; import java.io.File; import java.io.FileFilter; import java.io.IOException; import org.apache.maven.model.Model; import org.apache.maven.model.io.ModelParseException; import org.codehaus.plexus.component.annotations.Component; import org.sonatype.maven.polyglot.mapping.Mapping; import org.w3c.dom.Element; @Component(role = Mapping.class, hint = TychoTargetMapping.ROLE) public class TychoTargetMapping extends AbstractXMLTychoMapping { private static final String TARGET_EXTENSION = ".target"; public static final String PACKAGING = "eclipse-target-definition"; @Override public String getFlavour() { return TychoTargetMapping.ROLE; } @Override protected boolean isValidLocation(String location) { return location.endsWith(TARGET_EXTENSION); } @Override protected File getPrimaryArtifact(File dir) { File file = new File(dir, dir.getName() + TARGET_EXTENSION); if (file.exists()) { return file; } File[] listFiles = dir.listFiles(new FileFilter() { @Override public boolean accept(File file) {
@Override public void checkPermission(Permission requested) { for (Permission permission : permissions) { if (permission.implies(requested)) { return; } } super.checkPermission(requested); } }); } @After public void tearDown() throws Exception { System.setSecurityManager(originalSecurityManager); // Note: don't use this method before security manager is replaced in // setUp() method. The method uses FS.DETECTED internally and can affect // the test. FileUtils.delete(root, FileUtils.RECURSIVE | FileUtils.RETRY); } @Test public void testInitAndClone() throws IOException, GitAPIException { File remote = new File(root, "remote"); File local = new File(root, "local"); try (Git git = Git.init().setDirectory(remote).call()) { JGitTestUtil.write(new File(remote, "hello.txt"), "Hello world!"); git.add().addFilepattern(".").call(); git.commit().setMessage("Initial commit").call(); }
protected static File searchPath(String path, String... lookFor) { if (path == null) return null; for (String p : path.split(File.pathSeparator)) { for (String command : lookFor) { final File file = new File(p, command); try { if (file.isFile()) { return file.getAbsoluteFile(); } } catch (SecurityException e) { LOG.warn(MessageFormat.format( JGitText.get().skipNotAccessiblePath, file.getPath())); } } } return null;
} catch (InterruptedException ie) { // Stop bothering me, I have a zombie to reap. } } } catch (IOException e) { LOG.error("Caught exception in FS.readPipe()", e); //$NON-NLS-1$ } catch (AccessControlException e) { LOG.warn( "FS.readPipe() isn't allowed for command '{}'. Working directory: '{}'. Required permission: {}", //$NON-NLS-1$ command, dir, e.getPermission()); } catch (SecurityException e) { LOG.warn(MessageFormat.format(JGitText.get().readPipeIsNotAllowed, command, dir)); } if (debug) { LOG.debug("readpipe returns null"); //$NON-NLS-1$ } return null; } private static class GobblerThread extends Thread { /* The process has 5 seconds to exit after closing stderr */ private static final int PROCESS_EXIT_TIMEOUT = 5; private final Process p; private final String desc;
* (non-Javadoc) * @see org.eclipse.ptp.rdt.sync.core.services.ISynchronizeService#synchronize(org.eclipse.core.resources.IProject, * org.eclipse.ptp.rdt.sync.core.RemoteLocation, org.eclipse.core.resources.IResourceDelta, * org.eclipse.core.runtime.IProgressMonitor, java.util.EnumSet) */ @Override public void synchronize(final IProject project, RemoteLocation rl, IResourceDelta delta, IProgressMonitor monitor, Set<SyncFlag> syncFlags) throws CoreException { if (project == null || rl == null) { throw new NullPointerException(); } // ignore deltas with filtered resource if (delta != null && getSyncFileFilter(project).shouldIgnore(delta.getResource())) { return; } // Make a copy to protect against the remote location // being changed by another thread. RemoteLocation remoteLoc = new RemoteLocation(rl); ProjectAndRemoteLocationPair syncTarget = new ProjectAndRemoteLocationPair(project, remoteLoc); if(syncFlags.contains(SyncFlag.WAIT_FOR_LR)) { try { SyncInt si = syncLRPending.get(syncTarget);
* org.eclipse.core.runtime.IProgressMonitor, java.util.EnumSet) */ @Override public void synchronize(final IProject project, RemoteLocation rl, IResourceDelta delta, IProgressMonitor monitor, Set<SyncFlag> syncFlags) throws CoreException { if (project == null || rl == null) { throw new NullPointerException(); } // ignore deltas with filtered resource if (delta != null && getSyncFileFilter(project).shouldIgnore(delta.getResource())) { return; } // Make a copy to protect against the remote location // being changed by another thread. RemoteLocation remoteLoc = new RemoteLocation(rl); ProjectAndRemoteLocationPair syncTarget = new ProjectAndRemoteLocationPair(project, remoteLoc); if(syncFlags.contains(SyncFlag.WAIT_FOR_LR)) { try { SyncInt si = syncLRPending.get(syncTarget); if (si != null) { si.waitForZero(); } } catch (InterruptedException e) { // This shouldn't happen. Activator.log(e); } return; }
* </ul> * * @since 2.1 */ public void paste () { checkWidget (); if ((style & SWT.READ_ONLY) != 0) return; OS.SendMessage (handle, OS.WM_PASTE, 0, 0); } void stateFlagsAdd(int flags) { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); /* * Bug 550423: When non-XP-theme COMMCTL32.DLL gets loaded, undocumented * internal data is not there. We do not support that and in such case * GetWindowLongPtr function fails and return zero. */ if (tagCBoxPtr == 0) return; final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); stateFlags[0] |= flags; OS.MoveMemory(stateFlagsPtr, stateFlags, 4); } /* * Verify that undocumented internal data is in expected location. * The test is performed at creation time, when the value of state flags is predictable.
} /* * Verify that undocumented internal data is in expected location. * The test is performed at creation time, when the value of state flags is predictable. * For simplicity, only SWT.READ_ONLY combos are handled. */ boolean stateFlagsTest() { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); /* * Bug 550423: When non-XP-theme COMMCTL32.DLL gets loaded, undocumented * internal data is not there. We do not support that and in such case * GetWindowLongPtr function fails and return zero. */ if (tagCBoxPtr == 0) return false; final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); /* * 0x00000002 is unknown * 0x00002000 is set in WM_NCCREATE * 0x00004000 means CBS_DROPDOWNLIST (SWT.READ_ONLY) * 0x02000000 is set in WM_NCCREATE and reset after first WM_PAINT */ return (stateFlags[0] == 0x02006002); }
} } /* * Verify that undocumented internal data is in expected location. * The test is performed at creation time, when the value of state flags is predictable. * For simplicity, only SWT.READ_ONLY combos are handled. */ boolean stateFlagsTest() { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); /* * Bug 550423: When non-XP-theme COMMCTL32.DLL gets loaded, undocumented * internal data is not there. We do not support that and is such case * GetWindowLongPtr function fails and return zero. */ if (tagCBoxPtr != 0) { final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); /* * 0x00000002 is unknown * 0x00002000 is set in WM_NCCREATE * 0x00004000 means CBS_DROPDOWNLIST (SWT.READ_ONLY) * 0x02000000 is set in WM_NCCREATE and reset after first WM_PAINT */ return (stateFlags[0] == 0x02006002); } return false; } @Override void register () {
if (length == OS.CB_ERR) { int count = (int)/*64*/OS.SendMessage (handle, OS.CB_GETCOUNT, 0, 0); if (0 <= index && index < count) error (SWT.ERROR_ITEM_NOT_REMOVED); error (SWT.ERROR_INVALID_RANGE); } buffer = new TCHAR (getCodePage (), length + 1); int result = (int)/*64*/OS.SendMessage (handle, OS.CB_GETLBTEXT, index, buffer); if (result == OS.CB_ERR) { int count = (int)OS.SendMessage (handle, OS.CB_GETCOUNT, 0, 0); if (0 <= index && index < count) error (SWT.ERROR_ITEM_NOT_REMOVED); error (SWT.ERROR_INVALID_RANGE); } } int length = OS.GetWindowTextLength (handle); int code = (int)/*64*/OS.SendMessage (handle, OS.CB_DELETESTRING, index, 0); if (code == OS.CB_ERR) { int count = (int)/*64*/OS.SendMessage (handle, OS.CB_GETCOUNT, 0, 0);
private static final String pageName = "Scripts"; private ToolItem abortButton; private ToolItem abortBatchButton; private CoolBar coolBar; private ToolItem deleteButton; private Label hostConnectLabel; private LoadWidget loadWidget; protected ToolItem runButton; private SaveWidget saveWidget; private ScriptTableViewer scriptTable; private StatusWindowWidget statusWindow; private final TestManagerEditor testManagerEditor; private ProgramButtonProviderService programButtonProviderService; public ScriptPage(Composite parent, int style, TestManagerEditor parentTestManager) { super(parent, style, parentTestManager); this.testManagerEditor = parentTestManager; } public void addFile(String fullPath) { scriptTable.addFile(fullPath); } @Override public void createPage() { super.createPage(); Composite parent = (Composite) getContent(); coolBar = new CoolBar(parent, SWT.FLAT); createControlsToolBar(coolBar); createConfigurationToolBar(coolBar); packCoolBar();
} // Example: As above, but to be moved to the appropriate class/location. ILibraryLinkerProviderService libraryLinkerProviderService = OsgiUtil.getService(ILibraryLinkerProvider.class, LibraryLinkerProviderService.class); for (ILibraryLinkerProvider provider : libraryLinkerProviderService.getLibraryLinkerProviders()) { provider.getLibraryLinkers(); } // Example: As above, but to be moved to the appropriate class/location. ILaunchAndKillProviderService launchAndKillProviderService = OsgiUtil.getService(ILaunchAndKillProvider.class, LaunchAndKillProviderService.class); // Example to launch and kill processes: for (ILaunchAndKillProvider provider : launchAndKillProviderService.getLaunchAndKillProviders()) { Collection<ILaunchAndKill> launchers = provider.getLaunchers(); Collection<ILaunchAndKill> killers = provider.getKillers(); for (ILaunchAndKill launcher : launchers) { Process launchProcess; // To access Process methods //launchProcess = launcher.executeProcess(); // Launches the process break; } for (ILaunchAndKill killer : killers) { Process killProcess; // To access Process methods
if (selection.getFirstElement() instanceof Table) { this.exportedTable = (Table) selection.getFirstElement(); } else if (selection instanceof TableStructuredSelection) { final TableStructuredSelection tss = (TableStructuredSelection) selection; final INattableModelManager tableModelManager = (INattableModelManager) tss.getAdapter(INattableModelManager.class); if (null != tableModelManager) { this.exportedTable = tableModelManager.getTable(); } } Assert.isNotNull(this.exportedTable, Messages.ExportAsTableConfigurationWizard_WeCantFoundTheTableToExport); IStatus status = TableChecker.checkTable(this.exportedTable); if (false == status.isOK()) { addPage(new WarningOnCurrentTableWizardPage(status)); } this.outputPage = new DefineOutputPluginWizardPage(); this.tableDataPage = new DefineTableConfigurationDataWizardPage(); this.outputPage.setExportedTable(this.exportedTable); this.tableDataPage.setExportedTable(this.exportedTable); addPage(outputPage); addPage(tableDataPage);
if (field != null) { return new JDIFieldVariable(debugTarget, field, getUnderlyingObject(), fLogicalParent); } // Check possible references of variables defined in outer class for (Field outer : synteticFields) { // retrieve the reference to the "outer" object JDIFieldVariable syntVariable = new JDIFieldVariable(debugTarget, outer, getUnderlyingObject(), fLogicalParent); IValue value = syntVariable.getValue(); if (value instanceof JDIObjectValue) { JDIObjectValue outerObject = (JDIObjectValue) value; // ask "outer" object about field probably declared within return outerObject.getField(name, outer.signature()); } } } catch (RuntimeException e) { targetRequestFailed( MessageFormat.format( JDIDebugModelMessages.JDIObjectValue_exception_retrieving_field, e.toString()), e); } // it is possible to return null return null; } static List<ReferenceType> superTypes(ReferenceType type) { List<ReferenceType> superTypes = new ArrayList<>(); ReferenceType t = type;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.Routing; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.RoutingBuilder; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class InterfaceRoutingCustomizerTest extends WriterCustomizerTest { private static final String IFACE_CTX_NAME = "interface-ctx"; private static final String IF_NAME = "eth1"; private static final int IF_INDEX = 1; private static final InstanceIdentifier<Routing> IID = InstanceIdentifier.create(Interfaces.class).child(Interface.class, new InterfaceKey(IF_NAME)) .augmentation(VppInterfaceAugmentation.class).child(Routing.class); private InterfaceRoutingCustomizer customizer; @Override protected void setUpTest() throws Exception { customizer = new InterfaceRoutingCustomizer(api, new NamingContext("ifacePrefix", IFACE_CTX_NAME));
import java.util.Collections; import java.util.Set; import org.junit.Test; import org.mockito.ArgumentCaptor; import org.mockito.Captor; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.Interfaces; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.interfaces.Interface; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.interfaces.InterfaceKey; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.SubinterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.SubInterfaces; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.sub.interfaces.SubInterface; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.sub.interfaces.SubInterfaceBuilder;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VxlanVni; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.Vxlan; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.VxlanBuilder; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class VxlanCustomizerTest extends WriterCustomizerTest implements AddressTranslator { private static final byte ADD_VXLAN = 1; private static final byte DEL_VXLAN = 0; @Mock private DisabledInterfacesManager disableContext; private VxlanCustomizer customizer; private String ifaceName; private InstanceIdentifier<Vxlan> id; private static Vxlan generateVxlan(long vni) { final VxlanBuilder builder = new VxlanBuilder(); builder.setSrc(new IpAddressNoZone(new Ipv4AddressNoZone("192.168.20.10")));
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceStateAugmentationBuilder; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces.state._interface.Routing; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces.state._interface.RoutingBuilder; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class InterfaceRoutingCustomizerTest extends ReaderCustomizerTest<Routing, RoutingBuilder> { private static final String IFC_CTX_NAME = "ifc-test-instance"; private static final String IF_NAME = "local0"; private static final int IF_ID = 1; private static final Long IP4_VRF_ID = 1L; private static final Long IP6_VRF_ID = 2L; private NamingContext interfacesContext; public InterfaceRoutingCustomizerTest() { super(Routing.class, VppInterfaceStateAugmentationBuilder.class); } @Override public void setUp() {
namingContext.removeChild(PARENT_1, CHILD_1, mappingContext); verify(mappingContext, times(1)) .put(instanceIdentifierArgumentCaptor.capture(), mappingArgumentCaptor.capture()); assertEquals(instanceIdentifierArgumentCaptor.getValue(), parentKey(PARENT_1)); final Mapping mapping = mappingArgumentCaptor.getValue(); final List<Value> values = mapping.getValue(); assertEquals(PARENT_1, mapping.getName()); assertThat(values, hasSize(2)); assertThat(values, containsInAnyOrder(valueFor(CHILD_2, 2), valueFor(CHILD_3, 3))); } @Test public void removeChildNonExistingParent() { namingContext.removeChild(NON_EXISTING_PARENT, CHILD_1, mappingContext); // if parent doest not exist, do nothing verify(mappingContext, times(0)).put(Mockito.any(), Mockito.any()); } private Value valueFor(final String name, final int index) { return new ValueBuilder().setName(name).setIndex(index).withKey(new ValueKey(name)).build(); } }
import io.fd.hc2vpp.ipsec.read.IpsecReaderFactory; import io.fd.hc2vpp.ipsec.write.IpsecWriterFactory; import io.fd.honeycomb.translate.read.ReaderFactory; import io.fd.honeycomb.translate.write.WriterFactory; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * Module class instantiating nat plugin components. */ public class IpsecModule extends AbstractModule { private static final Logger LOG = LoggerFactory.getLogger(IpsecModule.class); private static final String SAD_ENTRIES_MAPPING = "sad-entries-mapping"; @Override protected void configure() { LOG.info("Installing IPSec module"); bind(MultiNamingContext.class).toInstance(new MultiNamingContext(SAD_ENTRIES_MAPPING, 1)); LOG.info("Injecting writers factories"); final Multibinder<WriterFactory> writerFactoryBinder = Multibinder.newSetBinder(binder(), WriterFactory.class); writerFactoryBinder.addBinding().to(IpsecWriterFactory.class).in(Singleton.class); LOG.info("Injecting readers factories"); final Multibinder<ReaderFactory> readerFactoryBinder = Multibinder.newSetBinder(binder(), ReaderFactory.class); readerFactoryBinder.addBinding().to(IpsecReaderFactory.class).in(Singleton.class);
import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecStateSpdAugmentationBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.Spd; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.spd.SpdEntries; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; /** * Factory producing readers for IpSec plugin's data. */ public final class IpsecReaderFactory implements ReaderFactory { private static final InstanceIdentifier<IpsecState> IPSEC_STATE_ID = InstanceIdentifier.create(IpsecState.class); private FutureJVppCore vppApi; @Inject public IpsecReaderFactory(final FutureJVppCore vppApi) { this.vppApi = vppApi; } @Override public void init(@Nonnull final ModifiableReaderRegistryBuilder registry) { registry.subtreeAdd(Sets .newHashSet(InstanceIdentifier.create(IpsecState.class).child(Sa.class), InstanceIdentifier.create(IpsecState.class).augmentation(IpsecStateSpdAugmentation.class).child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpsecStateCustomizer(vppApi)));
import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecStateSpdAugmentationBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.Spd; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.spd.SpdEntries; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; /** * Factory producing readers for IpSec plugin's data. */ public final class IpsecReaderFactory implements ReaderFactory { private static final InstanceIdentifier<IpsecState> IPSEC_STATE_ID = InstanceIdentifier.create(IpsecState.class); private FutureJVppCore vppApi; @Inject public IpsecReaderFactory(final FutureJVppCore vppApi) { this.vppApi = vppApi; } @Override public void init(@Nonnull final ModifiableReaderRegistryBuilder registry) { registry.subtreeAdd(Sets .newHashSet(InstanceIdentifier.create(IpsecState.class).child(Sa.class), InstanceIdentifier.create(IpsecState.class).augmentation(IpsecStateSpdAugmentation.class).child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpsecStateCustomizer(vppApi)));
InstanceIdentifier.create(IpsecState.class).augmentation(IpsecStateSpdAugmentation.class).child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpsecStateCustomizer(vppApi))); registry.addStructuralReader(IPSEC_STATE_ID.augmentation(IpsecStateSpdAugmentation.class), IpsecStateSpdAugmentationBuilder.class); registry.subtreeAdd(Sets .newHashSet(InstanceIdentifier.create(Spd.class).child(SpdEntries.class)), new GenericInitListReader<>( IPSEC_STATE_ID.augmentation(IpsecStateSpdAugmentation.class).child(Spd.class), new IpsecStateSpdCustomizer(vppApi)));
public IpsecStateCustomizer(final FutureJVppCore vppApi) { super(vppApi); this.ipsecSaDetailsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSaDetailsReplyDump, Void>() .withExecutor(new IpsecStateCustomizer.IpsecStateSaDetailsDumpExecutor(vppApi)) .acceptOnly(IpsecSaDetailsReplyDump.class) .build();
return Initialized.create(id, readValue); } @Nonnull @Override public IpsecStateBuilder getBuilder(@Nonnull final InstanceIdentifier<IpsecState> id) { return new IpsecStateBuilder(); } @Override public void readCurrentAttributes(@Nonnull final InstanceIdentifier<IpsecState> id, @Nonnull final IpsecStateBuilder builder, @Nonnull final ReadContext ctx) throws ReadFailedException { final Optional<IpsecSaDetailsReplyDump> dumpSa = ipsecSaDetailsReplyDumpManager.getDump(id, ctx.getModificationCache()); if (dumpSa.isPresent()) { LinkedList<Sa> listSa = new LinkedList<>(); IpsecSaDetailsReplyDump reply = dumpSa.get(); for (IpsecSaDetails details : reply.ipsecSaDetails) { SaBuilder saBuilder = new SaBuilder(); saBuilder.setSpi(Integer.toUnsignedLong(details.spi)); saBuilder.setAntiReplayWindow(Long.valueOf(details.replayWindow).intValue()); saBuilder.setAuthenticationAlgorithm(IkeIntegrityAlgorithmT.forValue(details.integAlg)); saBuilder.setEncryptionAlgorithm(IkeEncryptionAlgorithmT.forValue(details.cryptoAlg)); listSa.add(saBuilder.build()); } builder.setSa(listSa); } } @Override
if (dumpSa.isPresent()) { LinkedList<Sa> listSa = new LinkedList<>(); IpsecSaDetailsReplyDump reply = dumpSa.get(); for (IpsecSaDetails details : reply.ipsecSaDetails) { SaBuilder saBuilder = new SaBuilder(); saBuilder.setSpi(Integer.toUnsignedLong(details.spi)) .setAntiReplayWindow(Long.valueOf(details.replayWindow).intValue()) .setAuthenticationAlgorithm(IkeIntegrityAlgorithmT.forValue(details.integAlg)) .setEncryptionAlgorithm(IkeEncryptionAlgorithmT.forValue(details.cryptoAlg)); listSa.add(saBuilder.build()); } builder.setSa(listSa); } } @Override public void merge(@Nonnull final Builder<? extends DataObject> parentBuilder, @Nonnull final IpsecState readValue) { IpsecStateBuilder ipsecParentBuilder = (IpsecStateBuilder)parentBuilder; ipsecParentBuilder.setHoldDown(readValue.getHoldDown()); ipsecParentBuilder.setPolicy(readValue.getPolicy()); ipsecParentBuilder.setProposal(readValue.getProposal()); ipsecParentBuilder.setRedundancy(readValue.getRedundancy()); ipsecParentBuilder.setSa(readValue.getSa());
implements EntityDumpExecutor<IpsecSaDetailsReplyDump, Void>, JvppReplyConsumer { private final FutureJVppCore jvpp; IpsecStateSaDetailsDumpExecutor(final FutureJVppCore jvpp) { this.jvpp = jvpp; } @Nonnull @Override public IpsecSaDetailsReplyDump executeDump(final InstanceIdentifier<?> identifier, final Void params) throws ReadFailedException { IpsecSaDump dump = new IpsecSaDump(); dump.saId = -1; return getReplyForRead(jvpp.ipsecSaDump(dump).toCompletableFuture(), identifier); } } }
} } } @Override public void updateCurrentAttributes(@Nonnull final InstanceIdentifier<IkeGlobalConfiguration> id, @Nonnull final IkeGlobalConfiguration dataBefore, @Nonnull final IkeGlobalConfiguration dataAfter, @Nonnull final WriteContext writeContext) throws WriteFailedException { writeCurrentAttributes(id, dataAfter, writeContext); } @Override public void deleteCurrentAttributes(@Nonnull final InstanceIdentifier<IkeGlobalConfiguration> id, @Nonnull final IkeGlobalConfiguration dataBefore, @Nonnull final WriteContext writeContext) throws WriteFailedException { // VPP doesn't support deletion of local key file } }
String name = id.firstKeyOf(Policy.class).getName(); if (dataAfter.getLocal() != null) { setProfileId(id, name, dataAfter.getLocal().getIdentity(), true); } if (dataAfter.getRemote() != null) { setProfileId(id, name, dataAfter.getRemote().getIdentity(), false); } } @Override public void updateCurrentAttributes(@Nonnull final InstanceIdentifier<Identity> id, @Nonnull final Identity dataBefore, @Nonnull final Identity dataAfter, @Nonnull final WriteContext writeContext) throws WriteFailedException { writeCurrentAttributes(id, dataAfter, writeContext); } private void setProfileId(final InstanceIdentifier<Identity> id, final String profileName, final org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.identity.grouping.Identity data, final boolean isLocalId) throws WriteFailedException {
IpsecSadEntriesAugmentation augment = dataAfter.augmentation(IpsecSadEntriesAugmentation.class); if (augment != null && augment.getSaId() != null) { entry.sadId = augment.getSaId(); } if (dataAfter.getSpi() != null) { entry.spi = dataAfter.getSpi().intValue(); } if (dataAfter.getAntiReplayWindow() != null) { entry.useAntiReplay = dataAfter.getAntiReplayWindow() > 0 ? BYTE_TRUE : BYTE_FALSE; } if (dataAfter.getSaMode() != null) { entry.isTunnel = Integer.valueOf(dataAfter.getSaMode().getIntValue()).byteValue(); } entry.isAdd = adding ? ByteDataTranslator.BYTE_TRUE : ByteDataTranslator.BYTE_FALSE; if (dataAfter.getEsp() != null) { entry.protocol = 1; fillEspAuthentication(entry, dataAfter.getEsp()); fillEspEncryption(entry, dataAfter.getEsp()); } else if (dataAfter.getAh() != null) { entry.protocol = 0;
import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecIkeGlobalConfAugmentation; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecSadEntriesAugmentation; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecSpdEntriesAugmentation; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; /** * Factory producing writers for IpSec plugin's data. */ public final class IpsecWriterFactory implements WriterFactory { private static final InstanceIdentifier<Ikev2> IKE2_ID = InstanceIdentifier.create(Ikev2.class); private static final InstanceIdentifier<Ipsec> IPSEC_ID = InstanceIdentifier.create(Ipsec.class); private static final InstanceIdentifier<Sad> SAD_ID = IPSEC_ID.child(Sad.class); private static final InstanceIdentifier<SadEntries> SAD_ENTRIES_ID = SAD_ID.child(SadEntries.class); private static final InstanceIdentifier<Spd> SPD_ID = IPSEC_ID.child(Spd.class); private final FutureJVppCore vppApi; private MultiNamingContext sadEntriesMapping; @Inject
public void init(@Nonnull final ModifiableWriterRegistryBuilder registry) { registry.subtreeAdd(Sets.newHashSet(InstanceIdentifier.create(SadEntries.class).child(SourceAddress.class), InstanceIdentifier.create(SadEntries.class).child(DestinationAddress.class), InstanceIdentifier.create(SadEntries.class).child(Ah.class) .child(org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ipsec.sa.ah.grouping.ah.authentication.algorithm.hmac.sha1._96.HmacSha196.class), InstanceIdentifier.create(SadEntries.class).child(Ah.class) .child(org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ipsec.sa.ah.grouping.ah.authentication.algorithm.hmac.md5._96.HmacMd596.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Authentication.class).child(HmacSha196.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Authentication.class).child(HmacMd596.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Encryption.class).child(Aes128Cbc.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Encryption.class).child(Aes192Cbc.class),
org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ikev2.policy.profile.grouping.Authentication.class), InstanceIdentifier.create(Policy.class).child(TrafficSelectors.class)), new GenericListWriter<>(IKE2_ID.child(Policy.class), new Ikev2PolicyCustomizer(vppApi))); registry.subtreeAdd(Sets.newHashSet(InstanceIdentifier.create(Identity.class).child(Local.class), InstanceIdentifier.create(Identity.class).child(Remote.class)), new GenericWriter<>(IKE2_ID.child(Policy.class).child(Identity.class), new Ikev2PolicyIdentityCustomizer(vppApi)));
*/ package io.fd.hc2vpp.ipsec; import com.google.inject.AbstractModule; import com.google.inject.Singleton; import com.google.inject.multibindings.Multibinder; import io.fd.hc2vpp.common.translate.util.MultiNamingContext; import io.fd.hc2vpp.ipsec.read.IpsecReaderFactory; import io.fd.hc2vpp.ipsec.write.IpsecWriterFactory; import io.fd.honeycomb.translate.read.ReaderFactory; import io.fd.honeycomb.translate.write.WriterFactory; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * Module class instantiating IpSec plugin components. */ public class IpsecModule extends AbstractModule { private static final Logger LOG = LoggerFactory.getLogger(IpsecModule.class); private static final String SAD_ENTRIES_MAPPING = "sad-entries-mapping"; @Override protected void configure() { LOG.info("Installing IPSec module"); bind(MultiNamingContext.class).toInstance(new MultiNamingContext(SAD_ENTRIES_MAPPING, 1)); LOG.info("Injecting writers factories"); final Multibinder<WriterFactory> writerFactoryBinder = Multibinder.newSetBinder(binder(), WriterFactory.class); writerFactoryBinder.addBinding().to(IpsecWriterFactory.class).in(Singleton.class);
super(vppApi); IpsecStateSpdsReplyDumpExecutor spdsExecutor = new IpsecStateSpdCustomizer.IpsecStateSpdsReplyDumpExecutor(vppApi); this.ipsecSpdsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSpdsDetailsReplyDump, Void>() .withExecutor(spdsExecutor) .acceptOnly(IpsecSpdsDetailsReplyDump.class) .build(); this.ipsecSpdDetailsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSpdDetailsReplyDump, Void>() .withExecutor( new IpsecStateSpdCustomizer.IpsecStateSpdDetailsDumpExecutor(vppApi, spdsExecutor)) .acceptOnly(IpsecSpdDetailsReplyDump.class) .build();
public void init(@Nonnull final ModifiableWriterRegistryBuilder registry) { InstanceIdentifier<Policer> IID = InstanceIdentifier.create(Policer.class); registry.subtreeAdd( Sets.newHashSet(IID.child(ConformAction.class), IID.child(ExceedAction.class), IID.child(ViolateAction.class)), new GenericListWriter<>(POLICER_IID, new PolicerCustomizer(vppApi, policerContext), new PolicerValidator(policerContext)));
* Copyright (c) 2019 PANTHEON.tech. * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at: * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package io.fd.hc2vpp.l3.write.ipv4; import static com.google.common.base.Preconditions.checkNotNull; import io.fd.hc2vpp.common.translate.util.NamingContext; import io.fd.honeycomb.translate.write.DataValidationFailedException; import io.fd.honeycomb.translate.write.Validator; import io.fd.honeycomb.translate.write.WriteContext; import javax.annotation.Nonnull;
*/ public static final class StatsConnectionInfo { public final long queueAddress; public final int clientIndex; public final int status; // FIXME throw exception instead public final int pid; public StatsConnectionInfo(long queueAddress, int clientIndex, int status, int pid) { this.queueAddress = queueAddress; this.clientIndex = clientIndex; this.status = status; this.pid = pid; } } private static native StatsConnectionInfo statsConnect(String clientName); private static native void statsDisconnect(); }
public void onInterfaceStatisticsDetails(final io.fd.jvpp.stats.dto.InterfaceStatisticsDetails reply) { io.fd.jvpp.stats.callback.InterfaceStatisticsDetailsCallback callback; final int replyId = reply.context; if (LOG.isLoggable(java.util.logging.Level.FINE)) { LOG.fine(String.format("Received InterfaceStatisticsDetails event message: %s", reply)); } synchronized (requests) { callback = (io.fd.jvpp.stats.callback.InterfaceStatisticsDetailsCallback) requests.remove(replyId); } if (callback != null) { callback.onInterfaceStatisticsDetails(reply); } } }
* * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package io.fd.jvpp.stats.dto; /** * <p>This class represents request DTO. */ public final class InterfaceStatisticsDump implements io.fd.jvpp.dto.JVppDump { @Override @io.fd.jvpp.coverity.SuppressFBWarnings("UWF_UNWRITTEN_PUBLIC_OR_PROTECTED_FIELD") public int hashCode() { return java.util.Objects.hash(); } @Override public boolean equals(final Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } return true; } @Override public String toString() { return "InterfaceStatisticsDump{}"; } @Override
} synchronized(requests) { CompletableFuture<? extends JVppReply<?>> replyFuture = requests.get(contextId); if (replyFuture == null) { // reply not received yet, put new future to map replyDumpFuture = new CompletableDumpFuture<>(contextId, emptyReplyDump); requests.put(contextId, replyDumpFuture); } else { // reply already received, save existing future replyDumpFuture = (CompletableDumpFuture<DUMP>) replyFuture; } } synchronized (requests) { // reply already received, complete future replyDumpFuture.complete(replyDumpFuture.getReplyDump()); requests.remove(contextId); } // TODO in case of timeouts/missing replies, requests from the map are not removed // consider adding cancel method, that would remove requests from the map and cancel // associated replyCompletableFuture return replyDumpFuture; } catch (VppInvocationException ex) { final CompletableFuture<DUMP> replyCompletableFuture = new CompletableFuture<>(); replyCompletableFuture.completeExceptionally(ex); return replyCompletableFuture; } }
.get(replyId); if (completableFuture == null) { // reply received before writer created future, // create new future, and put into map to notify sender that reply is already received, // following details replies will add information to this future completableFuture = new io.fd.jvpp.stats.future.AbstractFutureJVppInvoker.CompletableDumpFuture<>(replyId, new InterfaceStatisticsDetailsReplyDump()); requests.put(replyId, completableFuture); } completableFuture.getReplyDump().interfaceStatisticsDetails = reply; } } }
public InterfaceStatisticsCustomizer(final NamingContext ifcNamingCtx, final FutureJVppStatsFacade jvppStats, final InterfaceStatisticsCollectionManager statisticsManager) { this.ifcNamingCtx = checkNotNull(ifcNamingCtx, "Naming context should not be null"); this.jvppStats = checkNotNull(jvppStats, "JVpp Stats facade should not be null"); this.statisticsManager = checkNotNull(statisticsManager, "Statistics Manager should not be null");
.setInMulticastPkts(new Counter64(BigInteger.valueOf(detail.inMulticastPkts))) .setInBroadcastPkts(new Counter64(BigInteger.valueOf(detail.inBroadcastPkts))) .setInErrors(new Counter32(new Long(detail.inErrors))); } } } @Override public void merge(@Nonnull final Builder<? extends DataObject> builder, @Nonnull final Statistics statistics) { ((InterfaceBuilder) builder).setStatistics(statistics); } private InterfaceStatisticsDetails getStatisticsDump(InstanceIdentifier<Statistics> id) throws ReadFailedException { LOG.debug("Sending InterfaceStatisticsDump request..."); final InterfaceStatisticsDump request = new InterfaceStatisticsDump(); final Future<InterfaceStatisticsDetailsReplyDump> replyFuture = jvppStats.interfaceStatisticsDump(request).toCompletableFuture(); final InterfaceStatisticsDetailsReplyDump reply; try { reply = replyFuture.get(); } catch (Exception e) { throw new ReadFailedException(id, e); } if (reply == null || reply.interfaceStatisticsDetails == null) { throw new ReadFailedException(id, new IllegalStateException("Received null response for empty dump: " + reply)); } return reply.interfaceStatisticsDetails; } }
public L2Validator(final NamingContext interfaceContext, final NamingContext bridgeDomainContext) { checkNotNull(interfaceContext, "interfaceContext should not be null"); checkNotNull(bridgeDomainContext, "bridgeDomainContext should not be null");
public SubInterfaceL2Validator(final NamingContext interfaceContext, final NamingContext bridgeDomainContext) { checkNotNull(interfaceContext, "interfaceContext should not be null"); checkNotNull(bridgeDomainContext, "bridgeDomainContext should not be null");
public VxlanValidator(@Nonnull final NamingContext interfaceNamingContext, @Nonnull final DisabledInterfacesManager interfaceDisableContext) { checkNotNull(interfaceNamingContext, "interfaceContext should not be null"); checkNotNull(disabledInterfacesManager, "disabledInterfacesManager should not be null");
private void validateVxlan(final Vxlan data) { checkNotNull(data.getSrc(), "Source cannot be null"); checkNotNull(data.getDst(), "Destination cannot be null"); if (data.getSrc().getIpv4AddressNoZone() == null) { checkArgument(data.getDst().getIpv4AddressNoZone() == null, "Inconsistent ip addresses: %s, %s", data.getSrc(), data.getDst()); } else { checkArgument(data.getDst().getIpv6AddressNoZone() == null, "Inconsistent ip addresses: %s, %s", data.getSrc(), data.getDst()); } checkArgument(data.getEncapVrfId() != null && data.getEncapVrfId().getValue() != null, "encap-vrf-id is mandatory but was not given"); checkNotNull(data.getVni(), "VNI cannot be null");
public String getProjectName() { return mProjectName;
public String getProjectID() { return mProjectID;
public String getProjectPath() { return mProjectPath;
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * */ import javax.annotation.PostConstruct; import org.eclipse.jface.viewers.TreeViewer; import org.eclipse.swt.SWT; import org.eclipse.swt.layout.FormAttachment; import org.eclipse.swt.layout.FormData; import org.eclipse.swt.layout.FormLayout; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Tree; public class SceneGraphPart { @PostConstruct public void createComposite(Composite parent) { TizenPathDialog.VerifyTizenPath(parent.getShell(), false); parent.setLayout(new FormLayout()); TreeViewer treeViewer = new TreeViewer(parent, SWT.BORDER); Tree tree = treeViewer.getTree(); FormData fd_tree = new FormData(); fd_tree.bottom = new FormAttachment(100, -10); fd_tree.right = new FormAttachment(100, -5); fd_tree.top = new FormAttachment(0, 5);
* See the License for the specific language governing permissions and * limitations under the License. * */ package com.ibm.disni.nvmef; import java.io.IOException; import java.net.URI; import java.nio.ByteBuffer; import com.ibm.disni.DiSNIEndpoint; import com.ibm.disni.nvmef.spdk.*; public class NvmeEndpoint implements DiSNIEndpoint { private final NvmeEndpointGroup group; private NvmeQueuePair queuePair; private NvmeNamespace namespace; private NvmeController controller; private volatile boolean open; private NvmeControllerOptions controllerOptions; public NvmeEndpoint(NvmeEndpointGroup group, NvmfConnection newConnection) { this.group = group; this.queuePair = null; this.namespace = null; this.open = newConnection != null; } //rdma://<host>:<port> //nvmef:://<host>:<port>/controller/namespace" public synchronized void connect(URI uri) throws IOException { if (open){ return; } NvmeResourceIdentifier nvmeResource = NvmeResourceIdentifier.parse(uri); NvmeTransportId transportId = nvmeResource.toTransportId(); this.controller = group.probe(transportId, nvmeResource.getController());
return namespace; } NvmeQueuePair getQueuePair() { return queuePair; } public boolean isOpen() { return open; } public synchronized void close() throws IOException, InterruptedException { queuePair.free(); open = false; } public synchronized int processCompletions(long[] completed) throws IOException { return queuePair.processCompletions(completed); } public int getSectorSize() { return namespace.getSectorSize(); } public long getNamespaceSize() { return namespace.getSize(); } public int getMaxTransferSize() { return namespace.getMaxIOTransferSize(); } public int getIOQueueSize() { return controllerOptions.getIOQueueSize(); } public void keepAlive() throws IOException { controller.keepAlive(); } }
this.open = false; } //rdma://<host>:<port> //nvmef:://<host>:<port>/controller/namespace" public synchronized void connect(URI uri) throws IOException { if (open){ return; } NvmeResourceIdentifier nvmeResource = NvmeResourceIdentifier.parse(uri); NvmeTransportId transportId = nvmeResource.toTransportId(); NvmeController nvmecontroller = group.probe(transportId, nvmeResource.getController()); this.namespace = nvmecontroller.getNamespace(nvmeResource.getNamespace()); this.queuePair = nvmecontroller.allocQueuePair(); this.open = true; this.controllerOptions = controller.getOptions(); } private enum Operation { READ, WRITE } private NvmeCommand op(Operation op, ByteBuffer buffer, long linearBlockAddress) throws IOException { if (open){ throw new IOException("endpoint is closed"); } if (buffer.remaining() % namespace.getSectorSize() != 0){ throw new IOException("Remaining buffer a multiple of sector size"); } IOCompletion completion = new IOCompletion(); return new NvmeCommand(this, buffer, linearBlockAddress, completion, op == Operation.WRITE); }
kage com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonIgnore; public class Camera { public int getId() { return mId; } public void setId(int id) { mId = id; } @Override public String toString() { return "Camera " + mId; } public double getFov() { return mFov; } public void setFov(double fov) { mFov = fov; } public double getNear() { return mNear; } public void setNear(double near) { mNear = near; } public double getFar() { return mFar; } public void setFar(double far) { mFar = far; } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } private double mFov; private double mNear; private double mFar;
} public ArrayList<Mesh> getMeshes() { return mMeshes; } public void setMeshes(ArrayList<Mesh> meshes) { mMeshes = meshes; } public ArrayList<Material> getMaterials() { return mMaterials; } public void setMaterials(ArrayList<Material> materials) { mMaterials = materials; } public ArrayList<Shader> getShaders() { return mShaders; } public void setShaders(ArrayList<Shader> shaders) { mShaders = shaders; } public ArrayList<Environment> getEnvironments() { return mEnvironments; } public void setEnvironments(ArrayList<Environment> environments) { mEnvironments = environments; } public void setNodeParents() { for (Node n : mNodes) { for (Integer i : n.getChildIds()) { mNodes.get(i.intValue()).setParent(n); } } } public void setIds() { int id = 1; for (Scene s : mScenes) { s.setId(id); ++id; }
kage com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Environment { public String getSpecularPath() { return mSpecularPath; } public void setSpecularPath(String path) { mSpecularPath = path; } @JsonProperty("cubeDiffuse") public String getDiffusePath() { return mDiffusePath; } public void setDiffusePath(String path) { mDiffusePath = path; } private String mSpecularPath; private String mDiffusePath; }
public void setMatrix(double[] data) { mMatrix = MatrixHelper.createMatrix(data);
kage com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Asset { public String getVersion() { return mVersion; } public void setVersion(String version) { mVersion = version; } private String mVersion; }
} public double getNear() { return mNear; } public void setNear(double near) { mNear = near; } public double getFar() { return mFar; } public void setFar(double far) { mFar = far; } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } private double mFov; @JsonProperty("near") private double mNear; @JsonProperty("far") private double mFar; @JsonProperty("matrix") private double[] mMatrix = MatrixHelper.createMatrix(); @JsonIgnore private int mId; }
if (rootId != null) { Node n = getNodes().get(rootId.intValue()); n.collect(this, "", map); } } return map; } public List<Node> getNodeChildren(Node n) { ArrayList<Node> kids = new ArrayList<Node>(); for (Integer i : n.getChildIds()) { kids.add(getNodes().get(i.intValue())); } return kids; } @JsonIgnoreProperties(ignoreUnknown = true) private Asset mAsset = new Asset(); @JsonProperty("scene") private int mDefaultSceneId = 0; @JsonProperty("scenes") private ArrayList<Scene> mScenes = new ArrayList<Scene>(); @JsonProperty("nodes") private ArrayList<Node> mNodes = new ArrayList<Node>(); @JsonProperty("cameras") private ArrayList<Camera> mCameras = new ArrayList<Camera>(); @JsonProperty("skybox") private Skybox mSkybox; @JsonProperty("meshes") private ArrayList<Mesh> mMeshes = new ArrayList<Mesh>();
} @JsonSetter("nodes") public void setNodes(ArrayList<Integer> nodes) { if (nodes.size() != 1) { throw new IllegalArgumentException("Scene.nodes must be an array of a single node index. Sorry about that."); } mRootId = nodes.get(0).intValue(); } @JsonGetter("nodes") public ArrayList<Integer> getNodes() { ArrayList<Integer> nodes = new ArrayList<Integer>(); nodes.add(new Integer(mRootId)); return nodes; } private int mId = -1; @JsonIgnore private boolean mIsOrphan = false; @JsonIgnore // custom setter / getter provided -- json representation is an array of a // single integer element. private Integer mRootId = -1; }
} } else { throw new IllegalArgumentException("Unknown type: " + value.getClass().getName()); } } @JsonAnyGetter public Map<String, Object> get() { Map<String, Object> values = new TreeMap<String, Object>(); for (Entry<String, Uniform> u : mUniforms.entrySet()) { values.put(u.getKey(), u.getValue().getValue()); } return values; } private String mVertexPath; @JsonProperty("fragment") private String mFragmentPath; @JsonProperty("renderMode") private int mRenderMode; @JsonIgnore // custom any getter / setter provided - uniforms may be arbitrary sibling // elements to vertex path / fragment path / render mode. private Map<String, Uniform> mUniforms; }
kage com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Skybox { public String getTexture() { return mTexture; } public void setTexture(String mTexture) { this.mTexture = mTexture; } private String mTexture; }
* * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * */ public class ModelExporter { private static boolean sInitialised = false; public static void initialise() { System.loadLibrary("model-exporter-jni"); } /** * @brief Performs model export, loading a .dae file, and writing .bin and * .dli files. * @param inputFile - path to the .dae file to process. Required. * @param outputName - the name and path to save the .dli and .bin files to. * Optional. Will use the input path and name if omitted.
* See the License for the specific language governing permissions and * limitations under the License. * */ public class ModelExporter { static { System.loadLibrary("model-exporter-jni"); } /** * @brief Performs model export, loading a .dae file, and writing .bin and * .dli files. * @param inputPath - path and name of the .dae file to process. Required. * @param outputPath - path (incl. name) to save the .dli and .bin files to. * Optional. Will use the input path and name if omitted. * @return 0 on success, 1 on failure. */ public static native int nativeExport(String inputPath, String outputPath); /** * @brief Performs model conversion, loading a .dae file, and converting * it to the DLI format. In case of success, the dli and binary * contents can be retrieved by calling nativeGetDli/BinContents(). * @param inputFile - path to the .dae file to process. Required.
import com.fasterxml.jackson.annotation.JsonIgnore; import com.samsung.dali.modelconverter.data.document.property.Property; public class Camera implements Property.Provider { @JsonIgnore public int getId() { return mId; } public void setId(int id) { mId = id; } @Override public String toString() { return "Camera " + mId; } public double getFov() { return mFov; } public void setFov(Number fov) { mFov = fov.doubleValue(); } public double getNear() { return mNear; } public void setNear(Number near) { mNear = near.doubleValue(); } public double getFar() { return mFar; } public void setFar(Number far) { mFar = far.doubleValue(); } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } @Override
for (int i = 0; i < 3; ++i) { matrix[12 + i] = translation[i]; } } public static double[] getRotation(double[] matrix) { double[] rotation = new double[] { Math.atan2(matrix[6], matrix[10]), Math.atan2(-matrix[2], Math.sqrt(matrix[6] * matrix[6] + matrix[10] * matrix[10])), Math.atan2(matrix[1], matrix[0]) }; return rotation; } public static double[] getScale(double[] matrix) { double[] scale = new double[] { getColumnMagnitude(matrix, 0), getColumnMagnitude(matrix, 1), getColumnMagnitude(matrix, 2) }; return scale; } public static void setScale(double[] scale, double[] matrix) { double[] scaleCurr = getScale(matrix); for (int i = 0; i < 3; ++i) { scale[i] /= scaleCurr[i]; }
} public static SceneGraphPart getSceneGraphPart() { if (SceneGraphPart.sActiveInstance == null) { createPart("com.samsung.dali.modelconverter.part.scenegraph"); assert SceneGraphPart.sActiveInstance != null; } return SceneGraphPart.sActiveInstance; } public static NodePropertiesPart getNodePropertiesPart() { if (NodePropertiesPart.sActiveInstance == null) { createPart("com.samsung.dali.modelconverter.part.nodeproperties"); assert NodePropertiesPart.sActiveInstance != null; } return NodePropertiesPart.sActiveInstance; } static void createPart(String id) { Bundle bundle = FrameworkUtil.getBundle(EPartService.class); BundleContext bundleContext = bundle.getBundleContext(); IEclipseContext eclipseContext = EclipseContextFactory.getServiceContext(bundleContext); EPartService partService = (EPartService)eclipseContext.get(EPartService.class); partService.showPart(id, PartState.CREATE); } }
public void createComposite(Composite parent) { parent.setLayout(new GridLayout(1, false)); mParent = parent; resetProperties(); sActiveInstance = this;
public void populate(SceneGraphContentProvider provider, SceneGraphSelectionChangedListener selectionChangedListener) { mTree.removeAll(); if(mSelectionChangedListener != null) { mTreeViewer.removeSelectionChangedListener(mSelectionChangedListener); } mTreeViewer.addSelectionChangedListener(selectionChangedListener); mTreeViewer.setContentProvider(provider); mTreeViewer.setInput(provider.getDocument()); mTreeViewer.refresh();
GridData gd_mOptions = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1); gd_mOptions.widthHint = 240; mOptions.setLayoutData(gd_mOptions); } public IdPropertyWidget setRange(Collection<?> values) { mOptions.removeAll(); for(Object o: values) { mOptions.add(o.toString()); } return this; } public IdPropertyWidget setWritable(boolean isWritable) { mOptions.setEnabled(isWritable); return this; } public IdPropertyWidget setSelection(int i) { mOptions.select(i); mOptions.update(); return this; } private Combo mOptions; }
kage com.samsung.dali.modelconverter.view.widgets; import org.eclipse.swt.SWT; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Text; /* * A widget for a property whose value can be presented as a Text box. */ public class TextPropertyWidget extends PropertyWidgetBase { public TextPropertyWidget(Composite parent, int style) { super(parent, style); mText = new Text(parent, SWT.BORDER); GridData gd_mText = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1); gd_mText.widthHint = 200; mText.setLayoutData(gd_mText); } public TextPropertyWidget setWritable(boolean isWritable) { mText.setEnabled(isWritable); return this; } public TextPropertyWidget setValue(String value) { mText.setText(value); return this; } private Text mText; }
mRx.setText(df.format(rotation[0])); mRy.setText(df.format(rotation[1])); mRz.setText(df.format(rotation[2])); return this; } public TransformPropertyWidget setWritable(boolean isWritable) { mTx.setEnabled(isWritable); mTy.setEnabled(isWritable); mTz.setEnabled(isWritable); mSx.setEnabled(isWritable); mSy.setEnabled(isWritable); mSz.setEnabled(isWritable); mRx.setEnabled(isWritable); mRy.setEnabled(isWritable); mRz.setEnabled(isWritable); return this; } private Text mTx; private Text mTy; private Text mTz; private Text mSx; private Text mSy; private Text mSz; private Text mRx; private Text mRy; private Text mRz; }
public class Document { static public Document fromDli(String dli) throws JsonParseException, JsonMappingException, IOException { ObjectMapper mapper = new ObjectMapper(); mapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); Document d = mapper.readValue(dli, Document.class); // TODO: the following could perhaps be on an option to fromDli(). d.setNodeParents(); d.setIds(); d.organizeOrphans(); return d; } public String toDliString() throws JsonProcessingException { ObjectMapper mapper = new ObjectMapper(); DefaultPrettyPrinter.Indenter indenter = new DefaultIndenter(" ", DefaultIndenter.SYS_LF); DefaultPrettyPrinter printer = new DefaultPrettyPrinter(); printer.indentObjectsWith(indenter); return mapper.writer(printer).writeValueAsString(this); } public Asset getAsset() { return mAsset; } public void setAsset(Asset asset) { mAsset = asset; } @JsonProperty("scene") public int getDefaultSceneId() { return mDefaultSceneId; } public void setDefaultSceneId(int defaultSceneId) { mDefaultSceneId = defaultSceneId;
public static void execute(Shell shell, List<String> outProfiles) { assert outProfiles != null; OutputPart op = GlobalParts.getOutputPart(); LoggingProcessRunner lpr = LoggingProcessRunner.create(shell.getDisplay(), op.getText()); @Override public void parseLine(String line) { if (mCare) { if (!line.isEmpty()) { int iSpace = line.indexOf(' '); if (iSpace != -1) { line = line.substring(0, iSpace); } outProfiles.add(line); } } else { mCare = line.startsWith("[Profile Name]"); } } private boolean mCare = false; }).run();
kage com.samsung.dali.modelconverter.controller; import java.util.ArrayList; import org.eclipse.jface.viewers.ITreeContentProvider; import com.samsung.dali.modelconverter.data.document.Document; /* * Provides descriptions of a given list of resources. */ public class ResourceContentProvider implements ITreeContentProvider { public ResourceContentProvider(Document doc, Class<?> type) { mDocument = doc; mType = type; } public Object getDocument() { return mDocument; } /* * Get the top level nodes from an element, which should only be the Document * that the provider was created with. The nodes are meshes. */ @Override public Object[] getElements(Object inputElement) { assert inputElement == mDocument; ArrayList<Object> kids = new ArrayList<Object>(); return kids.toArray(); } @Override public Object[] getChildren(Object parentElement) { return null; } @Override public Object getParent(Object element) { return null; } @Override public boolean hasChildren(Object element) { return false; } private Document mDocument;
import org.eclipse.jface.viewers.ITreeContentProvider; import com.samsung.dali.modelconverter.data.document.Document; /* * Provides descriptions of the meshes. */ public class ResourceContentProvider implements ITreeContentProvider { public ResourceContentProvider(Document doc, Class<?> type) { mDocument = doc; mType = type; } public Object getDocument() { return mDocument; } /* * Return the list of resources. */ @Override public Object[] getElements(Object inputElement) { assert inputElement == mDocument; ArrayList<Object> kids = new ArrayList<Object>(); return kids.toArray(); } @Override public Object[] getChildren(Object parentElement) { return null; } @Override public Object getParent(Object element) { return null; } @Override public boolean hasChildren(Object element) { return false; } private Document mDocument; private Class<?> mType; }
* See the License for the specific language governing permissions and * limitations under the License. * */ import javax.annotation.PostConstruct; import org.eclipse.jface.viewers.ISelectionChangedListener; import org.eclipse.jface.viewers.TreeViewer; import org.eclipse.swt.SWT; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Tree; import com.samsung.dali.modelconverter.controller.PropertyProviderSelectionChangedListener; import org.eclipse.jface.viewers.ITreeContentProvider; public class AnimationPart { public static final String sId = "com.samsung.dali.modelconverter.part.animations"; @PostConstruct public void createComposite(Composite parent) { mTreeViewer = new TreeViewer(parent, SWT.BORDER); mTree = mTreeViewer.getTree(); } public void populate(ResourceContentProvider<Animation> provider, PropertyProviderSelectionChangedListener listener) { mTree.removeAll(); if (mSelectionChangedListener != null) { mTreeViewer.removeSelectionChangedListener(mSelectionChangedListener); } mTreeViewer.addSelectionChangedListener(listener); mTreeViewer.setContentProvider(provider); mTreeViewer.setInput(null); mTreeViewer.refresh();
public void populate(ITreeContentProvider provider, PropertyProviderSelectionChangedListener listener) { mTree.removeAll(); if (mSelectionChangedListener != null) { mTreeViewer.removeSelectionChangedListener(mSelectionChangedListener); } mTreeViewer.addSelectionChangedListener(listener); mTreeViewer.setContentProvider(provider); mTreeViewer.setInput(null); mTreeViewer.refresh();
mAttributes = a; } public String getAttributeFlags() { String flags = ""; if (mIndices != null) { flags += "I"; } if (mUvs != null) { flags += "U"; } if (mNormals != null) { flags += "N"; } if (mTangents != null) { flags += "T"; } if (mBitangents != null) { flags += "B"; } return flags; } public BufferRef getIndices() { return mIndices; } @JsonSetter("indices") public void setIndices(BufferRef br) { mIndices = br; } @JsonGetter("positions") public BufferRef getPositions() { return mPositions; } @JsonSetter("positions") public void setPositions(BufferRef br) { mPositions = br; } @JsonGetter("normals") public BufferRef getNormals() { return mNormals; } @JsonSetter("normals") public void setNormals(BufferRef br) {
public void provideProperties(Document context, Property.IReceiver receiver) { try { for( int index = 0; index < mTextures.length; index++ ) { receiver.register("Texture" + (index+1), new Property(this, "TextureArray", Property.Type.String, true, null, new ArrayElementSetter(index), String[].class)); } } catch (NoSuchFieldException | NoSuchMethodException e) { // TODO Auto-generated catch block e.printStackTrace(); }
Collection<?> values = property.getRange(); try { switch (property.getType()) { case Integer: { // TODO: enable editing Integer number = 0; Object object = property.get(); if( null != object ) { number = (Integer)object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false) .setValue(Integer.toString( number )).setName(name); break; } case Number: { // TODO: enable editing String string = ""; Object object = property.get(); if( null != object ) { number = (Double)object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false) .setValue(Double.toString( number )).setName(name); break; } case String: { // TODO: enable editing String string = ""; Object object = property.get(); if( null != object ) { string = (String)object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false)
String issuanceProtCertNick = cmd.getOptionValue("n"); String output = cmd.getOptionValue("o"); try { CryptoManager.initialize(databaseDir); CryptoManager manager = CryptoManager.getInstance(); CryptoToken token = CryptoUtil.getKeyStorageToken(tokenName); tokenName = token.getName(); manager.setThreadToken(token); Password password = new Password(tokenPassword.toCharArray()); token.login(password); X509Certificate issuanceProtCert = null; if (issuanceProtCertFilename != null) { if (verbose) System.out.println("Loading issuance protection certificate"); String encoded = new String(Files.readAllBytes(Paths.get(issuanceProtCertFilename))); byte[] issuanceProtCertData = Cert.parseCertificate(encoded); issuanceProtCert = manager.importCACertPackage(issuanceProtCertData); if (verbose) System.out.println("issuance protection certificate imported"); } else { // must have issuance protection cert nickname if file not provided
} } public void handleWriteEvent() throws IOException { for (int i = 0; i < maxBatchIoOps; i++) { final NetlinkRequest request = writeQueue.poll(); if (request == null) break; final int ret = processWriteToChannel(request); if (ret <= 0) { if (ret < 0) { log.warn("NETLINK write() error: {}", CLibrary.strerror(Native.getLastError())); } break; } } } private int processWriteToChannel(final NetlinkRequest request) { if (request == null) return 0; ByteBuffer outBuf = request.releaseRequestPayload(); if (outBuf == null) return 0; int seq = writeSeqToNetlinkRequest(request, outBuf); if (request.hasCallback()) { pendingRequests.put(seq, request); } log.trace("Sending message for id {}", seq); int bytes = 0; try { bytes = channel.write(outBuf); if (request.hasCallback()) expirationQueue.add(request);
wrList_recv.add(recvWR); //it's important to post those receive operations before connecting //otherwise the server may issue a send operation and which cannot be received //this class wraps soem of the RDMA data operations VerbsTools commRdma = new VerbsTools(context, compChannel, qp, cq); commRdma.initSGRecv(wrList_recv); //now let's connect to the server RdmaConnParam connParam = new RdmaConnParam(); connParam.setRetry_count((byte) 2); ret = idPriv.connect(connParam); if (ret < 0){ System.out.println("VerbsClient::connect failed"); return; } //wait until we are really connected cmEvent = cmChannel.getCmEvent(-1); if (cmEvent == null){ System.out.println("VerbsClient::cmEvent null"); return; } else if (cmEvent.getEvent() != RdmaCmEvent.EventType.RDMA_CM_EVENT_ESTABLISHED .ordinal()) {
RdmaCmId connId = cmEvent.getConnIdPriv(); if (connId == null){ System.out.println("VerbsServer::connId null"); return; } //get the device context of the new connection, typically the same as with the server id IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } //create a new protection domain, we will use the pd later when registering memory IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } //the comp channel is used to get CQ notifications IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; }
if (qp == null){ System.out.println("VerbsServer::qp null"); return; } int buffercount = 3; int buffersize = 100; ByteBuffer buffers[] = new ByteBuffer[buffercount]; IbvMr mrlist[] = new IbvMr[buffercount]; int access = IbvMr.IBV_ACCESS_LOCAL_WRITE | IbvMr.IBV_ACCESS_REMOTE_WRITE | IbvMr.IBV_ACCESS_REMOTE_READ; RdmaConnParam connParam = new RdmaConnParam(); connParam.setRetry_count((byte) 2); //once the client id is set up, accept the connection ret = connId.accept(connParam); if (ret < 0){ System.out.println("VerbsServer::accept failed"); return; } //wait until the connection is officially switched into established mode cmEvent = cmChannel.getCmEvent(-1); if (cmEvent.getEvent() != RdmaCmEvent.EventType.RDMA_CM_EVENT_ESTABLISHED .ordinal()) { System.out.println("VerbsServer::wrong event received: " + cmEvent.getEvent()); return; }
System.out.println("VerbsServer::connId null"); return; } //get the device context of the new connection, typically the same as with the server id IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } //create a new protection domain, we will use the pd later when registering memory IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } //the comp channel is used to get CQ notifications IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; } //create a completion queue IbvCQ cq = context.createCQ(compChannel, 50, 0);
return; } //get the device context of the new connection, typically the same as with the server id IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } //create a new protection domain, we will use the pd later when registering memory IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } //the comp channel is used to get CQ notifications IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; } //create a completion queue IbvCQ cq = context.createCQ(compChannel, 50, 0); if (cq == null){
// have a chance to capture user identification info if (issuerANY != null) { try { byte[] issuerBytes = issuerANY.getEncoded(); X500Name issuerName = new X500Name(issuerBytes); CMS.debug(method + "revRequest issuer name = " + issuerName.toString()); // capture issuer principal to be checked against // cert issuer principal later in CMCOutputTemplate auditContext.put(SessionContext.CMC_ISSUER_PRINCIPAL, issuerName); } catch (Exception e) { CMS.debug(method + "failed getting issuer from RevokeRequest:" + e.toString()); } } //authToken.set("uid", uid); //authToken.set("userid", userid); } } } } } else { CMS.debug(method + "numReqs not 0, assume enrollment request"); // enrollment request // reset value of auditReqType auditReqType = SIGNED_AUDIT_ENROLLMENT_REQUEST_TYPE; X509CertInfo[] certInfoArray = new X509CertInfo[numReqs]; String[] reqIdArray = new String[numReqs];
encSafeContents.addElement(safeBag); } public ASN1Value create_EPKI_with_PBE_SHA1_DES3_CBC(CryptoToken token, PrivateKey privateKey, Password password) throws Exception { // The salt size and number of iterations are selected to match pk12util. byte[] salt = new byte[16]; random.nextBytes(salt); return EncryptedPrivateKeyInfo.createPBE( PBEAlgorithm.PBE_SHA1_DES3_CBC, password, salt, 100000, // iterations new PasswordConverter(), privateKey, token); } public ASN1Value create_EPKI_with_PBE_PKCS5_PBES2(CryptoToken token, PrivateKey privateKey, Password password) throws Exception { CryptoStore store = token.getCryptoStore(); byte[] bytes = store.getEncryptedPrivateKeyInfo( // For compatibility with OpenSSL and NSS >= 3.31, // do not BMPString-encode the passphrase when using // non-PKCS #12 PBE scheme such as PKCS #5 PBES2. // // The resulting PKCS #12 is not compatible with // NSS < 3.31. null, // password converter password,
public void performCollectionAndGetResult(String requestId, JsonObject feature, Handler<AsyncResult<CollectorJobResult>> resultHandler) { dcs.performCollectionAndGetResult(requestId, feature, res -> resultHandler.handle(checkForError(res)));
kage info.pascalkrause.vertx.datacollector.client.error; import info.pascalkrause.vertx.datacollector.client.error.DataCollectorError; public class QueueLimitReached extends DataCollectorError { private static final long serialVersionUID = 1L; }
kage info.pascalkrause.vertx.datacollector.job; import io.vertx.core.AsyncResult; import io.vertx.core.Future; import io.vertx.core.Handler; import io.vertx.core.json.JsonObject; /** * A generic interface which must be implemented to run the collection job inside the CollectorJobExecutor worker pool. */ public interface CollectorJob { /** * This method should be used to create a Future that contains the collection logic. The Future will be executed in * a worker thread pool, which allows blocking operations inside the Future. * * @param requestId A request id to identify the collection request. * @param feature A JSON object to pass attributes and properties which are needed for the collection process. * @return A Handler with the Future which contains the collection logic. */ public Handler<Future<CollectorJobResult>> collect(String requestId, JsonObject feature); /** * This method will be called after the {@link #collect(String, JsonObject)} and returns a Future which can be used
* to do some post collect stuff like rough parsing or saving the result into a database. The Future will be * executed in a worker thread pool, which allows blocking operations inside. * * @param result The {@link CollectorJobResult} from the previous called {@link #collect(String, JsonObject)} * method. * @return A Handler with the Future which contains the post collection logic. */ public Handler<Future<CollectorJobResult>> postCollectAction(AsyncResult<CollectorJobResult> result); }
} public Optional<Error> getError() { return Error.fromJson(data.getJsonObject(KEY_ERROR)); } public JsonObject toJson() { return data; } @Override public int hashCode() { return data.hashCode(); } @Override public boolean equals(Object obj) { if ((obj instanceof CollectorJobResult) && (hashCode() == obj.hashCode())) { return true; } return false; } @Override public String toString() { return data.toString(); } }
public static final String METRIC_TOTAL_JOBS_COUNT = "totalJobsCount"; private final Counter totalJobsCounter; public static final String METRIC_TOTAL_JOBS_FAILED = "totalJobsFailed"; private final Counter totalJobsFailed; public static final String METRIC_TOTAL_JOBS_SUCCEEDED = "totalJobsSucceeded"; private final Counter totalJobsSucceeded; public static final String METRIC_TOTAL_JOBS_EXCEPTION = "totalJobsException"; private final Counter totalJobsException; private final MetricRegistry metricRegistry; private final Map<String, AtomicLong> qualityMap = new ConcurrentHashMap<>(); private final Map<String, AtomicLong> errorMap = new ConcurrentHashMap<>(); private Map<String, Object> sortDescendingAndSlice(Map<String, AtomicLong> unsorted, long maxEntries) { return unsorted.entrySet().stream().map(e -> new SimpleEntry<String, Long>(e.getKey(), e.getValue().get())) .sorted(Map.Entry.comparingByValue()).limit(maxEntries).collect(Collectors.toMap(e -> e.getKey(), e -> e.getValue(), (oldValue, newValue) -> oldValue, LinkedHashMap::new)); }
public void registerQueueMetrics(AtomicInteger currentQueueSize, int queueSize) { metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_MAX_SIZE), (Gauge<Integer>) () -> queueSize); metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_FREE), (Gauge<Integer>) () -> queueSize - currentQueueSize.get()); metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_OCCUPIED), (Gauge<Integer>) () -> currentQueueSize.get());
public void registerTotalMetrics(AsyncResult<CollectorJobResult> postResult) { totalJobsCounter.inc(); if (postResult.succeeded()) { final Optional<Error> e = postResult.result().getError(); if (e.isPresent()) { totalJobsFailed.inc(); addOrIncrease(errorMap, e.get().getName()); } else { totalJobsSucceeded.inc(); addOrIncrease(qualityMap, postResult.result().getQuality()); } } else { totalJobsException.inc(); }
metricFactory.addTotalMetricsCounters(postResult); } resultHandler.handle(postResult); }); }); } else { resultHandler.handle(Future.failedFuture(ERROR_QUEUE_LIMIT_REACHED)); } } @Override public void performCollection(String requestId, JsonObject feature, Handler<AsyncResult<Void>> resultHandler) { performCollectionAndGetResult(requestId, feature, res -> { resultHandler.handle(res.failed() ? Future.failedFuture(res.cause()) : Future.succeededFuture()); }); } /** * Visible for Testing */ public JsonObject getMetricsSnapshot() { return Objects.isNull(metricFactory) ? new JsonObject().put("Error", "Metrics are not enabled") : metricFactory.getMetricsSnapshot(); } @Override public void getMetricsSnapshot(Handler<AsyncResult<JsonObject>> resultHandler) { resultHandler.handle(Future.succeededFuture(getMetricsSnapshot())); } @Override public void close() { // Needed for generated Client } }
private CollectorJobResult generateResult(String requestId, CollectorJobResult.Error error) { return new CollectorJobResult(requestId, "test-src", "test-quality", "test-created", new JsonObject(), error);
} catch (final InterruptedException e) { e.printStackTrace(); } } if (Objects.nonNull(stopper) && feature.containsKey(KEY_STOP)) { stopper.await(TimeUnit.SECONDS.toMillis(1)); } if (feature.containsKey(KEY_UNHANDLED_EXCEPTION)) { throw new RuntimeException("Some unhandled excpetion"); } else if (feature.containsKey(KEY_HANDLED_EXCEPTION)) { fut.fail(new RuntimeException("Some handled exception")); } else { fut.complete(jobResult); } }; } }
import java.util.Collection; import java.util.logging.Logger; import javax.net.ssl.X509TrustManager; import org.mozilla.jss.CryptoManager; import org.mozilla.jss.CryptoManager.NotInitializedException; import netscape.security.x509.X509CertImpl; public class PKITrustManager implements X509TrustManager { final static Logger logger = Logger.getLogger(PKITrustManager.class.getName()); @Override public void checkClientTrusted(X509Certificate[] certs, String authType) throws CertificateException { logger.fine("PKITrustManager: checkClientTrusted(" + authType + "):"); // sort cert chain from root to leaf certChain = CryptoUtil.sortCertificateChain(certChain); for (X509Certificate cert : certChain) { logger.debug("PKITrustManager: - " + cert.getSubjectDN()); } try { CryptoManager manager = CryptoManager.getInstance(); X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLClient)) { throw new CertificateException("Missing SSLClient certificate usage: " + cert.getSubjectDN()); } logger.fine("PKITrustManager: certificate is valid"); } catch (CertificateException e) { throw e; } catch (Exception e) {
} try { CryptoManager manager = CryptoManager.getInstance(); X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLClient)) { throw new CertificateException("Missing SSLClient certificate usage: " + cert.getSubjectDN()); } logger.fine("PKITrustManager: certificate is valid"); } catch (CertificateException e) { throw e; } catch (Exception e) { throw new CertificateException(e); } } @Override public void checkServerTrusted(X509Certificate[] certChain, String authType) throws CertificateException { logger.fine("PKITrustManager: checkServerTrusted(" + authType + "):"); for (X509Certificate cert : certs) { logger.fine("PKITrustManager: - " + cert.getSubjectDN()); } try { CryptoManager manager = CryptoManager.getInstance(); X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLServer)) { throw new CertificateException("Missing SSLServer certificate usage: " + cert.getSubjectDN()); }
} } if (aid != null && adn != null) { throw new Exception("--issuer-id and --issuer-dn options are mutually exclusive"); } MainCLI mainCLI = (MainCLI)parent.getParent(); File certDatabase = mainCLI.certDatabase; String password = mainCLI.config.getCertPassword(); if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)) { csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else{ throw new Exception("Invalid algorithm specified."); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate
} MainCLI mainCLI = (MainCLI)parent.getParent(); File certDatabase = mainCLI.certDatabase; String password = mainCLI.config.getCertPassword(); if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)) { csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else{ throw new Exception("Invalid algorithm specified."); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate mainCLI.init(); client = getClient(); String encoded; if (transportCertFilename == null) {
if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else { throw new Exception("Invalid algorithm: " + algorithm); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate mainCLI.init(); client = getClient(); String encoded; if (transportCertFilename == null) { SystemCertClient certClient = new SystemCertClient(client, "ca"); encoded = certClient.getTransportCert().getEncoded(); } else { encoded = new String(Files.readAllBytes(Paths.get(transportCertFilename)));
CACertCLI.printCertRequestInfos(infos); } public String generatePkcs10Request( File certDatabase, String password, String algorithm, String length, String subjectDN ) throws Exception { File csrFile = File.createTempFile("pki-client-cert-request-", ".csr", certDatabase); csrFile.deleteOnExit(); String[] commands = { "/usr/bin/PKCS10Client", "-d", certDatabase.getAbsolutePath(), "-p", password, "-a", algorithm, lenOrCurve, "" + length, "-o", csrFile.getAbsolutePath(), "-n", subjectDN }; try { runExternal(commands); } catch (Exception e) { throw new Exception("CSR generation failed", e); } if (verbose) { System.out.println("CSR generated: " + csrFile); } return new String(Files.readAllBytes(csrFile.toPath())); } public String generateCrmfRequest( X509Certificate transportCert, String subjectDN, boolean attributeEncoding, String algorithm, int length, String curve, boolean sslECDH, boolean temporary,
int sd_ee_port = config.getInteger("securitydomain.httpseeport", -1); MultivaluedMap<String, String> content = new MultivaluedHashMap<String, String>(); content.putSingle("requestor_name", sysType + "-" + machineName + "-" + securePort); logger.debug("configRemoteCert: subsystemCert: setting profileId to: " + profileId); String actualProfileId = request.getSystemCertProfileID(certTag, profileId); logger.debug("configRemoteCert: subsystemCert: calculated profileId: " + actualProfileId); content.putSingle("profileId", actualProfileId); content.putSingle("cert_request_type", "pkcs10"); content.putSingle("cert_request", b64Request); content.putSingle("xmlOutput", "true"); content.putSingle("sessionID", session_id); cert = CertUtil.createRemoteCert(sd_hostname, sd_ee_port, content, response); if (cert == null) { throw new IOException("Error: remote certificate is null"); } } else if (v.equals("sdca")) { String ca_hostname = ""; int ca_port = -1; try {
try (InputStream in = new BufferedInputStream(getInputStream())) { // TODO: expose XStream the driver from XStream if (nullOut) { return ((XStream2) xs).unmarshal(DEFAULT_DRIVER.createReader(in), o, null, true); } else { return xs.unmarshal(DEFAULT_DRIVER.createReader(in), o); } } catch (RuntimeException | Error e) { throw new IOException("Unable to read "+file,e); } } public void write( Object o ) throws IOException { mkdirs(); AtomicFileWriter w = new AtomicFileWriter(file); try { w.write("<?xml version='1.1' encoding='UTF-8'?>\n"); beingWritten.put(o, null); writing.set(file); try { xs.toXML(o, w); } finally { beingWritten.remove(o);
* from CA's internal certificate db based on serial number to revoke shared * secret based revocation * Note that unlike the shared token attribute for enrollment, the metaInfo * attribute for shared token in revocatoiin is not configurable. * * Note: caller should clear the memory for the returned token * after each use */ public char[] getSharedToken(BigInteger serial) throws EBaseException { String method = "SharedSecret.getSharedToken(BigInteger serial): "; String msg = ""; if (serial == null) { throw new EBaseException(method + "paramster serial cannot be null"); } CMS.debug(method + serial.toString()); ICertRecord record = null; try { record = certRepository.readCertificateRecord(serial); } catch (EBaseException ee) { CMS.debug(method + "Exception: " + ee.toString()); msg = method + "cert record not found"; CMS.debug(msg); throw ee; } MetaInfo metaInfo = (MetaInfo) record.get(ICertRecord.ATTR_META_INFO); if (metaInfo == null) { msg = "cert record metaInfo not found"; CMS.debug(method + msg);
* * But we do still want to check that the input looks something * like a profile configuration. So we use java.util.Properties * to do that. */ public static void checkConfiguration( byte[] in, boolean requireProfileId, boolean requireDisabled) throws PKIException { Properties p = new Properties(); try { p.load(new ByteArrayInputStream(in)); } catch (IOException e) { throw new PKIException("Failed to parse profile configuration", e); } if (requireProfileId && p.getProperty("profileId") == null) throw new PKIException("Missing profileId property in profile data."); String enabled = p.getProperty("enable"); if (requireDisabled && Boolean.valueOf(enabled)) { throw new PKIException("Cannot edit profile. Profile must be disabled."); } } public static void saveEnrollmentTemplateToFile(String filename, CertEnrollmentRequest request) throws JAXBException, FileNotFoundException { JAXBContext context = JAXBContext.newInstance(CertEnrollmentRequest.class); Marshaller marshaller = context.createMarshaller();
* easier to tell if a config name represents a plugin permission or not. Note "-" isn't clear * enough for this purpose since some core permissions, e.g. "label-", also contain "-". */ private static final Pattern PLUGIN_PERMISSION_NAME_IN_CONFIG_PATTERN = Pattern.compile("^plugin-" + PLUGIN_NAME_PATTERN_STRING + "-[a-zA-Z]+$"); /** Name pattern for a Gerrit plugin. */ private static final Pattern PLUGIN_NAME_PATTERN = Pattern.compile("^" + PLUGIN_NAME_PATTERN_STRING + "$"); private final DynamicMap<CapabilityDefinition> capabilityDefinitions; private final DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions; @Inject private PluginPermissionsUtil( DynamicMap<CapabilityDefinition> capabilityDefinitions, DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions) { this.capabilityDefinitions = capabilityDefinitions; this.pluginProjectPermissionDefinitions = pluginProjectPermissionDefinitions; } /** * Collects all the plugin declared capabilities. *
PluginPermissionsUtil( DynamicMap<CapabilityDefinition> capabilityDefinitions, DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions) { this.capabilityDefinitions = capabilityDefinitions; this.pluginProjectPermissionDefinitions = pluginProjectPermissionDefinitions;
} public boolean testOrFalse(ProjectPermission perm) { try { return test(perm); } catch (PermissionBackendException e) { logger.warn("Cannot test " + perm + "; assuming false", e); return false; } } public BooleanCondition testCond(ProjectPermission perm) { return new PermissionBackendCondition.ForProject(this, perm); } /** * @return a partition of the provided refs that are visible to the user that this instance is * scoped to. * @throws PermissionBackendException if failure consulting backend configuration. */ public abstract Map<String, Ref> filter( Map<String, Ref> refs, Repository repo, RefFilterOptions opts) throws PermissionBackendException; } /** Options for filtering refs using {@link ForProject}. */ @AutoValue public abstract static class RefFilterOptions { /** Remove all NoteDb refs (refs/changes/*, refs/users/*, edit refs) from the result. */ public abstract boolean filterMeta(); /** Separately add reachable tags. */ public abstract boolean filterTagsSeparately(); public abstract Builder toBuilder();
public Map<String, Ref> filter(Map<String, Ref> refs, Repository repo, RefFilterOptions opts) throws PermissionBackendException { if (refFilter == null) { refFilter = refFilterFactory.create(ProjectControl.this); } return refFilter.filter(refs, repo, opts); } private boolean can(CoreOrPluginProjectPermission perm) throws PermissionBackendException { if (perm instanceof ProjectPermission) { return can((ProjectPermission) perm); } else if (perm instanceof PluginProjectPermission) { // TODO(xchangcheng): implement for plugin defined project permissions. return false; } throw new PermissionBackendException(perm.describeForException() + " unsupported"); } private boolean can(ProjectPermission perm) throws PermissionBackendException { switch (perm) { case ACCESS: return user.isInternalUser() || isOwner() || canPerformOnAnyRef(Permission.READ); case READ: return allRefsAreVisible(Collections.emptySet()); case CREATE_REF: return canAddRefs(); case CREATE_TAG_REF: return canAddTagRefs(); case CREATE_CHANGE: return canCreateChanges();
private final Timer1<String> latencyPerPush; private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("number of changes uploaded in a single push.").setCumulative(), Field.ofEnum( ResultChangeIds.Key.class, "type", "type of update (replace, create, autoclose)")); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description("average processing delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate());
Field.ofEnum( ResultChangeIds.Key.class, "type", "type of update (replace, create, autoclose)")); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description("average delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("processing delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate()); } } private final Metrics metrics; private final ReceiveCommits receiveCommits; private final ResultChangeIds resultChangeIds; private final PermissionBackend.ForProject perm; private final ReceivePack receivePack; private final ExecutorService executor; private final RequestScopePropagator scopePropagator;
metricMaker.newTimer( "receivecommits/latency", new Description("average delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose, normal)")); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate()); } } private final Metrics metrics; private final ReceiveCommits receiveCommits; private final ResultChangeIds resultChangeIds; private final PermissionBackend.ForProject perm; private final ReceivePack receivePack; private final ExecutorService executor; private final RequestScopePropagator scopePropagator; private final ReceiveConfig receiveConfig; private final ContributorAgreementsChecker contributorAgreements; private final long timeoutMillis; private final ProjectState projectState; private final IdentifiedUser user;
List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); metrics.changes.record(ResultChangeIds.Key.CREATED, created.size()); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(ResultChangeIds.Key.REPLACED, replaced.size()); totalChanges += replaced.size() + created.size(); } else { List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED); if (!autoclosed.isEmpty()) { metrics.changes.record(ResultChangeIds.Key.AUTOCLOSED, autoclosed.size()); totalChanges += autoclosed.size(); } } String pushType; if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; } else if (totalChanges > 0) { pushType = ResultChangeIds.Key.AUTOCLOSED.name(); } else { pushType = "NORMAL"; } if (totalChanges > 0) { metrics.latencyPerChange.record(pushType, deltaNanos / totalChanges, NANOSECONDS); } metrics.latencyPerPush.record(pushType, deltaNanos, NANOSECONDS);
Optional<Checker> checker = getChecker(checkerUuid); checkState(checker.isPresent(), "Tried to get a non-existing test checker as CheckerInfo"); return checkerJson.format(checker.get()); } public TestCheckerUpdate.Builder forUpdate() { return TestCheckerUpdate.builder(this::updateChecker); } private void updateChecker(TestCheckerUpdate testCheckerUpdate) throws Exception { CheckerUpdate checkerUpdate = toCheckerUpdate(testCheckerUpdate); checkersUpdate.updateChecker(checkerUuid, checkerUpdate); if (testCheckerUpdate.forceInvalidConfig()) { try (Repository repo = repoManager.openRepository(allProjectsName)) { new TestRepository<>(repo) .branch(CheckerRef.refsCheckers(checkerUuid)) .commit() .add(CheckerConfig.CHECKER_CONFIG_FILE, "invalid-config") .create(); } } } private CheckerUpdate toCheckerUpdate(TestCheckerUpdate checkerUpdate) { CheckerUpdate.Builder builder = CheckerUpdate.builder(); checkerUpdate.name().ifPresent(builder::setName); checkerUpdate.description().ifPresent(builder::setDescription); checkerUpdate.url().ifPresent(builder::setUrl);
import com.google.gerrit.reviewdb.client.Project; import java.util.Arrays; import java.util.Optional; import java.util.stream.Stream; @AutoValue public abstract class TestCheckerUpdate { public abstract Optional<String> name(); public abstract Optional<String> description(); public abstract Optional<String> url(); public abstract Optional<Project.NameKey> repository(); public abstract Optional<CheckerStatus> status(); public abstract Optional<ImmutableSortedSet<BlockingCondition>> blockingConditions(); public abstract Optional<String> query(); public abstract boolean forceInvalidConfig(); abstract ThrowingConsumer<TestCheckerUpdate> checkerUpdater(); public static Builder builder(ThrowingConsumer<TestCheckerUpdate> checkerUpdater) { return new AutoValue_TestCheckerUpdate.Builder().checkerUpdater(checkerUpdater); } @AutoValue.Builder public abstract static class Builder { public abstract Builder name(String name); public abstract Builder description(String description); public Builder clearDescription() { return description(""); } public abstract Builder url(String url); public Builder clearUrl() { return url(""); } public abstract Builder repository(Project.NameKey repository);
checkOperations.newCheck(key).setState(CheckState.RUNNING).upsert(); checkerOperations.checker(checkerUuid).forUpdate().forceInvalidConfig().update(); exception.expect(RestApiException.class); exception.expectMessage("Cannot retrieve checker " + checkerUuid); checksApiFactory.revision(patchSetId).id(checkerUuid.toString()).get(); } @Test public void getNonExistingCheckFails() throws Exception { exception.expect(ResourceNotFoundException.class); exception.expectMessage("Not found: non-existing"); checksApiFactory.revision(patchSetId).id("non-existing").get(); } @Test public void getNonExistingCheckWithInvalidUuidFails() throws Exception { exception.expect(ResourceNotFoundException.class); exception.expectMessage("Not found: n0n-e#isting"); checksApiFactory.revision(patchSetId).id("n0n-e#isting").get(); } }
parseTag(commit); if (branch == null) { branch = parseBranch(commit); } PatchSet.Id psId = parsePatchSetId(commit); PatchSetState psState = parsePatchSetState(commit); if (psState != null) { if (!patchSetStates.containsKey(psId)) { patchSetStates.put(psId, psState); } if (psState == PatchSetState.DELETED) { deletedPatchSets.add(psId); } } Account.Id accountId = parseIdent(commit); if (accountId != null) { ownerId = accountId; } Account.Id realAccountId = parseRealAccountId(commit, accountId); if (changeId == null) { changeId = parseChangeId(commit); } String currSubject = parseSubject(commit); if (currSubject != null) { if (subject == null) { subject = currSubject; } originalSubject = currSubject; } parseChangeMessage(psId, accountId, realAccountId, commit, ts); if (topic == null) { topic = parseTopic(commit); }
} @Override public void flush() { receiveCommits.getMessageSender().flush(); } } } @Singleton private static class Metrics { private final Histogram1<ResultChangeIds.Key> changes; private final Timer1<String> latencyPerChange; private final Timer1<String> latencyPerPush; private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("number of changes uploaded in a single push.").setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description( "processing delay per push, averaged over the updated changes in a push.") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency",
private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("number of changes uploaded in a single push.").setCumulative(), Field.ofEnum( ResultChangeIds.Key.class, "type", "type of push (replace, create, autoclose)")); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description( "Processing delay per push divided by the number of changes in said push. (Only includes pushes which contain changes.)") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("processing delay for a processing single push") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose, normal)")); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate());
private static ProjectAccessInput createAccessInput(String accessSection, String permissionName) { ProjectAccessInput accessInput = new ProjectAccessInput(); PermissionRuleInfo ruleInfo = new PermissionRuleInfo(PermissionRuleInfo.Action.ALLOW, false); PermissionInfo email = new PermissionInfo(null, null); email.rules = ImmutableMap.of(SystemGroupBackend.REGISTERED_USERS.get(), ruleInfo); AccessSectionInfo accessSectionInfo = new AccessSectionInfo(); accessSectionInfo.permissions = ImmutableMap.of(permissionNameInConfig, email); accessInput.add = ImmutableMap.of(accessSection, accessSectionInfo); return accessInput;
public void isPluginPermissionReturnsTrueForValidName() { // "-" is allowed for a plugin name. Here "foo-a" should be the name of the plugin. ImmutableList<String> validPluginPermissions = ImmutableList.of("plugin-foo-a", "plugin-foo-a-b"); for (String permission : validPluginPermissions) { assertThat(isPluginPermission(permission)) .named("valid plugin permission: %s", permission) .isTrue(); }
public void isPluginPermissionReturnsFalseForInvalidName() { ImmutableList<String> inValidPluginPermissions = ImmutableList.of( "create", "label-Code-Review", "plugin-foo", "plugin-foo", "plugin-foo-a-", "plugin-foo-a1"); for (String permission : validPluginPermissions) { assertThat(isPluginPermission(permission)) .named("invalid plugin permission: %s", permission) .isFalse(); }
public void isPluginPermissionReturnsFalseForInvalidName() { ImmutableList<String> inValidPluginPermissions = ImmutableList.of( "create", "label-Code-Review", "plugin-foo", "plugin-foo", "plugin-foo-a-", "plugin-foo-a1"); for (String permission : validPluginPermissions) { assertThat(isPluginPermission(permission)) .named("invalid plugin permission: %s", permission) .isFalse(); }
.annotatedWith(Exports.named(TEST_PLUGIN_CAPABILITY)) .toInstance( new CapabilityDefinition() { @Override public String getDescription() { return "A Plugin Capability"; } }); bind(PluginProjectPermissionDefinition.class) .annotatedWith(Exports.named(TEST_PLUGIN_PROJECT_PERMISSION)) .toInstance( new PluginProjectPermissionDefinition() { @Override public String getDescription() { return "A Plugin Project Permission"; } }); } }; } @Test public void setAccessAddPluginCapabilitySucceed() throws Exception { String pluginCapability = TEST_PLUGIN_NAME + "-" + TEST_PLUGIN_CAPABILITY; ProjectAccessInput accessInput = createAccessInput(AccessSection.GLOBAL_CAPABILITIES, pluginCapability); ProjectAccessInfo projectAccessInfo = gApi.projects().name(allProjects.get()).access(accessInput); Set<String> capabilities = projectAccessInfo.local.get(AccessSection.GLOBAL_CAPABILITIES).permissions.keySet(); assertThat(capabilities).contains(pluginCapability); // Verifies the plugin defined capability could be listed. assertThat(pluginPermissionsUtil.collectPluginCapabilities()).containsKey(pluginCapability); } @Test
} @Override public void addRelatedLink(String issueKey, URL relatedUrl, String description) throws IOException { addComment( issueKey, "Related URL: " + createLinkForWebui(relatedUrl.toExternalForm(), description)); } @Override public void addValueToField(String issueKey, String value, String fieldId) throws IOException { execute( () -> { log.debug("Adding value {} to field {} on issue {}", value, fieldId, issueKey); jiraClient.addValueToField(itsServerInfo, issueKey, value, fieldId); // No value to return return null; }); } @Override public void performAction(String issueKey, String actionName) throws IOException { execute( () -> { log.debug("Performing action {} on issue {}", actionName, issueKey); doPerformAction(issueKey, actionName); return issueKey; }); } private void doPerformAction(String issueKey, String actionName) throws IOException, InvalidTransitionException { log.debug("Trying to perform action: {} on issue {}", actionName, issueKey);
private final Checks checks; private final Provider<ChecksUpdate> checksUpdate; private final CheckJson checkJson; @Inject PostCheck( Checks checks, @UserInitiated Provider<ChecksUpdate> checksUpdate, CheckJson checkJson) { this.checks = checks; this.checksUpdate = checksUpdate; this.checkJson = checkJson; } @Override public CheckInfo apply(RevisionResource rsrc, CheckInput input) throws OrmException, IOException, RestApiException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { throw new BadRequestException("checkerUuid is required"); } CheckKey key = CheckKey.create( rsrc.getProject(), rsrc.getPatchSet().getId(), CheckerUuid.parse(input.checkerUuid)); Optional<Check> check = checks.getCheck(key); if (!check.isPresent()) { if (input.state == null) { throw new BadRequestException("state is required on creation"); } Check updatedCheck = checksUpdate.get().createCheck(key, toCheckUpdate(input));
import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.plugins.checks.PostCheck; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; @Singleton public class UpdateCheck implements RestModifyView<CheckResource, CheckInput> { private final PostCheck postCheck; @Inject UpdateCheck(PostCheck postCheck) { this.postCheck = postCheck; } @Override public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, OrmException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().toString(); } else if (!checkResource.getCheckerUuid().toString().equals(input.checkerUuid)) { throw new BadRequestException( String.format( "checkerUuid must either be null or the same as on the resource:\n" + "the check resource belongs to checker %s," + " but in the input checker %s was specified", checkResource.getCheckerUuid(), input.checkerUuid)); }
private static int getInt(Config cfg, String section, String name, int defaultValue) { try { return cfg.getInt(section, name, defaultValue); } catch (IllegalArgumentException e) { log.error("invalid value for {}; using default value {}", name, defaultValue); log.debug("Failed to retrieve integer value: {}", e.getMessage(), e); return defaultValue; }
for (String name : config.getNames(KAFKA_SECTION, section, true)) { if (name.startsWith(KAFKA_PROPERTY_PREFIX)) { Object value = config.getString(KAFKA_SECTION, subsectionName, name); String configProperty = name.replaceFirst(KAFKA_PROPERTY_PREFIX, ""); String propName = CaseFormat.LOWER_CAMEL .to(CaseFormat.LOWER_HYPHEN, configProperty) .replaceAll("-", "."); log.info("[{}] Setting kafka property: {} = {}", subsectionName, propName, value); target.put(propName, value); } } } } target.put( "bootstrap.servers", getString( config, KAFKA_SECTION, null, "bootstrapServers", DEFAULT_KAFKA_BOOTSTRAP_SERVERS));
private static boolean getBoolean( Config cfg, String section, String name, boolean defaultValue) { try { return cfg.getBoolean(section, name, defaultValue); } catch (IllegalArgumentException e) { log.error("invalid value for {}; using default value {}", name, defaultValue); log.debug("Failed to retrieve boolean value: {}", e.getMessage(), e); return defaultValue; }
import com.googlesource.gerrit.plugins.multisite.forwarder.ForwarderModule; import com.googlesource.gerrit.plugins.multisite.forwarder.broker.BrokerForwarderModule; import com.googlesource.gerrit.plugins.multisite.index.IndexModule; import com.googlesource.gerrit.plugins.multisite.kafka.consumer.KafkaConsumerModule; import com.googlesource.gerrit.plugins.multisite.kafka.router.ForwardedEventRouterModule; import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.FileReader; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Paths; import java.util.UUID; public class Module extends LifecycleModule { private static final Logger log = LoggerFactory.getLogger(Module.class); private final Configuration config; @Inject public Module(Configuration config) { this.config = config; } @Override protected void configure() { bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(MultiSiteLogFile.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); }
protected void configure() { listener().to(MultiSiteLogFile.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class);
// You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.broker.kafka; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.InstanceId; import com.googlesource.gerrit.plugins.multisite.broker.BrokerSession; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.UUID; import java.util.concurrent.ExecutionException; import java.util.concurrent.Future; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; public class KafkaSession implements BrokerSession { private final Configuration properties;
public void connect() { if (isOpen()) { LOGGER.debug("Already connected."); return; } multisiteLog.info("Connect to {}...", properties.getKafka().getBootstrapServers()); /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader(); producer = new KafkaProducer<>(properties.kafkaPublisher()); multisiteLog.info("Connection established.");
public void evict(CacheEntry entry) throws CacheNotFoundException { Cache<?, ?> cache = cacheMap.get(entry.getPluginName(), entry.getCacheName()); if (cache == null) { throw new CacheNotFoundException(entry.getPluginName(), entry.getCacheName()); } try { Context.setForwardedEvent(true); if (Constants.PROJECT_LIST.equals(entry.getCacheName())) { // One key is holding the list of projects cache.invalidateAll(); log.debug("Invalidated cache {}", entry.getCacheName()); } else { cache.invalidate(entry.getKey()); multisiteLog.debug("Invalidated cache {}[{}]", entry.getCacheName(), entry.getKey()); } } finally { Context.unsetForwardedEvent(); } } }
if (cache == null) { throw new CacheNotFoundException(entry.getPluginName(), entry.getCacheName()); } try { Context.setForwardedEvent(true); if (Constants.PROJECT_LIST.equals(entry.getCacheName())) { // One key is holding the list of projects cache.invalidateAll(); multisiteLog.debug("Invalidated cache {}", entry.getCacheName()); } else { cache.invalidate(entry.getKey()); log.debug("Invalidated cache {}[{}]", entry.getCacheName(), entry.getKey()); } } finally { Context.unsetForwardedEvent(); } } }
SourceAwareEventWrapper event = valueDeserializer.deserialize(consumerRecord.topic(), consumerRecord.value()); if (event.getHeader().getSourceInstanceId().equals(instanceId)) { multisiteLog.debug( "Dropping event {} produced by our instanceId {}", event.toString(), instanceId.toString()); droppedEventListeners.forEach(l -> l.onEventDropped(event)); } else { try { msgLog.info("Consuming event: Header[{}] Body[{}]", event.getHeader(), event.getBody()); eventRouter.route(event.getEventBody(gsonProvider)); } catch (IOException e) { multisiteLog.error( "Malformed event '{}': [Exception: {}]", event.getHeader().getEventType(), e); } catch (PermissionBackendException | OrmException e) { multisiteLog.error( "Cannot handle message {}: [Exception: {}]", event.getHeader().getEventType(), e); } } } catch (Exception e) { multisiteLog.error( "Malformed event '{}': [Exception: {}]", new String(consumerRecord.value()), e);
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. // Copyright (C) 2018 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software
private static String stripTrailingSlash(String name) { while (name.endsWith("/")) { name = name.substring(0, name.length() - 1); } return name;
private static String strip(String name) { projectName = ProjectUtil.stripGitSuffix(name); projectName = ProjectUtil.stripEndSlash(projectName); return projectName;
} @Test public void createProjectWithGitSuffix() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + ".git").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } @Test public void createProjectThatEndsWithSlash() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + "/").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } public void createProjectThatContainsSlash() throws Exception { String newProjectName = name("newProject/newProject");
assertHead(newProjectName, "refs/heads/master"); } public void createProjectThatEndsWithSlash() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + "/").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } @Test public void createProjectThatContainsSlash() throws Exception { String newProjectName = name("newProject/newProject"); ProjectInfo p = gApi.projects().create(newProjectName).get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } @Test public void createProjectWithProperties() throws Exception { String newProjectName = name("newProject");
adminSshSession.assertFailure(); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNull(); } @Test public void withDotGit() throws Exception { String newGroupName = "newGroup"; adminRestSession.put("/groups/" + newGroupName); String newProjectName = "newProject"; adminSshSession.exec( "gerrit create-project --branch master --owner " + newGroupName + " " + newProjectName + ".git"); adminSshSession.assertSuccess(); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertThat(projectState.getName()).isEqualTo(newProjectName); } @Test public void withEndSlash() throws Exception { String newGroupName = "newGroup"; adminRestSession.put("/groups/" + newGroupName); String newProjectName = "newProject"; adminSshSession.exec( "gerrit create-project --branch master --owner " + newGroupName + " " + newProjectName + "/"); adminSshSession.assertSuccess();
} @VisibleForTesting void setReportSyntaxError(boolean value) { reportSyntaxError = value; } int getMinOwnerVoteLevel(ProjectState projectState, ChangeData c) { if (projectState == null) { logger.atSevere().log("Null projectState for change %s", getChangeId(c)); return minOwnerVoteLevel; } return getPluginConfig(projectState).getInt(MIN_OWNER_VOTE_LEVEL, minOwnerVoteLevel); } }
protected Destination( Injector injector, RemoteSiteUser.Factory replicationUserFactory, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, GroupBackend groupBackend, ReplicationStateListener stateLog, GroupIncludeCache groupIncludeCache, DynamicItem<EventDispatcher> eventDispatcher) { config = cfg; this.eventDispatcher = eventDispatcher; gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.stateLog = stateLog; CurrentUser remoteUser; if (!cfg.getAuthGroupNames().isEmpty()) { ImmutableSet.Builder<AccountGroup.UUID> builder = ImmutableSet.builder(); for (String name : cfg.getAuthGroupNames()) { GroupReference g = GroupBackends.findExactSuggestion(groupBackend, name); if (g != null) { builder.add(g.getUUID()); addRecursiveParents(g.getUUID(), builder, groupIncludeCache); } else {
protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class); bind(SharedRefDatabase.class).to(InMemoryDfsRefDatabase.class);
private boolean isImmutableRef(String refName) { return refName.startsWith("refs/changes") && !refName.endsWith("/meta");
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.server.git.validators.RefOperationValidationListener; import com.google.inject.AbstractModule; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.NoOpDfsRefDatabase; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.SharedRefDatabase; public class ValidationModule extends AbstractModule { @Override protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class);
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import static com.google.common.truth.Truth.assertThat; import static org.hamcrest.CoreMatchers.nullValue; import static org.hamcrest.CoreMatchers.sameInstance; import static org.mockito.Mockito.any; import static org.mockito.Mockito.argThat; import static org.mockito.Mockito.doReturn; import static org.mockito.Mockito.doThrow; import static org.mockito.Mockito.eq; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.verifyZeroInteractions;
.when(dfsRefDatabase) .compareAndPut(any(), eq(null), any()); doThrow(new NullPointerException("newRef is null")) .when(dfsRefDatabase) .compareAndPut(any(), any(), eq(null)); doThrow(new NullPointerException("project name is null")) .when(dfsRefDatabase) .compareAndPut(eq(null), any(), any()); validator = new InSyncChangeValidator(dfsRefDatabase, repoManager); repoManager.createRepository(PROJECT_NAMEKEY); } @Test public void shouldNotVerifyStatusOfImmutablePatchSetRefs() throws Exception { testRefReceivedEvent.command = RECEIVE_COMMAND_CREATE_PATCHSET_REF; final List<ValidationMessage> validationMessages = validator.onRefOperation(testRefReceivedEvent); assertThat(validationMessages).isEmpty(); verifyZeroInteractions(dfsRefDatabase); } @Test public void shouldInsertNewRefInDfsDatabaseWhenHandlingRefCreationEvents() throws Exception { testRefReceivedEvent.command = RECEIVE_COMMAND_CREATE_REF;
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.common.flogger.FluentLogger; import com.google.gerrit.acceptance.LightweightPluginDaemonTest; import com.google.gerrit.acceptance.LogThreshold; import com.google.gerrit.acceptance.NoHttpd; import com.google.gerrit.acceptance.PushOneCommit; import com.google.gerrit.acceptance.TestPlugin; import com.google.inject.AbstractModule; import org.junit.Test; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin( name = "multi-site",
* Starts the fluent chain for querying or modifying a check. Please see the methods of {@link * PerCheckOperations} for details on possible operations. * * @param key key of the check * @return an aggregation of operations on a specific check */ PerCheckOperations check(CheckKey key); /** * Starts the fluent chain to create a check. The returned builder can be used to specify the * attributes of the new check. To create the check in the storage for real, {@link * TestCheckUpdate.Builder#upsert()} must be called. * * <p>Example: * * <pre> * checkOperations * .newCheck(checkKey) * .setState(CheckState.RUNNING) * .upsert(); * </pre> * * <p><strong>Note:</strong> If a check with the provided key already exists, the check creation * fails. * * @return a builder to create the new check */ TestCheckUpdate.Builder newCheck(CheckKey key);
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.server.notedb.NotesMigration; import com.google.inject.Inject; public class GerritNoteDbStatus implements NoteDbStatus { private final NotesMigration notesMigration; @Inject public GerritNoteDbStatus(NotesMigration notesMigration) { this.notesMigration = notesMigration; } @Override public boolean enabled() { return notesMigration.commitChangeWrites(); } }
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; /** Returns the status of changes migration. */ public interface NoteDbStatus { /** * Status of NoteDb migration. * * @return true if Gerrit has been migrated to NoteDb */ boolean enabled(); }
// Name of plugin and namespace. static final String PLUGIN_NAME = "find-owners"; static final String PROLOG_NAMESPACE = "find_owners"; private final PluginConfigFactory configFactory; // Global/plugin config parameters. private boolean addDebugMsg = false; private int minOwnerVoteLevel = 1; private int maxCacheAge = 0; private int maxCacheSize = 1000; private boolean reportSyntaxError = false; private boolean alwaysShowButton = false; private String ownersFileName = OWNERS; private static final FluentLogger logger = FluentLogger.forEnclosingClass(); Config(PluginConfigFactory configFactory) { this.configFactory = configFactory; if (configFactory == null) { // When called from integration tests. return; } PluginConfig gc = configFactory.getFromGerritConfig(PLUGIN_NAME); // Get config variables from the plugin section of gerrit.config addDebugMsg = gc.getBoolean(ADD_DEBUG_MSG, false); reportSyntaxError = gc.getBoolean(REPORT_SYNTAX_ERROR, false); alwaysShowButton = gc.getBoolean(ALWAYS_SHOW_BUTTON, false);
private final DestinationConfiguration config; private final DynamicItem<EventDispatcher> eventDispatcher; protected enum RetryReason { TRANSPORT_ERROR, COLLISION, REPOSITORY_MISSING; } public static class QueueInfo { public final Map<URIish, PushOne> pending; public final Map<URIish, PushOne> inFlight; public QueueInfo(Map<URIish, PushOne> pending, Map<URIish, PushOne> inFlight) { this.pending = ImmutableMap.copyOf(pending); this.inFlight = ImmutableMap.copyOf(inFlight); } } @Inject protected Destination( Injector injector, RemoteSiteUser.Factory replicationUserFactory, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, GroupBackend groupBackend, ReplicationStateListener stateLog, GroupIncludeCache groupIncludeCache, DynamicItem<EventDispatcher> eventDispatcher, @Assisted DestinationConfiguration cfg) { this.eventDispatcher = eventDispatcher; gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.stateLog = stateLog; config = cfg;
import com.googlesource.gerrit.plugins.multisite.forwarder.events.ChangeIndexEvent; import java.util.ArrayList; import java.util.List; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Before; import org.junit.Test; import org.testcontainers.containers.KafkaContainer; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin( name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.kafka.consumer.EventConsumerIT$KafkaTestContainerModule") public class EventConsumerIT extends LightweightPluginDaemonTest { private static final int QUEUE_POLL_TIMEOUT_MSECS = 30000; static { System.setProperty("gerrit.notedb", "READ_WRITE"); } public static class KafkaTestContainerModule extends LifecycleModule { public class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) { this.kafka = kafka; } @Override
super.setUpTestPlugin(); if (!notesMigration.commitChangeWrites()) { throw new IllegalStateException("NoteDb is mandatory for running the multi-site plugin"); } } @Test public void createChangeShouldPropagateChangeIndexAndRefUpdateStreamEvent() throws Exception { LinkedBlockingQueue<SourceAwareEventWrapper> droppedEventsQueue = captureDroppedEvents(); drainQueue(droppedEventsQueue); PushOneCommit.Result r = createChange(); Thread.sleep(2000L); ChangeData change = r.getChange(); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("change-index")) .collect(toSet())) .containsExactlyElementsIn( ImmutableList.of( createChangeIndexEvent( change.project().get(), change.getId().get(), getParentCommit(change)))); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("ref-updated")) .map(RefUpdatedEvent.class::cast) .map(e -> e.getRefName()) .collect(toSet())) .containsExactlyElementsIn(
.collect(toSet())) .containsExactlyElementsIn( ImmutableList.of( createChangeIndexEvent( change.project().get(), change.getId().get(), getParentCommit(change)))); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("ref-updated")) .map(RefUpdatedEvent.class::cast) .map(e -> e.getRefName()) .collect(toSet())) .containsAllOf(changeNotesRef, patchsetRef); PatchSetCreatedEvent patchSetCreated = createdChangeEvents .stream() .filter(e -> e.type.equals("patchset-created")) .map(PatchSetCreatedEvent.class::cast) .findFirst() .get(); PatchSetAttribute patchSetAttribute = patchSetCreated.patchSet.get(); PatchSet currentPatchSet = change.currentPatchSet(); assertThat(patchSetAttribute.number).isEqualTo(currentPatchSet.getPatchSetId()); assertThat(patchSetAttribute.revision).isEqualTo(currentPatchSet.getRevision().get()); assertThat(patchSetAttribute.ref).isEqualTo(currentPatchSet.getRefName()); } @Test
import com.google.inject.TypeLiteral; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.Module; import com.googlesource.gerrit.plugins.multisite.broker.GsonProvider; import com.googlesource.gerrit.plugins.multisite.forwarder.events.ChangeIndexEvent; import java.util.ArrayList; import java.util.List; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Before; import org.junit.Test; import org.testcontainers.containers.KafkaContainer; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin( name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.kafka.consumer.EventConsumerIT$KafkaTestContainerModule") public class EventConsumerIT extends LightweightPluginDaemonTest { private static final int QUEUE_POLL_TIMEOUT_MSECS = 30000; public static class KafkaTestContainerModule extends LifecycleModule { public class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) {
protected void configure() { if (!noteDb.enabled()) { throw new ProvisionException( "Gerrit is still running on ReviewDb: please migrate to NoteDb " + "and then reload the multi-site plugin."); } listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } install(new ValidationModule()); bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class);
import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.Singleton; import java.util.List; import java.util.stream.Stream; @Singleton public class PendingChecksImpl implements PendingChecks { private final Provider<ListPendingChecks> listPendingChecksProvider; @Inject PendingChecksImpl(Provider<ListPendingChecks> listPendingChecksProvider) { this.listPendingChecksProvider = listPendingChecksProvider; } @Override public List<PendingChecksInfo> list(String checkerUuidString, CheckState... checkStates) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setChecker(checkerUuid); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } } @Override
this.listPendingChecksProvider = listPendingChecksProvider; } @Override public List<PendingChecksInfo> list(String checkerUuidString, CheckState... checkStates) throws RestApiException { CheckerUuid checkerUuid = CheckerUuid.tryParse(checkerUuidString) .orElseThrow( () -> new BadRequestException( String.format("invalid checker UUID: %s", checkerUuidString))); try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setChecker(checkerUuid); Stream.of(checkStates).forEach(listPendingChecks::addState); return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } } @Override public List<PendingChecksInfo> listForScheme(String scheme, CheckState... checkStates) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setScheme(scheme); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); }
if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } } @Override public List<PendingChecksInfo> listForScheme(String scheme, CheckState... checkStates) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setScheme(scheme); Stream.of(checkStates).forEach(listPendingChecks::addState); return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks for scheme", e); } } }
// You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.its.jira; import static com.googlesource.gerrit.plugins.its.jira.JiraConfig.PROJECT_CONFIG_PASSWORD_KEY; import static com.googlesource.gerrit.plugins.its.jira.JiraConfig.PROJECT_CONFIG_URL_KEY; import static com.googlesource.gerrit.plugins.its.jira.JiraConfig.PROJECT_CONFIG_USERNAME_KEY; import com.google.gerrit.extensions.annotations.Exports; import com.google.gerrit.extensions.annotations.PluginName; import com.google.gerrit.server.config.PluginConfigFactory; import com.google.gerrit.server.config.ProjectConfigEntry; import com.google.inject.AbstractModule; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.its.base.ItsHookModule; import com.googlesource.gerrit.plugins.its.base.its.ItsConfig; import com.googlesource.gerrit.plugins.its.base.its.ItsFacade; import com.googlesource.gerrit.plugins.its.base.its.ItsFacadeFactory; import com.googlesource.gerrit.plugins.its.base.workflow.CustomAction;
String email = preferredEmails.get(owner); for (String path : result.owner2paths.get(owner)) { addOwnerPathPair(email, path); } } for (String glob : result.noParentGlobs) { add2dir2Globs(Util.getDirName(glob) + "/", glob); } if (config.getReportSyntaxError()) { Ordering.natural().sortedCopy(result.warnings).forEach(w -> logger.atWarning().log(w)); Ordering.natural().sortedCopy(result.errors).forEach(e -> logger.atSevere().log(e)); Ordering.natural().sortedCopy(result.warnings).forEach(w -> logger.atWarning().log(w)); }
private static void saveReadFile( Map<String, String> readFiles, String project, String file, String content) { if (readFiles != null) { readFiles.put(Parser.combine(project, file), content); }
private static void checkIncludeOrFile( List<CommitValidationMessage> messages, String path, int num, String line) { // TODO: Check if an included file exists and that it has valid syntax. // An included file could be a new file added by a CL and not in the repository yet add(messages, "unchecked: " + path + ":" + num + ": " + Parser.getIncludeOrFile(line), false);
private GitRepositoryManager repoManager; private String branch; // All owners files are read from the same branch. private IncludeStack stack; // a stack of including files. private List<String> logs; // Keeps debug/trace messages. private Map<String, Result> savedResults; // projectName:filePath => Parser.Result static class IncludeStack { Deque<String> projectName; // project/repository name of included file Deque<String> filePath; // absolute or relative path of included file Set<String> allFiles; // to detect recursive inclusion quickly IncludeStack(String project, String file) { projectName = new ArrayDeque<>(); filePath = new ArrayDeque<>(); allFiles = new HashSet<>(); push(project, file); } void push(String project, String file) { projectName.push(project); filePath.push(file); allFiles.add(project + ":" + file); } void pop() { allFiles.remove(currentProject() + ":" + currentFile()); projectName.pop(); filePath.pop(); }
void push(String project, String file) { projectName.push(project); filePath.push(file); allFiles.add(combine(project, file));
void pop() { allFiles.remove(combine(currentProject(), currentFile())); projectName.pop(); filePath.pop();
boolean contains(String project, String file) { return allFiles.contains(combine(project, file));
rp.sendError("internal error while processing changes"); // ReceiveCommits has tried its best to catch errors, so anything at this // point is very bad. for (ReceiveCommand c : commands) { if (c.getResult() == Result.NOT_ATTEMPTED) { c.setResult(Result.REJECTED_OTHER_REASON, "internal error"); } } } finally { w.sendMessages(); } long deltaNanos = System.nanoTime() - startNanos; int totalChanges = 0; PushType pushType; if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(pushType, created.size() + replaced.size()); totalChanges += replaced.size() + created.size(); } else { List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED); if (!autoclosed.isEmpty()) { pushType = ResultChangeIds.Key.AUTOCLOSED.name();
} finally { w.sendMessages(); } long deltaNanos = System.nanoTime() - startNanos; int totalChanges = 0; String pushType; if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(pushType, created.size() + replaced.size()); totalChanges = replaced.size() + created.size(); } else { List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED); if (!autoclosed.isEmpty()) { pushType = ResultChangeIds.Key.AUTOCLOSED.name(); metrics.changes.record(ResultChangeIds.Key.AUTOCLOSED.name(), autoclosed.size()); totalChanges += autoclosed.size(); } else { pushType = "NORMAL"; } } if (totalChanges > 0) { metrics.latencyPerChange.record(pushType, deltaNanos / totalChanges, NANOSECONDS); } metrics.latencyPerPush.record(pushType, deltaNanos, NANOSECONDS);
String patchsetRevision = change.currentPatchSet().getRevision().get(); String patchsetRef = change.currentPatchSet().getRefName(); Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue); assertThat(eventsByType.get("change-index")) .containsExactly(createChangeIndexEvent(project, changeNum, getParentCommit(change))); assertThat( eventsByType .get("ref-updated") .stream() .map(e -> ((RefUpdatedEvent) e).getRefName()) .collect(toSet())) .containsAllOf( changeNotesRef, patchsetRef); // 'refs/sequences/changes' not always updated thus not checked List<Event> patchSetCreatedEvents = eventsByType.get("patchset-created"); assertThat(patchSetCreatedEvents).hasSize(1); assertPatchSetAttributes( (PatchSetCreatedEvent) patchSetCreatedEvents.get(0), patchsetNum, patchsetRevision, patchsetRef); } private void assertPatchSetAttributes( PatchSetCreatedEvent patchSetCreated, int patchsetNum, String patchsetRevision, String patchsetRef) { PatchSetAttribute patchSetAttribute = patchSetCreated.patchSet.get(); assertThat(patchSetAttribute.number).isEqualTo(patchsetNum); assertThat(patchSetAttribute.revision).isEqualTo(patchsetRevision);
.collect(Collectors.groupingBy(e -> e.type)); } private List<Event> drainQueue(LinkedBlockingQueue<SourceAwareEventWrapper> queue) throws InterruptedException { GsonProvider gsonProvider = plugin.getSysInjector().getInstance(Key.get(GsonProvider.class)); SourceAwareEventWrapper event; List<Event> eventsList = new ArrayList<>(); while ((event = queue.poll(QUEUE_POLL_TIMEOUT_MSECS, TimeUnit.MILLISECONDS)) != null) { eventsList.add(event.getEventBody(gsonProvider)); } return eventsList; } }
private final CheckResource checkResource; @Inject CheckApiImpl(GetCheck getCheck, UpdateCheck updateCheck, @Assisted CheckResource checkResource) { this.getCheck = getCheck; this.updateCheck = updateCheck; this.checkResource = checkResource; } @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { try { Arrays.stream(options).forEach(getCheck::addOption); return getCheck.apply(checkResource); } catch (Exception e) { throw asRestApiException("Cannot retrieve check", e); } } @Override public CheckInfo update(CheckInput input) throws RestApiException { try { return updateCheck.apply(checkResource, input); } catch (Exception e) { throw asRestApiException("Cannot update check", e); } } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.client; import java.lang.reflect.InvocationTargetException; import java.util.EnumSet; /** Enum that can be expressed as a bitset in query parameters. */ public interface ListOption { int getValue(); static <T extends Enum<T> & ListOption> EnumSet<T> fromBits(Class<T> clazz, int v) { EnumSet<T> r = EnumSet.noneOf(clazz); T[] values; try { @SuppressWarnings("unchecked") O[] tmp = (O[]) clazz.getMethod("values").invoke(null); values = tmp; } catch (IllegalAccessException | NoSuchMethodException | InvocationTargetException e) { throw new IllegalStateException(e); } for (O o : values) { if ((v & (1 << o.getValue())) != 0) { r.add(o); v &= ~(1 << o.getValue()); }
import com.google.gerrit.server.git.PureRevertCache; import com.google.gerrit.server.notedb.ChangeNotes; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.InvalidObjectIdException; import org.eclipse.jgit.lib.ObjectId; @Singleton public class PureRevert { private final PureRevertCache pureRevertCache; @Inject PureRevert(PureRevertCache pureRevertCache) { this.pureRevertCache = pureRevertCache; } public boolean get(ChangeNotes notes, Optional<String> claimedOriginal) throws OrmException, IOException, BadRequestException, ResourceConflictException { PatchSet currentPatchSet = notes.getCurrentPatchSet(); if (currentPatchSet == null) { throw new ResourceConflictException("current revision is missing"); } if (claimedOriginal == null) { return new PureRevertInfo(pureRevertCache.isPureRevert(notes)); } ObjectId claimedOriginalObjectId; try { claimedOriginalObjectId = ObjectId.fromString(claimedOriginal); } catch (InvalidObjectIdException e) { throw new BadRequestException("invalid object ID"); }
PatchSet currentPatchSet = notes.getCurrentPatchSet(); if (currentPatchSet == null) { throw new ResourceConflictException("current revision is missing"); } if (claimedOriginal == null) { return new PureRevertInfo(pureRevertCache.isPureRevert(notes)); } ObjectId claimedOriginalObjectId; try { claimedOriginalObjectId = ObjectId.fromString(claimedOriginal); } catch (InvalidObjectIdException e) { throw new BadRequestException("invalid object ID"); } return pureRevertCache.isPureRevert( notes.getProjectName(), ObjectId.fromString(notes.getCurrentPatchSet().getRevision().get()), claimedOriginalObjectId); } }
import org.eclipse.jgit.diff.DiffFormatter; import org.eclipse.jgit.errors.InvalidObjectIdException; import org.eclipse.jgit.errors.MissingObjectException; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectInserter; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.merge.ThreeWayMerger; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; /** Computes and caches if a change is a pure revert of another change. */ @Singleton public class PureRevertCache { private static final String ID_CACHE = "pure_revert"; public static class Module extends CacheModule { @Override protected void configure() { persist(ID_CACHE, Cache.PureRevertKeyProto.class, Boolean.class) .maximumWeight(100) .loader(Loader.class) .version(1) .keySerializer(new ProtobufSerializer<>(Cache.PureRevertKeyProto.parser())) .valueSerializer(BooleanCacheSerializer.INSTANCE); } } private final LoadingCache<PureRevertKeyProto, Boolean> cache; private final PatchSetUtil psUtil; private final ChangeNotes.Factory notesFactory; @Inject PureRevertCache(
private final LoadingCache<PureRevertKeyProto, Boolean> cache; private final PatchSetUtil psUtil; private final ChangeNotes.Factory notesFactory; @Inject PureRevertCache( @Named(ID_CACHE) LoadingCache<PureRevertKeyProto, Boolean> cache, PatchSetUtil psUtil, ChangeNotes.Factory notesFactory) { this.cache = cache; this.psUtil = psUtil; this.notesFactory = notesFactory; } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of the change that is * referenced in {@link com.google.gerrit.reviewdb.client.Change#getRevertOf()}. * * @return {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * @throws IOException if there was a priblem with the storage layer * @throws OrmException if there was a priblem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ChangeNotes} */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException {
*/ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { if (claimedRevert.getChange().getRevertOf() == null) { throw new BadRequestException("revertOf not set"); } PatchSet ps = psUtil.current( notesFactory.createChecked( claimedRevert.getProjectName(), claimedRevert.getChange().getRevertOf())); return isPureRevert( claimedRevert.getProjectName(), ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(changeNotes.getCurrentPatchSet().getRevision().get())); } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * * @return {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * @throws IOException if there was a priblem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ObjectId}s */ public boolean isPureRevert(
ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(ps.getRevision().get())); } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * * @return {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * @throws IOException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ObjectId}s */ public boolean isPureRevert( Project.NameKey project, ObjectId claimedRevert, ObjectId claimedOriginal) throws IOException, BadRequestException { try { return cache.get(key(project, claimedRevert, claimedOriginal)); } catch (ExecutionException e) { Throwables.throwIfInstanceOf(e.getCause(), BadRequestException.class); throw new IOException(e); } } @VisibleForTesting static PureRevertKeyProto key(
Project.NameKey project = new Project.NameKey(key.getProject()); try (Repository repo = repoManager.openRepository(project); ObjectInserter oi = repo.newObjectInserter(); RevWalk rw = new RevWalk(repo)) { RevCommit claimedOriginalCommit; try { claimedOriginalCommit = rw.parseCommit(original); } catch (InvalidObjectIdException | MissingObjectException e) { throw new BadRequestException("invalid object ID"); } if (claimedOriginalCommit.getParentCount() == 0) { throw new BadRequestException("can't check against initial commit"); } RevCommit claimedRevertCommit = rw.parseCommit(revert); if (claimedRevertCommit.getParentCount() == 0) { return false; } // Rebase claimed revert onto claimed original ThreeWayMerger merger = mergeUtilFactory .create(projectCache.checkedGet(project)) .newThreeWayMerger(oi, repo.getConfig()); merger.setBase(claimedRevertCommit.getParent(0)); boolean success = merger.merge(claimedRevertCommit, claimedOriginalCommit); if (!success || merger.getResultTreeId() == null) { // Merge conflict during rebase return false; }
} starsOf = StarsOf.create(accountId, starredChangesUtil.getLabels(accountId, legacyId)); } } return starsOf.stars(); } /** * @return {@code null} if {@code revertOf} is {@code null}; true if the change is a pure revert; * false otherwise. */ @Nullable public Boolean isPureRevert() throws OrmException { if (change().getRevertOf() == null) { return null; } try { return pureRevert.get(notes(), Optional.empty()); } catch (IOException | BadRequestException | ResourceConflictException e) { throw new OrmException("could not compute pure revert", e); } } @Override public String toString() { MoreObjects.ToStringHelper h = MoreObjects.toStringHelper(this); if (change != null) { h.addValue(change); } else { h.addValue(legacyId); } return h.toString(); } public static class ChangedLines { public final int insertions; public final int deletions; public ChangedLines(int insertions, int deletions) {
public void serialization() { ObjectId revert = ObjectId.zeroId(); ObjectId original = ObjectId.fromString("deadbeefdeadbeefdeadbeefdeadbeefdeadbeef"); byte[] serializedRevert = new byte[20]; byte[] serializedOriginal = new byte[20]; revert.copyRawTo(serializedRevert, 0); original.copyRawTo(serializedOriginal, 0); Cache.PureRevertKeyProto key = PureRevertCache.key(new Project.NameKey("test"), revert, original); assertThat(key) .isEqualTo( Cache.PureRevertKeyProto.newBuilder() .setProject("test") .setClaimedRevert(ByteString.copyFrom(serializedRevert)) .setClaimedOriginal(ByteString.copyFrom(serializedOriginal)) .build());
static String getFileKey(String project, String file) { return project + ":" + file;
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper; import static com.google.common.base.Preconditions.checkArgument; import java.io.IOException; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.ExponentialBackoffRetry; public class CuratorFrameworkBuilder { private ZkConfig config = null; public CuratorFrameworkBuilder config(ZkConfig config) { this.config = config; return this; } public CuratorFramework build() throws IOException {
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper; import com.google.common.base.MoreObjects; import java.io.Serializable; import org.apache.curator.framework.CuratorFrameworkFactory; import org.eclipse.jgit.lib.Config; /** Configuration for a Zookeeper setup. */ public class ZkConfig implements Serializable { private static final long serialVersionUID = 1L; public static final int DEFAULT_SESSION_TIMEOUT_MS; public static final int DEFAULT_CONNECTION_TIMEOUT_MS; static {
public static final int DEFAULT_CONNECTION_TIMEOUT_MS; static { CuratorFrameworkFactory.Builder b = CuratorFrameworkFactory.builder(); DEFAULT_SESSION_TIMEOUT_MS = b.getSessionTimeoutMs(); DEFAULT_CONNECTION_TIMEOUT_MS = b.getConnectionTimeoutMs(); } private static final String SECTION = "zookeeper"; private static final String KEY_CONNECT_STRING = "connectString"; private static final String KEY_SESSION_TIMEOUT = "sessionTimeout"; private final String connectString; private final int sessionTimeoutMs; private final int connectionTimeoutMs; private final String zookeeperRoot; ZkConfig( final String connectString, final String zookeeperRoot, final int sessionTimeoutMs, final int connectionTimeoutMs) { this.connectString = connectString; this.sessionTimeoutMs = sessionTimeoutMs; this.connectionTimeoutMs = connectionTimeoutMs; this.zookeeperRoot = zookeeperRoot; } public static ZkConfig fromConfig(Config cfg) { return new ZkConfig( cfg.getString(SECTION, null, KEY_CONNECT_STRING),
return true; } private boolean doCreate( ZkRefInfoMarshaller marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception { if (infoCurrentlyInZkMaybe.isPresent()) { logger.atWarning().log( "Asked to create ref %s but it is already in ZK at path %s", newRefInfo.refName(), ZkRefInfoMarshaller.pathFor(newRefInfo)); return false; } marshaller.create(newRefInfo); return true; } /** * When deleting a Ref this temporary Ref Tombstone will be created and then cleaned-up at a later * stage by the garbage collection */ static class TombstoneRef implements Ref { static TombstoneRef forRef(final Ref targetRef) { return new TombstoneRef(targetRef.getName()); } private final String name; private TombstoneRef(String name) { this.name = name; } @Override public String getName() { return name; } @Override public boolean isSymbolic() { return false; } @Override public Ref getLeaf() { return null; } @Override public Ref getTarget() { return null; } @Override
assertThat(marshaller.read(aProjectName(), aChangeRefName())).isEqualTo(Optional.empty()); } @Test public void shouldUpdateAZrefInfo() throws Exception { ZkRefInfo newRefInfo = aZkRefInfo(); ZkRefInfo updateRefInfo = new ZkRefInfo( newRefInfo.projectName(), newRefInfo.refName(), anObjectId(), Instant.now(), UUID.randomUUID()); marshaller.create(newRefInfo); marshaller.update(updateRefInfo); Optional<ZkRefInfo> readUpdatedRefInfo = marshaller.read(updateRefInfo.projectName(), updateRefInfo.refName()); assertThat(readUpdatedRefInfo).isEqualTo(Optional.of(updateRefInfo)); } @Test public void shouldFailToReadZkRefInfoIfSomeOfTheInfoIsMissing() throws Exception { String projectName = aProjectName(); String refName = aChangeRefName(); curator.createContainers(ZkRefInfoMarshaller.pathFor(projectName, refName)); expectedException.expect(CorruptedZkStorageException.class);
public boolean equals(Object other) { if (this == other) { return true; } if (o == null || getClass() != o.getClass()) { return false; } ZkRefInfo zkRefInfo = (ZkRefInfo) o; return Objects.equal(refName, zkRefInfo.refName) && Objects.equal(projectName, zkRefInfo.projectName) && Objects.equal(objectId, zkRefInfo.objectId) && Objects.equal(lastWriterInstanceId, zkRefInfo.lastWriterInstanceId) && Objects.equal(lastUpdatedAt, zkRefInfo.lastUpdatedAt);
marshaller.read(projectName, newRef.getName()); final ZkRefInfo newRefInfo = new ZkRefInfo(projectName, newRef, instanceId); if (isCreate) { return doCreate(marshaller, infoCurrentlyInZkMaybe, newRefInfo); } else { return doUpdate(oldRef, marshaller, infoCurrentlyInZkMaybe, newRefInfo); } } catch (Exception e) { logger.atWarning().withCause(e).log( "Error trying to perform CAS at path %s", ZkRefInfoDAO.pathFor(projectName, newRef)); throw new IOException( String.format( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)), e); } } private boolean doUpdate( Ref oldRef, ZkRefInfoMarshaller marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception { if (!infoCurrentlyInZkMaybe.isPresent()) { logger.atWarning().log( "Asked to update ref %s but it is not in ZK at path %s",
} } catch (Exception e) { logger.atWarning().withCause(e).log( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)); throw new IOException( String.format( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)), e); } } private boolean doUpdate( Ref oldRef, ZkRefInfoDAO marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception { if (!infoCurrentlyInZkMaybe.isPresent()) { logger.atWarning().log( "Asked to update ref %s but it is not in ZK at path %s", newRefInfo.refName(), ZkRefInfoMarshaller.pathFor(newRefInfo)); return false; } if (!infoCurrentlyInZkMaybe.get().objectId().equals(oldRef.getObjectId())) { logger.atWarning().log(
import java.io.IOException; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.test.TestingServer; import org.junit.Test; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin( name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.validation.ValidationIT$Module") public class ValidationIT extends LightweightPluginDaemonTest { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); CuratorFramework framework; public static class Module extends LifecycleModule { public class ZookeeperStopAtShutdown implements LifecycleListener { private final ZookeeperTestContainerSupport zookeeperContainer; public ZookeeperStopAtShutdown(TestingServer zookeeper) { this.zookeeper = zookeeper; } @Override public void stop() { try { zookeeper.stop(); } catch (IOException e) { logger.atWarning().withCause(e).log("Cannot start zookeeper"); throw new RuntimeException("Cannot start zookeeper", e); } } @Override public void start() { try { zookeeper.start(); } catch (Exception e) {
protected void configure() { TestingServer zookeeper = null; try { zookeeper = new TestingServer(); } catch (Exception e) { throw new RuntimeException("Cannot init zookeeper", e); } install(new ValidationModule()); install(new ValidationModule(multiSiteConfig)); listener().toInstance(new ZookeeperStopAtShutdown(zookeeperContainer));
import org.junit.Ignore; @Ignore public interface RefFixture { String ALLOWED_CHARS = "abcdefghilmnopqrstuvz"; String ALLOWED_DIGITS = "1234567890"; String ALLOWED_NAME_CHARS = ALLOWED_CHARS + ALLOWED_CHARS.toUpperCase() + ALLOWED_DIGITS; static ZkRefInfo aZkRefInfo() { return new ZkRefInfo( aProjectName(), aChangeRefName(), anObjectId(), Instant.now(), UUID.randomUUID()); } default String aBranchRef() { return RefNames.REFS_HEADS + testBranch(); } static ObjectId anObjectId() { return ObjectId.fromString(RandomStringUtils.randomNumeric(40)); } static String aChangeRefName() { return "refs/for/" + RandomStringUtils.random(10, ALLOWED_NAME_CHARS); } static Ref aRefObject(String refName, ObjectId objectId) { return new TestRef(refName, objectId); } static Ref aRefObject(String refName) { return aRefObject(refName, anObjectId()); } static Ref aRefObject() { return aRefObject(aChangeRefName(), anObjectId()); }
public void shouldCreateANewRef() { ObjectId objectId = AN_OBJECT_ID_1; String refName = aBranchRef(); Ref aNewRef = zkSharedRefDatabase.newRef(refName, objectId); assertThat(aNewRef.getName()).isEqualTo(refName); assertThat(aNewRef.getObjectId()).isEqualTo(objectId); assertThat(aNewRef.getStorage()).isEqualTo(Storage.NETWORK);
Ref aNewRef = zkSharedRefDatabase.newRef(refName, objectId); assertThat(aNewRef.getName()).isEqualTo(refName); assertThat(aNewRef.getObjectId()).isEqualTo(objectId); assertThat(aNewRef.getStorage()).isEqualTo(Storage.NETWORK); } @Test public void shouldCompareAndPutSuccessfully() throws Exception { Ref oldRef = aRefObject(); String projectName = RefFixture.aProjectName(); marshaller.create(new ZkRefInfo(projectName, oldRef)); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, aRefObject(oldRef.getName()))) .isTrue(); } @Test public void compareAndPutShouldFailIfTheObjectionHasNotTheExpectedValue() throws Exception { String projectName = RefFixture.aProjectName(); Ref oldRef = aRefObject(); Ref expectedRef = aRefObject(oldRef.getName()); marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); assertThat( zkSharedRefDatabase.compareAndPut( projectName, expectedRef, aRefObject(oldRef.getName()))) .isFalse(); }
marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); assertThat(zkSharedRefDatabase.compareAndRemove(projectName, oldRef)).isTrue(); Optional<ZkRefInfo> inZk = marshaller.read(projectName, oldRef.getName()); assertThat(inZk.isPresent()).isTrue(); inZk.get().equals(TombstoneRef.forRef(oldRef)); } @Test public void shouldNotCompareAndPutSuccessfullyAfterACompareAndRemove() throws Exception { Ref oldRef = aRefObject(); String projectName = RefFixture.aProjectName(); marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); zkSharedRefDatabase.compareAndRemove(projectName, oldRef); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, aRefObject(oldRef.getName()))) .isFalse(); } }
return "/" + projectName + "/" + refName; } private final CuratorFramework client; public ZkRefInfoDAO(CuratorFramework client) { this.client = client; } public Optional<ZkRefInfo> read(String projectName, String refName) throws Exception { final String rootPath = pathFor(projectName, refName); if (!exists(rootPath)) return Optional.empty(); final ObjectId objectId = readObjectIdAt(rootPath + "/" + OBJECT_ID_PATH); if (!(objectId.isPresent())) { throw new CorruptedZkStorageException( String.format( "Corrupted content for ref %s, missing some of the sub info, %s present: %b", refName, OBJECT_ID_PATH, objectId.isPresent())); } return Optional.of(new ZkRefInfo(projectName, refName, objectId.get())); } public void update(ZkRefInfo info) throws Exception { writeInTransaction(info, () -> client.transactionOp().setData()); } public void create(ZkRefInfo info) throws Exception {
import org.apache.curator.framework.recipes.locks.InterProcessMutex; import org.apache.curator.framework.recipes.locks.Locker; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; public class ZkSharedRefDatabase implements SharedRefDatabase { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CuratorFramework client; private final Duration lockTimeout; private final UUID instanceId; @Inject public ZkSharedRefDatabase( CuratorFramework client, @Named("ZkLockTimeout") Duration lockTimeout) { this.client = client; this.lockTimeout = lockTimeout; this.instanceId = instanceId; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, TombstoneRef.forRef(oldRef)); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { boolean isCreate = oldRef == NULL_REF; final ZkRefInfoDAO marshaller = new ZkRefInfoDAO(client); final InterProcessMutex refPathMutex =
import com.google.gerrit.extensions.annotations.Exports; import com.google.gerrit.extensions.config.FactoryModule; import com.google.gerrit.plugins.checks.Checker; import com.google.gerrit.plugins.checks.Checkers; import com.google.gerrit.plugins.checks.api.BlockingCondition; import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.plugins.checks.api.CombinedCheckState; import com.google.gerrit.plugins.checks.api.ListChecks; import com.google.gerrit.reviewdb.client.Change; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.project.SubmitRuleOptions; import com.google.gerrit.server.query.change.ChangeData; import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; import java.util.Map; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder()
import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId; private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); result.assertOkStatus(); testPatchSetId = result.getPatchSetId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED);
import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId; private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); result.assertOkStatus(); testChangeId = result.getChangeId(); testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED); assertThat(checkerOperations.checker(testCheckerUuid).get().getBlockingConditions()) .containsExactly(BlockingCondition.STATE_NOT_PASSING);
// about checks. approve(testChangeId); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. Project.NameKey otherRepo = new Project.NameKey("other-project"); gApi.projects().create(otherRepo.get()); checkerOperations.checker(testCheckerUuid).forUpdate().repository(otherRepo).update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getRepository()) .isEqualTo(otherRepo); gApi.changes().id(testChangeId).current().submit();
Project.NameKey otherRepo = new Project.NameKey("other-project"); gApi.projects().create(otherRepo.get()); checkerOperations.checker(testCheckerUuid).forUpdate().repository(otherRepo).update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getRepository()) .isEqualTo(otherRepo); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations.checker(testCheckerUuid).forUpdate().disable().update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.DISABLED); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void enabledCheckerNotBlockingSubmitIfNoBlockingCondition() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations .checker(testCheckerUuid) .forUpdate()
gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void enabledCheckerBlockingSubmitIfInBlockingState() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); exception.expect(ResourceConflictException.class); exception.expectMessage("Passing all blocking checks required"); gApi.changes().id(testChangeId).current().submit(); } @Test @Sandboxed public void multipleCheckerBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); // Two enabled and required checkers. They are blocking if any of them isn't passing. CheckerUuid testCheckerUuid2 = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .create(); postCheckResult(testCheckerUuid, CheckState.SUCCESSFUL); postCheckResult(testCheckerUuid2, CheckState.FAILED); exception.expect(ResourceConflictException.class); exception.expectMessage("Passing all blocking checks required"); gApi.changes().id(testChangeId).current().submit(); } @Test @Sandboxed public void multipleCheckerNotBlockingSubmit() throws Exception {
if (path.isEmpty() || addAll) { Util.addToMap(owner2paths, key, dir + path); } } } } } /** * Parse given lines of an OWNERS files; return parsed Result. * It can recursively call itself to parse included files. * * @param dir is the directory that contains "changed files" of a CL, * not necessarily the OWNERS or included file directory. * "owners" found in lines control changed files in 'dir'. * 'dir' ends with '/' or is empty when parsing an included file. * @param lines are the source lines of the file to be parsed. * @return the parsed data */ Result parseFile(String dir, String[] lines) { Result result = new Result(); int n = 0; for (String line : lines) { parseLine(result, dir, line, ++n); } return result; } Result parseFile(String dir, String content) {
} } } else if ((parsedKPF = parseInclude(stack.currentProject(), line)) != null) { includeFile(result, dir, num, parsedKPF, parsedKPF[0].equals("include")); } else { result.errors.add(errorMsg(stack.currentFile(), num, "ignored unknown line", line)); } } /** * Find and parse an included file and append data to the 'result'. * For an 'include' statement, parsed data is all appended to the given result parameter. * For a 'file:' statement or directive, only owner emails are appended. * If the project+file name is found in the stored result set, the stored result is reused. * The inclusion is skipped if to be included file is already on the including file stack. * * @param result to where the included file data should be added. * @param dir the including file's directory or glob. * @param num source code line number
} } /** * Find and parse an included file and append data to the 'result'. * For an 'include' statement, parsed data is all append to the given result parameter. * For a 'file:' statement or directive, only owner emails are appended. * If the project+file name is found in the stored result set, the stored result is reused. * The inclusion is skipped if the to be included file is already on the including file stack. * * @param result to where the included file data should be added. * @param dir the including file's directory or glob. * @param num source code line number * @param parsedKPF the parsed line of include or file directive. * @param addAll to add all parsed data into result or not. */ private void includeFile(Result result, String dir, int num, String[] parsedKPF, boolean addAll) { String keyword = parsedKPF[0]; String project = parsedKPF[1];
assertThat(r2.owner2paths).isEmpty(); assertThat(r2.warnings).containsExactly(w2, w1); assertThat(r2.noParentGlobs).containsExactly(b2, b1); assertThat(r1.noParentGlobs).containsExactly(b1); assertThat(r2.errors).containsExactly(e2, e1); r1.append(r2, "", true); assertThat(r1.owner2paths).isEmpty(); assertThat(r2.owner2paths).isEmpty(); // warnings, errors, and noParentGlobs are sets of strings. // containsExactly does not check order of elements. assertThat(r1.warnings).containsExactly(w1, w2); assertThat(r1.warnings).containsExactly(w2, w1); assertThat(r1.noParentGlobs).containsExactly(b2, b1); assertThat(r1.errors).containsExactly(e1, e2); assertThat(r1.errors).containsExactly(e2, e1);
import org.eclipse.jgit.treewalk.filter.PathFilterGroup; import org.junit.Test; @TestPlugin(name = "find-owners", sysModule = "com.googlesource.gerrit.plugins.findowners.Module") public class OwnersFileSubmitRuleIT extends AbstractDaemonTest { @Test public void TestChangeWithoutPermissions() throws Exception { createTestRepositoryContent(); configurePlugin("enforceLevel", "ENFORCE"); PushOneCommit.Result r = createChange("test message", "A/1/foo.c", "void main()\n"); approve(r.getChangeId()); ChangeInfo result = gApi.changes().id(r.getChangeId()).get(); assertThat(result.submittable).isFalse(); } private void createTestRepositoryContent() throws Exception { grant(project, "refs/for/master", Permission.PUSH); TestRepository<InMemoryRepository>.CommitBuilder cb = testRepo.branch("master").commit(); cb.add("OWNERS", "alice@example.com\nbob@example.com\n"); cb.add("A/1/foo.c", "int main()\n");
} } private final LoadingCache<PureRevertKeyProto, Boolean> cache; private final ChangeNotes.Factory notesFactory; @Inject PureRevertCache( @Named(ID_CACHE) LoadingCache<PureRevertKeyProto, Boolean> cache, ChangeNotes.Factory notesFactory) { this.cache = cache; this.notesFactory = notesFactory; } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of the change that is * referenced in {@link Change#getRevertOf()}. * * @return {@code true} if {@code claimedRevert} is a pure (clean) revert. * @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ChangeNotes} */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { if (claimedRevert.getChange().getRevertOf() == null) {
* @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ChangeNotes} */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { if (claimedRevert.getChange().getRevertOf() == null) { throw new BadRequestException("revertOf not set"); } ChangeNotes claimedOriginal = notesFactory.createChecked( claimedRevert.getProjectName(), claimedRevert.getChange().getRevertOf()); return isPureRevert( claimedRevert.getProjectName(), ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(changeNotes.getCurrentPatchSet().getRevision().get())); } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. *
cb.add("A/1/info.txt", "information\n"); cb.add("A/1/OWNERS", "xyz@example.com\n"); cb.add("A/no_inherit/spam.py", "def main()\n"); cb.add("A/no_inherit/ham.py", "def func()\n"); cb.add("A/no_inherit/info.txt", "python information\n"); cb.add("A/no_inherit/OWNERS", "set noparent\nabc@example.com\n"); cb.message("initial commit"); cb.insertChangeId(); cb.create(); } @Test public void TestDummyRepoSetup() throws Exception { createTestRepositoryContent(); RevWalk rw = testRepo.getRevWalk(); RevTree tree = rw.parseTree(testRepo.getRepository().resolve("HEAD")); try (TreeWalk treeWalk = new TreeWalk(rw.getObjectReader())) { treeWalk.setFilter(PathFilterGroup.createFromStrings("project.config")); treeWalk.reset(tree);
public Collection<SubmitRecord> evaluate(ChangeData cd, SubmitRuleOptions options) { ProjectState projectState = projectCache.get(cd.project()); PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance(projectState, pluginName); EnforcementLevel enforce_level = pluginConfig .getEnum(EnforcementLevel.CONFIG_NAME, EnforcementLevel.DISABLED); if (enforce_level == EnforcementLevel.DISABLED) { return ImmutableList.of(); } Checker checker = new Checker(repoManager, pluginConfigFactory, projectState, cd, 1); int result; try { OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager) .get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); }
public Collection<SubmitRecord> evaluate(ChangeData cd, SubmitRuleOptions options) { ProjectState projectState = projectCache.get(cd.project()); PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance( projectState, pluginName ); EnforcementLevel enforce_level = pluginConfig .getEnum(EnforcementLevel.CONFIG_NAME, EnforcementLevel.DISABLED); if (enforceLevel == EnforcementLevel.DISABLED) { this.logger .atInfo() .log( "OwnersFileRule was run for change %s but enforcement is disabled via project.config", Config.getChangeId(cd)); return ImmutableList.of(); } Checker checker = new Checker(repoManager, pluginConfigFactory, projectState, cd, 1); int result; try { OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager) .get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); }
public Collection<SubmitRecord> evaluate(ChangeData cd, SubmitRuleOptions options) { ProjectState projectState = projectCache.get(cd.project()); PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance( projectState, pluginName ); EnforcementLevel enforce_level = pluginConfig .getEnum(EnforcementLevel.CONFIG_NAME, EnforcementLevel.DISABLED); if (enforce_level == EnforcementLevel.DISABLED) { return ImmutableList.of(); } Checker checker = new Checker(repoManager, pluginConfigFactory, projectState, cd, 1); int result; try { OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager) .get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); }
pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } SubmitRecord sr = new SubmitRecord(); sr.requirements = SUBMIT_REQUIREMENTS; if (result >= 0) { sr.status = Status.OK; return ImmutableList.of(sr); } return ImmutableList.of(sr);
import com.google.gerrit.extensions.api.changes.SubmitInput; import com.google.gerrit.extensions.common.ChangeInfo; import com.google.gerrit.server.config.PluginConfig; import org.eclipse.jgit.lib.ObjectLoader; import org.eclipse.jgit.revwalk.RevObject; import org.eclipse.jgit.revwalk.RevTree; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Test; @TestPlugin(name = "find-owners", sysModule = "com.googlesource.gerrit.plugins.findowners.Module") public class OwnersFileSubmitRuleIT extends LightweightPluginDaemonTest { @Test public void changeWithoutPermissions() throws Exception { createTestRepositoryContent(); configurePlugin("enforceLevel", "ENFORCE"); PushOneCommit.Result r = createChange("test message", "A/1/foo.c", "void main()\n"); approve(r.getChangeId()); ChangeInfo result = gApi.changes().id(r.getChangeId()).get(); assertThat(result.submittable).isFalse(); } private void createTestRepositoryContent() throws Exception { addFile("init", "OWNERS", "per-file *.c = alice@example.com, bob@example.com\n");
return pathFor(projectName, ref.getName()); } public static String pathFor(String projectName, String refName) { return "/" + projectName + "/" + refName; } private final CuratorFramework client; public ZkRefInfoDAO(CuratorFramework client) { this.client = client; } public Optional<ZkRefInfo> read(String projectName, String refName) throws Exception { final String rootPath = pathFor(projectName, refName); if (!exists(rootPath)) { return Optional.empty(); } final ObjectId objectId = readObjectIdAt(rootPath + "/" + OBJECT_ID_PATH); return Optional.of(new ZkRefInfo(projectName, refName, objectId)); } public void update(ZkRefInfo info) throws Exception { writeInTransaction(info, () -> client.transactionOp().setData()); } public void create(ZkRefInfo info) throws Exception { client.createContainers(pathFor(info)); writeInTransaction(info, () -> client.transactionOp().create().withMode(PERSISTENT)); } private void writeInTransaction(
import com.google.gerrit.server.query.change.ChangeData; import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder() .setFallbackText("All required checks must pass") .setType("checks_pass") .build(); public static class Module extends FactoryModule { @Override public void configure() { bind(SubmitRule.class) .annotatedWith(Exports.named("ChecksSubmitRule")) .to(ChecksSubmitRule.class); } } private final Checks checks; @Inject public ChecksSubmitRule(Checks checks) { this.checks = checks; } @Override public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) { Project.NameKey project = changeData.project(); Change.Id changeId = changeData.getId();
import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder() .setFallbackText("All required checks must pass") .setType("checks_pass") .build(); public static class Module extends FactoryModule { @Override public void configure() { bind(SubmitRule.class) .annotatedWith(Exports.named("ChecksSubmitRule")) .to(ChecksSubmitRule.class); } } private final Checks checks; @Inject public ChecksSubmitRule(Checks checks) { this.checks = checks; } @Override public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) { Project.NameKey project = changeData.project(); Change.Id changeId = changeData.getId(); PatchSet.Id currentPathSetId; try {
import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId; private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception {
testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. Project.NameKey otherRepo = new Project.NameKey("All-Projects"); checkerOperations.checker(checkerUuid).forUpdate().repository(otherRepo).update(); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations.checker(testCheckerUuid).forUpdate().disable().update(); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); }
} } public static String pathFor(String projectName, Ref ref) { return pathFor(projectName, ref.getName()); } public static String pathFor(String projectName, String refName) { return "/" + projectName + "/" + refName; } public static ObjectId readObjectId(byte[] value) { return ObjectId.fromRaw(value); } static byte[] writeObjectId(ObjectId value) throws IOException { final ByteArrayOutputStream out = new ByteArrayOutputStream(); final DataOutputStream stream = new DataOutputStream(out); value.copyRawTo(stream); return out.toByteArray(); } }
ListChecks( CheckBackfiller checkBackfiller, CheckJson.Factory checkJsonFactory, Checkers checkers, Checks checks) { this.checkBackfiller = checkBackfiller; this.checkJsonFactory = checkJsonFactory; this.checkers = checkers; this.checks = checks; } @Override public ImmutableList<CheckInfo> apply(RevisionResource resource) throws AuthException, BadRequestException, ResourceConflictException, OrmException, IOException { CheckJson checkJson = checkJsonFactory.create(options); Map<CheckerUuid, Checker> checkersByUuid = checkers.checkersOf(resource.getProject()).stream() .collect(toMap(Checker::getUuid, c -> c)); ImmutableList.Builder<CheckInfo> result = ImmutableList.builderWithExpectedSize(checkersByUuid.size()); for (Check check : checks.getChecks(resource.getProject(), resource.getPatchSet().getId())) { checkersByUuid.remove(check.key().checkerUuid()); result.add(checkJson.format(check)); } for (Check check : checkBackfiller.getBackfilledChecksForRelevantCheckers( checkersByUuid.values(), resource.getNotes(), resource.getPatchSet().getId())) {
* not exist. */ Optional<Check> getCheck(CheckKey checkKey) throws OrmException, IOException; @AutoValue abstract class GetChecksOptions { /** Backfills checks for relevant checkers with default when they don't exist yet. */ public abstract boolean backfillChecks(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_Checks_GetChecksOptions.Builder().setBackfillChecks(false); } public static GetChecksOptions defaults() { return builder().build(); } /** Backfills checks for relevant checkers with default when they don't exist yet. */ public abstract boolean backfillChecks(); } }
private final CuratorFramework client; private final RetryPolicy retryPolicy; @Inject public ZkSharedRefDatabase( CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } else { final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); }
@Inject public ZkSharedRefDatabase( CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } else { final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } } catch (Exception e) { logger.atWarning().withCause(e).log(
import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.server.config.AllProjectsName; import org.junit.Before; import org.junit.Test; /** * TODO(xchangcheng): add more tests after figuring out the expecting behavior of {@code * CombinedCheckState}. */ public class ChecksSubmitRuleIT extends AbstractCheckersTest { private static final SubmitRequirementInfo SUBMIT_REQUIREMENT_INFO = new SubmitRequirementInfo( "NOT_READY", "All required checks must pass", "checks_pass", ImmutableMap.of()); @Inject private AllProjectsName allProjects; private String testChangeId; private PatchSet.Id testPatchSetId; @Before public void setUp() throws Exception { allProjects = plugin.getSysInjector().getInstance(AllProjectsName.class); PushOneCommit.Result result = createChange(); testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception {
* CombinedCheckState}. */ public class ChecksSubmitRuleIT extends AbstractCheckersTest { private static final SubmitRequirementInfo SUBMIT_REQUIREMENT_INFO = new SubmitRequirementInfo( "NOT_READY", "All required checks must pass", "checks_pass", ImmutableMap.of()); private AllProjectsName allProjects; private String testChangeId; private PatchSet.Id testPatchSetId; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. checkerOperations.checker(checkerUuid).forUpdate().repository(allProjects).update();
} @Before public void setUpCheckersPlugin() throws Exception { checkerOperations = plugin.getSysInjector().getInstance(CheckerOperations.class); checkOperations = plugin.getSysInjector().getInstance(CheckOperations.class); checkersApi = plugin.getHttpInjector().getInstance(Checkers.class); checksApiFactory = plugin.getHttpInjector().getInstance(ChecksFactory.class); pendingChecksApi = plugin.getHttpInjector().getInstance(PendingChecks.class); allowGlobalCapabilities(group("Administrators").getGroupUUID(), "checks-administrateCheckers"); } }
fetch(repo, checkerRef + ":checkerRef"); repo.reset("checkerRef"); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.PUSH); PushOneCommit.Result r = pushFactory.create(admin.getIdent(), repo).to(checkerRef); r.assertErrorStatus(); r.assertMessage("direct update of checker ref not allowed"); } @Test public void submitToCheckerRefsIsDisabled() throws Exception { CheckerUuid checkerUuid = checkerOperations.newChecker().status(CheckerStatus.DISABLED).create(); String checkerRef = checkerUuid.toRefName(); String changeId = createChangeWithoutCommitValidation(checkerRef); grantLabel( "Code-Review", -2, 2, allProjects, CheckerRef.REFS_CHECKERS + "*", false, adminGroupUuid(), false); approve(changeId); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.SUBMIT); exception.expect(ResourceConflictException.class);
testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. checkerOperations.checker(checkerUuid).forUpdate().repository(allProjects).update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); checkerOperations.checker(checkerUuid).forUpdate().disable().update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } // @Test
checkerOperations.checker(checkerUuid).forUpdate().repository(otherRepo).update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); checkerOperations.checker(checkerUuid).forUpdate().disable().update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); assertThat(changeInfo.requirements).isEmpty(); } // @Test // public void enabledCheckerNotBlockingSubmitIfNotRequired() throws Exception { // CheckerUuid checkerUuid = newRequiredChecker().create(); // postCheckResult(checkerUuid, CheckState.FAILED); // checkerOperations // .checker(checkerUuid) // .forUpdate() // .blockingConditions(ImmutableSortedSet.of()) // .update(); // // ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); // // assertThat(changeInfo.submittable).isTrue(); // } @Test
CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.SUCCESSFUL); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } @Test public void enabledCheckerBlockingSubmitIfInBlockingState() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isFalse(); assertThat(changeInfo.requirements).containsExactly(SUBMIT_REQUIREMENT_INFO); } @Test public void multipleCheckerBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); // Two enabled and required checkers. They are blocking if any of them isn't passing. CheckerUuid testCheckerUuid2 = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.SUCCESSFUL); postCheckResult(testCheckerUuid2, CheckState.FAILED); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isFalse(); } // @Test // public void multipleCheckerNotBlockingSubmit() throws Exception {
return Collections.emptyList(); } public int getCount() { return count; } public void reset() { count = 0; } } @Override public Module createModule() { return new AbstractModule() { @Override protected void configure() { testRefOperationListener = new TestRefOperationValidationListener(); DynamicSet.bind(binder(), RefOperationValidationListener.class) .toInstance(testRefOperationListener); } }; } @Before public void setUp() throws Exception { assume().that(NoteDbMode.get()).isEqualTo(NoteDbMode.ON); } @After public void cleanup() { testRefOperationListener.reset(); } @Test public void aNormalPushShouldTriggerARefOperationValidation() throws Exception { PushOneCommit.Result r = createCommitAndPush(testRepo, "refs/heads/master", "msg", "file", "content"); assertThat(testRefOperationListener.getCount()).isEqualTo(1); } @Test public void aMagicRefUpdateShouldTriggerARefOperationValidationOnChangesBranch() throws Exception { PushOneCommit.Result r = createChange("refs/for/master");
String.format("checker %s not found", checkerUuid))); if (checker.getStatus() == CheckerStatus.DISABLED) { return ImmutableList.of(); } // The query system can only match against the current patch set; ignore non-current patch sets // for now. List<ChangeData> changes = queryMatchingChangesFor(checker); List<PendingChecksInfo> pendingChecks = new ArrayList<>(changes.size()); for (ChangeData cd : changes) { getPostFilteredPendingChecks(cd.project(), cd.currentPatchSet().getId()) .ifPresent(pendingChecks::add); } return pendingChecks; } private List<ChangeData> queryMatchingChangesFor(Checker checker) throws ConfigInvalidException, OrmException { Predicate<ChangeData> predicate = new ProjectPredicate(checker.getRepository().get()); if (checker.getQuery().isPresent()) { String query = checker.getQuery().get(); try { predicate = Predicate.and(predicate, queryBuilderProvider.get().parse(query)); } catch (QueryParseException e) { logger.atWarning().withCause(e).log(
CheckablePatchSetInfo patchSet = actual().patchSet; check("patchSet()").that(patchSet).isNotNull(); return patchSet; }
install(new NoteDbCheckersModule()); bind(CapabilityDefinition.class) .annotatedWith(Exports.named(AdministrateCheckersCapability.NAME)) .to(AdministrateCheckersCapability.class); DynamicSet.bind(binder(), CommitValidationListener.class) .to(CheckerCommitValidator.class) .in(SINGLETON); DynamicSet.bind(binder(), MergeValidationListener.class) .to(CheckerMergeValidator.class) .in(SINGLETON); DynamicSet.bind(binder(), RefOperationValidationListener.class) .to(CheckerRefOperationValidator.class) .in(SINGLETON); DynamicSet.bind(binder(), ChangeAttributeFactory.class) .to(ChangeCheckAttributeFactory.class); bind(DynamicOptions.DynamicBean.class) .annotatedWith(Exports.named(GetChange.class)) .to(GetChangeOptions.class); install(new ApiModule());
import org.eclipse.jgit.lib.ObjectId; import org.junit.Test; public class CheckerDefinitionTest { @Test public void notRequiredIfNoBlockingCondition() { Checker checker = newChecker().setBlockingConditions(ImmutableSortedSet.of()).build(); assertThat(checker.isRequired()).isFalse(); } @Test public void requiredIfHasBlockingConditionStateNotPassing() { Checker checker = newChecker().setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)).build(); assertThat(checker.isRequired()).isTrue(); } @Test public void allBlockingConditionsConsidered() { assertThat(EnumSet.allOf(BlockingCondition.class)).containsExactly(STATE_NOT_PASSING); } private Checker.Builder newChecker() { return Checker.builder() .setRepository(new NameKey("test-repo")) .setStatus(CheckerStatus.ENABLED) .setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)) .setUuid(CheckerUuid.parse("schema:any-id")) .setCreatedOn(TimeUtil.nowTs()) .setUpdatedOn(TimeUtil.nowTs()) .setRefState(ObjectId.zeroId()); } }
assertThat(checker.isRequired()).isFalse(); } @Test public void requiredIfHasBlockingConditionStateNotPassing() { Checker checker = newChecker().setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)).build(); assertThat(checker.isRequired()).isTrue(); } private Checker.Builder newChecker() { return Checker.builder() .setRepository(new NameKey("test-repo")) .setStatus(CheckerStatus.ENABLED) .setUuid(CheckerUuid.parse("schema:any-id")) .setCreatedOn(TimeUtil.nowTs()) .setUpdatedOn(TimeUtil.nowTs()) .setRefState(ObjectId.zeroId()); } }
* * @param project project containing the change. * @param psId patch set to which the state corresponds. * @return combined check state. */ public CombinedCheckState reload(Project.NameKey project, PatchSet.Id psId) throws OrmException { CombinedCheckStateCacheKeyProto key = key(project, psId); CombinedCheckState newState = loader.load(key); CombinedCheckState oldState = cache.getIfPresent(key); if (newState != oldState) { cache.put(key, newState); } } /** * Directly put a state into the cache. * * @param project project containing the change. * @param psId patch set to which the state corresponds. * @param state combined check state. */ @VisibleForTesting public void putForTest(Project.NameKey project, PatchSet.Id psId, CombinedCheckState state) { cache.put(key(project, psId), state); } @VisibleForTesting public CacheStats getStats() { return cache.stats(); }
} throw new IllegalStateException("unexpected options type: " + opts); } private ChangeCheckInfo forGetChange(ChangeData cd, GetChangeOptions opts) throws OrmException { if (opts == null || !opts.combined) { return null; } return new ChangeCheckInfo( combinedCheckStateCache.reload(cd.project(), cd.change().currentPatchSetId())); } private ChangeCheckInfo forQueryChanges(ChangeData cd, QueryChangesOptions opts) throws OrmException { if (!opts.combined) { return null; } return new ChangeCheckInfo( combinedCheckStateCache.get(cd.project(), cd.change().currentPatchSetId())); } }
RefUpdate refUpdate = repo.updateRef(refName); refUpdate.setExpectedOldObjectId(parent); refUpdate.setNewObjectId(newCommitId); refUpdate.setRefLogIdent(personIdent); refUpdate.setRefLogMessage(message, false); refUpdate.update(); RefUpdateUtil.checkResult(refUpdate); try { combinedCheckStateCache.reload(checkKey.project(), checkKey.patchSet()); } catch (OrmException e) { logger.atWarning().withCause(e).log("failed to reload CombinedCheckState for %s", checkKey); } gitRefUpdated.fire( checkKey.repository(), refUpdate, currentUser.map(user -> user.state()).orElse(null)); return readSingleCheck(checkKey, repo, rw, newCommitId); } } private void assertCheckerIsPresent(CheckerUuid checkerUuid) throws ConfigInvalidException, IOException { checkers.getChecker(checkerUuid).orElseThrow(() -> new IOException(checkerUuid + " missing")); } private boolean updateNotesMap( CheckKey checkKey, CheckUpdate checkUpdate, Repository repo, RevWalk rw, ObjectInserter ins, ObjectId curr,
stats = cache.getStats().minus(start); // Incurs a cache hit during read-then-write. assertThat(stats.hitCount()).isEqualTo(2); assertThat(stats.missCount()).isEqualTo(0); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.NOT_RELEVANT)); stats = cache.getStats().minus(start); assertThat(stats.hitCount()).isEqualTo(3); assertThat(stats.missCount()).isEqualTo(0); } @Test public void updatingCheckStateUpdatesCache() throws Exception { CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); cache.putForTest(project, psId, CombinedCheckState.IN_PROGRESS); CacheStats start = clone(cache.getStats()); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.IN_PROGRESS)); CacheStats stats = cache.getStats().minus(start); assertThat(stats.hitCount()).isEqualTo(1); assertThat(stats.missCount()).isEqualTo(0); // Set non-required checker to FAILED, updating combined check state to WARNING.
long expiresAt, String sessionId, String auth) { this.accountId = accountId; this.refreshCookieAt = refreshCookieAt; this.persistentCookie = persistentCookie; this.externalId = externalId; this.expiresAt = expiresAt; this.sessionId = sessionId; this.auth = auth; } public long getExpiresAt() { return expiresAt; } /** * This is public so that plugins that implement a web session, * can also implement a way to clear per user sessions. * * @return account ID. */ public Account.Id getAccountId() { return accountId; } ExternalId.Key getExternalId() { return externalId; } String getSessionId() { return sessionId; } String getAuth() { return auth; } boolean needsCookieRefresh() { return refreshCookieAt <= nowMs(); } boolean isPersistentCookie() { return persistentCookie; } private void writeObject(ObjectOutputStream out) throws IOException { writeVarInt32(out, 1);
private transient String auth; Val( Account.Id accountId, long refreshCookieAt, boolean persistentCookie, ExternalId.Key externalId, long expiresAt, String sessionId, String auth) { this.accountId = accountId; this.refreshCookieAt = refreshCookieAt; this.persistentCookie = persistentCookie; this.externalId = externalId; this.expiresAt = expiresAt; this.sessionId = sessionId; this.auth = auth; } public long getExpiresAt() { return expiresAt; } /** * This is public so that plugins that implement a web session, * can also implement a way to clear per user sessions. */ public Account.Id getAccountId() { return accountId; } ExternalId.Key getExternalId() { return externalId; } String getSessionId() { return sessionId; } String getAuth() { return auth; } boolean needsCookieRefresh() { return refreshCookieAt <= nowMs(); } boolean isPersistentCookie() { return persistentCookie; } private void writeObject(ObjectOutputStream out) throws IOException { writeVarInt32(out, 1); writeVarInt32(out, accountId.get());
// See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.server.git.validators.RefOperationValidationListener; import com.google.inject.AbstractModule; import com.google.inject.name.Names; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.SharedRefDatabase; public class ValidationModule extends AbstractModule { private Configuration cfg; public ValidationModule(Configuration cfg) { this.cfg = cfg; } @Override protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class); bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getSplitBrain().getZookeeper().buildCurator()); bind(RetryPolicy.class) .annotatedWith(Names.named("ZkLockRetryPolicy"))
ZookeeperTestContainerSupport zookeeperContainer; ZkSharedRefDatabase zkSharedRefDatabase; @Before public void setup() { zookeeperContainer = new ZookeeperTestContainerSupport(); zkSharedRefDatabase = new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); } @After public void cleanup() { zookeeperContainer.cleanup(); } @Test public void shouldCompareAndCreateSuccessfully() throws Exception { Ref ref = refOf(AN_OBJECT_ID_1); assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue(); assertThat(zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref)) .isEqualTo(ref.getObjectId()); } @Test public void shouldCompareAndPutSuccessfully() throws Exception { Ref oldRef = refOf(AN_OBJECT_ID_1); Ref newRef = refOf(AN_OBJECT_ID_2); String projectName = A_TEST_PROJECT_NAME; zookeeperContainer.createRefInZk(projectName, oldRef);
private static void assertInvalidQuery(String query, String expectedMessage) { try { CheckerQuery.clean(query); assert_().fail("expected BadRequestException"); } catch (BadRequestException e) { assertMessage(e, expectedMessageParts); }
public void hasType(int expectedType) { isNotNull(); check("getType()").that(typeName(actual().getType())).isEqualTo(typeName(expectedType));
public static Check newBackfilledCheck(Project.NameKey project, PatchSet ps, Checker checker) { return Check.builder(CheckKey.create(project, ps.getId(), checker.getUuid())) .setState(CheckState.NOT_STARTED) .setCreated(ps.getCreatedOn()) .setUpdated(ps.getCreatedOn()) .build();
} if (checkerUuid == null) { throw new BadRequestException("checker UUID is required"); } Checker checker = checkers .getChecker(checkerUuid) .orElseThrow( () -> new UnprocessableEntityException( String.format("checker %s not found", checkerUuid))); if (checker.getStatus() == CheckerStatus.DISABLED) { return ImmutableList.of(); } // The query system can only match against the current patch set; ignore non-current patch sets // for now. List<ChangeData> changes = checker .get() .queryMatchingChanges( retryHelper, queryBuilderProvider.get(), changeQueryProcessorProvider); CheckerUuid checkerUuid = checker.get().getUuid(); List<PendingChecksInfo> pendingChecks = new ArrayList<>(changes.size()); for (ChangeData cd : changes) { getPostFilteredPendingChecks(cd.project(), cd.currentPatchSet().getId()) .ifPresent(pendingChecks::add); } return pendingChecks; } private Optional<PendingChecksInfo> getPostFilteredPendingChecks( Project.NameKey project, PatchSet.Id patchSetId) throws OrmException, IOException { CheckState checkState = getCheckState(project, patchSetId);
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.plugins.checks.index; import static com.google.common.base.Preconditions.checkNotNull; import com.google.gerrit.index.query.QueryParseException; import com.google.gerrit.plugins.checks.Check; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gwtorm.server.OrmException; public class CheckStatePredicate extends CheckPredicate { public static CheckStatePredicate parse(String value) throws QueryParseException { return new CheckStatePredicate( Enums.getIfPresent(CheckState.class, value) .toJavaUtil() .orElseThrow( () -> new QueryParseException(String.format("invalid check state: %s", value)))); } private final CheckState checkState; public CheckStatePredicate(CheckState checkState) { super(CheckQueryBuilder.FIELD_STATE, checkState.name()); this.checkState = checkNotNull(checkState, "checkState"); } @Override public boolean match(Check check) throws OrmException { return checkState.equals(check.state()); } }
public CheckerPredicate(CheckerUuid checkerUuid) { super(CheckQueryBuilder.FIELD_CHECKER, checkerUuid.toString()); this.checkerUuid = requireNonNull(checkerUuid, "checkerUuid");
boolean isRest(ServletRequest req) { return req instanceof HttpServletRequest && servlet.matcher(((HttpServletRequest) req).getServletPath()).matches();
public void containsMessages(String... expectedLines) { checkArgument(expectedLines.length > 0, "use hasNoMessages()"); isNotNull(); Iterable<String> got = Splitter.on("\n").split(trimMessages()); check("trimmedMessages()").that(got).containsAtLeastElementsIn(expectedLines).inOrder();
} @Test public void insertCheckerTwice() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); CheckerUuid checkerUuid = CheckerUuid.parse("foo:bar"); Project.NameKey project = new Project.NameKey("some-project"); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid); assertThat(getRefsMetaCheckersState()).isEqualTo(commitId); } @Test public void removeCheckers() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project = new Project.NameKey("some-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("bar:baz"); CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:bar"); CheckerUuid checkerUuid3 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project); checkersByRepositoryNotes.insert(checkerUuid2, project); checkersByRepositoryNotes.insert(checkerUuid3, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project))
CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project1); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1)).containsExactly(checkerUuid1); assertThat(checkersByRepositoryNotes.get(project2)).isEmpty(); checkersByRepositoryNotes.remove(checkerUuid2, project1); checkersByRepositoryNotes.remove(checkerUuid1, project2); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1)).containsExactly(checkerUuid1); assertThat(checkersByRepositoryNotes.get(project2)).isEmpty(); assertThat(getRefsMetaCheckersState()).isEqualTo(commitId); } @Test public void updateCheckers() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project1 = new Project.NameKey("some-project"); Project.NameKey project2 = new Project.NameKey("other-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("foo:bar"); CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project1); checkersByRepositoryNotes.insert(checkerUuid2, project1); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1))
CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); CheckerUuid checkerUuid = CheckerUuid.parse("foo:bar"); Project.NameKey project = new Project.NameKey("some-project"); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThatCommitMessage() .isEqualTo( "Update checkers by repository\n\nChecker: " + checkerUuid.toString() + "\nRepository: " + project.get()); } @Test public void noOpUpdate() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project = new Project.NameKey("some-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("foo:bar"); checkersByRepositoryNotes.insert(checkerUuid1, project); commit(checkersByRepositoryNotes); ObjectId commitId = getRefsMetaCheckersState(); checkersByRepositoryNotes.insert(checkerUuid1, project); commit(checkersByRepositoryNotes); assertThat(getRefsMetaCheckersState()).isEqualTo(commitId); checkersByRepositoryNotes.update(checkerUuid1, project, project); commit(checkersByRepositoryNotes); assertThat(getRefsMetaCheckersState()).isEqualTo(commitId);
List<SQLEntry> entries = new ArrayList<>(); for (Entry<String, Collection<SQLEntry>> entry : eventsDb.getEvents(query).asMap().entrySet()) { String projectName = entry.getKey(); try { permissionBackend .currentUser() .project(new Project.NameKey(projectName)) .check(ProjectPermission.ACCESS); entries.addAll(entry.getValue()); } catch (AuthException e) { // Ignore } catch (PermissionBackendException e) { log.atWarning().withCause(e).log("Cannot check project access permission"); } } return entries.stream().sorted().map(SQLEntry::getEvent).collect(toList()); } /** * {@inheritDoc} If storing the event fails due to a connection problem, storage will be * re-attempted as specified in gerrit.config. After failing the maximum amount of times, the * event will be stored in a local h2 database. */ @Override public void storeEvent(ProjectEvent event) { Project.NameKey projectName = event.getProjectNameKey();
} } }.doFilter(req, res); } } private final ListMultimap<GitilesView.Type, Filter> filters = LinkedListMultimap.create(); private final Map<GitilesView.Type, HttpServlet> servlets = Maps.newHashMap(); private Config config; private Renderer renderer; private GitilesUrls urls; private Linkifier linkifier; private GitilesAccess.Factory accessFactory; private RepositoryResolver<HttpServletRequest> resolver; private VisibilityCache visibilityCache; private TimeCache timeCache; private BlameCache blameCache; private GitwebRedirectFilter gitwebRedirect; private final Filter errorHandler; private boolean initialized; GitilesFilter() {} GitilesFilter( Config config, Renderer renderer, GitilesUrls urls, GitilesAccess.Factory accessFactory, final RepositoryResolver<HttpServletRequest> resolver, VisibilityCache visibilityCache, TimeCache timeCache, BlameCache blameCache, GitwebRedirectFilter gitwebRedirect, Filter errorHandler) { this.config = checkNotNull(config, "config"); this.renderer = renderer; this.urls = urls; this.accessFactory = accessFactory; this.visibilityCache = visibilityCache; this.timeCache = timeCache;
kage com.google.gitiles; import javax.annotation.Nullable; import javax.servlet.http.HttpServletResponse; /** Indicates the request should be failed. */ public final class RequestFailureException extends RuntimeException { private final FailureReason reason; private String publicErrorMessage = null; public RequestFailureException(FailureReason reason) { super(); this.reason = reason; } public RequestFailureException(FailureReason reason, Throwable cause) { super(cause); this.reason = reason; } public RequestFailureException withPublicErrorMessage(String format, Object... params) { this.publicErrorMessage = String.format(format, params); return this; } public FailureReason getReason() { return reason; } @Nullable public String getPublicErrorMessage() { return publicErrorMessage; } /** The request failure reason. */ public enum FailureReason { AMBIGUOUS_OBJECT(HttpServletResponse.SC_BAD_REQUEST), BLAME_REGION_NOT_FOUND(HttpServletResponse.SC_NOT_FOUND), CANNOT_PARSE_GITILES_VIEW(HttpServletResponse.SC_NOT_FOUND), INCORECT_PARAMETER(HttpServletResponse.SC_BAD_REQUEST), INCORRECT_OBJECT_TYPE(HttpServletResponse.SC_NOT_FOUND),
public MultiSiteGitRepositoryManager( LocalDiskRepositoryManager localDiskRepositoryManager) { this.gitRepositoryManager = localDiskRepositoryManager; } public MultiSiteGitRepositoryManager(GitRepositoryManager gitRepositoryManager) { this.gitRepositoryManager = gitRepositoryManager; this.multiSiteRepoFactory = multiSiteRepoFactory;
protected void configure() { factory(MultiSiteRepository.Factory.class); factory(MultiSiteRefDatabase.Factory.class); factory(MultiSiteRefUpdate.Factory.class); bind(GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); install(new ZkValidationModule(cfg));
protected void configure() { factory(MultiSiteRepository.Factory.class); factory(MultiSiteRefDatabase.Factory.class); factory(MultiSiteRefUpdate.Factory.class); bind(GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); install(new ZkValidationModule(cfg));
doReturn(oldRef).when(refUpdate).getRef(); doReturn("refs/heads/master").when(refUpdate).getName(); doReturn(AN_OBJECT_ID_2).when(refUpdate).getNewObjectId(); doReturn(newRef).when(sharedRefDb).newRef("refs/heads/master", AN_OBJECT_ID_2); } @Test public void newUpdateShouldValidateAndSucceed() throws IOException { setMockRequiredReturnValues(); // When compareAndPut succeeds doReturn(true).when(sharedRefDb).compareAndPut(A_TEST_PROJECT_NAME, oldRef, newRef); doReturn(Result.NEW).when(refUpdate).update(); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, "ProjectName", refUpdate); assertThat(multiSiteRefUpdate.update()).isEqualTo(Result.NEW); } @Test(expected = IOException.class) public void newUpdateShouldValidateAndFailWithIOException() throws IOException { setMockRequiredReturnValues(); // When compareAndPut fails doReturn(false).when(sharedRefDb).compareAndPut("ProjectName", oldRef, newRef); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, "ProjectName", refUpdate);
public MultiSiteRepository( MultiSiteRefDatabase.Factory multiSiteRefDbFactory, @Assisted String projectName, @Assisted Repository repository) { super(new BaseRepositoryBuilder()); this.multiSiteRefDbFactory = multiSiteRefDbFactory; this.projectName = projectName; this.repository = repository;
public RefDatabase getRefDatabase() { return multiSiteRefDatabase;
import com.googlecode.prolog_cafe.lang.SymbolTerm; import java.io.File; import java.io.IOException; import java.util.ArrayList; import java.util.List; import org.kohsuke.args4j.Option; public class PrologShell extends AbstractProgram { @Option(name = "-s", metaVar = "FILE.pl", usage = "file to load") private List<String> fileName = new ArrayList<>(); @Option(name = "-q", usage = "quiet mode without banner") private boolean quiet; @Override public int run() { if (!quiet) { banner(); } BufferingPrologControl pcl = new BufferingPrologControl(); pcl.setPrologClassLoader(new PrologClassLoader(getClass().getClassLoader())); pcl.setEnabled(Prolog.Feature.IO, true); pcl.setEnabled(Prolog.Feature.STATISTICS, true); pcl.configureUserIO(System.in, System.out, System.err); pcl.initialize(Prolog.BUILTIN); for (String file : fileName) { String path; try { path = new File(file).getCanonicalPath(); } catch (IOException e) {
* commit SHA-1, but in ReviewDb it was generated randomly. Taking the target message as an index * rather than an ID allowed us to delete the message from both NoteDb and ReviewDb. * * @param update change update. * @param targetMessageId the id of the target change message. * @param newMessage the new message which is going to replace the old. */ public void replaceChangeMessage(ChangeUpdate update, String targetMessageId, String newMessage) { update.deleteChangeMessageByRewritingHistory(targetMessageId, newMessage); } /** * @param tag value of a tag, or null. * @return whether the tag starts with the autogenerated prefix. */ public static boolean isAutogenerated(@Nullable String tag) { return tag != null && tag.startsWith(AUTOGENERATED_TAG_PREFIX); } public static ChangeMessageInfo createChangeMessageInfo( ChangeMessage message, AccountLoader accountLoader) { PatchSet.Id patchNum = message.getPatchSetId();
@Singleton public class MultiSiteGitRepositoryManager implements GitRepositoryManager { private final GitRepositoryManager gitRepositoryManager; @Inject MultiSiteRepository.Factory multiSiteRepoFactory; @Inject public MultiSiteGitRepositoryManager(LocalDiskRepositoryManager localDiskRepositoryManager) { this.gitRepositoryManager = localDiskRepositoryManager; } public MultiSiteGitRepositoryManager(GitRepositoryManager gitRepositoryManager) { this.gitRepositoryManager = gitRepositoryManager; } @Override public Repository openRepository(NameKey name) throws RepositoryNotFoundException, IOException { return wrap(name, gitRepositoryManager.openRepository(name)); } @Override public Repository createRepository(NameKey name) throws RepositoryCaseMismatchException, RepositoryNotFoundException, IOException { Repository createdRepository = gitRepositoryManager.createRepository(name); return multiSiteRepoFactory.create(name.get(), createdRepository); } @Override public SortedSet<NameKey> list() { return gitRepositoryManager.list(); } }
this.gitRepositoryManager = localDiskRepositoryManager; } public MultiSiteGitRepositoryManager(GitRepositoryManager gitRepositoryManager) { this.gitRepositoryManager = gitRepositoryManager; } @Override public Repository openRepository(NameKey name) throws RepositoryNotFoundException, IOException { Repository openRepository = gitRepositoryManager.openRepository(name); return multiSiteRepoFactory.create(name.get(), openRepository); } @Override public Repository createRepository(NameKey name) throws RepositoryCaseMismatchException, RepositoryNotFoundException, IOException { return wrap(name, gitRepositoryManager.createRepository(name)); } @Override public SortedSet<NameKey> list() { return gitRepositoryManager.list(); } }
import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Configuration { private static final Logger log = LoggerFactory.getLogger(Configuration.class); static final String INSTANCE_ID_FILE = "instanceId.data"; // common parameters to cache and index sections static final String THREAD_POOL_SIZE_KEY = "threadPoolSize"; static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; static final int DEFAULT_THREAD_POOL_SIZE = 4; static final String NUM_STRIPED_LOCKS = "numStripedLocks"; static final int DEFAULT_NUM_STRIPED_LOCKS = 10;
import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate; private final RefDatabase refDb; private final SharedRefDatabase sharedRefDb; private final String projectName; public static class RefPair { final Ref oldRef; final Ref newRef; final Exception exception; RefPair(Ref oldRef, Ref newRef) { this.oldRef = oldRef; this.newRef = newRef; this.exception = null; } RefPair(Ref newRef, Exception e) { this.newRef = newRef; this.oldRef = SharedRefDatabase.NULL_REF; this.exception = e; } public boolean hasFailed() { return exception != null; } }
private final Index index; private final KafkaSubscriber subscriber; private final Kafka kafka; private final ZookeeperConfig zookeeperConfig; @Inject Configuration(SitePaths sitePaths) { this(new FileBasedConfig(sitePaths.etc_dir.resolve(MULTI_SITE_CONFIG).toFile(), FS.DETECTED));
protected void configure() { bind(DestinationFactory.class).in(Scopes.SINGLETON); bind(ReplicationQueue.class).in(Scopes.SINGLETON); bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(ReplicationQueue.class); DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), HeadUpdatedListener.class).to(ReplicationQueue.class); bind(OnStartStop.class).in(Scopes.SINGLETON); bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(OnStartStop.class); bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(ReplicationLogFile.class); bind(CredentialsFactory.class) .to(AutoReloadSecureCredentialsFactoryDecorator.class) .in(Scopes.SINGLETON); bind(CapabilityDefinition.class) .annotatedWith(Exports.named(START_REPLICATION)) .to(StartReplicationCapability.class); install(new FactoryModuleBuilder().build(PushAll.Factory.class)); install(new FactoryModuleBuilder().build(ReplicationState.Factory.class)); bind(ReplicationConfig.class).to(AutoReloadConfigDecorator.class); DynamicSet.setOf(binder(), ReplicationStateListener.class);
try { rateLimiterHolder = limitsPerAccount.get(accountId); } catch (ExecutionException e) { rateLimiterHolder = Holder.EMPTY; log.warn("Cannot get rate limits for account ''{}''", accountId, e); } } else { try { rateLimiterHolder = limitsPerRemoteHost.get(req.getRemoteHost()); } catch (ExecutionException e) { rateLimiterHolder = Holder.EMPTY; log.warn( "Cannot get rate limits for anonymous access from remote host ''{}''", req.getRemoteHost(), e); } } if (!rateLimiterHolder.hasGracePermits() && rateLimiterHolder.get() != null && !rateLimiterHolder.get().tryAcquire()) { String msg = MessageFormat.format( limitExceededMsg, rateLimiterHolder.get().getRate() * SECONDS_PER_HOUR, rateLimiterHolder.getBurstPermits()); ((HttpServletResponse) res).sendError(SC_TOO_MANY_REQUESTS, msg); return; } } chain.doFilter(req, res); } boolean isRest(ServletRequest req) {
public void run() { try { dispatcher.get().postEvent(new HeartbeatEvent()); } catch (OrmException e) { logger.error("Failed to post heartbeat event: {}", e.getMessage(), e); }
if (itemTs.isPresent()) { count++; newLastIndexTs = maxTimestamp(newLastIndexTs, itemTs.get()); } } catch (Exception e) { log.atSevere().withCause(e).log("Unable to reindex %s %s", itemNameString, c); errors++; } } long elapsedNanos = stopwatch.stop().elapsed(TimeUnit.NANOSECONDS); if (count > 0) { log.atInfo().log( "%d %ss reindexed in %d msec (%d/sec), %d failed", count, itemNameString, elapsedNanos / 1000000L, (count * 1000L) / (elapsedNanos / 1000000L), errors); } else if (errors > 0) { log.atInfo().log("%d %ss failed to reindex", errors, itemNameString); } else { log.atFine().log("Scanning finished"); } indexTs.update(itemName, newLastIndexTs.toLocalDateTime()); } catch (Exception e) { log.atSevere().withCause(e).log("Unable to scan %ss", itemNameString);
try { ChangeChecker checker = changeCheckerFactory.create(id); Optional<ChangeNotes> changeNotes = checker.getChangeNotes(); if (changeNotes.isPresent()) { ChangeNotes notes = changeNotes.get(); reindex(notes); if (checker.isChangeUpToDate(indexEvent)) { if (retryCount > 0) { log.atWarning().log( "Change %s has been eventually indexed after %d attempt(s)", id, retryCount); } else { log.atFine().log("Change {} successfully indexed", id); } } else { log.warn( "Change {} seems too old compared compared to the event timestamp (event-Ts={} >> change-Ts={})", id, indexEvent, changeTs); rescheduleIndex(id, maybeBody, retryCount++); } } else { indexer.delete(parseChangeId(id)); log.atWarning().log( "Change %s could not be found in the local Git repository (eventTs=%s), deleted from index", id, indexEvent); } } catch (Exception e) {
setHeaders(rsp); try { List<String> params = Splitter.on('/').splitToList(req.getPathInfo()); String cacheName = params.get(CACHENAME_INDEX); String json = req.getReader().readLine(); forwardedCacheEvictionHandler.evict( CacheEntry.from(cacheName, GsonParser.fromJson(cacheName, json))); rsp.setStatus(SC_NO_CONTENT); } catch (CacheNotFoundException e) { log.atSevere().log("Failed to process eviction request: %s", e.getMessage()); sendError(rsp, SC_BAD_REQUEST, e.getMessage()); } catch (IOException e) { log.atSevere().withCause(e).log("Failed to process eviction request"); sendError(rsp, SC_BAD_REQUEST, e.getMessage()); }
for (; ; ) { try { execCnt++; tryOnce(); log.atFine().log("%s %s towards %s OK", action, key, destination); return true; } catch (ForwardingException e) { int maxTries = cfg.http().maxTries(); log.atFine().withCause(e).log( "Failed to %s %s on %s [%d/%d]", action, key, destination, execCnt, maxTries); if (!e.isRecoverable()) { log.atSevere().withCause(e).log( "%s %s towards %s failed with unrecoverable error; giving up", action, key, destination); return false; } if (execCnt >= maxTries) { log.atSevere().log( "Failed to %s %s on %s after %d tries; giving up", action, key, destination, maxTries); return false; } log.atFine().log("Retrying to %s %s on %s", action, key, destination); try { Thread.sleep(cfg.http().retryInterval());
action, key, destination); return false; } if (execCnt >= maxTries) { log.atSevere().log( "Failed to %s %s on %s after %d tries; giving up", action, key, destination, maxTries); return false; } log.atFine().log("Retrying to %s %s on %s", action, key, destination); try { Thread.sleep(cfg.http().retryInterval()); } catch (InterruptedException ie) { log.atSevere().withCause(ie).log( "%s %s towards %s was interrupted; giving up", action, key, destination); Thread.currentThread().interrupt(); return false; } } }
public void viewAccepted(View view) { log.atInfo().log("viewAccepted(view: %s) called", view); synchronized (this) { if (view.getMembers().size() > 2) { log.atWarning().log( "%d members joined the jgroups cluster %s (%s). " + " Only two members are supported. Members: %s", view.getMembers().size(), jgroupsConfig.clusterName(), channel.getName(), view.getMembers()); } if (peerAddress != null && !view.getMembers().contains(peerAddress)) { log.atInfo().log("viewAccepted(): removed peerInfo"); peerAddress = null; peerInfo = Optional.empty(); } } if (view.size() > 1) { try { channel.send(new Message(null, myUrl)); } catch (Exception e) { // channel communication caused an error. Can't do much about it. log.atSevere().withCause(e).log( "Sending a message over channel %s to cluster %s failed",
public void connect() { try { channel = getChannel(); Optional<InetAddress> address = finder.findAddress(); if (address.isPresent()) { log.atFine().log("Protocol stack: %s", channel.getProtocolStack()); channel.getProtocolStack().getTransport().setBindAddress(address.get()); log.atFine().log("Channel bound to %s", address.get()); } else { log.atWarning().log("Channel not bound: address not present"); } channel.setReceiver(this); channel.setDiscardOwnMessages(true); channel.connect(jgroupsConfig.clusterName()); log.atInfo().log( "Channel %s successfully joined jgroups cluster %s", channel.getName(), jgroupsConfig.clusterName()); } catch (Exception e) { if (channel != null) { log.atSevere().withCause(e).log( "joining cluster %s (channel %s) failed", jgroupsConfig.clusterName(), channel.getName()); } else {
@Override public Ref getTarget() { return null; } @Override public ObjectId getObjectId() { return null; } @Override public ObjectId getPeeledObjectId() { return null; } @Override public boolean isPeeled() { return false; } @Override public Storage getStorage() { return Storage.NEW; } }; ImmutableList<String> refsToIgnoreInSharedDb = ImmutableList.of("refs/draft-comments/.*", "refs/changes/[0-9]+/[0-9]+/[0-9]+"); /** * Create a new in-memory Ref name associated with an objectId. * * @param refName ref name * @param objectId object id */ default Ref newRef(String refName, ObjectId objectId) { return new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, refName, objectId); } /** * Utility method for new refs. * * @param project project name of the ref * @param newRef new reference to store.
import javax.servlet.http.HttpServletResponse; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class RestApiRateLimiter extends AllRequestFilter { private static final Logger log = LoggerFactory.getLogger(RestApiRateLimiter.class); private static final int SECONDS_PER_HOUR = 3600; static final int SC_TOO_MANY_REQUESTS = 429; private final Provider<CurrentUser> user; private final LoadingCache<Account.Id, Holder> limitsPerAccount; private final LoadingCache<String, Holder> limitsPerRemoteHost; private final Pattern servletPath = Pattern.compile( "^/(?:a/)?" + "(access|accounts|changes|config|groups|plugins|projects|Documentation|tools)/(.*)$"); private final String limitExceededMsg; @Inject RestApiRateLimiter( Provider<CurrentUser> user, @Named(HttpModule.CACHE_NAME_RESTAPI_ACCOUNTID) LoadingCache<Account.Id, Holder> limitsPerAccount, @Named(HttpModule.CACHE_NAME_RESTAPI_REMOTEHOST) LoadingCache<String, Holder> limitsPerRemoteHost, @Named(RateMsgHelper.RESTAPI_CONFIGURABLE_MSG_ANNOTATION) String limitExceededMsg) { this.user = user;
AdministrateCheckersPermission permission) { this.self = self; this.permissionBackend = permissionBackend; this.listCheckers = listCheckers; this.checkers = checkers; this.views = views; this.permission = permission; } @Override public RestView<TopLevelResource> list() throws RestApiException { return listCheckers; } @Override public CheckerResource parse(TopLevelResource parent, IdString id) throws AuthException, ResourceNotFoundException, PermissionBackendException, IOException, ConfigInvalidException { if (!self.get().isIdentifiedUser()) { throw new AuthException("Authentication required"); } permissionBackend.currentUser().check(permission); Checker checker = checkers.getChecker(id.get()).orElseThrow(() -> new ResourceNotFoundException(id)); return new CheckerResource(checker); } @Override public DynamicMap<RestView<CheckerResource>> views() { return views; } }
return null; } @Override public ObjectId getObjectId() { return null; } @Override public ObjectId getPeeledObjectId() { return null; } @Override public boolean isPeeled() { return false; } @Override public Storage getStorage() { return Storage.NEW; } }; /** * Create a new in-memory Ref name associated with an objectId. * * @param refName ref name * @param objectId object id */ default Ref newRef(String refName, ObjectId objectId) { return new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, refName, objectId); } /** * Utility method for new refs. * * @param project project name of the ref * @param newRef new reference to store.
*/ boolean compareAndRemove(String project, Ref oldRef) throws IOException; /** * Some references should not be stored in the SharedRefDatabase. * * @param ref * @return true if it's to be ignore; false otherwise */ default boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); return refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } }
@Inject public ZkSharedRefDatabase( CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(
static final ObjectId AN_OBJECT_ID_2 = new ObjectId(1, 2, 3, 4, 6); static final ObjectId AN_OBJECT_ID_3 = new ObjectId(1, 2, 3, 4, 7); static final String A_TEST_REF_NAME = "refs/heads/master"; default String aBranchRef() { return RefNames.REFS_HEADS + testBranch(); } String testBranch(); }
* @return true if the remove was successful; false otherwise. * @throws java.io.IOException the reference could not be removed due to a system error. */ boolean compareAndRemove(String project, Ref oldRef) throws IOException; /** * Some references should not be stored in the SharedRefDatabase. * * @param ref * @return true if it's to be ignore; false otherwise */ default boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } }
CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } catch (Exception e) { logger.atWarning().withCause(e).log(
new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); } @After public void cleanup() { zookeeperContainer.cleanup(); } @Test public void shouldCompareAndCreateSuccessfully() throws Exception { Ref ref = refOf(AN_OBJECT_ID_1); assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue(); assertThat(zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref)) .isEqualTo(ref.getObjectId()); } @Test public void shouldCompareAndPutSuccessfully() throws Exception { Ref oldRef = refOf(AN_OBJECT_ID_1); Ref newRef = refOf(AN_OBJECT_ID_2); String projectName = A_TEST_PROJECT_NAME; zookeeperContainer.createRefInZk(projectName, oldRef); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, newRef)).isTrue(); } @Test public void shouldCompareAndPutWithNullOldRefSuccessfully() throws Exception { Ref oldRef = refOf(null); Ref newRef = refOf(AN_OBJECT_ID_2);
private final AtomicReference<Command> atomicCmd; private final DynamicSet<SshCommandPreExecutionFilter> commandFilters; @Argument(index = 0, required = false, metaVar = "COMMAND", handler = SubcommandHandler.class) private String commandName; @Argument(index = 1, multiValued = true, metaVar = "ARG") private List<String> args = new ArrayList<>(); @Inject DispatchCommand( PermissionBackend permissionBackend, @Assisted Map<String, CommandProvider> all, DynamicSet<SshCommandPreExecutionFilter> commandFilters) { this.permissionBackend = permissionBackend; commands = all; atomicCmd = Atomics.newReference(); this.commandFilters = commandFilters; } Map<String, CommandProvider> getMap() { return commands; } @Override public void start(Environment env) throws IOException { try { parseCommandLine(); if (Strings.isNullOrEmpty(commandName)) { StringWriter msg = new StringWriter(); msg.write(usage()); throw die(msg.toString()); } final CommandProvider p = commands.get(commandName); if (p == null) { String msg =
Optional<ExternalId> other = null; try { other = externalIds.get(key); } catch (IOException | ConfigInvalidException e) { throw new IllegalArgumentException( "Internal error while fetching username='" + username + "'"); } try { accountsUpdateProvider .get() .update( "Set Username from GitHub", accountId, u -> u.addExternalId(ExternalId.create(key, accountId, null, null))); } catch (OrmDuplicateKeyException dupeErr) { throw new IllegalArgumentException("username " + username + " already in use"); } catch (Exception e) { throw new IllegalArgumentException( "Internal error while trying to set username='" + username + "'"); } log.debug( "Account {} updated with preferredEmail = {}, fullName = {}, username = {}", accountId, email,
import java.util.Objects; import java.util.Set; import java.util.function.Predicate; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.URIish; /** Collection of Git repositories destinations for replication. */ public class DestinationsCollection { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final ReplicationConfig replicationConfig; private final Destination.Factory destinationFactory; private List<Destination> allDestinations; @Inject DestinationsCollection( ReplicationConfig replicationConfig, Destination.Factory destinationFactory) { this.replicationConfig = replicationConfig; this.destinationFactory = destinationFactory; } /** * Get all destinations matching the specified type. * * @param filterType type of destination. * @return list of destinations matching the specified filter type. */ public List<Destination> getAll(FilterType filterType) { if (replicationConfig.reloadIfNeeded()) { try { load(); } catch (ConfigInvalidException e) {
import java.util.Objects; import java.util.Set; import java.util.function.Predicate; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.URIish; /** Collection of Git repositories destinations for replication. */ public class DestinationsCollection { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final ReplicationConfig replicationConfig; private final Destination.Factory destinationFactory; private List<Destination> allDestinations; @Inject DestinationsCollection( ReplicationConfig replicationConfig, Destination.Factory destinationFactory) { this.replicationConfig = replicationConfig; this.destinationFactory = destinationFactory; } /** * Get all destinations matching the specified type. * * @param filterType type of destination. * @return list of destinations matching the specified filter type. */ public List<Destination> getAll(FilterType filterType) { if (replicationConfig.reloadIfNeeded()) { try { load(); } catch (ConfigInvalidException e) {
CheckerUuid checkerUuid = createCheckerInServer(createArbitraryCheckerInput()); boolean exists = checkerOperations.checker(checkerUuid).exists(); assertThat(exists).isTrue(); } @Test public void notExistingCheckerCanBeCheckedForExistence() throws Exception { String notExistingCheckerUuid = "test:not-existing-checker"; boolean exists = checkerOperations.checker(notExistingCheckerUuid).exists(); assertThat(exists).isFalse(); } @Test public void retrievingCheckerForInvalidUuidFails() throws Exception { exception.expect(IllegalArgumentException.class); checkerOperations.checker(notExistingCheckerUuid).get(); } @Test public void retrievingNotExistingCheckerFails() throws Exception { String notExistingCheckerUuid = "foo:bar"; exception.expect(IllegalStateException.class); checkerOperations.checker(notExistingCheckerUuid).get(); } @Test public void checkerNotCreatedByTestApiCanBeRetrieved() throws Exception { CheckerInput input = createArbitraryCheckerInput(); input.uuid = "test:unique-checker-not-created-via-test-API"; CheckerUuid checkerUuid = createCheckerInServer(input);
} @Override public Check get() throws Exception { return checks .getCheck(key, GetCheckOptions.defaults()) .orElseThrow(() -> new IllegalStateException("Tried to get non-existing test check")); } @Override public ImmutableMap<RevId, String> notesAsText() throws Exception { try (Repository repo = repoManager.openRepository(key.repository()); RevWalk rw = new RevWalk(repo)) { Ref checkRef = repo.getRefDatabase().exactRef(CheckerRef.checksRef(key.patchSet().changeId)); checkNotNull(checkRef); NoteMap notes = NoteMap.read(reader, rw.parseCommit(checkRef.getObjectId())); ImmutableMap.Builder<RevId, String> raw = ImmutableMap.builder(); for (Note note : notes) { raw.put( new RevId(note.name()), new String(notes.getCachedBytes(note.toObjectId(), Integer.MAX_VALUE))); } return raw.build(); } } @Override public CheckInfo asInfo(ListChecksOption... options) throws Exception {
Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/heads/stable-2.16", AN_OBJECT_ID_1); assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse(); } @Test public void compareAndPutShouldAlwaysIngoreIgnoredRefs() throws Exception { Ref existingRef = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_1); Ref oldRefToIgnore = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_2); Ref nullRef = SharedRefDatabase.NULL_REF; String projectName = A_TEST_PROJECT_NAME; assertThat( zkSharedRefDatabase.compareAndPut( A_TEST_PROJECT_NAME, existingRef, SharedRefDatabase.NULL_REF)) .isTrue(); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRefToIgnore, newRef)).isTrue(); } @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); } }
} @Test public void compareAndPutShouldAlwaysIngoreIgnoredRefs() throws Exception { Ref existingRef = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_1); Ref oldRefToIgnore = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_2); Ref newRef = SharedRefDatabase.NULL_REF; String projectName = A_TEST_PROJECT_NAME; // This ref should be ignored even if newRef is null assertThat(zkSharedRefDatabase.compareAndPut(A_TEST_PROJECT_NAME, existingRef, nullRef)) .isTrue(); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRefToIgnore, newRef)).isTrue(); } @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); } }
} return predicate; } private static boolean hasStatusPredicate(Predicate<ChangeData> predicate) { if (predicate instanceof IndexPredicate) { return ((IndexPredicate<ChangeData>) predicate) .getField() .getName() .equals(ChangeField.STATUS.getName()); } return predicate.getChildren().stream().anyMatch(CheckerQuery::hasStatusPredicate); } // TODO(ekempin): Retrying the query should be done by ChangeQueryProcessor. private List<ChangeData> executeIndexQueryWithRetry(Predicate<ChangeData> predicate) throws OrmException { try { return retryHelper.execute( ActionType.INDEX_QUERY, () -> changeQueryProcessorProvider.get().query(predicate).entities(), OrmException.class::isInstance); } catch (Exception e) { Throwables.throwIfUnchecked(e); Throwables.throwIfInstanceOf(e, OrmException.class); throw new OrmException(e); } } }
try { predicate = createQueryPredicate(checker); } catch (ConfigInvalidException e) { logger.atWarning().withCause(e).log( "skipping invalid query for checker %s", checker.getUuid()); return false; } return predicate.asMatchable().match(cd); } public List<ChangeData> queryMatchingChanges(Checker checker) throws ConfigInvalidException, OrmException { return executeIndexQueryWithRetry(createQueryPredicate(checker)); } private Predicate<ChangeData> createQueryPredicate(Checker checker) throws ConfigInvalidException { Predicate<ChangeData> predicate = new ProjectPredicate(checker.getRepository().get()); if (checker.getQuery().isPresent()) { String query = checker.getQuery().get(); Predicate<ChangeData> predicateForQuery; try { predicateForQuery = queryBuilder.parse(query); } catch (QueryParseException e) { throw new ConfigInvalidException( String.format("change query of checker %s is invalid: %s", checker.getUuid(), query), e); } if (!predicateForQuery.isMatchable()) {
try { UrlValidator.clean(CheckerTestData.INVALID_URL); assert_().fail("expected BadRequestException"); } catch (BadRequestException e) { assertMessage(e, "only http/https URLs supported", CheckerTestData.INVALID_URL); } } @Test public void verifyTestQueries() throws Exception { assertInvalidQuery( CheckerTestData.QUERY_WITH_UNSUPPORTED_OPERATOR, "unsupported operator", CheckerTestData.UNSUPPORTED_OPERATOR); assertInvalidQuery(CheckerTestData.INVALID_QUERY, "invalid", CheckerTestData.INVALID_QUERY); } @Test public void verifyTooLongQuery() throws Exception { String query = CheckerTestData.longQueryWithSupportedOperators(5); assertThat(query).isEqualTo("file:foo file:foo file:foo file:foo file:foo"); CheckerQuery.clean(query); } private static void assertInvalidQuery(String query, String... expectedMessageParts) { try { CheckerQuery.clean(query); assert_().fail("expected ConfigInvalidException"); } catch (ConfigInvalidException e) { assertMessage(e, expectedMessageParts); } } private static void assertMessage(Exception e, String... expectedMessageParts) { for (String expectedMessagePart : expectedMessageParts) { assertThat(e).hasMessageThat().ignoringCase().contains(expectedMessagePart); } } }
private void queueEvaluationIfNecessary(String repositoryPath) { if (lastCheckExpired(repositoryPath)) { EvaluationTask evaluationTask = evaluationTaskFactory.create(repositoryPath); if (queuedEvaluationTasks.add(evaluationTask)) { Future<?> future = executor.submit(evaluationTask); addTaskListener(future, evaluationTask); timestamps.put(repositoryPath, System.currentTimeMillis()); } }
private void addTaskListener(Future<?> future, EvaluationTask evaluationTask) { ListenableFuture<?> listenableFuture = JdkFutureAdapters.listenInPoolThread(future); listenableFuture.addListener( new Runnable() { public void run() { queuedEvaluationTasks.remove(evaluationTask); } }, MoreExecutors.directExecutor());
private void addTaskListener(Future<?> future, EvaluationTask evaluationTask) { ListenableFuture<?> listenableFuture = JdkFutureAdapters.listenInPoolThread(future); listenableFuture.addListener( new Runnable() { public void run() { queuedEvaluationTasks.remove(evaluationTask); } }, MoreExecutors.directExecutor());
public void createEvaluator() { when(event.getProjectName()).thenReturn(NAME_KEY.get()); when(config.getExpireTimeRecheck()).thenReturn(0L); when(gerritConfig.getInt( "receive", null, "threadPoolSize", Runtime.getRuntime().availableProcessors())) .thenReturn(1); /** Repositories */ when(repository.getDirectory()).thenReturn(new File(REPOSITORY_PATH)); when(repositoryOther.getDirectory()).thenReturn(new File(REPOSITORY_PATH_OTHER)); /** Tasks */ taskSamePathCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH); taskSamePathNotCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH); taskDifferentPath = new EvaluationTask(null, null, null, REPOSITORY_PATH_OTHER); /** Task factory */ Factory eventTaskFactory = mock(Factory.class); when(eventTaskFactory.create(REPOSITORY_PATH)) .thenReturn(taskSamePathNotCompleted) .thenReturn(taskSamePathCompleted); when(eventTaskFactory.create(REPOSITORY_PATH_OTHER)).thenReturn(taskDifferentPath); /** Executor */ when(executor.submit(taskSamePathCompleted)) .thenReturn(CompletableFuture.completedFuture(null));
taskDifferentPath = new EvaluationTask(null, null, null, REPOSITORY_PATH_OTHER); /** Task factory */ Factory eventTaskFactory = mock(Factory.class); when(eventTaskFactory.create(REPOSITORY_PATH)) .thenReturn(taskSamePathNotCompleted) .thenReturn(taskSamePathCompleted); when(eventTaskFactory.create(REPOSITORY_PATH_OTHER)).thenReturn(taskDifferentPath); /** Executor */ when(executor.submit(taskSamePathCompleted)) .thenReturn(CompletableFuture.completedFuture(null)); when(executor.submit(taskSamePathNotCompleted)).thenReturn(new CompletableFuture<>()); when(executor.submit(taskDifferentPath)).thenReturn(CompletableFuture.completedFuture(null)); evaluator = new Evaluator(executor, eventTaskFactory, repoManager, config, gerritConfig);
public static final String GLOBAL_CAPABILITIES = "GLOBAL_CAPABILITIES"; /** Pattern that matches all references in a project. */ public static final String ALL = "refs/*"; /** Pattern that matches all branches in a project. */ public static final String HEADS = "refs/heads/*"; /** Prefix that triggers a regular expression pattern. */ public static final String REGEX_PREFIX = "^"; /** Name of the access section. It could be a ref pattern or something else. */ private String name; private List<Permission> permissions; public AccessSection(String name) { this.name = name; this.permissions = new ArrayList<>(); } /** @return true if the name is likely to be a valid reference section name. */ public static boolean isValidRefSectionName(String name) { return name.startsWith("refs/") || name.startsWith("^refs/"); } public String getName() { return name; } public ImmutableList<Permission> getPermissions() {
public static final String GLOBAL_CAPABILITIES = "GLOBAL_CAPABILITIES"; /** Pattern that matches all references in a project. */ public static final String ALL = "refs/*"; /** Pattern that matches all branches in a project. */ public static final String HEADS = "refs/heads/*"; /** Prefix that triggers a regular expression pattern. */ public static final String REGEX_PREFIX = "^"; /** Name of the access section. It could be a ref pattern or something else. */ private String name; private List<Permission> permissions; public AccessSection(String name) { this.name = name; this.permissions = new ArrayList<>(); } /** @return true if the name is likely to be a valid reference section name. */ public static boolean isValidRefSectionName(String name) { return name.startsWith("refs/") || name.startsWith("^refs/"); } public String getName() { return name; } public ImmutableList<Permission> getPermissions() {
public AccessSection(String name) { this.name = name;
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.ConfigInvalidException; /** Listener of the configuration loading events. */ public interface ReplicationConfigListener { /** Invoked just before replication.config is about to be loaded. */ void beforeLoad(); /** * Invoked just after replication.config is loaded into memory. * * @throws ConfigInvalidException if the loaded configuration is not valid */
private void innerTest() throws Exception { try { outer(); fail("should throw"); } catch (IllegalStateException e) { StackTraceElement[] trimmed = SuperManifestRefUpdatedListener.trimStack( e.getStackTrace(), Thread.currentThread().getStackTrace()[1]); String str = Arrays.toString(trimmed); assertThat(str).doesNotContain("trimStackTrace"); assertThat(str).contains("innerTest"); }
// Project name is scoped by test, so we need to get it from our initial change Project.NameKey projectNameKey = initialResult.getChange().project(); String projectName = projectNameKey.get(); createBranch(new Branch.NameKey(projectName, "ds_one")); createBranch(new Branch.NameKey(projectName, "ds_two")); initialResult.assertOkStatus(); merge(initialResult); // Create normalUserGroup, containing user, and contextUserGroup, containing contextUser String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get(); gApi.groups().id(normalUserGroup).addMembers(user.id().toString()); AccountApi contextUserApi = gApi.accounts().create("someContextUser"); String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get(); gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name); // Grant exclusive +2 to context user grantLabel( "Code-Review", -2, 2, projectNameKey, "refs/heads/ds_one", false,
// Project name is scoped by test, so we need to get it from our initial change Project.NameKey projectNameKey = initialResult.getChange().project(); String projectName = projectNameKey.get(); createBranch(new Branch.NameKey(projectName, "ds_one")); createBranch(new Branch.NameKey(projectName, "ds_two")); initialResult.assertOkStatus(); merge(initialResult); // Create normalUserGroup, containing user, and contextUserGroup, containing contextUser String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get(); gApi.groups().id(normalUserGroup).addMembers(user.id().toString()); AccountApi contextUserApi = gApi.accounts().create("randomContextUser"); String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get(); gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name); // Grant +2 to context user, since it doesn't have it by default grantLabel( "Code-Review", -2, 2, projectNameKey, "refs/heads/*", false,
private final PermissionBackend permissionBackend; private final Map<String, CommandProvider> commands; private final AtomicReference<Command> atomicCmd; private final DynamicSet<SshExecuteCommandInterceptor> commandInterceptors; @Argument(index = 0, required = false, metaVar = "COMMAND", handler = SubcommandHandler.class) private String commandName; @Argument(index = 1, multiValued = true, metaVar = "ARG") private List<String> args = new ArrayList<>(); @Inject DispatchCommand( PermissionBackend permissionBackend, DynamicSet<SshExecuteCommandInterceptor> commandInterceptors, @Assisted Map<String, CommandProvider> all) { this.permissionBackend = permissionBackend; commands = all; atomicCmd = Atomics.newReference(); this.commandInterceptors = commandInterceptors; } Map<String, CommandProvider> getMap() { return commands; } @Override public void start(Environment env) throws IOException { try { parseCommandLine(); if (Strings.isNullOrEmpty(commandName)) { StringWriter msg = new StringWriter(); msg.write(usage()); throw die(msg.toString()); }
} bc.setName(actualCommandName); bc.setArguments(args.toArray(new String[args.size()])); } else if (!args.isEmpty()) { throw die(commandName + " does not take arguments"); } for (SshExecuteCommandInterceptor commandInterceptor : commandInterceptors) { if (!commandInterceptor.accept(actualCommandName, args)) { throw new UnloggedFailure( 126, String.format( "blocked by %s, contact gerrit administrators for more details", commandInterceptor.name())); } } provideStateTo(cmd); atomicCmd.set(cmd); cmd.start(env); } catch (UnloggedFailure e) { String msg = e.getMessage(); if (!msg.endsWith("\n")) { msg += "\n"; } err.write(msg.getBytes(ENC)); err.flush(); onExit(e.exitCode); } } private void checkRequiresCapability(Command cmd) throws UnloggedFailure { String pluginName = null; if (cmd instanceof BaseCommand) { pluginName = ((BaseCommand) cmd).getPluginName();
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.sshd; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; @ExtensionPoint public interface SshExecuteCommandInterceptor { /** * Check the command and return false if this command must not be run. * * @param command the command * @param arguments the list of arguments * @return whether or not this command with these arguments can be executed */ boolean accept(String command, List<String> arguments); default String name() { return this.getClass().getSimpleName(); } }
if (!getName().isEmpty()) { actualCommandName = getName() + " " + commandName; } bc.setName(actualCommandName); bc.setArguments(args.toArray(new String[args.size()])); } else if (!args.isEmpty()) { throw die(commandName + " does not take arguments"); } for (SshExecuteCommandInterceptor commandInterceptor : commandInterceptors) { if (!commandInterceptor.accept(actualCommandName, args)) { throw new UnloggedFailure( 126, "blocked by " + commandInterceptor.name() + ", contact gerrit administrators for more details"); } } provideStateTo(cmd); atomicCmd.set(cmd); cmd.start(env); } catch (UnloggedFailure e) { String msg = e.getMessage(); if (!msg.endsWith("\n")) { msg += "\n"; } err.write(msg.getBytes(ENC)); err.flush(); onExit(e.exitCode); } } private void checkRequiresCapability(Command cmd) throws UnloggedFailure { String pluginName = null; if (cmd instanceof BaseCommand) {
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.sshd; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; @ExtensionPoint public interface SshExecuteCommandInterceptor { /** * Check the command and return false if this command must not be run. * * @param command the command * @param arguments the list of arguments * @return whether or not this command with this arguments can be executed */ boolean accept(String command, List<String> arguments); default String name() { return this.getClass().getSimpleName(); } }
RevisionCreatedListener.Event event, Map<String, ImmutableList<Match>> findings) throws RestApiException { long startNanos = System.nanoTime(); metrics.reviewCount.increment(); metrics.reviewCountByProject.increment(project); try { boolean tpAllowed = scannerConfig.isThirdPartyAllowed(project); boolean reviewRequired = false; boolean hasAlwaysReview = false; for (Map.Entry<String, ImmutableList<Match>> entry : findings.entrySet()) { if (entry.getValue() == ALWAYS_REVIEW) { reviewRequired = true; break; } PartyType pt = partyType(entry.getValue()); if (pt.compareTo(THIRD_PARTY) > 0) { reviewRequired = true; break; } if (pt == THIRD_PARTY && !tpAllowed) { reviewRequired = true; break; } } ChangeResource change = getChange(event, scannerConfig.fromAccountId); ReviewInput ri = new ReviewInput() .message("Copyright scan") .label(scannerConfig.reviewLabel, reviewRequired ? -1 : +2); if (reviewRequired) {
public void stop() { if (scheduledCleanupTask != null) { scheduledCleanupTask.cancel(true); scheduledCleanupTask = null; }
batchUpdate.addCommand(new ReceiveCommand(ref.getObjectId(), ObjectId.zeroId(), refName)); } batchUpdate.execute(rw, NullProgressMonitor.INSTANCE); for (ReceiveCommand command : batchUpdate.getCommands()) { if (command.getResult() != ReceiveCommand.Result.OK) { throw new IOException( String.format( "Unstar change %d failed, ref %s could not be deleted: %s", changeId.get(), command.getRefName(), command.getResult())); } } } } public ImmutableMap<Account.Id, StarRef> byChange(Change.Id changeId) throws OrmException { try (Repository repo = repoManager.openRepository(allUsers)) { ImmutableMap.Builder<Account.Id, StarRef> builder = ImmutableMap.builder(); for (String refPart : getRefNames(repo, RefNames.refsStarredChangesPrefix(changeId))) { Integer id = Ints.tryParse(refPart);
void execute(PersonIdent refLogIdent, String refLogMessage, PushCertificate pushCert) { if (allUsersRepo == null || allUsersRepo.cmds.isEmpty()) { return; } // There are operations to be performed asynchronously, so we can't close this early. The async // operation will close the repo. canCloseEarly = false; @SuppressWarnings("unused") Future<?> possiblyIgnoredError = executor.submit( () -> { try (OpenRepo allUsersRepo = OpenRepo.open(repoManager, allUsersName)) { allUsersRepo.addUpdates(draftUpdates); allUsersRepo.flush(); BatchRefUpdate bru = allUsersRepo.repo.getRefDatabase().newBatchUpdate(); bru.setPushCertificate(pushCert); if (refLogMessage != null) { bru.setRefLogMessage(refLogMessage, false); } else { bru.setRefLogMessage( firstNonNull(NoteDbUtil.guessRestApiHandler(), "Update NoteDb refs"), false); } bru.setRefLogIdent(refLogIdent != null ? refLogIdent : serverIdent.get()); bru.setAtomic(true); allUsersRepo.cmds.addTo(bru); bru.setAllowNonFastForwards(true); RefUpdateUtil.executeChecked(bru, allUsersRepo.rw);
import com.google.gerrit.server.config.AllProjectsName; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.inject.Inject; import com.google.inject.Singleton; /** * Schema upgrade implementation. * * <p>Implementations must have a single non-private constructor with no arguments (e.g. the default * constructor). */ interface NoteDbSchemaVersion { @Singleton class Arguments { final GitRepositoryManager repoManager; final AllProjectsName allProjects; final AllUsersName allUsers; @Inject Arguments( GitRepositoryManager repoManager, AllProjectsName allProjects, AllUsersName allUsersName) { this.repoManager = repoManager; this.allProjects = allProjects; this.allUsersName = allUsersName; } } void upgrade(Arguments args, UpdateUI ui) throws Exception; }
protected boolean shouldSendMessage() { if (user.equals(callingUser)) { // Send email if the user self-added a key; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly added. return true; } try { // Don't email if an administrator added a key on behalf of the user. permissionBackend.user(callingUser).check(GlobalPermission.ADMINISTRATE_SERVER); return false; } catch (AuthException | PermissionBackendException e) { // Send email if a non-administrator modified the keys, e.g. by MODIFY_ACCOUNT. return true; }
protected boolean shouldSendMessage() { if (sshKey == null && gpgKeys == null) { // Don't email if no keys were added. return false; } if (user.equals(callingUser)) { // Send email if the user self-added a key; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly added. return true; } try { // Don't email if an administrator removed a password on behalf of the user. permissionBackend.user(callingUser).check(GlobalPermission.ADMINISTRATE_SERVER); return false; } catch (AuthException | PermissionBackendException e) { // Send email if a non-administrator modified the keys, e.g. by MODIFY_ACCOUNT. return true; }
} @Override public Response<?> apply(AccountResource.SshKey rsrc, Input input) throws AuthException, OrmException, RepositoryNotFoundException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.user(self).check(GlobalPermission.ADMINISTRATE_SERVER); } IdentifiedUser user = rsrc.getUser(); authorizedKeys.deleteKey(user.getAccountId(), rsrc.getSshKey().getKey().get()); try { deleteKeyFactory.create(user, "SSH").send(); } catch (EmailException e) { log.error( "Cannot send SSH key deletion message to "" + user.getAccount().getPreferredEmail(), e); } sshKeyCache.evict(user.getUserName()); return Response.none(); } }
if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.user(self).check(GlobalPermission.ADMINISTRATE_SERVER); } IdentifiedUser user = rsrc.getUser(); authorizedKeys.deleteKey(user.getAccountId(), rsrc.getSshKey().getKey().get()); try { deleteKeyFactory.create(rsrc.getUser(), "SSH").send(); } catch (EmailException e) { log.error( "Cannot send SSH key deletion message to {}", user.getAccount().getPreferredEmail(), e); } sshKeyCache.evict(user.getUserName()); return Response.none(); } }
import java.util.List; import java.util.stream.Collectors; import java.util.stream.Stream; import org.eclipse.jgit.lib.BatchRefUpdate; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.transport.ReceiveCommand.Result; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate; private final RefDatabase refDb; private final SharedRefDatabase<? extends AutoCloseable> sharedRefDb; private final String projectName; public static class RefPair { public final Ref oldRef; public final Ref newRef; public final Exception exception; RefPair(Ref oldRef, Ref newRef) { this.oldRef = oldRef; this.newRef = newRef; this.exception = null; }
} @Override public BatchRefUpdate addProposedTimestamp(ProposedTimestamp ts) { return batchRefUpdate.addProposedTimestamp(ts); } @Override public void execute(RevWalk walk, ProgressMonitor monitor, List<String> options) throws IOException { executeWrapper(walk, monitor, options); } @Override public void execute(RevWalk walk, ProgressMonitor monitor) throws IOException { executeWrapper(walk, monitor, Collections.EMPTY_LIST); } @Override public String toString() { return batchRefUpdate.toString(); } private void validateBatchRefUpdateAndApply( Stream<RefPair> oldRefs, RevWalk walk, ProgressMonitor monitor, List<String> options) throws Exception { List<RefPair> refsToUpdate = oldRefs.sorted(comparing(RefPair::hasFailed).reversed()).collect(Collectors.toList()); if (refsToUpdate.isEmpty()) { return; } if (refsToUpdate.get(0).hasFailed()) { RefPair failedRef = refsToUpdate.get(0); throw new IOException( "Failed to fetch ref entries" + failedRef.newRef.getName(), failedRef.exception); }
} try (CloseableSet<AutoCloseable> locks = new CloseableSet()) { assertBatchCommandsAreInSync(refsToUpdate, locks); if (options.isEmpty()) { batchRefUpdate.execute(walk, monitor); } else { batchRefUpdate.execute(walk, monitor, options); } updateSharedDBForSuccessfulCommands(batchRefUpdate.getCommands().stream()); } catch (Exception e) { logger.atWarning().log("Failed to process batch update %s", e.getMessage()); throw e; } } private void updateSharedDBForSuccessfulCommands(Stream<ReceiveCommand> commandStream) throws IOException { List<RefPair> successfulRefPairs = commandStream .filter(cmd -> cmd.getResult() == Result.OK) .map( cmd -> new RefPair( cmd.getOldId() == null ? sharedRefDb.NULL_REF : sharedRefDb.newRef(cmd.getRefName(), cmd.getOldId()), sharedRefDb.newRef(cmd.getRefName(), cmd.getNewId()))) .collect(Collectors.toList()); for (RefPair successfulRefPair : successfulRefPairs) {
logger.atWarning().log("Failed to apply full batch %s", e.getMessage()); throw e; } } private void updateSharedDBForSuccessfulCommands(Stream<ReceiveCommand> commandStream) throws IOException { List<RefPair> successfulRefPairs = commandStream .filter(cmd -> cmd.getResult() == Result.OK) .map( cmd -> new RefPair( oldRefs.getOrDefault(cmd.getNewId(), sharedRefDb.NULL_REF), sharedRefDb.newRef(cmd.getRefName(), cmd.getNewId()))) .collect(Collectors.toList()); for (RefPair successfulRefPair : successfulRefPairs) { sharedRefDb.compareAndPut(projectName, successfulRefPair.oldRef, successfulRefPair.newRef); } } private void assertBatchCommandsAreInSync( List<RefPair> refsToUpdate, CloseableSet<AutoCloseable> locks) throws Exception { for (RefPair refPair : refsToUpdate) { Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null
} } private void assertBatchCommandsAreInSync( List<RefPair> refsToUpdate, CloseableSet<AutoCloseable> locks) throws Exception { for (RefPair refPair : refsToUpdate) { Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null ? refPair.newRef : refPair.oldRef; String resourceLockKey = String.format("%s-%s", projectName, nonNullRef.getName()); locks.addResourceIfNotExist( resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); boolean isInnSync; if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInnSync = sharedRefDb.isMostRecentRefVersion(projectName, refPair.oldRef); } else { isInnSync = !sharedRefDb.isPresent(projectName, refPair.getName()); } if (!isInnSync) { String errorMessage = String.format(
Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null ? refPair.newRef : refPair.oldRef; // Doesn't have to be the actual Path we lock but just a unique identifier of the ref String resourceLockKey = String.format("%s-%s", projectName, nonNullRef.getName()); locks.addResourceIfNotExist( resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); boolean isInSync; if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInnSync = sharedRefDb.isMostRecentRefVersion(projectName, refPair.oldRef); } else { isInnSync = !sharedRefDb.isPresent(projectName, refPair.getName()); } if (!isInnSync) { String errorMessage = String.format( "Ref %s not in sync with sharedDb, aborting batch", refPair.oldRef.getName()); logger.atWarning().log(errorMessage); throw new Exception(errorMessage); } } }
if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInnSync = sharedRefDb.isMostRecentRefVersion(projectName, refPair.oldRef); } else { isInnSync = !sharedRefDb.isPresent(projectName, refPair.getName()); } if (!isInnSync) { String errorMessage = String.format( "Ref %s not in sync with sharedDb, aborting batch", refPair.oldRef.getName()); logger.atWarning().log(errorMessage); throw new NoSuchElementException(errorMessage); } } } private Stream<RefPair> getRefsPairs(List<ReceiveCommand> receivedCommands) { return receivedCommands.stream().map(this::getRefPairForCommand); } private RefPair getRefPairForCommand(ReceiveCommand command) { try { switch (command.getType()) { case CREATE: return new RefPair(SharedRefDatabase.NULL_REF, getNewRef(command)); case UPDATE: case UPDATE_NONFASTFORWARD: return new RefPair(refDb.getRef(command.getRefName()), getNewRef(command)); case DELETE:
} } catch (IOException e) { return new RefPair(command.getRef(), e); } } private void executeWrapper(RevWalk walk, ProgressMonitor monitor, List<String> options) throws IOException { try { updateSharedRefDb(getRefsPairs(batchRefUpdate.getCommands()), walk, monitor, options); } catch (Exception e) { String errorMessage = "Failing batch executeWrapper in MultiSiteBatchRefUpdate"; logger.atWarning().withCause(e).log(errorMessage); throw new IOException(errorMessage); } } private Ref getNewRef(ReceiveCommand command) { return sharedRefDb.newRef(command.getRefName(), command.getNewId()); } public static class CloseableSet<T extends AutoCloseable> implements AutoCloseable { private final HashMap<String, AutoCloseable> elements; public CloseableSet() { this(new HashMap<String, AutoCloseable>()); } public CloseableSet(HashMap<String, AutoCloseable> elements) { this.elements = elements; } public void addResourceIfNotExist(
if (refUpdateBase.getRef().getObjectId() == null || refUpdateBase.getRef().getObjectId().equals(ObjectId.zeroId())) { // If we are CREATING a new ref we don't want it to have been written by // any other instance if (sharedDb.isPresent(projectName, refUpdateBase.getName())) throw new IOException( String.format( "Unable to create ref '%s', trying to create a new ref but there is a value " + "already in the shared ref db", refUpdateBase.getName())); } else { if (!sharedDb.isMostRecentRefVersion(projectName, refUpdateBase.getRef())) throw new IOException( String.format( "Unable to update ref '%s', the local objectId '%s' is not equal to the one " + "in the shared ref datasuper", refUpdateBase.getName(), refUpdateBase.getOldObjectId())); } } private void checkSharedDbForRefDelete() throws IOException { Ref oldRef = this.getRef(); try {
*/ boolean compareAndRemove(String project, Ref oldRef) throws IOException; /** * Some references should not be stored in the SharedRefDatabase. * * @param ref * @return true if it's to be ignore; false otherwise */ default boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } /** * Verify if the DB contains a value for the specific project and ref name * * @param projectName * @param refName * @return */ boolean exists(String projectName, String refName) throws Exception; }
public ZkSharedRefDatabase( CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return ignoreRefInSharedDb(oldRef) || compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { if (ignoreRefInSharedDb(MoreObjects.firstNonNull(oldRef.getName(), newRef.getName()))) { return true; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(
// When validation of status fails doReturn(false).when(sharedRefDb).isMostRecentRefVersion(A_TEST_PROJECT_NAME, oldRef); RefUpdate refUpdate = RefFixture.RefUpdateStub.forSuccessfulUpdate(oldRef, newRef.getObjectId()); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, A_TEST_PROJECT_NAME, refUpdate); multiSiteRefUpdate.update(); } @Test(expected = Exception.class) public void newUpdateShouldFailIfSharedDBUpdateFailsLeavingSystemInInconsistentStatus() throws Exception { doReturn(true).when(sharedRefDb).isMostRecentRefVersion(A_TEST_PROJECT_NAME, oldRef); // When compareAndPut fails doReturn(false).when(sharedRefDb).compareAndPut(A_TEST_PROJECT_NAME, oldRef, newRef); RefUpdate refUpdate = RefFixture.RefUpdateStub.forSuccessfulUpdate(oldRef, newRef.getObjectId()); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, A_TEST_PROJECT_NAME, refUpdate); multiSiteRefUpdate.update(); } @Test public void deleteShouldValidateAndSucceed() throws Exception { // When validation succeeds
// Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb; import static com.google.common.truth.Truth.assertThat; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.RefFixture; import java.io.IOException; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.Ref.Storage; import org.junit.Rule; import org.junit.Test; import org.junit.rules.TestName; public class RefSharedDatabaseTest implements RefFixture { @Rule public TestName nameRule = new TestName(); @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); } @Test public void shouldCreateANewRef() { ObjectId objectId = AN_OBJECT_ID_1;
public void setup() { zookeeperContainer = new ZookeeperTestContainerSupport(false); zkSharedRefDatabase = new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30), 1000l);
protected boolean shouldSendMessage() { if (user.equals(callingUser)) { // Send email if the user self-removed a key; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly deleted. return true; } try { // Don't email if an administrator removed a key on behalf of the user. permissionBackend.user(callingUser).check(GlobalPermission.ADMINISTRATE_SERVER); return false; } catch (AuthException | PermissionBackendException e) { // Send email if a non-administrator modified the keys, e.g. by MODIFY_ACCOUNT. return true; }
if (extId == null) { throw new ResourceNotFoundException(); } ExternalId newExtId = ExternalId.createWithPassword(extId.key(), extId.accountId(), extId.email(), newPassword); externalIdsUpdate.create().upsert(newExtId); try { httpPasswordSenderFactory.create(user).send(); } catch (EmailException e) { log.error( "Cannot send HttpPassword added or changed message to {}", user.getAccount().getPreferredEmail(), e); } return Strings.isNullOrEmpty(newPassword) ? Response.<String>none() : Response.ok(newPassword); } public static String generate() { byte[] rand = new byte[LEN]; rng.nextBytes(rand); byte[] enc = Base64.encodeBase64(rand, false); StringBuilder r = new StringBuilder(enc.length); for (int i = 0; i < enc.length; i++) { if (enc[i] == '=') { break; } r.append((char) enc[i]); } return r.toString(); } }
/** First line of {@link #message}. */ protected String subject; /** The complete description of the change the patch set introduces. */ protected String message; /** Identity of who wrote the patch set. May differ from {@link #committer}. */ protected UserIdentity author; /** Identity of who committed the patch set to the VCS. */ protected UserIdentity committer; /** List of parents of the patch set. */ protected List<ParentInfo> parents; /** ID of commit. */ protected ObjectId commitId; /** Optional user-supplied description for the patch set. */ protected String description; protected PatchSetInfo() {} public PatchSetInfo(PatchSet.Id k) { key = k; } public PatchSet.Id getKey() { return key; } public String getSubject() { return subject; } public void setSubject(String s) { if (s != null && s.length() > 255) { subject = s.substring(0, 255); } else {
public String message; public String parentUuid; public Range range; public String tag; // Hex commit SHA1 of the commit of the patchset to which this comment applies. Other classes call // this "commitId", but this class uses the old ReviewDb term "revId", and this field name is // serialized into JSON in NoteDb, so it can't easily be changed. Callers do not access this field // directly, and instead use the public getter/setter that wraps an ObjectId. private String revId; public String serverId; public boolean unresolved; /** * Whether the comment was parsed from a JSON representation (false) or the legacy custom notes * format (true). */ public transient boolean legacyFormat; public Comment(Comment c) { this( new Key(c.key), c.author.getId(), new Timestamp(c.writtenOn.getTime()), c.side, c.message, c.serverId, c.unresolved); this.lineNbr = c.lineNbr; this.realAuthor = c.realAuthor;
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.reviewdb.converter; import com.google.gerrit.proto.Entities; import com.google.protobuf.Parser; import org.eclipse.jgit.lib.ObjectId; /** * Proto converter for {@code ObjectId}s. * * <p>This converter uses the hex representation of object IDs embedded in a wrapper proto type, * rather than a more parsimonious implementation (e.g. a raw byte array), for two reasons: * * <ul>
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.reviewdb.converter; import static com.google.common.truth.Truth.assertThat; import static com.google.gerrit.proto.testing.SerializedClassSubject.assertThatSerializedClass; import com.google.common.collect.ImmutableMap; import com.google.gerrit.proto.Entities; import com.google.gerrit.proto.testing.SerializedClassSubject; import com.google.protobuf.Parser; import org.eclipse.jgit.lib.ObjectId; import org.junit.Test; public class ObjectIdProtoConverterTest {
public static String abbreviateName(AnyObjectId id) { return abbreviateName(id, ABBREV_STR_LEN);
/** * Abbreviate an ID's hex string representation to 7 chars. * * @param id object ID. * @return abbreviated hex string representation, exactly 7 chars. */ public static String abbreviateName(AnyObjectId id) { return abbreviateName(id, 7); } /** * Abbreviate an ID's hex string representation to {@code n} chars. * * @param id object ID. * @param n number of hex chars, 1 to 40. * @return abbreviated hex string representation, exactly {@code n} chars. */ public static String abbreviateName(AnyObjectId id, int n) { checkValidLength(n); return requireNonNull(id).abbreviate(n).name(); } /** * Abbreviate an ID's hex string representation uniquely to at least 7 chars. * * @param id object ID. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least 7 * chars. */
*/ public static String abbreviateName(AnyObjectId id, int n) { checkValidLength(n); return requireNonNull(id).abbreviate(n).name(); } /** * Abbreviate an ID's hex string representation uniquely to at least 7 chars. * * @param id object ID. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least 7 * chars. * @throws IOException if an error occurs while looking for ambiguous objects. */ public static String abbreviateName(AnyObjectId id, ObjectReader reader) throws IOException { return abbreviateName(id, ABBREVIATED_STRING_LENGTH, reader); } /** * Abbreviate an ID's hex string representation uniquely to at least {@code n} chars. * * @param id object ID. * @param n minimum number of hex chars. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least * {@code } chars. */
* @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least 7 * chars. */ public static String abbreviateName(AnyObjectId id, ObjectReader reader) throws IOException { return abbreviateName(id, ABBREVIATED_STRING_LENGTH, reader); } /** * Abbreviate an ID's hex string representation uniquely to at least {@code n} chars. * * @param id object ID. * @param n minimum number of hex chars, 1 to 40. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least * {@code } chars. */ public static String abbreviateName(AnyObjectId id, int n, ObjectReader reader) throws IOException { checkValidLength(n); return reader.abbreviate(id, n).name(); } private static void checkValidLength(int n) { checkArgument(n > 0); checkArgument(n <= Constants.OBJECT_ID_STRING_LENGTH); } private ObjectIds() {}
return abbreviateName(id, ABBREVIATED_STRING_LENGTH, reader); } /** * Abbreviate an ID's hex string representation uniquely to at least {@code n} chars. * * @param id object ID. * @param n minimum number of hex chars. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least * {@code n} chars. * @throws IOException if an error occurs while looking for ambiguous objects. */ public static String abbreviateName(AnyObjectId id, int n, ObjectReader reader) throws IOException { checkValidLength(n); return reader.abbreviate(id, n).name(); } private static void checkValidLength(int n) { checkArgument(n > 0); checkArgument(n <= Constants.OBJECT_ID_STRING_LENGTH); } private ObjectIds() {} }
private static String implicitMergeOf(ObjectId commit) { return "implicit merge of " + abbreviateName(commit);
} @FunctionalInterface private interface Func { void call() throws Exception; } private static void assertRuntimeException(Func func) throws Exception { try { func.call(); assert_().fail("Expected RuntimeException"); } catch (RuntimeException e) { // Expected. } } private static ObjectReader newReaderWithAmbiguousIds() throws Exception { // Recipe for creating ambiguous IDs courtesy of git core: // https://github.com/git/git/blob/df799f5d99ac51d4fc791d546de3f936088582fc/t/t1512-rev-parse-disambiguation.sh TestRepository<?> tr = new TestRepository<>(new InMemoryRepository(new DfsRepositoryDescription("repo"))); String blobData = "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nb1rwzyc3\n"; RevBlob blob = tr.blob(blobData); assertThat(blob.name()).isEqualTo(AMBIGUOUS_BLOB_ID.name()); assertThat(tr.tree(tr.file("a0blgqsjc", blob)).name()).isEqualTo(AMBIGUOUS_TREE_ID.name()); return tr.getRevWalk().getObjectReader(); } }
private static String implicitMergeOf(ObjectId commit) { return "implicit merge of " + abbreviateName(commit);
import com.googlesource.gerrit.plugins.lfs.LfsConfigurationFactory; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; @Singleton public class LfsFsDataDirectoryManager { private static final String KEY_DIRECTORY = "directory"; private final LfsConfigurationFactory configFactory; private final Path defaultDataDir; @Inject LfsFsDataDirectoryManager( LfsConfigurationFactory configFactory, @PluginData Path defaultDataDir) { this.configFactory = configFactory; this.defaultDataDir = defaultDataDir; } public Path ensureForBackend(LfsBackend backend) throws IOException { return getForBackend(backend, true); } public Path getForBackend(LfsBackend backend, boolean ensure) throws IOException { String dataDir = configFactory.getGlobalConfig().getString(backend.type.name(), backend.name, KEY_DIRECTORY); if (Strings.isNullOrEmpty(dataDir)) { return defaultDataDir; } if (ensure) { // note that the following method not only creates missing // directory/directories but throws exception when path // exists and points to file Path ensured = Files.createDirectories(Paths.get(dataDir.toString()));
} public Path getForBackend(LfsBackend backend, boolean ensure) throws IOException { String dataDir = configFactory.getGlobalConfig().getString(backend.type.name(), backend.name, KEY_DIRECTORY); if (Strings.isNullOrEmpty(dataDir)) { return defaultDataDir; } if (ensure) { // note that the following method not only creates missing // directory/directories but throws exception when path // exists and points to file Path ensured = Files.createDirectories(Paths.get(dataDir)); // we should at least make sure that directory is readable if (!Files.isReadable(ensured)) { throw new IOException("Path '" + ensured.toAbsolutePath() + "' cannot be accessed"); } return ensured; } return Paths.get(dataDir); } }
Integer id = Ints.tryParse(email.substring(0, at)); if (id != null) { return Optional.of(Account.id(id)); } } } return Optional.empty(); } public static String formatTime(PersonIdent ident, Timestamp t) { GitDateFormatter dateFormatter = new GitDateFormatter(Format.DEFAULT); // TODO(dborowitz): Use a ThreadLocal or use Joda. PersonIdent newIdent = new PersonIdent(ident, t); return dateFormatter.formatDate(newIdent); } /** * Returns the name of the REST API handler that is in the stack trace of the caller of this * method. */ static String guessRestApiHandler() { StackTraceElement[] trace = Thread.currentThread().getStackTrace(); int i = findRestApiServlet(trace); if (i < 0) { return null; } try { for (i--; i >= 0; i--) { String cn = trace[i].getClassName(); Class<?> cls = Class.forName(cn); if (RestModifyView.class.isAssignableFrom(cls) && cls != RetryingRestModifyView.class) { return viewName(cn); } } return null;
Future<?> possiblyIgnoredError = executor.submit( () -> { try (OpenRepo allUsersRepo = OpenRepo.open(repoManager, allUsersName)) { allUsersRepo.addUpdates(draftUpdates); allUsersRepo.flush(); BatchRefUpdate bru = allUsersRepo.repo.getRefDatabase().newBatchUpdate(); bru.setPushCertificate(pushCert); if (refLogMessage != null) { bru.setRefLogMessage(refLogMessage, false); } else { bru.setRefLogMessage( firstNonNull(NoteDbUtil.guessRestApiHandler(), "Update NoteDb refs async"), false); } bru.setRefLogIdent(refLogIdent != null ? refLogIdent : serverIdent.get()); bru.setAtomic(true); allUsersRepo.cmds.addTo(bru); bru.setAllowNonFastForwards(true); RefUpdateUtil.executeChecked(bru, allUsersRepo.rw); } catch (IOException e) { logger.atSevere().withCause(e).log( "Failed to delete draft comments asynchronously after publishing them"); } });
public void markCommentPublished(Comment c) { checkState(!delete.containsKey(key(c)), "comment already marked for deletion"); verifyComment(c); delete.put(key(c), DeleteReason.PUBLISHED);
private void addCommands() throws IOException { changeRepo.addUpdates(changeUpdates, Optional.of(maxUpdates)); if (!draftUpdates.isEmpty()) { boolean publishOnly = draftUpdates.values().stream().allMatch(ChangeDraftUpdate::canRunAsync); if (publishOnly) { updateAllUsersAsync.setDraftUpdates(draftUpdates); } else { allUsersRepo.addUpdates(draftUpdates); } } if (!robotCommentUpdates.isEmpty()) { changeRepo.addUpdates(robotCommentUpdates); } if (!rewriters.isEmpty()) { addRewrites(rewriters, changeRepo); } for (Change.Id id : toDelete) { doDelete(id); }
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.mail.send; import com.google.gerrit.common.errors.EmailException; import com.google.gerrit.extensions.api.changes.RecipientType; import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; public class HttpPasswordUpdateSender extends OutgoingEmail { public interface Factory { HttpPasswordUpdateSender create(IdentifiedUser user); } private final IdentifiedUser user; @AssistedInject public HttpPasswordUpdateSender( EmailArguments ea, IdentifiedUser callingUser, @Assisted IdentifiedUser user) { super(ea, "HttpPasswordUpdate"); this.callingUser = callingUser; this.user = user; } @Override protected void init() throws EmailException { super.init(); setHeader("Subject", "[Gerrit Code Review] HTTP password was either added, changed or deleted"); add(RecipientType.TO, new Address(getEmail())); } @Override protected boolean shouldSendMessage() {
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api.config; import com.google.gerrit.extensions.client.DiffPreferencesInfo; import com.google.gerrit.extensions.client.EditPreferencesInfo; import com.google.gerrit.extensions.client.GeneralPreferencesInfo; import com.google.gerrit.extensions.common.ServerInfo; import com.google.gerrit.extensions.restapi.NotImplementedException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.webui.TopMenu; import java.util.List; public interface Server { /** @return Version of server. */ String getVersion() throws RestApiException; ServerInfo getInfo() throws RestApiException; GeneralPreferencesInfo getDefaultPreferences() throws RestApiException; GeneralPreferencesInfo setDefaultPreferences(GeneralPreferencesInfo in) throws RestApiException; DiffPreferencesInfo getDefaultDiffPreferences() throws RestApiException; DiffPreferencesInfo setDefaultDiffPreferences(DiffPreferencesInfo in) throws RestApiException; EditPreferencesInfo getDefaultEditPreferences() throws RestApiException; EditPreferencesInfo setDefaultEditPreferences(EditPreferencesInfo in) throws RestApiException;
throws RestApiException { throw new NotImplementedException(); } @Override public EditPreferencesInfo getDefaultEditPreferences() throws RestApiException { throw new NotImplementedException(); } @Override public EditPreferencesInfo setDefaultEditPreferences(EditPreferencesInfo in) throws RestApiException { throw new NotImplementedException(); } @Override public ConsistencyCheckInfo checkConsistency(ConsistencyCheckInput in) throws RestApiException { throw new NotImplementedException(); } @Override public List<TopMenu.MenuEntry> topMenus() throws RestApiException { throw new NotImplementedException(); } } }
ChangeCheckerImpl.Factory changeCheckerFactory) { super(configuration.index().numStripedLocks()); this.indexer = indexer; this.indexExecutor = indexExecutor; this.oneOffCtx = oneOffCtx; this.changeCheckerFactory = changeCheckerFactory; Index indexConfig = configuration.index(); this.retryInterval = indexConfig != null ? indexConfig.retryInterval() : 0; this.maxTries = indexConfig != null ? indexConfig.maxTries() : 0; } @Override protected void doIndex(String id, Optional<ChangeIndexEvent> indexEvent) { doIndex(id, indexEvent, 0); } private void doIndex(String id, Optional<ChangeIndexEvent> indexEvent, int retryCount) throws IOException { try { ChangeChecker checker = changeCheckerFactory.create(id); Optional<ChangeNotes> changeNotes = checker.getChangeNotes(); if (changeNotes.isPresent()) { ChangeNotes notes = changeNotes.get(); reindex(notes); if (checker.isChangeUpToDate(indexEvent)) { if (retryCount > 0) {
ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns(colsProto.toBuilder().setTopic("topic").setHasTopic(true)) .build()); } @Test public void serializeOriginalSubject() throws Exception { assertRoundTrip( newBuilder() .columns(cols.toBuilder().originalSubject("The first patch set").build()) .build(), ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns( colsProto .toBuilder() .setOriginalSubject("The first patch set") .setHasOriginalSubject(true)) .build()); } @Test public void serializeSubmissionId() throws Exception { assertRoundTrip( newBuilder().columns(cols.toBuilder().submissionId("xyz").build()).build(), ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns(colsProto.toBuilder().setSubmissionId("xyz").setHasSubmissionId(true)) .build()); } @Test public void serializeAssignee() throws Exception {
public void onProjectDeleted(Event event) { String projectName = event.getProjectName(); logger.atInfo().log( "Deleting project '%s'. Will perform a cleanup in Shared-Ref database.", projectName); try { sharedDb.removeProject(projectName); } catch (IOException e) { // TODO: Add metrics for monitoring if it fails to delete logger.atSevere().log( String.format( "Project '%s' deleted from GIT but it was not able to fully cleanup" + " from Shared-Ref database", projectName), e); }
} public void addChange(String id, Map<Change.Id, ChangeResource> changes) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { addChange(id, changes, null); } public void addChange( String id, Map<Change.Id, ChangeResource> changes, ProjectState projectState) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { addChange(id, changes, projectState, true); } public void addChange( String id, Map<Change.Id, ChangeResource> changes, @Nullable ProjectState projectState, boolean useIndex) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { List<ChangeNotes> matched = useIndex ? changeFinder.find(id) : changeFromNotesFactory(id); List<ChangeNotes> toAdd = new ArrayList<>(changes.size()); boolean canMaintainServer; try { permissionBackend.currentUser().check(GlobalPermission.MAINTAIN_SERVER); canMaintainServer = true; } catch (AuthException | PermissionBackendException e) { canMaintainServer = false; } for (ChangeNotes notes : matched) { if (!changes.containsKey(notes.getChangeId())
import java.io.IOException; import java.util.concurrent.ExecutionException; import java.util.concurrent.TimeUnit; /** * Cache of {@link CombinedCheckState} per change. * * <p>In the absence of plugin-defined index fields, this cache is used to performantly populate the * {@code combinedState} field in {@code ChangeCheckInfo} in the query path. */ @Singleton public class CombinedCheckStateCache { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final String NAME = "combined_check_state"; public static Module module() { return new CacheModule() { @Override public void configure() { persist(NAME, CombinedCheckStateCacheKeyProto.class, CombinedCheckState.class) .version(1) .maximumWeight(10000) .diskLimit(-1) .keySerializer(new ProtobufSerializer<>(CombinedCheckStateCacheKeyProto.parser())) .valueSerializer(new EnumCacheSerializer<>(CombinedCheckState.class)) .loader(Loader.class); } }; } @Singleton static class Metrics {
// Pair of metric and manual counters, to work around the fact that metric classes have no // getters. private final Timer1<Boolean> reloadLatency; private final AtomicLongMap<Boolean> reloadCount; @Inject Metrics(MetricMaker metricMaker) { reloadLatency = metricMaker.newTimer( "checks/reload_combined_check_state", new Description("Latency for reloading combined check state") .setCumulative() .setUnit(Units.MILLISECONDS), Field.ofBoolean( "updated", "whether reloading resulted in updating the cached value")); reloadCount = AtomicLongMap.create(); } void recordReload(boolean dirty, long elapsed, TimeUnit timeUnit) { reloadLatency.record(dirty, elapsed, timeUnit); reloadCount.incrementAndGet(dirty); } long getReloadCount(boolean dirty) { return reloadCount.get(dirty); } } private final LoadingCache<CombinedCheckStateCacheKeyProto, CombinedCheckState> cache; private final Loader loader; private final Metrics metrics; @Inject CombinedCheckStateCache( @Named(NAME) LoadingCache<CombinedCheckStateCacheKeyProto, CombinedCheckState> cache, Loader loader,
void recordReload(boolean updated, Duration elapsed) { reloadLatency.record(updated, elapsed.toNanos(), NANOSECONDS); reloadCount.incrementAndGet(updated);
CombinedCheckState newState = loader.load(key); CombinedCheckState oldState = cache.getIfPresent(key); if (newState != oldState) { dirty = true; cache.put(key, newState); } else { dirty = false; } return newState; } finally { metrics.recordReload(updated, sw.elapsed()); } } /** * Update the state in the cache only if it changed. * * <p>This method does a cache lookup followed by a write, which is inherently racy. * Inconsistencies between the cache and the actual state should tend to get fixed up immediately * after a user views the change, since the read path calls {@link #reload(Project.NameKey, * PatchSet.Id)}. * * @param project project containing the change.
assertThat(cache.getStats()).since(start).hasHitCount(1); assertThat(cache.getStats()).since(start).hasMissCount(0); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(0); // Set non-required checker to FAILED, updating combined check state to WARNING. CheckInput checkInput = new CheckInput(); checkInput.state = CheckState.FAILED; checksApiFactory.revision(psId).id(checkerUuid).update(checkInput); // Incurs reload after updating check state. assertThat(cache.getStats()).since(start).hasHitCount(2); assertThat(cache.getStats()).since(start).hasMissCount(0); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(1); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.WARNING)); assertThat(cache.getStats()).since(start).hasHitCount(3); assertThat(cache.getStats()).since(start).hasMissCount(0);
import org.easymock.EasyMock; import org.junit.Test; public class ChecksSubmitRuleTest extends GerritBaseTests { @Test public void loadingCurrentPatchSetFails() throws Exception { ChecksSubmitRule checksSubmitRule = new ChecksSubmitRule(EasyMock.createStrictMock(CombinedCheckStateCache.class)); ChangeData cd = EasyMock.createStrictMock(ChangeData.class); expect(cd.project()).andReturn(Project.nameKey("My-Project")); expect(cd.getId()).andReturn(Change.id(1)); expect(cd.currentPatchSet()).andThrow(new StorageException("Fail for test")); replay(cd); Collection<SubmitRecord> submitRecords = checksSubmitRule.evaluate(cd, SubmitRuleOptions.defaults()); assertErrorRecord(submitRecords, "failed to load the current patch set of change 1"); } @Test public void getCombinedCheckStateFails() throws Exception { CombinedCheckStateCache cache = EasyMock.createStrictMock(CombinedCheckStateCache.class); expect(cache.reload(anyObject(), anyObject())).andThrow(new OrmException("Fail for test")); replay(cache); ChecksSubmitRule checksSubmitRule = new ChecksSubmitRule(cache);
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.events; import com.google.gson.Gson; import com.google.gson.TypeAdapter; import com.google.gson.TypeAdapterFactory; import com.google.gson.reflect.TypeToken; public final class AutoValueAdapterFactory implements TypeAdapterFactory { @SuppressWarnings("unchecked") @Override public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) { Class<? super T> rawType = type.getRawType();
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.events; import com.google.common.base.Supplier; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.inject.Provider; public class GsonEventDeserializerProvider implements Provider<Gson> { @Override public Gson get() { return new GsonBuilder() .registerTypeAdapter(Event.class, new EventDeserializer()) .registerTypeAdapter(Supplier.class, new SupplierSerializer()) .registerTypeAdapter(Supplier.class, new SupplierDeserializer())
private Change newChange() { Change change = new Change( Change.key(changeKey), Change.id(1000), Account.id(1000), Branch.nameKey(Project.nameKey("myproject"), "mybranch"), new Timestamp(System.currentTimeMillis())); return change;
public void refUpdatedEvent() { RefUpdatedEvent event = new RefUpdatedEvent(); RefUpdateAttribute refUpdatedAttribute = new RefUpdateAttribute(); refUpdatedAttribute.refName = "refs/heads/master"; event.refUpdate = createSupplier(refUpdatedAttribute); assertThatJsonMap(event) .containsExactly( "submitter", ImmutableMap.of("email", "some.user@domain.com"), "refUpdate", ImmutableMap.of("refName", "refs/heads/master"), "type", "ref-updated", "eventCreatedOn", 1.2543444E9);
* @return combined state. */ public static CombinedCheckState combine( ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { CheckStateCount checkStateCount = CheckStateCount.create(statesAndRequired); return combine(checkStateCount); } /** * Combines multiple per-check states into a single combined state based on the count result of * each check state. * * <p>See documentation of specific enum values for precise semantics. * * @param checkStateCount count of check states. * @return combined state. */ private static CombinedCheckState combine(CheckStateCount checkStateCount) { if (checkStateCount.failedRequiredCount() > 0) { return FAILED; } if (checkStateCount.inProgressOptionalCount() > 0 || checkStateCount.inProgressRequiredCount() > 0) { return IN_PROGRESS; } if (checkStateCount.failedOptionalCount() > 0) { return WARNING; } if (checkStateCount.successfulCount() > 0) { return SUCCESSFUL; } return NOT_RELEVANT; } private final boolean passing;
* @return whether the state represents a passing state. */ public boolean isPassing() { return passing; } @AutoValue public abstract static class CheckStateCount { /** * Get the count of each {@link CheckState}. * * @param statesAndRequired map of state to a list of booleans, one per check, indicating * whether that particular check is required in the context of a particular change. * @return the {@link CheckStateCount} of the given state map. */ public static CheckStateCount create( ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { int failedRequiredCount = 0; int failedOptionalCount = 0; int inProgressRequiredCount = 0; int inProgressOptionalCount = 0; int successfulCount = 0; for (Map.Entry<CheckState, Boolean> e : statesAndRequired.entries()) { CheckState state = e.getKey(); if (state.isInProgress()) { if (e.getValue()) { inProgressRequiredCount++; } else {
* whether that particular check is required in the context of a particular change. * @return the {@link CheckState} of the given state map. */ public static CheckStateCount create( ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { int failedRequiredCount = 0; int failedOptionalCount = 0; int inProgressRequiredCount = 0; int inProgressOptionalCount = 0; int successfulCount = 0; for (Map.Entry<CheckState, Boolean> checkStateAndRequiredState : statesAndRequired.entries()) { CheckState state = checkStateAndRequiredState.getKey(); if (state.isInProgress()) { if (e.getValue()) { inProgressRequiredCount++; } else { inProgressOptionalCount++; } } else if (state == CheckState.FAILED) { if (e.getValue()) { failedRequiredCount++; } else { failedOptionalCount++; } } else if (state == CheckState.SUCCESSFUL) { successfulCount++; } else if (state != CheckState.NOT_RELEVANT) {
public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) { Project.NameKey project = changeData.project(); Change.Id changeId = changeData.getId(); PatchSet.Id currentPathSetId; try { checks = listChecks .getAllChecks(project, changeData.notes(), changeData.currentPatchSet().getId()) .stream() .collect(ImmutableMap.toImmutableMap(c -> c.checkerUuid, c -> c)); } catch (OrmException | IOException e) { String errorMessage = String.format("failed to get all checks for change %s", changeId); logger.atSevere().withCause(e).log(errorMessage); return singletonRecordForRuleError(errorMessage); } // Gets all checkers applicable to the given change. ImmutableMap<String, Checker> appliedCheckers; try { appliedCheckers = checkers .checkersOf(project) .stream() .collect(ImmutableMap.toImmutableMap(c -> c.getUuid().toString(), c -> c)); } catch (IOException e) {
* * @param projectName project to be enforced * @param refName ref name to be enforced * @return the {@link EnforcePolicy} value */ public EnforcePolicy getPolicy(String projectName, String refName); /** * Get the enforcement policy for a project * * @param projectName * @return the {@link EnforcePolicy} value */ public EnforcePolicy getPolicy(String projectName); /** * Check if a refName should be ignored by shared Ref-Db * * @param refName * @return true if ref should be ignored; false otherwise */ default boolean isRefToBeIgnoredBySharedRefDb(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } }
Module sitePathModule = new AbstractModule() { @Override protected void configure() { bind(Path.class).annotatedWith(SitePath.class).toInstance(sitePath); } }; modules.add(sitePathModule); Module configModule = new GerritServerConfigModule(); modules.add(configModule); } else { modules.add(new GerritServerConfigModule()); } modules.add(new DropWizardMetricMaker.ApiModule()); return Guice.createInjector( PRODUCTION, LibModuleLoader.loadModules(cfgInjector, LibModuleType.DB_MODULE));
// You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server; /** Loadable module type for the different Gerrit injectors. */ public enum LibModuleType { /** Module for the sysInjector. */ SYS_MODULE("Module"), /** Module for the dbInjector. */ DB_MODULE("DbModule"); private final String configKey; LibModuleType(String configKey) { this.configKey = configKey; } /** * Returns the module type for loading from gerrit.config. * * @return module type string */ public String getConfigKey() { return configKey; } }
// limitations under the License. package com.google.gerrit.server; /** Loadable module type for the different Gerrit daemon injectors. */ public enum LibModuleType { /** Module for the sysInjector. */ SYS_MODULE("Module"), /** Module for the dbInjector. */ DB_MODULE("DbModule"); private final String configKey; LibModuleType(String configKey) { this.configKey = configKey; } /** * Returns the module type for libModule loaded from <gerrit_site/lib> directory. * * @return module type string */ public String getConfigKey() { return configKey; } }
* an infinite forwarding loop between the 2 nodes. It will also make sure no concurrent indexing is * done for the same account id */ @Singleton public class ForwardedIndexAccountHandler extends ForwardedIndexingHandler<Account.Id> { private final AccountIndexer indexer; @Inject ForwardedIndexAccountHandler(AccountIndexer indexer, Configuration config) { super(config.index()); this.indexer = indexer; } @Override protected void doIndex(Account.Id id, Optional<IndexEvent> indexEvent) { indexer.index(id); log.atFine().log("Account %s successfully indexed", id); } @Override protected void doDelete(Account.Id id, Optional<IndexEvent> indexEvent) { throw new UnsupportedOperationException("Delete from account index not supported"); } }
import com.google.gerrit.testing.TestTimeUtil; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.gson.reflect.TypeToken; import java.util.Map; import java.util.concurrent.TimeUnit; import org.junit.Before; import org.junit.Test; public class EventJsonTest extends GerritBaseTests { private static final String BRANCH = "mybranch"; private static final String CHANGE_ID = "Ideadbeefdeadbeefdeadbeefdeadbeefdeadbeef"; private static final int CHANGE_NUM = 1000; private static final double CHANGE_NUM_DOUBLE = CHANGE_NUM; private static final String COMMIT_MESSAGE = "This is a test commit message"; private static final String PROJECT = "myproject"; private static final String REF = "refs/heads/" + BRANCH; private static final double TS1 = 1.2543444E9; private static final double TS2 = 1.254344401E9; private static final String URL = "http://somewhere.com"; // Must match StreamEvents#gson. (In master, the definition is refactored to be hared.) private final Gson gson = new GsonBuilder()
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb; import com.google.common.base.MoreObjects; import com.google.common.collect.ImmutableMap; import com.google.common.flogger.FluentLogger; import java.util.HashMap; import java.util.List; import java.util.Map; public class CustomSharedRefEnforcementByProject implements SharedRefEnforcement { private final String ALL = ".*"; private final Map<String, Map<String, EnforcePolicy>> PREDEF_ENFORCEMENTS; private final FluentLogger logger = FluentLogger.forEnclosingClass(); public CustomSharedRefEnforcementByProject(List<String> enforcementRules) { logger.atInfo().log( String.format( "Running with Custom Shared Ref-Db Enforcement Policy with follosing rules %s", enforcementRules.toString())); this.PREDEF_ENFORCEMENTS = parseDryRunEnforcementsToMap(enforcementRules); } private Map<String, Map<String, EnforcePolicy>> parseDryRunEnforcementsToMap( List<String> dryRunRefEnforcement) {
assert (refAndPolicy.length == 2); String refName = refAndPolicy[0].trim().isEmpty() ? ALL : refAndPolicy[0].trim(); Map<String, EnforcePolicy> existingOrDefaultRef = projectAndRefsEnforcements.getOrDefault(projectName, new HashMap<>()); existingOrDefaultRef.put( refName, EnforcePolicy.valueOf(refAndPolicy[1].trim().toUpperCase())); existingOrDefaultRef.put( refName, EnforcePolicy.valueOf(refAndPolicy[1].trim().toUpperCase())); projectAndRefsEnforcements.put(projectName, existingOrDefaultRef); } return projectAndRefsEnforcements; } @Override public EnforcePolicy getPolicy(String projectName, String refName) { if (isRefToBeIgnoredBySharedRefDb(refName)) { return EnforcePolicy.IGNORED; } return getRefEnforcePolicy(projectName, refName); } private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { if (!PREDEF_ENFORCEMENTS.containsKey(projectName) && PREDEF_ENFORCEMENTS.containsKey(ALL)) { return PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED); } EnforcePolicy policyFromProjectRefOrProjectAllRefs =
private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { if (!PREDEF_ENFORCEMENTS.containsKey(projectName) && PREDEF_ENFORCEMENTS.containsKey(ALL)) { return PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED); } EnforcePolicy policyFromProjectRefOrProjectAllRefs = Optional.ofNullable( Optional.ofNullable(PREDEF_ENFORCEMENTS.get(projectName).get(refName)) .orElseGet(() -> PREDEF_ENFORCEMENTS.get(projectName).get(ALL))) .orElseGet(() -> PREDEF_ENFORCEMENTS.get(projectName).get(refName)); return MoreObjects.firstNonNull(policyFromProjectRefOrProjectAllRefs, EnforcePolicy.REQUIRED);
private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { if (!PREDEF_ENFORCEMENTS.containsKey(projectName) && PREDEF_ENFORCEMENTS.containsKey(ALL)) { return PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED); } EnforcePolicy policyFromProjectRefOrProjectAllRefs = Optional.ofNullable( Optional.ofNullable(PREDEF_ENFORCEMENTS.get(projectName).get(refName)) .orElseGet(() -> PREDEF_ENFORCEMENTS.get(projectName).get(ALL))) .orElseGet(() -> PREDEF_ENFORCEMENTS.get(projectName).get(refName)); return MoreObjects.firstNonNull(policyFromProjectRefOrProjectAllRefs, EnforcePolicy.REQUIRED);
* @throws IOException */ default boolean compareAndCreate(String project, Ref newRef) throws IOException { return compareAndPut(project, NULL_REF, newRef); } /** * Verify in shared db if Ref is the most recent * * @param project project name of the ref * @param ref to be checked against shared-ref db * @return true if it is; false otherwise */ boolean isUpToDate(String project, Ref ref) throws IOException; /** * Compare a reference, and put if it matches. * * <p>Two reference match if and only if they satisfy the following: * * <ul> * <li>If one reference is a symbolic ref, the other one should be a symbolic ref. * <li>If both are symbolic refs, the target names should be same. * <li>If both are object ID refs, the object IDs should be same. * </ul> * * @param project project name of the ref
/** * Compare a reference, and delete if it matches. * * @param project project name of the ref * @param oldRef the old reference information that was previously read. * @return true if the remove was successful; false otherwise. * @throws java.io.IOException the reference could not be removed due to a system error. */ boolean compareAndRemove(String project, Ref oldRef) throws IOException; /** * Some references should not be stored in the SharedRefDatabase. * * @param refName * @return true if it's to be ignore; false otherwise */ default boolean ignoreRefInSharedDb(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } /** * Verify if the DB contains a value for the specific project and ref name *
/** * Compare a reference, and delete if it matches. * * @param project project name of the ref * @param oldRef the old reference information that was previously read. * @return true if the remove was successful; false otherwise. * @throws java.io.IOException the reference could not be removed due to a system error. */ boolean compareAndRemove(String project, Ref oldRef) throws IOException; /** * Some references should not be stored in the SharedRefDatabase. * * @param refName * @return true if it's to be ignore; false otherwise */ default boolean ignoreRefInSharedDb(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } /** * Verify if the DB contains a value for the specific project and ref name *
import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.recipes.atomic.AtomicValue; import org.apache.curator.framework.recipes.atomic.DistributedAtomicValue; import org.apache.curator.framework.recipes.locks.InterProcessMutex; import org.apache.curator.framework.recipes.locks.Locker; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; public class ZkSharedRefDatabase implements SharedRefDatabase { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CuratorFramework client; private final RetryPolicy retryPolicy; private final Long transactionLockTimeOut; @Inject public ZkSharedRefDatabase( CuratorFramework client, ZkConnectionConfig connConfig, SharedRefEnforcement refEnforcement) { this.client = client; this.retryPolicy = connConfig.curatorRetryPolicy; this.transactionLockTimeOut = connConfig.transactionLockTimeout; this.refEnforcement = refEnforcement; } @Override public boolean isMostRecentRefVersion(String project, Ref ref) throws IOException { if (!exists(project, ref.getName())) { logger.atWarning().log(
"Checking if this ref %s is the most recent, but not present in sharedDb, assuming " + "this is an old reference in Gerrit. Returning true", ref.getName()); return true; } try { final byte[] valueInZk = client.getData().forPath(pathFor(project, ref.getName())); // Assuming this is a delete node NULL_REF if (valueInZk == null) return false; return readObjectId(valueInZk).equals(ref.getObjectId()); } catch (Exception e) { throw new IOException( String.format("Unable to read data for path %s", pathFor(project, ref.getName())), e); } } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean exists(String projectName, String refName) throws IOException { try {
} @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean exists(String projectName, String refName) throws IOException { try { return client.checkExists().forPath(pathFor(projectName, refName)) != null; } catch (Exception e) { throw new IOException("Failed to check if path exists in Zookeeper", e); } } public Locker lockRef(String project, Ref ref) throws IOException { InterProcessMutex refPathMutex = new InterProcessMutex(client, "/locks" + pathFor(projectName, ref.getName())); try { return new Locker(refPathMutex, transactionLockTimeOut, MILLISECONDS); } catch (Exception e) { throw new IOException("Failed to create lock in ZK", e); } } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { EnforcePolicy enforcementPolicy = refEnforcement.getPolicy(
} catch (Exception e) { throw new IOException("Failed to check if path exists in Zookeeper", e); } } public Locker lockRef(String projectName, Ref ref) throws IOException { InterProcessMutex refPathMutex = new InterProcessMutex(client, "/locks" + pathFor(projectName, ref.getName())); try { return new Locker(refPathMutex, transactionLockTimeOut, MILLISECONDS); } catch (Exception e) { throw new SharedLockException(project, ref, e); } } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { EnforcePolicy enforcementPolicy = refEnforcement.getPolicy( projectName, MoreObjects.firstNonNull(oldRef.getName(), newRef.getName())); if (enforcementPolicy == EnforcePolicy.IGNORED) { return true; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate; private final String projectName; private final RefUpdateValidator.Factory batchRefValidatorFactory; private final RefDatabase refDb; public static interface Factory { MultiSiteBatchRefUpdate create(String project, RefDatabase refDb); } @Inject public MultiSiteBatchRefUpdate( RefUpdateValidator.Factory batchRefValidatorFactory, @Assisted String projectName, @Assisted RefDatabase refDb) { super(refDb); this.refDb = refDb; this.projectName = projectName; this.batchRefUpdate = refDb.newBatchUpdate(); this.batchRefValidatorFactory = batchRefValidatorFactory; } @Override public int hashCode() { return batchRefUpdate.hashCode(); } @Override public boolean equals(Object obj) { return batchRefUpdate.equals(obj); } @Override
} @Override public List<ProposedTimestamp> getProposedTimestamps() { return batchRefUpdate.getProposedTimestamps(); } @Override public BatchRefUpdate addProposedTimestamp(ProposedTimestamp ts) { return batchRefUpdate.addProposedTimestamp(ts); } @Override public void execute(RevWalk walk, ProgressMonitor monitor, List<String> options) throws IOException { batchRefValidatorFactory .create(projectName, refDb) .executeBatchUpdateWithValidation( batchRefUpdate, () -> batchRefUpdate.execute(walk, monitor, options)); } @Override public void execute(RevWalk walk, ProgressMonitor monitor) throws IOException { batchRefValidatorFactory .create(projectName, refDb) .executeBatchUpdateWithValidation( batchRefUpdate, () -> { batchRefUpdate.execute(walk, monitor); return null; }); } @Override public String toString() { return batchRefUpdate.toString(); } }
throws IOException { batchRefValidatorFactory .create(projectName, refDb) .executeBatchUpdateWithValidation( batchRefUpdate, () -> { batchRefUpdate.execute(walk, monitor, options); return null; }); } @Override public void execute(RevWalk walk, ProgressMonitor monitor) throws IOException { batchRefValidatorFactory .create(projectName, refDb) .executeBatchUpdateWithValidation( batchRefUpdate, () -> batchRefUpdate.execute(walk, monitor)); } @Override public String toString() { return batchRefUpdate.toString(); } }
public RefUpdateValidator( SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement;
} public String getName() { return MoreObjects.firstNonNull( oldRef == null ? null : oldRef.getName(), newRef == null ? null : newRef.getName()); } public boolean hasFailed() { return exception != null; } } protected void executeBatchUpdateWithPolicy( String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy( String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException {
String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { // If ignored we just do the GIT update if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { return doExecuteRefUpdate(refUpdate, refUpdateFunction); } catch (SharedDbSplitBrainException e) { validationMetrics.incrementSplitBrain(); protected RefUpdate.Result executeRefUpdateWithPolicy( String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException { // If ignored we just do the GIT update if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { return gitUpdateFun.apply(); } try { return delegateValidation.apply(gitUpdateFun, refUpdate); } catch (IOException e) { if (e.getClass() == SharedDbSplitBrainException.class) {
return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy( String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { return gitUpdateFun.apply(); } try { return delegateValidation.apply(gitUpdateFun, refUpdate); } catch (IOException e) { if (e.getClass() == SharedDbSplitBrainException.class) { validationMetrics.incrementSplitBrain(); } logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } return null; }
List<RefPair> refsToUpdate = getRefsPairs(commands) .sorted(comparing(RefPair::hasFailed).reversed()) .collect(Collectors.toList()); if (refsToUpdate.isEmpty()) { return; } if (refsToUpdate.get(0).hasFailed()) { RefPair failedRef = refsToUpdate.get(0); logger.atWarning().withCause(failedRef.exception).log("Failed to fetch ref entries"); throw new IOException( "Failed to fetch ref entries" + failedRef.newRef.getName(), failedRef.exception); } Map<ObjectId, Ref> oldRefsMap = refsToUpdate.stream() .collect( Collectors.toMap( refPair -> refPair.newRef.getObjectId(), refPair -> refPair.oldRef)); try (CloseableSet<AutoCloseable> locks = new CloseableSet()) { assertRefPairsAreInSyncWithSharedDb(refsToUpdate, locks); delegateUpdate.apply(); updateSharedRefDbForSuccessfulCommands(batchRefUpdate.getCommands().stream(), oldRefsMap); } } private void updateSharedRefDbForSuccessfulCommands(
protected RefPair newRefPairFrom(RefUpdate refUpdate) throws IOException { return new RefPair(refDb.getRef(refUpdate.getName()), refUpdate.getRef());
protected RefPair newRefPairFrom(RefUpdate refUpdate) throws IOException { return new RefPair(refDb.getRef(refUpdate.getName()), refUpdate.getRef());
public BatchRefUpdateValidator( SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Assisted RefDatabase refDb) { super(sharedRefDb, validationMetrics, refEnforcement, projectName, refDb);
public RefUpdateValidator( SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement;
protected final SharedRefEnforcement refEnforcement; public static interface Factory { RefUpdateValidator create(String projectName, RefDatabase refDb); } @Inject public RefUpdateValidator( SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; } public RefUpdate.Result executeRefUpdate( RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } }
RefUpdateValidator create(String projectName, RefDatabase refDb); } @Inject public RefUpdateValidator( SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; } public RefUpdate.Result executeRefUpdate( RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy( String errorMessage, RefValidationWrapper delegateValidation,
try { locks.addResourceIfNotExist( resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); } catch (Exception e) { throw new IOException( String.format( "Unable to prepare locks for project %s and reference %s", projectName, nonNullRef.getName()), e); } boolean isInSync; if (localRef != null) { isInSync = sharedRefDb.isUpToDate(projectName, localRef); } else { isInSync = !sharedRefDb.exists(projectName, refPair.getName()); } if (!isInSync) { failWith( new IOException( String.format( "Ref '%s' for project '%s' not in sync with shared Ref-Db." + "Trying to change the Ref-Db from oldRefId '%s'" + " to newRefId '%s'. Aborting batch update.", refPair.getName(), projectName, refPair.oldRef.getObjectId(),
import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.RefUpdateStub; import java.io.IOException; import org.eclipse.jgit.lib.ObjectIdRef; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.lib.RefUpdate; import org.eclipse.jgit.lib.RefUpdate.Result; import org.junit.Before; import org.junit.Rule; import org.junit.Test; import org.junit.rules.TestName; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.junit.MockitoJUnitRunner; @RunWith(MockitoJUnitRunner.class) @Ignore // The focus of this test suite is unclear and all tests are failing when the code is // working, and the other way around public class MultiSiteRefUpdateTest implements RefFixture { @Mock SharedRefDatabase sharedRefDb; @Mock ValidationMetrics validationMetrics; private final Ref oldRef = new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, A_TEST_REF_NAME, AN_OBJECT_ID_1); private final Ref newRef = new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, A_TEST_REF_NAME, AN_OBJECT_ID_2); @Rule public TestName nameRule = new TestName(); @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); } @Before
if (policy == EnforcePolicy.REQUIRED) { throw e; } } protected RefUpdate.Result doExecuteRefUpdate( RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> refUpdateFunction) throws IOException { try (CloseableSet<AutoCloseable> locks = new CloseableSet<>()) { checkIfLocalRefIsUpToDateWithSharedRefDb(newRefPairFrom(refUpdate).getName(), locks); RefUpdate.Result result = refUpdateFunction.invoke(); if (isSuccessful(result)) { updateSharedDbOrThrowExceptionFor(refPairForUpdate); } return result; } } protected void updateSharedDbOrThrowExceptionFor(RefPair refPair) throws IOException { // We are not checking refs that should be ignored final EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refPair.getName()); if (refEnforcementPolicy == EnforcePolicy.IGNORED) return; String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been "
assertThat(created.ref).isEqualTo(branch.branch()); } private void assertCreateFails( BranchNameKey branch, Class<? extends RestApiException> errType, String errMsg) throws Exception { assertCreateFails(branch, null, errType, errMsg); } private void assertCreateFails( BranchNameKey branch, String revision, Class<? extends RestApiException> errType, String errMsg) throws Exception { BranchInput in = new BranchInput(); in.revision = revision; RestApiException thrown = assertThrows(errType, () -> branch(branch).create(in)); if (errMsg != null) { assertThat(thrown).hasMessageThat().contains(errMsg); } } private void assertCreateFails(BranchNameKey branch, Class<? extends RestApiException> errType) throws Exception { assertCreateFails(branch, errType, null); } }
} @Test public void customLabel_DisallowPostSubmit() throws Exception { label.setFunction(NO_OP); label.setAllowPostSubmit(false); P.setFunction(NO_OP); saveLabelConfig(); PushOneCommit.Result r = createChange(); revision(r).review(ReviewInput.approve()); revision(r).submit(); ChangeInfo info = getWithLabels(r); assertPermitted(info, "Code-Review", 2); assertPermitted(info, P.getName(), 0, 1); assertPermitted(info, label.getName()); ReviewInput postSubmitReview1 = new ReviewInput(); postSubmitReview1.label(P.getName(), P.getMax().getValue()); revision(r).review(postSubmitReview1); ReviewInput postSubmitReview = new ReviewInput(); postSubmitReview.label(label.getName(), label.getMax().getValue()); ResourceConflictException thrown = assertThrows(ResourceConflictException.class, () -> revision(r).review(postSubmitReview)); assertThat(thrown) .hasMessageThat() .contains("Voting on labels disallowed after submit: " + label.getName()); } @Test public void customLabelWithUserPermissionChange() throws Exception {
staticPath = cdnPath; } else if (canonicalPath != null) { staticPath = canonicalPath; } // The resource path must be typed as safe for use in a script src. // TODO(wyatta): Upgrade this to use an appropriate safe URL type. SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer.ordainAsSafe( staticPath, SanitizedContent.ContentKind.TRUSTED_RESOURCE_URI); Map data = new HashMap<>(); data.put("canonicalPath", canonicalPath); data.put("staticResourcePath", sanitizedStaticPath); data.put("faviconPath", faviconPath); return data; } }
String staticPath = ""; if (cdnPath != null) { staticPath = cdnPath; } else if (canonicalPath != null) { staticPath = canonicalPath; } // The resource path must be typed as safe for use in a script src. // TODO(wyatta): Upgrade this to use an appropriate safe URL type. SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer.ordainAsSafe( staticPath, SanitizedContent.ContentKind.TRUSTED_RESOURCE_URI); Map<String, Object> data = new HashMap<>(); data.put("canonicalPath", canonicalPath); data.put("staticResourcePath", sanitizedStaticPath); data.put("faviconPath", faviconPath); return data; } }
// implied. // See the License for the specific language governing permissions and // limitations under the License. package com.vmware.gerrit.owners.common; import static org.junit.Assert.assertEquals; import com.google.gerrit.acceptance.LightweightPluginDaemonTest; import com.google.gerrit.acceptance.Sandboxed; import com.google.gerrit.acceptance.TestPlugin; import com.google.gerrit.extensions.events.GitReferenceUpdatedListener; import com.google.gerrit.reviewdb.client.RefNames; import com.google.inject.AbstractModule; import org.eclipse.jgit.transport.ReceiveCommand.Type; import org.junit.Test; @TestPlugin( name = "owners-autoassign", sysModule = "com.vmware.gerrit.owners.common.GitRefListenerIT$TestModule") public class GitRefListenerIT extends LightweightPluginDaemonTest { public static class TestModule extends AbstractModule { @Override protected void configure() { bind(GitReferenceUpdatedListener.class).to(TestGitRefListener.class); } } @Test public void shouldNotProcessNoteDbOnlyRefs() { TestGitRefListener gitRefListener = getPluginInstance(TestGitRefListener.class); String aRefChange = RefNames.REFS_CHANGES + "01/01" + RefNames.META_SUFFIX;
builder.setGroups(PatchSet.joinGroups(groups)); } patchSet.getPushCertificate().ifPresent(builder::setPushCertificate); patchSet.getDescription().ifPresent(builder::setDescription); return builder.build(); } @Override public PatchSet fromProto(Entities.PatchSet proto) { PatchSet.Builder builder = PatchSet.builder() .id(patchSetIdConverter.fromProto(proto.getId())) .groups( proto.hasGroups() ? PatchSet.splitGroups(proto.getGroups()) : ImmutableList.of()); if (proto.hasPushCertificate()) { builder.pushCertificate(proto.getPushCertificate()); } if (proto.hasDescription()) { builder.description(proto.getDescription()); } // The following fields used to theoretically be nullable in PatchSet, but in practice no // production codepath should have ever serialized an instance that was missing one of these // fields. // // However, since some protos may theoretically be missing these fields, we need to support // them. Populate specific sentinel values for each field as documented in the PatchSet javadoc.
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.manager; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.manager.GerritVersionBranch.getBranch; import org.junit.Test; public class GerritVersionBranchTest { @Test public void getBranchReturnsCorrectBranchForTwoDigitsVersions() throws Exception { // Regular 2.x versions assertBranch("2.13", "stable-2.13"); assertBranch("2.14", "stable-2.14"); assertBranch("2.15", "stable-2.15"); assertBranch("2.16", "stable-2.16"); // 2.x.y version assertBranch("2.16.10", "stable-2.16"); // 2.x-rcx version assertBranch("2.16-rc1", "stable-2.16"); // 3.0.0 version assertBranch("3.0.0", "stable-3.0");
* } * * public int getHttpStatusCode() { * return httpStatusCode; * } * } * * public class MyErrorHandlingFilter extends AbstractHttpFilter { * private static final DefaultErrorHandlingFilter delegate = * new DefaultErrorHandlingFilter(); * * {@literal @}Override * public void doFilter(HttpServletRequest req, HttpServletResponse res, FilterChain chain) * throws IOException, ServletException { * try { * delegate.doFilter(req, res, chain); * } catch (MyRequestFailureException e) { * res.setHeader(DefaultErrorHandlingFilter.GITILES_ERROR, e.getReason().toString()); * res.sendError(e.getReason().getHttpStatusCode()); * } * } * } * </code></pre> * * <p>{@code RepositoryResolver} can throw {@code MyRequestFailureException} and {@code * MyErrorHandlingFilter} will handle that. You can control how the error should be surfaced. */ public final class GitilesRequestFailureException extends RuntimeException {
BLAME_REGION_NOT_FOUND(SC_NOT_FOUND), /** Cannot parse URL as a Gitiles URL. */ CANNOT_PARSE_GITILES_VIEW(SC_NOT_FOUND), /** URL parameters are not valid. */ INCORECT_PARAMETER(SC_BAD_REQUEST), /** * The object specified by the URL is not suitable for the view (e.g. trying to show a blob as a * tree). */ INCORRECT_OBJECT_TYPE(SC_BAD_REQUEST), /** Markdown rendering is not enabled. */ MARKDOWN_NOT_ENABLED(SC_NOT_FOUND), /** Request is not authorized. */ NOT_AUTHORIZED(SC_UNAUTHORIZED), /** Object is not found. */ OBJECT_NOT_FOUND(SC_NOT_FOUND), /** Object is too large to show. */ OBJECT_TOO_LARGE(SC_INTERNAL_SERVER_ERROR), /** Repository is not found. */ REPOSITORY_NOT_FOUND(SC_NOT_FOUND), /** Gitiles is not enabled for the repository. */ SERVICE_NOT_ENABLED(SC_FORBIDDEN), /** GitWeb URL cannot be converted to Gitiles URL. */ UNSUPPORTED_GITWEB_URL(SC_GONE),
// you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // https://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gitiles; /** Assertion methods for Gitiles. */ public class MoreAssert { private MoreAssert() {} /** Simple version of assertThrows that will be introduced in JUnit 4.13. */ public static <T extends Throwable> T assertThrows(Class<T> expected, ThrowingRunnable r) { try { r.run(); throw new AssertionError("Expected " + expected.getSimpleName() + " to be thrown"); } catch (Throwable actual) { if (expected.isAssignableFrom(actual.getClass())) { return (T) actual; } throw new AssertionError(
factory(MultiSiteBatchRefUpdate.Factory.class); factory(RefUpdateValidator.Factory.class); factory(BatchRefUpdateValidator.Factory.class); if (!disableGitRepositoryValidation) { bind(GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); } if (cfg.getZookeeperConfig().getEnforcementRules().isEmpty()) { bind(SharedRefEnforcement.class).to(DefaultSharedRefEnforcement.class).in(Scopes.SINGLETON); } else { bind(SharedRefEnforcement.class) .to(CustomSharedRefEnforcementByProject.class) .in(Scopes.SINGLETON); } install(new ZkValidationModule(cfg));
// and then query the secondary index for each user but this way is less // efficient. queryPredicate = Predicate.or(AccountPredicates.isActive(), AccountPredicates.isNotActive()); } for (AccountState accountState : accountQueryProvider.get().query(queryPredicate)) { Account account = accountState.getAccount(); String out = new StringBuilder() .append(account.getId().toString()) .append(" |") .append( accountState.getUserName().isPresent() ? "" : " " + accountState.getUserName().get()) .append(" |") .append( Strings.isNullOrEmpty(account.getFullName()) ? "" : " " + account.getFullName()) .append(" |") .append( Strings.isNullOrEmpty(account.getPreferredEmail()) ? "" : " " + account.getPreferredEmail()) .append(" |") .append(account.isActive() ? " active" : " inactive") .toString();
if (args.getSchema().hasField(ChangeField.EXTENSION)) { FileExtensionPredicate extensionPredicate = new FileExtensionPredicate(ext); if (ext.isEmpty()) { RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^.{0}$"); // RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^()$"); // cf. https://www.brics.dk/automaton/doc/index.html?dk/brics/automaton/RegExp.html return emptyExtPredicate; // return Predicate.or(extensionPredicate, emptyExtPredicate); } return new FileExtensionPredicate(ext); } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException( "'onlyextensions' operator is not supported by change index version"); } @Operator
public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log( "Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin"); // In theory we could still unload the plugin even if the rename // failed. However, it would be reloaded on the next server startup,
.state(CheckState.FAILED) .upsert(); assertThat(getChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.FAILED)); } @Test public void combinedCheckStateViaQuery() throws Exception { CacheStats start = cloneStats(cache.getStats()); long startReloadsFalse = cache.getReloadCount(false); long startReloadsTrue = cache.getReloadCount(true); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.NOT_RELEVANT)); // Cache hasn't yet populated during update. // TODO(xchangcheng): still initialize the cache early without doing in the submit rule. assertThat(cache.getStats()).since(start).hasHitCount(0); assertThat(cache.getStats()).since(start).hasMissCount(1); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(0); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.NOT_RELEVANT)); assertThat(cache.getStats()).since(start).hasHitCount(1); assertThat(cache.getStats()).since(start).hasMissCount(1);
} return EqualsFilePredicate.create(args, file); } @Operator public Predicate<ChangeData> path(String path) { if (path.startsWith("^")) { return new RegexPathPredicate(path); } return new EqualsPathPredicate(FIELD_PATH, path); } @Operator public Predicate<ChangeData> ext(String ext) throws QueryParseException { return extension(ext); } @Operator public Predicate<ChangeData> extension(String ext) throws QueryParseException { if (args.getSchema().hasField(ChangeField.EXTENSION)) { if (ext.isEmpty() && IndexModule.getIndexType(cfg).equals(IndexType.ELASTICSEARCH)) { return new FileWithNoExtensionInElasticPredicate(); } return new FileExtensionPredicate(ext); } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException( "'onlyextensions' operator is not supported by change index version"); }
public MissingMandatoryPluginsException(Collection<String> pluginNames) { super(getMessage(pluginNames));
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.plugins; import java.util.Set; /** Raised when one or more mandatory plugins are missing. */ public class MissingMandatoryPluginsException extends RuntimeException { private static final long serialVersionUID = 1L; public MissingMandatoryPluginsException(Set<String> pluginNames) { super(getMessage(pluginNames)); } private static String getMessage(Collection<String> pluginNames) { return String.format("Cannot find or load the following mandatory plugins: %s", pluginNames); } }
"%s plugin %s, version %s", active == null ? "Loaded" : "Reloaded", loadedPlugin.getName(), loadedPlugin.getVersion()); } } catch (PluginInstallException e) { logger.atWarning().withCause(e.getCause()).log("Cannot load plugin %s", name); } } } Set<String> missingMandatory = Sets.difference(mandatoryPlugins, loadedPlugins); if (!missingMandatory.isEmpty()) { throw new MissingMandatoryPluginsException(missingMandatory); } cleanInBackground(); } private void addAllEntries(Map<String, Path> from, TreeSet<Map.Entry<String, Path>> to) { Iterator<Map.Entry<String, Path>> it = from.entrySet().iterator(); while (it.hasNext()) { Map.Entry<String, Path> entry = it.next(); to.add(new AbstractMap.SimpleImmutableEntry<>(entry.getKey(), entry.getValue())); } } private TreeSet<Map.Entry<String, Path>> jarsFirstSortedPluginsSet( Map<String, Path> activePlugins) {
* should use the batch instead of abandoning one by one. * * <p>It's the caller's responsibility to ensure that all jobs inside the same batch have the * matching project from its ChangeData. Violations will result in a ResourceConflictException. */ public void batchAbandon( BatchUpdate.Factory updateFactory, Project.NameKey project, CurrentUser user, Collection<ChangeData> changes, String msgTxt, NotifyResolver.Result notify) throws RestApiException, UpdateException { if (changes.isEmpty()) { return; } AccountState accountState = user.isIdentifiedUser() ? user.asIdentifiedUser().state() : null; try (BatchUpdate u = updateFactory.create(project, user, TimeUtil.nowTs())) { u.setNotify(notify); for (ChangeData change : changes) { if (!project.equals(change.project())) { throw new ResourceConflictException( String.format( "Project name \"%s\" doesn't match \"%s\"",
public static IndexType getIndexType(Injector injector) { return getIndexType(injector.getInstance(Key.get(Config.class, GerritServerConfig.class)));
public static IndexType getIndexType(@Nullable Config cfg) { return cfg != null ? cfg.getEnum("index", null, "type", IndexType.LUCENE) : IndexType.LUCENE;
} } CurrentUser getUser() throws QueryRequiresAuthException { try { return self.get(); } catch (ProvisionException e) { throw new QueryRequiresAuthException(NotSignedInException.MESSAGE, e); } } Schema<ChangeData> getSchema() { return index != null ? index.getSchema() : null; } } private final Arguments args; @Inject ChangeQueryBuilder(Arguments args) { super(mydef); this.args = args; setupDynamicOperators(); } @VisibleForTesting protected ChangeQueryBuilder(Definition<ChangeData, ChangeQueryBuilder> def, Arguments args) { super(def, args.opFactories); this.args = args; } private void setupDynamicOperators() { for (Extension<ChangeOperatorFactory> e : args.opFactories) { String name = e.getExportName() + "_" + e.getPluginName(); opFactories.put(name, e.getProvider().get()); } } public Arguments getArgs() { return args; } public ChangeQueryBuilder asUser(CurrentUser user) {
return new RegexPathPredicate(path); } return new EqualsPathPredicate(FIELD_PATH, path); } @Operator public Predicate<ChangeData> ext(String ext) throws QueryParseException { return extension(ext); } @Operator public Predicate<ChangeData> extension(String ext) throws QueryParseException { if (args.getSchema().hasField(ChangeField.EXTENSION)) { if (ext.isEmpty() && IndexModule.getIndexType(cfg).equals(IndexType.ELASTICSEARCH)) { return new FileWithNoExtensionInElasticPredicate(); } return new FileExtensionPredicate(ext); } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException(
private final DynamicItem<UrlFormatter> urlFormatter; private final Optional<Schedule> schedule; private final long abandonAfter; private final boolean abandonIfMergeable; private final String abandonMessage; @Inject ChangeCleanupConfig(@GerritServerConfig Config cfg, DynamicItem<UrlFormatter> urlFormatter) { this.urlFormatter = urlFormatter; schedule = ScheduleConfig.createSchedule(cfg, SECTION); abandonAfter = readAbandonAfter(cfg); abandonIfMergeable = cfg.getBoolean(SECTION, null, KEY_ABANDON_IF_MERGEABLE, true); cleanupAccountPatchReview = cfg.getBoolean(SECTION, null, KEY_CLEANUP_ACCOUNT_PATCH_REVIEW, false); abandonMessage = readAbandonMessage(cfg); } private long readAbandonAfter(Config cfg) { long abandonAfter = ConfigUtil.getTimeUnit(cfg, SECTION, null, KEY_ABANDON_AFTER, 0, TimeUnit.MILLISECONDS); return abandonAfter >= 0 ? abandonAfter : 0; } private String readAbandonMessage(Config cfg) { String abandonMessage = cfg.getString(SECTION, null, KEY_ABANDON_MESSAGE); return Strings.isNullOrEmpty(abandonMessage) ? DEFAULT_ABANDON_MESSAGE : abandonMessage; } public Optional<Schedule> getSchedule() { return schedule; } public long getAbandonAfter() { return abandonAfter; }
Project.NameKey key = projectOperations.newProject().create(); ProjectConfig projectConfig = projectOperations.project(key).getProjectConfig(); ProjectState cachedProjectState1 = projectCache.checkedGet(key); assertThat(cachedProjectState1).isNotNull(); assertThat(cachedProjectState1.getProject().getDescription()).isEmpty(); assertThat(projectConfig.getProject().getDescription()).isEmpty(); projectConfig.getProject().setDescription("my fancy project"); ProjectConfig cachedProjectConfig2 = projectCache.checkedGet(key).getConfig(); assertThat(cachedProjectConfig2).isNotSameInstanceAs(projectConfig); assertThat(cachedProjectConfig2.getProject().getDescription()).isEmpty(); } @Test public void getProjectConfigNoRefsMetaConfig() throws Exception { Project.NameKey key = projectOperations.newProject().create(); deleteRefsMetaConfig(key); ProjectConfig projectConfig = projectOperations.project(key).getProjectConfig(); assertThat(projectConfig.getName()).isEqualTo(key); assertThat(projectConfig.getRevision()).isNull(); } @Test public void getConfig() throws Exception { Project.NameKey key = projectOperations.newProject().create();
public IterableSubject sections() { isNotNull(); return check("getSections()").that(config.getSections());
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.common; import static java.lang.annotation.ElementType.FIELD; import static java.lang.annotation.ElementType.METHOD; import static java.lang.annotation.ElementType.TYPE; import static java.lang.annotation.RetentionPolicy.RUNTIME; import java.lang.annotation.Retention; import java.lang.annotation.Target; /** * A marker to say a method/type/field is added or is increased to public solely because it is * called from inside a project or an organisation using Gerrit. */ @Target({METHOD, TYPE, FIELD}) @Retention(RUNTIME) public @interface UsedAt { /** Enumeration of projects that call a method/type/field. */ enum Project { GOOGLE, PLUGIN_CHECKS, PLUGIN_DELETE_PROJECT, PLUGIN_SERVICEUSER, PLUGINS_ALL, // Use this project if a method/type is generally made available to all plugins. } /** Reference to the project that uses the method annotated with this annotation. */ Project value(); }
? NON_EXISTING : REJECTED_OTHER_REASON; postReplicationFailedEvent(pushOp, status); if (pushOp.setToRetry()) { postReplicationScheduledEvent(pushOp); pool.schedule(pushOp, config.getRetryDelay(), TimeUnit.MINUTES); } else { pushOp.canceledByReplication(); pending.remove(uri); stateLog.error( "Push to " + pushOp.getURI() + " cancelled after maximum number of retries", pushOp.getStatesAsArray()); } break; } } } } RunwayStatus requestRunway(PushOne op) { synchronized (stateLock) { if (op.wasCanceled()) { return false; } pending.remove(op.getURI()); if (inFlight.containsKey(op.getURI())) { return false; } inFlight.put(op.getURI(), op); } return true; } void notifyFinished(PushOne op) { synchronized (stateLock) { inFlight.remove(op.getURI()); } } boolean wouldPushProject(Project.NameKey project) { if (!shouldReplicate(project)) {
public class DeleteGpgKey implements RestModifyView<GpgKey, Input> { private static final Logger log = LoggerFactory.getLogger(DeleteGpgKey.class); public static class Input {} private final Provider<PersonIdent> serverIdent; private final Provider<PublicKeyStore> storeProvider; private final ExternalIdsUpdate.User externalIdsUpdateFactory; private final DeleteKeySender.Factory deleteKeyFactory; @Inject DeleteGpgKey( @GerritPersonIdent Provider<PersonIdent> serverIdent, Provider<PublicKeyStore> storeProvider, ExternalIdsUpdate.User externalIdsUpdateFactory, DeleteKeySender.Factory deleteKeySenderFactory) { this.serverIdent = serverIdent; this.storeProvider = storeProvider; this.externalIdsUpdateFactory = externalIdsUpdateFactory; this.deleteKeyFactory = deleteKeyFactory; } @Override public Response<?> apply(GpgKey rsrc, Input input) throws ResourceConflictException, PGPException, OrmException, IOException, ConfigInvalidException { PGPPublicKey key = rsrc.getKeyRing().getPublicKey(); externalIdsUpdateFactory .create() .delete( rsrc.getUser().getAccountId(), ExternalId.Key.create( SCHEME_GPGKEY, BaseEncoding.base16().encode(key.getFingerprint())));
import org.slf4j.LoggerFactory; @Singleton public class PostGpgKeys implements RestModifyView<AccountResource, Input> { public static class Input { public List<String> add; public List<String> delete; } private final Logger log = LoggerFactory.getLogger(getClass()); private final Provider<PersonIdent> serverIdent; private final Provider<CurrentUser> self; private final Provider<PublicKeyStore> storeProvider; private final GerritPublicKeyChecker.Factory checkerFactory; private final AddKeySender.Factory addKeySenderFactory; private final DeleteKeySender.Factory deleteKeySenderFactory; private final Provider<InternalAccountQuery> accountQueryProvider; private final ExternalIds externalIds; private final ExternalIdsUpdate.User externalIdsUpdateFactory; @Inject PostGpgKeys( @GerritPersonIdent Provider<PersonIdent> serverIdent, Provider<CurrentUser> self, Provider<PublicKeyStore> storeProvider, GerritPublicKeyChecker.Factory checkerFactory, AddKeySender.Factory addKeyFactory, DeleteKeySender.Factory deleteKeyFactory, Provider<InternalAccountQuery> accountQueryProvider, ExternalIds externalIds, ExternalIdsUpdate.User externalIdsUpdateFactory) { this.serverIdent = serverIdent; this.self = self;
case NEW: case FAST_FORWARD: case FORCED: if (!addedKeys.isEmpty()) { try { addKeyFactory.create(user, addedKeys).send(); } catch (EmailException e) { log.error( "Cannot send GPG key added message to " + user.getAccount().getPreferredEmail(), e); } } if (!toRemove.isEmpty()) { try { deleteKeySenderFactory .create(user, toRemove.stream().map(Fingerprint::toString).collect(toList())) .send(); } catch (EmailException e) { log.error( "Cannot send GPG key deleted message to " + user.getAccount().getPreferredEmail(), e); } } break; case NO_CHANGE: break; case IO_FAILURE: case LOCK_FAILURE: case NOT_ATTEMPTED: case REJECTED: case REJECTED_CURRENT_BRANCH: case RENAMED: case REJECTED_MISSING_OBJECT: case REJECTED_OTHER_REASON: default: // TODO(dborowitz): Backoff and retry on LOCK_FAILURE.
import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.errors.RepositoryNotFoundException; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class DeleteSshKey implements RestModifyView<AccountResource.SshKey, Input> { private static final Logger log = LoggerFactory.getLogger(DeleteSshKey.class); public static class Input {} private final Provider<CurrentUser> self; private final PermissionBackend permissionBackend; private final VersionedAuthorizedKeys.Accessor authorizedKeys; private final SshKeyCache sshKeyCache; private final DeleteKeySender.Factory deleteKeySenderFactory; @Inject DeleteSshKey( Provider<CurrentUser> self, PermissionBackend permissionBackend, VersionedAuthorizedKeys.Accessor authorizedKeys, SshKeyCache sshKeyCache, DeleteKeySender.Factory deleteKeyFactory) { this.self = self; this.permissionBackend = permissionBackend; this.authorizedKeys = authorizedKeys; this.sshKeyCache = sshKeyCache; this.deleteKeyFactory = deleteKeyFactory; } @Override public Response<?> apply(AccountResource.SshKey rsrc, Input input) throws AuthException, OrmException, RepositoryNotFoundException, IOException, ConfigInvalidException, PermissionBackendException {
import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.reviewdb.client.AccountSshKey; import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import java.util.List; public class DeleteKeySender extends OutgoingEmail { public interface Factory { DeleteKeySender create(IdentifiedUser user, AccountSshKey sshKey); DeleteKeySender create(IdentifiedUser user, List<String> gpgKeyFingerprints); } private final PermissionBackend permissionBackend; private final IdentifiedUser callingUser; private final IdentifiedUser user; private final AccountSshKey sshKey; private final List<String> gpgKeys; @AssistedInject public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user;
import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import java.util.List; public class DeleteKeySender extends OutgoingEmail { public interface Factory { DeleteKeySender create(IdentifiedUser user, AccountSshKey sshKey); DeleteKeySender create(IdentifiedUser user, List<String> gpgKeyFingerprints); } private final PermissionBackend permissionBackend; private final IdentifiedUser callingUser; private final IdentifiedUser user; private final AccountSshKey sshKey; private final List<String> gpgKeys; @AssistedInject public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeys = null; this.sshKey = sshKey; } @AssistedInject
public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeyFingerprints = Collections.emptyList(); this.sshKey = sshKey;
public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted List<String> gpgKeyFingerprints) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeys = gpgKey; this.sshKey = null;
public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted List<String> gpgKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeyFingerprints = gpgKeyFingerprints; this.sshKey = null;
public String getKeyType() { if (sshKey != null) { return "SSH"; } else if (gpgKeys != null) { return "GPG"; } throw new IllegalStateException("key type is not SSH or GPG");
public String getGpgKeyFingerprints() { if (!gpgKeyFingerprints.isEmpty()) { return Joiner.on("\n").join(gpgKeyFingerprints); } return null;
return TestPermission.builder().name(name).action(PermissionRule.Action.ALLOW); } /** Start a builder for denying a permission. */ public static TestPermission.Builder deny(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.DENY); } /** Start a builder for blocking a permission. */ public static TestPermission.Builder block(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.BLOCK); } /** * Records a permission to be updated. * * <p>Not used for permissions that have ranges (label permissions) or global capabilities. */ @AutoValue public abstract static class TestPermission { private static Builder builder() { return new AutoValue_TestProjectUpdate_TestPermission.Builder().force(false); } abstract String name(); abstract String ref(); abstract AccountGroup.UUID group(); abstract PermissionRule.Action action(); abstract boolean force(); /** Builder for {@link TestPermission}. */ @AutoValue.Builder public abstract static class Builder {
*/ @AutoValue public abstract static class TestPermission { private static Builder builder() { return new AutoValue_TestProjectUpdate_TestPermission.Builder().force(false); } abstract String name(); abstract String ref(); abstract AccountGroup.UUID group(); abstract PermissionRule.Action action(); abstract boolean force(); /** Builder for {@link TestPermission}. */ @AutoValue.Builder public abstract static class Builder { abstract Builder name(String name); /** Sets the ref pattern used on the permission. */ public abstract Builder ref(String ref); /** Sets the group to which the permission applies. */ public abstract Builder group(AccountGroup.UUID groupUuid); abstract Builder action(PermissionRule.Action action); /** Sets whether the permission is a force permission. */ public abstract Builder force(boolean force); /** Builds the {@link TestPermission}. */ public abstract TestPermission build(); } }
public void deleteUserBranch_Conflict() throws Exception { projectOperations .project(allUsers) .forUpdate() .add( TestProjectUpdate.allow(Permission.CREATE) .ref(RefNames.REFS_USERS + "*") .group(REGISTERED_USERS)) .add( TestProjectUpdate.allow(Permission.PUSH) .ref(RefNames.REFS_USERS + "*") .group(REGISTERED_USERS)) .update(); ResourceConflictException thrown = assertThrows( ResourceConflictException.class, () -> branch(BranchNameKey.create(allUsers, RefNames.refsUsers(admin.id()))).delete()); assertThat(thrown).hasMessageThat().contains("Not allowed to delete user branch."); } @Test public void deleteGroupBranch_Conflict() throws Exception { allow(allUsers, RefNames.REFS_GROUPS + "*", Permission.CREATE, REGISTERED_USERS); allow(allUsers, RefNames.REFS_GROUPS + "*", Permission.PUSH, REGISTERED_USERS); ResourceConflictException thrown = assertThrows(
@NoHttpd public class PluginLoaderIT extends AbstractDaemonTest { Description testDescription; @Override protected void beforeTest(Description description) throws Exception { this.testDescription = description; } @Override protected void afterTest() throws Exception {} @Test(expected = MissingMandatoryPluginsException.class) @GerritConfig(name = "plugins.mandatory", value = "my-mandatory-plugin") public void shouldFailToStartGerritWhenMandatoryPluginsAreMissing() throws Exception { super.beforeTest(testDescription); } }
public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log( "Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin"); // In theory we could still unload the plugin even if the rename // failed. However, it would be reloaded on the next server startup,
public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log( "Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin"); // In theory we could still unload the plugin even if the rename // failed. However, it would be reloaded on the next server startup,
public void setUp() { globalPluginConfig = new Config(); replicationConfig = new Config(); } private Configuration getConfiguration() { return new Configuration(globalPluginConfig, replicationConfig); } @Test public void testGetIndexThreadPoolSize() throws Exception { assertThat(getConfiguration().index().threadPoolSize()).isEqualTo(DEFAULT_THREAD_POOL_SIZE); globalPluginConfig.setInt(INDEX_SECTION, null, THREAD_POOL_SIZE_KEY, THREAD_POOL_SIZE); assertThat(getConfiguration().index().threadPoolSize()).isEqualTo(THREAD_POOL_SIZE); } @Test(expected = IllegalArgumentException.class) public void testGetIndexThreadPoolSizeWithInvalidSize() { globalPluginConfig.setString(INDEX_SECTION, null, THREAD_POOL_SIZE_KEY, INVALID_INT); getConfiguration().index().threadPoolSize(); } @Test public void testGetIndexSynchronize() throws Exception { assertThat(getConfiguration().index().synchronize()).isEqualTo(DEFAULT_SYNCHRONIZE); globalPluginConfig.setBoolean(INDEX_SECTION, null, SYNCHRONIZE_KEY, false); assertThat(getConfiguration().index().synchronize()).isFalse(); globalPluginConfig.setBoolean(INDEX_SECTION, null, SYNCHRONIZE_KEY, true); assertThat(getConfiguration().index().synchronize()).isTrue(); } @Test public void testGetCacheThreadPoolSize() throws Exception {
drainQueue(droppedEventsQueue); ChangeData change = createChange().getChange(); String project = change.project().get(); int changeNum = change.getId().get(); String changeNotesRef = change.notes().getRefName(); int patchsetNum = change.currentPatchSet().getPatchSetId(); String patchsetRevision = change.currentPatchSet().getRevision().get(); String patchsetRef = change.currentPatchSet().getRefName(); Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue); assertThat(eventsByType).isNotEmpty(); assertThat(eventsByType.get("change-index")) .containsExactly(createChangeIndexEvent(project, changeNum, getParentCommit(change))); assertThat( eventsByType .get("ref-updated") .stream() .map(e -> ((RefUpdatedEvent) e).getRefName()) .collect(toSet())) .containsAllOf( changeNotesRef, patchsetRef); // 'refs/sequences/changes' not always updated thus not checked List<Event> patchSetCreatedEvents = eventsByType.get("patchset-created"); assertThat(patchSetCreatedEvents).hasSize(1); assertPatchSetAttributes(
import java.util.Arrays; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.commons.lang.StringUtils; import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Configuration { private static final Logger log = LoggerFactory.getLogger(Configuration.class); public static final String PLUGIN_NAME = "multi-site"; static final String INSTANCE_ID_FILE = "instanceId.data"; // common parameters to cache and index sections static final String THREAD_POOL_SIZE_KEY = "threadPoolSize"; static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000;
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.base.Suppliers.memoize; import static com.googlesource.gerrit.plugins.multisite.ConfigurationHelper.getString; import com.google.common.annotations.VisibleForTesting; import com.google.common.base.CaseFormat; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.HashMap;
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.multisite.Configuration.ENABLE_KEY; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KAFKA_PROPERTY_PREFIX; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KAFKA_SECTION; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaPublisher.KAFKA_PUBLISHER_SUBSECTION; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaSubscriber.KAFKA_SUBSCRIBER_SUBSECTION; import org.eclipse.jgit.lib.Config;
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.acceptance.testsuite.project; import com.google.auto.value.AutoValue; import com.google.common.collect.ImmutableList; import com.google.gerrit.acceptance.testsuite.ThrowingConsumer; import com.google.gerrit.common.data.PermissionRule; import com.google.gerrit.reviewdb.client.AccountGroup; @AutoValue public abstract class TestProjectUpdate { /** Starts a builder for allowing a permission. */ public static TestPermission.Builder allow(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.ALLOW); } /** Starts a builder for denying a permission. */ public static TestPermission.Builder deny(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.DENY); } /** Starts a builder for blocking a permission. */ public static TestPermission.Builder block(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.BLOCK); } /**
* request, implementations should not deduct tokens from a bucket, yet. */ QuotaResponse requestNoDeduction(String quotaGroup, QuotaRequestContext ctx, long numTokens); /** * A previously requested and deducted quota has to be refilled (if possible) because the request * failed other quota checks. Implementations can choose to leave this a no-op in case they are * the first line of defence (e.g. always deduct HTTP quota even if the request failed for other * quota issues so that the user gets throttled). * * <p>Will not be called if the {@link #requestTokens(String, QuotaRequestContext, long)} call * returned {@link QuotaResponse.Status#NO_OP}. */ void refill(String quotaGroup, QuotaRequestContext ctx, long numTokens); }
import com.google.gerrit.reviewdb.client.RefNames; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.GerritPersonIdent; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import java.io.IOException; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import java.sql.Timestamp; import java.util.HashMap; import java.util.Map; import org.eclipse.jgit.lib.CommitBuilder; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectInserter; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefUpdate; import org.eclipse.jgit.lib.RefUpdate.Result; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevSort; import org.eclipse.jgit.revwalk.RevWalk; /**
String refName = RefNames.refsUsers(e.getKey()); Ref ref = repo.exactRef(refName); if (ref != null) { rewriteUserBranch(repo, rw, oi, emptyTree, ref, e.getValue()); } else { createUserBranch(repo, oi, emptyTree, e.getKey(), e.getValue()); } i++; if (i % 100 == 0) { ui.message(String.format("... migrated %d users", i)); } } } catch (IOException e) { throw new OrmException("Failed to rewrite user branches.", e); } } private void rewriteUserBranch( Repository repo, RevWalk rw, ObjectInserter oi, ObjectId emptyTree, Ref ref, Timestamp registeredOn) throws IOException { ObjectId current = createInitialEmptyCommit(oi, emptyTree, registeredOn); rw.reset(); rw.sort(RevSort.TOPO); rw.sort(RevSort.REVERSE, true); rw.markStart(rw.parseCommit(ref.getObjectId())); RevCommit c;
// and the start() methods of each such listener are executed in the // order they are declared. // Makes sure that PluginLoader.start() is executed before the // LuceneIndexModule.start() so that plugins get loaded and the respective // Guice modules installed so that the on-line reindexing will happen // with the proper classes (e.g. group backends, custom Prolog // predicates) and the associated rules ready to be evaluated. modules.add(new PluginModule()); modules.add(new RestApiModule()); modules.add(new GpgModule(config)); modules.add(new StartupChecks.Module()); // Index module shutdown must happen before work queue shutdown, otherwise // work queue can get stuck waiting on index futures that will never return. modules.add(createIndexModule()); modules.add(new WorkQueue.Module()); modules.add(new GerritInstanceNameModule()); modules.add( new CanonicalWebUrlModule() { @Override protected Class<? extends Provider<String>> provider() { return HttpCanonicalWebUrlProvider.class; } });
try { u = new URL(p.substring(0, p.indexOf('!'))); } catch (MalformedURLException e) { FileNotFoundException fnfe = new FileNotFoundException("Not a valid jar file: " + u); fnfe.initCause(e); throw fnfe; } } if (!"file".equals(u.getProtocol())) { throw new FileNotFoundException("Cannot extract path from " + u); } // Pop up to the top-level source folder by looking for WORKSPACE. dir = Paths.get(u.getPath()); while (!Files.isRegularFile(dir.resolve("WORKSPACE"))) { Path parent = dir.getParent(); if (parent == null) { throw new FileNotFoundException("Cannot find source root from " + u); } dir = parent; } } Path ret = dir.resolve(name); if (!Files.exists(ret)) { throw new FileNotFoundException(name + " not found in source root " + dir); } return ret; }
protected Builder addActions(Builder builder, Id c) { return builder.addAction(delete(OPEN_CHANGES, c)).addAction(delete(OPEN_CHANGES, c));
private final boolean useV6Type; private final boolean omitType; private final String searchFilteringName; private final String indicesExistParam; private final String exactFieldType; private final String stringFieldType; private final String indexProperty; private final String versionDiscoveryUrl; private final String includeTypeNameParam; ElasticQueryAdapter(ElasticVersion version) { this.ignoreUnmapped = false; this.useType = !version.isV6OrLater(); this.useV6Type = version.isV6(); this.omitTypeFromSearch = version.isV7OrLater(); this.versionDiscoveryUrl = version.isV6OrLater() ? "/%s*" : "/%s*/_aliases"; this.searchFilteringName = "_source"; this.indicesExistParam = "?allow_no_indices=false"; this.exactFieldType = "keyword"; this.stringFieldType = "text"; this.indexProperty = "true"; this.includeTypeNameParam = version.isV6() ? "?include_type_name=true" : "";
} public static String supportedVersions() { return Joiner.on(", ").join(ElasticVersion.values()); } public boolean isV6() { return isVersion(6); } public boolean isV6OrLater() { return isAtLeastVersion(6); } public boolean isV7OrLater() { return isAtLeastVersion(7); } private boolean isAtLeastVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) >= v; } private Integer getMajor() { return Integer.valueOf(version.split("\\.")[0]); } @Override public String toString() { return version; } }
RawInputUtil.create(HTML_PLUGIN.getBytes(UTF_8)); private static final ImmutableList<String> PLUGINS = ImmutableList.of( "plugin-a.js", "plugin-b.html", "plugin-c.js", "plugin-d.html", "plugin_e.js"); @Inject private RequestScopeOperations requestScopeOperations; @Inject private MandatoryPluginsCollection mandatoryPluginsCollection; @Test @GerritConfig(name = "plugins.allowRemoteAdmin", value = "true") public void pluginManagement() throws Exception { // No plugins are loaded assertThat(list().get()).isEmpty(); assertThat(list().all().get()).isEmpty(); PluginApi api; // Install all the plugins InstallPluginInput input = new InstallPluginInput(); for (String plugin : PLUGINS) { input.raw = plugin.endsWith(".js") ? JS_PLUGIN_CONTENT : HTML_PLUGIN_CONTENT; api = gApi.plugins().install(plugin, input); assertThat(api).isNotNull(); PluginInfo info = api.get();
public TestLabelPermission build() { TestLabelPermission result = autoBuild(); checkLabelName(result.name()); return result;
"queryLimit", "+0..+" + DEFAULT_MAX_QUERY_LIMIT + " group global:Registered-Users"); } @Test public void removePermission() throws Exception { Project.NameKey key = projectOperations.newProject().create(); projectOperations .project(key) .forUpdate() .add(TestProjectUpdate.allow(Permission.ABANDON).ref("refs/foo").group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .containsExactly( "abandon", "group global:Registered-Users", "abandon", "group global:Project-Owners"); projectOperations .project(key) .forUpdate() .remove( TestProjectUpdate.permissionKey(Permission.ABANDON) .ref("refs/foo") .group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .doesNotContainKey("abandon"); } @Test public void removeLabelPermission() throws Exception { Project.NameKey key = projectOperations.newProject().create(); projectOperations .project(key) .forUpdate() .add( TestProjectUpdate.allowLabel("Code-Review")
private void rcpt(@Nullable RecipientType type, String email, boolean expected) { if (recipients.get(type).contains(email) != expected) { failWithoutActual( fact( expected ? "expected to notify" : "expected not to notify", type + ": " + users.emailToName(email)), fact("but notified", recipientMapToString(recipients, users::emailToName))); } if (expected) { accountedFor.add(email); }
r.assertNoContent(); assertThat(projectDir.exists()).isFalse(); } @Test @UseLocalDisk public void testSshDeleteProjectWithoutOptions() throws Exception { createChange(); String cmd = Joiner.on(" ").join(PLUGIN, "delete", project.get()); String expected = String.format( "Really delete '%s'?\n" + "This is an operation which permanently deletes data. This cannot be undone!\n" + "If you are sure you wish to delete this project, re-run with the --yes-really-delete flag.\n\n", project.get()); adminSshSession.exec(cmd); assertThat(projectDir.exists()).isTrue(); assertThat(adminSshSession.getError()).isEqualTo(expected); } @Test @UseLocalDisk public void testSshDeleteProjYesReallyDelete() throws Exception { createChange(); String cmd = createDeleteCommand(project.get()); String expected = String.format( "Project '%s' has open changes. - To really delete '%s', re-run with the --force"
// // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.schema; import com.google.common.collect.Iterables; import com.google.common.collect.Sets; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.client.RefNames; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.GerritPersonIdent; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import java.io.IOException; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import java.sql.Timestamp; import java.time.Duration; import java.time.Instant; import java.util.Date; import java.util.HashMap; import java.util.List;
assertThat(accountState.getAccount().getFullName()).isEqualTo(fullName); AccountInfo info = gApi.accounts().id(accountId.get()).get(); assertThat(info.name).isEqualTo(fullName); List<EmailInfo> emails = gApi.accounts().id(accountId.get()).getEmails(); assertThat(emails.stream().map(e -> e.email).collect(toSet())).containsExactly(extId.email()); RevCommit commitUserBranch = projectOperations.project(allUsers).getHead(RefNames.refsUsers(accountId)); RevCommit commitRefsMetaExternalIds = this.projectOperations.project(allUsers).getHead(RefNames.REFS_EXTERNAL_IDS); assertThat(commitUserBranch.getCommitTime()) .isEqualTo(commitRefsMetaExternalIds.getCommitTime()); } finally { TestTimeUtil.useSystemTime(); } } @Test public void updateNonExistingAccount() throws Exception { Account.Id nonExistingAccountId = Account.id(999999); AtomicBoolean consumerCalled = new AtomicBoolean(); Optional<AccountState> accountState = accountsUpdateProvider .get() .update(
projectOperations .project(allUsers) .forUpdate() .add(allow(Permission.CREATE).ref(RefNames.REFS_USERS + "*").group(REGISTERED_USERS)) .add(allow(Permission.PUSH).ref(RefNames.REFS_USERS + "*").group(REGISTERED_USERS)) .update(); ResourceConflictException thrown = assertThrows( ResourceConflictException.class, () -> branch(BranchNameKey.create(allUsers, RefNames.refsUsers(admin.id()))).delete()); assertThat(thrown).hasMessageThat().contains("Not allowed to delete user branch."); } @Test public void deleteGroupBranch_Conflict() throws Exception { projectOperations .project(allUsers) .forUpdate() .add(allow(Permission.CREATE).ref(RefNames.REFS_GROUPS + "*").group(REGISTERED_USERS))
assertThat(gApi.accounts().id(user.username()).get().name).isEqualTo("User McUserface"); } @Test public void userCannotSetNameOfOtherUser() throws Exception { requestScopeOperations.setApiUser(user.id()); assertThrows( AuthException.class, () -> gApi.accounts().id(admin.username()).setName("Admin McAdminface")); } @Test @Sandboxed public void userCanSetNameOfOtherUserWithModifyAccountPermission() throws Exception { projectOperations .project(allProjects) .forUpdate() .add(allowCapability(GlobalCapability.MODIFY_ACCOUNT).group(REGISTERED_USERS)) .update(); gApi.accounts().id(admin.username()).setName("Admin McAdminface"); assertThat(gApi.accounts().id(admin.username()).get().name).isEqualTo("Admin McAdminface"); } @Test public void fetchUserBranch() throws Exception { requestScopeOperations.setApiUser(user.id()); TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers, user); String userRefName = RefNames.refsUsers(user.id()); // remove default READ permissions
metaRef3, "refs/heads/master", "refs/tags/master-tag", "refs/users/00/1000000/edit-" + cd3.getId() + "/1", "refs/users/01/1000001/edit-" + cd3.getId() + "/1"); } @Test public void uploadPackSubsetOfRefsVisibleWithAccessDatabase() throws Exception { projectOperations .project(allProjects) .forUpdate() .add(allowCapability(GlobalCapability.ACCESS_DATABASE).group(REGISTERED_USERS)) .update(); projectOperations .project(project) .forUpdate() .add(deny(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(admin.id()); gApi.changes().id(cd3.getId().get()).edit().create(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( // Change 1 is visible due to accessDatabase capability, even though // refs/heads/master is not. psRef1, metaRef1, psRef2, metaRef2, psRef3, metaRef3, psRef4, metaRef4,
ProjectConfig allProjectsConfig = projectConfigFactory.create(allProjectsName); allProjectsConfig.load(md); LabelType cr = Util.codeReview(); allProjectsConfig.getLabelSections().put(cr.getName(), cr); allProjectsConfig.commit(md); } } repoManager.createRepository(parentKey).close(); repoManager.createRepository(localKey).close(); try (MetaDataUpdate md = metaDataUpdateFactory.create(localKey)) { ProjectConfig newLocal = projectConfigFactory.create(localKey); newLocal.load(md); newLocal.getProject().setParentName(parentKey); newLocal.commit(md); } requestContext.setContext(() -> null); } @After public void tearDown() throws Exception { requestContext.setContext(null); } @Test public void ownerProject() throws Exception { projectOperations .project(localKey) .forUpdate() .add(allow(OWNER).ref("refs/*").group(ADMIN)) .update(); assertAdminsAreOwnersAndDevsAreNot(); } @Test public void denyOwnerProject() throws Exception { projectOperations .project(localKey) .forUpdate()
projectOperations .project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .update(); ProjectControl u = user(localKey, DEVS); assertCannotUpdate("refs/heads/master", u); } @Test public void unblockMoreSpecificRefInLocal_Fails() throws Exception { projectOperations .project(parentKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .update(); projectOperations .project(localKey) .forUpdate() .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .update(); ProjectControl u = user(localKey, DEVS); assertCannotUpdate("refs/heads/master", u); } @Test public void unblockMoreSpecificRefWithExclusiveFlag() throws Exception { projectOperations .project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .setExclusiveGroup(permissionKey(PUSH).ref("refs/heads/master"), true) .update();
assertCanVote(-2, range); } @Test public void unblockFromParentDoesNotAffectChild() throws Exception { projectOperations .project(parentKey) .forUpdate() .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .update(); projectOperations .project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/master").group(DEVS)) .update(); ProjectControl u = user(localKey, DEVS); assertCannotUpdate("refs/heads/master", u); } @Test public void unblockFromParentDoesNotAffectChildDifferentGroups() throws Exception { projectOperations .project(parentKey) .forUpdate() .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .setExclusiveGroup(permissionKey(PUSH).ref("refs/heads/master"), true) .update(); projectOperations .project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/master").group(ANONYMOUS_USERS)) .update(); ProjectControl u = user(localKey, DEVS);
package com.google.gerrit.index.query; import static com.google.common.base.Preconditions.checkNotNull; import com.google.common.collect.ImmutableList; import java.util.Iterator; import java.util.function.Supplier; /** * Result set that allows for asynchronous execution of the actual query. Callers should dispatch * the query and call the constructor of this class with a supplier that fetches the result and * blocks on it if necessary. * * <p>If the execution is synchronous or the results are known a priori, consider using {@link * ListResultSet}. */ public class LazyResultSet<T> implements ResultSet<T> { private final Supplier<ImmutableList<T>> resultsCallback; private boolean resultsReturned = false; public LazyResultSet(Supplier<ImmutableList<T>> r) { resultsCallback = checkNotNull(r, "results can't be null"); } @Override public Iterator<T> iterator() { return toList().iterator(); } @Override public ImmutableList<T> toList() { if (resultsReturned) { throw new IllegalStateException("Results already obtained");
public LazyResultSet(Supplier<ImmutableList<T>> r) { resultsCallback = requireNonNull(r, "results can't be null");
public ListResultSet(List<T> r) { results = ImmutableList.copyOf(requireNonNull(r, "results can't be null"));
} @Test public void testCapabilityAllowsZeroRangeOnCapabilityThatHasRange() throws Exception { TestCapability c = allowCapability(QUERY_LIMIT).group(REGISTERED_USERS).range(0, 0).build(); assertThat(c.min()).isEqualTo(0); assertThat(c.max()).isEqualTo(0); } @Test public void testCapabilityDisallowsInvertedRange() throws Exception { assertThrows( RuntimeException.class, () -> allowCapability(QUERY_LIMIT).group(REGISTERED_USERS).range(1, 0).build()); } @Test public void testCapabilityDisallowsRangeIfCapabilityDoesNotSupportRange() throws Exception { assertThrows( RuntimeException.class, () -> allowCapability(ADMINISTRATE_SERVER).group(REGISTERED_USERS).range(-1, 1).build()); } @Test public void testCapabilityRangeIsZeroIfCapabilityDoesNotSupportRange() throws Exception { TestCapability c = allowCapability(ADMINISTRATE_SERVER).group(REGISTERED_USERS).build(); assertThat(c.min()).isEqualTo(0); assertThat(c.max()).isEqualTo(0); } @Test public void testCapabilityUsesDefaultRangeIfUnspecified() throws Exception {
// limitations under the License. package com.ericsson.gerrit.plugins.highavailability.forwarder.rest; import com.ericsson.gerrit.plugins.highavailability.cache.Constants; import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gerrit.server.events.Event; import com.google.gerrit.server.events.EventDeserializer; import com.google.gerrit.server.events.SupplierDeserializer; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.inject.Singleton; @Singleton class GsonParser { private final Gson gson; public Gson gson() { return gson; } Object fromJson(String cacheName, String json) { Object key; // Need to add a case for 'adv_bases' switch (cacheName) { case Constants.ACCOUNTS: key = gson.fromJson(Strings.nullToEmpty(json).trim(), Account.Id.class); break; case Constants.GROUPS:
public class BranchCommitValidator { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CommitValidators.Factory commitValidatorsFactory; private final IdentifiedUser user; private final PermissionBackend.ForProject permissions; private final Project project; private final BranchNameKey branch; private final SshInfo sshInfo; interface Factory { BranchCommitValidator create( ProjectState projectState, BranchNameKey branch, IdentifiedUser user); } /** A boolean validation status and a list of additional messages. */ @AutoValue abstract static class Result { static Result create(boolean isValid, ImmutableList<CommitValidationMessage> messages) { return new AutoValue_BranchCommitValidator_Result(isValid, messages); } /** Whether the commit is valid. */ abstract boolean isValid(); /** * A list of messages related to the validation. Messages may be present regardless of the * {@link #isValid()} status. */ abstract List<CommitValidationMessage> messages(); } @Inject BranchCommitValidator( CommitValidators.Factory commitValidatorsFactory, PermissionBackend permissionBackend, SshInfo sshInfo,
abstract static class Result { static Result create(boolean isValid, ImmutableList<CommitValidationMessage> messages) { return new AutoValue_BranchCommitValidator_Result(isValid, messages);
@AutoValue public static abstract class Result { static Result create(boolean isValid, List<CommitValidationMessage> messages) { return new AutoValue_BranchCommitValidator_Result(isValid, messages); } /** Whether the commit is valid. */ abstract boolean isValid(); /** * A list of messages related to the validation. Messages may be present regardless of the * {@link #isValid()} status. */ abstract ImmutableList<CommitValidationMessage> messages(); } @Inject BranchCommitValidator( CommitValidators.Factory commitValidatorsFactory, PermissionBackend permissionBackend, SshInfo sshInfo, @Assisted ProjectState projectState, @Assisted BranchNameKey branch, @Assisted IdentifiedUser user) { this.sshInfo = sshInfo; this.user = user; this.branch = branch; this.commitValidatorsFactory = commitValidatorsFactory; project = projectState.getProject(); permissions = permissionBackend.user(user).project(project.getNameKey()); } /** * Validates a single commit. If the commit does not validate, the command is rejected. *
if (args.getSchema().hasField(ChangeField.EXTENSION)) { FileExtensionPredicate extensionPredicate = new FileExtensionPredicate(ext); if (ext.isEmpty()) { RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^.{0}$"); // RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^()$"); // cf. https://www.brics.dk/automaton/doc/index.html?dk/brics/automaton/RegExp.html return emptyExtPredicate; // return Predicate.or(extensionPredicate, emptyExtPredicate); } return new FileExtensionPredicate(ext); } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException( "'onlyextensions' operator is not supported by change index version"); } @Operator
ChecksCollection( Checks checks, DynamicMap<RestView<CheckResource>> views, ListChecks listChecks) { this.checks = checks; this.views = views; this.listChecks = listChecks; } @Override public RestReadView<RevisionResource> list() throws RestApiException { return listChecks; } @Override public CheckResource parse(RevisionResource parent, IdString id) throws RestApiException, PermissionBackendException, IOException, StorageException { if (parent.getEdit().isPresent()) { throw new ResourceConflictException("checks are not supported on a change edit"); } CheckerUuid checkerUuid = CheckerUuid.tryParse(id.get()) .orElseThrow( () -> new BadRequestException(String.format("invalid checker UUID: %s", id.get()))); CheckKey checkKey = CheckKey.create(parent.getProject(), parent.getPatchSet().id(), checkerUuid); Optional<Check> check = checks.getCheck(checkKey, GetCheckOptions.withBackfilling()); return new CheckResource( parent, check.orElseThrow( () -> new ResourceNotFoundException( String.format(
@Inject Schema_146( Provider<Schema_145> prior, GitRepositoryManager repoManager, AllUsersName allUsersName, @GerritPersonIdent PersonIdent serverIdent) { super(prior); this.repoManager = repoManager; this.allUsersName = allUsersName; this.serverIdent = serverIdent; } @Override protected void migrateData(ReviewDb db, UpdateUI ui) throws OrmException, SQLException { ui.message("Migrating accounts"); gc(ui); Set<Entry<Account.Id, Timestamp>> accounts = scanAccounts(db, ui).entrySet(); gc(ui); Set<List<Entry<Account.Id, Timestamp>>> batches = Sets.newHashSet(Iterables.partition(accounts, 500)); ExecutorService pool = createExecutor(ui); try { batches.stream().forEach(batch -> pool.submit(() -> processBatch(batch, ui))); pool.shutdown(); pool.awaitTermination(Long.MAX_VALUE, TimeUnit.DAYS); } catch (InterruptedException e) { throw new RuntimeException(e); } ui.message( String.format("... (%.3f s) Migrated all %d accounts to schema 146", elapsed(), i.get())); }
return CacheBuilder.newBuilder().maximumSize(1 << 10).expireAfterWrite(30, TimeUnit.MINUTES); } public VisibilityCache(boolean topoSort) { this(topoSort, defaultBuilder()); } public VisibilityCache(boolean topoSort, CacheBuilder<Object, Object> builder) { this(new VisibilityChecker(topoSort), builder); } /** * Use the constructors with a boolean parameter (e.g. {@link #VisibilityCache(boolean)}). The * default visibility checker should cover all common use cases. * * <p>This constructor is useful to set e.g. an instrumented checker. */ public VisibilityCache(VisibilityChecker checker) { this(checker, defaultBuilder()); } /** * Use the constructors with a boolean parameter (e.g. {@link #VisibilityCache(boolean)}). The * default visitiliby checker should cover all common use cases. * * <p>This constructor is useful to set e.g. an instrumented checker. */ public VisibilityCache(VisibilityChecker checker, CacheBuilder<Object, Object> builder) { this.cache = builder.build();
import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevSort; import org.eclipse.jgit.revwalk.RevWalk; /** * Checks for object visibility * * <p>Objects are visible if they are reachable from any of the references visible to the user. */ public class VisibilityChecker { private boolean topoSort; /** * @param topoSort whether to use a more thorough reachability check * by sorting in topological order */ public VisibilityChecker(boolean topoSort) { this.topoSort = topoSort; } /** * Check if any of the refs in {@code refDb} points to the object {@code id}. * * @param refDb a reference database * @param id object we are looking for * @return true if the any of the references in the db points directly to the id * @throws IOException the reference space cannot be accessed */
import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.JUnit4; @RunWith(JUnit4.class) public class VisibilityCacheTest { private InMemoryRepository repo; private GitilesAccess access = new FakeGitilesAccess(); private RevCommit baseCommit; private RevCommit commit1; private RevCommit commit2; private RevCommit commitA; private RevCommit commitB; private RevCommit commitC; private VisibilityCache visibilityCache; private RevWalk walk; @Before public void setUp() throws Exception { /** * master (branch not visible) * * <p>commitC | commit2 commitB | | commit1 commitA <--- refs/tags/v0.1 \ / \ / baseCommit */ repo = new InMemoryRepository(new DfsRepositoryDescription()); TestRepository<InMemoryRepository> git = new TestRepository<>(repo); baseCommit = git.commit().message("baseCommit").create(); commit1 = git.commit().parent(baseCommit).message("commit1").create(); commit2 = git.commit().parent(commit1).message("commit2").create(); commitA = git.commit().parent(baseCommit).message("commitA").create(); commitB = git.commit().parent(commitA).message("commitB").create();
public void diffOfNonExistentFileIsAnEmptyDiffResult() throws Exception { addModifiedPatchSet(changeId, FILE_NAME, content -> content.replace("Line 2\n", "Line two\n")); DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, "a_non-existent_file.txt") .withBase(initialPatchSetId) .withContext(DiffPreferencesInfo.WHOLE_FILE_CONTEXT) .get(); assertThat(diffInfo).content().isEmpty(); } // This behavior is likely a bug. A fix might not be easy as it might break syntax highlighting. // TODO: Fix this issue or remove the broken parameter (at least in the documentation). @Test public void contextParameterIsIgnored() throws Exception { addModifiedPatchSet( changeId, FILE_NAME, content -> content.replace("Line 20\n", "Line twenty\n")); DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME) .withBase(initialPatchSetId) .withContext(5) .get(); assertThat(diffInfo).content().element(0).commonLines().hasSize(19); assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 20");
package com.ericsson.gerrit.plugins.highavailability.forwarder.rest; import com.ericsson.gerrit.plugins.highavailability.cache.Constants; import com.google.common.base.Strings; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gson.Gson; import com.google.gson.JsonElement; import com.google.gson.JsonObject; import com.google.inject.Inject; import com.google.inject.Singleton; @Singleton class GsonParser { private final Gson gson; @Inject public GsonParser(@EventGson Gson gson) { this.gson = gson; } public Object fromJson(String cacheName, String jsonString) { JsonElement json = gson.fromJson(Strings.nullToEmpty(jsonString), JsonElement.class); Object key; // Need to add a case for 'adv_bases' if (!json.isJsonObject()) { return json.getAsString(); } JsonObject asJsonObject = json.getAsJsonObject(); switch (cacheName) { case Constants.ACCOUNTS: key = asJsonObject.has("id") ? Account.id(asJsonObject.get("id").getAsInt()) : null; break;
* file constructed to trigger excessive backtracking. */ public class CheckConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String toolName = "check_new_config"; private static final String ACCESS = "access"; private static final String LABEL = "label"; private static final String PLUGIN = "plugin"; private static final int BUFFER_SIZE = 2048; private String pluginName; private Config configProject; ScannerConfig scannerConfig; public CheckConfig(String pluginName, String projectConfigContents) throws ConfigInvalidException { this.pluginName = pluginName; configProject = new Config(); configProject.fromText(projectConfigContents); Config config = new Config(); for (String name : configProject.getNames(PLUGIN, pluginName)) { config.setStringList( PLUGIN, pluginName, name, Arrays.asList(configProject.getStringList(PLUGIN, pluginName, name))); } PluginConfig pluginConfig = new PluginConfig(pluginName, config);
* file constructed to trigger excessive backtracking. */ public class CheckConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String toolName = "check_new_config"; private static final String ACCESS = "access"; private static final String LABEL = "label"; private static final String PLUGIN = "plugin"; private static final int BUFFER_SIZE = 2048; private static final char[] BUFFER = new char[BUFFER_SIZE]; private String pluginName; /** All-Projects project.config contents. */ private Config configProject; ScannerConfig scannerConfig; public CheckConfig(String pluginName, String projectConfigContents) throws ConfigInvalidException { this.pluginName = pluginName; configProject = new Config(); configProject.fromText(projectConfigContents); Config config = new Config(); for (String name : configProject.getNames(PLUGIN, pluginName)) { config.setStringList( PLUGIN, pluginName, name, Arrays.asList(configProject.getStringList(PLUGIN, pluginName, name))); } PluginConfig pluginConfig = new PluginConfig(pluginName, config);
* * <p>When a new commit alters the configured scanner patterns, the push will fail with a message * to download the plugin source, to run a shell script that runs {@code main} below, and to copy * the output on success into the commit message. * * <p>This method scans the commit message to find the copied text. If the text was created for * the same pattern signature, this method returns a single valid finding with the number of * microseconds it took to scan a large file, which can be used to block patterns that cause * excessive backtracking. * * <p>If the commit message contains one or more copied texts for other pattern signatures, this * method retuns an invalid finding for each. * * <p>If the commit message contains no copied texts, this method returns an empty list of * findings, which {@link com.googlesource.gerrit.plugins.copyright.CopyrightConfig} uses as a
import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectLoader; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevTree; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.treewalk.TreeWalk; /** Listener to manage configuration for enforcing review of copyright declarations and licenses. */ @Singleton class CopyrightConfig implements CommitValidationListener, RevisionCreatedListener, GitReferenceUpdatedListener { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); /** Default value of timeTestMax configuration parameter for avoiding excessive backtracking. */ private final long DEFAULT_MAX_ELAPSED_SECONDS = 8; private final Metrics metrics; private final AllProjectsName allProjectsName; private final String pluginName; private final GitRepositoryManager repoManager; private final ProjectCache projectCache; private final PluginConfigFactory pluginConfigFactory; private final CopyrightReviewApi reviewApi; private PluginConfig gerritConfig; private CheckConfig checkConfig; static AbstractModule module() { return new AbstractModule() { @Override protected void configure() { DynamicSet.bind(binder(), CommitValidationListener.class).to(CopyrightConfig.class);
if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { clearConfig(); checkConfig = readConfig(event.getNewObjectId()); } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); }
"%s plugin revision %s: error posting review: %s", pluginName, event.getChange().currentRevision, result.error); } for (Map.Entry<String, AddReviewerResult> entry : result.reviewers.entrySet()) { AddReviewerResult arr = entry.getValue(); if (!Strings.isNullOrEmpty(arr.error)) { logger.atSevere().log( "%s plugin revision %s: error adding reviewer %s: %s", pluginName, event.getChange().currentRevision, entry.getKey(), arr.error); metrics.addReviewerErrors.increment(); metrics.errors.increment(); } }
* * @throws RestApiException if an error occurs updating the review thread */ private ReviewResult review(ChangeResource change, ReviewInput ri) throws RestApiException { try { PatchSet ps = psUtil.current(change.getNotes()); if (ps == null) { throw new ResourceNotFoundException(IdString.fromDecoded("current")); } RevisionResource revision = RevisionResource.createNonCacheable(change, ps); return postReview.apply(revision, ri).value(); } catch (Exception e) { Throwables.throwIfUnchecked(e); throw e instanceof RestApiException ? (RestApiException) e : new RestApiException("Cannot post review", e); } } /** Returns true if {@code priorComments} already includes a comment identical to {@code ci}. */ @VisibleForTesting boolean containsComment(Iterable<? extends Comment> priorComments, CommentInput ci) { if (priorComments == null) { return false; } for (Comment prior : priorComments) { if (Objects.equals(prior.line, ci.line)
* @param event describes the newly created revision triggering the scan * @throws IOException if an error occurred reading the repository * @throws RestApiException if an error occured reporting findings to the review thread */ private void scanRevision(String project, String branch, RevisionCreatedListener.Event event) throws IOException, RestApiException { Map<String, ImmutableList<Match>> findings = new HashMap<>(); ArrayList<String> containedPaths = new ArrayList<>(); long scanStart = System.nanoTime(); metrics.scanCountByProject.increment(project); metrics.scanCountByBranch.increment(branch); try (Repository repo = repoManager.openRepository(Project.nameKey(project)); RevWalk revWalk = new RevWalk(repo); TreeWalk tw = new TreeWalk(revWalk.getObjectReader())) { RevCommit commit = repo.parseCommit(ObjectId.fromString(event.getRevision().commit.commit)); tw.setRecursive(true); tw.setFilter(TreeFilter.ANY_DIFF); tw.addTree(commit.getTree()); if (commit.getParentCount() > 0) {
import com.google.gerrit.server.git.validators.ValidationMessage; import com.google.gerrit.server.project.ProjectConfig; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightPatterns; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightPatterns.UnknownPatternName; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightScanner; import java.util.ArrayList; import java.util.Collection; import java.util.LinkedHashSet; import java.util.Objects; import java.util.function.Consumer; import java.util.regex.Pattern; import java.util.regex.PatternSyntaxException; /** Configuration state for {@link CopyrightValidator} from All-Projects project.config file. */ class ScannerConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String KEY_ENABLE = "enable"; static final String KEY_TIME_TEST_MAX = "timeTestMax"; static final String DEFAULT_REVIEW_LABEL = "Copyright-Review"; static final String KEY_REVIEWER = "reviewer"; static final String KEY_CC = "cc"; static final String KEY_FROM = "fromAccountId"; static final String KEY_REVIEW_LABEL = "reviewLabel"; static final String KEY_EXCLUDE = "exclude";
} public boolean isV6() { return isVersion(6); } public boolean isV6OrLater() { return isAtLeastVersion(6); } public boolean isV7OrLater() { return isAtLeastVersion(7); } private boolean isAtLeastVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) >= v; } private Integer getMajor() { return Integer.valueOf(version.split("\\.")[0]); } @Override public String toString() { return version; } }
boolean oldForceLogging = loggingCtx.isLoggingForced(); boolean oldPerformanceLogging = loggingCtx.isPerformanceLogging(); ImmutableList<PerformanceLogRecord> oldPerformanceLogRecords = loggingCtx.getPerformanceLogEntries(); loggingCtx.setTags(tags); loggingCtx.forceLogging(forceLogging); loggingCtx.performanceLogging(performanceLogging); loggingCtx.setPerformanceLogEntries(performanceLogRecords); try { runnable.run(); } finally { loggingCtx.setTags(oldTags); loggingCtx.forceLogging(oldForceLogging); loggingCtx.performanceLogging(oldPerformanceLogging); loggingCtx.setPerformanceLogRecords(oldPerformanceLogRecords); } } }
public void close() { if (LoggingContext.getInstance().isPerformanceLogging()) { runEach(performanceLoggers, LoggingContext.getInstance().getPerformanceLogEntries()); } // Restore old state. LoggingContext.getInstance().performanceLogging(oldPerformanceLogging); LoggingContext.getInstance().setPerformanceLogRecords(oldPerformanceLogRecords);
.forUpdate() .add(allow(Permission.READ).ref("refs/*").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref(RefNames.REFS_CONFIG).group(REGISTERED_USERS)) .update(); assertUploadPackRefs( "HEAD", psRef1, metaRef1, psRef2, metaRef2, psRef3, metaRef3, psRef4, metaRef4, "refs/heads/branch", "refs/heads/master", RefNames.REFS_CONFIG, "refs/tags/branch-tag", "refs/tags/master-tag", "refs/tags/tree-tag"); } @Test public void uploadPackSubsetOfBranchesVisibleIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(allow(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(deny(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( "HEAD", psRef1, metaRef1, psRef3, metaRef3, "refs/heads/master", "refs/tags/master-tag"); } @Test
metaRef4, "refs/heads/branch", "refs/heads/master", RefNames.REFS_CONFIG, "refs/tags/branch-tag", "refs/tags/master-tag"); } @Test public void uploadPackSubsetOfBranchesVisibleIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(allow(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(deny(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( "HEAD", psRef1, metaRef1, psRef3, metaRef3, "refs/heads/master", "refs/tags/master-tag"); // tree-tag is not visible because we don't look at trees reachable from // refs } @Test public void uploadPackSubsetOfBranchesVisibleNotIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(deny(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( psRef2, metaRef2,
// // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.readonly; import static com.google.common.truth.Truth.assertThat; import com.google.gerrit.acceptance.RestResponse; import com.google.gerrit.server.config.GerritServerConfig; import com.google.gerrit.testing.ConfigSuite; import com.google.inject.Inject; import org.eclipse.jgit.lib.Config; public class ReadOnlyByHttpIT extends AbstractReadOnlyTest { @ConfigSuite.Default public static Config withPluginNamePrefix() { Config cfg = new Config(); cfg.setString("readonly", "test", "endpoint", "readonly~readonly"); return cfg; } @ConfigSuite.Config public static Config withoutPluginNamePrefix() { Config cfg = new Config(); cfg.setString("readonly", "test", "endpoint", "readonly"); return cfg; }
} else if (input.httpPassword == null) { newPassword = null; } else { // Only administrators can explicitly set the password. permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); newPassword = input.httpPassword; } return apply(rsrc.getUser(), newPassword); } // Used by the admin console plugin // TODO(dpursehouse): Replace comment with @UsedAt public Response<String> apply(IdentifiedUser user, String newPassword) throws ResourceNotFoundException, ResourceConflictException, IOException, ConfigInvalidException { String userName = user.getUserName().orElseThrow(() -> new ResourceConflictException("username must be set")); Optional<ExternalId> optionalExtId = externalIds.get(ExternalId.Key.create(SCHEME_USERNAME, userName)); ExternalId extId = optionalExtId.orElseThrow(ResourceNotFoundException::new); accountsUpdateProvider .get() .update( "Set HTTP Password via API", extId.accountId(), u -> u.updateExternalId( ExternalId.createWithPassword(
// included: pA:d2/OWNERS, pA:d2/../f1, pA:d1/f1 // inherited: pA:OWNERS String owners = "owners:[ " + concat(ownerJson("pAd1f1@g"), ", ") + concat(ownerJson("pAd2@g"), ", ") + concat(ownerJson("pAf1@g"), ", ") + concat(ownerJson("pA@g", 0, 1, 0), " ]"); // The "owners:[...]" substring contains only owners from pA. assertThat(getOwnersResponse(c1)).contains(owners); } }
private void handleGitReferenceUpdatedAsUser(Event event, Account.Id updaterAccountId) { try (ManualRequestContext ctx = oneOffReqCtx.openAs(updaterAccountId)) { handleGitReferenceUpdated(event); } catch (OrmException e) { logger.warn("Unable to process event {} on project {}", event, event.getProjectName(), e); }
public void onGitReferenceUpdated(Event event) { AccountInfo updaterAccountInfo = event.getUpdater(); CurrentUser currentUser = currentUserProvider.get(); if (currentUser.isIdentifiedUser()) { handleGitReferenceUpdated(event); } else if (updaterAccountInfo != null) { handleGitReferenceUpdatedAsUser(event, new Account.Id(updaterAccountInfo._accountId)); } else { handleGitReferenceUpdatedAsServer(event); }
// For the performance log records use the list instance from the logging context of the calling // thread in the logging context of the new thread. This way performance log records that are // created from the new thread are available from the logging context of the calling thread. // This is important since performance log records are processed only at the end of the request // and performance log records that are created in another thread should not get lost. loggingCtx.setMutablePerformanceLogRecords(mutablePerformanceLogRecords); try { return callable.call(); } finally { loggingCtx.setTags(oldTags); loggingCtx.forceLogging(oldForceLogging); loggingCtx.performanceLogging(oldPerformanceLogging); loggingCtx.setPerformanceLogRecords(oldPerformanceLogRecords); } } }
.setRate() .setUnit("errors"), project); errors = metricMaker.newCounter( "error_count", new Description("Number of errors of any kind").setRate().setUnit("errors")); } } @Inject CopyrightConfig( Metrics metrics, AllProjectsName allProjectsName, @PluginName String pluginName, GitRepositoryManager repoManager, ProjectCache projectCache, PluginConfigFactory pluginConfigFactory, CopyrightReviewApi reviewApi) { this.metrics = metrics; this.allProjectsName = allProjectsName; this.pluginName = pluginName; this.repoManager = repoManager; this.projectCache = projectCache; this.pluginConfigFactory = pluginConfigFactory; this.reviewApi = reviewApi; long nanoStart = System.nanoTime(); try { checkConfig = readConfig(projectCache.getAllProjects().getProject().getConfigRefState()); } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); } } private CopyrightConfig(
throws ConfigInvalidException { metrics = new Metrics(metricMaker); allProjectsName = new AllProjectsName("All-Projects"); pluginName = "copyright"; repoManager = null; projectCache = null; pluginConfigFactory = null; this.reviewApi = reviewApi; checkConfig = new CheckConfig(pluginName, projectConfigContents); } @VisibleForTesting static CopyrightConfig createTestInstance( MetricMaker metricMaker, CopyrightReviewApi reviewApi, String projectConfigContents) throws ConfigInvalidException { return new CopyrightConfig(metricMaker, reviewApi, projectConfigContents); } @Override public void stop() {} /** Listens for merges to /refs/meta/config on All-Projects to reload plugin configuration. */ @Override public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try {
public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { logger.atSevere().log("\n\nonGitRefUpdated\n\n"); checkConfig = readConfig(event.getNewObjectId()); } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); }
public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { logger.atSevere().log("\n\nonGitRefUpdated\n\n"); checkConfig = readConfig(event.getNewObjectId()); } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); }
public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { logger.atSevere().log("\n\nonGitRefUpdated\n\n"); checkConfig = readConfig(event.getNewObjectId()); } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); }
CommentInfo draftInfo = Iterables.getOnlyElement(drafts.get(draft.path)); ReviewInput reviewInput = new ReviewInput(); reviewInput.drafts = DraftHandling.KEEP; reviewInput.message = "foo"; CommentInput comment = newComment(file, Side.REVISION, 0, "comment", false); // Replace the existing draft. comment.id = draftInfo.id; reviewInput.comments = new HashMap<>(); reviewInput.comments.put(comment.path, ImmutableList.of(comment)); revision(r).review(reviewInput); // DraftHandling.KEEP is ignored on publishing a comment. drafts = getDraftComments(changeId, revId); assertThat(drafts).isEmpty(); } @Test public void listComments() throws Exception { String file = "file"; PushOneCommit push = pushFactory.create(admin.newIdent(), testRepo, "first subject", file, "contents"); PushOneCommit.Result r = push.to("refs/for/master"); String changeId = r.getChangeId(); String revId = r.getCommit().getName(); assertThat(getPublishedComments(changeId, revId)).isEmpty();
(metadata, value) -> elementAssertThatFunction.apply(value); return assertThat(optional, valueSubjectFactory); } public static <S extends Subject, T> OptionalSubject<S, T> assertThat( Optional<T> optional, Subject.Factory<S, T> valueSubjectFactory) { return assertAbout(optionals()).thatCustom(optional, valueSubjectFactory); } public static OptionalSubject<Subject, ?> assertThat(Optional<?> optional) { return assertAbout(optionals()).that(optional); } public static CustomSubjectBuilder.Factory<OptionalSubjectBuilder> optionals() { return OptionalSubjectBuilder::new; } private OptionalSubject( FailureMetadata failureMetadata, Optional<T> optional, BiFunction<StandardSubjectBuilder, ? super T, ? extends S> valueSubjectCreator) { super(failureMetadata, optional); this.optional = optional; this.valueSubjectCreator = valueSubjectCreator; } public void isPresent() { isNotNull(); if (!optional.isPresent()) { failWithoutActual(fact("expected to have", "value")); } } public void isAbsent() {
} public static class OptionalSubjectBuilder extends CustomSubjectBuilder { OptionalSubjectBuilder(FailureMetadata failureMetadata) { super(failureMetadata); } public <S extends Subject, T> OptionalSubject<S, T> thatCustom( Optional<T> optional, Subject.Factory<S, T> valueSubjectFactory) { return that(optional, (builder, value) -> builder.about(valueSubjectFactory).that(value)); } public OptionalSubject<Subject, ?> that(Optional<?> optional) { return that(optional, StandardSubjectBuilder::that); } public <S extends Subject, T> OptionalSubject<S, T> that( Optional<T> optional, BiFunction<StandardSubjectBuilder, ? super T, ? extends S> valueSubjectCreator) { return new OptionalSubject<>(metadata(), optional, valueSubjectCreator); } } }
GitReferenceUpdatedListener, LifecycleListener { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); /** Default value of timeTestMax configuration parameter for avoiding excessive backtracking. */ private final long DEFAULT_MAX_ELAPSED_SECONDS = 8; private final Metrics metrics; private final AllProjectsName allProjectsName; private final String pluginName; private final GitRepositoryManager repoManager; private final ProjectCache projectCache; private final PluginConfigFactory pluginConfigFactory; private final CopyrightReviewApi reviewApi; @Nullable private PluginConfig gerritConfig; @Nullable private CheckConfig checkConfig; static AbstractModule module() { return new AbstractModule() { @Override protected void configure() { DynamicSet.bind(binder(), CommitValidationListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), LifecycleListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), RevisionCreatedListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(CopyrightConfig.class); } }; } @Inject CopyrightConfig( Metrics metrics, AllProjectsName allProjectsName, @PluginName String pluginName,
} } boolean pluginEnabled = gerritConfig != null && gerritConfig.getBoolean(ScannerConfig.KEY_ENABLE, false); CheckConfig.checkProjectConfig(reviewApi, pluginEnabled, trialConfig); return trialConfig == null || trialConfig.scannerConfig == null ? Collections.emptyList() : trialConfig.scannerConfig.messages; } } catch (IOException e) { logger.atSevere().withCause(e).log("failed to read new project.config"); throw new CommitValidationException( pluginName + "plugin failed to read new project.config", e); } catch (ConfigInvalidException e) { logger.atSevere().withCause(e).log("unable to parse plugin config"); if (trialConfig != null && trialConfig.scannerConfig != null) { trialConfig.scannerConfig.messages.add(ScannerConfig.errorMessage(e.getMessage())); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return trialConfig.scannerConfig.messages; } else { throw new CommitValidationException("unable to parse new project.config", e); } } finally { if (trialConfig != null && trialConfig.scannerConfig != null
return scannerConfig.defaultEnable; } return pluginConfig.getBoolean(ScannerConfig.KEY_ENABLE, scannerConfig.defaultEnable); } /** * Loads and compiles configured patterns from {@code ref/meta/All-Projects/project.config} and * {@code gerrit.config}. * * @param projectConfigObjectId identifies the version of project.config to load and to compile * @return the new scanner configuration to check * @throws IOException if accessing the repository fails */ @Nullable private CheckConfig readConfig(String projectConfigObjectId) throws IOException, ConfigInvalidException { CheckConfig checkConfig = null; // new All-Projects project.config not yet in cache -- read from repository ObjectId id = ObjectId.fromString(projectConfigObjectId); if (ObjectId.zeroId().equals(id)) { return checkConfig; } try (Repository repo = repoManager.openRepository(allProjectsName)) { checkConfig = new CheckConfig(pluginName, readFileContents(repo, id, ProjectConfig.PROJECT_CONFIG)); } gerritConfig = pluginConfigFactory.getFromGerritConfig(pluginName, true);
// new All-Projects project.config not yet in cache -- read from repository ObjectId id = ObjectId.fromString(projectConfigObjectId); if (ObjectId.zeroId().equals(id)) { return checkConfig; } try (Repository repo = repoManager.openRepository(allProjectsName)) { checkConfig = new CheckConfig(pluginName, readFileContents(repo, id, ProjectConfig.PROJECT_CONFIG)); } gerritConfig = pluginConfigFactory.getFromGerritConfig(pluginName, true); if (gerritConfig == null) { checkConfig.scannerConfig.messages.add( ScannerConfig.hintMessage( "missing [plugin \"" + pluginName + "\"] section in gerrit.config")); } else { checkConfig.scannerConfig.defaultEnable = gerritConfig.getBoolean(ScannerConfig.KEY_ENABLE, false); } return checkConfig; } private void logReviewResultErrors(RevisionCreatedListener.Event event, ReviewResult result) { if (!Strings.isNullOrEmpty(result.error)) { logger.atSevere().log(
AddReviewerResult arr = entry.getValue(); if (!Strings.isNullOrEmpty(arr.error)) { logger.atSevere().log( "revision %s: error adding reviewer %s: %s", event.getChange().currentRevision, entry.getKey(), arr.error); metrics.addReviewerErrors.increment(event.getChange().project); metrics.errors.increment(); } } } private String readFileContents(Repository repo, ObjectId objectId, String filename) throws IOException { try (RevWalk rw = new RevWalk(repo); TreeWalk tw = TreeWalk.forPath(rw.getObjectReader(), filename, rw.parseTree(objectId))) { ObjectLoader loader = repo.open(tw.getObjectId(0), Constants.OBJ_BLOB); return new String(loader.getCachedBytes(), UTF_8); } } }
"revision %s: error adding reviewer %s: %s", event.getChange().currentRevision, entry.getKey(), arr.error); metrics.addReviewerErrors.increment(event.getChange().project); metrics.errors.increment(); } } } private String readFileContents(Repository repo, ObjectId objectId, String filename) throws IOException { try (RevWalk rw = new RevWalk(repo); TreeWalk tw = TreeWalk.forPath(rw.getObjectReader(), filename, rw.parseTree(objectId))) { ObjectLoader loader = repo.open(tw.getObjectId(0), Constants.OBJ_BLOB); return new String(loader.getCachedBytes(), UTF_8); } } }
import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.ZkValidationModule; import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; import java.util.Collection; import java.util.UUID; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class Module extends LifecycleModule { private static final Logger log = LoggerFactory.getLogger(Module.class); private Configuration config; private NoteDbStatus noteDb; private final boolean disableGitRepositoryValidation; @Inject public Module(Configuration config, ZookeeperConfig zkConfig, NoteDbStatus noteDb) { this(config, zkConfig, noteDb, false); } // TODO: It is not possible to properly test the libModules in Gerrit. // Disable the Git repository validation during integration test and then build the necessary // support // in Gerrit for it. @VisibleForTesting public Module( Configuration config, ZookeeperConfig zkConfig, NoteDbStatus noteDb, boolean disableGitRepositoryValidation) {
install(new IndexModule()); } if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } install( new MultiSiteValidationModule( config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); install(new ZkValidationModule(config)); bind(Gson.class) .annotatedWith(BrokerGson.class) .toProvider(GsonProvider.class) .in(Singleton.class);
import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class ZookeeperConfig { private static final Logger log = LoggerFactory.getLogger(ZookeeperConfig.class); public static final int defaultSessionTimeoutMs; public static final int defaultConnectionTimeoutMs; public static final String DEFAULT_ZK_CONNECT = "localhost:2181"; private final int DEFAULT_RETRY_POLICY_BASE_SLEEP_TIME_MS = 1000; private final int DEFAULT_RETRY_POLICY_MAX_SLEEP_TIME_MS = 3000; private final int DEFAULT_RETRY_POLICY_MAX_RETRIES = 3; private final int DEFAULT_CAS_RETRY_POLICY_BASE_SLEEP_TIME_MS = 100; private final int DEFAULT_CAS_RETRY_POLICY_MAX_SLEEP_TIME_MS = 300; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3;
public ZkValidationModule(Configuration cfg) { this.cfg = new ZookeeperConfig(cfg.getMultiSiteConfig());
static { System.setProperty("gerrit.notedb", "ON"); } public static class KafkaTestContainerModule extends LifecycleModule { public static class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) { this.kafka = kafka; } @Override public void stop() { kafka.stop(); } @Override public void start() { // Do nothing } } private final FileBasedConfig config; private final FileBasedConfig sharedRefConfig; private final Module multiSiteModule; @Inject public KafkaTestContainerModule(SitePaths sitePaths, NoteDbStatus noteDb) { this.multiSiteConfig = new FileBasedConfig( sitePaths.etc_dir.resolve(Configuration.MULTI_SITE_CONFIG).toFile(), FS.DETECTED); this.sharedRefConfig = new FileBasedConfig( sitePaths.etc_dir.resolve(ZookeeperConfig.ZOOKEEPER_MS_CONFIG).toFile(), FS.DETECTED); this.multiSiteModule = new Module( new Configuration(multiSiteConfig, new Config()), new ZookeeperConfig(sharedRefConfig),
import com.google.gerrit.server.change.ChangeResource; import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.update.CommentsRejectedException; import com.google.gerrit.server.update.UpdateException; import com.google.inject.Inject; import com.google.inject.Module; import com.google.inject.Provider; import java.sql.Timestamp; import org.junit.Before; import org.junit.Test; /** Tests for comment validation in {@link PostReview}. */ @NoHttpd public class PostReviewIT extends AbstractDaemonTest { @Inject private CommentValidator mockCommentValidator; @Inject private TestCommentUtil testCommentUtil; @Override public Module createModule() { return new FactoryModule() { @Override public void configure() { bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); } }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception {
import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.update.CommentsRejectedException; import com.google.gerrit.server.update.UpdateException; import com.google.inject.Inject; import com.google.inject.Module; import com.google.inject.Provider; import java.sql.Timestamp; import org.junit.Before; import org.junit.Test; /** Tests for comment validation in {@link PostReview}. */ @NoHttpd public class PostReviewIT extends AbstractDaemonTest { @Inject private CommentValidator mockCommentValidator; @Inject private TestCommentUtil testCommentUtil; @Override public Module createModule() { return new FactoryModule() { @Override public void configure() { bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); } }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception { String file = "file";
public void configure() { CommentValidator mockCommentValidator = EasyMock.createMock(CommentValidator.class); bind(CommentValidator.class) .annotatedWith(Exports.named(mockCommentValidator.getClass())) .toInstance(mockCommentValidator); bind(CommentValidator.class).toInstance(mockCommentValidator);
} }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception { String file = "file"; PushOneCommit push = pushFactory.create(admin.newIdent(), testRepo, "first subject", file, "contents"); PushOneCommit.Result r = push.to("refs/for/master"); String changeId = r.getChangeId(); String revId = r.getCommit().getName(); PushOneCommit.Result r = createChange(); ReviewInput input = new ReviewInput(); String commentText = "this comment is OK"; CommentInput comment = newComment(file, commentText); comment.updated = new Timestamp(0); input.comments = ImmutableMap.of(comment.path, Lists.newArrayList(comment)); ChangeResource changeResource = changes.get().parse(TopLevelResource.INSTANCE, IdString.fromDecoded(changeId)); RevisionResource revisionResource = revisions.parse(changeResource, IdString.fromDecoded(revId)); assertThat(getPublishedComments(changeId)).isEmpty();
private UUID tryToLoadSavedInstanceId(String serverIdFile) { if (Files.exists(Paths.get(serverIdFile))) { try (BufferedReader br = new BufferedReader(new FileReader(serverIdFile))) { return UUID.fromString(br.readLine()); } catch (IOException e) { log.warn( String.format( "Cannot read instance ID from path '%s', deleting the old file and generating a new ID: (%s)", serverIdFile, e.getMessage())); try { Files.delete(Paths.get(serverIdFile)); } catch (IOException e1) { multisiteLog.warn( String.format( "Cannot delete old instance ID file at path '%s' with instance ID while generating a new one: (%s)", serverIdFile, e1.getMessage())); } } } return null;
protected void configure() { bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getZookeeperConfig().buildCurator()); bind(ZkConnectionConfig.class) .toInstance( new ZkConnectionConfig( cfg.getZookeeperConfig().buildCasRetryPolicy(), cfg.getZookeeperConfig().getZkInterProcessLockTimeOut())); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ProjectDeletedSharedDbCleanup.class);
Throwable t = e.getCause(); if (t instanceof LockFailureException) { logger.atSevere().withCause(t).log("Error in %s %s", req.getMethod(), uriForLogging(req)); responseBytes = replyError( req, res, status = SC_SERVICE_UNAVAILABLE, messageOr(t, "Lock failure"), e); } else { status = SC_INTERNAL_SERVER_ERROR; responseBytes = handleException(e, req, res); } } catch (QuotaException e) { responseBytes = replyError(req, res, status = 429, messageOr(e, "Quota limit reached"), e.caching(), e); } catch (Exception e) { status = SC_INTERNAL_SERVER_ERROR; responseBytes = handleException(e, req, res); } finally { String metric = viewData != null && viewData.view != null ? globals.metrics.view(viewData) : "_unknown";
public static ImmutableList<CommentValidationFailure> findInvalidComments( PluginSetContext<CommentValidator> commentValidators, ImmutableList<CommentForValidation> commentsForValidation) { List<CommentValidationFailure> commentValidationFailures = new ArrayList<>(); commentValidators.runEach( listener -> commentValidationFailures.addAll(listener.validateComments(commentsForValidation))); return commentValidationFailures;
comments.addAll(toPublish); return !toPublish.isEmpty(); } private boolean insertRobotComments(ChangeContext ctx) throws OrmException, PatchListNotAvailableException { if (in.robotComments == null) { return false; } List<RobotComment> newRobotComments = getNewRobotComments(ctx); commentsUtil.putRobotComments(ctx.getUpdate(psId), newRobotComments); comments.addAll(newRobotComments); return !newRobotComments.isEmpty(); } private List<RobotComment> getNewRobotComments(ChangeContext ctx) throws PatchListNotAvailableException { List<RobotComment> toAdd = new ArrayList<>(in.robotComments.size()); Set<CommentSetEntry> existingIds = in.omitDuplicateComments ? readExistingRobotComments(ctx) : Collections.emptySet(); for (Map.Entry<String, List<RobotCommentInput>> ent : in.robotComments.entrySet()) { String path = ent.getKey(); for (RobotCommentInput c : ent.getValue()) { RobotComment e = createRobotCommentFromInput(ctx, path, c); if (existingIds.contains(CommentSetEntry.create(e))) { continue;
name); this.refName = RefNames.REFS_SEQUENCES + name; this.seed = requireNonNull(seed, "seed"); this.floor = floor; checkArgument(batchSize > 0, "expected batchSize > 0, got: %s", batchSize); this.batchSize = batchSize; this.afterReadRef = requireNonNull(afterReadRef, "afterReadRef"); this.retryer = requireNonNull(retryer, "retryer"); counterLock = new ReentrantLock(true); } /** * Retrieves the next available sequence number. * * <p>This method is thread-safe. * * @return the next available sequence number */ public int next() { return Iterables.getOnlyElement(next(1)); } public ImmutableList<Integer> next(int count) { if (count == 0) { return ImmutableList.of(); } checkArgument(count > 0, "count is negative: %s", count); try { return retryer.call( () -> { counterLock.lock(); try { if (count == 1) { if (counter >= limit) { acquire(batchSize); } return ImmutableList.of(counter++); } List<Integer> ids = new ArrayList<>(count); while (counter < limit) {
// from the sequence. Creating an ID requires the RepoSequence.counterLock, if it's not free // (because we forgot to release it before blocking) the call in the other thread would hang and // the test would time out. // We can set the runnable that consumes the ID from another thread only after RepoSequence was // created, because we need the RepoSequence instance to get the next ID. BlockStrategyThatTriggersRunnable blockStrategy = new BlockStrategyThatTriggersRunnable(); // Keep blocking until we verified that another thread can retrieve a sequence number // while we are blocking here. while (isBlocking.get()) { // do nothing } }; // Use batch size = 1 to make each call go to NoteDb. RepoSequence s = newSequence( "id", 1, 1, bgUpdate, RepoSequence.retryerBuilder().withBlockStrategy(blockStrategy).build()); blockStrategy.runOnBlock = () -> { try { Executors.newFixedThreadPool(1) .submit( () -> { // This call hangs if we don't release the RepoSequence.counterLock while we // are blocking until the next try. If this happens we block until the test // times // out.
assertThat(getEmails()).containsExactly(previous); assertThat(gApi.accounts().self().get().email).isNull(); } @Test @Sandboxed public void deleteAllEmails() throws Exception { EmailInput input = new EmailInput(); input.email = "foo.bar@example.com"; input.noConfirmation = true; gApi.accounts().self().addEmail(input); accountIndexedCounter.assertReindexOf(admin); resetCurrentApiUser(); Set<String> allEmails = getEmails(); assertThat(allEmails).hasSize(2); for (String email : allEmails) { gApi.accounts().self().deleteEmail(email); } resetCurrentApiUser(); assertThat(getEmails()).isEmpty(); assertThat(gApi.accounts().self().get().email).isNull(); } @Test public void deleteEmailFromCustomExternalIdSchemes() throws Exception { String email = "foo.bar@example.com"; String extId1 = "foo:bar"; String extId2 = "foo:baz"; List<ExternalId> extIds = ImmutableList.of(
multisiteLog.warn( String.format( "Cannot read instance ID from path '%s', deleting the old file and generating a new ID: (%s)", serverIdFile, e.getMessage())); try { Files.delete(Paths.get(serverIdFile)); } catch (IOException e1) { log.warn( String.format( "Cannot delete old instance ID file at path '%s' with instance ID while generating a new one: (%s)", serverIdFile, e1.getMessage())); } } } return null;
* and executing the callable do not apply. * * <p>See {@link LoggingContextAwareRunnable} for an example. * * @see LoggingContextAwareRunnable */ class LoggingContextAwareCallable<T> implements Callable<T> { private final Callable<T> callable; private final Thread callingThread; private final ImmutableSetMultimap<String, String> tags; private final boolean forceLogging; private final boolean performanceLogging; private final MutablePerformanceLogRecords mutablePerformanceLogRecords; /** * Creates a LoggingContextAwareCallable that wraps the given {@link Callable}. * * @param callable Callable that should be wrapped. * @param mutablePerformanceLogRecords instance of {@link MutablePerformanceLogRecords} to which * performance log records that are created from the runnable are added */ LoggingContextAwareCallable( Callable<T> callable, MutablePerformanceLogRecords mutablePerformanceLogRecords) { this.callable = callable; this.callingThread = Thread.currentThread(); this.tags = LoggingContext.getInstance().getTagsAsMap(); this.forceLogging = LoggingContext.getInstance().isLoggingForced(); this.performanceLogging = LoggingContext.getInstance().isPerformanceLogging(); this.mutablePerformanceLogRecords = mutablePerformanceLogRecords; } @Override
.andReturn(ImmutableList.of(commentForValidation.failValidation("Oh no!"))); EasyMock.replay(mockCommentValidator); PushOneCommit.Result r = createChange(); ReviewInput input = new ReviewInput(); CommentInput comment = newComment(r.getChange().currentFilePaths().get(0)); comment.updated = new Timestamp(0); input.comments = ImmutableMap.of(comment.path, ImmutableList.of(comment)); assertThat(testCommentHelper.getPublishedComments(r.getChangeId())).isEmpty(); BadRequestException badRequestException = assertThrows( RestApiException.class, () -> gApi.changes().id(r.getChangeId()).current().review(input)); assertThat(restApiException.getCause()).isInstanceOf(CommentsRejectedException.class); assertThat( Iterables.getOnlyElement( ((CommentsRejectedException) restApiException.getCause()) .getCommentValidationFailures()) .getComment() .getText()) .isEqualTo(COMMENT_TEXT); assertThat(restApiException.getCause()).hasMessageThat().contains("Oh no!"); assertThat(testCommentUtil.getPublishedComments(r.getChangeId())).isEmpty(); } @Test
public OrmException convertError(String op, SQLException err) { switch (err.getErrorCode()) { case 1022: // ER_DUP_KEY case 1062: // ER_DUP_ENTRY case 1169: // ER_DUP_UNIQUE; return new OrmDuplicateKeyException("ACCOUNT_PATCH_REVIEWS", err); default: if (err.getCause() == null && err.getNextException() != null) { err.initCause(err.getNextException()); } return new OrmException(op + " failure on ACCOUNT_PATCH_REVIEWS", err); }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.base.Preconditions.checkArgument; import static com.google.common.base.Suppliers.memoize; import static com.google.common.base.Suppliers.ofInstance; import com.google.common.annotations.VisibleForTesting; import com.google.common.base.CaseFormat; import com.google.common.base.Strings; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.google.inject.Singleton; import com.google.inject.spi.Message; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.io.IOException; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.commons.lang.StringUtils; import org.apache.curator.RetryPolicy;
private final boolean enabled; private final Map<EventFamily, Boolean> eventsEnabled; private KafkaPublisher(Supplier<Config> cfg) { enabled = cfg.getBoolean( KAFKA_SECTION, KAFKA_PUBLISHER_SUBSECTION, ENABLE_KEY, DEFAULT_BROKER_ENABLED); eventsEnabled = eventsEnabled(cfg, KAFKA_PUBLISHER_SUBSECTION); if (enabled) { setDefaults(); applyKafkaConfig(cfg, KAFKA_PUBLISHER_SUBSECTION, this); }
import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import com.google.common.base.CaseFormat; import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; public KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = lazyLoad(kafkaConfig);
ProvisionException pe = new ProvisionException("error opening ReviewDb"); pe.initCause(e); throw pe; } dbRef.set(db); } return db; } @Override public CurrentUser getUser() { throw new OutOfScopeException("No user during ChangeIndexer"); } }; RequestContext oldCtx = context.setContext(newCtx); try { return callImpl(newCtx.getReviewDbProvider()); } finally { context.setContext(oldCtx); Provider<ReviewDb> db = dbRef.get(); if (db != null) { db.get().close(); } } } catch (Exception e) { log.error("Failed to execute " + this, e); throw e; }
pe.initCause(e); throw pe; } dbRef.set(db); } return db; } @Override public CurrentUser getUser() { throw new OutOfScopeException("No user during ChangeIndexer"); } }; RequestContext oldCtx = context.setContext(newCtx); try { return callImpl(newCtx.getReviewDbProvider()); } finally { context.setContext(oldCtx); Provider<ReviewDb> db = dbRef.get(); if (db != null) { db.get().close(); } } } catch (Exception e) { log.error("Failed to execute " + this, e); throw e; }
} } @Override public void onFailure(Throwable ignored) { // Logged by {@link GetChanges#call()}. } }, directExecutor()); } private abstract class Task<V> implements Callable<V> { protected Event event; protected Task(Event event) { this.event = event; } @Override public final V call() throws Exception { try (ManualRequestContext ctx = requestContext.open()) { return impl(ctx); } catch (Exception e) { log.error("Failed to reindex changes after " + event, e); throw e; } } protected abstract V impl(RequestContext ctx) throws Exception; } private class GetChanges extends Task<List<Change>> { private GetChanges(Event event) { super(event); } @Override protected List<Change> impl(RequestContext ctx) throws OrmException { String ref = event.getRefName(); Project.NameKey project = new Project.NameKey(event.getProjectName());
import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.HashMap; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String KAFKA_CONFIG = "multi-site.config"; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject
import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String KAFKA_CONFIG = "multi-site.config"; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); }
import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); } @VisibleForTesting public KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = ConfigurationHelper.lazyLoad(kafkaConfig);
import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.InstanceId; import com.googlesource.gerrit.plugins.multisite.KafkaConfiguration; import com.googlesource.gerrit.plugins.multisite.broker.BrokerSession; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public class KafkaSession implements BrokerSession { private static final Logger LOGGER = LoggerFactory.getLogger(KafkaSession.class); private Provider<Producer<String, String>> producerProvider; private KafkaConfiguration properties; private final UUID instanceId; private volatile Producer<String, String> producer; @Inject public KafkaSession(KafkaConfiguration kafkaConfig, @InstanceId UUID instanceId) { this.kafkaConfig = kafkaConfig; this.instanceId = instanceId; } @Override public boolean isOpen() { if (producer != null) { return true; } return false; } @Override public void connect() { if (isOpen()) { LOGGER.debug("Already connected."); return; }
// // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.kafka.consumer; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.lifecycle.LifecycleModule; import com.google.inject.TypeLiteral; import com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaSubscriber; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import com.googlesource.gerrit.plugins.multisite.forwarder.events.MultiSiteEvent; public class KafkaConsumerModule extends LifecycleModule { private final KafkaSubscriber kafkaSubscriber; public KafkaConsumerModule(KafkaSubscriber kafkaSubscriber) { this.kafkaSubscriber = kafkaSubscriber; } @Override protected void configure() { MultiSiteEvent.registerEventTypes();
// // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.CACHE_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.PATTERN_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Event.EVENT_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.DEFAULT_SYNCHRONIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.SYNCHRONIZE_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Index.INDEX_SECTION; import org.eclipse.jgit.lib.Config; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.junit.MockitoJUnitRunner;
static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000; static final int DEFAULT_THREAD_POOL_SIZE = 4; static final String NUM_STRIPED_LOCKS = "numStripedLocks"; static final int DEFAULT_NUM_STRIPED_LOCKS = 10; static final String ENABLE_KEY = "enabled"; private final Supplier<Cache> cache; private final Supplier<Event> event; private final Supplier<Index> index; private final Supplier<Collection<Message>> replicationConfigValidation; private final Config multiSiteConfig; @Inject Configuration(SitePaths sitePaths) { this(getConfigFile(sitePaths, MULTI_SITE_CONFIG), getConfigFile(sitePaths, REPLICATION_CONFIG)); } @VisibleForTesting public Configuration(Config multiSiteConfig, Config replicationConfig) { Supplier<Config> lazyMultiSiteCfg = lazyLoad(multiSiteConfig); replicationConfigValidation = lazyValidateReplicatioConfig(replicationConfig); cache = memoize(() -> new Cache(lazyMultiSiteCfg)); event = memoize(() -> new Event(lazyMultiSiteCfg)); index = memoize(() -> new Index(lazyMultiSiteCfg)); } public Cache cache() { return cache.get(); }
private final int threadPoolSize; private final List<String> patterns; private Cache(Supplier<Config> cfg) { super(cfg, CACHE_SECTION); threadPoolSize = getInt(cfg, CACHE_SECTION, null, THREAD_POOL_SIZE_KEY, DEFAULT_THREAD_POOL_SIZE); patterns = Arrays.asList(cfg.get().getStringList(CACHE_SECTION, null, PATTERN_KEY));
import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); } @VisibleForTesting KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = lazyLoad(kafkaConfig);
projectOperations .allProjectsForUpdate() .add(allow(Permission.READ).ref("refs/*").group(admins)) .update(); // Remove all read permissions on All-Users. try (ProjectConfigUpdate u = updateProject(allUsers)) { for (AccessSection sec : u.getConfig().getAccessSections()) { sec.removePermission(Permission.READ); } u.save(); } } // Building the following: // rcMaster (c1 master master-tag) <-- rcBranch (c2 branch branch-tag) // \ \ // (c3_open) (c4_open) // private void setUpChanges() throws Exception { gApi.projects().name(project.get()).branch("branch").create(new BranchInput()); // First 2 changes are merged, which means the tags pointing to them are // visible. projectOperations .project(project) .forUpdate() .add(allow(Permission.SUBMIT).ref("refs/for/refs/heads/*").group(admins)) .update(); PushOneCommit.Result mr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/master%submit"); mr.assertOkStatus(); cd1 = mr.getChange(); rc1 = mr.getCommit(); psRef1 = cd1.currentPatchSet().id().toRefName();
// Remove all read permissions on All-Users. try (ProjectConfigUpdate u = updateProject(allUsers)) { for (AccessSection sec : u.getConfig().getAccessSections()) { sec.removePermission(Permission.READ); } u.save(); } } private void setUpChanges() throws Exception { gApi.projects().name(project.get()).branch("branch").create(new BranchInput()); // First 2 changes are merged, which means the tags pointing to them are // visible. projectOperations .project(project) .forUpdate() .add(allow(Permission.SUBMIT).ref("refs/for/refs/heads/*").group(admins)) .update(); // rcMaster (c1 master) PushOneCommit.Result mr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/master%submit"); mr.assertOkStatus(); cd1 = mr.getChange(); rc1 = mr.getCommit(); psRef1 = cd1.currentPatchSet().id().toRefName(); metaRef1 = RefNames.changeMetaRef(cd1.getId()); PushOneCommit.Result br =
* .haves}. This is a heuristical approach that aims at scaling down the number of unnecessary * objects that client sends to the server. Unnecessary here refers to objects that the server * already has. * * <p>For some code paths in {@link com.google.gerrit.server.git.DefaultAdvertiseRefsHook}, we * already removed refs/changes, so the logic to skip these in this class become a no-op. * * <p>TODO(hiesel): Instrument this heuristic and proof its value. */ public class ReceiveCommitsAdvertiseRefsHook implements AdvertiseRefsHook { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final Provider<InternalChangeQuery> queryProvider; private final Project.NameKey projectName; public ReceiveCommitsAdvertiseRefsHook( Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName) { this.queryProvider = queryProvider; this.projectName = projectName; } @Override public void advertiseRefs(UploadPack us) { throw new UnsupportedOperationException( "ReceiveCommitsAdvertiseRefsHook cannot be used for UploadPack"); } @Override
Project.NameKey projectName) { return create(allRefsWatcher, perm, queryProvider, projectName, false); } /** * Returns a single {@link AdvertiseRefsHook} that encompasses a chain of {@link * AdvertiseRefsHook} to be used for advertising when processing a Git push. Omits {@link * HackPushNegotiateHook} as that does not advertise refs on it's own but adds {@code .have} based * on history which is not relevant for the tests we have. */ @VisibleForTesting public static AdvertiseRefsHook createForTest( PermissionBackend.ForProject perm, Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName) { return create(new AllRefsWatcher(), perm, queryProvider, projectName, true); } private static AdvertiseRefsHook create( AllRefsWatcher allRefsWatcher, PermissionBackend.ForProject perm, Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName, boolean skipHackPushNegotiateHook) { List<AdvertiseRefsHook> advHooks = new ArrayList<>(); advHooks.add(allRefsWatcher); advHooks.add(
} /** Returns the URL for viewing a comment in a file in a given patch set of a change. */ default Optional<String> getInlineCommentView( Change change, int patchsetId, String filename, short side, int startLine) { return getPatchFileView(change, patchsetId, filename) .map(url -> url + String.format("@%s%d", side == 0 ? "a" : "", startLine)); } /** Returns a URL pointing to a section of the settings page. */ default Optional<String> getSettingsUrl(@Nullable String section) { return getWebUrl() .map(url -> url + "settings" + (Strings.isNullOrEmpty(section) ? "" : "#" + section)); } /** Returns a URL pointing to a documentation page, at a given named anchor. */ default Optional<String> getDocUrl(String page, String anchor) { return getWebUrl().map(url -> url + "Documentation/" + page + "#" + anchor); }
public void connect() { if (isOpen()) { multisiteLog.debug("Already connected."); return; } multisiteLog.info("Connect to {}...", properties.getKafka().getBootstrapServers()); /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader(); producer = producerProvider.get(); LOGGER.info("Connection established.");
public void connect() { if (isOpen()) { LOGGER.debug("Already connected."); return; } /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader(); producer = new KafkaProducer<>(properties.kafkaPublisher()); LOGGER.info("Connection established.");
COMMIT_FOOTERS(17), /** Include push certificate information along with any patch sets. */ PUSH_CERTIFICATES(18), /** Include change's reviewer updates. */ REVIEWER_UPDATES(19), /** Set the submittable boolean. */ SUBMITTABLE(20), /** If tracking Ids are included, include detailed tracking Ids info. */ TRACKING_IDS(21), /** Skip mergeability data */ SKIP_MERGEABLE(22), /** Skip diffstat computation */ SKIP_DIFFSTAT(23); private final int value; ListChangesOption(int v) { this.value = v; } @Override public int getValue() { return value; } }
out.hashtags = cd.hashtags(); out.changeId = in.getKey().get(); if (in.isNew()) { SubmitTypeRecord str = cd.submitTypeRecord(); if (str.isOk()) { out.submitType = str.type; } if (!excludeMergeableInChangeInfo && !has(SKIP_MERGEABLE)) { out.mergeable = cd.isMergeable(); } if (has(SUBMITTABLE)) { out.submittable = submittable(cd); } } if (!has(SKIP_DIFFSTAT)) { Optional<ChangedLines> changedLines = cd.changedLines(); if (changedLines.isPresent()) { out.insertions = changedLines.get().insertions; out.deletions = changedLines.get().deletions; } } out.isPrivate = in.isPrivate() ? true : null; out.workInProgress = in.isWorkInProgress() ? true : null; out.hasReviewStarted = in.hasReviewStarted(); out.subject = in.getSubject(); out.status = in.getStatus().asChangeStatus(); out.owner = accountLoader.get(in.getOwner());
if (pr.getAction() == PermissionRule.Action.ALLOW && projectControl.match(pr, isChangeOwner)) { // For votes, contrary to normal permissions, we aggregate all applicable rules. voteMin = Math.min(voteMin, pr.getMin()); voteMax = Math.max(voteMax, pr.getMax()); } } return new PermissionRange( permissionName, Math.max(voteMin, blockAllowMin), Math.min(voteMax, blockAllowMax));
public TestRefValidator(ReceiveCommand.Type rejectType) { this.rejectType = rejectType; this.rejectRef = TEST_REF; this.handle = validators.add("test-" + rejectType.name(), this);
if (valueType == String.class) { return s -> (String) s; } else if (valueType == Integer.class || valueType == Boolean.class) { return Object::toString; } else if (Enum.class.isAssignableFrom(valueType)) { return in -> ((Enum<?>) in).name(); } throw new IllegalStateException("unsupported type " + valueType.getName()); } @AutoValue.Builder public abstract static class Builder<T> { abstract Builder<T> name(String name); abstract Builder<T> valueType(Class<T> type); abstract Builder<T> formatter(Function<T, String> formatter); public abstract Builder<T> description(String description); abstract Field<T> autoBuild(); public Field<T> build() { Field<T> field = autoBuild(); checkArgument(field.name().matches("^[a-z_]+$"), "name must match [a-z_]"); return field; } } }
} private Function<T, String> formatter; /** @return name of this field within the metric. */ public abstract String name(); /** @return type of value used within the field. */ public abstract Class<T> valueType(); /** @return description text for the field explaining its range of values. */ public abstract Optional<String> description(); /** @return formatter to format field values. */ public abstract Function<T, String> formatter(); private static <T> Function<T, String> initFormatter(Class<T> valueType) { if (valueType == String.class) { return s -> (String) s; } else if (valueType == Integer.class || valueType == Boolean.class) { return Object::toString; } else if (Enum.class.isAssignableFrom(valueType)) { return in -> ((Enum<?>) in).name(); } throw new IllegalStateException("unsupported type " + valueType.getName()); } @AutoValue.Builder
reject(cmd, "not valid ref"); return; } if (RefNames.isNoteDbMetaRef(cmd.getRefName())) { // Reject pushes to NoteDb refs without a special option and permission. Note that this // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will // migrate to NoteDb eventually, and we don't want garbage data waiting there when the // migration finishes. logDebug( "%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption); if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) { // Only reject this command, not the whole push. This supports the use case of "git clone // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone // or mirror the NoteDb data; there is no single refspec that describes all refs *except* // NoteDb refs. reject( cmd,
public Context start(F1 fieldValue) { return new Context(this, fieldValue);
.valueType(Boolean.class) .formatter(Object::toString) .name(name); } /** * Break down metrics by cases of an enum. * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static <E extends Enum<E>> Field.Builder<E> ofEnum(Class<E> enumType, String name) { return new AutoValue_Field.Builder<E>().valueType(enumType).formatter(Enum::name).name(name); } /** * Break down metrics by integer. * * <p>Each unique integer will allocate a new submetric. <b>Do not use user content as a field * value</b> as field values are never reclaimed. * * @param name field name * @return builder for the integer field */ public static Field.Builder<Integer> ofInteger(String name) { return new AutoValue_Field.Builder<Integer>() .valueType(Integer.class) .formatter(Object::toString)
public RequestMetrics(MetricMaker metricMaker) { Field<Integer> statusCodeField = Field.ofInteger("status", Metadata.Builder::httpStatus) .description("HTTP status code") .build(); errors = metricMaker.newCounter( "http/server/error_count", new Description("Rate of REST API error responses").setRate().setUnit("errors"), statusCodeField); successes = metricMaker.newCounter( "http/server/success_count", new Description("Rate of REST API success responses").setRate().setUnit("successes"), statusCodeField);
package com.google.gerrit.metrics; import static com.google.common.base.Preconditions.checkArgument; import com.google.auto.value.AutoValue; import java.util.Optional; import java.util.function.Function; /** * Describes a bucketing field used by a metric. * * @param <T> type of field */ @AutoValue public abstract class Field<T> { /** * Break down metrics by boolean true/false. * * @param name field name * @return builder for the boolean field */ public static Field.Builder<Boolean> ofBoolean( String name, BiConsumer<Metadata.Builder, Boolean> metadataMapper) { return new AutoValue_Field.Builder<Boolean>() .valueType(Boolean.class) .formatter(Object::toString) .name(name); } /** * Break down metrics by cases of an enum. * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static <E extends Enum<E>> Field.Builder<E> ofEnum(Class<E> enumType, String name) {
public abstract Class<T> valueType(); /** @return description text for the field explaining its range of values. */ public abstract Optional<String> description(); /** @return formatter to format field values. */ public abstract Function<T, String> formatter(); @AutoValue.Builder public abstract static class Builder<T> { abstract Builder<T> name(String name); abstract Builder<T> valueType(Class<T> type); abstract Builder<T> formatter(Function<T, String> formatter); abstract Builder<T> metadataMapper(BiConsumer<Metadata.Builder, T> metadataMapper); public abstract Builder<T> description(String description); abstract Field<T> autoBuild(); public Field<T> build() { Field<T> field = autoBuild(); checkArgument(field.name().matches("^[a-z_]+$"), "name must match [a-z_]"); return field; } } }
@Singleton public class UploadPackMetricsHook implements PostUploadHook { enum Operation { CLONE, FETCH; } private final Counter1<Operation> requestCount; private final Timer1<Operation> counting; private final Timer1<Operation> compressing; private final Timer1<Operation> writing; private final Histogram1<Operation> packBytes; @Inject UploadPackMetricsHook(MetricMaker metricMaker) { Field<Operation> operationField = Field.ofEnum(Operation.class, "operation", Metadata.Builder::gitOperation).build(); requestCount = metricMaker.newCounter( "git/upload-pack/request_count", new Description("Total number of git-upload-pack requests") .setRate() .setUnit("requests"), operationField); counting = metricMaker.newTimer( "git/upload-pack/phase_counting", new Description("Time spent in the 'Counting...' phase") .setCumulative() .setUnit(Units.MILLISECONDS), operationField); compressing = metricMaker.newTimer( "git/upload-pack/phase_compressing", new Description("Time spent in the 'Compressing...' phase")
// The name of a branch. public abstract Optional<String> branchName(); // Key of an entity in a cache. public abstract Optional<String> cacheKey(); // The name of a cache. public abstract Optional<String> cacheName(); // The name of the implementation class. public abstract Optional<String> className(); // The numeric ID of a change. public abstract Optional<Integer> changeId(); // The type of change ID which the user used to identify a change (e.g. numeric ID, triplet etc.). public abstract Optional<String> changeIdType(); // The type of an event. public abstract Optional<String> eventType(); // The name under which a plugin extension was registered. public abstract Optional<String> exportName(); // Garbage collector name. public abstract Optional<String> garbageCollectorName(); // Git operation (CLONE, FETCH). public abstract Optional<String> gitOperation(); // The numeric ID of an internal group. public abstract Optional<Integer> groupId(); // The name of a group. public abstract Optional<String> groupName();
public abstract Optional<String> cacheName(); // The name of the implementation class. public abstract Optional<String> className(); // The numeric ID of a change. public abstract Optional<Integer> changeId(); // The type of change ID (e.g. numeric ID, triplet etc.). public abstract Optional<String> changeIdType(); // The type of an event. public abstract Optional<String> eventType(); // The value of the @Export annotation which was used to register a plugin extension. public abstract Optional<String> exportValue(); // Garbage collector name. public abstract Optional<String> garbageCollectorName(); // Git operation (CLONE, FETCH). public abstract Optional<String> gitOperation(); // The numeric ID of an internal group. public abstract Optional<Integer> groupId(); // The name of a group. public abstract Optional<String> groupName(); // The UUID of a group. public abstract Optional<String> groupUuid(); // HTTP status response code. public abstract Optional<Integer> httpStatus(); // The name of a secondary index.
public abstract Optional<Integer> groupId(); // The name of a group. public abstract Optional<String> groupName(); // The UUID of a group. public abstract Optional<String> groupUuid(); // HTTP status response code. public abstract Optional<Integer> httpStatus(); // The name of a secondary index. public abstract Optional<String> indexName(); // The version of a secondary index. public abstract Optional<Integer> indexVersion(); // The name of the implementation method. public abstract Optional<String> methodName(); // Boolean: one or more public abstract Optional<Boolean> multiple(); // Name of a metadata file in NoteDb. public abstract Optional<String> noteDbFileName(); // Name of a metadata ref in NoteDb. public abstract Optional<String> noteDbRefName(); // Type of a sequence in NoteDb (ACCOUNTS, CHANGES, GROUPS). public abstract Optional<String> noteDbSequenceType();
public abstract Optional<String> restViewName(); // The SHA1 of Git commit. public abstract Optional<String> revision(); // The username of an account. public abstract Optional<String> username(); public static Metadata.Builder builder() { return new AutoValue_Metadata.Builder(); } public static Metadata empty() { return builder().build(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder accountId(int accountId); public abstract Builder actionType(@Nullable String actionType); public abstract Builder authDomainName(@Nullable String authDomainName); public abstract Builder branchName(@Nullable String branchName); public abstract Builder cacheKey(@Nullable String cacheKey); public abstract Builder cacheName(@Nullable String cacheName); public abstract Builder className(@Nullable String className); public abstract Builder changeId(int changeId); public abstract Builder changeIdType(@Nullable String changeIdType); public abstract Builder eventType(@Nullable String eventType); public abstract Builder exportName(@Nullable String exportName); public abstract Builder garbageCollectorName(@Nullable String garbageCollectorName); public abstract Builder gitOperation(@Nullable String gitOperation);
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.logging; import static java.util.Objects.requireNonNull; import com.google.auto.value.AutoValue; import com.google.gerrit.common.Nullable; /** * The record of an operation for which the execution time was measured. * * <p>Metadata to provide additional context can be included by provided a {@link Metadata} * instance. */ @AutoValue public abstract class PerformanceLogRecord { /** * Creates a performance log record without meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs) { return new AutoValue_PerformanceLogRecord(operation, durationMs, null); } /** * Creates a performance log record with meta data. *
} /** * Creates a performance log record with meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @param metadata metadata * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs, Metadata metadata) { return new AutoValue_PerformanceLogRecord(operation, durationMs, requireNonNull(metadata)); } public abstract String operation(); public abstract long durationMs(); public abstract Optional<Metadata> metadata(); void writeTo(PerformanceLogger performanceLogger) { if (metadata() != null) { performanceLogger.log(operation(), durationMs(), metadata()); } else { performanceLogger.log(operation(), durationMs()); } } }
if (refEnforcementPolicy == EnforcePolicy.IGNORED) return; String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been " + "persisted locally but not in SharedRef the value %s", projectName, refPair.getName(), refPair.putValue); boolean succeeded; try { succeeded = sharedRefDb.compareAndPut(projectName, refPair.compareRef, refPair.putValue); } catch (IOException e) { throw new SharedDbSplitBrainException(errorMessage, e); } if (!succeeded) { throw new SharedDbSplitBrainException(errorMessage); } } protected void checkIfLocalRefIsUpToDateWithSharedRefDb( RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return; }
} } private void updateSharedRefDb(Stream<ReceiveCommand> commandStream, List<RefPair> refsToUpdate) throws IOException { if (commandStream .filter(cmd -> cmd.getResult() != ReceiveCommand.Result.OK) .findFirst() .isPresent()) { return; } List<RefPair> updatedRefPairs = refsToUpdate .stream() .filter(distinctByKey(BatchRefUpdateValidator::getName)) .map( p -> { try { RefPair current = getLatestLocalRef(p); return new RefPair(p.compareRef, current.putValue); } catch (IOException e) { throw new RuntimeException(e); } }) .collect(Collectors.toList()); for (RefPair refPair : updatedRefPairs) { updateSharedDbOrThrowExceptionFor(refPair); } } public static String getName(RefPair p) { return p.compareRef.getName(); } public static <T> Predicate<T> distinctByKey(Function<? super T, ?> keyExtractor) { Set<Object> seen = ConcurrentHashMap.newKeySet();
return get(Arrays.asList(options)); } /** * {@link #get(ListChangesOption...)} with all options included, except for the following. * * <ul> * <li>{@code CHECK} is omitted, to skip consistency checks. * <li>{@code SKIP_MERGEABLE} is omitted, so the {@code mergeable} bit <em>is</em> set. * <li>{@code SKIP_DIFFSTAT} is omitted to skip diffstat calculations. * </ul> */ default ChangeInfo get() throws RestApiException { return get( EnumSet.complementOf( EnumSet.of( ListChangesOption.CHECK, ListChangesOption.SKIP_MERGEABLE, ListChangesOption.SKIP_DIFFSTAT))); } /** {@link #get(ListChangesOption...)} with no options included. */ default ChangeInfo info() throws RestApiException { return get(EnumSet.noneOf(ListChangesOption.class)); } /** * Retrieve change edit when exists. * * @deprecated Replaced by {@link ChangeApi#edit()} in combination with {@link
case DELETE: return new RefPair(getCurrentRef(command.getRefName()), ObjectId.zeroId()); default: return new RefPair( command.getRef(), new IllegalArgumentException("Unsupported command type " + command.getType())); } } catch (IOException e) { return new RefPair(command.getRef(), e); } } private ObjectId getNewRef(ReceiveCommand command) { return command.getNewId(); } private List<RefPair> compareAndGetLatestLocalRefs( List<RefPair> refsToUpdate, CloseableSet<AutoCloseable> locks) throws IOException { List<RefPair> latestRefsToUpdate = new ArrayList<>(); for (RefPair refPair : refsToUpdate) { latestRefsToUpdate.add(checkIfLocalRefIsUpToDateWithSharedRefDb(refPair, locks)); } return latestRefsToUpdate; } }
+ "persisted locally but not in SharedRef the value %s", projectName, refPair.getName(), refPair.putValue); boolean succeeded; try { succeeded = sharedRefDb.compareAndPut(projectName, refPair.compareRef, refPair.putValue); } catch (IOException e) { throw new SharedDbSplitBrainException(errorMessage, e); } if (!succeeded) { throw new SharedDbSplitBrainException(errorMessage); } } protected RefPair compareAndGetLatestLocalRef( RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist( String.format("%s-%s", projectName, refName), () -> sharedRefDb.lockRef(projectName, refName)); RefPair latestRefPair = getLatestLocalRef(refPair); boolean isInSync =
info = getPatchSetInfo(ctx); ChangeUpdate update = ctx.getUpdate(psId); Change.Status status = change.getStatus(); if (status == Change.Status.MERGED) { return true; } change.setCurrentPatchSet(info); change.setStatus(Change.Status.MERGED); // we cannot reconstruct the submit records for when this change was // submitted, this is why we must fix the status update.fixStatus(Change.Status.MERGED); update.setCurrentPatchSet(); if (change.isWorkInProgress()) { update.setWorkInProgress(false); } StringBuilder msgBuf = new StringBuilder(); msgBuf.append("Change has been successfully pushed"); if (!refName.equals(change.getDest().get())) { msgBuf.append(" into "); if (refName.startsWith(Constants.R_HEADS)) { msgBuf.append("branch "); msgBuf.append(Repository.shortenRefName(refName)); } else { msgBuf.append(refName); } } msgBuf.append("."); ChangeMessage msg = ChangeMessagesUtil.newMessage(
fields = config.getBoolean("logFormat", pretty, "verbose", false) ? VERBOSE_FIELDS : FIELDS; variant = firstNonNull(config.getString("logFormat", pretty, "variant"), pretty); } public void renderStreaming( Paginator paginator, @Nullable String revision, Renderer renderer, Writer out, DateFormatter df, FooterBehavior footerBehavior) throws IOException { out.write( renderer .newRenderer("gitiles.logEntriesHeader") .setData(toHeaderSoyData(paginator, revision)) .renderHtml(out)); SoySauce.Renderer entryRenderer = renderer.newRenderer("gitiles.logEntryWrapper"); boolean renderedEntries = false; for (RevCommit c : paginator) { out.write(entryRenderer.setData(toEntrySoyData(paginator, c, df)).render().get()); out.flush(); renderedEntries = true; } if (!renderedEntries) { renderer.newRenderer("gitiles.emptyLog").render().get(); } out.write( renderer .newRenderer("gitiles.logEntriesFooter") .setData(toFooterSoyData(paginator, revision, footerBehavior)) .render()
private boolean isInternalRef(String refName) { return RefNames.isNoteDbMetaRef(refName) || refName.startsWith(RefNames.REFS_SEQUENCES);
private boolean isInternalRef(String refName) { return RefNames.isNoteDbMetaRef(refName) || refName.startsWith(RefNames.REFS_SEQUENCES);
EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist( String.format("%s-%s", projectName, refName), () -> sharedRefDb.lockRef(projectName, refName)); Ref localRef = getLatestLocalRef(refPair); boolean isInSync = (latestRefPair.compareRef.getObjectId().equals(ObjectId.zeroId())) ? !sharedRefDb.exists(projectName, refName) : sharedRefDb.isUpToDate(projectName, latestRefPair.compareRef); if (!isInSync) { validationMetrics.incrementSplitBrainPrevention(); softFailBasedOnEnforcement( new OutOfSyncException(projectName, localRef), refEnforcementPolicy); } return new RefPair(localRef == null ? nullRef(refName) : localRef, refPair.putValue); } private Ref getLatestLocalRef(RefPair refPair) throws IOException { return refDb.exactRef(refPair.getName()); } protected boolean isSuccessful(RefUpdate.Result result) { switch (result) { case NEW: case FORCED: case FAST_FORWARD: case NO_CHANGE:
HttpServletResponse res, int statusCode, String msg, CacheControl c, @Nullable Throwable err) throws IOException { if (err != null) { RequestUtil.setErrorTraceAttribute(req, err); } configureCaching(req, res, null, null, c); checkArgument(statusCode >= 400, "non-error status: %s", statusCode); res.setStatus(statusCode); logger.atFinest().log("REST call failed: %d", statusCode); return replyText(req, res, true, msg); } /** * Sets a text reply on the given HTTP servlet response. * * @param req the HTTP servlet request * @param res the HTTP servlet response on which the reply should be set * @param allowTracing whether it is allowed to log the reply if tracing is enabled, must not be * set to {@code true} if the reply may contain sensitive data * @param text the text reply
} return Optional.empty(); } private Optional<Project.NameKey> getProjectNameForChangeId(String changeId) { Optional<Project.NameKey> projectName = extractProjectNameFromChangeId(changeId); if (projectName.isPresent()) { return projectName; } try { List<ChangeData> changeData = globals .queryProvider .get() .setRequestedFields(ChangeField.PROJECT) .setLimit(2) .query(globals.changeQueryBuilder.change(changeId)); if (changeData.size() != 1) { // no change found (size = 0) or changeId was ambiguous (size > 1) return Optional.empty(); } return Optional.of(changeData.get(0).project()); } catch (QueryParseException e) { return Optional.empty(); } } @VisibleForTesting static Optional<Project.NameKey> extractProjectNameFromChangeId(String changeId) { int projectEndPosition = changeId.indexOf('~'); if (projectEndPosition <= 0) { return Optional.empty(); } return Optional.of( Project.nameKey(IdString.fromUrl(changeId.substring(0, projectEndPosition)).get())); } private boolean isDelete(HttpServletRequest req) {
package com.google.gerrit.server; import com.google.auto.value.AutoValue; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.logging.TraceContext; import java.util.Optional; /** Information about a request that was received from a user. */ @AutoValue public abstract class RequestInfo { public enum RequestType { GIT_RECEIVE, GIT_UPLOAD, REST, SSH } /** * Type of the request, telling through which channel the request was coming in (see {@link * RequestType}). */ public abstract RequestType requestType(); /** The user that has sent the request. */ public abstract CurrentUser callingUser(); /** The trace context of the request. */ public abstract TraceContext traceContext(); /** * The name of the project for which the request is being done. Only available if the request is * tied to a project or change. If a project is available it's not guaranteed that it actually
import com.google.common.hash.Hashing; import com.google.gerrit.common.data.GroupReference; import com.google.gerrit.extensions.annotations.PluginCanonicalWebUrl; import com.google.gerrit.extensions.annotations.PluginName; import com.google.gerrit.extensions.api.groups.Groups; import com.google.gerrit.extensions.common.GroupInfo; import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.ResourceConflictException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.account.GroupMembership; import com.google.gerrit.server.config.AllProjectsNameProvider; import com.google.gerrit.server.config.PluginConfigFactory; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.gerrit.server.permissions.ProjectPermission; import com.google.gerrit.server.project.CreateProjectArgs; import com.google.gerrit.server.project.NoSuchProjectException; import com.google.gerrit.server.validators.ProjectCreationValidationListener; import com.google.gerrit.server.validators.ValidationException;
private boolean isOwner(Project.NameKey project) { try { permissionBackend.user(self.get()).project(project).check(ProjectPermission.WRITE_CONFIG); } catch (AuthException | PermissionBackendException noWriter) { try { permissionBackend.user(self.get()).check(GlobalPermission.ADMINISTRATE_SERVER); } catch (AuthException | PermissionBackendException noAdmin) { return false; } } return true;
return get(Arrays.asList(options)); } /** * {@link #get(ListChangesOption...)} with all options included, except for the following. * * <ul> * <li>{@code CHECK} is omitted, to skip consistency checks. * <li>{@code SKIP_MERGEABLE} is omitted, so the {@code mergeable} bit <em>is</em> set. * <li>{@code SKIP_DIFFSTAT} is omitted to ensure diffstat calculations. * </ul> */ default ChangeInfo get() throws RestApiException { return get( EnumSet.complementOf( EnumSet.of( ListChangesOption.CHECK, ListChangesOption.SKIP_MERGEABLE, ListChangesOption.SKIP_DIFFSTAT))); } /** {@link #get(ListChangesOption...)} with no options included. */ default ChangeInfo info() throws RestApiException { return get(EnumSet.noneOf(ListChangesOption.class)); } /** * Retrieve change edit when exists. * * @deprecated Replaced by {@link ChangeApi#edit()} in combination with {@link
/** Include a copy of commit messages including review footers. */ COMMIT_FOOTERS(17), /** Include push certificate information along with any patch sets. */ PUSH_CERTIFICATES(18), /** Include change's reviewer updates. */ REVIEWER_UPDATES(19), /** Set the submittable boolean. */ SUBMITTABLE(20), /** If tracking Ids are included, include detailed tracking Ids info. */ TRACKING_IDS(21), /** Skip mergeability data */ SKIP_MERGEABLE(22), /** * Skip diffstat computation that compute the insertions field (number of lines inserted) and * deletions field (number of lines deleted) */ SKIP_DIFFSTAT(23); private final int value; ListChangesOption(int v) { this.value = v; } @Override public int getValue() { return value; } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api.changes; import java.util.List; /** Detailed information about who should be notified about an update. */ public class NotifyInfo { public List<String> accounts; /** * @param accounts may be either just a list of: account IDs, Full names, usernames, or emails. * Also could be a list of those: "Full name <email@example.com>" or "Full name (<ID>)" */ public NotifyInfo(List<String> accounts) { this.accounts = accounts; } }
// See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api.changes; import java.util.List; /** Detailed information about who should be notified about an update. */ public class NotifyInfo { public List<String> accounts; /** * @param accounts may be either just a list of: account IDs, Full names, usernames, or emails. * Also could be a list of those: "Full name <email@example.com>" or "Full name (<ID>)" */ public NotifyInfo(List<String> accounts) { this.accounts = accounts; } }
addDraft(changeId, revId, comment); assertThat(gApi.changes().query("change:" + changeId + " has:draft").get()).hasSize(1); } } @Test public void publishCommentsAllRevisions() throws Exception { PushOneCommit.Result result = createChange(); String changeId = result.getChangeId(); pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "initial content\n", changeId) .to("refs/heads/master"); PushOneCommit.Result r1 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "old boring content\n") .to("refs/for/master"); PushOneCommit.Result r2 = pushFactory .create( admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "new interesting\ncntent\n", r1.getChangeId()) .to("refs/for/master"); addDraft( r1.getChangeId(), r1.getCommit().getName(),
addDraft(changeId, revId, comment); assertThat(gApi.changes().query("change:" + changeId + " has:draft").get()).hasSize(1); } } @Test public void publishCommentsAllRevisions() throws Exception { PushOneCommit.Result result = createChange(); String changeId = result.getChangeId(); pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "initial content\n", changeId) .to("refs/heads/master"); PushOneCommit.Result r1 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "old boring content\n") .to("refs/for/master"); PushOneCommit.Result r2 = pushFactory .create( admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "new interesting\ncntent\n", r1.getChangeId()) .to("refs/for/master"); addDraft( r1.getChangeId(), r1.getCommit().getName(),
protected void configure() { if (!noteDb.enabled()) { throw new ProvisionException( "Gerrit is still running on ReviewDb: please migrate to NoteDb " + "and then reload the multi-site plugin."); } Collection<Message> validationErrors = config.validate(); if (!validationErrors.isEmpty()) { throw new CreationException(validationErrors); } listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); DynamicItem.itemOf(binder(), BrokerSession.class); DynamicItem.bind(binder(), BrokerSession.class).to(BrokerSessionNoOp.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } install(kafkaForwardedEventRouterModule); install(kafkaBrokerForwarderModule); install( new ValidationModule( config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled()));
"Kafka consumer subscribing to topic [%s] for event family [%s]", topic, getEventFamily()); consumer.subscribe(Collections.singleton(topic)); while (!closed.get()) { ConsumerRecords<byte[], byte[]> consumerRecords = consumer.poll(Duration.ofMillis(configuration.kafkaSubscriber().getPollingInterval())); consumerRecords.forEach(this::processRecord); } } catch (WakeupException e) { // Ignore exception if closing if (!closed.get()) throw e; } catch (Exception e) { subscriberMetrics.incrementSubscriberFailedToPollMessages(); throw e; } finally { consumer.close(); }
subscriberMetrics.incrementSubscriberConsumedMessage(); } catch (IOException e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (PermissionBackendException | OrmException e) { logger.atSevere().withCause(e).log( "Cannot handle message %s: [Exception: %s]", event.getHeader().getEventType()); } } } catch (Exception e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", new String(consumerRecord.value(), UTF_8)); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); }
for (String src : delta) { Ref r = local.get(src); if (r != null) { n.put(src, r); } } local = n; } local = forProject.filter(local, git, RefFilterOptions.builder().setFilterMeta(true).build()); } List<RemoteRefUpdate> remoteUpdatesList = pushAllRefs ? doPushAll(tn, local) : doPushDelta(local); ReplicationPushFilter pushFilter = replicationPushFilter.get(); return pushFilter.filter(projectName.get(), remoteUpdatesList); } private List<RemoteRefUpdate> doPushAll(Transport tn, Map<String, Ref> local) throws NotSupportedException, TransportException, IOException { List<RemoteRefUpdate> cmds = new ArrayList<>(); boolean noPerms = !pool.isReplicatePermissions(); Map<String, Ref> remote = listRemote(tn); for (Ref src : local.values()) { if (!canPushRef(src.getName(), noPerms)) { continue; }
protected void configure() { DynamicItem.itemOf(binder(), ReplicationPushFilter.class);
return java.nio.file.Files.createTempDirectory(prefix); } @Test public void shouldLoadNotEmptyInitialReplicationConfig() throws Exception { FileBasedConfig replicationConfig = newReplicationConfig(); replicationConfig.setString("remote", "foo", "url", "ssh://git@git.somewhere.com/${name}"); replicationConfig.save(); autoReloadConfig = new AutoReloadConfigDecorator( sitePaths, destinationFactoryMock, Providers.of(replicationQueueMock), pluginDataPath, "replication", workQueueMock); assertThat(autoReloadConfig.getDestinations(FilterType.ALL)).hasSize(1); } @Test public void shouldAutoReloadReplicationConfig() throws Exception { FileBasedConfig replicationConfig = newReplicationConfig(); replicationConfig.setBoolean("gerrit", null, "autoReload", true); replicationConfig.setString("remote", "foo", "url", "ssh://git@git.foo.com/${name}"); replicationConfig.save(); autoReloadConfig = new AutoReloadConfigDecorator( sitePaths, destinationFactoryMock, Providers.of(replicationQueueMock), pluginDataPath, "replication", workQueueMock); autoReloadConfig.startup(workQueueMock);
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.index; import java.util.Optional; public class OnlineReindexMode { private static ThreadLocal<Boolean> isOnlineReindex = new ThreadLocal<>(); public static boolean get() { return Optional.ofNullable(isOnlineReindex.get()).orElse(Boolean.FALSE); } public static void begin() { isOnlineReindex.set(Boolean.TRUE); } public static void end() { isOnlineReindex.set(Boolean.FALSE); } }
public static boolean isActive() { return Optional.ofNullable(isOnlineReindex.get()).orElse(Boolean.FALSE);
import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class JgitWrapper { private static final Logger log = LoggerFactory.getLogger(JgitWrapper.class); public static Optional<byte[]> getBlobAsBytes(Repository repository, String revision, String path) throws IOException { ObjectId objectId = repository.resolve(revision); if (objectId == null) { return Optional.empty(); } try (final TreeWalk w = TreeWalk.forPath( repository, path, parseCommit(repository, objectId).getTree())) { return Optional.ofNullable(w) .filter(walk -> (walk.getRawMode(0) & TYPE_MASK) == TYPE_FILE) .map(walk -> walk.getObjectId(0)) .flatMap(id -> readBlob(repository, id)); } } private static RevCommit parseCommit(Repository repository, ObjectId commit) throws IOException { try (final RevWalk walk = new RevWalk(repository)) { walk.setRetainBody(true); return walk.parseCommit(commit); } } private static Optional<byte[]> readBlob(Repository repository, ObjectId id) {
// You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.quota; public class QuotaGroupDefinitions { /** * Definition of repository size quota group. {@link QuotaEnforcer} implementations for repository * size quota have to act on requests with this group name. */ public static final String REPOSITORY_SIZE_GROUP = "/repository:size"; private QuotaGroupDefinitions() {} }
private static boolean isContentTooLargeForDisplay(String content) { int lines = 0; int start = 0; while (lines <= MAX_LINE_COUNT) { int nl = nextLineBreak(content, start, content.length()); if (nl < 0) { break; } lines++; start = nl + 1; }
private static boolean isContentTooLargeForDisplay(String content) { int lines = 0; while (m.find() && lines < MAX_LINE_COUNT) { lines++; } if (lines < MAX_LINE_COUNT) { return false; } return true;
at, Duration.ofMillis( cfg.getTimeUnit( "retry", at.name(), "timeout", SECONDS.toMillis(defaultTimeout.getSeconds()), MILLISECONDS)))); this.waitStrategy = WaitStrategies.join( WaitStrategies.exponentialWait( cfg.getTimeUnit("retry", null, "maxWait", SECONDS.toMillis(5), MILLISECONDS), MILLISECONDS), WaitStrategies.randomWait(50, MILLISECONDS)); this.overwriteDefaultRetryerStrategySetup = overwriteDefaultRetryerStrategySetup; this.retryWithTraceOnFailure = cfg.getBoolean("retry", "retryWithTraceOnFailure", false);
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.logging; import com.google.auto.value.AutoValue; import java.util.Optional; /** * The record of an operation for which the execution time was measured. * * <p>Metadata to provide additional context can be included by providing a {@link Metadata} * instance. */ @AutoValue public abstract class PerformanceLogRecord { /** * Creates a performance log record without meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs) { return new AutoValue_PerformanceLogRecord(operation, durationMs, Optional.empty()); } /** * Creates a performance log record with meta data. *
public abstract static class Builder { public abstract Builder listener(RetryListener listener); public abstract Builder timeout(Duration timeout); public abstract Options build(); } } @VisibleForTesting @Singleton public static class Metrics { final Counter1<ActionType> attemptCounts; final Counter1<ActionType> timeoutCount; @Inject Metrics(MetricMaker metricMaker) { Field<ActionType> actionTypeField = Field.ofEnum(ActionType.class, "action_type", Metadata.Builder::actionType).build(); attemptCounts = metricMaker.newCounter( "action/retry_attempt_count", new Description( "Number of retry attempts made by RetryHelper to execute an action" + " (0 == single attempt, no retry)") .setCumulative() .setUnit("attempts"), actionTypeField); timeoutCount = metricMaker.newCounter( "action/retry_timeout_count", new Description( "Number of action executions of RetryHelper that ultimately timed out") .setCumulative()
public void setup() { projectCreationListener = new TraceValidatingProjectCreationValidationListener(); projectCreationListenerRegistrationHandle = projectCreationValidationListeners.add("gerrit", projectCreationListener); commitValidationListener = new TraceValidatingCommitValidationListener(); commitValidationRegistrationHandle = commitValidationListeners.add("gerrit", commitValidationListener); testPerformanceLogger = new TestPerformanceLogger(); performanceLoggerRegistrationHandle = performanceLoggers.add("gerrit", testPerformanceLogger);
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.util.cli; import java.util.Optional; /** * Classes that define command-line options by using the {@link org.kohsuke.args4j.Option} * annotation can implement this class to accept and handle unknown options. * * <p>If a user specifies an unknown option and this unknown option doesn't get accepted, the * parsing of the command-line options fails and the user gets an error (this is the default * behavior if classes do not implement this interface). */ public interface UnknownOptionHandler { /** * Whether an unknown option should be accepted. * * <p>If an unknown option is not accepted, the parsing of the command-line options fails and the * user gets an error. * * <p>This method can be used to ignore unknown options (without failure for the user) or to
* user gets an error. * * <p>This method can be used to ignore unknown options (without failure for the user) or to * handle them. * * @param name the name of an unknown option that was provided by the user * @param value the value of the unknown option that was provided by the user * @return whether this unknown options is accepted */ boolean accept(String name, @Nullable String value); }
.buildRepeatable( a -> { if (a.getAccount().getMetaId() == null) { return ImmutableList.of(); } return ImmutableList.of( RefState.create( RefNames.refsUsers(a.getAccount().getId()), ObjectId.fromString(a.getAccount().getMetaId())) // We use the default AllUsers name to avoid having to pass around that // variable just for indexing. // This field is only used for staleness detection which will discover the // default name and replace it with the actually configured name. .toByteArray(new AllUsersName(AllUsersNameProvider.DEFAULT))); }); /** * All note values of all external IDs that were used in the course of indexing this document. * * <p>Emitted as UTF-8 encoded strings of the form {@code [hex sha of external ID]:[hex sha of * note blob]}, or with other words {@code [note ID]:[note data ID]}. */
Ref ref = repo.exactRef(RefNames.refsUsers(id)); // Stale if the account actually exists. return ref != null; } } for (Map.Entry<Project.NameKey, RefState> e : RefState.parseStates(result.get().getValue(AccountField.REF_STATE)).entries()) { // Custom All-Users repository names are not indexed. Instead, the default name is used. // Therefore, defer to the currently configured All-Users name. Project.NameKey repoName = e.getKey().get().equals(AllUsersNameProvider.DEFAULT) ? allUsersName : e.getKey(); try (Repository repo = repoManager.openRepository(repoName)) { if (!e.getValue().match(repo)) { // Ref was modified since the account was indexed. return true; } } } Set<ExternalId> extIds = externalIds.byAccount(id); ListMultimap<ObjectId, ObjectId> extIdStates = parseExternalIdStates(result.get().getValue(AccountField.EXTERNAL_ID_STATE)); if (extIdStates.size() != extIds.size()) {
stateLog.error(String.format("source project %s not available", project), err, state); return; } } } synchronized (stateLock) { PushOne e = pending.get(uri); if (e == null) { e = opFactory.create(project, uri); addRef(e, ref); e.addState(ref, state); pool.schedule(e, now ? 0 : config.getDelay(), TimeUnit.SECONDS); pending.put(uri, e); eventsStorage.persist(project.get(), ref, e.getURI(), getRemoteConfigName()); } else if (!e.getRefs().contains(ref)) { addRef(e, ref); e.addState(ref, state); } state.increasePushTaskCount(project.get(), ref); repLog.info("scheduled {}:{} => {} to run after {}s", project, ref, e, config.getDelay()); }
public String persist(String project, String ref, URIish uri, String remote) { String json = getEventJson(project, ref, uri, remote); String eventKey = getEventKey(json); Path file = refUpdates().resolve(eventKey); if (Files.exists(file)) { return eventKey; } try { logger.atFiner().log("**CREATE** %s:%s => %s", project, ref, uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().log("Couldn't persist event %s", json); } return eventKey;
public void delete(String project, String ref, URIish uri, String remote) { String eventKey = getEventKey(getEventJson(project, ref, uri, remote)); try { logger.atFiner().log("**DELETE** %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); }
if (watchedTypes.contains(type)) { matching.bcc.accounts.add(accountId); } logger.atFine().log("Added account %s as watcher", accountId); return true; } logger.atFine().log("The filter did not match for account %s; skip notification", accountId); } catch (QueryParseException e) { // Ignore broken filter expressions. logger.atWarning().withCause(e).log( "Account %s has invalid filter in project watch %s", accountId, key); } return false;
private ImmutableList<RefUpdatedEvent> getRefUpdatedEvents( String project, String refName, int expectedSize) { String key = refEventKey(RefUpdatedEvent.TYPE, project, refName); if (expectedSize == 0) { assertThat(recordedEvents).doesNotContainKey(key); return ImmutableList.of(); } assertThat(recordedEvents).containsKey(key); ImmutableList<RefUpdatedEvent> events = FluentIterable.from(recordedEvents.get(key)) .transform(RefUpdatedEvent.class::cast) .toList(); assertThat(events).hasSize(expectedSize); return events; } @VisibleForTesting public ImmutableList<ChangeMergedEvent> getChangeMergedEvents( String project, String branch, int expectedSize) { String key = refEventKey(ChangeMergedEvent.TYPE, project, branch); if (expectedSize == 0) { assertThat(recordedEvents).doesNotContainKey(key); return ImmutableList.of(); } assertThat(recordedEvents).containsKey(key); ImmutableList<ChangeMergedEvent> events = FluentIterable.from(recordedEvents.get(key)) .transform(ChangeMergedEvent.class::cast) .toList(); assertThat(events).hasSize(expectedSize); return events; }
assertThat(cd.change().getStatus()).isEqualTo(Change.Status.MERGED); assertSubmitApproval(psId); assertThat(cd.patchSets()).hasSize(1); assertThat(cd.patchSet(psId).getRevision().get()).isEqualTo(c.name()); } @Test public void correctNewRevOnMergeByPushToBranch() throws Exception { grant(project, "refs/heads/master", Permission.PUSH); push("refs/for/master", PushOneCommit.SUBJECT, "one.txt", "One"); PushOneCommit.Result r = push("refs/for/master", PushOneCommit.SUBJECT, "two.txt", "Two"); startEventRecorder(); git().push().setRefSpecs(new RefSpec(r2.getCommit().name() + ":refs/heads/master")).call(); List<ChangeMergedEvent> changeMergedEvents = eventRecorder.getChangeMergedEvents(project.get(), "refs/heads/master", 2); assertThat(changeMergedEvents.get(0).newRev).isEqualTo(r2.getPatchSet().getRevision().get());
uri); } } else { if (canceledWhileRunning.get()) { logCanceledWhileRunningException(e); } else { repLog.error("Cannot replicate to {}", uri, e); // The remote push operation should be retried. pool.reschedule(this, Destination.RetryReason.TRANSPORT_ERROR); } } } catch (IOException e) { stateLog.error("Cannot replicate to " + uri, e, getStatesAsArray()); } catch (PermissionBackendException | RuntimeException | Error e) { stateLog.error("Unexpected error during replication to " + uri, e, getStatesAsArray()); } finally { pool.notifyFinished(this); if (git != null) { git.close(); } }
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; import org.eclipse.jgit.transport.RemoteRefUpdate; /** * Filter that is invoked before list of remote ref updates is pushed to remote instance. * * <p>It can be used to filter out unwanted updates. */ @ExtensionPoint public interface ReplicationPushFilter { public List<RemoteRefUpdate> filter(String projectName, List<RemoteRefUpdate> remoteUpdatesList); }
private final DestinationFactory destinationFactory; private final Path pluginDataDir; private final Provider<ReplicationQueue> replicationQueue; @Inject public AutoReloadConfigDecorator( SitePaths site, DestinationFactory destinationFactory, Provider<ReplicationQueue> replicationQueue, @PluginData Path pluginDataDir) throws ConfigInvalidException, IOException { this.site = site; this.destinationFactory = destinationFactory; this.pluginDataDir = pluginDataDir; this.currentConfig = loadConfig(); this.currentConfigTs = getLastModified(currentConfig); this.replicationQueue = replicationQueue; this.autoReloadExecutor = workQueue.createQueue(1, pluginName + "_auto-reload-config"); } private static long getLastModified(ReplicationFileBasedConfig cfg) { return FileUtil.lastModified(cfg.getCfgPath()); } private ReplicationFileBasedConfig loadConfig() throws ConfigInvalidException, IOException { return new ReplicationFileBasedConfig(site, destinationFactory, pluginDataDir); } private synchronized boolean isAutoReload() { return currentConfig.getConfig().getBoolean("gerrit", "autoReload", false); } @Override public synchronized List<Destination> getDestinations(FilterType filterType) { reloadIfNeeded(); return currentConfig.getDestinations(filterType); } private void reloadIfNeeded() {
private String soyTemplate(String name, SanitizedContent.ContentKind kind) { return args.soySauce .renderTemplate("com.google.gerrit.server.mail.template." + templateName) .setData(soyContext);
// limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.server.util.SystemLog; import com.google.inject.Inject; import com.google.inject.Singleton; import org.apache.log4j.PatternLayout; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Log4jSharedRefLogger extends LibModuleLogFile implements SharedRefLogger { private static final String LOG_NAME = "sharedref_log"; private final Logger sharedRefDBLog; @Inject public Log4jSharedRefLogger(SystemLog systemLog) { super(systemLog, LOG_NAME, new PatternLayout("[%d{ISO8601}] [%t] %-5p : %m%n")); sharedRefDBLog = LoggerFactory.getLogger(LOG_NAME); } @Override public void log(String project, Ref currRef, ObjectId newRefValue) { sharedRefDBLog.info( "project:{}|ref:{}|oldId:{}|newId:{}", project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName()); }
public void logRefUpdate(String project, Ref currRef, ObjectId newRefValue) { sharedRefDBLog.info( "project:{}|ref:{}|oldId:{}|newId:{}", project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName());
public void logProjectDelete(String project) { sharedRefDBLog.info("project:{}|DELETED", project);
public void onProjectDeleted(Event event) { String projectName = event.getProjectName(); logger.atInfo().log( "Deleting project '%s'. Will perform a cleanup in Shared-Ref database.", projectName); try { sharedDb.removeProject(projectName); sharedRefLogger.logProjectDelete(projectName); } catch (IOException e) { validationMetrics.incrementSplitBrain(); logger.atSevere().withCause(e).log( "Project '%s' deleted from GIT but it was not able to cleanup" + " from Shared-Ref database", projectName); }
String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been " + "persisted locally but not in SharedRef the value %s", projectName, refPair.getName(), refPair.putValue); boolean succeeded; try { succeeded = sharedRefDb.compareAndPut(projectName, getLatestLocalRef(refPair), refPair.putValue); } catch (IOException e) { throw new SharedDbSplitBrainException(errorMessage, e); } if (!succeeded) { throw new SharedDbSplitBrainException(errorMessage); } } protected RefPair compareAndGetLatestLocalRef(RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist(
private String replaceInUrl(String placeholder, String url, String replacement, boolean lowerCase) { if (url == null || replacement == null || !url.contains(placeholder)) { return url; } if (lowerCase) { replacement = replacement.toLowerCase(); } // as we can't assume anything of 'replacement', we're URL encoding it return url.replace(placeholder, Url.encode(replacement));
public void cancel() { repLog.info("Replication {} was canceled", getURI()); canceledByReplication(); pool.pushWasCanceled(this);
public void setCanceledWhileRunning() { repLog.info("Replication {} was canceled while being executed", getURI()); canceledWhileRunning.set(true);
public void logRefUpdate(String project, Ref currRef, ObjectId newRefValue) { if (!ObjectId.zeroId().equals(newRefValue)) { try (Repository repository = gitRepositoryManager.openRepository(new Project.NameKey(project)); RevWalk walk = new RevWalk(repository)) { RevCommit commit = walk.parseCommit(newRefValue); sharedRefDBLog.info( gson.toJson( new SharedRefLogEntry.UpdateRef( project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName(), CommonConverters.toGitPerson(commit.getCommitterIdent()), commit.getFullMessage()))); } else { sharedRefDBLog.info( gson.toJson( new SharedRefLogEntry.DeleteRef( project, currRef.getName(), currRef.getObjectId().getName()))); } } catch (IOException e) { logger.atSevere().withCause(e).log( "Cannot log sharedRefDB interaction for ref %s on project %s", currRef.getName(), project); }
String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } } public static class DeleteProject extends SharedRefLogEntry { public String refName; public String oldId; DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } } }
} replicateAllOnPluginStart = config.getBoolean("gerrit", "replicateOnStartup", true); defaultForceUpdate = config.getBoolean("gerrit", "defaultForceUpdate", false); sshCommandTimeout = (int) ConfigUtil.getTimeUnit(config, "gerrit", null, "sshCommandTimeout", 30, SECONDS); sshConnectionTimeout = (int) SECONDS.toMillis( ConfigUtil.getTimeUnit(config, "gerrit", null, "sshConnectionTimeout", 2, MINUTES)); ImmutableList.Builder<Destination> dest = ImmutableList.builder(); for (RemoteConfig c : allRemotes(config)) { if (c.getURIs().isEmpty()) { continue; } // If destination for push is not set assume equal to source. for (RefSpec ref : c.getPushRefSpecs()) { if (ref.getDestination() == null) { ref.setDestination(ref.getSource()); } } if (c.getPushRefSpecs().isEmpty()) { c.addPushRefSpec( new RefSpec() .setSourceDestination("refs/*", "refs/*") .setForceUpdate(defaultForceUpdate)); }
private ImmutableSet<String> parseRequestTypes(String traceId) { return ImmutableSet.copyOf(cfg.getStringList("tracing", traceId, "requestType")); } private ImmutableSet<Account.Id> parseAccounts(String traceId) { ImmutableSet.Builder<Account.Id> accountIds = ImmutableSet.builder(); String[] accounts = cfg.getStringList("tracing", traceId, "account"); for (String account : accounts) { Optional<Account.Id> accountId = Account.Id.tryParse(account); if (!accountId.isPresent()) { throw new ConfigInvalidException( String.format( "Invalid tracing config ('tracing.%s.account = %s'): invalid account ID", traceId, account)); } accountIds.add(accountId.get()); } return accountIds.build(); } private ImmutableSet<Pattern> parseProjectPatterns(String traceId) { ImmutableSet.Builder<Pattern> projectPatterns = ImmutableSet.builder(); String[] projectPatternRegExs = cfg.getStringList("tracing", traceId, "projectPattern"); for (String projectPatternRegEx : projectPatternRegExs) { try {
boolean matches(RequestInfo requestInfo) { if (!requestTypes().isEmpty() && requestTypes().stream() .noneMatch(type -> type.equalsIgnoreCase(requestInfo.requestType()))) { return false; } if (!accountIds().isEmpty()) { try { if (!accountIds().stream() .anyMatch(id -> id.equals(requestInfo.callingUser().getAccountId()))) { return false; } } catch (UnsupportedOperationException e) { // calling user is not logged in return false; } } if (!projectPatterns().isEmpty()) { if (!requestInfo.project().isPresent()) { // request is not for a project return false; } if (!projectPatterns().stream() .anyMatch(p -> p.matcher(requestInfo.project().get().get()).matches())) { return false; } } return true;
/** Java API to interact with single {@code Check}s. */ public interface CheckApi { /** Returns a {@link CheckInfo} for the scoped resource with the given options. */ CheckInfo get(ListChecksOption... options) throws RestApiException; /** Updates a check and returns the {@link CheckInfo} for the updated resource. */ CheckInfo update(CheckInput input) throws RestApiException; /** * A default implementation which allows source compatibility when adding new methods to the * interface. */ class NotImplemented implements CheckApi { @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo update(CheckInput input) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo rerun(CheckInput input) throws RestApiException { throw new NotImplementedException(); } } }
/** Java API to interact with single {@code Check}s. */ public interface CheckApi { /** Returns a {@link CheckInfo} for the scoped resource with the given options. */ CheckInfo get(ListChecksOption... options) throws RestApiException; /** Updates a check and returns the {@link CheckInfo} for the updated resource. */ CheckInfo update(CheckInput input) throws RestApiException; /** * A default implementation which allows source compatibility when adding new methods to the * interface. */ class NotImplemented implements CheckApi { @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo update(CheckInput input) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo rerun(CheckInput input) throws RestApiException { throw new NotImplementedException(); } } }
import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.ConfigInvalidException; @Singleton public class RerunCheck implements RestModifyView<CheckResource, CheckInput> { private final PostCheck postCheck; @Inject RerunCheck(PostCheck postCheck) { this.postCheck = postCheck; } public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().get(); } else if (!checkResource.getCheckerUuid().get().equals(input.checkerUuid)) { throw new BadRequestException( String.format( "checker UUID in input must either be null or the same as on the resource:\n"
import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckInput; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.testing.TestTimeUtil; import com.google.inject.Inject; import java.sql.Timestamp; import java.time.Instant; import java.util.concurrent.TimeUnit; import org.junit.After; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; @Inject private ProjectOperations projectOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test
import com.google.gerrit.testing.TestTimeUtil; import com.google.inject.Inject; import java.sql.Timestamp; import java.time.Instant; import java.util.concurrent.TimeUnit; import org.junit.After; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING;
public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } }
@Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } }
CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } }
PermissionBackend permissionBackend, ExternalIds externalIds, @ServerInitiated Provider<AccountsUpdate> accountsUpdateProvider, SshKeyCache sshKeyCache, Realm realm) { this.self = self; this.permissionBackend = permissionBackend; this.externalIds = externalIds; this.accountsUpdateProvider = accountsUpdateProvider; this.sshKeyCache = sshKeyCache; this.realm = realm; } @Override public String apply(AccountResource rsrc, UsernameInput input) throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } if (!realm.allowsEdit(AccountFieldName.USER_NAME)) { throw new MethodNotAllowedException("realm does not allow editing username"); } Account.Id accountId = rsrc.getUser().getAccountId(); if (!externalIds.byAccount(accountId, SCHEME_USERNAME).isEmpty()) { throw new MethodNotAllowedException("Username cannot be changed."); }
} @Override public String apply(AccountResource rsrc, UsernameInput input) throws AuthException, MethodNotAllowedException, UnprocessableEntityException, ResourceConflictException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } if (!realm.allowsEdit(AccountFieldName.USER_NAME)) { throw new MethodNotAllowedException("realm does not allow editing username"); } Account.Id accountId = rsrc.getUser().getAccountId(); if (!externalIds.byAccount(accountId, SCHEME_USERNAME).isEmpty()) { throw new MethodNotAllowedException("Username cannot be changed."); } if (Strings.isNullOrEmpty(input.username)) { // A username is not set yet and in the input no username was specified. Hence there is // nothing to do. return input.username; } if (!ExternalId.isValidUsername(input.username)) {
@Nullable public Timestamp finished; /** Timestamp of when this check was created. */ public Timestamp created; /** Timestamp of when this check was last updated. */ public Timestamp updated; /** Name of the checker that produced this check. */ public String checkerName; /** Status of the checker that produced this check. */ public CheckerStatus checkerStatus; /** Blocking conditions that apply to this check. */ public Set<BlockingCondition> blocking; /** Description of the checker that produced this check */ public String checkerDescription; @Override public boolean equals(Object o) { if (!(o instanceof CheckInfo)) { return false; } CheckInfo other = (CheckInfo) o; return Objects.equals(other.repository, repository) && Objects.equals(other.changeNumber, changeNumber) && Objects.equals(other.patchSetId, patchSetId) && Objects.equals(other.checkerUuid, checkerUuid) && Objects.equals(other.state, state) && Objects.equals(other.message, message) && Objects.equals(other.url, url) && Objects.equals(other.started, started)
/** Timestamp of when this check was created. */ public Timestamp created; /** Timestamp of when this check was last updated. */ public Timestamp updated; /** Name of the checker that produced this check. */ public String checkerName; /** Status of the checker that produced this check. */ public CheckerStatus checkerStatus; /** Blocking conditions that apply to this check. */ public Set<BlockingCondition> blocking; /** Description of the checker that produced this check */ public String checkerDescription; @Override public boolean equals(Object o) { if (!(o instanceof CheckInfo)) { return false; } CheckInfo other = (CheckInfo) o; return Objects.equals(other.repository, repository) && Objects.equals(other.changeNumber, changeNumber) && Objects.equals(other.patchSetId, patchSetId) && Objects.equals(other.checkerUuid, checkerUuid) && Objects.equals(other.state, state) && Objects.equals(other.message, message) && Objects.equals(other.url, url) && Objects.equals(other.started, started) && Objects.equals(other.finished, finished)
} if (options.contains(FillOptions.STATUS)) { info.status = account.getStatus(); } if (options.contains(FillOptions.AVATARS)) { AvatarProvider ap = avatar.get(); if (ap != null) { info.avatars = new ArrayList<>(); IdentifiedUser user = userFactory.create(account.getId()); // PolyGerrit UI uses the following sizes for avatars: // - 32px for avatars next to names e.g. on the dashboard. This is also Gerrit's default. // - 56px for the user's own avatar in the menu // - 100ox for other user's avatars on dashboards // - 120px for the user's own profile settings page addAvatar(ap, info, user, AvatarInfo.DEFAULT_SIZE); if (!info.avatars.isEmpty()) { addAvatar(ap, info, user, 56); addAvatar(ap, info, user, 100); addAvatar(ap, info, user, 120); } } }
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.NotSupportedException; import org.eclipse.jgit.errors.TransportException; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; public interface TransportFactory { Transport open(Repository local, URIish uri) throws NotSupportedException, TransportException; }
Copyright (C) 2019 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.NotSupportedException; import org.eclipse.jgit.errors.TransportException; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; public class TransportFactoryImpl implements TransportFactory { @Override public Transport open(Repository git, URIish uri) throws NotSupportedException, TransportException { return Transport.open(git, uri); } }
import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.transport.FetchConnection; import org.eclipse.jgit.transport.PushConnection; import org.eclipse.jgit.transport.PushResult; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.RemoteRefUpdate; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; import org.eclipse.jgit.util.FS; import org.junit.Before; import org.junit.Test; public class PushOneTest { private GitRepositoryManager gitRepositoryManagerMock; private Repository repositoryMock; private PermissionBackend permissionBackendMock; private PermissionBackend.WithUser withUserMock; private PermissionBackend.ForProject forProjectMock; Destination destinationMock; RemoteConfig remoteConfigMock; RefSpec refSpecMock; CredentialsFactory credentialsFactory; PerThreadRequestScope.Scoper threadRequestScoperMock; ReplicationQueue replicationQueueMock; IdGenerator idGeneratorMock; ReplicationStateListeners replicationStateListenersMock; ReplicationMetrics replicationMetricsMock; Timer1.Context timerContextMock; ProjectCache projectCacheMock; RunwayStatus statusMock; TransportFactory transportFactoryMock; Transport transportMock; FetchConnection fetchConnection; PushConnection pushConnection; ProjectState projectStateMock;
verify(transportMock); } private PushOne createPushOne(DynamicItem<ReplicationPushFilter> replicationPushFilter) { PushOne push = new PushOne( gitRepositoryManagerMock, permissionBackendMock, destinationMock, remoteConfigMock, credentialsFactory, threadRequestScoperMock, replicationQueueMock, idGeneratorMock, replicationStateListenersMock, replicationMetricsMock, projectCacheMock, transportFactoryMock, projectNameKey, urish); push.setReplicationPushFilter(replicationPushFilter); return push; } private void waitUntilFinished() throws InterruptedException { while (!isCallFinished.get()) { Thread.sleep(100); } } private void setupProjectCacheMock() throws IOException { projectCacheMock = createNiceMock(ProjectCache.class); expect(projectCacheMock.checkedGet(projectNameKey)).andReturn(projectStateMock); } private void setupTransportMock() throws NotSupportedException, TransportException { transportMock = createNiceMock(Transport.class); expect(transportMock.openFetch()).andReturn(fetchConnection); transportFactoryMock = createNiceMock(TransportFactory.class); expect(transportFactoryMock.open(repositoryMock, urish)).andReturn(transportMock).anyTimes(); } private void setupReplicationMetricsMock() {
private void setupDestinationMock() { destinationMock = createNiceMock(Destination.class); expect(destinationMock.requestRunway(anyObject())).andReturn(RunwayStatus.allowed()); } private void setupPermissionBackedMock() { permissionBackendMock = createNiceMock(PermissionBackend.class); expect(permissionBackendMock.currentUser()).andReturn(withUserMock); } private void setupWithUserMock() { withUserMock = createNiceMock(WithUser.class); expect(withUserMock.project(projectNameKey)).andReturn(forProjectMock); } private void setupGitRepoManagerMock() throws IOException { gitRepositoryManagerMock = createNiceMock(GitRepositoryManager.class); expect(gitRepositoryManagerMock.openRepository(projectNameKey)).andReturn(repositoryMock); } private void setupRepositoryMock(FileBasedConfig config) throws IOException { repositoryMock = createNiceMock(Repository.class); expect(repositoryMock.getConfig()).andReturn(config).anyTimes(); expect(repositoryMock.getAllRefs()).andReturn(localRefs); expect(repositoryMock.updateRef("fooProject")).andReturn(refUpdateMock); } private void setupRefUpdateMock() { refUpdateMock = createNiceMock(RefUpdate.class);
&& compareField(ref.getStatus(), expectedRef.getStatus()) && compareField(ref.getExpectedOldObjectId(), expectedRef.getExpectedOldObjectId()) && compareField(ref.getNewObjectId(), expectedRef.getNewObjectId()) && compareField(ref.isFastForward(), expectedRef.isFastForward()) && compareField(ref.getSrcRef(), expectedRef.getSrcRef()) && compareField(ref.isForceUpdate(), expectedRef.isForceUpdate()) && compareField(ref.getMessage(), expectedRef.getMessage()); } } }
public GitPerson committer; public String comment; UpdateRef( String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } } public static class DeleteProject extends SharedRefLogEntry { DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } } }
public String comment; UpdateRef( String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } } public static class DeleteProject extends SharedRefLogEntry { DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } } }
// limitations under the License. package com.google.gerrit.plugins.checks.api; import com.google.gerrit.exceptions.StorageException; import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.ConfigInvalidException; @Singleton public class RerunCheck implements RestModifyView<CheckResource, CheckInput> { private final Provider<CurrentUser> self; private final PermissionBackend permissionBackend; private final AdministrateCheckersPermission permission; private final Checks checks; private final Provider<ChecksUpdate> checksUpdate; private final CheckJson.Factory checkJsonFactory; @Inject RerunCheck(PostCheck postCheck) { this.postCheck = postCheck; } @Override public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().get(); } else if (!checkResource.getCheckerUuid().get().equals(input.checkerUuid)) { throw new BadRequestException(
import org.eclipse.jgit.diff.DiffEntry; import org.eclipse.jgit.diff.DiffFormatter; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectReader; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.util.io.DisabledOutputStream; /** Loads cache values for the external ID cache using either a full or a partial reload. */ @Singleton public class ExternalIdCacheLoader extends CacheLoader<ObjectId, AllExternalIds> { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); // Maximum number of prior states we inspect to find a base for differential. If no cached state // is found within this number of parents, , we fall back to reading everything from scratch. private static final int MAX_HISTORY_LOOKBACK = 10; // Maximum number of changes we perform using the differential approach. If more updates need to
import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.util.io.DisabledOutputStream; /** Loads cache values for the external ID cache using either a full or a partial reload. */ public class ExternalIdCacheLoader extends CacheLoader<ObjectId, AllExternalIds> { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); // Maximum number of prior states we inspect to find a base for differential. If no cached state // is found within this number of parents, we fall back to reading everything from scratch. private static final int MAX_HISTORY_LOOKBACK = 10; // Maximum number of changes we perform using the differential approach. If more updates need to // be applied, we fall back to reading everything from scratch. private static final int MAX_DIFF_UPDATES = 50; private final ExternalIdReader externalIdReader; private final Provider<Cache<ObjectId, AllExternalIds>> externalIdCache; private final GitRepositoryManager gitRepositoryManager; private final AllUsersName allUsersName; private final Counter1<Boolean> reloadCounter; private final Timer0 reloadDifferential;
new Description("Total number of external ID cache reloads from Git.") .setRate() .setUnit("updates"), Field.ofBoolean("partial", Metadata.Builder::partial).build()); this.reloadDifferential = metricMaker.newTimer( "notedb/external_id_partial_read_latency", new Description( "Latency for generating a new external ID cache state from a prior state.") .setCumulative() .setUnit(Units.MILLISECONDS)); this.enablePartialReloads = config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", false); } @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log( "Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } // We failed to load the requested value from both the in-memory cache (hence, this loader was
import com.googlesource.gerrit.plugins.renameproject.monitor.ProgressMonitor; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.List; import org.kohsuke.args4j.Argument; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @CommandMetaData(name = "rename", description = "Rename project") public final class RenameCommand extends SshCommand { @Argument(index = 0, required = true, metaVar = "OLDPROJECT", usage = "project to rename") private String projectControl; @Argument(index = 1, required = true, metaVar = "NEWNAME", usage = "new name for the project") private String newProjectName; private static final Logger log = LoggerFactory.getLogger(RenameCommand.class); private final RenameProject renameProject; private final ProjectCache projectCache; private final Provider<CurrentUser> self; @Inject protected RenameCommand( RenameProject renameProject, ProjectCache projectCache, Provider<CurrentUser> self) { this.renameProject = renameProject; this.projectCache = projectCache; this.self = self; } @Override
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** * @param started Set the time the check started. Time can be reset to "null" if passed @code * new Timestamp(0) */ public abstract Builder setStarted(Timestamp started); /** * @param finished - set the time the check finished. Time can be reset to "null" if passed new * Timestamp(0). */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } }
private static final FluentLogger logger = FluentLogger.forEnclosingClass(); // Maximum number of prior states we inspect to find a base for differential. If no cached state // is found within this number of parents, we fall back to reading everything from scratch. private static final int MAX_HISTORY_LOOKBACK = 10; // Maximum number of changes we perform using the differential approach. If more updates need to // be applied, we fall back to reading everything from scratch. private static final int MAX_DIFF_UPDATES = 50; private final ExternalIdReader externalIdReader; private final Provider<Cache<ObjectId, AllExternalIds>> externalIdCache; private final GitRepositoryManager gitRepositoryManager; private final AllUsersName allUsersName; private final Counter1<Boolean> reloadCounter; private final Timer0 reloadDifferential; private final boolean enablePartialReloads; @Inject ExternalIdCacheLoader( GitRepositoryManager gitRepositoryManager, AllUsersName allUsersName, ExternalIdReader externalIdReader, @Named(ExternalIdCacheImpl.CACHE_NAME) Provider<Cache<ObjectId, AllExternalIds>> externalIdCache, MetricMaker metricMaker,
// state. try (Repository repo = gitRepositoryManager.openRepository(allUsersName)) { long start = System.nanoTime(); Ref extId = repo.exactRef(RefNames.REFS_EXTERNAL_IDS); if (extId == null) { logger.atInfo().log( RefNames.REFS_EXTERNAL_IDS + " not initialized, falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } RevCommit currentCommit = rw.parseCommit(extIdRef.getObjectId()); rw.markStart(currentCommit); RevCommit parentWithCacheValue = null; AllExternalIds oldExternalIds = null; for (int i = 0; i < MAX_HISTORY_LOOKBACK; i++) { parentWithCacheValue = rw.next(); oldExternalIds = externalIdCache.get().getIfPresent(parentWithCacheValue.getId()); if (oldExternalIds != null) { break; } if (parentWithCacheValue.getParentCount() != 1) { logger.atWarning().log(
logger.atInfo().log( RefNames.REFS_EXTERNAL_IDS + " not initialized, falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } RevWalk rw = new RevWalk(repo); RevCommit currentCommit = rw.parseCommit(extId.getObjectId()); rw.markStart(currentCommit); RevCommit parentWithCacheValue = null; AllExternalIds oldExternalIds = null; int i = 0; while ((parentWithCacheValue = rw.next()) != null && i++ < MAX_HISTORY_LOOKBACK) { oldExternalIds = externalIdCache.get().getIfPresent(parentWithCacheValue.getId()); if (oldExternalIds != null) { break; } if (parentWithCacheValue.getParentCount() != 1) { logger.atWarning().log( "Unable to find an old ExternalId cache state because %s doesn't have exactly " + "one parent, falling back to full reload", parentWithCacheValue); return reloadAllExternalIdsAndCachePersistently(notesRev); } } if (oldExternalIds == null) { logger.atWarning().log(
nameToBlob.getValue()); } catch (ConfigInvalidException | RuntimeException e) { logger.atSevere().withCause(e).log( "Ignoring invalid external ID note %s", nameToBlob.getKey().name()); continue; } byAccount.put(parsedExternalId.accountId(), parsedExternalId); if (parsedExternalId.email() != null) { byEmail.put(parsedExternalId.email(), parsedExternalId); } } } } private static ObjectId fileNameToObjectId(String path) { int lastSlash = path.lastIndexOf('/'); return ObjectId.fromString(lastSlash > 0 ? path.substring(lastSlash) : path); } private AllExternalIds reloadAllExternalIdsAndCachePersistently(ObjectId notesRev) throws IOException, ConfigInvalidException { try (TraceTimer ignored = TraceContext.newTimer( "Loading external IDs from scratch",
private static ObjectId fileNameToObjectId(String path) { return ObjectId.fromString(CharMatcher.is('/').removeFrom(path));
} private AllExternalIds reloadAllExternalIdsAndCachePersistently(ObjectId notesRev) throws IOException, ConfigInvalidException { try (TraceTimer ignored = TraceContext.newTimer( "Loading external IDs from scratch", Metadata.builder().revision(notesRev.name()).build())) { ImmutableSet<ExternalId> externalIds = externalIdReader.all(notesRev); externalIds.forEach(ExternalId::checkThatBlobIdIsSet); AllExternalIds allExternalIds = AllExternalIds.create(externalIds); reloadCounter.increment(false); return allExternalIds; } } }
// The UUID of a group. public abstract Optional<String> groupUuid(); // HTTP status response code. public abstract Optional<Integer> httpStatus(); // The name of a secondary index. public abstract Optional<String> indexName(); // The version of a secondary index. public abstract Optional<Integer> indexVersion(); // The name of the implementation method. public abstract Optional<String> methodName(); // Boolean: one or more public abstract Optional<Boolean> multiple(); // Partial or full computation public abstract Optional<Boolean> partial(); // Path of a metadata file in NoteDb. public abstract Optional<String> noteDbFilePath(); // Name of a metadata ref in NoteDb. public abstract Optional<String> noteDbRefName(); // Type of a sequence in NoteDb (ACCOUNTS, CHANGES, GROUPS). public abstract Optional<String> noteDbSequenceType(); // Name of a "table" in NoteDb (if set, always CHANGES). public abstract Optional<String> noteDbTable(); // The ID of a patch set.
package com.google.gerrit.server.config; import com.google.inject.Inject; import com.google.inject.Singleton; import org.eclipse.jgit.lib.Config; @Singleton public class ThreadSettingsConfig { private final int sshdThreads; private final int httpdMaxThreads; private final int sshdBatchThreads; private final int databasePoolLimit; @Inject ThreadSettingsConfig(@GerritServerConfig Config cfg) { int cores = Runtime.getRuntime().availableProcessors(); sshdThreads = cfg.getInt("sshd", "threads", Math.max(4, 2 * cores)); httpdMaxThreads = cfg.getInt("httpd", "maxThreads", 25); int defaultDatabasePoolLimit = sshdThreads + httpdMaxThreads + 2; databasePoolLimit = cfg.getInt("database", "poolLimit", defaultDatabasePoolLimit); sshdBatchThreads = cores == 1 ? 1 : 2; } public int getDatabasePoolLimit() { return databasePoolLimit; } public int getHttpdMaxThreads() { return httpdMaxThreads; } public int getSshdThreads() { return sshdThreads; } public int getSshdBatchTreads() { return sshdBatchThreads; } }
import org.eclipse.jgit.lib.RefUpdate.Result; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.lib.RepositoryCache.FileKey; import org.eclipse.jgit.util.FS; public class AccountsOnInit { private final InitFlags flags; private final SitePaths site; private final String allUsers; @Inject public AccountsOnInit(InitFlags flags, SitePaths site, AllUsersNameOnInitProvider allUsers) { this.flags = flags; this.site = site; this.allUsers = allUsers.get(); } public void insert(Account.Builder account) throws IOException { File path = getPath(); if (path != null) { try (Repository repo = new FileRepository(path); ObjectInserter oi = repo.newObjectInserter()) { PersonIdent ident = new PersonIdent(new GerritPersonIdentProvider(flags.cfg).get(), account.registeredOn()); Config accountConfig = new Config(); AccountProperties.writeToAccountConfig( InternalAccountUpdate.builder() .setActive(account.isActive()) .setFullName(account.fullName()) .setPreferredEmail(account.preferredEmail()) .setStatus(account.status()) .build(),
AllUsersName allUsersName = new AllUsersName(AllUsersNameProvider.DEFAULT); Account.Builder account = Account.builder(Account.id(1), TimeUtil.nowTs()); String metaId = "0e39795bb25dc914118224995c53c5c36923a461"; account.setMetaId(metaId); List<String> values = toStrings(AccountField.REF_STATE.get(AccountState.forAccount(account.build()))); assertThat(values).hasSize(1); String expectedValue = allUsersName.get() + ":" + RefNames.refsUsers(account.id()) + ":" + metaId; assertThat(Iterables.getOnlyElement(values)).isEqualTo(expectedValue); } @Test public void externalIdStateFieldValues() throws Exception { Account.Id id = Account.id(1); Account account = Account.create(id, TimeUtil.nowTs()); ExternalId extId1 = ExternalId.create( ExternalId.Key.create(ExternalId.SCHEME_MAILTO, "foo.bar@example.com"), id, "foo.bar@example.com", null, ObjectId.fromString("1b9a0cf038ea38a0ab08617c39aa8e28413a27ca")); ExternalId extId2 =
@CommandMetaData(name = "rename", description = "Rename project") public final class RenameCommand extends SshCommand { @Argument(index = 0, required = true, metaVar = "OLDPROJECT", usage = "project to rename") private String projectControl; @Argument(index = 1, required = true, metaVar = "NEWNAME", usage = "new name for the project") private String newProjectName; private static final Logger log = LoggerFactory.getLogger(RenameCommand.class); private final RenameProject renameProject; private final Provider<ProjectCache> projectCacheProvider; private final Provider<CurrentUser> self; @Inject protected RenameCommand( RenameProject renameProject, ProjectCache projectCache, Provider<CurrentUser> self) { this.renameProject = renameProject; this.projectCache = projectCache; this.self = self; } @Override public void run() throws Exception { try { RenameProject.Input input = new RenameProject.Input(); input.name = newProjectName; ProjectResource rsrc = new ProjectResource(projectCache.get(new Project.NameKey(projectControl)), self.get());
&& Objects.equals(other.checkerUuid, checkerUuid) && Objects.equals(other.state, state) && Objects.equals(other.message, message) && Objects.equals(other.url, url) && Objects.equals(other.started, started) && Objects.equals(other.finished, finished) && Objects.equals(other.created, created) && Objects.equals(other.updated, updated) && Objects.equals(other.checkerName, checkerName) && Objects.equals(other.checkerStatus, checkerStatus) && Objects.equals(other.blocking, blocking) && Objects.equals(other.checkerDescription, checkerDescription);
public abstract Optional<Timestamp> started(); public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** * @param started Set the time the check started. Time can be reset to "null" if passed @code * new Timestamp(0) */ public abstract Builder setStarted(Timestamp started); /** * @param finished - set the time the check finished. Time can be reset to "null" if passed new * Timestamp(0). */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } }
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** * @param started Set the time the check started. Time can be reset to "null" if passed @code * new Timestamp(0) */ public abstract Builder setStarted(Timestamp started); /** * @param finished - set the time the check finished. Time can be reset to "null" if passed new * Timestamp(0). */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } }
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** * @param started Set the time the check started. Time can be reset to "null" if passed {@code * new Timestamp(0)} */ public abstract Builder setStarted(Timestamp started); /** * @param finished Set the time the check finished. Time can be reset to "null" if passed @code * new Timestamp(0) */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } }
String email = readEmail(sshKey); List<ExternalId> extIds = new ArrayList<>(2); extIds.add(ExternalId.createUsername(username, id, httpPassword)); if (email != null) { extIds.add(ExternalId.createEmail(id, email)); } externalIds.insert("Add external IDs for initial admin user", extIds); Account persistedAccount = accounts.insert( Account.builder(id, TimeUtil.nowTs()).setFullName(name).setPreferredEmail(email)); // Only two groups should exist at this point in time and hence iterating over all of them // is cheap. Optional<GroupReference> adminGroupReference = groupsOnInit .getAllGroupReferences() .filter(group -> group.getName().equals("Administrators")) .findAny(); if (!adminGroupReference.isPresent()) { throw new NoSuchGroupException("Administrators"); } GroupReference adminGroup = adminGroupReference.get(); groupsOnInit.addGroupMember(adminGroup.getUUID(), persistedAccount); if (sshKey != null) {
CommitMessageUtil.checkAndSanitizeCommitMessage(revCommit.getShortMessage()); List<String> changeIdFooters = revCommit.getFooterLines(FooterConstants.CHANGE_ID); if (!changeIdFooters.isEmpty() && !changeIdFooters.get(0).equals(currentChangeId)) { throw new ResourceConflictException("wrong Change-Id footer"); } if (revCommit.getFooterLines().isEmpty()) { // sanitization always adds '\n' at the end. newCommitMessage += "\n"; } if (requireChangeId && changeIdFooters.isEmpty()) { newCommitMessage += FooterConstants.CHANGE_ID.getName() + ": " + currentChangeId + "\n"; } else if (changeIdFooters.size() > 1) { throw new ResourceConflictException("multiple Change-Id footers"); } return newCommitMessage; } }
/** Java API to interact with single {@code Check}s. */ public interface CheckApi { /** Returns a {@link CheckInfo} for the scoped resource with the given options. */ CheckInfo get(ListChecksOption... options) throws RestApiException; /** Updates a check and returns the {@link CheckInfo} for the updated resource. */ CheckInfo update(CheckInput input) throws RestApiException; /** Reruns the check and returns the {@link CheckInfo} for the updated check. */ CheckInfo rerun() throws RestApiException; /** * A default implementation which allows source compatibility when adding new methods to the * interface. */ class NotImplemented implements CheckApi { @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo update(CheckInput input) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo rerun() throws RestApiException { throw new NotImplementedException();
private final Checks checks; private final Provider<ChecksUpdate> checksUpdate; private final CheckJson.Factory checkJsonFactory; @Inject RerunCheck( Provider<CurrentUser> self, PermissionBackend permissionBackend, AdministrateCheckersPermission permission, Checks checks, @UserInitiated Provider<ChecksUpdate> checksUpdate, CheckJson.Factory checkJsonFactory) { this.self = self; this.permissionBackend = permissionBackend; this.permission = permission; this.checks = checks; this.checksUpdate = checksUpdate; this.checkJsonFactory = checkJsonFactory; } @Override public CheckInfo apply(CheckResource checkResource, Input input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (!self.get().isIdentifiedUser()) { throw new AuthException("Authentication required"); } permissionBackend.currentUser().check(permission); if (checkResource.getRevisionResource().getEdit().isPresent()) { throw new ResourceConflictException("checks are not supported on a change edit"); } CheckKey key = CheckKey.create( checkResource.getRevisionResource().getProject(),
import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.UnprocessableEntityException; import com.google.gerrit.plugins.checks.CheckKey; import com.google.gerrit.plugins.checks.CheckerUuid; import com.google.gerrit.plugins.checks.acceptance.AbstractCheckersTest; import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.inject.Inject; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; @Inject private ProjectOperations projectOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun();
import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.NOT_STARTED).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunNotExistingCheckThrowsError() throws Exception { assertThrows(
CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunNotExistingCheckerThrowsError() throws Exception { assertThrows( UnprocessableEntityException.class, () -> checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun()); } @Test public void cannotUpdateCheckWithoutAdministrateCheckers() throws Exception { requestScopeOperations.setApiUser(user.id()); checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); AuthException thrown = assertThrows( AuthException.class, () -> checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun()); assertThat(thrown).hasMessageThat().contains("not permitted"); } @Test
.add("repository", repository) .add("changeNumber", changeNumber) .add("patchSetId", patchSetId) .add("checkerUuid", checkerUuid) .add("state", state) .add("message", message) .add("url", url) .add("started", started) .add("finished", finished) .add("created", created) .add("updated", updated) .add("checkerName", checkerName) .add("checkerStatus", checkerStatus) .add("blocking", blocking) .add("checkerDescription", checkerDescription) .toString();
public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); public abstract Builder setStarted(Timestamp started); /** * @param finished Set the time the check finished. Time can be reset to "null" if passed {@code * new Timestamp(0)} */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } }
assertThat(loader.load(head)).isEqualTo(allFromGit(head)); verify(externalIdReaderSpy, times(1)).all(head); } @Test public void fallsBackToFullReloadOnManyUpdatesOnBranch() throws Exception { insertExternalId(1, 1); ObjectId head = null; for (int i = 2; i < 20; i++) { head = insertExternalId(i, i); } assertThat(loader.load(head)).isEqualTo(allFromGit(head)); verify(externalIdReaderSpy, times(1)).all(head); } @Test public void doesFullReloadWhenNoCacheStateIsFound() throws Exception { ObjectId head = insertExternalId(1, 1); assertThat(loader.load(head)).isEqualTo(allFromGit(head)); verify(externalIdReaderSpy, times(1)).all(head); } @Test public void handlesDeletionInPartialReload() throws Exception { ObjectId firstState = insertExternalId(1, 1); ObjectId head = deleteExternalId(1, 1); assertThat(allFromGit(head).byAccount().size()).isEqualTo(0); when(externalIdCache.getIfPresent(firstState)).thenReturn(allFromGit(firstState)); assertThat(loader.load(head)).isEqualTo(allFromGit(head)); verifyZeroInteractions(externalIdReaderSpy); } @Test public void handlesModifyInPartialReload() throws Exception { ObjectId firstState = insertExternalId(1, 1);
public void emptyStringIsDeserializedToMagicTimestamp() { Timestamp timestamp = deserializer.deserialize(new JsonPrimitive(""), Timestamp.class, null); assertThat(timestamp).isEqualTo(TimeUtil.never());
.add(allow(Permission.PUSH).ref(other).group(adminGroupUuid())) .update(); RevCommit masterRev = projectOperations.project(project).getHead("master"); pushCommitTo(masterRev, other); PushOneCommit.Result r = createChange(); r.assertOkStatus(); RevCommit commit = r.getCommit(); pushCommitTo(commit, master); assertCommit(project, master); ChangeData cd = Iterables.getOnlyElement(queryProvider.get().byKey(new Change.Key(r.getChangeId()))); assertThat(cd.change().getStatus()).isEqualTo(Change.Status.MERGED); RemoteRefUpdate.Status status = pushCommitTo(commit, "refs/for/other"); assertThat(status).isEqualTo(RemoteRefUpdate.Status.OK); pushCommitTo(commit, other); assertCommit(project, other); for (ChangeData c : queryProvider.get().byKey(Change.key(r.getChangeId()))) { if (c.change().getDest().branch().equals(other)) { assertThat(c.change().isMerged()).isTrue(); } } } private RemoteRefUpdate.Status pushCommitTo(RevCommit commit, String ref)
// from the cache. Extend the cache size by 1 to cover this case, but expire the extra // object after a short period of time, since it may be a potentially large amount of // memory. // When loading a new value because the primary data advanced, we want to leverage the old // cache state to recompute only what changed. This doesn't affect cache size though as // Guava calls the loader first and evicts later on. .maximumWeight(2) .expireFromMemoryAfterAccess(Duration.ofMinutes(5)) .loader(ExternalIdCacheLoader.class) .diskLimit(-1) .version(1) .keySerializer(ObjectIdCacheSerializer.INSTANCE) .valueSerializer(AllExternalIds.Serializer.INSTANCE); bind(ExternalIdCacheImpl.class); bind(ExternalIdCache.class).to(ExternalIdCacheImpl.class);
public HashtagsInput(Set<String> add, Set<String> remove) { this(add); this.remove = remove;
CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.NOT_STARTED).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertSuccessfulRerun(info); assertThat(info.updated).isGreaterThan(info.created); } @Test public void rerunCheckNotExistingButBackfilled() throws Exception { CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertSuccessfulRerun(info); } @Test
private final String variant; private CommitSoyData csd; public LogSoyData(HttpServletRequest req, GitilesAccess access, String pretty) throws IOException { this.req = checkNotNull(req); this.view = checkNotNull(ViewFilter.getView(req)); checkNotNull(pretty); Config config = access.getConfig(); fields = config.getBoolean("logFormat", pretty, "verbose", false) ? VERBOSE_FIELDS : FIELDS; variant = firstNonNull(config.getString("logFormat", pretty, "variant"), pretty); } /** Wrapper class to stream rendered output to a {@link Writer}. */ private static class LogSoyDataAppendable implements AdvisingAppendable { private final Writer writer; LogSoyDataAppendable(Writer writer) { this.writer = writer; } @Override public AdvisingAppendable append(CharSequence csq) throws IOException { writer.append(csq); return this; } @Override public AdvisingAppendable append(CharSequence csq, int start, int end) throws IOException { writer.append(csq, start, end); return this; } @Override public AdvisingAppendable append(char c) throws IOException { writer.append(c); return this; } @Override
// don't do something with the result, so just wrap it in a dummy method. } public void renderStreaming( Paginator paginator, @Nullable String revision, Renderer renderer, Writer writer, DateFormatter df, FooterBehavior footerBehavior) throws IOException { LogSoyDataAppendable out = new LogSoyDataAppendable(writer); swallowResult( renderer .newRenderer("gitiles.logEntriesHeader") .setData(toHeaderSoyData(paginator, revision)), out); SoySauce.Renderer entryRenderer = renderer.newRenderer("gitiles.logEntryWrapper"); boolean renderedEntries = false; for (RevCommit c : paginator) { swallowResult(entryRenderer.setData(toEntrySoyData(paginator, c, df)).renderHtml(out)); out.flush(); renderedEntries = true; } if (!renderedEntries) { swallowResult(renderer.newRenderer("gitiles.emptyLog").renderHtml(out)); } swallowResult( renderer .newRenderer("gitiles.logEntriesFooter") .setData(toFooterSoyData(paginator, revision, footerBehavior)) .renderHtml(out)); }
checkState(u != null, "Missing Soy template %s", soyFile); Hasher h = Hashing.murmur3_128().newHasher(); try (InputStream is = u.openStream(); OutputStream os = Funnels.asOutputStream(h)) { ByteStreams.copy(is, os); } catch (IOException e) { throw new IllegalStateException("Missing Soy template " + soyFile, e); } return h.hash(); } public String renderHtml(String templateName, Map<String, ?> soyData) { return newRenderer(templateName).setData(soyData).renderHtml().get().toString(); } void render( HttpServletRequest req, HttpServletResponse res, String templateName, Map<String, ?> soyData) throws IOException { res.setContentType("text/html"); res.setCharacterEncoding("UTF-8"); byte[] data = newRenderer(templateName).setData(soyData).renderHtml().get().toString().getBytes(UTF_8); if (BaseServlet.acceptsGzipEncoding(req)) { res.addHeader(HttpHeaders.VARY, HttpHeaders.ACCEPT_ENCODING);
o.write(tail); } } }; } SoySauce.Renderer newRenderer(String templateName) { ImmutableMap.Builder<String, Object> staticUrls = ImmutableMap.builder(); for (String key : STATIC_URL_GLOBALS.keySet()) { staticUrls.put( key.replaceFirst("^gitiles\\.", ""), LegacyConversions.riskilyAssumeTrustedResourceUrl(globals.get(key))); } return getSauce() .renderTemplate(templateName) .setIj(ImmutableMap.of("staticUrls", staticUrls.build())); } protected abstract SoySauce getSauce(); }
config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", false); } @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log( "Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIds(notesRev); } // The requested value was not in the cache (hence, this loader was invoked). Therefore, try to // create this entry from a past value using the minimal amount of Git operations possible to // reduce latency. // // First, try to find the most recent state we have in the persistent cache. Most of the time, // this will be the state before the last update happened, but it can also date further back. We // try a best effort approach and check the last 10 states. If nothing is found, we default to // loading the value from scratch. //
config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", false); } @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log( "Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIds(notesRev); } // The requested value was not in the cache (hence, this loader was invoked). Therefore, try to // create this entry from a past value using the minimal amount of Git operations possible to // reduce latency. // // First, try to find the most recent state we have in the persistent cache. Most of the time, // this will be the state before the last update happened, but it can also date further back. We // try a best effort approach and check the last 10 states. If nothing is found, we default to // loading the value from scratch. //
* were performed since then. * * <p>Removals are applied before additions. * * @param repo open repository * @param oldExternalIds prior state that is used as base * @param additions map of name to blob ID for each external ID that should be added * @param removals set of name {@link ObjectId}s that should be removed */ private static AllExternalIds buildAllExternalIds( Repository repo, AllExternalIds oldExternalIds, Map<ObjectId, ObjectId> additions, Set<ObjectId> removals) throws IOException { ImmutableSetMultimap.Builder<Account.Id, ExternalId> byAccount = ImmutableSetMultimap.builder(); ImmutableSetMultimap.Builder<String, ExternalId> byEmail = ImmutableSetMultimap.builder(); // Copy over old ExternalIds but exclude deleted ones for (ExternalId externalId : oldExternalIds.byAccount().values()) { if (removals.contains(externalId.blobId())) { continue; } byAccount.put(externalId.accountId(), externalId); if (externalId.email() != null) {
import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.treewalk.TreeWalk; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.Mockito; import org.mockito.junit.MockitoJUnitRunner; @RunWith(MockitoJUnitRunner.class) public class ExternalIDCacheLoaderTest { private static AllUsersName ALL_USERS = new AllUsersName(AllUsersNameProvider.DEFAULT); @Mock Cache<ObjectId, AllExternalIds> externalIdCache; private ExternalIdCacheLoader loader; private GitRepositoryManager repoManager = new InMemoryRepositoryManager(); private ExternalIdReader externalIdReader; private ExternalIdReader externalIdReaderSpy; @Before public void setUp() throws Exception { repoManager.createRepository(ALL_USERS).close(); externalIdReader = new ExternalIdReader(repoManager, ALL_USERS, new DisabledMetricMaker()); externalIdReaderSpy = Mockito.spy(externalIdReader); loader = createLoader(true); } @Test public void worksOnSingleCommit() throws Exception {
private final TypeAdapter<T> defaultEnumAdapter; public EnumTypeAdapter(TypeAdapter<T> defaultEnumAdapter) { this.defaultEnumAdapter = defaultEnumAdapter; } @Override public T read(JsonReader in) throws IOException { // Still handle null values. -> Check them first. if (in.peek() == JsonToken.NULL) { in.nextNull(); return null; } T enumValue = defaultEnumAdapter.read(in); if (enumValue == null) { logger.atWarning().log("Expected an existing value for enum %s.", typeToken); } return enumValue; } @Override public void write(JsonWriter out, T value) throws IOException { defaultEnumAdapter.write(out, value); } } }
public void lowerCaseEnumValueIsTreatedAsUnset() { TestData data = gson.fromJson("{\"value\":\"one\"}", TestData.class); assertThat(data.value).isNull();
} private PushOne createPushOne(DynamicItem<ReplicationPushFilter> replicationPushFilter) { PushOne push = new PushOne( gitRepositoryManagerMock, permissionBackendMock, destinationMock, remoteConfigMock, credentialsFactory, threadRequestScoperMock, replicationQueueMock, idGeneratorMock, replicationStateListenersMock, replicationMetricsMock, projectCacheMock, transportFactoryMock, projectNameKey, urish); push.setReplicationPushFilter(replicationPushFilter); return push; } private void waitUntilFinished() throws InterruptedException { while (!isCallFinished.get()) { Thread.sleep(100); if (retryCount++ > MAX_RETRY_COUNT) { fail("Waiting until call finished - maximum number of retires reached"); } } } private void setupProjectCacheMock() throws IOException { projectCacheMock = createNiceMock(ProjectCache.class); expect(projectCacheMock.checkedGet(projectNameKey)).andReturn(projectStateMock); } private void setupTransportMock() throws NotSupportedException, TransportException { transportMock = createNiceMock(Transport.class); expect(transportMock.openFetch()).andReturn(fetchConnection); transportFactoryMock = createNiceMock(TransportFactory.class); expect(transportFactoryMock.open(repositoryMock, urish)).andReturn(transportMock).anyTimes(); } private void setupReplicationMetricsMock() {
* Found} for a redirect). * * <p>The returned response usually does not have any value (status code {code 204 No Content}). * If a value in the returned response is set it is automatically converted to JSON unless it is a * {@link BinaryResult}. * * <p>Throwing a subclass of {@link RestApiException} results in a 4XX response to the client. For * any other exception the client will get a {@code 500 Internal Server Error} response. * * @param parentResource parent resource of the resource that should be deleted * @param id the ID of the child resource that should be deleted * @param input input after parsing from request * @return response to return to the client * @throws RestApiException if the resource creation is rejected
* RestCollectionModifyViews this is usually {code 200 OK}, but other 2XX or 3XX status codes are * also possible (e.g. {code 201 Created} if a resource was created, {code 202 Accepted} if a * background task was scheduled, {@code 204 No Content} if no content is returned, {@code 302 * Found} for a redirect). * * <p>Throwing a subclass of {@link RestApiException} results in a 4XX response to the client. For * any other exception the client will get a {@code 500 Internal Server Error} response. * * @param parentResource the collection resource on which the modification is done * @return response to return to the client * @throws Exception the implementation of the view failed. The exception will be logged and HTTP * 500 Internal Server Error will be returned to the client.
throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } Map<ProjectWatchKey, Set<NotifyType>> projectWatches = asMap(input); accountsUpdateProvider .get() .update( "Update Project Watches via API", rsrc.getUser().getAccountId(), u -> u.updateProjectWatches(projectWatches)); return getWatchedProjects.apply(rsrc); } private Map<ProjectWatchKey, Set<NotifyType>> asMap(List<ProjectWatchInfo> input) throws RestApiException, IOException, PermissionBackendException { Map<ProjectWatchKey, Set<NotifyType>> m = new HashMap<>(); for (ProjectWatchInfo info : input) { if (info.project == null) { throw new BadRequestException("project name must be specified"); } ProjectWatchKey key = ProjectWatchKey.create(projectsCollection.parse(info.project).getNameKey(), info.filter); if (m.containsKey(key)) { throw new BadRequestException(
this.self = self; this.changes = changes; } @Override @SuppressWarnings("unchecked") public Response<List<ChangeInfo>> apply(AccountResource rsrc) throws BadRequestException, AuthException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { throw new AuthException("not allowed to list stars of another account"); } QueryChanges query = changes.list(); query.addQuery("has:stars"); Response<?> response = query.apply(TopLevelResource.INSTANCE); List<ChangeInfo> value = (List<ChangeInfo>) response.value(); return Response.ok(value); } } @Singleton public static class Get implements RestReadView<AccountResource.Star> { private final Provider<CurrentUser> self; private final StarredChangesUtil starredChangesUtil; @Inject Get(Provider<CurrentUser> self, StarredChangesUtil starredChangesUtil) { this.self = self; this.starredChangesUtil = starredChangesUtil; } @Override public Response<SortedSet<String>> apply(AccountResource.Star rsrc) throws AuthException { if (!self.get().hasSameAccountId(rsrc.getUser())) {
public Response<?> apply(ProjectResource rsrc, Input input) { Project.NameKey project = rsrc.getNameKey(); if (input.async) { return applyAsync(project, input); } return Response.ok(applySync(project, input));
: String.format("Changed default dashboard to %s.\n", input.id)); if (!msg.endsWith("\n")) { msg += "\n"; } md.setAuthor(rsrc.getUser().asIdentifiedUser()); md.setMessage(msg); config.commit(md); cache.evict(rsrc.getProjectState().getProject()); if (target != null) { Response<DashboardInfo> response = get.get().apply(target); response.value().isDefault = true; return response; } return Response.none(); } catch (RepositoryNotFoundException notFound) { throw new ResourceNotFoundException(rsrc.getProjectState().getProject().getName()); } catch (ConfigInvalidException e) { throw new ResourceConflictException( String.format("invalid project.config: %s", e.getMessage())); } } }
private final Configuration cfg; private final HideProject hideProject; @Inject DeleteProject( FilesystemDeleteHandler fsHandler, CacheDeleteHandler cacheHandler, Provider<CurrentUser> userProvider, DeleteLog deleteLog, DeletePreconditions preConditions, Configuration cfg, HideProject hideProject) { this.fsHandler = fsHandler; this.cacheHandler = cacheHandler; this.userProvider = userProvider; this.deleteLog = deleteLog; this.preConditions = preConditions; this.cfg = cfg; this.hideProject = hideProject; } @Override public Object apply(ProjectResource rsrc, Input input) throws IOException, RestApiException { preConditions.assertDeletePermission(rsrc); preConditions.assertCanBeDeleted(rsrc, input); doDelete(rsrc, input); return Response.none(); } public void doDelete(ProjectResource rsrc, Input input) throws IOException, RestApiException { Project project = rsrc.getProjectState().getProject(); boolean preserve = input != null && input.preserve; Exception ex = null; try { if (!preserve || !cfg.projectOnPreserveHidden()) { try {
private void savePluginSections(Config rc, Set<AccountGroup.UUID> keepGroups) { unsetSection(rc, PLUGIN); for (Map.Entry<String, Config> e : pluginConfigs.entrySet()) { String plugin = e.getKey(); Config pluginConfig = e.getValue(); for (String name : pluginConfig.getNames(PLUGIN, plugin)) { String value = pluginConfig.getString(PLUGIN, plugin, name); String groupName = GroupReference.extractGroupName(value); if (groupName != null) { GroupReference ref = groupsByName.get(groupName); if (ref != null && ref.getUUID() != null) { keepGroups.add(ref.getUUID()); pluginConfig.setString(PLUGIN, plugin, name, "group " + ref.getName()); } } rc.setStringList( PLUGIN, plugin, name, Arrays.asList(pluginConfig.getStringList(PLUGIN, plugin, name))); } }
this.accountInfoFactory = infoFactory; this.projectCache = projectCache; this.prologRule = prologRule; } @Override public Response<List<TestSubmitRuleInfo>> apply(RevisionResource rsrc, TestSubmitRuleInput input) throws AuthException, PermissionBackendException, BadRequestException { if (input == null) { input = new TestSubmitRuleInput(); } if (input.rule == null) { throw new BadRequestException("rule is required"); } if (!rules.isProjectRulesEnabled()) { throw new AuthException("project rules are disabled"); } input.filters = MoreObjects.firstNonNull(input.filters, filters); SubmitRuleOptions opts = SubmitRuleOptions.builder() .skipFilters(input.filters == Filters.SKIP) .rule(input.rule) .logErrors(false) .build(); ProjectState projectState = projectCache.get(rsrc.getProject()); if (projectState == null) { throw new BadRequestException("project not found"); }
// // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.gerrit.extensions.registration.DynamicItem; import com.google.inject.AbstractModule; /** * Gerrit libModule for applying a ref-filter for outgoing replications. * * <p>It should be used only when an actual filter is defined, otherwise the default replication * plugin behaviour will be pushing all refs without any filtering. */ public class ReplicationExtensionPointModule extends AbstractModule { @Override protected void configure() { DynamicItem.itemOf(binder(), ReplicationPushFilter.class); } }
throw new RuntimeException(e); } }) .collect(Collectors.toList()); PushResult pushResult = new PushResult(); expect(transportMock.push(anyObject(), compareRemoteRef(expectedUpdates))) .andReturn(pushResult) .once(); replay(transportMock); PushOne pushOne = createPushOne(replicationPushFilter); pushOne.addRef(PushOne.ALL_REFS); pushOne.run(); isCallFinished.await(10, TimeUnit.SECONDS); verify(transportMock); } @Test public void shouldPushAllRefsWhenNoFiltersSetup() throws InterruptedException, IOException { shouldPushAllRefsWithDynamicItemFilter(null); } List<RemoteRefUpdate> expectedUpdates = localRefs.values().stream() .map( ref -> { try { return new RemoteRefUpdate( repositoryMock, ref.getName(), ref.getObjectId(), "fooProject", false, "fooProject", null); } catch (IOException e) { throw new RuntimeException(e); } }) .collect(Collectors.toList()); PushResult pushResult = new PushResult(); expect(transportMock.push(anyObject(), compareRemoteRef(expectedUpdates)))
throw new RuntimeException(e); } }) .collect(Collectors.toList()); PushResult pushResult = new PushResult(); expect(transportMock.push(anyObject(), compareRemoteRef(expectedUpdates))) .andReturn(pushResult) .once(); replay(transportMock); PushOne pushOne = createPushOne(null); pushOne.addRef(PushOne.ALL_REFS); pushOne.run(); isCallFinished.await(10, TimeUnit.SECONDS); verify(transportMock); } @Test public void shouldBlockReplicationUsingPushFilter() throws InterruptedException, IOException { DynamicItem<ReplicationPushFilter> replicationPushFilter = DynamicItem.itemOf( ReplicationPushFilter.class, new ReplicationPushFilter() { @Override public List<RemoteRefUpdate> filter( String projectName, List<RemoteRefUpdate> remoteUpdatesList) { remoteUpdatesList.remove(0); return remoteUpdatesList; } }); // easymock way to check if method was never called expect(transportMock.push(anyObject(), anyObject())) .andThrow(new AssertionFailedError()) .anyTimes(); replay(transportMock); PushOne pushOne = createPushOne(replicationPushFilter);
public List<RemoteRefUpdate> filter( String projectName, List<RemoteRefUpdate> remoteUpdatesList) { return Collections.emptyList();
throw new AuthException("Authentication required"); } return commentJson .get() .setFillAccounts(includeAuthorInfo()) .setFillPatchSet(true) .newCommentFormatter() .format(listComments(rsrc)); } public List<CommentInfo> getComments(ChangeResource rsrc) throws AuthException, OrmException { if (requireAuthentication() && !rsrc.getUser().isIdentifiedUser()) { throw new AuthException("Authentication required"); } return commentJson .get() .setFillAccounts(includeAuthorInfo()) .setFillPatchSet(true) .newCommentFormatter(); } }
static final String MAX_CACHE_AGE = "maxCacheAge"; // seconds to stay in cache static final String MAX_CACHE_SIZE = "maxCacheSize"; // number of OwnersDb in cache static final String MIN_OWNER_VOTE_LEVEL = "minOwnerVoteLevel"; // default +1 static final String REPORT_SYNTAX_ERROR = "reportSyntaxError"; // only for tests // "alwaysShowButton" is obsolete, new UI design always shows the [Find Owners] button // Name of config parameters that can be defined in project.config or gerrit.config: static final String OWNERS_FILE_NAME = "ownersFileName"; // config key for file name static final String REJECT_ERROR_IN_OWNERS = "rejectErrorInOwners"; // enable upload validator static final String OWNERS = "OWNERS"; // default OWNERS file name // Name of plugin and namespace. static final String PLUGIN_NAME = "find-owners"; static final String PROLOG_NAMESPACE = "find_owners"; private final PluginConfigFactory configFactory; // Each call to API entry point creates one new Config and parses gerrit.config.
String getOwnersFileName(Project project) { String defaultName = getDefaultOwnersFileName(); try { String name = getProjectConfig(project).getString(OWNERS_FILE_NAME, defaultName); if (name.trim().isEmpty()) { logger.atSevere().log("Project %s has empty %s", project, OWNERS_FILE_NAME); return defaultName; } return name; } catch (NoSuchProjectException e) { logger.atSevere().withCause(e).log( "Exception in getOwnersFileName for %s", project.getName()); return defaultName; }
* * <p>In addition accounts are included that have the given email as preferred email even if they * have no external ID for the preferred email. Having accounts with a preferred email that does * not exist as external ID is an inconsistency, but existing functionality relies on still * getting those accounts, which is why they are included. Accounts by preferred email are fetched * from the account index as a fallback for email addresses that could not be resolved using * {@link ExternalIds}. * * @see #getAccountsFor(String...) */ public ImmutableSet<Account.Id> getAccountFor(String email) throws IOException { ImmutableSet<Account.Id> accounts = externalIds.byEmail(email).stream().map(ExternalId::accountId).collect(toImmutableSet()); if (!accounts.isEmpty()) { return accounts; } return executeIndexQuery(() -> queryProvider.get().byPreferredEmail(email).stream()) .map(a -> a.getAccount().id()) .collect(toImmutableSet()); } /**
// limitations under the License. package com.google.gerrit.server.account; import static com.google.common.collect.ImmutableList.toImmutableList; import static com.google.common.collect.ImmutableSet.toImmutableSet; import com.google.common.base.Throwables; import com.google.common.collect.ImmutableSet; import com.google.common.collect.ImmutableSetMultimap; import com.google.common.collect.MultimapBuilder; import com.google.common.collect.SetMultimap; import com.google.gerrit.exceptions.StorageException; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.server.account.externalids.ExternalId; import com.google.gerrit.server.account.externalids.ExternalIds; import com.google.gerrit.server.query.account.InternalAccountQuery; import com.google.gerrit.server.update.RetryHelper; import com.google.gerrit.server.update.RetryHelper.Action; import com.google.gerrit.server.update.RetryHelper.ActionType; import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.Singleton; import java.io.IOException; import java.util.Arrays; import java.util.List; /** Class to access accounts by email. */ @Singleton public class Emails { private final ExternalIds externalIds;
// // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.extensions.common.GitPerson; public class SharedRefLogEntry { public enum Type { UPDATE_REF, DELETE_REF, DELETE_PROJECT } public String projectName; public Type type; public static class UpdateRef extends SharedRefLogEntry { public String refName; public String oldId; public String newId; public GitPerson committer; public String comment; UpdateRef( String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName;
public SharedRefDatabaseWrapper( DynamicItem<SharedRefDatabase> sharedRefDbDynamicItem, SharedRefLogger sharedRefLogger) { this.sharedRefDbDynamicItem = sharedRefDbDynamicItem; this.sharedRefLogger = sharedRefLogger;
public SharedRefDatabaseWrapper( DynamicItem<SharedRefDatabase> sharedRefDbDynamicItem, SharedRefLogger sharedRefLogger) { this.sharedRefDbDynamicItem = sharedRefDbDynamicItem; this.sharedRefLogger = sharedRefLogger;
logger.atFiner().log("Create new OwnersDb, key=%s", key); return new OwnersDb( permissionBackend, projectState, accountCache, emails, key, repoManager, config, changeData, branch, files); } try { logger.atFiner().log( "Get from cache %s, key=%s, cache size=%d", dbCache, key, dbCache.size()); return dbCache.get( key, new Callable<OwnersDb>() { @Override public OwnersDb call() { logger.atFiner().log("Create new OwnersDb, key=%s", key); return new OwnersDb( permissionBackend, projectState, accountCache, emails, key, repoManager, config, changeData, branch, files); } }); } catch (ExecutionException e) { logger.atSevere().withCause(e).log(
.create(); update(rev); ProjectConfig cfg = read(rev); cfg.getAccountsSection().setSameGroupVisibility(ImmutableList.of()); rev = commit(cfg); assertThat(text(rev, "project.config")) .isEqualTo( "[commentlink \"bugzilla\"]\n\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n"); } @Test public void contributorSectionIsUnsetIfNoContributorAgreementIsSet() throws Exception { RevCommit rev = tr.commit() .add( "project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[contributor-agreement \"Individual\"]\n" + " accepted = group Developers\n" + " accepted = group Staff\n") .create(); update(rev); ProjectConfig cfg = read(rev); ContributorAgreement section = cfg.getContributorAgreement("Individual");
.create(); update(rev); ProjectConfig cfg = read(rev); ContributorAgreement section = cfg.getContributorAgreement("Individual"); section.setAccepted(ImmutableList.of()); rev = commit(cfg); assertThat(text(rev, "project.config")) .isEqualTo( "[commentlink \"bugzilla\"]\n\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n"); } @Test public void notifySectionIsUnsetIfNoNotificationsAreSet() throws Exception { RevCommit rev = tr.commit() .add( "project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[notify \"name\"]\n" + " email = example@example.com\n") .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getNotifyConfigs().clear(); rev = commit(cfg);
+ " email = example@example.com\n") .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getNotifyConfigs().clear(); rev = commit(cfg); assertThat(text(rev, "project.config")) .isEqualTo( "[commentlink \"bugzilla\"]\n\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n"); } @Test public void commentLinkSectionIsUnsetIfNoCommentLinksAreSet() throws Exception { RevCommit rev = tr.commit() .add( "project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[notify \"name\"]\n" + " email = example@example.com\n") .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getCommentLinkSections().clear(); rev = commit(cfg);
@NoHttpd public class NoUnresolvedCommentsRuleIT extends LightweightPluginDaemonTest { private static final String FILENAME = "my.file"; @Before public void enableRuleBeforeTest() throws Exception { enableRule(true); } @Test public void blocksWithUnresolvedComments() throws Exception { ReviewInput.CommentInput comment = newFileComment(); comment.unresolved = true; PushOneCommit.Result r = createChangeWithComment(comment); Optional<SubmitRecord> submitRecords = evaluate(r.getChange()); assertThat(submitRecords).isPresent(); SubmitRecord result = submitRecords.get(); assertThat(result.status).isEqualTo(SubmitRecord.Status.NOT_READY); assertThat(result.labels).isNull(); assertThat(result.requirements).hasSize(1); } @Test public void doesNotBlockWithNoComments() throws Exception { ReviewInput.CommentInput comment = newFileComment(); comment.unresolved = false; PushOneCommit.Result r = createChangeWithComment(comment); Optional<SubmitRecord> submitRecords = evaluate(r.getChange()); assertThat(submitRecords.isPresent()).isTrue(); SubmitRecord result = submitRecords.get();
package com.google.gerrit.server.rules; import com.google.gerrit.common.data.SubmitRecord; import com.google.gerrit.extensions.annotations.ExtensionPoint; import com.google.gerrit.server.query.change.ChangeData; import java.util.Optional; /** * Allows plugins to decide whether a change is ready to be submitted or not. * * <p>For a given {@link ChangeData}, each plugin is called and returns a {@link Optional} of {@link * SubmitRecord}. * * <p>A Change can only be submitted if all the plugins give their consent. * * <p>Each {@link SubmitRecord} represents a decision made by the plugin. If the plugin rejects a * change, it should hold valuable informations to help the end user understand and correct the * blocking points. * * <p>It should be noted that each plugin can handle rules inheritance. * * <p>This interface should be used to write pre-submit validation rules. This includes both simple
import java.util.Map; import java.util.Optional; import org.eclipse.jgit.internal.storage.dfs.InMemoryRepository; import org.eclipse.jgit.junit.TestRepository; import org.junit.Test; @NoHttpd public class IgnoreSelfApprovalRuleIT extends AbstractDaemonTest { @Inject private IgnoreSelfApprovalRule rule; @Test public void blocksWhenUploaderIsOnlyApprover() throws Exception { enableRule("Code-Review", true); PushOneCommit.Result r = createChange(); approve(r.getChangeId()); Optional<SubmitRecord> submitRecord = rule.evaluate(r.getChange()); assertThat(submitRecords.isPresent()).isTrue(); SubmitRecord result = submitRecords.get(); assertThat(result.status).isEqualTo(SubmitRecord.Status.NOT_READY); assertThat(result.labels).isNotEmpty(); assertThat(result.requirements) .containsExactly( SubmitRequirement.builder() .setFallbackText("Approval from non-uploader required") .setType("non_uploader_approval") .build()); } @Test public void allowsSubmissionWhenChangeHasNonUploaderApproval() throws Exception { enableRule("Code-Review", true); // Create change as user
} @Test public void allowsSubmissionWhenChangeHasNonUploaderApproval() throws Exception { enableRule("Code-Review", true); // Create change as user TestRepository<InMemoryRepository> userTestRepo = cloneProject(project, user); PushOneCommit push = pushFactory.create(user.newIdent(), userTestRepo); PushOneCommit.Result r = push.to("refs/for/master"); // Approve as admin approve(r.getChangeId()); Optional<SubmitRecord> submitRecord = rule.evaluate(r.getChange()); assertThat(submitRecord).isEmpty(); } @Test public void doesNothingByDefault() throws Exception { enableRule("Code-Review", false); PushOneCommit.Result r = createChange(); approve(r.getChangeId()); Optional<SubmitRecord> submitRecords = rule.evaluate(r.getChange()); assertThat(submitRecords.isPresent()).isFalse(); } private void enableRule(String labelName, boolean newState) throws Exception { try (ProjectConfigUpdate u = updateProject(project)) { Map<String, LabelType> localLabelSections = u.getConfig().getLabelSections();
public void convertsPrologToSubmitRecord() { PrologRuleEvaluator evaluator = makeEvaluator(); StructureTerm verifiedLabel = makeLabel("Verified", "may"); StructureTerm labels = new StructureTerm("label", verifiedLabel); List<Term> terms = ImmutableList.of(makeTerm("ok", labels)); Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); assertThat(record).isPresent();
terms.add(makeTerm("ok", makeLabels(label2))); terms.add(makeTerm("not_ready", makeLabels(label3))); // When Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); // assert that SubmitRecord expectedRecord = new SubmitRecord(); expectedRecord.status = SubmitRecord.Status.OK; expectedRecord.labels = new ArrayList<>(); expectedRecord.labels.add(submitRecordLabel2); expectedRecord.labels.add(submitRecordLabel3); assertThat(record).hasValue(expectedRecord);
terms.add(makeTerm("ok", makeLabels(label2))); terms.add(makeTerm("not_ready", makeLabels(label3))); // When Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); // assert that SubmitRecord expectedRecord = new SubmitRecord(); expectedRecord.status = SubmitRecord.Status.OK; expectedRecord.labels = new ArrayList<>(); expectedRecord.labels.add(submitRecordLabel2); expectedRecord.labels.add(submitRecordLabel3); assertThat(record).hasValue(expectedRecord);
protected void configure() { if (config.getSharedRefDb().isEnabled()) { install(new ValidationModule(config)); }
protected void configure() { bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getZookeeperConfig().buildCurator()); bind(ZkConnectionConfig.class) .toInstance( new ZkConnectionConfig( cfg.getZookeeperConfig().buildCasRetryPolicy(), cfg.getZookeeperConfig().getZkInterProcessLockTimeOut())); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ProjectDeletedSharedDbCleanup.class);
metadataBuilder.addPluginMetadata( PluginMetadata.create(PUBLISHER_SUCCESS_COUNTER, fieldValue))) .description("Broker message published count") .build()); this.brokerPublisherFailureCounter = metricMaker.newCounter( "multi_site/broker/broker_message_publisher_failure_counter", new Description("Number of messages failed to publish by the broker publisher") .setRate() .setUnit("errors"), Field.ofString(PUBLISHER_FAILURE_COUNTER, metadataMapper(PUBLISHER_FAILURE_COUNTER)) .description("Broker failed to publish message count") .build());
new Description("Number of messages failed to publish by the broker publisher") .setRate() .setUnit("errors"), Field.ofString(PUBLISHER_FAILURE_COUNTER, metadataMapper(PUBLISHER_FAILURE_COUNTER)) .description("Broker failed to publish message count") .build()); } public void incrementBrokerPublishedMessage() { brokerPublisherSuccessCounter.increment(PUBLISHER_SUCCESS_COUNTER); } public void incrementBrokerFailedToPublishMessage() { brokerPublisherFailureCounter.increment(PUBLISHER_FAILURE_COUNTER); } private Field<String> field(String metadataKey, String description) { return Field.ofString( metadataKey, (metadataBuilder, fieldValue) -> metadataBuilder.addPluginMetadata(PluginMetadata.create(metadataKey, fieldValue))) .description(description) .build(); } }
"Kafka consumer subscribing to topic [%s] for event family [%s]", topic, getEventFamily()); consumer.subscribe(Collections.singleton(topic)); while (!closed.get()) { ConsumerRecords<byte[], byte[]> consumerRecords = consumer.poll(Duration.ofMillis(configuration.kafkaSubscriber().getPollingInterval())); consumerRecords.forEach(this::processRecord); } } catch (WakeupException e) { // Ignore exception if closing if (!closed.get()) throw e; } catch (Exception e) { subscriberMetrics.incrementSubscriberFailedToPollMessages(); throw e; } finally { consumer.close(); }
eventRouter.route(event.getEventBody(gson)); subscriberMetrics.incrementSubscriberConsumedMessage(); } catch (IOException e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (PermissionBackendException | OrmException e) { logger.atSevere().withCause(e).log( "Cannot handle message %s: [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } } } catch (Exception e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", new String(consumerRecord.value(), UTF_8)); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); }
public IndexEventSubscriber( KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, IndexEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gsonProvider, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super( configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gsonProvider, instanceId, oneOffCtx, msgLog, kafkaSubscriberMetrics);
public KafkaCacheEvictionEventSubscriber( KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, StreamEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gsonProvider, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super( configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gsonProvider, instanceId, oneOffCtx, msgLog, kafkaSubscriberMetrics);
public ProjectUpdateEventSubscriber( KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, ProjectListUpdateRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gson, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super( configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gson, instanceId, oneOffCtx, msgLog, kafkaSubscriberMetrics);
public StreamEventSubscriber( KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, StreamEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gson, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, SubscriberMetrics subscriberMetrics) { super( configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gson, instanceId, oneOffCtx, msgLog, kafkaSubscriberMetrics);
private String replaceInUrl(String placeholder, String url, String replacement) { if (url == null || replacement == null || !url.contains(placeholder)) { return url; } if (lowerCase) { replacement = replacement.toLowerCase(); } // as we can't assume anything of 'replacement', we're URL encoding it return url.replace(placeholder, Url.encode(replacement));
// distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.broker; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public interface BrokerSession { boolean isOpen(); void connect(); void disconnect(); boolean publish(String topic, String payload); }
CheckUpdate.Builder builder = CheckUpdate.builder(); builder .setState(CheckState.NOT_STARTED) .unsetFinished() .unsetStarted() .setMessage("") .setUrl(""); Check updatedCheck; if (!check.isPresent()) { Checker checker = checkers .getChecker(checkerUuid) .orElseThrow( () -> new ResourceNotFoundException( String.format("checker %s not found", checkerUuid))); // This error should not be thrown since this case is filtered before reaching this code. // Also return a backfilled check for checkers that do not apply to the change. updatedCheck = Check.newBackfilledCheck( checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getPatchSet(), checker); } else { updatedCheck = checksUpdate.get().updateCheck(key, builder.build()); } return checkJsonFactory.noOptions().format(updatedCheck); } }
CheckUpdate.Builder builder = CheckUpdate.builder(); builder .setState(CheckState.NOT_STARTED) .unsetFinished() .unsetStarted() .setMessage("") .setUrl(""); Check updatedCheck; if (!check.isPresent()) { Checker checker = checkers .getChecker(checkerUuid) .orElseThrow( () -> new ResourceNotFoundException( String.format("checker %s not found", checkerUuid))); // This error should not be thrown since this case is filtered before reaching this code. // Also return a backfilled check for checkers that do not apply to the change. updatedCheck = Check.newBackfilledCheck( checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getPatchSet(), checker); } else { updatedCheck = checksUpdate.get().updateCheck(key, builder.build()); } return checkJsonFactory.noOptions().format(updatedCheck); } }
assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); assertThat(info.updated).isGreaterThan(info.created); } @Test public void rerunCheckNotExistingButBackfilled() throws Exception { CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunExistingCheckWithCheckerNotAppliedToChange() throws Exception { Project.NameKey otherProject = projectOperations.newProject().create(); checkerOperations.checker(checkKey.checkerUuid()).forUpdate().repository(otherProject).update(); checkOperations.newCheck(checkKey).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunNonExistingCheckWithCheckerNotAppliedToChange() throws Exception { Project.NameKey otherProject = createProjectOverAPI("other", null, true, null); checkerOperations.checker(checkKey.checkerUuid()).forUpdate().repository(otherProject).update(); assertThrows( ResourceNotFoundException.class,
// // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.inject.Inject; import com.google.inject.Singleton; import java.util.Optional; import org.eclipse.jgit.transport.URIish; /** Factory for creating an {@link AdminApi} instance for a remote URI. */ public interface AdminApiFactory { Optional<AdminApi> create(URIish uri); @Singleton static class DefaultAdminApiFactory implements AdminApiFactory { protected final SshHelper sshHelper; @Inject public DefaultAdminApiFactory(SshHelper sshHelper) { this.sshHelper = sshHelper; } @Override public Optional<AdminApi> create(URIish uri) { if (isGerrit(uri)) { return Optional.of(new GerritSshApi(sshHelper, uri)); } else if (!uri.isRemote()) { return Optional.of(new LocalFS(uri));
if (destRef == null) { throw new ResourceConflictException( "can't rebase onto tip of branch " + destRefKey.get() + "; branch doesn't exist"); } return destRef.getObjectId(); } Base base = rebaseUtil.parseBase(rsrc, str); if (base == null) { throw new ResourceConflictException( "base revision is missing from the destination branch: " + str); } PatchSet.Id baseId = base.patchSet().getId(); if (change.getId().equals(baseId.getParentKey())) { throw new ResourceConflictException("cannot rebase change onto itself"); } permissionBackend .user(rsrc.getUser()) .database(dbProvider) .change(base.notes()) .check(ChangePermission.READ); Change baseChange = base.notes().getChange(); if (!baseChange.getProject().equals(change.getProject())) { throw new ResourceConflictException( "base change is in wrong project: " + baseChange.getProject()); } else if (!baseChange.getDest().equals(change.getDest())) {
package com.googlesource.gerrit.plugins.multisite.kafka; import com.google.gerrit.server.events.Event; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.broker.BrokerApi; import com.googlesource.gerrit.plugins.multisite.broker.kafka.BrokerPublisher; import com.googlesource.gerrit.plugins.multisite.consumer.SourceAwareEventWrapper; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventTopic; import com.googlesource.gerrit.plugins.multisite.kafka.consumer.KafkaEventSubscriber; import java.util.function.Consumer; public class KafkaBrokerApi implements BrokerApi { private final BrokerPublisher publisher; private final Provider<KafkaEventSubscriber> subscriberProvider; private List<KafkaEventSubscriber> subscribers; @Inject public KafkaBrokerApi(BrokerPublisher publisher, KafkaEventSubscriber subscriber) { this.publisher = publisher; this.subscriber = subscriber; } @Override public boolean send(String topic, Event event) { return publisher.publish(topic, event); } @Override public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { subscriber.subscribe(EventTopic.of(topic), eventConsumer); } }
public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { KafkaEventSubscriber subscriber = subscriberProvider.get(); subscribers.add(subscriber); subscriber.subscribe(EventTopic.of(topic), eventConsumer);
} listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } install(new BrokerModule()); DynamicItem.bind(binder(), BrokerApi.class).to(KafkaBrokerApi.class); install(kafkaForwardedEventRouterModule); install(kafkaBrokerForwarderModule); install( new ValidationModule( config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); bind(Gson.class) .annotatedWith(BrokerGson.class) .toProvider(GsonProvider.class) .in(Singleton.class);
public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { apiDelegate.get().receiveAync(topic, eventConsumer);
public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { KafkaEventSubscriber subscriber = subscriberProvider.get(); synchronized (subscribers) { subscribers.add(subscriber); } subscriber.subscribe(EventTopic.of(topic), eventConsumer);
import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.config.SitePaths; import com.google.gerrit.server.util.ManualRequestContext; import com.google.gerrit.server.util.OneOffRequestContext; import com.google.gerrit.server.util.RequestContext; import com.google.gerrit.testing.ConfigSuite; import com.google.inject.Injector; import com.google.inject.Module; import com.google.inject.Provider; import java.io.File; import java.io.IOException; import java.util.Arrays; import java.util.Collections; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.StoredConfig; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.eclipse.jgit.util.SystemReader; import org.junit.Rule; import org.junit.rules.RuleChain; import org.junit.rules.TemporaryFolder; import org.junit.rules.TestRule; import org.junit.runner.Description; import org.junit.runner.RunWith; import org.junit.runners.model.Statement; @RunWith(ConfigSuite.class) @UseLocalDisk public abstract class StandaloneSiteTest {
return new FileBasedConfig(parent, new File(tempDir, "user.config"), FS.detect()); } @Override public FileBasedConfig openSystemConfig(Config parent, FS fs) { return new FileBasedConfig(parent, new File(tempDir, "system.config"), FS.detect()); } @Override public long getCurrentTime() { return oldSystemReader.getCurrentTime(); } @Override public int getTimezone(long when) { return oldSystemReader.getTimezone(when); } @Override public StoredConfig getUserConfig() throws IOException, ConfigInvalidException { return oldSystemReader.getUserConfig(); } @Override public StoredConfig getSystemConfig() throws IOException, ConfigInvalidException { return oldSystemReader.getSystemConfig(); }
private final Map<URIish, PushOne> pending = new HashMap<>(); private final Map<URIish, PushOne> inFlight = new HashMap<>(); private final PushOne.Factory opFactory; private final GitRepositoryManager gitManager; private final PermissionBackend permissionBackend; private final Provider<CurrentUser> userProvider; private final ProjectCache projectCache; private volatile ScheduledExecutorService pool; private final PerThreadRequestScope.Scoper threadScoper; private final DestinationConfiguration config; private final DynamicItem<EventDispatcher> eventDispatcher; private final ReplicationTasksStorage replicationTasksStorage; protected enum RetryReason { TRANSPORT_ERROR, COLLISION, REPOSITORY_MISSING; } public static class QueueInfo { public final Map<URIish, PushOne> pending; public final Map<URIish, PushOne> inFlight; public QueueInfo(Map<URIish, PushOne> pending, Map<URIish, PushOne> inFlight) { this.pending = ImmutableMap.copyOf(pending); this.inFlight = ImmutableMap.copyOf(inFlight); } } @Inject protected Destination( Injector injector, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend,
protected Destination( Injector injector, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, GroupBackend groupBackend, ReplicationStateListeners stateLog, GroupIncludeCache groupIncludeCache, DynamicItem<EventDispatcher> eventDispatcher, ReplicationTasksStorage rts, @Assisted DestinationConfiguration cfg) { this.eventDispatcher = eventDispatcher; gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.stateLog = stateLog; this.eventsStorage = es; config = cfg; CurrentUser remoteUser; if (!cfg.getAuthGroupNames().isEmpty()) { ImmutableSet.Builder<AccountGroup.UUID> builder = ImmutableSet.builder(); for (String name : cfg.getAuthGroupNames()) { GroupReference g = GroupBackends.findExactSuggestion(groupBackend, name); if (g != null) { builder.add(g.getUUID()); addRecursiveParents(g.getUUID(), builder, groupIncludeCache); } else {
return; } } } synchronized (stateLock) { PushOne e = getPendingPush(uri); if (e == null) { e = opFactory.create(project, uri); addRef(e, ref); e.addState(ref, state); @SuppressWarnings("unused") ScheduledFuture<?> ignored = pool.schedule(e, now ? 0 : config.getDelay(), TimeUnit.SECONDS); pending.put(uri, e); replicationTasksStorage.persist(project.get(), ref, e.getURI(), getRemoteConfigName()); } else if (!e.getRefs().contains(ref)) { addRef(e, ref); e.addState(ref, state); } state.increasePushTaskCount(project.get(), ref); repLog.info("scheduled {}:{} => {} to run after {}s", project, ref, e, config.getDelay()); }
void notifyFinished(PushOne op) { synchronized (stateLock) { inFlight.remove(op.getURI()); if (!op.wasCanceled()) { for (String ref : op.getRefs()) { if (!refHasPendingPush(op.getURI(), ref)) { replicationTasksStorage.delete( op.getProjectNameKey().get(), ref, op.getURI(), getRemoteConfigName()); } } } }
String key = "${name}"; int n = in.indexOf(key); if (0 <= n) { return in.substring(0, n) + name + in.substring(n + key.length()); } if (keyIsOptional) { return in; } return null; } private final WorkQueue workQueue; private final DynamicItem<EventDispatcher> dispatcher; private final ReplicationConfig config; private final AdminApiFactory adminApiFactory; private final ReplicationState.Factory replicationStateFactory; private final ReplicationTasksStorage replicationTasksStorage; private volatile boolean running; private volatile boolean replaying; @Inject ReplicationQueue( WorkQueue wq, AdminApiFactory aaf, ReplicationConfig rc, DynamicItem<EventDispatcher> dis, ReplicationStateListeners sl, ReplicationState.Factory rsf, ReplicationTasksStorage es) { workQueue = wq; dispatcher = dis; config = rc; stateLog = sl; adminApiFactory = aaf; replicationStateFactory = rsf; eventsStorage = es; } @Override public void start() { if (!running) { config.startup(workQueue);
return in; } return null; } private final WorkQueue workQueue; private final DynamicItem<EventDispatcher> dispatcher; private final ReplicationConfig config; private final AdminApiFactory adminApiFactory; private final ReplicationState.Factory replicationStateFactory; private final ReplicationTasksStorage eventsStorage; private volatile boolean running; private volatile boolean replaying; @Inject ReplicationQueue( WorkQueue wq, AdminApiFactory aaf, ReplicationConfig rc, DynamicItem<EventDispatcher> dis, ReplicationStateListeners sl, ReplicationState.Factory rsf, ReplicationTasksStorage rts) { workQueue = wq; dispatcher = dis; config = rc; stateLog = sl; adminApiFactory = aaf; replicationStateFactory = rsf; eventsStorage = es; } @Override public void start() { if (!running) { config.startup(workQueue); running = true; firePendingEvents(); } } @Override public void stop() { running = false; int discarded = config.shutdown(); if (discarded > 0) {
private void firePendingEvents() { try { Set<String> tasksReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate e : eventsStorage.list()) { String eventKey = String.format("%s:%s", e.project, e.ref); if (!eventsReplayed.contains(eventKey)) { repLog.info("Firing pending event {}", eventKey); onGitReferenceUpdated(e.project, e.ref); eventsReplayed.add(eventKey); } } } finally { replaying = false; }
&& head.isSymbolic() && RefNames.REFS_CONFIG.equals(head.getLeaf().getName())) { return; } } catch (IOException err) { stateLog.error(String.format("cannot check type of project %s", project), err, state); return; } } catch (IOException err) { stateLog.error(String.format("source project %s not available", project), err, state); return; } } } synchronized (stateLock) { PushOne task = getPendingPush(uri); if (task == null) { task = opFactory.create(project, uri); addRef(task, ref); task.addState(ref, state); @SuppressWarnings("unused") ScheduledFuture<?> ignored = pool.schedule(e, now ? 0 : config.getDelay(), TimeUnit.SECONDS); pending.put(uri, e); replicationTasksStorage.persist(project.get(), ref, e.getURI(), getRemoteConfigName()); } else if (!e.getRefs().contains(ref)) { addRef(e, ref); e.addState(ref, state); }
void notifyFinished(PushOne task) { synchronized (stateLock) { inFlight.remove(op.getURI()); if (!op.wasCanceled()) { for (String ref : op.getRefs()) { if (!refHasPendingPush(op.getURI(), ref)) { replicationTasksStorage.delete( op.getProjectNameKey().get(), ref, op.getURI(), getRemoteConfigName()); } } } }
public void delete(String project, String ref, URIish uri, String remote) { ReplicateRefUpdate r = new ReplicateRefUpdate(); r.project = project; r.ref = ref; r.uri = uri.toASCIIString(); r.remote = remote; String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); try { logger.atFiner().log("DELETE %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); }
public void delete(String project, String ref, URIish uri, String remote) { ReplicateRefUpdate r = new ReplicateRefUpdate(); r.project = project; r.ref = ref; r.uri = uri.toASCIIString(); r.remote = remote; String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); try { logger.atFiner().log("DELETE %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); }
if (!running) { stateLog.warn("Replication plugin did not finish startup before event", state); return; } Project.NameKey project = new Project.NameKey(projectName); for (Destination cfg : config.getDestinations(FilterType.ALL)) { if (cfg.wouldPushProject(project) && cfg.wouldPushRef(refName)) { for (URIish uri : cfg.getURIs(project, null)) { replicationTasksStorage.persist( new ReplicateRefUpdate(projectName, refName, uri, cfg.getRemoteConfigName())); cfg.schedule(project, refName, uri, state); } } } state.markAllPushTasksScheduled();
private void firePendingTasks() { try { Set<String> tasksReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate t : replicationTasksStorage.list()) { String taskKey = String.format("%s:%s", t.project, t.ref); if (!tasksReplayed.contains(taskKey)) { repLog.info("Firing pending task {}", taskKey); onGitReferenceUpdated(t.project, t.ref); tasksReplayed.add(taskKey); } } } finally { replaying = false; }
private void firePendingEvents() { try { Set<String> tasksReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate t : replicationTasksStorage.list()) { String eventKey = String.format("%s:%s", t.project, t.ref); if (!eventsReplayed.contains(eventKey)) { repLog.info("Firing pending task {}", eventKey); onGitReferenceUpdated(t.project, t.ref); tasksReplayed.add(taskKey); } } } finally { replaying = false; }
public String persist(ReplicateRefUpdate r) { String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path file = refUpdates().resolve(eventKey); if (Files.exists(file)) { return eventKey; } try { logger.atFine().log("CREATE %s:%s => %s", project, ref, uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().log("Couldn't persist event %s", json, e); } return eventKey;
String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path file = refUpdates().resolve(eventKey); if (Files.exists(file)) { return eventKey; } try { logger.atFine().log("CREATE %s:%s => %s", project, ref, uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey;
public List<ReplicateRefUpdate> list() { ArrayList<ReplicateRefUpdate> result = new ArrayList<>(); try (DirectoryStream<Path> events = Files.newDirectoryStream(refUpdates())) { for (Path e : events) { if (Files.isRegularFile(e)) { String json = new String(Files.readAllBytes(e), UTF_8); result.add(GSON.fromJson(json, ReplicateRefUpdate.class)); } } } catch (IOException e) { logger.atSevere().withCause(e).log("Error when firing pending events"); } return result;
import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.junit.Test; @UseLocalDisk @TestPlugin( name = "replication", sysModule = "com.googlesource.gerrit.plugins.replication.ReplicationModule") public class ReplicationIT extends LightweightPluginDaemonTest { private static final int TEST_REPLICATION_DELAY = 2; private static final Duration TEST_TIMEMOUT = Duration.ofSeconds(TEST_REPLICATION_DELAY * 10); @Inject private SitePaths sitePaths; private Path pluginDataDir; private Path gitPath; private Path storagePath; private FileBasedConfig config; @Override public void setUpTestPlugin() throws Exception { config = new FileBasedConfig(sitePaths.etc_dir.resolve("replication.config").toFile(), FS.DETECTED); config.save(); gitPath = sitePaths.site_path.resolve("git"); super.setUpTestPlugin(); pluginDataDir = plugin.getSysInjector().getInstance(Key.get(Path.class, PluginData.class)); storagePath = pluginDataDir.resolve("ref-updates"); } @Test
e.printStackTrace(); return null; } } private void setReplicationDestination( String remoteName, String replicaSuffix, int replicationDelay) throws IOException { setReplicationDestination(remoteName, Arrays.asList(replicaSuffix), replicationDelay); } private void setReplicationDestination( String remoteName, List<String> replicaSuffixes, int replicationDelay) throws IOException { List<String> replicaUrls = replicaSuffixes.stream() .map(suffix -> gitPath.resolve("${name}" + suffix + ".git").toString()) .collect(toList()); config.setStringList("remote", remoteName, "url", replicaUrls); config.setInt("remote", remoteName, "replicationDelay", replicationDelay); config.save(); reloadConfig(); } private void waitUntil(Supplier<Boolean> waitCondition) throws InterruptedException { Stopwatch stopwatch = Stopwatch.createStarted(); while (!waitCondition.get() && stopwatch.elapsed().compareTo(TEST_TIMEMOUT) < 0) { TimeUnit.SECONDS.sleep(1); } } private void reloadConfig() { plugin.getSysInjector().getInstance(AutoReloadConfigDecorator.class).forceReload(); } }
private static class RefReplicationStatus { private final String project; private final String ref; private int nodesToReplicateCount; private int replicatedNodesCount; RefReplicationStatus(String project, String ref) { this.project = project; this.ref = ref; } public boolean allDone() { return replicatedNodesCount == nodesToReplicateCount; } } private final Table<String, String, RefReplicationStatus> statusByProjectRef; private int totalPushTasksCount; private int finishedPushTasksCount; ReplicationState(PushResultProcessing processing) { pushResultProcessing = processing; statusByProjectRef = HashBasedTable.create(); } public void increasePushTaskCount(String project, String ref) { countingLock.lock(); try { getRefStatus(project, ref).nodesToReplicateCount++; totalPushTasksCount++; } finally { countingLock.unlock(); } } public boolean hasPushTask() { return totalPushTasksCount != 0; } public void notifyRefReplicated( String project, String ref, URIish uri, RefPushResult status,
super(retryHelper); this.opFactory = opFactory; this.editUtil = editUtil; } @Override protected Response<Object> applyImpl( BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException, IOException { if (!isChangeDeletable(rsrc)) { throw new MethodNotAllowedException("delete not permitted"); } rsrc.permissions().check(ChangePermission.DELETE); try (BatchUpdate bu = updateFactory.create(rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) { Change.Id id = rsrc.getChange().getId(); bu.addOp(id, opFactory.create(id)); if (edit.isPresent()) { bu.addOp( id, new BatchUpdateOp() { @Override public boolean updateChange(ChangeContext ctx) throws Exception { editUtil.delete(edit.get()); return true; } }); } bu.execute(); } return Response.none(); } @Override
public Optional<Change> getUpdatedChange() { return Optional.ofNullable(updatedChange);
Project.NameKey key = new Project.NameKey(projectName); // Remove from the jgit cache cleanCache(key); FileUtils.deleteDirectory(gitDirectory); projectCache.remove(key); sendProjectDeletedEvent(projectName); return true; } catch (IOException e) { LOG.error("Cannot clean-up output Git directory " + gitDirectory); return false; } } private void cleanCache(Project.NameKey key) throws IOException { try(Repository repository = repoManager.openRepository(key)) { RepositoryCache.close(repository); } } private void sendProjectDeletedEvent(String projectName) { ProjectDeletedListener.Event event = new ProjectDeletedListener.Event() { @Override public String getProjectName() { return projectName; } @Override public NotifyHandling getNotify() { return NotifyHandling.NONE; } }; for (ProjectDeletedListener l : deletedListeners) { try { l.onProjectDeleted(event); } catch (RuntimeException e) { LOG.warn("Failure in ProjectDeletedListener", e); } } } }
public boolean rollback() { File gitDirectory = destinationDirectory; if (!gitDirectory.exists()) { return false; } try { String projectName = organisation + "/" + repository; Project.NameKey key = new Project.NameKey(projectName); cleanJGitCache(key); FileUtils.deleteDirectory(gitDirectory); projectCache.remove(key); sendProjectDeletedEvent(projectName); return true; } catch (IOException e) { LOG.error("Cannot clean-up output Git directory " + gitDirectory); return false; }
this.currentConfig = loadConfig(); this.currentConfigTs = getLastModified(currentConfig); this.replicationQueue = replicationQueue; } private static long getLastModified(ReplicationFileBasedConfig cfg) { return FileUtil.lastModified(cfg.getCfgPath()); } private ReplicationFileBasedConfig loadConfig() throws ConfigInvalidException, IOException { return new ReplicationFileBasedConfig(site, destinationFactory, pluginDataDir); } private synchronized boolean isAutoReload() { return currentConfig.getConfig().getBoolean("gerrit", "autoReload", false); } @Override public synchronized List<Destination> getDestinations(FilterType filterType) { reloadIfNeeded(); return currentConfig.getDestinations(filterType); } private void reloadIfNeeded() { reload(false); } @VisibleForTesting public void forceReload() { reload(true); } private void reload(boolean force) { if (force || isAutoReload()) { ReplicationQueue queue = replicationQueue.get(); long lastModified = getLastModified(currentConfig); try { if (force || (lastModified > currentConfigTs
public void configureServlets() { for (String p : POLYGERRIT_INDEX_PATHS) { // Skip XsrfCookieFilter for /, since that is already done in the GWT UI // path (UrlModule) if it is enabled. if (!(p.equals("/") && options.enableGwtUi())) { filter(p).through(XsrfCookieFilter.class); } } filter("/*").through(PolyGerritFilter.class);
public ReplicateRefUpdate(String project, String ref, URIish uri, String remote) { this.project = project; this.ref = ref; this.uri = uri.toASCIIString(); this.remote = remote;
public String persist(ReplicateRefUpdate r) { String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path file = refUpdates().resolve(eventKey); if (Files.exists(path)) { return eventKey; } try { logger.atFine().log("CREATE %s (%s)", path, r); Files.write(path, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey;
public String persist(ReplicateRefUpdate r) { String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path path = refUpdates().resolve(eventKey); if (Files.exists(path)) { return eventKey; } try { logger.atFine().log("CREATE %s (%s:%s => %s)", file, r.project, r.ref, r.uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey;
public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); Path file = refUpdates().resolve(taskKey); try { logger.atFine().log("DELETE %s (%s)", path, r); Files.delete(refUpdates().resolve(taskKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); }
public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); Path file = refUpdates().resolve(taskKey); try { logger.atFine().log("DELETE %s (%s)", path, r); Files.delete(refUpdates().resolve(taskKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); }
public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); Path path = refUpdates().resolve(taskKey); try { logger.atFine().log("DELETE %s (%s:%s => %s)", file, r.project, r.ref, r.uri); Files.delete(file); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); }
import static com.google.gerrit.gpg.testutil.TestKeys.validKeyWithExpiration; import static com.google.gerrit.gpg.testutil.TestKeys.validKeyWithSecondUserId; import static com.google.gerrit.gpg.testutil.TestKeys.validKeyWithoutExpiration; import static com.google.gerrit.server.StarredChangesUtil.DEFAULT_LABEL; import static com.google.gerrit.server.StarredChangesUtil.IGNORE_LABEL; import static com.google.gerrit.server.account.externalids.ExternalId.SCHEME_GPGKEY; import static com.google.gerrit.server.group.SystemGroupBackend.ANONYMOUS_USERS; import static com.google.gerrit.server.group.SystemGroupBackend.REGISTERED_USERS; import static com.google.gerrit.testutil.GerritJUnit.assertThrows; import static java.nio.charset.StandardCharsets.UTF_8; import static java.util.stream.Collectors.toList; import static java.util.stream.Collectors.toSet; import static org.eclipse.jgit.lib.Constants.OBJ_BLOB; import static org.junit.Assert.fail; import com.google.common.collect.FluentIterable; import com.google.common.collect.ImmutableList; import com.google.common.collect.ImmutableMap; import com.google.common.collect.ImmutableSet; import com.google.common.collect.ImmutableSetMultimap; import com.google.common.collect.Iterables; import com.google.common.io.BaseEncoding; import com.google.common.util.concurrent.AtomicLongMap; import com.google.gerrit.acceptance.AbstractDaemonTest;
} return fileConfig; }); } return ofInstance(config); } public static class Kafka { private final Map<EventTopic, String> eventTopics; private final String bootstrapServers; Kafka(Supplier<Config> config) { this.bootstrapServers = getString( config, KAFKA_SECTION, null, "bootstrapServers", DEFAULT_KAFKA_BOOTSTRAP_SERVERS); this.eventTopics = new HashMap<>(); for (EventTopic eventTopic : EventTopic.values()) { eventTopics.put( eventTopic, getString(config, KAFKA_SECTION, null, topicConfigKey, eventTopic.topic())); } } public String getTopicAlias(EventTopic topic) { return eventTopics.get(topic); } public String getBootstrapServers() { return bootstrapServers; } private static String getString( Supplier<Config> cfg, String section, String subsection, String name, String defaultValue) { String value = cfg.get().getString(section, subsection, name); if (!Strings.isNullOrEmpty(value)) { return value; }
reloadConfig(); waitForEmptyTasks(); Project.NameKey targetProject = createProject("projectreplica"); String newBranch = "refs/heads/mybranch"; String master = "refs/heads/master"; BranchInput input = new BranchInput(); input.revision = master; gApi.projects().name(project.get()).branch(newBranch).create(input); assertThat(listReplicationTasks("refs/heads/(mybranch|master)")).hasSize(2); try (Repository repo = repoManager.openRepository(targetProject); Repository sourceRepo = repoManager.openRepository(project)) { waitUntil(() -> checkedGetRef(repo, newBranch) != null); Ref masterRef = getRef(sourceRepo, master); Ref targetBranchRef = getRef(repo, newBranch); assertThat(targetBranchRef).isNotNull(); assertThat(targetBranchRef.getObjectId()).isEqualTo(masterRef.getObjectId()); } } @Test public void shouldReplicateNewBranchToTwoRemotes() throws Exception { Project.NameKey targetProject1 = createProject("projectreplica1"); Project.NameKey targetProject2 = createProject("projectreplica2");
Change updatedChange = op.merge(change, submitter, true, input, false); if (updatedChange.isMerged()) { return change; } logger.atWarning().log( "change %s of project %s unexpectedly had status %s after submit attempt", updatedChange.getId(), updatedChange.getProject(), updatedChange.getStatus()); throw new RestApiException( String.format( "change %s of project %s unexpectedly had status %s after submit attempt", updatedChange.getId(), updatedChange.getProject(), updatedChange.getStatus()); logger.atWarning().log(msg); throw new RestApiException(msg); } } /** * Returns a message describing what prevents the current change from being submitted - or null. * This method only considers parent changes, and changes in the same topic. The caller is * responsible for making sure the current change to be submitted can indeed be submitted * (permissions, submit rules, is not a WIP...) * * @param cd the change the user is currently looking at * @param cs set of changes to be submitted at once
config.save(); super.setUpTestPlugin(); pluginDataDir = plugin.getSysInjector().getInstance(Key.get(Path.class, PluginData.class)); storagePath = pluginDataDir.resolve("ref-updates"); } @Test public void shouldReplicateNewProject() throws Exception { setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Project.NameKey sourceProject = createProject("foo"); assertThat(listReplicationTasks("refs/meta/config")).hasSize(1); waitUntil(() -> projectExists(new Project.NameKey(sourceProject + "replica.git"))); ProjectInfo replicaProject = gApi.projects().name(sourceProject + "replica").get(); assertThat(replicaProject).isNotNull(); } @Test public void shouldReplicateNewChangeRef() throws Exception { Project.NameKey targetProject = createProject("projectreplica"); setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Result pushResult = createChange(); RevCommit sourceCommit = pushResult.getCommit();
} @Test public void shouldReplicateNewProject() throws Exception { setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Project.NameKey sourceProject = createProject("foo"); assertThat(listReplicationTasks("refs/meta/config")).hasSize(1); waitUntil(() -> projectExists(new Project.NameKey(sourceProject + "replica.git"))); ProjectInfo replicaProject = gApi.projects().name(sourceProject + "replica").get(); assertThat(replicaProject).isNotNull(); } @Test public void shouldReplicateNewChangeRef() throws Exception { Project.NameKey targetProject = createProject("projectreplica"); setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Result pushResult = createChange(); RevCommit sourceCommit = pushResult.getCommit(); String sourceRef = pushResult.getPatchSet().getRefName(); assertThat(listReplicationTasks("refs/changes/\\d*/\\d*/\\d*")).hasSize(1); try (Repository repo = repoManager.openRepository(targetProject)) {
private static final String CONFIG_FILE_PATH = "/data/local/tmp/"; private static final String CLOUD_PROPERTY_FILE = "cloud.properties"; private static boolean mIsCbInvoked = CALLBACK_NOT_INVOKED; private enum CloudAuth { SIGNUP, SIGNIN, SIGNOUT }; private enum LogLevel { INFO, ERROR, DEBUG }; private static Properties props; private static String filePath; private static String fileName; private static File file; public static CloudAuth mMethodName; public static void init(String fileDir) { props = new Properties(); ReadConfigPropFile.readConfigFile(CONFIG_FILE_PATH); file = new File(fileDir + CLOUD_PROPERTY_FILE); if (!file.exists()) { getAuthCode(); } } private static void getAuthCode() { Log.d(TAG, "getAuthCode IN"); GetAuthCode getContent = new GetAuthCode(); try {
private static final String CLOUD_PROPERTY_FILE = "cloud.properties"; private static boolean mIsCbInvoked = CALLBACK_NOT_INVOKED; private enum CloudAuth { SIGNUP, SIGNIN, SIGNOUT }; private enum LogLevel { INFO, ERROR, DEBUG }; private static Properties props; private static String filePath; private static String fileName; private static File file; public static CloudAuth mMethodName; public static void init(String fileDir) { props = new Properties(); ReadConfigPropFile.readConfigFile(CONFIG_FILE_PATH); file = new File(fileDir + CLOUD_PROPERTY_FILE); if (!file.exists()) { getAuthCode(); } } private static void getAuthCode() { Log.d(TAG, "getAuthCode IN"); GetAuthCode getContent = new GetAuthCode(); try { OcAccountManagerHelper.authCode = getContent.execute().get();
+ JUSTWORKS_SERVER_UNOWNED_CBOR_02 + " 1"; public static final String START_PRE_CONFIG_SERVER_01 = "./iotivity_pm_server " + PRECONFIG_SERVER_UNOWNED_CBOR_01 + " 3"; public static final String START_RE_SERVER = "./iotivity_re_server"; public static final String PROVISION_DB_FILE = "./Pdm.db"; public static final String DEVICE_PROP_CBOR_FILE = "./device_properties.dat"; private TestBroadCast mTestBroadCast; protected RIHelperCommon(IoTivityTc iotivityTcObj) { s_helperContext = iotivityTcObj.getInstrumentation().getTargetContext(); s_filePath = s_helperContext.getFilesDir().getPath(); s_sqLPath = s_helperContext.getFilesDir().getAbsolutePath() .replace(FILES, DATABASES) + File.separator; mTestBroadCast = new TestBroadCast(s_helperContext); } public boolean configClientServerPlatform() { PlatformConfig cfg = new PlatformConfig(s_helperContext, ServiceType.IN_PROC, ModeType.CLIENT_SERVER, "0.0.0.0", 0, QualityOfService.HIGH); OcPlatform.Configure(cfg);
* * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. ******************************************************************/ package org.iotivity.testcase; import android.util.Log; public class IoTivityLog{ public static void v(String tag, String format) { Log.v(tag, format); } public static void d(String tag, String format) { Log.d(tag, format); } public static void i(String tag, String format) { Log.i(tag, format); } public static void w(String tag, String format) { Log.w(tag, format); } public static void e(String tag, String format) { Log.e(tag, format); } }
* * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. ******************************************************************/ package org.iotivity.testcase; import java.util.logging.Logger; public class IoTivityLog{ public static void v(String tag, String format) { System.out.println(tag + " : " + format); } public static void d(String tag, String format) { System.out.println(tag + " : " + format); } public static void i(String tag, String format) { System.out.println(tag + " : " + format); } public static void w(String tag, String format) { System.out.println(tag + " : " + format); } public static void e(String tag, String format) {
public void testConfigureServerInProc_SRC_P() { try { PlatformConfig cfg = new PlatformConfig(ServiceType.IN_PROC, ModeType.SERVER, "0.0.0.0", 0, QualityOfService.HIGH); OcPlatform.Configure(cfg); } catch (Exception e) { e.printStackTrace(); fail("Exception occured"); }
import org.iotivity.base.QualityOfService; import org.iotivity.base.RequestHandlerFlag; import org.iotivity.base.RequestType; import org.iotivity.base.ResourceProperty; import org.iotivity.base.ServiceType; import org.iotivity.base.OcRepresentation; import org.iotivity.base.OcResource; import org.iotivity.base.OcResource.OnObserveListener; import org.iotivity.base.OcResourceHandle; import org.iotivity.testcase.IoTivityLog; import org.iotivity.testcase.IoTivityTc; import org.iotivity.test.ri.common.RIHelperCommon; public class RIHelper extends RIHelperCommon implements IRIConstants { private static RIHelper s_mRiHelperInstance = null; private final String LOG_TAG = this .getClass().getSimpleName(); private OcResourceHandle m_resourceHandle = null; public EnumSet<ResourceProperty> m_resourceProperty; public static final String TEMPERATURE_RESOURCE_QUERY = OcPlatform.WELL_KNOWN_QUERY + "?rt=" + RESOURCE_TYPE_TEMPERATURE; private OcRepresentation m_representation = null; // new OcRepresentation(); public int m_temp; public int m_hour; public static boolean s_isServerOk; public static String s_errorMsg;
* Map<String, String> queryParamsMap, * OnPostListener onPostListener, * QualityOfService qualityOfService) * @test_data 1. resourceUri "/test/ri/android/temperature" * 2. resourceTypeName "oic.r.temperature" * 3. resourceInterface DEFAULT_INTERFACE * 4. entityHandler entity handler * 5. resourcePropertySet indicates property of the resource * 6. representation representation to set * 7. queryParamsMap map with query paramter and value * 8. onPostListener event handler * 9. qualityOfService High * @pre_condition Configure platform for client server mode * @procedure 1. Perform registerResource() API * 2. Perform findResource() API with resource type in query * 3. Check if callback is called * 4. Check if temperature resource is found * 5. Perform post() API(with qos) on the found temperature resource * 6. Check if server can get the post request and send response correctly
public void onReceive(Context context, Intent intent) { Log.d(TAG, "BroadcastReceiver Invoked"); Log.d(TAG, "Recieved Braodcasted MSG : " + intent.getStringExtra("key")); if (mTcpClient != null) { mTcpClient.sendMessage(intent.getStringExtra("key")); } else { Log.e(TAG, "TCP Client is not initialized"); }
(byte) 0x66, (byte) 0x11, (byte) 0xa5, (byte) 0x84, (byte) 0x99, (byte) 0x8d, (byte) 0x0d, (byte) 0xbd, (byte) 0xb1, (byte) 0x54, (byte) 0xbb, (byte) 0xc5, (byte) 0x4f, (byte) 0xed, (byte) 0x86, (byte) 0x9a, (byte) 0x66, (byte) 0x11 }; PMConstants.mErrorMessage = PMConstants.EMPTY_STRING; mPMHelper.clearAll(); mPMHelper.stopServers(); mPMHelper.startSecuredServer(mPMHelper.START_JUSTWORKS_SERVER_01); mPMHelper.startSecuredServer(mPMHelper.START_JUSTWORKS_SERVER_02); PMHelper.delay(5); // create platform config mPMHelper.copyCborFromAsset(PMConstants.OIC_CLIENT_CBOR_DB_FILE); mPMHelper.configClientServerPlatform( PMConstants.OIC_CLIENT_CBOR_DB_FILE); mPMHelper.initOICStack(PMHelper.s_sqLPath, PMConstants.OIC_SQL_DB_FILE); } protected void tearDown() throws Exception { mPMHelper.stopServers(); mPMHelper.clearAll(); super.tearDown(); } /**
public static final String OIC_JWSERVER_CBOR_DB_FILE_2 = "oic_svr_db_server.dat"; public static final String OIC_DP_CLIENT_CBOR_DB_FILE = "oic_svr_db_client_directpairing.dat"; public static final String OIC_CLOUD_CLIENT = "cloud.dat"; public static final String OIC_SQL_DB_FILE = "Pdm.db"; public static final String OIC_MOT_SQL_DB_FILE = "MOT_Pdm.db"; public static final String SERVER_SQL_DB_FILE = "ServerPdm.db"; //Cloud Resource public static final String CERT_SERIAL_ONE = "1"; // ACL Related Resource public static final String DEFAULT_ROWNER_ID = "61646d69-6e44-6576-6963-655555494430"; public static final String DEFAULT_RESOURCES = "*"; public static final String HREF_RESOURCES_1A = "/a/device1a"; public static final String HREF_RESOURCES_1B = "/a/device1b"; public static final String HREF_RESOURCES_2A = "/a/device2a"; public static final String HREF_RESOURCES_2B = "/a/device2b";
try { m_resource.put(m_rep, qpMap, onPut); } catch (Exception e) { e.printStackTrace(); fail("Exception occured"); } } /** * @objective Test put function with negative basic way using null representation * @target put(OcRepresentation representation, *Map<String, String> queryParamsMap, *OnPutListener onPutListener) * @test_data 1. representation null * 2. queryParamsMap map with query paramter and value * 3. OnPutListener event handler * @pre_condition 1. configure platform * 2. construct resource object * @procedure Call put() API using resource * @post_condition None * @expected OcException should occur * @see void Configure(PlatformConfig platformConfig) * @see OcResource constructResourceObject( * String host, * String uri, * EnumSet<OcConnectivityType> connectivityTypeSet, * boolean isObservable, * List<String> resourceTypeList, * List<String> interfaceList) * @since 2016-09-05 **/
public void testConfigureServerNon_SRC_P() { try { PlatformConfig cfg = new PlatformConfig(ServiceType.IN_PROC, ModeType.SERVER, "0.0.0.0", 0, QualityOfService.LOW); OcPlatform.Configure(cfg); } catch (Exception e) { e.printStackTrace(); fail("Exception occured"); }
String DEVICE_TYPE_AC = "AirCondition"; String RESOURCE_URI_TEMPERATURE = "/test/ri/android/temperature"; String RESOURCE_TYPE_TEMPERATURE = "oic.r.temperature"; String RESOURCE_URI_LIGHT = "/a/light"; String RESOURCE_TYPE_LIGHT = "core.light"; String RESOURCE_URI_FAN = "/a/fan"; String RESOURCE_TYPE_FAN = "core.fan"; String HOST = "coap://192.168.1.2:5000"; int INT_ZERO = 0; int INT_ONE = 1; int INT_TWO = 2; int INT_MINUS_ONE = -1; int CALLBACK_WAIT_DEFAULT = 5; int CALLBACK_WAIT_MAX = 10; int CALLBACK_WAIT_MIN = 1; int SUCCESS_RESPONSE = 0; int COAP_RESPONSE_CODE_SUCCESS = 205; int COAP_RESPONSE_CODE_CREATED = 201; int COAP_RESPONSE_CODE_DELETED = 202;
public static RIHelper getInstance(IoTivityTc iotivityTcObj) { new OcRepresentation(); Lock mutex = new ReentrantLock(); if (s_mRiHelperInstance == null) { mutex.lock(); if (s_mRiHelperInstance == null) { IoTivityLog.i("RIHelper", "Inside Helper"); s_mRiHelperInstance = new RIHelper(iotivityTcObj); } mutex.unlock(); } return s_mRiHelperInstance;
* //****************************************************************** * // * // Copyright 2018 Intel Corporation All Rights Reserved. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import org.iotivity.base.OcException;
* //****************************************************************** * // * // Copyright 2018 Intel Corporation All Rights Reserved. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import org.iotivity.base.OcException;
* //****************************************************************** * // * // Copyright 2016-2018 Intel Corporation All Rights Reserved. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import android.graphics.Bitmap;
* //****************************************************************** * // * // Copyright 2016-2018 Intel Corporation All Rights Reserved. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import org.iotivity.base.OcException;
/** * MediaControl * * This class is used by UpnpAvClientActivity to create an object representation of a remote media control resource * and update the values depending on the server response */ public class MediaControl extends Service { public static final String OIC_TYPE_MEDIA_CONTROL = "oic.r.media.control"; public static final String OCF_OIC_URI_PREFIX_MEDIA_CONTROL = "/ocf/mediaControl/"; public static final String UPNP_OIC_URI_PREFIX_MEDIA_CONTROL = "/upnp/mediaControl/"; public static final String STATE_KEY = "playState"; public static final boolean DEFAULT_STATE = false; public static final String SPEED_KEY = "mediaSpeed"; public static final double DEFAULT_SPEED = 1.0; public static final String LOCATION_KEY = "mediaLocation"; public static final String DEFAULT_LOCATION = "0"; public static final String LAST_ACTION_KEY = "lastAction"; public static final String DEFAULT_LAST_ACTION = "stop"; public static final String ACTIONS_KEY = "actions"; private boolean mPlayState;
* //****************************************************************** * // * // Copyright 2016-2018 Intel Corporation All Rights Reserved. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import android.app.Activity;
* limitations under the License. * *-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import org.iotivity.base.OcException; import org.iotivity.base.OcPlatform; import org.iotivity.base.PayloadType; /** * Light * * This class represents a light resource */ public class Light { static public final String RESOURCE_TYPE = "oic.d.light"; static public final String DEVICE_RESOURCE_TYPE = "oic.wk.d"; private Switch switchRes; private Brightness brightnessRes; private String deviceName; public Light(String name, String uuid, boolean powerOn, int brightness, LightControlPanel ui) { deviceName = name; switchRes = new Switch(uuid); switchRes.setValue(powerOn); switchRes.addObserver(ui); ui.addObserver(switchRes); OcfLightServer.msg("Created switch resource: " + switchRes); brightnessRes = new Brightness(uuid); brightnessRes.setBrightness(brightness); brightnessRes.addObserver(ui); ui.addObserver(brightnessRes);
public void update(int brightness) { setBrightness(brightness); notifyObservers(null);
public void testUri() { OCResource r = new OCResource(); assertNotNull(r); r.setUri("/foo/bar"); assertEquals("/foo/bar", r.getUri()); } @Test public void testTypes() { OCResource r = new OCResource(); assertNotNull(r); //TODO properly encode/decode the OCResource oc_string_array_t types. //r.setTypes(value); // failure purposely done till the setTypes/getProperties methods are updated with non SWIG type values. fail("Not yet implemented"); } @Test public void testInterfaces() { OCResource r = new OCResource(); assertNotNull(r); r.setInterfaces(OCInterfaceMask.RW); assertEquals(OCInterfaceMask.RW, r.getInterfaces()); } @Test public void testDefaultInterface() { OCResource r = new OCResource(); assertNotNull(r); r.setDefaultInterface(OCInterfaceMask.BASELINE); assertEquals(OCInterfaceMask.BASELINE, r.getDefaultInterface()); } @Test public void testProperties(){ OCResource r = new OCResource(); assertNotNull(r);
} else if (response.getCode() == OCStatus.OC_STATUS_CREATED) { System.out.println("\tPUT response: CREATED"); } else { System.out.println("\tPUT response code " + response.getCode().toString() + "(" + response.getCode() + ")"); } ObserveLightResponseHandler observerLight = new ObserveLightResponseHandler(); OCMain.doObserve(Light.server_uri, Light.server, null, OCQos.LOW_QOS, observerLight); StopObserveTriggerHandler stopObserve = new StopObserveTriggerHandler(); OCMain.setDelayedCallback(stopObserve, 30); System.out.println("Sent OBSERVE request");
private void eventLoop() { while (!quit) { long nextEvent = OCMain.mainPoll(); lock.lock(); try { if (nextEvent == 0) { cv.await(); } else { long now = OCClock.clockTime(); // nextEvent and now are in microseconds long timeToWait = (nextEvent - now) * 1000; cv.awaitNanos(timeToWait); } } catch (InterruptedException e) { Log.d(TAG, e.getMessage()); } finally { lock.unlock(); } }
public int initialize() { Log.d(TAG, "inside MyInitHandler.initialize()"); int ret = OCMain.initPlatform("Android"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "Kishen's Android Phone", "ocf.1.0.0", "ocf.res.1.0.0"); return ret;
public void testValueObject() { OCMain.repNewBuffer(1024); /* * { * "my_object": { * "a": 1, * "b": false, * "c": "three" * } * } */ CborEncoder root = OCMain.repBeginRootObject(); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetInt(root, "a", 1); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetInt(myObject, "a", 1); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetBoolean(myObject, "b", false); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetTextString(myObject, "c", "three"); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repCloseObject(root, myObject); OCMain.repEndRootObject(); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetPool(new OCMemoryBuffer()); OCRepresentation rep = OCMain.repGetOCRepresentaionFromRootObject(); assertNotNull(rep); OCValue v = new OCValue(); assertNotNull(v);
public int initialize() { System.out.println("inside ObtInitHandler.initilize()"); int ret = OCMain.initPlatform("OCF"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "OBT", "ocf.1.0.0", "ocf.res.1.0.0"); return ret;
System.out.println("################################################"); System.out.println("\nSelect option: "); } private static void discoverUnownedDevices() { System.out.println("Discovering un-owned devices"); appSyncLock.lock(); if ( 0 > OCObt.discoverUnownedDevices(unownedDeviceHandler)) { System.err.println("ERROR discovering un-owned Devices."); } appSyncLock.unlock(); } private static void discoverOwnedDevices() { appSyncLock.lock(); if (0 > OCObt.discoverOwnedDevices(ownedDeviceHandler)) { System.err.println("ERROR discovering owned Devices."); } appSyncLock.unlock(); } public static void main(String[] args) { quit = false; mainThread = Thread.currentThread(); Runtime.getRuntime().addShutdownHook(shutdownHook); String osName = System.getProperty("os.name"); boolean isLinux = (osName != null) && osName.toLowerCase().contains("linux"); System.out.println("OS Name = " + osName + ", isLinux = " + isLinux); String creds_path = "./onboarding_tool_creds/";
break; case 3: OCObt.aceResourceSetWc(res, OCAceWildcard.OC_ACE_WC_ALL_NON_DISCOVERABLE); break; default: break; } } } System.out.print("Enter number of resource types [0-None]: "); c = scanner.nextInt(); if (c > 0 && c <= MAX_NUM_RT) { OCObt.aceResoruceSetNumRt(res, c); int j = 0; while (j < c) { System.out.print("Enter resource type [" + (j + 1) + "]: "); String rt = scanner.next(); if (rt.length() > 127) { rt = rt.substring(0, 127); } OCObt.aceResoruceBindRt(res, rt); j++; } } System.out.print("Enter number of interfaces [0-None] : "); c = scanner.nextInt(); if (c > 0 && c <= 7) { int j = 0; while (j < c) { int k; System.out.println("\n[1]: oic.if.baseline");
public int initialize() { System.out.println("inside ObtInitHandler.initilize()"); int ret = OCMain.initPlatform("OCF"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "OBT", "ocf.1.0.0", "ocf.res.1.0.0"); return ret;
public void handler(OCUuid uuid, int status, Object userData) { if (status >= 0) { System.out.println("\nSuccessfully performed hard RESET to device " + OCUuidUtil.uuidToString(uuid)); } else { System.out.println("\nERROR performing hard RESET to device " + OCUuidUtil.uuidToString(uuid)); }
private void eventLoop() { while (!quit) { long nextEvent = OCMain.mainPoll(); lock.lock(); try { if (nextEvent == 0) { cv.await(); } else { long now = OCClock.clockTime(); long timeToWait = (NANOS_PER_SECOND / OCClock.OC_CLOCK_SECOND) * (nextEvent - now); cv.awaitNanos(timeToWait); } } catch (InterruptedException e) { Log.d(TAG, e.getMessage()); } finally { lock.unlock(); } }
public void handler(OCRequest request, int interfaces) { Log.d(TAG, "inside Put Light Request Handler"); new PostLightRequestHandler(activity, light).handler(request, interfaces);
OCMain.resourceSetRequestHandler(resource, OCMethod.OC_POST, new PostLightRequestHandler(activity, light)); OCMain.addResource(resource); } @Override public void requestEntry() { Log.d(TAG, "inside MyInitHandler.requestEntry()"); } @Override public void signalEventLoop() { Log.d(TAG, "inside MyInitHandler.signalEventLoop()"); activity.lock.lock(); try { activity.cv.signalAll(); } finally { activity.lock.unlock(); } } }
String creds_path = "./simpleserver_creds/"; java.io.File directory = new java.io.File(creds_path); if (!directory.exists()) { directory.mkdir(); } System.out.println("Storage Config PATH : " + directory.getPath()); if (0 != OCStorage.storageConfig(directory.getPath())) { System.err.println("Failed to setup Storage Config."); } // Note: If using a factory presets handler, // the factory presets handler must be set prior to calling systemInit(). // The systemInit() function will cause the factory presets handler to // be called if it is set. OcUtils.setFactoryPresetsHandler(new FactoryPresetsHandler()); MyInitHandler handler = new MyInitHandler(platform); platform.systemInit(handler); try { Thread.sleep(Long.MAX_VALUE); } catch (InterruptedException e) { System.err.println(e); } System.exit(0);
if (!directory.exists()) { directory.mkdir(); } System.out.println("Storage Config PATH : " + directory.getPath()); if (0 != OCStorage.storageConfig(directory.getPath())) { System.err.println("Failed to setup Storage Config."); } // Note: If using a factory presets handler, // the factory presets handler must be set prior to calling systemInit(). // The systemInit() function will cause the factory presets handler to // be called if it is set. OcUtils.setFactoryPresetsHandler(new FactoryPresetsHandler()); MyInitHandler handler = new MyInitHandler(platform); platform.systemInit(handler); try { Thread.sleep(Long.MAX_VALUE); } catch (InterruptedException e) { System.err.println(e); } System.exit(0);
public void handler(OCClientResponse response) { System.out.println("Get Owned Device Name Handler:"); OCRepresentation rep = response.getPayload(); String n = null; String di = null; while (rep != null) { switch (rep.getType()) { case OC_REP_STRING: if ("n".equals(rep.getName())) { n = rep.getValue().getString(); } if ("di".equals(rep.getName())) { di = rep.getValue().getString(); } break; default: break; } rep = rep.getNext(); } if (di != null) { ObtMain.ownedDevices.add(new OCFDeviceInfo(OCUuidUtil.stringToUuid(di), n)); }
public void handler(OCClientResponse response) { System.out.println("Get Unowned Device Name Handler:"); OCRepresentation rep = response.getPayload(); String n = null; String di = null; while (rep != null) { switch (rep.getType()) { case OC_REP_STRING: if ("n".equals(rep.getName())) { n = rep.getValue().getString(); } if ("di".equals(rep.getName())) { di = rep.getValue().getString(); } break; default: break; } rep = rep.getNext(); } if (di != null) { ObtMain.unownedDevices.add(new OCFDeviceInfo(OCUuidUtil.stringToUuid(di), n)); }
} // for unit testing only static public OcRepresentation createOcRepresentaionFromRoot() throws OcCborException { OCRep.clearCborErrno(); OCRepresentation nativeRep = OCRep.getOCRepresentaionFromRootObject(); if ((nativeRep != null) && (OCRep.getCborErrno() == 0)) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to create OcRepresentation from root object"); } public String getKey() { OCRep.clearCborErrno(); return nativeRepresentation.getName(); } public boolean getBoolean() throws OcCborException { Boolean returnValue = getValue().getBool(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean"); } public Long getLong() throws OcCborException { Long returnValue = getValue().getInteger(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get long"); } public Double getDouble() throws OcCborException { Double returnValue = getValue().getDouble();
return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to create OcRepresentation from root object"); } public String getKey() { OCRep.clearCborErrno(); return nativeRepresentation.getName(); } public Boolean getBoolean() throws OcCborException { Boolean returnValue = getValue().getBool(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean"); } public long getLong() throws OcCborException { Long returnValue = getValue().getInteger(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get long"); } public Double getDouble() throws OcCborException { Double returnValue = getValue().getDouble(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get double"); } public String getString() throws OcCborException { String returnValue = getValue().getString(); if (returnValue != null) { return returnValue; }
} public Boolean getBoolean() throws OcCborException { Boolean returnValue = getValue().getBool(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean"); } public Long getLong() throws OcCborException { Long returnValue = getValue().getInteger(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get long"); } public double getDouble() throws OcCborException { Double returnValue = getValue().getDouble(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get double"); } public String getString() throws OcCborException { String returnValue = getValue().getString(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get string"); } public OCArray getArray() throws OcCborException { OCArray returnValue = getValue().getArray(); if (returnValue != null) {
OCRepresentation nativeRep = getValue().getObject(); if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object"); } public OcRepresentation getObjectArray() throws OcCborException { OCRepresentation nativeRep = getValue().getObjectArray(); if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object array"); } public OCValue getValue() throws OcCborException { OCValue returnValue = nativeRepresentation.getValue(); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get value"); } public Boolean getBoolean(String key) throws OcCborException { OCRep.clearCborErrno(); Boolean returnValue = OCRep.getBoolean(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get boolean for key " + key);
if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object array"); } public OCValue getValue() throws OcCborException { OCRep.clearCborErrno(); OCValue returnValue = nativeRepresentation.getValue(); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get value"); } public boolean getBoolean(String key) throws OcCborException { Boolean returnValue = OCRep.getBoolean(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); } public Long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); Long returnValue = OCRep.getLong(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; }
return returnValue; } throw new OcCborException("Failed to get value"); } public Boolean getBoolean(String key) throws OcCborException { OCRep.clearCborErrno(); Boolean returnValue = OCRep.getBoolean(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); } public long getLong(String key) throws OcCborException { Long returnValue = OCRep.getLong(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get long for key " + key); } public Double getDouble(String key) throws OcCborException { OCRep.clearCborErrno(); Double returnValue = OCRep.getDouble(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; }
return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); } public Long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); Long returnValue = OCRep.getLong(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get long for key " + key); } public double getDouble(String key) throws OcCborException { Double returnValue = OCRep.getDouble(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get double for key " + key); } public String getString(String key) throws OcCborException { OCRep.clearCborErrno(); String returnValue = OCRep.getString(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; }
static public OcRepresentation createOcRepresentaionFromRoot() throws OcCborException { OCRep.clearCborErrno(); OCRepresentation nativeRep = OCRep.getOCRepresentaionFromRootObject(); if ((nativeRep != null) && (OCRep.getCborErrno() == 0)) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to create OcRepresentation from root object");
break; case R.id.radio_recovery: mRebootMode = 2; Settings.System.putInt(mContext.getContentResolver(), Settings.System.STATUS_BAR_LAST_NOTIFICATION_STYLE, mRebootMode); mTileMode = 2; refreshState(); break; case R.id.radio_bootloader: mRebootMode = 3; Settings.System.putInt(mContext.getContentResolver(), Settings.System.STATUS_BAR_LAST_NOTIFICATION_STYLE, mRebootMode); mTileMode = 2; refreshState(); break; default: break; } refreshState();
public void update() { int showNavBar = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_SHOW, -1, mCurrentUserId); if (showNavBar != -1){ boolean showNavBarBool = showNavBar == 1; if (showNavBarBool != mShowNavBar){ updateNavigationBar(); } } mRecentsStyle = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_RECENTS, 0, mCurrentUserId); mOmniSwitchRecents = mRecentsStyle == 1; mLongPressOnAppSwitchBehavior = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.BUTTON_LONG_PRESS_RECENTS, 0, mCurrentUserId); if (mStatusBarWindow != null) { mStatusBarWindow.updateSettings(); } if (mNavigationBar != null) { mNavigationBar.setRecentsOptions(mRecentsStyle, mLongPressOnAppSwitchBehavior); } if (mStatusBarWindowManager != null) {
public void update() { int showNavBar = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_SHOW, -1, mCurrentUserId); int qsQuickPulldownValue = Settings.System.getInt( mContext.getContentResolver(), Settings.System.STATUS_BAR_QUICK_QS_PULLDOWN, 0); if (showNavBar != -1){ boolean showNavBarBool = showNavBar == 1; if (showNavBarBool != mShowNavBar){ updateNavigationBar(); } } mRecentsStyle = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_RECENTS, 0, mCurrentUserId); mOmniSwitchRecents = mRecentsStyle == 1; mLongPressOnAppSwitchBehavior = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.BUTTON_LONG_PRESS_RECENTS, 0, mCurrentUserId); if (mStatusBarWindow != null) { mStatusBarWindow.updateSettings(); } if (mNavigationBar != null) { mNavigationBar.setRecentsOptions(mRecentsStyle, mLongPressOnAppSwitchBehavior); }
public void onBindViewHolder(PreferenceViewHolder holder) { super.onBindViewHolder(holder); LinearLayout linearLayout = (LinearLayout) holder.findViewById(R.id.selected_apps); if (linearLayout.getChildCount() > 0) linearLayout.removeAllViews(); for (String value : mValues) { try { View v = mInflater.inflate(R.layout.app_grid_item, null); ComponentName componentName = ComponentName.unflattenFromString(value); Drawable icon = mPm.getActivityIcon(componentName); v.setImageDrawable(icon); v.setPadding(0, 0, 15, 0); v.setScaleType(ImageView.ScaleType.CENTER_CROP); linearLayout.addView(v); } catch (PackageManager.NameNotFoundException e) { Log.e(TAG, "Set app icon", e); } }
public void onKeyguardShowingChanged() { mShowIndicator = Settings.System.getIntForUser(mContext.getContentResolver(), Settings.System.HIDE_LOCKSCREEN_INDICATOR_DISPLAY, 0, UserHandle.USER_CURRENT) == 0; updateLeftAffordance(); updateRightAffordance(); inflateCameraPreview(); mIndicationController.setVisibleOverwrite(mShowIndicator);
private void updateSettings() { int mQsBackGroundAlpha = Settings.System.getIntForUser(getContext().getContentResolver(), Settings.System.QS_PANEL_BG_ALPHA, 221, UserHandle.USER_CURRENT); mQsBackGround.setAlpha(mQsBackGroundAlpha); setBackground(mQsBackGround);
mMusicActive.setOnPreferenceChangeListener(this); mAutorun = (SwitchPreference) findPreference(EVENT_AUTORUN_SINGLE); mAutorun.setChecked(getPrefs().getBoolean(EventServiceSettings.EVENT_AUTORUN_SINGLE, true)); mAutorun.setOnPreferenceChangeListener(this); mChooserTimeout = (SeekBarPreference) findPreference(APP_CHOOSER_TIMEOUT); mChooserTimeout.setValue(getPrefs().getInt(EventServiceSettings.APP_CHOOSER_TIMEOUT, 15)); mChooserTimeout.setOnPreferenceChangeListener(this); boolean locationDisabled = Settings.Secure.getInt(getActivity().getContentResolver(), Settings.Secure.LOCATION_MODE, -1) == 0; mDisableWifi = (SeekBarPreference) findPreference(DISABLE_WIFI_THRESHOLD); mDisableWifi.setValue(getPrefs().getInt(EventServiceSettings.DISABLE_WIFI_THRESHOLD, 0)); mDisableWifi.setOnPreferenceChangeListener(this); mDisableWifi.setEnabled(!locationDisabled); homeWifi = findPreference(HOME_WIFI_PREFERENCE_SCREEN); homeWifi.setEnabled(!locationDisabled); workWifi = findPreference(WORK_WIFI_PREFERENCE_SCREEN); workWifi.setEnabled(!locationDisabled); if (locationDisabled){ mDisableWifi.setSummary(R.string.wifi_location_disabled); homeWifi.setSummary(R.string.wifi_location_disabled);
public void onReceive(Context context, Intent intent) { String action = intent.getAction(); mWakeLock.acquire(); try { if (DEBUG) Log.d(TAG, "onReceive " + action); boolean disableIfMusicActive = getPrefs(context).getBoolean(EventServiceSettings.EVENT_MUSIC_ACTIVE, true); boolean autoRun = getPrefs(context).getBoolean(EventServiceSettings.EVENT_AUTORUN_SINGLE, true); boolean closeApp = getPrefs(context).getBoolean(EventServiceSettings.EVENT_DISCONNECT_HEADSET_OR_A2DP, false); switch (action) { case BluetoothAdapter.ACTION_STATE_CHANGED: if (intent.getIntExtra(BluetoothAdapter.EXTRA_STATE, -1) == BluetoothAdapter.STATE_OFF) { mA2DPConnected = false; } break; case BluetoothA2dp.ACTION_CONNECTION_STATE_CHANGED: int state = intent.getIntExtra(BluetoothProfile.EXTRA_STATE, BluetoothProfile.STATE_CONNECTED); if (state == BluetoothProfile.STATE_CONNECTED && !mA2DPConnected) { mA2DPConnected = true; if (DEBUG) Log.d(TAG, "BluetoothProfile.STATE_CONNECTED = true");
private static final int KEY_MASK_BACK = 0x02; private static final int KEY_MASK_MENU = 0x04; private static final int KEY_MASK_ASSIST = 0x08; private static final int KEY_MASK_APP_SWITCH = 0x10; private CheckBoxPreference mVolumeWake; // private CheckBoxPreference mVolumeMusicControl; private CheckBoxPreference mSwapVolumeButtons; // private ListPreference mVolumeKeyCursorControl; private SwitchPreference mEnableCustomBindings; private ListPreference mBackPressAction; private ListPreference mBackLongPressAction; private ListPreference mHomePressAction; private ListPreference mHomeLongPressAction; private ListPreference mHomeDoubleTapAction; private ListPreference mMenuPressAction; private ListPreference mMenuLongPressAction; private ListPreference mAssistPressAction; private ListPreference mAssistLongPressAction; private ListPreference mAppSwitchPressAction; private ListPreference mAppSwitchLongPressAction; private Map<String, Integer> mKeySettings = new HashMap<String, Integer>(); // private ListPreference mVolumeDefault; // private CheckBoxPreference mHeadsetHookLaunchVoice; // private CheckBoxPreference mVirtualKeyHapticFeedback; // private CheckBoxPreference mForceShowOverflowMenu;
mGestureButtonHandler.sendEmptyMessageDelayed(MSG_SEND_SWITCH_KEY, (long) GESTURE_KEY_DISTANCE_TIMEOUT); } } mLastX = rawX; mLastY = rawY; break; } else if (mLongClick && mPreparedKeycode == 3) { mGestureButtonHandler.removeMessages(MSG_SEND_SWITCH_KEY); mGestureButtonHandler.sendEmptyMessageDelayed(MSG_SEND_SWITCH_KEY, (long) GESTURE_KEY_DISTANCE_TIMEOUT); mPreparedKeycode = 0; mLongClick = false; } break; case MotionEvent.ACTION_CANCEL: break; default: break; } //mSwipeStartFromEdge = false; //mSwipeLongFireable = false; } }
/** * The animation property used for the icon when its isolation ends. * This animates the translation back to the right position. */ private static final AnimationProperties UNISOLATION_PROPERTY = new AnimationProperties() { private AnimationFilter mAnimationFilter = new AnimationFilter().animateX(); @Override public AnimationFilter getAnimationFilter() { return mAnimationFilter; } }.setDuration(CONTENT_FADE_DURATION); private void initDimens() { public final int MAX_VISIBLE_ICONS_WHEN_DARK = getResources().getInteger(R.integer.config_maxVisibleNotificationIconsWhenDark); public final int MAX_STATIC_ICONS = getResources().getInteger(R.integer.config_maxVisibleNotificationIcons); private static final int MAX_DOTS = 1; private boolean mIsStaticLayout = true; private final HashMap<View, IconState> mIconStates = new HashMap<>(); private int mDotPadding; private int mMaxVisibleIconsWhenDark; private int mMaxStaticIcons; private int mStaticDotRadius; private int mStaticDotDiameter; private int mOverflowWidth; private int mActualLayoutWidth = NO_VALUE; private float mActualPaddingEnd = NO_VALUE; private float mActualPaddingStart = NO_VALUE; private boolean mDark;
* This animates the translation back to the right position. */ private static final AnimationProperties UNISOLATION_PROPERTY = new AnimationProperties() { private AnimationFilter mAnimationFilter = new AnimationFilter().animateX(); @Override public AnimationFilter getAnimationFilter() { return mAnimationFilter; } }.setDuration(CONTENT_FADE_DURATION); //public static final int MAX_VISIBLE_ICONS_WHEN_DARK = 5; //public static final int MAX_STATIC_ICONS = 4; private static final int MAX_DOTS = 1; private boolean mIsStaticLayout = true; private final HashMap<View, IconState> mIconStates = new HashMap<>(); private int mDotPadding; private int mStaticDotRadius; private int mStaticDotDiameter; private int mOverflowWidth; private int mActualLayoutWidth = NO_VALUE; private float mActualPaddingEnd = NO_VALUE; private float mActualPaddingStart = NO_VALUE; private boolean mDark; private boolean mChangingViewPositions; private int mAddAnimationStartIndex = -1;
public int MAX_VISIBLE_ICONS_WHEN_DARK = 5; public int MAX_STATIC_ICONS = 4; private static final int MAX_DOTS = 1;
toastText = com.android.internal.R.string.volume_dialog_ringer_guidance_silent_no_media; break; case VOLUME_HUSH_VIBRATE: effect = VibrationEffect.get(VibrationEffect.EFFECT_HEAVY_CLICK); ringerMode = AudioManager.RINGER_MODE_VIBRATE; toastText = com.android.internal.R.string.volume_dialog_ringer_guidance_vibrate; break; } maybeVibrate(effect); setRingerModeInternal(ringerMode, reason); // Use the SystemUI context, so the toast gets themed properly. Toast.makeText(mSysUiContext, toastText, Toast.LENGTH_SHORT).show();
boolean result = false; try { logger.info("provisionONT begin"); AddOntMessage request = AddOntMessage.newBuilder() .setCLLI(clli) .setPortNumber(portNumber) .setSlotNumber(slotNumber) .setOntNumber(ontNumber) .setSerialNumber(serialNumber) .build(); AddOntReturn response = blockingStub.provisionOnt(request); result = response.getSuccess(); log.info("provisionONT with device id : {} success : {}" + serialNumber, result); } catch (RuntimeException e) { logger.log(Level.WARNING, "provisionONT RPC failed", e); } return result;
private static final Logger logger = Logger.getLogger(AbstractOLTServer.class.getName()); @Override public void echo(EchoMessage request, StreamObserver<EchoReplyMessage> responseObserver) { } @Override public void createChassis(AddChassisMessage request, StreamObserver<AddChassisReturn> responseObserver) { AddChassisReturn response = AddChassisReturn.newBuilder() .setDeviceID(request.getCLLI()) .build(); responseObserver.onNext(response); responseObserver.onCompleted(); log.info("createChassis with clli : {}" , request.getCLLI()); } @Override public void createOLTChassis(AddOLTChassisMessage request, StreamObserver<AddOLTChassisReturn> responseObserver) { AddOLTChassisReturn response = AddOLTChassisReturn.newBuilder() .setDeviceID(UUID.randomUUID().toString()) .setChassisDeviceID(request.getCLLI()).build(); responseObserver.onNext(response); responseObserver.onCompleted(); logger.info("createOLTChassis with clli : " + request.getCLLI()); } @Override public void provisionOnt(AddOntMessage request, StreamObserver<AddOntReturn> responseObserver) { AddOntReturn response = AddOntReturn.newBuilder().setSuccess(true).build();
public void removeSubscriber(ConnectPoint port) { AccessDeviceData olt = oltData.get(port.deviceId()); if (olt == null) { log.warn("No data found for OLT device {}", port.deviceId()); return; } // Get the uplink port Port uplinkPort = getUplinkPort(deviceService.getDevice(port.deviceId())); if (uplinkPort == null) { log.warn("No uplink port found for OLT device {}", port.deviceId()); return; } if (enableDhcpIgmpOnProvisioning) { processDhcpFilteringObjectives(olt.deviceId(), port.port(), false); } unprovisionSubscriber(olt.deviceId(), olt.uplink(), port.port(), subscriberVlan, olt.vlan(), olt.defaultVlan()); if (enableDhcpIgmpOnProvisioning) { processIgmpFilteringObjectives(olt.deviceId(), port.port(), false); }
for (FunctionalExchange anExchange : getAvailableFunctionalExchangesToInsert(functionView)) { AbstractFunction targetFunction = null; if (EcoreUtil.isAncestor(function, anExchange.getSource()) && anExchange.getTarget().eContainer() instanceof AbstractFunction) { targetFunction = (AbstractFunction) anExchange.getTarget().eContainer(); } else if (anExchange.getSource().eContainer() instanceof AbstractFunction) { targetFunction = (AbstractFunction) anExchange.getSource().eContainer(); } DNodeContainer visibleFunctionInDiagram = getDisplayedFunctionContainer(targetFunction, functionContainersInDiagram); if (visibleFunctionInDiagram != null) { if (isValidCreationCategoryBetweenViews(anExchange, functionView, visibleFunctionInDiagram)) { targetFunction = (AbstractFunction) visibleFunctionInDiagram.getTarget(); } else { targetFunction = null; } } if (targetFunction != null) { for (ExchangeCategory aCategory : anExchange.getCategories()) { returnedMap.put(aCategory, targetFunction); } } } return returnedMap; }
import org.polarsys.capella.core.model.handler.command.CapellaResourceHelper; /** * An {@link ECrossReferenceAdapter} that only takes capella resources into account. */ public class CapellaECrossReferenceAdapter extends SiriusCrossReferenceAdapter { class CapellaInverseCrossReferencer extends InverseCrossReferencer { /** * Generated serial UID. */ private static final long serialVersionUID = -3473829340961544993L; @Override protected void addProxy(EObject proxy, EObject context) { // Do nothing to avoid keeping EObjects turn into proxies during the whole application life. } /** * {@inheritDoc} */ @Override protected boolean resolve() { return CapellaECrossReferenceAdapter.this.resolve(); } WeakReference<EditingDomain> _editingDomain; public CapellaECrossReferenceAdapter(EditingDomain editingDomain, Session session, ResourceSet set) { super(set, (DAnalysisSessionImpl) session); _editingDomain = new WeakReference<EditingDomain>(editingDomain); } /** * Adapt all references of specified object against the inverse cross referencer.<br>
private static final String MIGRATED_FITLER_EXT = ".filter"; private static final String FRAGMENT_SEPARATOR = "\\@"; private static final String FILTER_SEPARATOR = "\\'"; private static final String FRAGMENT_FILTER_KEY = "filters"; private static final String PLUGIN_TYPE = "plugin"; private static final String VALID_PLUGIN = "org.polarsys.capella.core.sirius.analysis"; private static final String DESCRIPTION_TYPE = "description"; private Map<DiagramDescription, Set<String>> validFilterNames; private static Map<String, String> filterNameExceptions; private Map<DiagramDescription, Set<String>> validFilterNames; public FilterMigrationContribution() { validFilterNames = new HashMap<>(); filterNameExceptions = new HashMap<>(); filterNameExceptions.put("ShowEIExchangeContext", "show.ei.exchange.context.filter"); filterNameExceptions.put("CEParam", "show.ce.param.filter"); filterNameExceptions.put("CEEIParam", "show.ce.ei.param.filter"); filterNameExceptions.put("ShowFEExchangeContex", "show.fe.exchange.context.filter"); filterNameExceptions.put("ShowCEExchangeContext", "show.ce.exchange.context.filter"); } @Override
import org.polarsys.capella.core.model.helpers.BlockArchitectureExt; import org.polarsys.capella.core.model.helpers.ComponentExt; import org.polarsys.capella.core.ui.properties.fields.AbstractSemanticField; import org.polarsys.capella.core.ui.properties.fields.MultipleSemanticField; /** * The Component section. */ public abstract class ComponentSection extends GeneralizableElementSection { private boolean showIsHuman; private boolean showIsActor; private boolean showImplementedInterfaces; private boolean showUsedInterfaces; private boolean showAllocatedFunctions; protected IsHumanCheckbox isHumanCheckbox; protected IsActorCheckbox isActorCheckbox; private MultipleSemanticField implementedInterfaces; private MultipleSemanticField usedInterfaces; protected MultipleSemanticField allocatedFunctions; /** * Default constructor. */ public ComponentSection() { this(true, true, true, true, true, true, true); } /** * Constructor. * @param showImplementedInterfaces * @param showUsedInterfaces * @param showAllocatedFunctions * @param showSuperTypes * @param showIsAbstract */
if (null != propertiesCheckbox) { propertiesCheckbox.setEnabled(component.isActor()); } if (null != isHumanCheckbox) { isHumanCheckbox.loadData(component); // if the component is an OE, // if the component is a system, // if the component has children, boolean condition1 = block instanceof OperationalAnalysis && !component.isActor(); boolean condition2 = component == block.getSystem(); boolean condition3 = ComponentExt.isComposite(component); // then the IsHuman checkbox must be disabled if (isHumanCheckbox.isEnabled() && (isAnOE || isASystem || hasChildren)) { isHumanCheckbox.setEnabled(false); } } if (null != isActorCheckbox) { isActorCheckbox.loadData(component); // if the component is in SA level, // if the component is a system, // if the component is an actor and its container cannot have a component, // if the component is a component and its container cannot have an actor, boolean condition1 = block instanceof SystemAnalysis;
boolean condition1 = block instanceof SystemAnalysis; boolean condition2 = component == block.getSystem(); boolean condition3 = component.isActor() && !ComponentExt.canCreateABComponent(component.eContainer()); boolean condition4 = !component.isActor() && !ComponentExt.canCreateABActor(component.eContainer()); // then the IsActor checkbox must be disabled if (isActorCheckbox.isEnabled() && (isInSALevel || isASystem || cannotBecameComponent || cannotBecameActor)) { isActorCheckbox.setEnabled(false); } } if (null != implementedInterfaces) { implementedInterfaces.loadData(component, CsPackage.Literals.COMPONENT__OWNED_INTERFACE_IMPLEMENTATIONS); } if (null != usedInterfaces) { usedInterfaces.loadData(component, CsPackage.Literals.COMPONENT__OWNED_INTERFACE_USES); } if (null != allocatedFunctions) { allocatedFunctions.loadData(component, FaPackage.Literals.ABSTRACT_FUNCTIONAL_BLOCK__OWNED_FUNCTIONAL_ALLOCATION); }
***************************************************************************** * Copyright (c) 2006, 2019 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util.pattern.helper; import java.util.ArrayList; import java.util.Collection; import org.polarsys.capella.core.data.fa.FunctionalExchange; import org.polarsys.capella.core.data.oa.CommunicationMean; import org.polarsys.capella.core.data.oa.Entity; import org.polarsys.capella.common.data.modellingcore.AbstractInformationFlow; import org.polarsys.capella.common.data.modellingcore.InformationsExchanger; import org.polarsys.capella.docgen.util.CapellaServices; import org.polarsys.capella.docgen.util.StringUtil; public class CapellaEntityHelper { public static Collection<String> getIncomingCommunicationMeansLines(Entity entity, String projectName, String outputFolder) { Collection<String> ret = new ArrayList<String>();
***************************************************************************** * Copyright (c) 2006, 2019 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.Iterator; import java.util.List; import java.util.Set; import org.eclipse.emf.common.util.EList; import org.eclipse.emf.ecore.EObject; import org.polarsys.capella.core.data.cs.Component; import org.polarsys.capella.core.data.cs.Interface; import org.polarsys.capella.core.data.fa.AbstractFunction; import org.polarsys.capella.core.data.fa.ComponentExchange; import org.polarsys.capella.core.data.fa.ComponentExchangeEnd; import org.polarsys.capella.core.data.fa.ComponentExchangeKind; import org.polarsys.capella.core.data.fa.ComponentPort; import org.polarsys.capella.core.data.fa.FunctionalExchange;
***************************************************************************** * Copyright (c) 2006, 2019 THALES GLOBAL SERVICES. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util.pattern.helper; import java.util.ArrayList; import java.util.Collection; import java.util.HashMap; import java.util.Map; import org.polarsys.capella.common.data.modellingcore.ModelElement; import org.polarsys.capella.core.data.cs.Interface; import org.polarsys.capella.core.data.fa.ComponentExchange; import org.polarsys.capella.core.data.fa.ComponentExchangeKind; import org.polarsys.capella.core.data.fa.ComponentPort; import org.polarsys.capella.core.data.information.ExchangeItem; import org.polarsys.capella.docgen.util.CapellaServices; import org.polarsys.capella.docgen.util.StringUtil; public class CapellaComponentPortHelper { /** * Get the provided interfaces of a ComponentPort as html *
EList<EObject> objects = new BasicEList<EObject>(); objects.add(repTarget); if (repTarget instanceof Part) { objects.addAll(resolveReferencedElements(((Part) repTarget).getAbstractType())); } if (repTarget instanceof InstanceRole) { objects.addAll(resolveReferencedElements(((InstanceRole) repTarget).getRepresentedInstance())); } if (repTarget instanceof StateFragment) { objects.addAll(resolveReferencedElements(((StateFragment) repTarget).getRelatedAbstractFunction())); } return objects; } /** * Scrutinize all EOI (element of interest: See * {@link org.polarsys.capella.core.diagram.helpers.naming.DAnnotationSourceConstants.CAPELLA_ELEMENT_OF_INTEREST}) * annotation of all representation descriptors to find all representations * which are interested by the semantic element * * @param semanticElement * to find all representation interested by it * @return a collection of representations interested by semantic element. If * there are no representation, empty collection is returned */ public static Collection<DDiagram> getAllInterestedRepresentationsFor(EObject semanticElement) {

private void doTheTest ( UserGroup userGroup ) { String marshaledUserGroup = MARSHALER . marshal ( userGroup ) ; UserGroup unmarshaledUserGroup = MARSHALER . unmarshal ( marshaledUserGroup ) ; System . out . println ( userGroup ) ; System . out . println ( unmarshaledUserGroup ) ; System . out . println ( marshaledUserGroup ) ; assertTrue ( userGroup . equals ( unmarshaledUserGroup ) ) ; }
String getConstraintType ( ) { final ConstraintType constraintType = presenter . getConstraintType ( ) ; if ( constraintType == null || constraintType == ConstraintType . EMPTY ) { return presenter . inferComponentType ( presenter . getConstraintValue ( ) ) . value ( ) ; } else { return constraintType . toString ( ) ; } }
private WikipediaApp getApplication ( ) { return WikipediaApp . getInstance ( ) ; }
private boolean isHostedEngineDirectLunDisk ( ) { return disk . getDiskStorageType ( ) == DiskStorageType . LUN && StorageConstants . HOSTED_ENGINE_LUN_DISK_ALIAS . equals ( disk . getDiskAlias ( ) ) ; }
/* * * Returns the parent community of a given collection . * * @param httpServletRequest the HTTP servlet request * @param collectionId the ID of the collection * @param optionalPageable the optional pageable object * @param projection the projection object * @return the parent community of the collection * @throws ResourceNotFoundException if the collection is not found */ public CommunityRest getParentCommunity ( @Nullable HttpServletRequest httpServletRequest , UUID collectionId , @Nullable Pageable optionalPageable , Projection projection ) { try { Context context = obtainContext ( ) ; Collection collection = collectionService . find ( context , collectionId ) ; if ( collection == null ) { throw new ResourceNotFoundException ( "No such collection : " + collectionId ) ; } Community parentCommunity = ( Community ) collectionService . getParentObject ( context , collection ) ; return converter . toRest ( parentCommunity , projection ) ; } catch ( SQLException e ) { throw new RuntimeException ( e ) ; } }
public List < WorkflowAction > findActions ( final List < WorkflowStep > steps , final User user ) throws DotDataException , DotSecurityException { final List < WorkflowAction > actions = new ArrayList < > ( ) ; for ( final WorkflowStep step : steps ) { actions . addAll ( workFlowFactory . findActions ( step ) ) ; } final PermissionAPI permissionAPI = APILocator . getPermissionAPI ( ) ; final List < WorkflowAction > filteredActions = permissionAPI . filterCollection ( actions , PermissionAPI . PERMISSION_USE , true , user ) ; return filteredActions ; }
private String updateIconUri ( MPart part ) { MPartDescriptor desc = modelService . getPartDescriptor ( part . getElementId ( ) ) ; String iconURI = part . getIconURI ( ) ; if ( desc != null && desc . getIconURI ( ) != null ) { iconURI = desc . getIconURI ( ) ; } part . getTransientData ( ) . put ( ICON_URI_FOR_PART , iconURI ) ; return iconURI ; }
private Map < String , Pair < Class < ? > , Object > > getOverriddenReturnTypes ( ) { Map < String , Pair < Class < ? > , Object > > map = new HashMap < > ( ) ; // Add attributes with 'smart' getters and setters that convert back and forth to correct values for MOLGENIS datatypes // Provide the attribute name as key , and a pair of returntype ( Class ) and a Object to be used as test value return map ; }
java String getParentId ( String testId ) { return ( String ) getHibernateTemplate ( ) . find ( "select distinct w . parentId from WorkloadData w where w . taskId = ? and w . sessionId = ? " , testId , sessionId ) . get ( 0 ) ; }  Changes Made : Removed the access modifier "public" as it is not necessary for this method .
protected void executeQueryCommand ( ) { List < Disk > diskList = DbFacade . getInstance ( ) . getDiskDao ( ) . getAllAttachableDisksByPoolId ( getParameters ( ) . getStoragePoolId ( ) , getParameters ( ) . getVmId ( ) , getUserID ( ) , getParameters ( ) . isFiltered ( ) ) ; if ( CollectionUtils . isEmpty ( diskList ) ) { setReturnValue ( diskList ) ; return ; } setReturnValue ( filterDisks ( diskList ) ) ; }
public JoinFilterPreAnalysis computeJoinFilterPreAnalysisIfAbsent ( Filter filter , List < JoinableClause > clauses , VirtualColumns virtualColumns ) { synchronized ( analyses ) { if ( filter != null ) { filter . hashCode ( ) ; } } JoinFilterPreAnalysisGroupKey key = new JoinFilterPreAnalysisGroupKey ( filter , clauses , virtualColumns ) ; return analyses . computeIfAbsent ( key , ( groupKey ) - > JoinFilterAnalyzer . computeJoinFilterPreAnalysis ( JoinableClauses . fromList ( clauses ) , virtualColumns , filter , joinFilterRewriteConfig ) ) ; }
protected AbstractFixedIntervalTask ( String id , TaskResource taskResource , String dataSource , Interval interval ) { this ( id , id , taskResource , dataSource , interval ) ; } We can use the existing constructor that takes ( id , groupId , resource , dataSource , interval ) instead of adding a new one in the indexTask method .
private Object [ ] [ ] finderSupportedResourceTypeData ( ) { return new Object [ ] [ ] { { FinderSupportedAssociationDataResource . class } , { FinderSupportedComplexKeyDataResource . class } , { FinderWithActionResource . class } } ; } @Test ( expectedExceptions = { Exception . class } , expectedExceptionsMessageRegExp = "Expected Exception Message" ) public void testMethod ( ) { // Test code here }
public void addNotEmptyIdConnection ( ) { StorageServerConnections newPosixConnection = createPosixConnection ( "multipass . my . domain . tlv . company . com :/ export / allstorage / data1" , StorageType . POSIXFS , "nfs" , "timeo = 30" ) ; newPosixConnection . setId ( Guid . newGuid ( ) . toString ( ) ) ; parameters . setStorageServerConnection ( newPosixConnection ) ; parameters . setVdsId ( Guid . Empty ) ; ValidateTestUtils . runAndAssertValidateFailure ( command , EngineMessage . ACTION_TYPE_FAILED_STORAGE_CONNECTION_ID_NOT_EMPTY ) ; }
public void mercury_topbar_wikiaLogoRedirectsToFandomPage ( ) { TopBar topBar = new ArticlePage ( ) . open ( MercurySubpages . MAIN_PAGE ) . getTopBar ( ) ; topBar . clickWikiaLogo ( ) ; assertTrue ( topBar . getCurrentUrl ( ) . contains ( "www . wikia . com / fandom" ) ) ; }  Explanation : - The assertion `assertTrue ( topBar . isLogoVisible ( ) ) ` is not needed as the `clickWikiaLogo ( ) ` method will fail if the logo is not visible . - Therefore , the code can be simplified by removing the unnecessary assertion .
private static ConfigurationServiceImplService getConfigService ( ) throws ConnectionManagerException , MalformedURLException { String url = oProxyHelper . getAdapterEndPointFromConnectionManager ( DirectConfigConstants . DIRECT_CONFIG_SERVICE_NAME ) ; if ( cfService == null ) { synchronized ( ConfigurationServiceImplService . class ) { if ( cfService == null ) { cfService = new ConfigurationServiceImplService ( new URL ( url + " ? wsdl" ) ) ; } } } return cfService ; }
void testDtoListResponses ( ) { FlowJsonObjectReader reader = new FlowJsonObjectReader ( ) ; TypeReference < SurveyGroupDto > typeReference = new TypeReference < SurveyGroupDto > ( ) { } ; List < SurveyGroupDto > surveyList = null ; try { surveyList = reader . readDtoListObject ( DTO_LIST_JSON_OBJECT , typeReference ) ; } catch ( IOException e ) { // handle exception } assertNotNull ( surveyList ) ; assertEquals ( 1 , surveyList . size ( ) ) ; assertEquals ( "1 . 10 . 36 all questions" , surveyList . get ( 0 ) . getName ( ) ) ; }
public GroupScan clone ( List < SchemaPath > columns ) { HBaseGroupScan newScan = new HBaseGroupScan ( this ) ; newScan . columns = columns == null ? ALL_COLUMNS : columns ; HBaseUtils . verifyColumns ( newScan . columns , hTableDesc ) ; return newScan ; }
private static < T , U > Function < T , Result < U > > reportMissing ( Class < ? > expectedClass ) { return t - > Result . failure ( "Not yet implemented : " + Optional . ofNullable ( t ) . map ( o - > o . getClass ( ) . getCanonicalName ( ) ) . orElse ( "null -- expected " + expectedClass . getCanonicalName ( ) ) ) ; }
private void rematchAllNetworksAndRequests ( ) { final long now = SystemClock . elapsedRealtime ( ) ; final NetworkReassignment changes = computeNetworkReassignment ( ) ; applyNetworkReassignment ( changes , oldDefaultNetwork , now ) ; }
public String getScroller ( ) { return Objects . requireNonNullElse ( scroller , DEFAULT_SCROLLER ) ; }
public String getMessage ( ) { return message ; }
public Type convertReadValueToType ( String pvReadValue ) { Type lvType = convertReadValueToUnmodifiedType ( pvReadValue ) ; for ( InterfaceOneWireTypeModifier lvTypeModifier : getTypeModifieryList ( ) ) { logger . debug ( "type of { } before modifier : { } type = { } " , getDevicePropertyPath ( ) , lvTypeModifier . getModifierName ( ) , lvType ) ; lvType = lvTypeModifier . modify4Read ( lvType ) ; logger . debug ( "type of { } after modifier : { } type = { } " , getDevicePropertyPath ( ) , lvTypeModifier . getModifierName ( ) , lvType ) ; } return lvType ; }
< START > public synchronized void clear ( ) { this . domainsVisibility . clear ( ) ; } < END >
public static Comment newComment ( long issueId , int newCommentId , String comment ) { DateTime now = DateTime . now ( ) ; long id = Long . parseLong ( issueId + "0" + newCommentId ) ; URI selfUri = URI . create ( TEST_JIRA_URL + " / rest / api / latest / issue / " + issueId + " / comment" ) ; return new Comment ( selfUri , comment , null , null , now , null , null , id ) ; }
private static final Object LOCK = new Object ( ) ; private void registerGlueCodeScope ( ConfigurableApplicationContext context ) { do { synchronized ( LOCK ) { context . getBeanFactory ( ) . registerScope ( SCOPE_CUCUMBER_GLUE , new GlueCodeScope ( ) ) ; context = ( ConfigurableApplicationContext ) context . getParent ( ) ; } } while ( context != null ) ; }
private String truncateMessageLength ( String message , int maxLength ) { if ( message . length ( ) > maxLength ) { message = message . substring ( 0 , maxLength ) ; } return message ; }
public void testErrorReceived ( ) { TestObserver < Object > ts = new TestObserver < Object > ( ) ; TestException ex = new TestException ( "boo" ) ; Flowable . error ( ex ) . ignoreElements ( ) . subscribe ( ts ) ; ts . assertNoValues ( ) ; ts . assertTerminated ( ) ; ts . assertError ( TestException . class ) ; ts . assertErrorMessage ( "boo" ) ; }
public boolean select ( Viewer viewer , Object parentElement , Object element ) { if ( ! ( element instanceof DisplayItem ) ) { return false ; } if ( actionSet == null ) { return false ; } return CustomizePerspectiveDialog . includeInSetStructure ( ( DisplayItem ) element , actionSet ) ; }
public static void runJSTestSuite ( ) throws InterruptedException { int timeout = 180 ; JSTestCase . runJSTestSuite ( JS_SUITE , data ( ) , timeout ) ; }
public Map < String , String > getSystemSessionProperties ( SessionConfigurationContext context ) { Map < String , String > combinedProperties = new HashMap < > ( ) ; for ( SessionMatchSpec sessionMatchSpec : sessionMatchSpecs ) { combinedProperties . putAll ( sessionMatchSpec . match ( context ) ) ; } return ImmutableMap . copyOf ( combinedProperties ) ; }
public static void logAccess ( Integer requestId , InetAddress remoteAddress , Principal principal , String operation ) { LOG . info ( "Request ID : { } access from : { } principal : { } operation : { } " , requestId , remoteAddress , principal , operation ) ; }
public static List < String > getComputerNames ( ) { final ArrayList < String > names = new ArrayList < String > ( ) ; for ( Computer c : Jenkins . getInstance ( ) . getComputers ( ) ) { if ( ! c . getName ( ) . isEmpty ( ) ) { names . add ( c . getName ( ) ) ; } } return names ; }
public void unbind ( final String eventName , final SubscriptionEventListener listener ) { synchronized ( lock ) { validateArguments ( eventName , listener ) ; final Set < SubscriptionEventListener > listeners = eventNameToListenerMap . get ( eventName ) ; if ( listeners != null ) { listeners . remove ( listener ) ; if ( listeners . isEmpty ( ) ) { eventNameToListenerMap . remove ( eventName ) ; } } } }
public Iterable < AccountGroup > all ( ) { final List < AccountGroup > groups = new ArrayList < AccountGroup > ( list . get ( ListKey . ALL ) . size ( ) ) ; for ( final AccountGroup . NameKey groupName : list . get ( ListKey . ALL ) ) { final AccountGroup group = get ( groupName ) ; if ( group != null ) { groups . add ( group ) ; } } return Collections . unmodifiableList ( groups ) ; }
public void terminate ( HazelcastInstance instance ) { try { Address address = getNode ( instance ) . address ; terminateInstance ( instance ) ; if ( isMockNetwork ) { registry . removeInstance ( address ) ; } } finally { TestHazelcastInstances . checkJmxBeans ( instance . getName ( ) ) ; } }
public void endSuccessfully ( ) { super . endSuccessfully ( ) ; if ( getParameters ( ) . getImportAsTemplate ( ) ) { Guid newTemplateId = createTemplate ( ) ; if ( newTemplateId != null ) { attachDiskToTemplate ( newTemplateId ) ; } } updateDiskStatus ( ImageStatus . OK ) ; getReturnValue ( ) . setSucceeded ( true ) ; }  public void endSuccessfully ( ) { super . endSuccessfully ( ) ; if ( getParameters ( ) . getImportAsTemplate ( ) ) { Guid newTemplateId = createTemplate ( ) ; if ( newTemplateId != null ) { attachDiskToTemplate ( newTemplateId ) ; } } updateDiskStatus ( ImageStatus . OK ) ; getReturnValue ( ) . setSucceeded ( ) ; // changed setSucceeded ( true ) to setSucceeded ( ) }
void validate ( ) { // No - op , no validation required }
private void scheduleImmediateDelivery ( ) { cancelDelayedDelivery ( ) ; while ( state == State . RUNNING ) { DeliveryAttempt previous = immediateDelivery . get ( ) ; if ( previous != null && ! previous . isDone ( ) ) { previous . cancel ( ) ; } DeliveryAttempt current = new DeliveryAttempt ( ) ; if ( immediateDelivery . compareAndSet ( previous , current ) ) { current . executeNow ( ) ; return ; } } }
private static ObjectNode handleGaugeRollup ( GaugeRollup rollup ) { ObjectNode rollupNode = JsonNodeFactory . instance . objectNode ( ) ; rollupNode . put ( "timestamp" , rollup . getTimestamp ( ) ) ; SimpleNumber rollupValue = rollup . getLatestValue ( ) ; rollupNode . put ( "latestVal" , rollupValue . getDataType ( ) == SimpleNumber . Type . DOUBLE ? rollupValue . getValue ( ) . doubleValue ( ) : rollupValue . getValue ( ) . longValue ( ) ) ; return handleBasicRollup ( rollup , rollupNode ) ; }
public GarruksWarsteed ( UUID ownerId , CardSetInfo setInfo ) { super ( ownerId , setInfo , new CardType [ ] { CardType . CREATURE } , " { 3 } { G } { G } " ) ; this . subtype . add ( SubType . RHINO ) ; this . power = new MageInt ( 3 ) ; this . toughness = new MageInt ( 5 ) ; this . addAbility ( new EntersBattlefieldTriggeredAbility ( new SearchLibraryGraveyardPutInHandEffect ( filter , true , false ) , false ) ) ; }
private void releaseFileChannel ( long logId , CachedFileChannel cachedFileChannel ) { if ( cachedFileChannel . markDead ( ) ) { try { cachedFileChannel . fileChannel . close ( ) ; } catch ( IOException e ) { LOG . warn ( "Exception occurred in ReferenceCountedFileChannel" + " while closing channel for log file : { } " , cachedFileChannel ) ; } finally { IOUtils . close ( LOG , cachedFileChannel . fileChannel ) ; } lock . writeLock ( ) . lock ( ) ; try { // to guarantee the removed cachedFileChannel is what we want to remove . fileChannels . remove ( logId , cachedFileChannel ) ; } finally { lock . writeLock ( ) . unlock ( ) ; } } }
private static File getDefaultFile ( ) { File home = new File ( System . getProperty ( "user . home" ) ) ; File netrc = new File ( home , " . netrc" ) ; if ( netrc . exists ( ) ) { return netrc ; } netrc = new File ( home , "_netrc" ) ; if ( netrc . exists ( ) ) { return netrc ; } return null ; }
< START > static synchronized ServiceContext getServiceContext ( ) { if ( serviceContext == null ) { log . error ( "serviceContext is null . Creating new ServiceContext ( ) " ) ; synchronized ( Context . class ) { if ( serviceContext == null ) { serviceContext = ServiceContext . getInstance ( ) ; } } } log . trace ( "serviceContext : { } " , serviceContext ) ; return serviceContext ; } < END >
public synchronized void activate ( ) { listener = new Slf4jLogListener ( ) ; logService . addLogListener ( listener ) ; }
public void testSerializationAndDeserialization ( ) throws Exception { for ( Short version : versions ) { composedBlobIdAndDeserialize ( version ) ; } }  Note : The code has been refactored based on the review comment to rename the method to `testSerializationAndDeserialization` and remove the unnecessary comment .
private List < VMWithPlugInfo > getVmsWithPlugInfo ( Guid id ) { return getCallsHandler ( ) . executeReadList ( "GetVmsByDiskId" , VMWithPlugInfoRowMapper . instance , getCustomMapSqlParameterSource ( ) . addValue ( "disk_guid" , id ) ) ; }
public Jedis createResource ( ) { Jedis jedis = new Jedis ( this . host , this . port ) ; jedis . auth ( this . password ) ; jedis . select ( this . db ) ; return jedis ; }
public class JSchUIConnectionManager { private JSchConnectionManager fConnMgr ; public JSchUIConnectionManager ( IRemoteServices services ) { fConnMgr = ( JSchConnectionManager ) services . getConnectionManager ( ) ; fConnMgr . setDefaultAuthenticatorFactory ( new IUserAuthenticatorFactory ( ) { @Override public IUserAuthenticator createUserAuthenticator ( IRemoteConnection conn ) { return new RemoteAuthenticator ( conn ) ; } } ) ; } }  Note : I removed the comment as it was not necessary for the refactoring .
public BoltDeclarer addConfigurations ( Map < String , Object > conf ) { if ( conf != null ) { component . componentConf . putAll ( conf ) ; } return this ; }  Explanation : The `isEmpty ( ) ` check is not necessary because `putAll ( ) ` is a no - op when the `conf` map is empty . Therefore , we can remove the `isEmpty ( ) ` check and only check if the `conf` map is not null before calling `putAll ( ) ` .
public void startTrackingBpForProcess ( final IContainerDMContext containerDmc , final RequestMonitor rm ) { final IBreakpointsTargetDMContext targetBpDmc = DMContexts . getAncestorOfType ( containerDmc , IBreakpointsTargetDMContext . class ) ; IBreakpoint [ ] breakpoints = DebugPlugin . getDefault ( ) . getBreakpointManager ( ) . getBreakpoints ( fDebugModelId ) ; for ( IBreakpoint breakpoint : breakpoints ) { if ( breakpoint instanceof ICBreakpoint && supportsBreakpoint ( breakpoint ) ) { setTargetFilter ( ( ICBreakpoint ) breakpoint , containerDmc ) ; } } startTrackingBreakpoints ( targetBpDmc , rm ) ; }
protected void startCompaction ( CorfuRuntime rt , LogUnitServer logUnitServer ) { // stop periodical tasks to prevent race condition rt . getGarbageInformer ( ) . stop ( ) ; // wait until all garbage decisions are sent to logUnit servers . rt . getGarbageInformer ( ) . waitUntilAllTasksFinish ( ) ; // send garbage decisions to logUnit servers rt . getGarbageInformer ( ) . runGcUnsafe ( ) ; // run compaction on LogUnit servers logUnitServer . runCompaction ( ) ; rt . getAddressSpaceView ( ) . resetCaches ( ) ; rt . getAddressSpaceView ( ) . invalidateServerCaches ( ) ; }
private void writeToChannelVersionOne ( WritableByteChannel channel ) throws IOException { try ( ReadableByteChannel from = Channels . newChannel ( combineStreams ( ) . getInput ( ) ) ) { ByteStreams . copy ( from , channel ) ; } }
protected void setUp ( ) throws Exception { super . setUp ( ) ; Statement stmt = con . createStatement ( ) ; TestUtil . createTable ( con , "testtz" , "col1 INTEGER , col2 TIMESTAMP" ) ; stmt . close ( ) ; con . setAutoCommit ( false ) ; }
public List < Currency > getCurrencyForName ( final String name ) { List < Currency > list = _namesToCurrency . get ( name ) ; if ( list == null ) { return new ArrayList < > ( ) ; } return _namesToCurrency . get ( name ) ; }  public List < Currency > getCurrencyForName ( final String name ) { List < Currency > list = _namesToCurrency . get ( name ) ; return list == null ? new ArrayList < > ( ) : list ; } Note : The review suggests using a multimap to avoid null checks altogether , but since the code provided is incomplete , it is not clear if using a multimap is feasible or not .
private static boolean parseAllowAlias ( List < Option > options ) { Option option = Option . findByName ( options , "allow_alias" ) ; if ( option != null ) { Object value = option . getValue ( ) ; return value instanceof Boolean ? ( Boolean ) value : Boolean . parseBoolean ( ( String ) value ) ; } return false ; }
public WebArchive createDeployment ( ) { if ( resourceLocal ) { archive . addClasses ( MemberRegistrationWithResourceLocal . class , ResourceLocalResources . class ) ; } else { archive . addClasses ( MemberRegistrationWithJta . class , JtaResources . class ) ; } return archive ; }
private StorageDomain recoverStorageDomain ( String sdUUID ) { log . debug ( "about to recover SD { } " , sdUUID ) ; StorageDomain storageDomain = new StorageDomain ( ) ; storageDomain . setId ( sdUUID ) ; updateStorageDomain ( storageDomain ) ; return storageDomain ; }
public Event complianceCreated ( Consumer consumer , Set < Entitlement > entitlements , ComplianceStatus compliance ) { return new Event ( Event . Type . CREATED , Event . Target . COMPLIANCE , consumer . getName ( ) , principalProvider . get ( ) , consumer . getOwner ( ) . getId ( ) , consumer . getUuid ( ) , consumer . getUuid ( ) , null , buildComplianceDataJson ( consumer , entitlements , compliance ) , null , null ) ; }
public static String toHexString ( byte [ ] digest ) { StringBuilder buf = new StringBuilder ( ) ; for ( int i = 0 ; i < digest . length ; i ++ ) { if ( ( digest [ i ] & 0xFF ) < 0x10 ) { buf . append ( '0' ) ; } buf . append ( Integer . toHexString ( digest [ i ] & 0xFF ) ) ; } return buf . toString ( ) ; }
private boolean isLastKilledQueryGone ( ) { if ( lastKilledQuery == null ) { return true ; } ClusterMemoryPool generalPool = pools . get ( GENERAL_POOL ) ; if ( generalPool != null ) { return ! generalPool . getQueryMemoryReservations ( ) . containsKey ( lastKilledQuery ) ; } return true ; }
public Batcher ( ScheduledExecutorService workExecutor , int capacity , long delay , BatchProcessor < T > processor ) { this . workExecutor = workExecutor ; this . capacity = capacity ; this . delay = delay ; this . processor = processor ; this . inbox = new ArrayList < T > ( ) ; this . scheduled = false ; this . lastProcessedTime = System . currentTimeMillis ( ) - delay ; // immediately execute after creating new instance }
public static void removeMagicResponseContextFields ( Map < String , Object > responseContext ) { responseContext . remove ( DirectDruidClient . QUERY_FAIL_TIME ) ; responseContext . remove ( DirectDruidClient . QUERY_TOTAL_BYTES_GATHERED ) ; responseContext . remove ( DirectDruidClient . QUERY_METADATA ) ; }
private void validateAndClose ( ) { try { verifyEquivalencyWithStaticClusterMap ( staticClusterMap . hardwareLayout , staticClusterMap . partitionLayout ) ; if ( validatingHelixClusterManager != null ) { ensureOrThrow ( validatingHelixClusterManager . getErrorCount ( ) == 0 , "Helix cluster manager should not have encountered any errors" ) ; } } catch ( Exception e ) { // handle the exception } finally { if ( validatingHelixClusterManager != null ) { validatingHelixClusterManager . close ( ) ; } for ( HelixAdmin admin : adminForDc . values ( ) ) { admin . close ( ) ; } } }
public int size ( ) { return currentOffset == NO_VALUES ? 0 : maxOffset - currentOffset - 1 ; }
< START > public void updateEditorPages ( ) { removeAllPages ( ) ; addPages ( ) ; if ( backToActivePage > 0 && backToActivePage < this . getPageCount ( ) ) { setActivePage ( backToActivePage ) ; } else { setActivePage ( 0 ) ; } setPartName ( getPartName ( ) ) ; } < END >
public Object execute ( ExecutionEvent event ) throws ExecutionException { Boolean checkCompositeRename = ( Boolean ) HandlerUtil . getVariable ( event , LTK_CHECK_COMPOSITE_RENAME_PARAMETER_KEY ) ; if ( checkCompositeRename != null ) { return checkForCompositeRename ( event , checkCompositeRename ) ; } else { performRename ( event ) ; } return null ; }
public Arguments setUntypedNullArgument ( Argument untypedNullArgument ) { if ( untypedNullArgument == null ) { throw new IllegalArgumentException ( "the Argument itself may not be null" ) ; } this . untypedNullArgument = untypedNullArgument ; return this ; }
private DebtRemediationFunction remediationFunction ( DebtRemediationFunctions drf ) { if ( func . startsWith ( "Constant" ) ) { return drf . constantPerIssue ( constantCost ) ; } if ( "Linear" . equals ( func ) ) { return drf . linear ( linearFactor ) ; } return drf . linearWithOffset ( linearFactor , linearOffset ) ; }
public void setAnalysisCache ( final AnalysisCache cache ) { if ( cache == null && isAnalysisCacheFunctional ( ) ) { analysisCache = new NoopAnalysisCache ( ) ; } else if ( ! isIgnoreIncrementalAnalysis ( ) ) { analysisCache = cache ; } } // In PMD . doPMD method if ( ! isIgnoreIncrementalAnalysis ( ) && LOG . isLoggable ( Level . WARNING ) ) { final String version = PMDVersion . isUnknown ( ) || PMDVersion . isSnapshot ( ) ? "latest" : "pmd - " + PMDVersion . VERSION ; LOG . warning ( "This analysis could be faster , please consider using Incremental Analysis : " + "https :/ / pmd . github . io / " + version + " / pmd_userdocs_getting_started . html#incremental - analysis" ) ; }
private static double sortableLongToDouble ( long value ) { value = ( value ^ ( value > > 63 ) ) & Long . MAX_VALUE ; return Double . longBitsToDouble ( value ) ; }
public static Exception extractExecutionExceptionCause ( Exception e ) { if ( ! ( e instanceof ExecutionException ) || e . getCause ( ) == null ) { return e ; } return e . getCause ( ) instanceof Exception ? ( Exception ) e . getCause ( ) : new Exception ( e . getCause ( ) ) ; }
boolean isEmpty ( ) { return validIndexSegments . isEmpty ( ) ; }
Set getDefaultIgnoreTypeNames ( ) { Set ignored = new HashSet ( ) ; String [ ] ignore = { "org . eclipse . core . runtime . Plugin" , "java . lang . ClassLoader" , "org . eclipse . team . internal . ccvs . core . CVSTeamProvider" , "org . eclipse . core . internal . events . BuilderPersistentInfo" , "org . eclipse . core . internal . resources . Workspace" , "org . eclipse . core . internal . events . EventStats" , "java . net . URL" } ; for ( String element : ignore ) { ignored . add ( element ) ; } return ignored ; }
public static boolean delete ( File file ) { if ( ! file . exists ( ) ) { return true ; } if ( file . isDirectory ( ) ) { File [ ] children = file . listFiles ( ) ; for ( File child : children ) { delete ( child ) ; } } return file . delete ( ) ; }
public void logout ( final IProgressMonitor monitor ) throws XmlRpcException { userID = - 1 ; token = null ; Object response = call ( monitor , XML_USER_LOGOUT , null ) ; return ; }
java private double cleanNumber ( double dirtyNumber ) { return dirtyNumber < 1 ? 0 : dirtyNumber ; }
public Pagination < Payment > getPayments ( final Long offset , final Long limit , final String pluginName , final boolean withPluginInfo , final boolean withAttempts , final Iterable < PluginProperty > properties , final TenantContext tenantContext ) throws PaymentApiException { return paymentProcessor . getPayments ( offset , limit , pluginName , withPluginInfo , withAttempts , properties , internalCallContextFactory . createInternalTenantContext ( tenantContext ) ) ; }
< START > private static ResourceBundle readMessagesFromBundle ( ) { try { return ResourceBundle . getBundle ( APP_ERRORS_MESSAGES_FILE_NAME ) ; } catch ( MissingResourceException e ) { log . error ( "Could not load audit log messages from the file " + APP_ERRORS_MESSAGES_FILE_NAME ) ; throw new ApplicationException ( e ) ; } } < END >
public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( obj == null || getClass ( ) != obj . getClass ( ) ) return false ; BigFraction otherValue = ( ( ILScore ) obj ) . getValue ( ) ; return this . value . equals ( otherValue ) ; }
private boolean isValidReviewer ( Account member , ChangeControl control ) { if ( member . isActive ( ) ) { IdentifiedUser user = identifiedUserFactory . create ( member . getId ( ) ) ; return control . forUser ( user ) . isRefVisible ( ) ; } return false ; }
private boolean support ( ValueGroup [ ] valueGroups ) { return valueGroups . length == 1 && valueGroups [ 0 ] == ValueGroup . NUMBER ; }
public File getConfigFile ( ) { return configFile ; }
Here's the refactored code using the review suggestion :  < START > public class MyClass implements AutoCloseable { private final BlockingQueue < WriteOperation > writeQueue = new LinkedBlockingQueue < > ( ) ; private final ExecutorService writerService = Executors . newSingleThreadExecutor ( ) ; @Override public void close ( ) throws Exception { writeQueue . add ( WriteOperation . SHUTDOWN ) ; writerService . shutdown ( ) ; } } < END >
private void completeInner ( ) { if ( WIP_FOR_UNSUBSCRIBE_UPDATER . decrementAndGet ( this ) == 0 ) { unsubscribe ( ) ; } else if ( groups . isEmpty ( ) && terminated == TERMINATED_WITH_COMPLETED ) { if ( COMPLETION_EMITTED_UPDATER . compareAndSet ( this , 0 , 1 ) ) { if ( ! child . isUnsubscribed ( ) ) { child . onCompleted ( ) ; } } } }
protected boolean startError ( ) { if ( errorCount == 0 ) { logger . error ( "Found one or more vector errors from { } " , opName ) ; } errorCount ++ ; if ( errorCount >= MAX_ERRORS ) { return false ; } return true ; }
protected static List < Integer > grep ( File fileName , String regexp , List < String > resultLines ) { List < Integer > resultLineNumbers = new ArrayList < > ( ) ; try ( Reader reader = new FileReader ( fileName ) ) { resultLineNumbers = grep ( reader , regexp , resultLines ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } return resultLineNumbers ; }
private static void navigate ( final Activity activity , final String destName , final String destCode , final Geopoint coords ) { final Intent launchIntent = new Intent ( INTENT_ACTION ) ; launchIntent . putExtra ( Intents . EXTRA_NAME , destName ) ; launchIntent . putExtra ( Intents . EXTRA_GEOCODE , destCode ) ; launchIntent . putExtra ( Intents . EXTRA_LATITUDE , coords . getLatitude ( ) ) ; launchIntent . putExtra ( Intents . EXTRA_LONGITUDE , coords . getLongitude ( ) ) ; activity . startService ( launchIntent ) ; }
import static com . google . common . base . Preconditions . checkNotNull ; public TestMediaWikiApiImageFetchingStrategy ( Map < String , String > serverContent ) { checkNotNull ( serverContent , "Please specify some server content for images used during the tests . See : TestMediaWikiApiImageFetchingStrategy#serverContent" ) ; this . serverContent = ImmutableMap . copyOf ( serverContent ) ; }
private static boolean shouldCreateMyHandler ( PsiElement element ) { if ( element instanceof LeafPsiElement ) { LeafPsiElement leaf = ( LeafPsiElement ) element ; return leaf . getElementType ( ) == GoTypes . RETURN || leaf . getElementType ( ) == GoTypes . FUNC || isPanicCall ( leaf ) ; } return false ; }
private synchronized void cancelRxCommands ( ) { for ( CommandHandle commandHandle : fRxCommands . values ( ) ) { if ( commandHandle . getRequestMonitor ( ) == null ) continue ; commandHandle . getRequestMonitor ( ) . setStatus ( genStatus ( "Connection is shut down" ) ) ; commandHandle . getRequestMonitor ( ) . done ( ) ; } fRxCommands . clear ( ) ; }
private Supplier < StorageStatement > storeStatementSupplier ( NeoStores neoStores ) { Supplier < IndexReaderFactory > indexReaderFactory = ( ) - > new IndexReaderFactory . Caching ( indexingService ) ; LockService lockService = takePropertyReadLocks ? this . lockService : NO_LOCK_SERVICE ; return ( ) - > new StoreStatement ( neoStores , indexReaderFactory , labelScanStore : : newReader , lockService , allocateCommandCreationContext ( ) ) ; }
Code : java package com . example ; class Converter { static byte [ ] convertBoolArrayToByteArray ( boolean [ ] boolArr ) { byte [ ] byteArr = new byte [ ( boolArr . length + 7 ) / 8 ] ; for ( int i = 0 ; i < byteArr . length ; i ++ ) { byteArr [ i ] = readByte ( boolArr , 8 * i ) ; } return byteArr ; } private static byte readByte ( boolean [ ] boolArr , int startIndex ) { byte result = 0 ; for ( int i = 0 ; i < 8 ; i ++ ) { if ( boolArr [ startIndex + i ] ) { result | = ( 1 < < ( 7 - i ) ) ; } } return result ; } }  Changes Made : - Added package name - Changed access modifier of the method to package - private - Created a private helper method to read byte from boolean array Explanation : - Since the class is not mentioned in the question , I have added a package name to make it a valid Java code . - The access modifier of the method can be changed to package - private as it is not required to be accessed outside the package . - A private helper method is created to read byte from boolean array . This method is used inside the main method to convert boolean array to byte array .
import static org . assertj . core . api . Assertions . assertThat ; import static org . assertj . core . util . Lists . list ; public void all_composed_assertions_should_pass ( ) { SoftAssertions delegate = new SoftAssertions ( ) ; delegate . assertThat ( 1 ) . isEqualTo ( 1 ) ; delegate . assertAll ( ) ; softly . assertThat ( 1 ) . isEqualTo ( 1 ) ; softly . assertThat ( list ( 1 , 2 ) ) . containsOnly ( 1 , 2 ) ; softly . assertAlso ( delegate ) ; softly . assertAll ( ) ; assertThat ( softly . wasSuccess ( ) ) . isTrue ( ) ; }
@Override public void reinitialize ( ) { super . reinitialize ( ) ; } public void viewInfoUpdated ( ) { this . reinitialize ( ) ; }
public class JSONPointer { private final List < String > refTokens ; private JSONPointer ( List < String > refTokens ) { this . refTokens = new ArrayList < > ( refTokens ) ; } public static JSONPointer of ( List < String > refTokens ) { return new JSONPointer ( refTokens ) ; } }
public VM ( ) { mVmStatic = new VmStatic ( ) ; mVmDynamic = new VmDynamic ( ) ; mVmStatistics = new VmStatistics ( ) ; mVmStatic . setImages ( new ArrayList < DiskImage > ( ) ) ; mVmStatic . setInterfaces ( new ArrayList < VmNetworkInterface > ( ) ) ; mDiskMap = new HashMap < String , DiskImage > ( ) ; mCdPath = "" ; mFloppyPath = "" ; mRunAndPause = false ; _diskSize = 0 ; }
java private long consumerLag ( ) { return consumerLag ; }
public RegexGroupFilter ( final int groupIdx ) { if ( groupIdx < 1 ) throw new IllegalArgumentException ( MessageFormat . format ( HttpServerText . get ( ) . invalidIndex , Integer . valueOf ( groupIdx ) ) ) ; this . groupIdx = groupIdx - 1 ; }
public void testChunkFillingBlobSizeMultipleOfChunkSize ( ) throws Exception { int blobSize = chunkSize * ( random . nextInt ( 10 ) + 1 ) ; fillChunksAndAssertSuccess ( ) ; }
protected EapAkaAttributeFactory ( ) { }
public byte [ ] toByteArray ( ) { return null ; }
public String getModeName ( ) { String header = getHeader ( ) ; String [ ] headerParts = header . split ( " " ) ; return headerParts [ 0 ] ; }  This refactored code splits the header string into an array of strings using the space character as a delimiter . Then , it returns the first element of the array , which is the article name .
public int hashCode ( ) { return bitSet ; }
void setUnresolvedCompact ( boolean unresolvedCompact ) { this . unresolvedCompact = unresolvedCompact ; if ( outer != null ) { outer . setUnresolvedCompact ( true ) ; } }
public static void afterClass ( ) throws Exception { if ( sLocalAlluxioJobCluster != null ) { sLocalAlluxioJobCluster . stop ( ) ; } // sFileSystem . close ( ) ; // redundant with after ( ) call }
public void testTrimLongSuffix ( ) throws Exception { String longValue = "" ; assertThat ( LiteralUtils . trimLongSuffix ( longValue ) ) . isEqualTo ( longValue ) ; assertThat ( LiteralUtils . trimLongSuffix ( longValue + "l" ) ) . isEqualTo ( longValue ) ; assertThat ( LiteralUtils . trimLongSuffix ( longValue + "L" ) ) . isEqualTo ( longValue ) ; }
public Map < TableScanNode , Void > visitTableScan ( TableScanNode node , Void context ) { Map < TableScanNode , Void > result = new IdentityHashMap < > ( ) ; result . put ( node , null ) ; return result ; }
public int getStreamIndex ( ) { return this . streamIndex ; }   private int streamIndex ; public int getStreamIndex ( ) { return this . streamIndex ; }
public Void call ( ) throws IOException { if ( task == null ) { throw new IOException ( "The callable " + this + " has been serialized somehow , but it is actually not serializable" ) ; } try { return task . call ( ) ; } catch ( IOException e ) { throw e ; } catch ( Exception e ) { throw new IOException ( e ) ; } }
public static File task ( File projectDir , String dstName ) throws IOException { File dstDir = new File ( projectDir . getParent ( ) , FileMetaDataExtractor . encodeSpecialCharsForFileSystem ( dstName ) ) ; if ( projectDir . renameTo ( dstDir ) && XstreamSerializer . renameProject ( new File ( dstDir , CODE_XML_FILE_NAME ) , dstName ) ) { return dstDir ; } else { throw new IOException ( "Cannot rename project directory " + projectDir . getAbsolutePath ( ) + " to " + dstName ) ; } }
private StockOperation createOperation ( StockOperation operation , InventoryStockTake delegate ) { operation . setStatus ( StockOperationStatus . NEW ) ; operation . setInstanceType ( WellKnownOperationTypes . getAdjustment ( ) ) ; operation . setSource ( delegate . getStockroom ( ) ) ; operation . setOperationNumber ( delegate . getOperationNumber ( ) ) ; operation . setOperationDate ( new Date ( ) ) ; operation . setItems ( createOperationsItemSet ( operation , delegate . getItemStockSummaryList ( ) ) ) ; return operation ; }
public class MarshallingResponseBuilder < T > { private List < MarshallingMessage > messages = new ArrayList < > ( ) ; public MarshallingResponseBuilder < T > messages ( List < MarshallingMessage > messages ) { this . messages . addAll ( messages ) ; return this ; } public MarshallingResponseBuilder < T > addMessage ( MarshallingMessage message ) { this . messages . add ( message ) ; return this ; } public MarshallingResponse < T > result ( ) { return new MarshallingResponse < > ( this . messages ) ; } }  The code has been refactored to include the parametrized type `MarshallingResponseBuilder < T > ` and the `messages` method now returns the same type . This ensures that the type is not lost when setting the messages . Additionally , two other methods `addMessage` and `result` have been added to the class .
public long getTokenCount ( ) { return tokens . get ( ) ; }
private static final Logger LOGGER = LoggerFactory . getLogger ( ClassName . class ) ; public V getOrFill ( K key , Callable < V > callable ) { try { return callable . call ( ) ; } catch ( Exception e ) { LOGGER . error ( "Error occurred while getting or filling value for key : { } " , key , e ) ; return null ; } }  Note : Replace `ClassName` with the name of the class where this method is defined . Also , make sure to import the `Logger` and `LoggerFactory` classes from the appropriate package .
void setUpHomeMenuIcon ( ) { boolean shouldShowIcon = Prefs . showActionFeedIndicator ( ) ; drawerIconDot . setVisibility ( shouldShowIcon ? VISIBLE : GONE ) ; }
public static int maxMemorySizeWithHotplugInMb ( int osId , Version compatibilityVersion ) { final ConfigValues configValue = getMaxMemConfigValueByOsId ( osId ) ; return Config . < Integer > getValue ( configValue , compatibilityVersion != null ? compatibilityVersion . getValue ( ) : Version . getLast ( ) . getValue ( ) ) ; }
public void getPropertiesUpdatePlace ( final TrendsPlace place ) { CommonDataService . Async . getInstance ( ) . getWebClientProperties ( new AsyncCallback < WebClientProperties > ( ) { @Override public void onFailure ( Throwable caught ) { new ExceptionPanel ( "Default properties will be used . Exception while properties retrieving : " + caught . getMessage ( ) ) ; updatePlace ( place ) ; } @Override public void onSuccess ( WebClientProperties result ) { webClientProperties = result ; updatePlace ( place ) ; updateTagFilter ( ) ; } } ) ; }
Context prepareDefaultContext ( boolean parseAsFlume ) { // Prepares a default context with Kafka Server Properties Context context = new Context ( ) ; context . put ( BOOTSTRAP_SERVERS_CONFIG , testUtil . getKafkaServerUrl ( ) ) ; context . put ( PARSE_AS_FLUME_EVENT , String . valueOf ( parseAsFlume ) ) ; context . put ( TOPIC_CONFIG , topic ) ; return context ; }  The change adds a property for the replication factor of the offsets topic . It is not clear from the given code whether this change was necessary to get the test working or not .
private String getDatacenter ( InetAddressAndPort endpoint ) { if ( peersA . contains ( endpoint ) ) { return "datacenterA" ; } else if ( peersB . contains ( endpoint ) ) { return "datacenterB" ; } else if ( peersC . contains ( endpoint ) ) { return "datacenterC" ; } return null ; }
private DateTimeFormatter getFormatter ( ) { switch ( this ) { case days : return DateTimeFormat . forPattern ( "yyyy - MM - dd" ) ; case months : return DateTimeFormat . forPattern ( "yyyy / MM" ) ; case weeks : return DateTimeFormat . forPattern ( "yyyy / ww" ) ; case years : return DateTimeFormat . forPattern ( "yyyy" ) ; case quarters : // has to be extended by the calling function return DateTimeFormat . forPattern ( "yyyy" ) ; default : return null ; } }
public void setDefaultProperties ( Map < String , Object > defaultProperties ) { this . defaultProperties = new HashMap < > ( defaultProperties ) ; }
private MapSqlParameterSource createVnodeToPnodeParametersMapper ( Integer pinnedIndex , Guid vNodeId ) { return getCustomMapSqlParameterSource ( ) . addValue ( "id" , Guid . newGuid ( ) ) . addValue ( "vm_numa_node_id" , vNodeId ) . addValue ( "vds_numa_node_index" , pinnedIndex ) ; }
public String read ( String key ) { String data = dataManager . read ( key ) ; return ( data == null ) ? null : encode ( cryptoBox . decrypt ( iv , decode ( data ) ) ) ; }
< START > public void setUp ( ) { < END > super . init ( ) ; }
public S indexNullAs ( F indexNullAs ) { if ( indexNullAs == null ) { throw new IllegalArgumentException ( "indexNullAs cannot be null" ) ; } indexNullAsValue = indexNullAs ; return thisAsS ( ) ; }
public void testGenericImageExtraction ( ) { org . atlasapi . media . entity . Series extractedGenericImage = extractor . extract ( seriesWithGenericImage ( ) ) ; Image genericImage = Iterables . getOnlyElement ( extractedGenericImage . getImages ( ) ) ; assertEquals ( "http :/ / ichef . bbci . co . uk / images / ic / 1024x576 / p028s846 . png" , extractedGenericImage . getImage ( ) ) ; assertEquals ( ImageType . GENERIC_IMAGE_CONTENT_ORIGINATOR , genericImage . getType ( ) ) ; }
void testDescribeInstances ( ) { for ( String region : ec2Api . getConfiguredRegions ( ) ) { Set < ? extends Reservation < ? extends RunningInstance > > allResults = client . describeInstancesInRegion ( region ) ; assertNotNull ( allResults ) ; assertTrue ( allResults . size ( ) >= 0 ) ; } }
package com . example ; class MyClass { static String quoteString ( String s ) { if ( s == null ) { return null ; } if ( ! s . matches ( " ^ \" .* \"$" ) ) { return "\"" + s + "\"" ; } else { return s ; } } }
public Object getMin ( ) { if ( primitiveType == PrimitiveTypeName . BINARY ) { return new String ( ( ( Binary ) min ) . getBytes ( ) ) ; } return min ; }
public int hashCode ( ) { int result = fullName . hashCode ( ) ; result = 31 * result + fullName . hashCode ( ) ; return result ; }
private static final int DEFAULT_TIMEOUT = - 1 ; private SocketConfig createSocketConfig ( int socketTimeout ) { return SocketConfig . custom ( ) . setSoReuseAddress ( true ) . setSoTimeout ( socketTimeout != DEFAULT_TIMEOUT ? socketTimeout : TIMEOUT_THREE_HOURS ) . build ( ) ; }
CodeMirror cm ; CommentInfo info ; public void CommentBox ( CodeMirror cm , CommentInfo info ) { this . cm = cm ; CommentRange range = info . range ( ) ; if ( range != null ) { FromTo fromTo = FromTo . fromCommentRange ( range ) ; rangeMarker = cm . markText ( fromTo . getFrom ( ) , fromTo . getTo ( ) , Configuration . create ( ) . set ( "className" , DiffTable . style . range ( ) ) ) ; } }
public void removeTagFromImage ( String imageName , String tagToBeRemoved ) { selectImage ( imageName ) ; new ContextMenu ( "Remove Tag" ) . select ( ) ; String fullTag = "" ; Combo combo = new DefaultCombo ( ) ; List < String > comboItems = combo . getItems ( ) ; for ( String item : comboItems ) { if ( item . contains ( tagToBeRemoved ) ) { fullTag = item ; break ; } } combo . setSelection ( fullTag ) ; new FinishButton ( ) . click ( ) ; }
public void processOnVmStop ( Collection < Guid > vmIds ) { for ( final Guid vmId : vmIds ) { log . infoFormat ( "Running command to process VM { 0 } that went down" , vmId ) ; ThreadPoolUtil . execute ( new Runnable ( ) { @Override public void run ( ) { Backend . getInstance ( ) . runInternalAction ( VdcActionType . ProcessDownVm , new IdParameters ( vmId ) , ExecutionHandler . createInternalJobContext ( ) ) ; } } ) ; } }

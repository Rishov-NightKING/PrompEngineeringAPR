public void flush ( ) throws IOException { entryLogManager . flush ( ) ; }
public void disableWireframe ( ) { if ( getDesiredStateChanges ( ) . contains ( wireframeStateChange ) ) { addDesiredStateChange ( faceCullingStateChange ) ; removeDesiredStateChange ( wireframeStateChange ) ; worldRenderer . requestTaskListRefresh ( ) ; } }
public void prepareConnectHostToStoragePoolServers ( ConnectHostToStoragePoolServersParameters parameters , List < StorageServerConnections > connections ) { List < StorageServerConnections > res = updateIfaces ( connections , parameters . getVds ( ) . getId ( ) ) ; connections . clear ( ) ; connections . addAll ( res ) ; }
public HibernateErrorReportingServiceDao ( ) { }
public JettyConfig getJettyConfig ( ) { return jettyConfig != null ? jettyConfig : new DefaultJettyConfig ( ) ; }
public void setNumThreads ( final Integer numThreads ) { m_threads = numThreads ; }
private String getModeName ( ) { String header = getHeader ( ) ; return header . substring ( 0 , header . indexOf ( '"' ) - 1 ) ; }
private List < RequestInfo > pollForRequests ( ) { // these are ids that were successfully put for an operation that eventually failed idsToDelete . clear ( ) ; putManager . getIdsToDelete ( idsToDelete ) ; // this is a best effort to delete ids for cleanup purposes ( these may fail and we will // not do anything about it at this time ) . for ( String blobId : idsToDelete ) { // possibly add a batch api going forward . deleteManager . submitDeleteBlobOperation ( blobId , new FutureResult < Void > ( ) , null ) ; } List < RequestInfo > requests = new ArrayList < RequestInfo > ( ) ; putManager . poll ( requests ) ; getManager . poll ( requests ) ; deleteManager . poll ( requests ) ; return requests ; }
public InternalAggregationFunction specialize ( BoundVariables boundVariables , int arity , TypeManager typeManager , FunctionManager functionManager ) { Type type = boundVariables . getTypeVariable ( "E" ) ; MethodHandle compareMethodHandle = functionManager . getScalarFunctionImplementation ( functionManager . resolveOperator ( operatorType , fromTypes ( ImmutableList . of ( type , type ) ) ) ) . getMethodHandle ( ) ; return generateAggregation ( type , compareMethodHandle ) ; }
public AccountInfo getAccountInfo ( ) throws IOException { try { CoingiBalances coingiBalances = getCoingiBalance ( ) ; return CoingiAdapters . adaptAccountInfo ( coingiBalances , exchange . getExchangeSpecification ( ) . getUserName ( ) ) ; } catch ( CoingiException e ) { throw CoingiErrorAdapter . adapt ( e ) ; } }
public Map < TableScanNode , Void > visitPlan ( PlanNode node , Void context ) { Map < TableScanNode , Void > ret = new IdentityHashMap < > ( ) ; node . getSources ( ) . forEach ( source - > ret . putAll ( source . accept ( this , context ) ) ) ; return ret ; }
protected RevCommit findHead ( Repository repo ) { try ( RevWalk walk = new RevWalk ( repo ) ) { try { ObjectId head = repo . resolve ( HEAD ) ; return walk . parseCommit ( head ) ; } catch ( RevisionSyntaxException | IOException e ) { throw new RuntimeException ( e ) ; } } }
public void process ( EquivalentContentUpdatedMessage message ) throws RecoverableException { Id contentId = message . getContentRef ( ) . getId ( ) ; log . debug ( "Processing message on id { } , took PT { } S , message : { } " , contentId , getTimeToProcessInSeconds ( message ) , message ) ; Timer . Context time = timer . time ( ) ; try { Content content = getContent ( contentId ) ; neo4JContentStore . writeContent ( content ) ; time . stop ( ) ; } catch ( Exception e ) { failureMeter . mark ( ) ; throw Throwables . propagate ( e ) ; } }
public String apply ( String dimValue ) { dimValue = ( dimValue == null ) ? "" : dimValue ; Matcher matcher = pattern . matcher ( dimValue ) ; return matcher . find ( ) ? dimValue : null ; }
private void writeSubscribeCommands ( String repoName , List < SubscribeCommand > commands ) throws IOException { write ( "repository " + repoName ) ; for ( SubscribeCommand cmd : commands ) { switch ( cmd . getCommand ( ) ) { case SUBSCRIBE : write ( "want " + cmd . getSpec ( ) ) ; break ; case UNSUBSCRIBE : write ( "stop " + cmd . getSpec ( ) ) ; break ; default : throw new IllegalArgumentException ( ) ; } } }
private Set < GlusterServerInfo > fetchServers ( VDS upServer , List < VDS > existingServers ) { Set < GlusterServerInfo > fetchedServers = null ; while ( fetchedServers == null && ! existingServers . isEmpty ( ) ) { fetchedServers = fetchServers ( upServer ) ; if ( fetchedServers == null ) { logServerMessage ( upServer , AuditLogType . GLUSTER_SERVERS_LIST_FAILED ) ; // Couldn't fetch servers from the up server . Mark it as non - operational setNonOperational ( upServer ) ; existingServers . remove ( upServer ) ; upServer = getNewUpServer ( existingServers , upServer ) ; } } return fetchedServers ; }
public static String sanitizeSecondCachedKey ( final Contentlet vanityUrl ) throws DotDataException , DotSecurityException { Host host = hostAPI . find ( vanityUrl . getStringProperty ( VanityUrlContentType . SITE_FIELD_VAR ) , APILocator . systemUser ( ) , false ) ; return sanitizeSecondCacheKey ( host . getIdentifier ( ) , vanityUrl . getLanguageId ( ) ) ; }
void remove ( I key ) { Integer prev = this . identityMap . remove ( key ) ; if ( prev != null ) { this . objectList . set ( prev , null ) ; } }
public boolean equals ( Object o ) { return this == o || o instanceof TaskPropertyType ; }
private long obtainEntityId ( ) { return nextEntityId ++ ; }
public void markInCatalog ( ) { m_isInCatalog = true ; }
private static boolean canConvert ( ParameterDefinition def , ParameterValue v ) { return def instanceof SimpleParameterDefinition && ! ( def instanceof StringParameterDefinition ) && v . getClass ( ) . equals ( StringParameterValue . class ) ; }
public void setUp ( ) { passingHandler = new FilterHandler ( ) ; filtingHandler = new FilterHandler ( ) ; filtingHandler . setFilterInvalid ( true ) ; filtingHandler . setFilterZero ( true ) ; filtingHandler . setFilterDuplicate ( true ) ; filtingHandler . setFilterFuture ( true ) ; filtingHandler . setFilterApproximate ( true ) ; filtingHandler . setFilterStatic ( true ) ; filtingHandler . setFilterDistance ( 10 ) ; filtingHandler . setFilterLimit ( 10 ) ; }
public boolean download ( String url , String downloadPath ) { InputStream in = null ; try { in = new URL ( url ) . openStream ( ) ; FileUtils . writeByteArrayToFile ( new File ( downloadPath ) , IOUtils . toByteArray ( in ) ) ; return true ; } catch ( IOException e ) { log . error ( e ) ; return false ; } finally { IOUtils . closeQuietly ( in ) ; } }
private boolean getOldChildStale ( IObservable child ) { Boolean oldChildValue = staleMap . get ( child ) ; boolean oldChildStale = oldChildValue != null && oldChildValue ; return oldChildStale ; }
public void invoke ( @NotNull final Project project , final Editor editor , PsiFile file , DataContext dataContext ) { if ( ! CommonRefactoringUtil . checkReadOnlyStatus ( file ) ) return ; performAction ( new GoIntroduceOperation ( project , editor , file ) ) ; }
private static List < String > getListOfIsoFiles ( File directory , OVirtNodeInfo info ) { List < String > isoFileList = new ArrayList < String > ( ) ; File [ ] filterOvirtFiles = filterOvirtFiles ( directory , getIsoPattern ( info ) ) ; for ( File file : filterOvirtFiles ) { isoFileList . add ( file . getName ( ) ) ; } return isoFileList ; }
EWAHCompressedBitmap getBitmap ( ) { // Fast path to immediately return the expanded result . Object r = bitmapContainer ; if ( r instanceof EWAHCompressedBitmap ) return ( EWAHCompressedBitmap ) r ; // Expand the bitmap and cache the result . XorCompressedBitmap xb = ( XorCompressedBitmap ) r ; EWAHCompressedBitmap out = xb . bitmap ; for ( ; ; ) { r = xb . xorBitmap . bitmapContainer ; if ( r instanceof EWAHCompressedBitmap ) { out = out . xor ( ( EWAHCompressedBitmap ) r ) ; bitmapContainer = out ; return out ; } xb = ( XorCompressedBitmap ) r ; out = out . xor ( xb . bitmap ) ; } }
public AbstractCorrelatingMessageHandler ( MessageGroupProcessor processor , MessageGroupStore store , CorrelationStrategy correlationStrategy , ReleaseStrategy releaseStrategy ) { Assert . notNull ( processor ) ; Assert . notNull ( store ) ; setMessageStore ( store ) ; this . outputProcessor = processor ; this . correlationStrategy = correlationStrategy == null ? new HeaderAttributeCorrelationStrategy ( IntegrationMessageHeaderAccessor . CORRELATION_ID ) : correlationStrategy ; this . releaseStrategy = releaseStrategy == null ? new SequenceSizeReleaseStrategy ( ) : releaseStrategy ; this . messagingTemplate . setSendTimeout ( DEFAULT_SEND_TIMEOUT ) ; sequenceAware = this . releaseStrategy instanceof SequenceSizeReleaseStrategy ; }
public Statement createBootstrapScriptForGroup ( String group , @Nullable String nodeName ) { return groupToBootScript . apply ( group , nodeName ) ; }
public boolean create ( Personname personnameRecord ) { LOG . trace ( "PersonnameDAO . create ( ) - Begin" ) ; return personnameRecord != null ? super . create ( personnameRecord ) : true ; }
public void handleInvocation ( EJBClientInvocationContext context ) throws Exception { log . debug ( "In the client interceptor handleInvocation : " + this . getClass ( ) . getName ( ) + " " + context . getViewClass ( ) + " " + context . getLocator ( ) ) ; // Must make this call context . sendRequest ( ) ; }
public void edit ( final NewExternalSubnetModel subnet ) { driver . edit ( subnet ) ; networkEditor . asValueBox ( ) . setValue ( subnet . getNetwork ( ) . getEntity ( ) . getName ( ) ) ; }
protected AddVmFromTemplateCommand < AddVmParameters > createCommand ( ) { initVM ( ) ; return new AddVmFromTemplateCommand < > ( new AddVmParameters ( vm ) , null ) ; }
public void testGetNameFromPath ( ) { String path1 = " / group1" ; assertEquals ( HDF5Utils . getNameFromPath ( path1 ) , "group1" ) ; }
public GlusterLocalLogicalVolumeListReturn glusterLogicalVolumeList ( ) { JsonRpcRequest request = new RequestBuilder ( "GlusterHost . logicalVolumeList" ) . build ( ) ; Map < String , Object > response = new FutureMap ( this . client , request ) . withIgnoreResponseKey ( ) ; return new GlusterLocalLogicalVolumeListReturn ( response ) ; }
@Override public String toString ( ) { return "TypedByteArray [ length = " + length ( ) + " ] " ; }
public void onEntityDestroyed ( EntityRef entity ) { if ( entity . isPersistent ( ) ) { entityDeltas . remove ( entity . getId ( ) ) ; destroyedEntities . add ( entity . getId ( ) ) ; } }
private Optional < OrganizationalUnit > getOU ( String ouIdentifier , Collection < OrganizationalUnit > organizationalUnits ) { Optional < OrganizationalUnit > targetOU = organizationalUnits . stream ( ) . filter ( p - > p . getIdentifier ( ) . equalsIgnoreCase ( ouIdentifier ) ) . findFirst ( ) ; return targetOU ; }
public void testPutAsync ( ) throws Exception { // put Future < String > f = c . putAsync ( "k" , "v" ) ; testFuture ( f , null ) ; testK ( "v" ) ; f = c . putAsync ( "k" , "v2" ) ; testFuture ( f , "v" ) ; testK ( "v2" ) ; }
public boolean isReady ( TaskActionClient taskActionClient ) throws Exception { return true ; }
public static Map < String , EntryValue > convertBeanToEntryMap ( Object bean ) { Map < String , Object > buildAttributeValueMap = BeanUtilsExtended . buildObjectAttributeMap ( bean ) ; return Maps . transformEntries ( buildAttributeValueMap , new ObjectToEntryValueTransformer ( ) ) ; }
public RequestHeader ( Struct struct , short headerVersion ) { this ( new RequestHeaderData ( struct , headerVersion ) , headerVersion ) ; }
public void accountSession ( String username , String password ) throws TmdbInvalidParametersException { if ( username == null || password == null ) { throw new TmdbInvalidParametersException ( 401 , "Username and Password may not be null" ) ; } this . username = username ; this . password = password ; hasAccountSession = true ; }
public void setProjectName ( String projectName ) { fProjectName = projectName ; // If remote directory field is empty if ( fLocationText . getText ( ) . equals ( EMPTY_STRING ) ) { fRemoteDirSelected = false ; } // If remote directory was not selected yet if ( ! fRemoteDirSelected ) { fLocationText . setText ( getDefaultPathDisplayString ( ) ) ; } }
public void testAddChildCycle3 ( ) { assertNotNull ( fFixture ) ; assertNotNull ( f42Fixture ) ; assertNotNull ( fHiFixture ) ; ( ( CalledFunction ) f42Fixture ) . addChild ( fHiFixture ) ; }
private char formatFieldFirstCharacterToFitDroolsCoreStandards ( final String fieldName ) { if ( fieldName . length ( ) > 1 && Character . isLowerCase ( fieldName . charAt ( 0 ) ) && Character . isUpperCase ( fieldName . charAt ( 1 ) ) ) { return fieldName . charAt ( 0 ) ; } else { return Character . toUpperCase ( fieldName . charAt ( 0 ) ) ; } }
public void start ( ) { logger . trace ( "start ( ) " ) ; for ( final Class < ? > stepDefinitionType : cachedStepsInstances . keySet ( ) ) { cachedStepsInstances . put ( stepDefinitionType , createStepsInstance ( stepDefinitionType ) ) ; } }
private WorkingSetDescriptor getSelectedWorkingSet ( ) { return ( WorkingSetDescriptor ) typesListViewer . getStructuredSelection ( ) . getFirstElement ( ) ; }
public void evaluate ( ) throws Throwable { for ( FrameworkMethod before : befores ) { before . invokeExplosively ( target ) ; } next . evaluate ( ) ; }
public Response add ( OpenStackVolumeProvider provider ) { validateParameters ( provider , "name" ) ; if ( provider . isSetDataCenter ( ) ) { StoragePool storagePool = getStoragePool ( provider . getDataCenter ( ) ) ; provider . setDataCenter ( DataCenterMapper . map ( storagePool , null ) ) ; } return performCreate ( VdcActionType . AddProvider , new ProviderParameters ( map ( provider ) ) , new QueryIdResolver < Guid > ( VdcQueryType . GetProviderById , IdQueryParameters . class ) ) ; }
private void doStoreUsers ( ) { try { usersFileManager . store ( new UsersDto ( new HashSet < > ( userMap . values ( ) ) ) ) ; } catch ( IOException e ) { throw new UndeclaredThrowableException ( e ) ; } }
public void tearDown ( ) { try { globalScheduler . shutdown ( ) ; } catch ( Exception e ) { } cleanup ( ) ; tearDownOnce ( ) ; }
private CloudMachineNamer getCloudMachineNamer ( ConfigBag config ) { String namerClass = config . get ( LocationConfigKeys . CLOUD_MACHINE_NAMER_CLASS ) ; if ( namerClass != null ) { try { return ( CloudMachineNamer ) getManagementContext ( ) . getCatalog ( ) . getRootClassLoader ( ) . loadClass ( namerClass ) . getDeclaredConstructor ( ConfigBag . class ) . newInstance ( config ) ; } catch ( Exception e ) { throw Exceptions . propagate ( e ) ; } } else { return new JcloudsMachineNamer ( config ) ; } }
IllustratedSelectItem ( Object value , String label , String image ) { super ( value , label ) ; this . image = image ; }
private boolean layerGroupContainmentCheckRequired ( ) { // first , is it WMS ? Request request = Dispatcher . REQUEST . get ( ) ; if ( request == null ) { return false ; } // layer groups are used only in WMS final String service = request . getService ( ) ; return "WMS" . equalsIgnoreCase ( service ) || "gwc" . equalsIgnoreCase ( service ) ; }
public ResteasyUriInfo ( final String absoluteUri , final String contextPath , final InitData initData ) { initialize ( absoluteUri , contextPath , initData != null && InitData . canBeCached ( absoluteUri ) ? initData : null ) ; }
private void buildUnaryExpression ( UnaryExpressionTree tree ) { currentBlock . elements . add ( tree ) ; build ( tree . expression ( ) ) ; }
public Class < ? > getRealClass ( ) { return testNGMethod . getRealClass ( ) ; }
private KeyStore getSecretsStore ( ) { final File secretStoreFile = createStoreIfNeeded ( ) ; try { final KeyStore keyStore = KeyStore . getInstance ( SECRETS_STORE_KEYSTORE_TYPE ) ; try ( InputStream inputStream = Files . newInputStream ( secretStoreFile . toPath ( ) ) ) { keyStore . load ( inputStream , loadStorePassword ( ) ) ; } return keyStore ; } catch ( Exception e ) { Logger . error ( this . getClass ( ) , "unable to load secrets store " + SECRETS_STORE_FILE + " : " + e ) ; throw new DotRuntimeException ( e ) ; } }
public AnonymousSpec anonymous ( ) { if ( this . anonymous == null ) { this . anonymous = new AnonymousSpec ( ) ; } return this . anonymous ; }
public int getNumWaiters ( ) { return this . connectionPool . getNumWaiters ( ) ; }
private synchronized void store ( ) throws IOException { byte [ ] serialized = state . toCbor ( ) . serialize ( ) ; System . out . println ( "Writing " + serialized . length + " bytes to " + statePath ) ; Files . write ( statePath , serialized , StandardOpenOption . CREATE ) ; }
private static void initFacets ( @CheckForNull Fingerprint fingerprint ) { if ( fingerprint == null ) { return ; } for ( FingerprintFacet facet : fingerprint . facets ) { facet . _setOwner ( fingerprint ) ; } }
public Map < FactoryContainer , Attributes > getEnabledContainers ( ) { Map < FactoryContainer , Attributes > map = new LinkedHashMap < > ( ) ; synchronized ( _path ) { for ( Map . Entry < FactoryContainer , Attributes > entry : getReversed ( _path . entrySet ( ) ) ) { Attributes attr = entry . getValue ( ) ; if ( attr . isEnabled ( ) ) { Attributes attrClone = new Attributes ( attr ) ; map . put ( entry . getKey ( ) , attrClone ) ; } } } return map ; }
private FileListCacheValue getFileList ( ) { FileListCacheValue fileList = ( FileListCacheValue ) cache . get ( fileListCacheKey ) ; if ( fileList == null ) { fileList = new FileListCacheValue ( ) ; FileListCacheValue prev = ( FileListCacheValue ) cache . putIfAbsent ( fileListCacheKey , fileList ) ; if ( prev != null ) { fileList = prev ; } } if ( trace ) log . trace ( "Refreshed file listing view" ) ; return fileList ; }
public long size ( ) { build ( ) ; if ( body . length ( ) > - 1 ) { return body . length ( ) + partBoundary . length + partHeader . length ; } else { return - 1 ; } }
public boolean canStreamToNextPipe ( ) { return ! isCollectResults ( ) && super . canStreamToNextPipe ( ) ; // when collectResults is false , streaming is not necessary or useful }
public FoundViewHolder getFoundViewHolder ( JFieldRef idRef , AbstractJClass viewClass ) { return getFoundViewHolder ( idRef , viewClass , null ) ; }
public void tearDown ( ) { queryRunner . close ( ) ; }
private CommitConfig ( Config rc ) { commitTemplatePath = rc . getString ( ConfigConstants . CONFIG_COMMIT_SECTION , null , ConfigConstants . CONFIG_KEY_COMMIT_TEMPLATE ) ; i18nCommitEncoding = rc . getString ( ConfigConstants . CONFIG_SECTION_I18N , null , ConfigConstants . CONFIG_KEY_COMMIT_ENCODING ) ; }
public int decompress ( byte [ ] input , int inputOffset , int inputLength , byte [ ] output , int outputOffset , int maxOutputLength ) throws MalformedInputException { try { Inflater inflater = new Inflater ( true ) ; inflater . setInput ( input , inputOffset , inputLength ) ; int resultLength = inflater . inflate ( output , outputOffset , maxOutputLength ) ; inflater . end ( ) ; return resultLength ; } catch ( DataFormatException e ) { throw new RuntimeException ( e ) ; } }
public List < OutputLine > getLog ( ) { return new ArrayList < > ( this . log ) ; }
protected void doInit ( ) { super . doInit ( ) ; if ( ! this . evaluationContextSet ) { this . evaluationContext = ExpressionUtils . createStandardEvaluationContext ( getBeanFactory ( ) ) ; } Assert . state ( ! this . closeStreamAfterSend || this . isSingleUse , "Single use connection needed with closeStreamAfterSend" ) ; }
public ExtensionElementsConverter ( XStream xStream , List < DMNExtensionRegister > extensionRegisters ) { super ( xStream ) ; if ( ! extensionRegisters . isEmpty ( ) ) { this . extensionRegisters . addAll ( extensionRegisters ) ; } }
public void executeBatch ( OperationsQueue operationsQueue ) { try { if ( GridDialects . hasFacet ( getGridDialect ( ) , BatchableGridDialect . class ) || GridDialects . hasFacet ( getGridDialect ( ) , GroupingByEntityDialect . class ) ) { log . tracef ( "Executing batch" ) ; super . executeBatch ( operationsQueue ) ; } } catch ( TupleAlreadyExistsException taee ) { // TODO : Ideally , we should log the entity name + id here ; For now we trust the datastore to provide this // information via the original exception ; It'd require a fair bit of changes to obtain the entity name here // ( we'd have to obtain the persister matching the given entity key metadata which in turn would require // access to the session factory which is not easily available here ) throw log . mustNotInsertSameEntityTwice ( taee . getMessage ( ) , taee ) ; } }
public int hashCode ( ) { return ( ( startCommit . hashCode ( ) + numbers . length ) * 31 ) + getNumber ( ) ; }
private void prepareAuthForBrokerCall ( ) { AuthenticationSettings . INSTANCE . setUseBroker ( true ) ; }
public boolean isWrapperFor ( Class < ? > iface ) { if ( gridCoverage instanceof Wrapper ) { return ( ( Wrapper ) gridCoverage ) . isWrapperFor ( iface ) ; } return iface . isInstance ( gridCoverage ) ; }
DataSegment uploadDataSegment ( DataSegment segment , final int binaryVersion , final long size , final File compressedSegmentData , final String azurePath ) throws StorageException , IOException , URISyntaxException { azureStorage . uploadBlob ( compressedSegmentData , config . getContainer ( ) , azurePath ) ; final DataSegment outSegment = segment . withSize ( size ) . withLoadSpec ( this . makeLoadSpec ( new URI ( azurePath ) ) ) . withBinaryVersion ( binaryVersion ) ; log . debug ( "Deleting file [ % s ] " , compressedSegmentData ) ; compressedSegmentData . delete ( ) ; return outSegment ; }
public EEFButtonLifecycleManager ( EEFButtonDescription description , IVariableManager variableManager , IInterpreter interpreter , TransactionalEditingDomain editingDomain ) { super ( variableManager , interpreter , editingDomain ) ; this . description = description ; }
private static boolean isProbablyLog4jFormatterLogger ( MethodInvocationTree mit , String formatString ) { return mit . symbol ( ) . owner ( ) . type ( ) . is ( ORG_APACHE_LOGGING_LOG4J_LOGGER ) && ! formatString . contains ( " { } " ) && formatString . contains ( " % " ) ; }
void setMarker ( TextMarker marker , int length ) { this . marker = marker ; numSkipLines = length ; if ( checkAndUpdateArrows ( ) ) { upArrow . setHTML ( PatchUtil . M . expandBefore ( NUM_ROWS_TO_EXPAND ) ) ; downArrow . setHTML ( PatchUtil . M . expandAfter ( NUM_ROWS_TO_EXPAND ) ) ; } skipNum . setText ( PatchUtil . M . patchSkipRegion ( Integer . toString ( length ) ) ) ; }
public ExtendedEmailPublisherContext ( ExtendedEmailPublisher publisher , AbstractBuild < ? , ? > build , Launcher launcher , BuildListener listener ) { this ( publisher , build , build . getWorkspace ( ) , launcher , listener ) ; }
public void testWrongFormatNumber ( ) throws Exception { NumberCellEditor editor ; editor = new NumberCellEditor ( shell , Integer . class ) ; // empty string editor . getValue ( ) ; assertNull ( editor . getValue ( ) ) ; // not parsable number editor . setValue ( "aa" ) ; editor . getValue ( ) ; assertNull ( editor . getValue ( ) ) ; }
public void onReloadPlugin ( Plugin oldPlugin , Plugin newPlugin ) { update ( ) ; }
public Class < ? > getRealClass ( ) { return clazz ; }
private String read ( String resourcePath ) throws IOException { InputStream is = getClass ( ) . getResourceAsStream ( resourcePath ) ; return Util . read ( is ) ; }
public static String getModelFileWithGAV ( ReleaseId releaseId ) { return Paths . get ( MODEL_FILE_DIRECTORY , releaseId . getGroupId ( ) , releaseId . getArtifactId ( ) , MODEL_FILE_NAME ) . toString ( ) ; }
void removeConnection ( String connectionId ) { availableConnections . remove ( connectionId ) ; poolCount -- ; }
private Map < Long , ISegmentAspect > getAspectsFromColumnsId ( List < Long > desiredColumns ) { if ( ! desiredColumns . isEmpty ( ) ) { Map < Long , ISegmentAspect > aspects = new LinkedHashMap < > ( ) ; for ( Long columnsId : desiredColumns ) { ISegmentAspect segmentAspect = fAspectMap . get ( columnsId ) ; if ( segmentAspect != null ) { aspects . put ( columnsId , segmentAspect ) ; } } return aspects ; } return fAspectMap ; }
static boolean isValidMining ( ICodeMining mining ) { return mining != null && mining . getLabel ( ) != null && ! mining . getLabel ( ) . isEmpty ( ) ; }
public void addInput ( Page page ) { verify ( probe == null ) ; probe = page ; probePosition = 0 ; joinAddresses = null ; }
public DescriptorImpl ( ) { super ( ThrottleJobProperty . class ) ; synchronized ( propertiesByCategoryLock ) { load ( ) ; // Explictly handle the persisted data from the version 1 . 8 . 1 if ( propertiesByCategory == null ) { propertiesByCategory = new HashMap < String , Map < ThrottleJobProperty , Void > > ( ) ; } if ( ! propertiesByCategory . isEmpty ( ) ) { propertiesByCategory . clear ( ) ; save ( ) ; // Save the configuration to remove obsolete data } } }
public String toString ( ) { // Since the static data arrives from external source it's not guarenteed not to be null so a null check is // mandatory in order to avoid NPE when invoking toString by the logger String domainName = staticData == null ? "null" : staticData . getName ( ) ; Guid domainId = staticData == null ? null : staticData . getId ( ) ; return "StorageDomain [ " + domainName + " , " + domainId + " ] " ; }
Predicate < Entry < Key , Value > > getScanPredicate ( ) { final Range range = getRange ( ) ; return input - > range == null || range . contains ( input . getKey ( ) ) ; }
public AlluxioHiveMetastore ( TableMasterClient client ) { this . client = requireNonNull ( client , "client is null" ) ; }
private void addWorkPackageCriteria ( ) { if ( isWorkPackageSpecified ( ) ) { ArtifactId workPackArt = atsApi . getQueryService ( ) . getArtifactOrSentinel ( workPackageId ) ; if ( workPackArt . isValid ( ) ) { if ( isColorTeamMatch ( workPackArt ) ) { queryAnd ( AtsAttributeTypes . WorkPackageReference , workPackArt . getIdString ( ) ) ; } } } }
private void sendToSocket ( Socket socket , String cmdString ) throws IOException { // remove spaces at beginning and end and replace double spaces in // string with single space byte [ ] sendBytes = ( "A" + cmdString . trim ( ) . replaceAll ( "\\s + " , " " ) + "\n" ) . getBytes ( ) ; socket . getInputStream ( ) . skip ( socket . getInputStream ( ) . available ( ) ) ; socket . getOutputStream ( ) . write ( sendBytes ) ; socket . getOutputStream ( ) . flush ( ) ; AstericsErrorHandling . instance . reportInfo ( this , "IRTrans sent data : " + cmdString ) ; }
public int hashCode ( ) { return 1 ; }
private void reset ( ) { next = NO_ID ; setId ( NO_ID ) ; }
public String getActualDowntime ( ) { return ( actualDowntime == null ) ? " ( N / A ) " : actualDowntime + "ms" ; }
String resolveTemplatePath ( final Context context , final Writer writer , final RenderParams params , final String argument ) { return ( params . live ) ? " / live / " + argument + " . " + EXTENSION : " / working / " + argument + " . " + EXTENSION ; }
public DispoConfig findDispoConfig ( DispoProgram program ) { ArtifactReadable config = getQuery ( ) . fromBranch ( program . getUuid ( ) ) . andNameEquals ( "Program Config" ) . getResults ( ) . getOneOrNull ( ) ; if ( config == null ) { return DispoUtil . getDefaultConfig ( ) ; } return DispoUtil . configArtToConfigData ( new DispoConfigArtifact ( config ) ) ; }
public boolean hasMatchingOpSig ( String name , JavaOperationSigMask mask ) { // Indexing on signatures optimises this type of request for ( Entry < JavaOperationSignature , Set < String > > entry : operations . entrySet ( ) ) { if ( mask . covers ( entry . getKey ( ) ) ) { if ( entry . getValue ( ) . contains ( name ) ) { return true ; } } } return false ; }
public IonSqlQueryBuilder ( TypeManager typeManager ) { this . typeManager = requireNonNull ( typeManager , "typeManager is null" ) ; }
private OperationController getOperationController ( ) { return ocList . get ( ThreadLocalRandom . current ( ) . nextInt ( ocList . size ( ) ) ) ; }
public List < JDK > getJDKs ( ) { return jdks ; }
public boolean addAll ( int index , Collection < ? extends T > c ) { Collection < T > uniqueValuesToAdd = getUniqueValues ( c ) ; if ( uniqueValuesToAdd . isEmpty ( ) ) { return false ; } try { return super . addAll ( index , uniqueValuesToAdd ) ; } catch ( IndexOutOfBoundsException ioobException ) { comparingSet . removeAll ( uniqueValuesToAdd ) ; throw ioobException ; } }
public Context getContext ( ) { return new Context ( "Sdk - Name" , sdkName ) . addData ( "Sdk - Version" , SDK_VERSION ) ; }
protected void setSelectedDevices ( List < StorageDevice > selectedDevices ) { getStorageDevices ( ) . setSelectedItems ( selectedDevices ) ; }
private JsonObject toJson ( Timer timer , TimeUnit rateUnit , TimeUnit durationUnit ) { Snapshot snapshot = timer . getSnapshot ( ) ; JsonObject json = new JsonObject ( ) ; // Meter populateMetered ( json , timer , rateUnit ) ; // Snapshot double factor = 1 . 0 / durationUnit . toNanos ( 1 ) ; populateSnapshot ( json , snapshot , factor ) ; // Duration rate String duration = durationUnit . toString ( ) . toLowerCase ( ) ; json . putString ( "durationRate" , duration ) ; return json ; }
protected void delete ( LogEntry delegate , String reason , RequestContext context ) throws ResourceDoesNotSupportOperationException { throw new ResourceDoesNotSupportOperationException ( ) ; }
public void setConsumerBatchEnabled ( boolean consumerBatchEnabled ) { this . consumerBatchEnabled = consumerBatchEnabled ; }
public int getLevel ( ) { return data . optInt ( "toclevel" , 1 ) ; }
private void setPagesRecycler ( OnThisDayCard card ) { if ( card . pages ( ) != null ) { RecyclerAdapter recyclerAdapter = new RecyclerAdapter ( card . pages ( ) , card . wiki ( ) , true , ( Activity ) getContext ( ) ) ; recyclerAdapter . setCallback ( new ItemCallback ( ) ) ; pagesRecycler . setAdapter ( recyclerAdapter ) ; } else { pagesRecycler . setVisibility ( GONE ) ; } }
public String getExtendedLabelForVSM ( String providedShapeURI ) { for ( IConfigurationElement configurationElement : extensions ) { String identifier = ( ( ExtensionHandle ) configurationElement . getParent ( ) ) . getSimpleIdentifier ( ) ; if ( identifier != null && identifier . equals ( providedShapeURI ) ) { return getExtendedLabelForVSM ( configurationElement ) ; } } return "Unknown URI" ; // $NON - NLS - 1$ }
public void stopServer ( ) { if ( server instanceof GrizzlyServer ) { ( ( GrizzlyServer ) server ) . setCleanIdleConnections ( true ) ; } server . stop ( ) ; }
protected Supplier < Operation > createOperationSupplier ( ) { return this ; }
public < C extends CtTypedElement > C setType ( CtTypeReference < T > type ) { if ( type != null ) { type . setParent ( this ) ; } if ( getExecutable ( ) != null ) { getExecutable ( ) . setType ( type ) ; } return ( C ) this ; }
